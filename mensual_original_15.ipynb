{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "293a981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:198: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/23/25 13:43:48] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/23/25 13:43:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=555522;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=67056;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\u001b\\\u001b[2m1352\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\Usuario\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "#importación de librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from pandas import DateOffset\n",
    "import boto3\n",
    "import sagemaker\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d70a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data_csv/15_materiales.csv',sep=',',index_col=0,parse_dates=True,decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "88e02f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los materiales son [20008046001 20001374001 25109225001 20000400003 25109232001 20003257004\n",
      " 20003147001 20001016001 20003257001 20003257002 20000837001 20000815002\n",
      " 20000337001 20000837002 20000815003]\n"
     ]
    }
   ],
   "source": [
    "materiales = df['material'].unique()\n",
    "print(f'Los materiales son {materiales}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ef6478e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = []\n",
    "materiales = df['material'].unique()\n",
    "for mat in materiales:\n",
    "    serie = df[df['material'] == mat].sort_index()\n",
    "    timeseries.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "d08a2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumar_cantidades_fechas(lista_dataframes, fechas=['2023-11-01', '2023-11-02']):\n",
    "    \"\"\"\n",
    "    Suma la columna 'cantidad' para las fechas especificadas en cada dataframe\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha\n",
    "        fechas: Lista de fechas a considerar (por defecto '2023-11-01' y '2023-11-02')\n",
    "    \n",
    "    Returns:\n",
    "        Un diccionario con las sumas por cada dataframe\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        suma = 0\n",
    "        for fecha in fechas:\n",
    "            if fecha in df.index:\n",
    "                suma += df.loc[fecha, 'cantidad']\n",
    "        resultados[f'dataframe_{i}'] = suma\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "70e31e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = sumar_cantidades_fechas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "660f22ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataframe_0': 41.0,\n",
       " 'dataframe_1': 5.0,\n",
       " 'dataframe_2': 77.0,\n",
       " 'dataframe_3': 20.0,\n",
       " 'dataframe_4': 42.0,\n",
       " 'dataframe_5': 24.0,\n",
       " 'dataframe_6': 128.0,\n",
       " 'dataframe_7': 3.0,\n",
       " 'dataframe_8': 43.0,\n",
       " 'dataframe_9': 58.0,\n",
       " 'dataframe_10': 28.0,\n",
       " 'dataframe_11': 24.0,\n",
       " 'dataframe_12': 32.0,\n",
       " 'dataframe_13': 43.0,\n",
       " 'dataframe_14': 30.0}"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e1469fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_fechas(lista_dataframes, fechas=['2023-11-01', '2023-11-02']):\n",
    "    \"\"\"\n",
    "    Elimina los registros de las fechas especificadas en cada dataframe\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha\n",
    "        fechas: Lista de fechas a eliminar (por defecto '2023-11-01' y '2023-11-02')\n",
    "    \n",
    "    Returns:\n",
    "        Una nueva lista de dataframes sin los registros de las fechas indicadas\n",
    "    \"\"\"\n",
    "    nuevos_dataframes = []\n",
    "    \n",
    "    for df in lista_dataframes:\n",
    "        # Crear una copia para no modificar el original\n",
    "        df_nuevo = df.copy()\n",
    "        # Eliminar las fechas especificadas si existen en el índice\n",
    "        df_nuevo = df_nuevo.drop(fechas, errors='ignore')\n",
    "        nuevos_dataframes.append(df_nuevo)\n",
    "    \n",
    "    return nuevos_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "7a27fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = eliminar_fechas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "f61924e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_por_mes(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Agrupa los datos por mes-año, sumando la columna 'cantidad' y manteniendo las columnas categóricas.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha en formato 'YYYY-MM-DD'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con datos agrupados por mes-año\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    dataframes_agrupados = []\n",
    "    \n",
    "    for df in lista_dataframes:\n",
    "        # Verificar que el índice sea de tipo datetime\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Crear una columna con el mes-año para agrupar\n",
    "        df_copia = df.copy()\n",
    "        df_copia['mes_anio'] = df_copia.index.strftime('%Y-%m')\n",
    "        \n",
    "        # Identificar columnas categóricas (todas excepto 'cantidad')\n",
    "        cols_categoricas = [col for col in df_copia.columns if col != 'cantidad' and col != 'mes_anio']\n",
    "        \n",
    "        # Realizar la agrupación\n",
    "        if cols_categoricas:\n",
    "            # Si hay columnas categóricas, agrupar por mes_anio y columnas categóricas\n",
    "            grupos = df_copia.groupby(['mes_anio'] + cols_categoricas)\n",
    "            # Sumar la cantidad para cada grupo\n",
    "            agrupado = grupos['cantidad'].sum().reset_index()\n",
    "            # Convertir 'mes_anio' en índice de datetime (primer día del mes)\n",
    "            agrupado['fecha'] = pd.to_datetime(agrupado['mes_anio'] + '-01')\n",
    "            agrupado = agrupado.set_index('fecha')\n",
    "            agrupado = agrupado.drop('mes_anio', axis=1)\n",
    "        else:\n",
    "            # Si no hay columnas categóricas, agrupar solo por mes_anio\n",
    "            agrupado = df_copia.groupby('mes_anio')['cantidad'].sum().reset_index()\n",
    "            agrupado['fecha'] = pd.to_datetime(agrupado['mes_anio'] + '-01')\n",
    "            agrupado = agrupado.set_index('fecha')\n",
    "            agrupado = agrupado.drop('mes_anio', axis=1)\n",
    "        \n",
    "        dataframes_agrupados.append(agrupado)\n",
    "    \n",
    "    return dataframes_agrupados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "81f46803",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = agrupar_por_mes(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d5a5bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_ultimo_registro(dataframes_agrupados):\n",
    "    \"\"\"\n",
    "    Elimina el último registro de cada dataframe en la lista.\n",
    "    \n",
    "    Args:\n",
    "        dataframes_agrupados: Lista de dataframes con datos agrupados por mes-año\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con el último registro eliminado en cada uno\n",
    "    \"\"\"\n",
    "    resultado = []\n",
    "    \n",
    "    for df in dataframes_agrupados:\n",
    "        # Si el dataframe tiene al menos un registro\n",
    "        if len(df) > 0:\n",
    "            # Eliminar el último registro\n",
    "            df_sin_ultimo = df.iloc[:-1].copy()\n",
    "            resultado.append(df_sin_ultimo)\n",
    "        else:\n",
    "            # Si el dataframe está vacío, agregarlo sin cambios\n",
    "            resultado.append(df.copy())\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "4eb5b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = eliminar_ultimo_registro(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d2fea5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajustar_para_mantener_ratios(timeseries, resultados):\n",
    "    \"\"\"\n",
    "    Ajusta los valores de 2023-09 y 2023-10 sumando cantidades para que mantengan \n",
    "    los mismos ratios que 2022-09 y 2022-10, utilizando los valores de 'resultados'.\n",
    "    \n",
    "    Args:\n",
    "        timeseries: Lista de dataframes mensuales\n",
    "        resultados: Diccionario con las sumas de cantidades\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con las cantidades ajustadas\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    dataframes_ajustados = []\n",
    "    \n",
    "    for i, df in enumerate(timeseries):\n",
    "        df_ajustado = df.copy()\n",
    "        clave_resultado = f'dataframe_{i}'\n",
    "        \n",
    "        # Verificar que exista el valor en resultados\n",
    "        if clave_resultado in resultados:\n",
    "            valor_a_distribuir = resultados[clave_resultado]\n",
    "            \n",
    "            # 1. Calcular los ratios objetivo de 2022-09 y 2022-10\n",
    "            if '2022-09-01' in df_ajustado.index and '2022-10-01' in df_ajustado.index:\n",
    "                valor_sep_2022 = df_ajustado.loc['2022-09-01', 'cantidad']\n",
    "                valor_oct_2022 = df_ajustado.loc['2022-10-01', 'cantidad']\n",
    "                \n",
    "                # Ratio objetivo (proporción de sep respecto a la suma)\n",
    "                if valor_sep_2022 + valor_oct_2022 > 0:\n",
    "                    ratio_objetivo = valor_sep_2022 / (valor_sep_2022 + valor_oct_2022)\n",
    "                else:\n",
    "                    ratio_objetivo = 0.5\n",
    "                \n",
    "                # Valores actuales o cero si no existen\n",
    "                valor_sep_2023 = df_ajustado.loc['2023-09-01', 'cantidad'] if '2023-09-01' in df_ajustado.index else 0\n",
    "                valor_oct_2023 = df_ajustado.loc['2023-10-01', 'cantidad'] if '2023-10-01' in df_ajustado.index else 0\n",
    "                \n",
    "                # 2. Calcular cuánto agregar a cada mes para mantener el ratio objetivo\n",
    "                # Resolviendo el sistema de ecuaciones:\n",
    "                # (valor_sep_2023 + x) / (valor_sep_2023 + x + valor_oct_2023 + y) = ratio_objetivo\n",
    "                # x + y = valor_a_distribuir\n",
    "                \n",
    "                # Si ambos valores son cero, distribuimos según el ratio objetivo\n",
    "                if valor_sep_2023 == 0 and valor_oct_2023 == 0:\n",
    "                    incremento_sep = valor_a_distribuir * ratio_objetivo\n",
    "                    incremento_oct = valor_a_distribuir * (1 - ratio_objetivo)\n",
    "                else:\n",
    "                    # Para mantener el ratio: (a + x) / (a + b + x + y) = r, donde x + y = v\n",
    "                    # Resolviendo: x = (r*(a+b) - a) + r*v\n",
    "                    a = valor_sep_2023\n",
    "                    b = valor_oct_2023\n",
    "                    r = ratio_objetivo\n",
    "                    v = valor_a_distribuir\n",
    "                    \n",
    "                    # Calculamos los incrementos\n",
    "                    incremento_sep = max(0, (r*(a+b) - a) + r*v)\n",
    "                    incremento_oct = max(0, v - incremento_sep)\n",
    "                    \n",
    "                    # Si hay valores negativos, ajustamos la distribución\n",
    "                    if incremento_sep < 0 or incremento_oct < 0:\n",
    "                        incremento_sep = v * r\n",
    "                        incremento_oct = v * (1 - r)\n",
    "                \n",
    "                # Actualizar o crear los registros para 2023-09\n",
    "                if '2023-09-01' in df_ajustado.index:\n",
    "                    # Sumar el incremento calculado\n",
    "                    df_ajustado.loc['2023-09-01', 'cantidad'] += incremento_sep\n",
    "                else:\n",
    "                    # Crear nuevo registro\n",
    "                    nuevo_registro = pd.DataFrame(index=[pd.to_datetime('2023-09-01')])\n",
    "                    \n",
    "                    # Copiar valores categóricos\n",
    "                    if len(df_ajustado) > 0:\n",
    "                        for col in df_ajustado.columns:\n",
    "                            if col != 'cantidad':\n",
    "                                nuevo_registro[col] = df_ajustado[col].iloc[0]\n",
    "                    \n",
    "                    # Asignar el valor calculado\n",
    "                    nuevo_registro['cantidad'] = incremento_sep\n",
    "                    \n",
    "                    # Concatenar\n",
    "                    df_ajustado = pd.concat([df_ajustado, nuevo_registro])\n",
    "                \n",
    "                # Actualizar o crear los registros para 2023-10\n",
    "                if '2023-10-01' in df_ajustado.index:\n",
    "                    # Sumar el incremento calculado\n",
    "                    df_ajustado.loc['2023-10-01', 'cantidad'] += incremento_oct\n",
    "                else:\n",
    "                    # Crear nuevo registro\n",
    "                    nuevo_registro = pd.DataFrame(index=[pd.to_datetime('2023-10-01')])\n",
    "                    \n",
    "                    # Copiar valores categóricos\n",
    "                    if len(df_ajustado) > 0:\n",
    "                        for col in df_ajustado.columns:\n",
    "                            if col != 'cantidad':\n",
    "                                nuevo_registro[col] = df_ajustado[col].iloc[0]\n",
    "                    \n",
    "                    # Asignar el valor calculado\n",
    "                    nuevo_registro['cantidad'] = incremento_oct\n",
    "                    \n",
    "                    # Concatenar\n",
    "                    df_ajustado = pd.concat([df_ajustado, nuevo_registro])\n",
    "                \n",
    "                # Ordenar por fecha\n",
    "                df_ajustado = df_ajustado.sort_index()\n",
    "        \n",
    "        dataframes_ajustados.append(df_ajustado)\n",
    "    \n",
    "    return dataframes_ajustados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "2cfb4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = ajustar_para_mantener_ratios(timeseries,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7c88d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_columnas_temporales(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Agrega las columnas 'month' y 'quarter' a cada dataframe, calculadas a partir del índice de fecha.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con las nuevas columnas 'month' y 'quarter'\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    resultado = []\n",
    "    \n",
    "    for df in lista_dataframes:\n",
    "        # Crear una copia del dataframe\n",
    "        df_nuevo = df.copy()\n",
    "        \n",
    "        # Asegurarse de que el índice es de tipo datetime\n",
    "        if not isinstance(df_nuevo.index, pd.DatetimeIndex):\n",
    "            df_nuevo.index = pd.to_datetime(df_nuevo.index)\n",
    "        \n",
    "        # Agregar columna de mes (valores 1-12)\n",
    "        df_nuevo['month'] = df_nuevo.index.month\n",
    "        \n",
    "        # Agregar columna de trimestre (valores 1-4)\n",
    "        df_nuevo['quarter'] = df_nuevo.index.quarter\n",
    "        \n",
    "        # Añadir a la lista de resultados\n",
    "        resultado.append(df_nuevo)\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "135b69cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = agregar_columnas_temporales(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5602e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificar_columnas_categoricas(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Codifica las columnas categóricas usando códigos numéricos únicos para cada valor.\n",
    "    Las columnas a codificar son: Tipo_Producto, segmento_producto, supergrupo_producto, \n",
    "    grupo_producto y subgrupo_producto.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con columnas categóricas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con columnas categóricas codificadas y diccionario de mapeos\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Columnas categóricas a codificar\n",
    "    columnas_categoricas = [\n",
    "        'Tipo_Producto', \n",
    "        'segmento_producto', \n",
    "        'supergrupo_producto', \n",
    "        'grupo_producto', \n",
    "        'subgrupo_producto'\n",
    "    ]\n",
    "    \n",
    "    # Diccionario para almacenar los mapeos para cada columna\n",
    "    mapeos = {col: {} for col in columnas_categoricas}\n",
    "    \n",
    "    # Lista para almacenar los dataframes codificados\n",
    "    dataframes_codificados = []\n",
    "    \n",
    "    # Crear mapeos para cada columna categórica\n",
    "    codigo_actual = {}\n",
    "    for col in columnas_categoricas:\n",
    "        codigo_actual[col] = 0\n",
    "    \n",
    "    # Iterar sobre cada dataframe para crear los mapeos\n",
    "    for df in lista_dataframes:\n",
    "        for col in columnas_categoricas:\n",
    "            if col in df.columns:\n",
    "                # Obtener el valor único en esta columna para este dataframe\n",
    "                # (asumiendo que cada dataframe tiene un solo valor para cada columna categórica)\n",
    "                if len(df) > 0:\n",
    "                    valor = df[col].iloc[0]\n",
    "                    \n",
    "                    # Si el valor no está en el mapeo, asignarle un código\n",
    "                    if valor not in mapeos[col]:\n",
    "                        mapeos[col][valor] = codigo_actual[col]\n",
    "                        codigo_actual[col] += 1\n",
    "    \n",
    "    # Aplicar los mapeos a cada dataframe\n",
    "    for df in lista_dataframes:\n",
    "        df_codificado = df.copy()\n",
    "        \n",
    "        for col in columnas_categoricas:\n",
    "            if col in df.columns:\n",
    "                if len(df) > 0:\n",
    "                    valor = df[col].iloc[0]\n",
    "                    codigo = mapeos[col][valor]\n",
    "                    \n",
    "                    # Reemplazar el valor categórico con su código\n",
    "                    df_codificado[col] = codigo\n",
    "        \n",
    "        dataframes_codificados.append(df_codificado)\n",
    "    \n",
    "    return dataframes_codificados, mapeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "7fc8d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries,mapeos = codificar_columnas_categoricas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "76a7acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tipo_Producto': {'LILI PINK': 0, 'YOI': 1},\n",
       " 'segmento_producto': {'ADULTO': 0, 'TEEN': 1, 'GIRLS': 2, 'JUVENIL': 3},\n",
       " 'supergrupo_producto': {'INTERIOR MUJER': 0,\n",
       "  'INTERIOR TEEN': 1,\n",
       "  'BELLEZA Y BIENESTAR': 2,\n",
       "  'INTERIOR JUVENIL': 3,\n",
       "  'LINEA SECRET': 4},\n",
       " 'grupo_producto': {'PANTY PAQX2': 0,\n",
       "  'FRAGANCIAS': 1,\n",
       "  'BRASIER PAQX2': 2,\n",
       "  'BRASIER SILICONA': 3,\n",
       "  'PANTY': 4,\n",
       "  'PANTY PAQX3': 5},\n",
       " 'subgrupo_producto': {'MICROFIBRA': 0,\n",
       "  'SEAMLESS': 1,\n",
       "  'NO APLICA': 2,\n",
       "  'ALGODON': 3,\n",
       "  'SILICONA': 4,\n",
       "  'ENCAJE': 5}}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "950521f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_registros_mensuales(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Verifica que existan registros para todos los meses desde la primera hasta la última fecha\n",
    "    en cada dataframe, e identifica los meses faltantes.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha en formato 'YYYY-MM-DD'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de tuplas (dataframe_id, completo, meses_faltantes) donde:\n",
    "        - dataframe_id: Índice del dataframe en la lista\n",
    "        - completo: Boolean indicando si tiene todos los meses\n",
    "        - meses_faltantes: Lista de fechas de meses faltantes en formato 'YYYY-MM-01'\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Asegurarse de que el índice es de tipo datetime\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df = df.copy()\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Verificar que hay registros en el dataframe\n",
    "        if len(df) == 0:\n",
    "            resultados.append((i, True, []))\n",
    "            continue\n",
    "        \n",
    "        # Obtener la primera y última fecha\n",
    "        primera_fecha = df.index.min()\n",
    "        ultima_fecha = df.index.max()\n",
    "        \n",
    "        # Crear un rango de todos los meses entre la primera y última fecha\n",
    "        todos_los_meses = pd.date_range(\n",
    "            start=pd.Timestamp(year=primera_fecha.year, month=primera_fecha.month, day=1),\n",
    "            end=pd.Timestamp(year=ultima_fecha.year, month=ultima_fecha.month, day=1),\n",
    "            freq='MS'  # Inicio de mes (Month Start)\n",
    "        )\n",
    "        \n",
    "        # Convertir los índices del dataframe a inicio de mes\n",
    "        meses_presentes = df.index.to_period('M').to_timestamp()\n",
    "        meses_presentes = meses_presentes.unique()  # Eliminar duplicados\n",
    "        \n",
    "        # Encontrar meses faltantes\n",
    "        meses_faltantes = [fecha for fecha in todos_los_meses if fecha not in meses_presentes]\n",
    "        \n",
    "        # Determinar si está completo\n",
    "        completo = len(meses_faltantes) == 0\n",
    "        \n",
    "        # Guardar resultados\n",
    "        resultados.append((i, completo, meses_faltantes))\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "a5323dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, True, []),\n",
       " (1, True, []),\n",
       " (2, True, []),\n",
       " (3, True, []),\n",
       " (4, True, []),\n",
       " (5, True, []),\n",
       " (6, True, []),\n",
       " (7, True, []),\n",
       " (8, True, []),\n",
       " (9, True, []),\n",
       " (10, True, []),\n",
       " (11, True, []),\n",
       " (12, True, []),\n",
       " (13, True, []),\n",
       " (14, True, [])]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verificar_registros_mensuales(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "982031b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_vectores_categoricos(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae los valores categóricos del primer registro de cada dataframe y crea\n",
    "    un vector con estos valores.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes que contienen columnas categóricas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de vectores categóricos, uno por cada dataframe\n",
    "    \"\"\"\n",
    "    # Definir las columnas categóricas\n",
    "    columnas_categoricas = [\n",
    "        'Tipo_Producto', \n",
    "        'segmento_producto', \n",
    "        'supergrupo_producto', \n",
    "        'grupo_producto', \n",
    "        'subgrupo_producto'\n",
    "    ]\n",
    "    \n",
    "    vectores_categoricos = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío, se usará un vector de ceros.\")\n",
    "            vectores_categoricos.append([0] * len(columnas_categoricas))\n",
    "            continue\n",
    "        \n",
    "        # Crear el vector para este dataframe\n",
    "        vector = []\n",
    "        \n",
    "        for col in columnas_categoricas:\n",
    "            # Verificar si la columna existe en el dataframe\n",
    "            if col in df.columns:\n",
    "                # Obtener el valor del primer registro\n",
    "                valor = df[col].iloc[0]\n",
    "                \n",
    "                # Convertir a entero si es posible, de lo contrario usar un código hash\n",
    "                try:\n",
    "                    valor_numerico = int(valor)\n",
    "                except (ValueError, TypeError):\n",
    "                    # Si no se puede convertir a entero, usar un código hash simple\n",
    "                    if valor is None:\n",
    "                        valor_numerico = 0\n",
    "                    else:\n",
    "                        # Hash simple basado en la representación string del valor\n",
    "                        valor_numerico = hash(str(valor)) % 10000  # Limitar a 4 dígitos\n",
    "            else:\n",
    "                # Si la columna no existe, usar 0\n",
    "                valor_numerico = 0\n",
    "            \n",
    "            vector.append(valor_numerico)\n",
    "        \n",
    "        vectores_categoricos.append(vector)\n",
    "        \n",
    "    return vectores_categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d63ec96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_cat = extraer_vectores_categoricos(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a31cbf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_vectores_cantidad(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae los valores de la columna 'cantidad' de cada dataframe y crea \n",
    "    un vector con estos valores.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes que contienen la columna 'cantidad'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de vectores, donde cada vector contiene los valores de 'cantidad' de un dataframe\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    vectores_cantidad = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío.\")\n",
    "            vectores_cantidad.append([])\n",
    "            continue\n",
    "        \n",
    "        # Verificar que exista la columna 'cantidad'\n",
    "        if 'cantidad' not in df.columns:\n",
    "            print(f\"Advertencia: Dataframe {i} no tiene columna 'cantidad'.\")\n",
    "            vectores_cantidad.append([])\n",
    "            continue\n",
    "        \n",
    "        # Extraer los valores de 'cantidad' como una lista\n",
    "        valores = df['cantidad'].tolist()\n",
    "        \n",
    "        # Opcionalmente, puedes manejar valores NaN\n",
    "        # valores = [0 if pd.isna(x) else x for x in valores]  # Convierte NaN a 0\n",
    "        # O simplemente:\n",
    "        valores = df['cantidad'].fillna(0).tolist()  # Rellena NaN con 0\n",
    "        \n",
    "        vectores_cantidad.append(valores)\n",
    "    \n",
    "    return vectores_cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5db630e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_target = extraer_vectores_cantidad(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "327fa6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_vectores_temporales(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae los valores de las columnas 'month' y 'quarter' de cada dataframe\n",
    "    y crea un conjunto de vectores con estos valores.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes que contienen las columnas 'month' y 'quarter'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de conjuntos de vectores, donde cada conjunto contiene los vectores\n",
    "        de 'month' y 'quarter' para un dataframe\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    conjuntos_vectores = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío.\")\n",
    "            conjuntos_vectores.append(([], []))\n",
    "            continue\n",
    "        \n",
    "        # Verificar que existan las columnas necesarias\n",
    "        columnas_faltantes = []\n",
    "        if 'month' not in df.columns:\n",
    "            columnas_faltantes.append('month')\n",
    "        if 'quarter' not in df.columns:\n",
    "            columnas_faltantes.append('quarter')\n",
    "        \n",
    "        if columnas_faltantes:\n",
    "            print(f\"Advertencia: Dataframe {i} no tiene las columnas: {columnas_faltantes}\")\n",
    "            \n",
    "            # Si faltan las columnas, podemos crearlas a partir del índice si es de tipo fecha\n",
    "            df_temp = df.copy()\n",
    "            \n",
    "            if isinstance(df_temp.index, pd.DatetimeIndex):\n",
    "                if 'month' not in df_temp.columns:\n",
    "                    df_temp['month'] = df_temp.index.month\n",
    "                if 'quarter' not in df_temp.columns:\n",
    "                    df_temp['quarter'] = df_temp.index.quarter\n",
    "            else:\n",
    "                # Si el índice no es de tipo fecha, tratar de convertirlo\n",
    "                try:\n",
    "                    df_temp.index = pd.to_datetime(df_temp.index)\n",
    "                    if 'month' not in df_temp.columns:\n",
    "                        df_temp['month'] = df_temp.index.month\n",
    "                    if 'quarter' not in df_temp.columns:\n",
    "                        df_temp['quarter'] = df_temp.index.quarter\n",
    "                except:\n",
    "                    # Si no se puede convertir, usar valores vacíos\n",
    "                    month_vector = []\n",
    "                    quarter_vector = []\n",
    "                    conjuntos_vectores.append((month_vector, quarter_vector))\n",
    "                    continue\n",
    "            \n",
    "            # Usar el dataframe temporal con las columnas agregadas\n",
    "            df = df_temp\n",
    "        \n",
    "        # Extraer los vectores\n",
    "        month_vector = df['month'].tolist()\n",
    "        quarter_vector = df['quarter'].tolist()\n",
    "        \n",
    "        # Guardar el conjunto de vectores\n",
    "        conjuntos_vectores.append((month_vector, quarter_vector))\n",
    "    \n",
    "    return conjuntos_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "7ebcdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_dynamic = extraer_vectores_temporales(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "bf970b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_primeros_indices(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae el primer índice de cada dataframe y lo devuelve en formato \"YYYY-MM-DD 00:00:00\".\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índices de fecha\n",
    "    \n",
    "    Returns:\n",
    "        Lista de strings con los primeros índices en formato \"YYYY-MM-DD 00:00:00\"\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    primeros_indices = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío. Se usará fecha por defecto.\")\n",
    "            primeros_indices.append(\"2000-01-01 00:00:00\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener el primer índice\n",
    "        primer_indice = df.index[0]\n",
    "        \n",
    "        # Convertir a datetime si no lo es\n",
    "        if not isinstance(primer_indice, pd.Timestamp) and not isinstance(primer_indice, datetime):\n",
    "            try:\n",
    "                primer_indice = pd.to_datetime(primer_indice)\n",
    "            except:\n",
    "                print(f\"Advertencia: No se pudo convertir el índice del Dataframe {i} a fecha. Se usará fecha por defecto.\")\n",
    "                primeros_indices.append(\"2000-01-01 00:00:00\")\n",
    "                continue\n",
    "        \n",
    "        # Formatear a \"YYYY-MM-DD 00:00:00\"\n",
    "        indice_formateado = primer_indice.strftime(\"%Y-%m-%d 00:00:00\")\n",
    "        \n",
    "        primeros_indices.append(indice_formateado)\n",
    "    \n",
    "    return primeros_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "4042f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = extraer_primeros_indices(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "18af2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_test(start, vectores_target, vectores_cat, vectores_dynamic):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios con la estructura requerida para entrenamiento,\n",
    "    donde start son las fechas de inicio de cada serie (un valor por dataframe).\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else float(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic\n",
    "        if len(target_data) != len(month_vector) or len(target_data) != len(quarter_vector):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes - target: {len(target_data)}, \"\n",
    "                  f\"month: {len(month_vector)}, quarter: {len(quarter_vector)}\")\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector, quarter_vector]  # Usar valores originales sin normalizar\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "e92b152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = crear_diccionarios_test(start,vectores_target,vectores_cat,vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "731b34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_entrenamiento(start, vectores_target, vectores_cat, vectores_dynamic, puntos_a_excluir=6):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios excluyendo los últimos 'puntos_a_excluir' valores de \n",
    "    target y dynamic_feat para cada serie.\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "        puntos_a_excluir: Número de puntos a excluir del final de las series (default=6)\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else float(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar que hay suficientes puntos para excluir\n",
    "        if len(target_data) <= puntos_a_excluir:\n",
    "            print(f\"Advertencia: Serie {i} tiene menos puntos ({len(target_data)}) que los requeridos a excluir ({puntos_a_excluir}). Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Excluir los últimos 'puntos_a_excluir' valores\n",
    "        target_data_recortado = target_data[:-puntos_a_excluir]\n",
    "        month_vector_recortado = month_vector[:-puntos_a_excluir]\n",
    "        quarter_vector_recortado = quarter_vector[:-puntos_a_excluir]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic después del recorte\n",
    "        if len(target_data_recortado) != len(month_vector_recortado) or len(target_data_recortado) != len(quarter_vector_recortado):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes después del recorte - target: {len(target_data_recortado)}, \"\n",
    "                  f\"month: {len(month_vector_recortado)}, quarter: {len(quarter_vector_recortado)}\")\n",
    "            # Ajustar a la longitud mínima\n",
    "            min_len = min(len(target_data_recortado), len(month_vector_recortado), len(quarter_vector_recortado))\n",
    "            target_data_recortado = target_data_recortado[:min_len]\n",
    "            month_vector_recortado = month_vector_recortado[:min_len]\n",
    "            quarter_vector_recortado = quarter_vector_recortado[:min_len]\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data_recortado),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector_recortado, quarter_vector_recortado]\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "1abad3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = crear_diccionarios_entrenamiento(start,vectores_target, vectores_cat, vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "14b00d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, \"wb\") as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef54ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 4.28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"data_json/mensual_original_float/train.json\", train)\n",
    "write_dicts_to_file(\"data_json/mensual_original_float/test.json\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "110638ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 11:47:16] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 11:47:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=250257;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=647545;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\u001b\\\u001b[2m1352\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boto_session = boto3.Session(profile_name='lilipink', region_name='us-east-1')\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "s3_client = boto_session.client('s3')\n",
    "sm_client= boto_session.client('sagemaker')\n",
    "s3 = boto_session.resource(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "7439c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region=None):\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration=location\n",
    "            )\n",
    "        print(f\"Bucket S3 '{bucket_name}' creado exitosamente en {region if region else 'la región por defecto'}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        print(f\"Error al crear el bucket S3: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "bd32a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket S3 'forecasting-mensual-15-v1' creado exitosamente en la región por defecto\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"forecasting-mensual-15-v1\"\n",
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "9b5a1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = bucket_name  # replace with an existing bucket if needed\n",
    "s3_bucket_prefix = (\n",
    "        \"lilipink\"  \n",
    "    )\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "if default_bucket_prefix:\n",
    "    s3_prefix = f\"{default_bucket_prefix}/{s3_bucket_prefix}\"\n",
    "else:\n",
    "    s3_prefix = s3_bucket_prefix\n",
    "\n",
    "role = \"arn:aws:iam::844598627082:role/service-role/AmazonSageMaker-ExecutionRole-20250513T105052\"  # IAM role to use by SageMaker\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ea21564f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 11:47:30] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Same images used for training and inference. Defaulting to image     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         scope: inference.                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 11:47:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Same images used for training and inference. Defaulting to image     \u001b]8;id=297342;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=740115;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         scope: inference.                                                    \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#530\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=513080;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=663416;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#530\u001b\\\u001b[2m530\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_name = sagemaker.image_uris.retrieve(\"forecasting-deepar\", region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "cc300d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith(\"s3://\")\n",
    "    split = s3_path.split(\"/\")\n",
    "    bucket = split[2]\n",
    "    path = \"/\".join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "\n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print(\n",
    "                \"File s3://{}/{} already exists.\\nSet override to upload anyway.\\n\".format(\n",
    "                    s3_bucket, s3_path\n",
    "                )\n",
    "            )\n",
    "            return\n",
    "        else:\n",
    "            print(\"Overwriting existing file\")\n",
    "    with open(local_file, \"rb\") as data:\n",
    "        print(\"Uploading file to {}\".format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7061e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file\n",
      "Uploading file to s3://forecasting-mensual-15-v1/lilipink/data/train/train.json\n",
      "Overwriting existing file\n",
      "Uploading file to s3://forecasting-mensual-15-v1/lilipink/data/test/test.json\n"
     ]
    }
   ],
   "source": [
    "local_file = 'data_json/mensual_original_float/'\n",
    "copy_to_s3(local_file + 'train.json', s3_data_path + \"/train/train.json\",override=True)\n",
    "copy_to_s3(local_file + 'test.json', s3_data_path + \"/test/test.json\",override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "35a4dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.2xlarge\",\n",
    "   # use_spot_instances=True,\n",
    "   # max_run=1800,  # max training time in seconds\n",
    "   # max_wait=1800,  # seconds to wait for spot instance\n",
    "    base_job_name=\"lilipink-forecasting\",\n",
    "    output_path=s3_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "cb5e23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###PRIMER ENTRENAMIENTO###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "067612dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 12\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    #\"learning_rate\": \"1E-3\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "8e98ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "91d8d854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 11:48:49] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 11:48:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=148095;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=912098;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-16-48-49-177                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=55006;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=3381;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-16-48-49-177                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 16:48:52 Starting - Starting the training job...\n",
      "2025-05-21 16:49:27 Downloading - Downloading input data...\n",
      "2025-05-21 16:49:47 Downloading - Downloading the training image.........\n",
      "2025-05-21 16:51:08 Training - Training image download completed. Training in progress.Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '12', 'early_stopping_patience': '40', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '12', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Detected entry point for worker worker\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Using early stopping with patience 40\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] random_seed is None\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] [cardinality=auto] Inferred value of cardinality=[2, 4, 5, 6, 6] from dataset.\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Training set statistics:\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Real time series\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] number of time series: 15\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] number of observations: 582\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] mean target length: 38.8\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] min/mean/max target: 1.0/28.5893470790378/343.0\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] mean abs(target): 28.5893470790378\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] contains missing values: no\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Small number of time series. Doing 86 passes over dataset with prob 0.9922480620155039 per epoch.\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Test set statistics:\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Real time series\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] number of time series: 15\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] number of observations: 672\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] mean target length: 44.8\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] min/mean/max target: 1.0/28.702380952380953/368.0\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] mean abs(target): 28.702380952380953\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] contains missing values: no\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] #memory_usage::<batchbuffer> = 1.875 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] nvidia-smi: took 0.031 seconds to run.\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] nvidia-smi identified 0 GPUs.\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Number of GPUs being used: 0\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Create Store: local\n",
      "#metrics {\"StartTime\": 1747846285.3509579, \"EndTime\": 1747846285.3883147, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 36.5145206451416, \"count\": 1, \"min\": 36.5145206451416, \"max\": 36.5145206451416}}}\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Number of GPUs being used: 0\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] #memory_usage::<model> = 16 mb\n",
      "#metrics {\"StartTime\": 1747846285.3883877, \"EndTime\": 1747846285.447812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 96.73810005187988, \"count\": 1, \"min\": 96.73810005187988, \"max\": 96.73810005187988}}}\n",
      "[16:51:25] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 20480 bytes with malloc directly\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] Epoch[0] Batch[0] avg_epoch_loss=3.961972\n",
      "[05/21/2025 16:51:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.961972236633301\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] Epoch[0] Batch[5] avg_epoch_loss=3.817334\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.8173344135284424\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] Epoch[0] Batch [5]#011Speed: 2605.22 samples/sec#011loss=3.817334\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] Epoch[0] Batch[10] avg_epoch_loss=3.797232\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.77310848236084\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] Epoch[0] Batch [10]#011Speed: 2696.33 samples/sec#011loss=3.773108\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747846285.4478667, \"EndTime\": 1747846286.2942407, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 846.3022708892822, \"count\": 1, \"min\": 846.3022708892822, \"max\": 846.3022708892822}}}\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1533.5728418048939 records/second\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.7972317175431685\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_3cc3d12a-9fa5-4ab2-a11a-96585e805e88-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846286.2943003, \"EndTime\": 1747846286.3037863, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.137630462646484, \"count\": 1, \"min\": 9.137630462646484, \"max\": 9.137630462646484}}}\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] Epoch[1] Batch[0] avg_epoch_loss=3.633147\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.6331465244293213\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] Epoch[1] Batch[5] avg_epoch_loss=3.595626\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.5956255197525024\n",
      "[05/21/2025 16:51:26 INFO 140202337613632] Epoch[1] Batch [5]#011Speed: 2607.27 samples/sec#011loss=3.595626\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] Epoch[1] Batch[10] avg_epoch_loss=3.651300\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.718110370635986\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] Epoch[1] Batch [10]#011Speed: 2568.77 samples/sec#011loss=3.718110\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747846286.3038375, \"EndTime\": 1747846287.0950882, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.1999225616455, \"count\": 1, \"min\": 791.1999225616455, \"max\": 791.1999225616455}}}\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1683.2819909611328 records/second\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.651300451972268\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_7c3ffbe0-7edb-442c-b758-afc25082539a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846287.0951724, \"EndTime\": 1747846287.1046593, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.216070175170898, \"count\": 1, \"min\": 9.216070175170898, \"max\": 9.216070175170898}}}\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] Epoch[2] Batch[0] avg_epoch_loss=3.583228\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.583228349685669\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] Epoch[2] Batch[5] avg_epoch_loss=3.620843\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.6208425760269165\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] Epoch[2] Batch [5]#011Speed: 2238.09 samples/sec#011loss=3.620843\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] Epoch[2] Batch[10] avg_epoch_loss=3.622245\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.623928165435791\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] Epoch[2] Batch [10]#011Speed: 2205.73 samples/sec#011loss=3.623928\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747846287.1047096, \"EndTime\": 1747846287.9901907, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 885.4272365570068, \"count\": 1, \"min\": 885.4272365570068, \"max\": 885.4272365570068}}}\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1547.0973477584143 records/second\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.622245116667314\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:27 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_3b6e6cac-f33f-4a7b-a5ef-ce86719fbe43-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846287.9902596, \"EndTime\": 1747846287.9991255, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.401632308959961, \"count\": 1, \"min\": 8.401632308959961, \"max\": 8.401632308959961}}}\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] Epoch[3] Batch[0] avg_epoch_loss=3.700933\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.7009329795837402\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] Epoch[3] Batch[5] avg_epoch_loss=3.640377\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.6403770446777344\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] Epoch[3] Batch [5]#011Speed: 2232.31 samples/sec#011loss=3.640377\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] processed a total of 1271 examples\n",
      "#metrics {\"StartTime\": 1747846287.9991744, \"EndTime\": 1747846288.8284926, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 829.26344871521, \"count\": 1, \"min\": 829.26344871521, \"max\": 829.26344871521}}}\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1532.513586462035 records/second\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.618362283706665\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:28 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_e411755f-ae19-47d0-ac87-b2476a088082-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846288.8285556, \"EndTime\": 1747846288.8379998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.115934371948242, \"count\": 1, \"min\": 9.115934371948242, \"max\": 9.115934371948242}}}\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] Epoch[4] Batch[0] avg_epoch_loss=3.660010\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.6600098609924316\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] Epoch[4] Batch[5] avg_epoch_loss=3.556035\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.5560352007548013\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] Epoch[4] Batch [5]#011Speed: 2784.75 samples/sec#011loss=3.556035\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] Epoch[4] Batch[10] avg_epoch_loss=3.576955\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.6020577430725096\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] Epoch[4] Batch [10]#011Speed: 2515.13 samples/sec#011loss=3.602058\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747846288.8380508, \"EndTime\": 1747846289.6224804, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.3613624572754, \"count\": 1, \"min\": 784.3613624572754, \"max\": 784.3613624572754}}}\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1713.2756388299695 records/second\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.5769545381719414\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_c7bba173-06bf-4f40-9fb8-b1053de521d3-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846289.6225367, \"EndTime\": 1747846289.6313896, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.537054061889648, \"count\": 1, \"min\": 8.537054061889648, \"max\": 8.537054061889648}}}\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] Epoch[5] Batch[0] avg_epoch_loss=3.516720\n",
      "[05/21/2025 16:51:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.5167200565338135\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] Epoch[5] Batch[5] avg_epoch_loss=3.524207\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.524206837018331\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] Epoch[5] Batch [5]#011Speed: 2789.95 samples/sec#011loss=3.524207\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] Epoch[5] Batch[10] avg_epoch_loss=3.536960\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.55226411819458\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] Epoch[5] Batch [10]#011Speed: 2643.60 samples/sec#011loss=3.552264\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747846289.631441, \"EndTime\": 1747846290.402438, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 770.9474563598633, \"count\": 1, \"min\": 770.9474563598633, \"max\": 770.9474563598633}}}\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1730.102462284661 records/second\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.536960146643899\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_1d81865c-0ebf-43b3-8f24-5d27c58c8107-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846290.402516, \"EndTime\": 1747846290.4112322, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.393049240112305, \"count\": 1, \"min\": 8.393049240112305, \"max\": 8.393049240112305}}}\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] Epoch[6] Batch[0] avg_epoch_loss=3.481763\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.4817631244659424\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] Epoch[6] Batch[5] avg_epoch_loss=3.494517\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.494516889254252\n",
      "[05/21/2025 16:51:30 INFO 140202337613632] Epoch[6] Batch [5]#011Speed: 2708.51 samples/sec#011loss=3.494517\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] Epoch[6] Batch[10] avg_epoch_loss=3.577189\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.6763963222503664\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] Epoch[6] Batch [10]#011Speed: 2648.28 samples/sec#011loss=3.676396\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747846290.4112818, \"EndTime\": 1747846291.1865804, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 775.2499580383301, \"count\": 1, \"min\": 775.2499580383301, \"max\": 775.2499580383301}}}\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1708.932774334087 records/second\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.5771893587979404\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] Epoch[7] Batch[0] avg_epoch_loss=3.423080\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.4230802059173584\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] Epoch[7] Batch[5] avg_epoch_loss=3.497044\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.49704376856486\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] Epoch[7] Batch [5]#011Speed: 2910.78 samples/sec#011loss=3.497044\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] Epoch[7] Batch[10] avg_epoch_loss=3.370101\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.217770290374756\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] Epoch[7] Batch [10]#011Speed: 2596.12 samples/sec#011loss=3.217770\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747846291.1866426, \"EndTime\": 1747846291.9564977, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 769.5903778076172, \"count\": 1, \"min\": 769.5903778076172, \"max\": 769.5903778076172}}}\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1729.3012916281912 records/second\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.370101278478449\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:31 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_66da8e17-9fd1-4cc2-b111-be97f1780572-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846291.9565558, \"EndTime\": 1747846291.9656625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.832216262817383, \"count\": 1, \"min\": 8.832216262817383, \"max\": 8.832216262817383}}}\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] Epoch[8] Batch[0] avg_epoch_loss=3.452159\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.4521594047546387\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] Epoch[8] Batch[5] avg_epoch_loss=3.516331\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.516331195831299\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] Epoch[8] Batch [5]#011Speed: 2741.96 samples/sec#011loss=3.516331\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] Epoch[8] Batch[10] avg_epoch_loss=3.492963\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.4649221897125244\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] Epoch[8] Batch [10]#011Speed: 2523.04 samples/sec#011loss=3.464922\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747846291.9657152, \"EndTime\": 1747846292.7512872, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.5188846588135, \"count\": 1, \"min\": 785.5188846588135, \"max\": 785.5188846588135}}}\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1742.6066484272692 records/second\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.4929634657773105\n",
      "[05/21/2025 16:51:32 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] Epoch[9] Batch[0] avg_epoch_loss=3.486963\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.4869625568389893\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] Epoch[9] Batch[5] avg_epoch_loss=3.390658\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.390657981236776\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] Epoch[9] Batch [5]#011Speed: 2777.79 samples/sec#011loss=3.390658\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] Epoch[9] Batch[10] avg_epoch_loss=3.417914\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.4506219387054444\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] Epoch[9] Batch [10]#011Speed: 2561.18 samples/sec#011loss=3.450622\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747846292.751344, \"EndTime\": 1747846293.53187, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.2760601043701, \"count\": 1, \"min\": 780.2760601043701, \"max\": 780.2760601043701}}}\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1740.2177132458885 records/second\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.417914325540716\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] Epoch[10] Batch[0] avg_epoch_loss=3.335431\n",
      "[05/21/2025 16:51:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.335430860519409\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] Epoch[10] Batch[5] avg_epoch_loss=3.338338\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.338338295618693\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] Epoch[10] Batch [5]#011Speed: 2545.89 samples/sec#011loss=3.338338\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] Epoch[10] Batch[10] avg_epoch_loss=3.312267\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.2809816360473634\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] Epoch[10] Batch [10]#011Speed: 2529.52 samples/sec#011loss=3.280982\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747846293.5319276, \"EndTime\": 1747846294.3393877, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.2094917297363, \"count\": 1, \"min\": 807.2094917297363, \"max\": 807.2094917297363}}}\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1653.6865358853258 records/second\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.3122670867226343\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_e43dc814-3ec9-4240-a633-b264b1ff3802-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846294.3394399, \"EndTime\": 1747846294.3494787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.772539138793945, \"count\": 1, \"min\": 9.772539138793945, \"max\": 9.772539138793945}}}\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] Epoch[11] Batch[0] avg_epoch_loss=3.365313\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.3653132915496826\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] Epoch[11] Batch[5] avg_epoch_loss=3.392573\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.392572561899821\n",
      "[05/21/2025 16:51:34 INFO 140202337613632] Epoch[11] Batch [5]#011Speed: 2678.84 samples/sec#011loss=3.392573\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] Epoch[11] Batch[10] avg_epoch_loss=3.399430\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=3.407659101486206\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] Epoch[11] Batch [10]#011Speed: 2437.53 samples/sec#011loss=3.407659\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747846294.3495362, \"EndTime\": 1747846295.1521623, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.5715351104736, \"count\": 1, \"min\": 802.5715351104736, \"max\": 802.5715351104736}}}\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1675.6813800535497 records/second\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.3994300798936323\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] Epoch[12] Batch[0] avg_epoch_loss=3.341011\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.3410112857818604\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] Epoch[12] Batch[5] avg_epoch_loss=3.312394\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.3123942216237388\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] Epoch[12] Batch [5]#011Speed: 2718.51 samples/sec#011loss=3.312394\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] Epoch[12] Batch[10] avg_epoch_loss=3.348541\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=3.391918087005615\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] Epoch[12] Batch [10]#011Speed: 2509.58 samples/sec#011loss=3.391918\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747846295.1522202, \"EndTime\": 1747846295.945547, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 793.0638790130615, \"count\": 1, \"min\": 793.0638790130615, \"max\": 793.0638790130615}}}\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1664.190720839141 records/second\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.348541433160955\n",
      "[05/21/2025 16:51:35 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] Epoch[13] Batch[0] avg_epoch_loss=3.472206\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.4722063541412354\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] Epoch[13] Batch[5] avg_epoch_loss=3.363670\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.363670031229655\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] Epoch[13] Batch [5]#011Speed: 2726.01 samples/sec#011loss=3.363670\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] Epoch[13] Batch[10] avg_epoch_loss=3.311683\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.249298667907715\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] Epoch[13] Batch [10]#011Speed: 2563.80 samples/sec#011loss=3.249299\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747846295.945615, \"EndTime\": 1747846296.7349725, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.0682220458984, \"count\": 1, \"min\": 789.0682220458984, \"max\": 789.0682220458984}}}\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1715.764431202201 records/second\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.3116830479015005\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:36 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_8fda87fd-3c5a-4a0d-ad9e-993d5a085dc2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846296.7350285, \"EndTime\": 1747846296.7445612, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.265899658203125, \"count\": 1, \"min\": 9.265899658203125, \"max\": 9.265899658203125}}}\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] Epoch[14] Batch[0] avg_epoch_loss=3.382259\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.3822593688964844\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] Epoch[14] Batch[5] avg_epoch_loss=3.339340\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.3393396139144897\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] Epoch[14] Batch [5]#011Speed: 2744.89 samples/sec#011loss=3.339340\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] Epoch[14] Batch[10] avg_epoch_loss=3.371518\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=3.410132884979248\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] Epoch[14] Batch [10]#011Speed: 2572.46 samples/sec#011loss=3.410133\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747846296.7446153, \"EndTime\": 1747846297.5286741, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.0051651000977, \"count\": 1, \"min\": 784.0051651000977, \"max\": 784.0051651000977}}}\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1702.608507393159 records/second\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.37151837348938\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] Epoch[15] Batch[0] avg_epoch_loss=3.353911\n",
      "[05/21/2025 16:51:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.3539111614227295\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] Epoch[15] Batch[5] avg_epoch_loss=3.327349\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=3.327349066734314\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] Epoch[15] Batch [5]#011Speed: 2517.69 samples/sec#011loss=3.327349\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] Epoch[15] Batch[10] avg_epoch_loss=3.331850\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=3.337250518798828\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] Epoch[15] Batch [10]#011Speed: 2669.20 samples/sec#011loss=3.337251\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747846297.5287316, \"EndTime\": 1747846298.3460143, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.0292377471924, \"count\": 1, \"min\": 817.0292377471924, \"max\": 817.0292377471924}}}\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1577.5035002089155 records/second\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=15, train loss <loss>=3.3318497267636387\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] Epoch[16] Batch[0] avg_epoch_loss=3.370557\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.3705568313598633\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] Epoch[16] Batch[5] avg_epoch_loss=3.335061\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=3.3350613514582315\n",
      "[05/21/2025 16:51:38 INFO 140202337613632] Epoch[16] Batch [5]#011Speed: 2740.34 samples/sec#011loss=3.335061\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] Epoch[16] Batch[10] avg_epoch_loss=3.427435\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=3.5382843971252442\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] Epoch[16] Batch [10]#011Speed: 2604.84 samples/sec#011loss=3.538284\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747846298.3460727, \"EndTime\": 1747846299.1325703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.2460613250732, \"count\": 1, \"min\": 786.2460613250732, \"max\": 786.2460613250732}}}\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1670.9553752203406 records/second\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.4274354631250556\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] Epoch[17] Batch[0] avg_epoch_loss=3.441988\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.4419877529144287\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] Epoch[17] Batch[5] avg_epoch_loss=3.387683\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.387683351834615\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] Epoch[17] Batch [5]#011Speed: 2618.55 samples/sec#011loss=3.387683\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] Epoch[17] Batch[10] avg_epoch_loss=3.221437\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.0219403982162474\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] Epoch[17] Batch [10]#011Speed: 2661.53 samples/sec#011loss=3.021940\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747846299.132672, \"EndTime\": 1747846299.9178753, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.9400043487549, \"count\": 1, \"min\": 784.9400043487549, \"max\": 784.9400043487549}}}\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1671.2846065747383 records/second\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.221436554735357\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:39 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_59c0f226-257e-4ec8-b073-a48f10e91c36-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846299.9179313, \"EndTime\": 1747846299.927589, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.387493133544922, \"count\": 1, \"min\": 9.387493133544922, \"max\": 9.387493133544922}}}\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] Epoch[18] Batch[0] avg_epoch_loss=3.265195\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.265195369720459\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] Epoch[18] Batch[5] avg_epoch_loss=3.244661\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.244661331176758\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] Epoch[18] Batch [5]#011Speed: 2729.52 samples/sec#011loss=3.244661\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] Epoch[18] Batch[10] avg_epoch_loss=3.216871\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.183522272109985\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] Epoch[18] Batch [10]#011Speed: 2644.90 samples/sec#011loss=3.183522\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747846299.927646, \"EndTime\": 1747846300.7064133, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 778.7153720855713, \"count\": 1, \"min\": 778.7153720855713, \"max\": 778.7153720855713}}}\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1675.5768616171301 records/second\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.2168708497827705\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:40 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_b0f01198-403b-45ea-af18-38de482327b3-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846300.7065067, \"EndTime\": 1747846300.716358, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.567022323608398, \"count\": 1, \"min\": 9.567022323608398, \"max\": 9.567022323608398}}}\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] Epoch[19] Batch[0] avg_epoch_loss=3.304569\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.3045690059661865\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] Epoch[19] Batch[5] avg_epoch_loss=3.282924\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=3.2829243342081704\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] Epoch[19] Batch [5]#011Speed: 2705.56 samples/sec#011loss=3.282924\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] Epoch[19] Batch[10] avg_epoch_loss=3.287024\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=3.291943359375\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] Epoch[19] Batch [10]#011Speed: 2711.44 samples/sec#011loss=3.291943\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747846300.7164147, \"EndTime\": 1747846301.5026655, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.1969470977783, \"count\": 1, \"min\": 786.1969470977783, \"max\": 786.1969470977783}}}\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1640.5987918643386 records/second\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=19, train loss <loss>=3.287023891102184\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] Epoch[20] Batch[0] avg_epoch_loss=3.197391\n",
      "[05/21/2025 16:51:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.1973907947540283\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] Epoch[20] Batch[5] avg_epoch_loss=3.242642\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=3.2426417668660483\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] Epoch[20] Batch [5]#011Speed: 2428.66 samples/sec#011loss=3.242642\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] processed a total of 1252 examples\n",
      "#metrics {\"StartTime\": 1747846301.5027351, \"EndTime\": 1747846302.2782962, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 775.2172946929932, \"count\": 1, \"min\": 775.2172946929932, \"max\": 775.2172946929932}}}\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1614.8358671418775 records/second\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.240668797492981\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] Epoch[21] Batch[0] avg_epoch_loss=3.203862\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.203862190246582\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] Epoch[21] Batch[5] avg_epoch_loss=3.279961\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.279961109161377\n",
      "[05/21/2025 16:51:42 INFO 140202337613632] Epoch[21] Batch [5]#011Speed: 2719.91 samples/sec#011loss=3.279961\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] Epoch[21] Batch[10] avg_epoch_loss=3.256430\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=3.2281917095184327\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] Epoch[21] Batch [10]#011Speed: 2333.82 samples/sec#011loss=3.228192\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] processed a total of 1396 examples\n",
      "#metrics {\"StartTime\": 1747846302.2783594, \"EndTime\": 1747846303.0819912, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.3082485198975, \"count\": 1, \"min\": 803.3082485198975, \"max\": 803.3082485198975}}}\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1737.6258787547672 records/second\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=21, train loss <loss>=3.2564295638691294\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] Epoch[22] Batch[0] avg_epoch_loss=3.194875\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=3.1948750019073486\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] Epoch[22] Batch[5] avg_epoch_loss=3.178227\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=3.1782270272572837\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] Epoch[22] Batch [5]#011Speed: 2697.10 samples/sec#011loss=3.178227\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] Epoch[22] Batch[10] avg_epoch_loss=3.217377\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=3.2643564224243162\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] Epoch[22] Batch [10]#011Speed: 2511.10 samples/sec#011loss=3.264356\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747846303.0820491, \"EndTime\": 1747846303.8849425, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.5872707366943, \"count\": 1, \"min\": 802.5872707366943, \"max\": 802.5872707366943}}}\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1680.6373625524966 records/second\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=22, train loss <loss>=3.2173767523332075\n",
      "[05/21/2025 16:51:43 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] Epoch[23] Batch[0] avg_epoch_loss=3.215198\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=3.215197801589966\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] Epoch[23] Batch[5] avg_epoch_loss=3.210416\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=3.210415999094645\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] Epoch[23] Batch [5]#011Speed: 2612.65 samples/sec#011loss=3.210416\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] Epoch[23] Batch[10] avg_epoch_loss=3.247860\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=3.2927925109863283\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] Epoch[23] Batch [10]#011Speed: 2521.63 samples/sec#011loss=3.292793\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747846303.8849976, \"EndTime\": 1747846304.6891823, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.8527965545654, \"count\": 1, \"min\": 803.8527965545654, \"max\": 803.8527965545654}}}\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1640.7016975280724 records/second\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=23, train loss <loss>=3.2478598681363193\n",
      "[05/21/2025 16:51:44 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] Epoch[24] Batch[0] avg_epoch_loss=3.215883\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=3.215883255004883\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] Epoch[24] Batch[5] avg_epoch_loss=3.234376\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=3.2343764702479043\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] Epoch[24] Batch [5]#011Speed: 2484.23 samples/sec#011loss=3.234376\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747846304.6892262, \"EndTime\": 1747846305.4470737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 757.6439380645752, \"count\": 1, \"min\": 757.6439380645752, \"max\": 757.6439380645752}}}\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1686.5996069451026 records/second\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=24, train loss <loss>=3.2216195583343508\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] Epoch[25] Batch[0] avg_epoch_loss=3.284057\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=3.2840566635131836\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] Epoch[25] Batch[5] avg_epoch_loss=3.222582\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=3.2225815057754517\n",
      "[05/21/2025 16:51:45 INFO 140202337613632] Epoch[25] Batch [5]#011Speed: 2827.87 samples/sec#011loss=3.222582\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] Epoch[25] Batch[10] avg_epoch_loss=3.223441\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=3.2244731903076174\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] Epoch[25] Batch [10]#011Speed: 2585.07 samples/sec#011loss=3.224473\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747846305.447138, \"EndTime\": 1747846306.222754, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 775.3040790557861, \"count\": 1, \"min\": 775.3040790557861, \"max\": 775.3040790557861}}}\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1734.6069049873179 records/second\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=25, train loss <loss>=3.2234413623809814\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] Epoch[26] Batch[0] avg_epoch_loss=3.233247\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=3.2332472801208496\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] Epoch[26] Batch[5] avg_epoch_loss=3.217604\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=3.2176037232081094\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] Epoch[26] Batch [5]#011Speed: 2767.80 samples/sec#011loss=3.217604\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] Epoch[26] Batch[10] avg_epoch_loss=3.184208\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=3.1441320896148683\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] Epoch[26] Batch [10]#011Speed: 2685.88 samples/sec#011loss=3.144132\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747846306.2228134, \"EndTime\": 1747846306.9983408, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 775.202751159668, \"count\": 1, \"min\": 775.202751159668, \"max\": 775.202751159668}}}\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1697.4334979399064 records/second\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=26, train loss <loss>=3.1842075261202725\n",
      "[05/21/2025 16:51:46 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_004cb7d3-9281-4b9e-9042-1cb4ab4a39d0-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846306.998398, \"EndTime\": 1747846307.0081558, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.450674057006836, \"count\": 1, \"min\": 9.450674057006836, \"max\": 9.450674057006836}}}\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] Epoch[27] Batch[0] avg_epoch_loss=3.207069\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=3.207068920135498\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] Epoch[27] Batch[5] avg_epoch_loss=3.216483\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=3.2164832750956216\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] Epoch[27] Batch [5]#011Speed: 2737.17 samples/sec#011loss=3.216483\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] Epoch[27] Batch[10] avg_epoch_loss=3.243025\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=3.27487530708313\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] Epoch[27] Batch [10]#011Speed: 2656.47 samples/sec#011loss=3.274875\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747846307.0082116, \"EndTime\": 1747846307.7847111, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 776.4465808868408, \"count\": 1, \"min\": 776.4465808868408, \"max\": 776.4465808868408}}}\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1696.0044507119574 records/second\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=27, train loss <loss>=3.2430251078172163\n",
      "[05/21/2025 16:51:47 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] Epoch[28] Batch[0] avg_epoch_loss=3.256016\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=3.2560160160064697\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] Epoch[28] Batch[5] avg_epoch_loss=3.165655\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=3.165655016899109\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] Epoch[28] Batch [5]#011Speed: 2688.85 samples/sec#011loss=3.165655\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] Epoch[28] Batch[10] avg_epoch_loss=3.260141\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=3.3735235691070558\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] Epoch[28] Batch [10]#011Speed: 2622.50 samples/sec#011loss=3.373524\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747846307.7847683, \"EndTime\": 1747846308.608124, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 823.1017589569092, \"count\": 1, \"min\": 823.1017589569092, \"max\": 823.1017589569092}}}\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1575.5766157154144 records/second\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=28, train loss <loss>=3.2601407224481758\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] Epoch[29] Batch[0] avg_epoch_loss=3.172521\n",
      "[05/21/2025 16:51:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=3.1725213527679443\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] Epoch[29] Batch[5] avg_epoch_loss=3.243168\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=3.2431681553522744\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] Epoch[29] Batch [5]#011Speed: 2704.74 samples/sec#011loss=3.243168\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] Epoch[29] Batch[10] avg_epoch_loss=3.180978\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=3.106350469589233\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] Epoch[29] Batch [10]#011Speed: 2349.97 samples/sec#011loss=3.106350\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747846308.6081843, \"EndTime\": 1747846309.4319205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 823.4801292419434, \"count\": 1, \"min\": 823.4801292419434, \"max\": 823.4801292419434}}}\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1644.0613263916553 records/second\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=29, train loss <loss>=3.180978298187256\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_10d7c495-1e68-4249-a841-9da9f39cd79b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846309.4319816, \"EndTime\": 1747846309.44127, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.004592895507812, \"count\": 1, \"min\": 9.004592895507812, \"max\": 9.004592895507812}}}\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] Epoch[30] Batch[0] avg_epoch_loss=3.277492\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=3.277491569519043\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] Epoch[30] Batch[5] avg_epoch_loss=3.193256\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=3.1932560205459595\n",
      "[05/21/2025 16:51:49 INFO 140202337613632] Epoch[30] Batch [5]#011Speed: 2626.14 samples/sec#011loss=3.193256\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747846309.441326, \"EndTime\": 1747846310.187498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 746.117115020752, \"count\": 1, \"min\": 746.117115020752, \"max\": 746.117115020752}}}\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1715.3214460984786 records/second\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=30, train loss <loss>=3.167878842353821\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_00447d0f-d29f-41ee-b0de-73278e5eb23f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846310.1875648, \"EndTime\": 1747846310.1975713, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.679794311523438, \"count\": 1, \"min\": 9.679794311523438, \"max\": 9.679794311523438}}}\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] Epoch[31] Batch[0] avg_epoch_loss=3.013572\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=3.0135724544525146\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] Epoch[31] Batch[5] avg_epoch_loss=3.145054\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=3.1450536648432412\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] Epoch[31] Batch [5]#011Speed: 2767.16 samples/sec#011loss=3.145054\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] Epoch[31] Batch[10] avg_epoch_loss=3.125537\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=3.1021172523498537\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] Epoch[31] Batch [10]#011Speed: 2597.81 samples/sec#011loss=3.102117\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747846310.197631, \"EndTime\": 1747846310.9963756, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.6865043640137, \"count\": 1, \"min\": 798.6865043640137, \"max\": 798.6865043640137}}}\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1663.798275022207 records/second\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=31, train loss <loss>=3.1255371137098833\n",
      "[05/21/2025 16:51:50 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_d1aa9990-add1-4992-a496-9f61aba24f44-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846310.9964354, \"EndTime\": 1747846311.006163, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.920907974243164, \"count\": 1, \"min\": 8.920907974243164, \"max\": 8.920907974243164}}}\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] Epoch[32] Batch[0] avg_epoch_loss=3.113621\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=3.1136205196380615\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] Epoch[32] Batch[5] avg_epoch_loss=3.167189\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=3.1671886841456094\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] Epoch[32] Batch [5]#011Speed: 2365.16 samples/sec#011loss=3.167189\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] Epoch[32] Batch[10] avg_epoch_loss=3.195746\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=3.2300142288208007\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] Epoch[32] Batch [10]#011Speed: 2443.49 samples/sec#011loss=3.230014\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747846311.0062242, \"EndTime\": 1747846311.8463788, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 840.1007652282715, \"count\": 1, \"min\": 840.1007652282715, \"max\": 840.1007652282715}}}\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1594.8797377530748 records/second\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=32, train loss <loss>=3.19574574990706\n",
      "[05/21/2025 16:51:51 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] Epoch[33] Batch[0] avg_epoch_loss=3.189201\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=3.1892011165618896\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] Epoch[33] Batch[5] avg_epoch_loss=3.159375\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=3.159375270207723\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] Epoch[33] Batch [5]#011Speed: 2624.47 samples/sec#011loss=3.159375\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] Epoch[33] Batch[10] avg_epoch_loss=3.179724\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=3.2041424751281737\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] Epoch[33] Batch [10]#011Speed: 2451.44 samples/sec#011loss=3.204142\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] processed a total of 1392 examples\n",
      "#metrics {\"StartTime\": 1747846311.8464384, \"EndTime\": 1747846312.663534, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 816.8027400970459, \"count\": 1, \"min\": 816.8027400970459, \"max\": 816.8027400970459}}}\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1704.0242922069508 records/second\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=33, train loss <loss>=3.179723999717019\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] Epoch[34] Batch[0] avg_epoch_loss=3.103749\n",
      "[05/21/2025 16:51:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=3.1037487983703613\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] Epoch[34] Batch[5] avg_epoch_loss=3.156920\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=3.1569195985794067\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] Epoch[34] Batch [5]#011Speed: 2608.94 samples/sec#011loss=3.156920\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] processed a total of 1223 examples\n",
      "#metrics {\"StartTime\": 1747846312.663594, \"EndTime\": 1747846313.4000902, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 736.2473011016846, \"count\": 1, \"min\": 736.2473011016846, \"max\": 736.2473011016846}}}\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1660.9125672709517 records/second\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=34, train loss <loss>=3.166719889640808\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] Epoch[35] Batch[0] avg_epoch_loss=3.116706\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=3.116705894470215\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] Epoch[35] Batch[5] avg_epoch_loss=3.193710\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=3.193709929784139\n",
      "[05/21/2025 16:51:53 INFO 140202337613632] Epoch[35] Batch [5]#011Speed: 2727.53 samples/sec#011loss=3.193710\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] Epoch[35] Batch[10] avg_epoch_loss=3.203792\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=3.2158894538879395\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] Epoch[35] Batch [10]#011Speed: 2531.08 samples/sec#011loss=3.215889\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747846313.400153, \"EndTime\": 1747846314.2042387, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.7586212158203, \"count\": 1, \"min\": 803.7586212158203, \"max\": 803.7586212158203}}}\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1683.1599607423364 records/second\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=35, train loss <loss>=3.203791531649503\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] Epoch[36] Batch[0] avg_epoch_loss=3.113364\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=3.11336350440979\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] Epoch[36] Batch[5] avg_epoch_loss=3.119586\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=3.119586189587911\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] Epoch[36] Batch [5]#011Speed: 2810.47 samples/sec#011loss=3.119586\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] Epoch[36] Batch[10] avg_epoch_loss=3.072201\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=3.0153385162353517\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] Epoch[36] Batch [10]#011Speed: 2529.99 samples/sec#011loss=3.015339\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747846314.204297, \"EndTime\": 1747846314.989649, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.0961685180664, \"count\": 1, \"min\": 785.0961685180664, \"max\": 785.0961685180664}}}\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1658.20873694282 records/second\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=36, train loss <loss>=3.072200883518566\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:54 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_9b15671a-0e28-4f75-b24c-9093032b049e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846314.9897082, \"EndTime\": 1747846314.9989693, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.99052619934082, \"count\": 1, \"min\": 8.99052619934082, \"max\": 8.99052619934082}}}\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] Epoch[37] Batch[0] avg_epoch_loss=3.091909\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=3.091909170150757\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] Epoch[37] Batch[5] avg_epoch_loss=3.104918\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=3.1049177249272666\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] Epoch[37] Batch [5]#011Speed: 2733.07 samples/sec#011loss=3.104918\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] Epoch[37] Batch[10] avg_epoch_loss=3.149018\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=3.2019374847412108\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] Epoch[37] Batch [10]#011Speed: 2653.33 samples/sec#011loss=3.201937\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747846314.999029, \"EndTime\": 1747846315.7792652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.1792621612549, \"count\": 1, \"min\": 780.1792621612549, \"max\": 780.1792621612549}}}\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1660.9709133965334 records/second\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=37, train loss <loss>=3.1490176157517866\n",
      "[05/21/2025 16:51:55 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] Epoch[38] Batch[0] avg_epoch_loss=3.026590\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=3.026589870452881\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] Epoch[38] Batch[5] avg_epoch_loss=3.115106\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=3.115105946858724\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] Epoch[38] Batch [5]#011Speed: 2723.46 samples/sec#011loss=3.115106\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] Epoch[38] Batch[10] avg_epoch_loss=3.070707\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=3.017428398132324\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] Epoch[38] Batch [10]#011Speed: 2555.87 samples/sec#011loss=3.017428\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747846315.7793238, \"EndTime\": 1747846316.577041, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.468900680542, \"count\": 1, \"min\": 797.468900680542, \"max\": 797.468900680542}}}\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1701.4414745882539 records/second\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=38, train loss <loss>=3.0707070610739966\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_de65a4b6-384d-4950-b9e0-753c982bd3a9-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846316.5771039, \"EndTime\": 1747846316.586993, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.533405303955078, \"count\": 1, \"min\": 9.533405303955078, \"max\": 9.533405303955078}}}\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] Epoch[39] Batch[0] avg_epoch_loss=3.116857\n",
      "[05/21/2025 16:51:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=3.1168572902679443\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] Epoch[39] Batch[5] avg_epoch_loss=3.112615\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=3.112615466117859\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] Epoch[39] Batch [5]#011Speed: 2727.62 samples/sec#011loss=3.112615\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] Epoch[39] Batch[10] avg_epoch_loss=3.096340\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=3.0768104553222657\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] Epoch[39] Batch [10]#011Speed: 2634.75 samples/sec#011loss=3.076810\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747846316.5870686, \"EndTime\": 1747846317.3741076, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.9749069213867, \"count\": 1, \"min\": 786.9749069213867, \"max\": 786.9749069213867}}}\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1660.5736047221017 records/second\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=39, train loss <loss>=3.096340461210771\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] Epoch[40] Batch[0] avg_epoch_loss=2.991592\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.9915924072265625\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] Epoch[40] Batch[5] avg_epoch_loss=3.085321\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=3.0853206713994346\n",
      "[05/21/2025 16:51:57 INFO 140202337613632] Epoch[40] Batch [5]#011Speed: 2747.65 samples/sec#011loss=3.085321\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747846317.374176, \"EndTime\": 1747846318.1099076, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 735.3923320770264, \"count\": 1, \"min\": 735.3923320770264, \"max\": 735.3923320770264}}}\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1738.8519673656199 records/second\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=40, train loss <loss>=3.0883697986602785\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] Epoch[41] Batch[0] avg_epoch_loss=2.944446\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.944446325302124\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] Epoch[41] Batch[5] avg_epoch_loss=3.014776\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=3.0147759914398193\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] Epoch[41] Batch [5]#011Speed: 2621.15 samples/sec#011loss=3.014776\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747846318.1100223, \"EndTime\": 1747846318.8624878, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 752.0391941070557, \"count\": 1, \"min\": 752.0391941070557, \"max\": 752.0391941070557}}}\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1701.760023938141 records/second\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=41, train loss <loss>=3.0307084798812864\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:58 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_413cc88e-098a-4289-92c4-8bd0d1bee8f3-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846318.8625512, \"EndTime\": 1747846318.872013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.079694747924805, \"count\": 1, \"min\": 9.079694747924805, \"max\": 9.079694747924805}}}\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] Epoch[42] Batch[0] avg_epoch_loss=3.090153\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=3.090153217315674\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] Epoch[42] Batch[5] avg_epoch_loss=3.053081\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=3.053080598513285\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] Epoch[42] Batch [5]#011Speed: 2631.83 samples/sec#011loss=3.053081\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] Epoch[42] Batch[10] avg_epoch_loss=2.974734\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.8807185649871827\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] Epoch[42] Batch [10]#011Speed: 2442.83 samples/sec#011loss=2.880719\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747846318.872064, \"EndTime\": 1747846319.6900058, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.8837299346924, \"count\": 1, \"min\": 817.8837299346924, \"max\": 817.8837299346924}}}\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1628.418183164268 records/second\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.974734219637784\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:51:59 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_c55bc035-746c-48c0-91ae-72f506b76c62-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846319.6900628, \"EndTime\": 1747846319.6990788, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.738994598388672, \"count\": 1, \"min\": 8.738994598388672, \"max\": 8.738994598388672}}}\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] Epoch[43] Batch[0] avg_epoch_loss=3.046784\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=3.046783924102783\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] Epoch[43] Batch[5] avg_epoch_loss=3.053983\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=3.0539828141530356\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] Epoch[43] Batch [5]#011Speed: 2689.88 samples/sec#011loss=3.053983\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] Epoch[43] Batch[10] avg_epoch_loss=3.060841\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=3.0690715312957764\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] Epoch[43] Batch [10]#011Speed: 2589.55 samples/sec#011loss=3.069072\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747846319.6991365, \"EndTime\": 1747846320.488743, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.5517349243164, \"count\": 1, \"min\": 789.5517349243164, \"max\": 789.5517349243164}}}\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1699.509258031956 records/second\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=43, train loss <loss>=3.0608413219451904\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] Epoch[44] Batch[0] avg_epoch_loss=2.952001\n",
      "[05/21/2025 16:52:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.952000856399536\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] Epoch[44] Batch[5] avg_epoch_loss=3.021656\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=3.0216559171676636\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] Epoch[44] Batch [5]#011Speed: 2669.03 samples/sec#011loss=3.021656\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] Epoch[44] Batch[10] avg_epoch_loss=3.024740\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=3.0284408569335937\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] Epoch[44] Batch [10]#011Speed: 2588.15 samples/sec#011loss=3.028441\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747846320.4888015, \"EndTime\": 1747846321.287227, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.1712818145752, \"count\": 1, \"min\": 798.1712818145752, \"max\": 798.1712818145752}}}\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1626.0357122910075 records/second\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=44, train loss <loss>=3.024739980697632\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] Epoch[45] Batch[0] avg_epoch_loss=2.982815\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.9828150272369385\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] Epoch[45] Batch[5] avg_epoch_loss=2.965097\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.9650972286860147\n",
      "[05/21/2025 16:52:01 INFO 140202337613632] Epoch[45] Batch [5]#011Speed: 2720.90 samples/sec#011loss=2.965097\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] Epoch[45] Batch[10] avg_epoch_loss=2.974791\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=2.986423921585083\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] Epoch[45] Batch [10]#011Speed: 2376.51 samples/sec#011loss=2.986424\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747846321.2872872, \"EndTime\": 1747846322.0988276, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.2838268280029, \"count\": 1, \"min\": 811.2838268280029, \"max\": 811.2838268280029}}}\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1619.4752142794805 records/second\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.974791180003773\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] Epoch[46] Batch[0] avg_epoch_loss=2.969517\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.9695167541503906\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] Epoch[46] Batch[5] avg_epoch_loss=2.991330\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.991329868634542\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] Epoch[46] Batch [5]#011Speed: 2707.79 samples/sec#011loss=2.991330\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] Epoch[46] Batch[10] avg_epoch_loss=3.124710\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=3.2847668647766115\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] Epoch[46] Batch [10]#011Speed: 2535.47 samples/sec#011loss=3.284767\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747846322.0988882, \"EndTime\": 1747846322.8965425, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.398567199707, \"count\": 1, \"min\": 797.398567199707, \"max\": 797.398567199707}}}\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1622.622651538933 records/second\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=46, train loss <loss>=3.1247103214263916\n",
      "[05/21/2025 16:52:02 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] Epoch[47] Batch[0] avg_epoch_loss=3.128850\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=3.1288504600524902\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] Epoch[47] Batch[5] avg_epoch_loss=3.080924\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=3.080924312273661\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] Epoch[47] Batch [5]#011Speed: 2626.30 samples/sec#011loss=3.080924\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] Epoch[47] Batch[10] avg_epoch_loss=3.109865\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=3.144593048095703\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] Epoch[47] Batch [10]#011Speed: 2521.45 samples/sec#011loss=3.144593\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747846322.8965917, \"EndTime\": 1747846323.7107372, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.899040222168, \"count\": 1, \"min\": 813.899040222168, \"max\": 813.899040222168}}}\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1581.1035211174785 records/second\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=47, train loss <loss>=3.1098646467382256\n",
      "[05/21/2025 16:52:03 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] Epoch[48] Batch[0] avg_epoch_loss=3.153189\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=3.153188943862915\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] Epoch[48] Batch[5] avg_epoch_loss=3.148259\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=3.1482588052749634\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] Epoch[48] Batch [5]#011Speed: 2606.90 samples/sec#011loss=3.148259\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] Epoch[48] Batch[10] avg_epoch_loss=3.104645\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=3.052307462692261\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] Epoch[48] Batch [10]#011Speed: 2486.47 samples/sec#011loss=3.052307\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747846323.7107964, \"EndTime\": 1747846324.5430827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 831.9253921508789, \"count\": 1, \"min\": 831.9253921508789, \"max\": 831.9253921508789}}}\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1599.7444543848258 records/second\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=48, train loss <loss>=3.1046445586464624\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] Epoch[49] Batch[0] avg_epoch_loss=3.015861\n",
      "[05/21/2025 16:52:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=3.0158605575561523\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] Epoch[49] Batch[5] avg_epoch_loss=2.992792\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.9927918116251626\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] Epoch[49] Batch [5]#011Speed: 2589.99 samples/sec#011loss=2.992792\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] processed a total of 1258 examples\n",
      "#metrics {\"StartTime\": 1747846324.5431378, \"EndTime\": 1747846325.3184018, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 774.935245513916, \"count\": 1, \"min\": 774.935245513916, \"max\": 774.935245513916}}}\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1623.091288907072 records/second\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=49, train loss <loss>=3.0168187856674193\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] Epoch[50] Batch[0] avg_epoch_loss=2.971262\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.971262216567993\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] Epoch[50] Batch[5] avg_epoch_loss=2.999553\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.999552845954895\n",
      "[05/21/2025 16:52:05 INFO 140202337613632] Epoch[50] Batch [5]#011Speed: 2595.32 samples/sec#011loss=2.999553\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] Epoch[50] Batch[10] avg_epoch_loss=3.024114\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=3.0535879611968992\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] Epoch[50] Batch [10]#011Speed: 2413.50 samples/sec#011loss=3.053588\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747846325.3184955, \"EndTime\": 1747846326.1348753, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 816.0545825958252, \"count\": 1, \"min\": 816.0545825958252, \"max\": 816.0545825958252}}}\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1647.9939938448595 records/second\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=50, train loss <loss>=3.024114261973988\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] Epoch[51] Batch[0] avg_epoch_loss=2.933276\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.9332761764526367\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] Epoch[51] Batch[5] avg_epoch_loss=2.988121\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.9881213903427124\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] Epoch[51] Batch [5]#011Speed: 2736.94 samples/sec#011loss=2.988121\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] Epoch[51] Batch[10] avg_epoch_loss=3.016694\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=3.050981903076172\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] Epoch[51] Batch [10]#011Speed: 2564.92 samples/sec#011loss=3.050982\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747846326.1349359, \"EndTime\": 1747846326.9287224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 793.5218811035156, \"count\": 1, \"min\": 793.5218811035156, \"max\": 793.5218811035156}}}\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1659.5110805346344 records/second\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=51, train loss <loss>=3.016694350676103\n",
      "[05/21/2025 16:52:06 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] Epoch[52] Batch[0] avg_epoch_loss=3.010231\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=3.0102312564849854\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] Epoch[52] Batch[5] avg_epoch_loss=3.024280\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=3.0242804686228433\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] Epoch[52] Batch [5]#011Speed: 2462.83 samples/sec#011loss=3.024280\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] Epoch[52] Batch[10] avg_epoch_loss=3.076307\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=3.1387381553649902\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] Epoch[52] Batch [10]#011Speed: 2587.02 samples/sec#011loss=3.138738\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747846326.9287784, \"EndTime\": 1747846327.745508, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 816.4381980895996, \"count\": 1, \"min\": 816.4381980895996, \"max\": 816.4381980895996}}}\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1638.6468533306236 records/second\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=52, train loss <loss>=3.076306689869274\n",
      "[05/21/2025 16:52:07 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] Epoch[53] Batch[0] avg_epoch_loss=3.188769\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=3.1887688636779785\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] Epoch[53] Batch[5] avg_epoch_loss=3.207035\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=3.2070348660151162\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] Epoch[53] Batch [5]#011Speed: 2761.79 samples/sec#011loss=3.207035\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] Epoch[53] Batch[10] avg_epoch_loss=3.227704\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=3.2525074005126955\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] Epoch[53] Batch [10]#011Speed: 2539.90 samples/sec#011loss=3.252507\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747846327.7455685, \"EndTime\": 1747846328.532568, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.7438793182373, \"count\": 1, \"min\": 786.7438793182373, \"max\": 786.7438793182373}}}\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1737.3544157047547 records/second\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=53, train loss <loss>=3.2277041998776523\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] Epoch[54] Batch[0] avg_epoch_loss=3.143379\n",
      "[05/21/2025 16:52:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=3.143378734588623\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] Epoch[54] Batch[5] avg_epoch_loss=3.115731\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=3.1157310406366983\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] Epoch[54] Batch [5]#011Speed: 2696.43 samples/sec#011loss=3.115731\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] Epoch[54] Batch[10] avg_epoch_loss=3.035835\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=2.9399602890014647\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] Epoch[54] Batch [10]#011Speed: 2566.97 samples/sec#011loss=2.939960\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747846328.5326262, \"EndTime\": 1747846329.3235223, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.6408309936523, \"count\": 1, \"min\": 790.6408309936523, \"max\": 790.6408309936523}}}\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1636.4437604775976 records/second\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=54, train loss <loss>=3.0358352444388648\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] Epoch[55] Batch[0] avg_epoch_loss=3.109055\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=3.1090548038482666\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] Epoch[55] Batch[5] avg_epoch_loss=3.081992\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=3.081991990407308\n",
      "[05/21/2025 16:52:09 INFO 140202337613632] Epoch[55] Batch [5]#011Speed: 2728.72 samples/sec#011loss=3.081992\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] Epoch[55] Batch[10] avg_epoch_loss=3.003486\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.9092777729034425\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] Epoch[55] Batch [10]#011Speed: 2596.57 samples/sec#011loss=2.909278\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] processed a total of 1362 examples\n",
      "#metrics {\"StartTime\": 1747846329.3235874, \"EndTime\": 1747846330.1074734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 783.5726737976074, \"count\": 1, \"min\": 783.5726737976074, \"max\": 783.5726737976074}}}\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1737.99876601353 records/second\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=55, train loss <loss>=3.003485527905551\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] Epoch[56] Batch[0] avg_epoch_loss=3.001082\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=3.001081943511963\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] Epoch[56] Batch[5] avg_epoch_loss=2.973177\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.9731768369674683\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] Epoch[56] Batch [5]#011Speed: 2770.80 samples/sec#011loss=2.973177\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] Epoch[56] Batch[10] avg_epoch_loss=3.034566\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=3.108233642578125\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] Epoch[56] Batch [10]#011Speed: 2622.13 samples/sec#011loss=3.108234\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747846330.1075318, \"EndTime\": 1747846330.8883784, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.5535793304443, \"count\": 1, \"min\": 780.5535793304443, \"max\": 780.5535793304443}}}\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1697.3192969510908 records/second\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=56, train loss <loss>=3.034566294063221\n",
      "[05/21/2025 16:52:10 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] Epoch[57] Batch[0] avg_epoch_loss=3.021663\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=3.021662712097168\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] Epoch[57] Batch[5] avg_epoch_loss=2.982664\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.9826637506484985\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] Epoch[57] Batch [5]#011Speed: 2658.46 samples/sec#011loss=2.982664\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] Epoch[57] Batch[10] avg_epoch_loss=3.002409\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=3.02610239982605\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] Epoch[57] Batch [10]#011Speed: 2407.56 samples/sec#011loss=3.026102\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] processed a total of 1396 examples\n",
      "#metrics {\"StartTime\": 1747846330.8884377, \"EndTime\": 1747846331.7002873, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.549186706543, \"count\": 1, \"min\": 811.549186706543, \"max\": 811.549186706543}}}\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1719.9829107632581 records/second\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=57, train loss <loss>=3.002408591183749\n",
      "[05/21/2025 16:52:11 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] Epoch[58] Batch[0] avg_epoch_loss=3.027767\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=3.027766704559326\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] Epoch[58] Batch[5] avg_epoch_loss=2.979721\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.979721466700236\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] Epoch[58] Batch [5]#011Speed: 2478.08 samples/sec#011loss=2.979721\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] Epoch[58] Batch[10] avg_epoch_loss=3.029600\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=3.0894537925720216\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] Epoch[58] Batch [10]#011Speed: 2574.18 samples/sec#011loss=3.089454\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747846331.7003424, \"EndTime\": 1747846332.5205102, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 819.8337554931641, \"count\": 1, \"min\": 819.8337554931641, \"max\": 819.8337554931641}}}\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1578.163164567268 records/second\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=58, train loss <loss>=3.0295997966419566\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] Epoch[59] Batch[0] avg_epoch_loss=2.916540\n",
      "[05/21/2025 16:52:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.9165396690368652\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] Epoch[59] Batch[5] avg_epoch_loss=2.952953\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.9529529809951782\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] Epoch[59] Batch [5]#011Speed: 2586.99 samples/sec#011loss=2.952953\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] Epoch[59] Batch[10] avg_epoch_loss=2.989330\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=3.0329819202423094\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] Epoch[59] Batch [10]#011Speed: 2375.39 samples/sec#011loss=3.032982\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] processed a total of 1400 examples\n",
      "#metrics {\"StartTime\": 1747846332.5205817, \"EndTime\": 1747846333.338468, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.5168037414551, \"count\": 1, \"min\": 817.5168037414551, \"max\": 817.5168037414551}}}\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1712.2748165771507 records/second\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.989329771562056\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] Epoch[60] Batch[0] avg_epoch_loss=2.954544\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.9545438289642334\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] Epoch[60] Batch[5] avg_epoch_loss=2.994434\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.9944337606430054\n",
      "[05/21/2025 16:52:13 INFO 140202337613632] Epoch[60] Batch [5]#011Speed: 2404.56 samples/sec#011loss=2.994434\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] Epoch[60] Batch[10] avg_epoch_loss=2.944134\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.8837741374969483\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] Epoch[60] Batch [10]#011Speed: 2603.00 samples/sec#011loss=2.883774\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747846333.3385317, \"EndTime\": 1747846334.1712596, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 832.4234485626221, \"count\": 1, \"min\": 832.4234485626221, \"max\": 832.4234485626221}}}\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1595.1714761112432 records/second\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.944133931940252\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_020398ed-c9ca-4b8d-95de-21bac3562070-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846334.1713195, \"EndTime\": 1747846334.1812716, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.667396545410156, \"count\": 1, \"min\": 9.667396545410156, \"max\": 9.667396545410156}}}\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] Epoch[61] Batch[0] avg_epoch_loss=2.895561\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.895561456680298\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] Epoch[61] Batch[5] avg_epoch_loss=2.918402\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.9184022347132363\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] Epoch[61] Batch [5]#011Speed: 2676.04 samples/sec#011loss=2.918402\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] processed a total of 1245 examples\n",
      "#metrics {\"StartTime\": 1747846334.1813319, \"EndTime\": 1747846334.9157894, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 734.3990802764893, \"count\": 1, \"min\": 734.3990802764893, \"max\": 734.3990802764893}}}\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1695.0126349144316 records/second\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.9533533811569215\n",
      "[05/21/2025 16:52:14 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] Epoch[62] Batch[0] avg_epoch_loss=2.985775\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.9857752323150635\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] Epoch[62] Batch[5] avg_epoch_loss=2.891817\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.8918166557947793\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] Epoch[62] Batch [5]#011Speed: 2697.41 samples/sec#011loss=2.891817\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] Epoch[62] Batch[10] avg_epoch_loss=2.824715\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.7441919803619386\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] Epoch[62] Batch [10]#011Speed: 2626.75 samples/sec#011loss=2.744192\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747846334.9158638, \"EndTime\": 1747846335.7043853, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.017749786377, \"count\": 1, \"min\": 788.017749786377, \"max\": 788.017749786377}}}\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1665.9939163972003 records/second\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.8247145305980337\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:52:15 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_917bb5ca-4aac-4488-99da-673b338959db-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846335.704452, \"EndTime\": 1747846335.7132213, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.430957794189453, \"count\": 1, \"min\": 8.430957794189453, \"max\": 8.430957794189453}}}\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] Epoch[63] Batch[0] avg_epoch_loss=2.843010\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.843010425567627\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] Epoch[63] Batch[5] avg_epoch_loss=2.909933\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.909932533899943\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] Epoch[63] Batch [5]#011Speed: 2707.67 samples/sec#011loss=2.909933\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] Epoch[63] Batch[10] avg_epoch_loss=2.852522\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.7836286544799806\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] Epoch[63] Batch [10]#011Speed: 2575.94 samples/sec#011loss=2.783629\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747846335.7132754, \"EndTime\": 1747846336.5045059, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.1713123321533, \"count\": 1, \"min\": 791.1713123321533, \"max\": 791.1713123321533}}}\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1661.9018113206182 records/second\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.852521679618142\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] Epoch[64] Batch[0] avg_epoch_loss=2.999316\n",
      "[05/21/2025 16:52:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.9993155002593994\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] Epoch[64] Batch[5] avg_epoch_loss=2.932273\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.9322732289632163\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] Epoch[64] Batch [5]#011Speed: 2736.03 samples/sec#011loss=2.932273\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] Epoch[64] Batch[10] avg_epoch_loss=2.852988\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=2.757845067977905\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] Epoch[64] Batch [10]#011Speed: 2666.67 samples/sec#011loss=2.757845\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747846336.504565, \"EndTime\": 1747846337.283878, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 778.9900302886963, \"count\": 1, \"min\": 778.9900302886963, \"max\": 778.9900302886963}}}\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1657.0859383320092 records/second\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.85298770124262\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] Epoch[65] Batch[0] avg_epoch_loss=2.824189\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.8241894245147705\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] Epoch[65] Batch[5] avg_epoch_loss=2.938473\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.938472549120585\n",
      "[05/21/2025 16:52:17 INFO 140202337613632] Epoch[65] Batch [5]#011Speed: 2742.06 samples/sec#011loss=2.938473\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] Epoch[65] Batch[10] avg_epoch_loss=2.949494\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.962720251083374\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] Epoch[65] Batch [10]#011Speed: 2645.59 samples/sec#011loss=2.962720\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747846337.2839336, \"EndTime\": 1747846338.062964, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 778.7477970123291, \"count\": 1, \"min\": 778.7477970123291, \"max\": 778.7477970123291}}}\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1710.2366395342074 records/second\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.949494231830944\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] Epoch[66] Batch[0] avg_epoch_loss=2.948043\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.9480433464050293\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] Epoch[66] Batch[5] avg_epoch_loss=2.925707\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.9257071812947593\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] Epoch[66] Batch [5]#011Speed: 2475.40 samples/sec#011loss=2.925707\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] Epoch[66] Batch[10] avg_epoch_loss=2.957706\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.9961053371429442\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] Epoch[66] Batch [10]#011Speed: 2565.61 samples/sec#011loss=2.996105\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747846338.0630257, \"EndTime\": 1747846338.8787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 815.361499786377, \"count\": 1, \"min\": 815.361499786377, \"max\": 815.361499786377}}}\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1577.0213089931185 records/second\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.957706343043934\n",
      "[05/21/2025 16:52:18 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] Epoch[67] Batch[0] avg_epoch_loss=2.917137\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.9171371459960938\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] Epoch[67] Batch[5] avg_epoch_loss=2.909036\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.909035881360372\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] Epoch[67] Batch [5]#011Speed: 2718.11 samples/sec#011loss=2.909036\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] Epoch[67] Batch[10] avg_epoch_loss=2.980499\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=3.0662543773651123\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] Epoch[67] Batch [10]#011Speed: 2583.87 samples/sec#011loss=3.066254\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747846338.878768, \"EndTime\": 1747846339.6672146, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.1040573120117, \"count\": 1, \"min\": 788.1040573120117, \"max\": 788.1040573120117}}}\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1669.6312470091732 records/second\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.9804988340897993\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] Epoch[68] Batch[0] avg_epoch_loss=2.994429\n",
      "[05/21/2025 16:52:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.9944286346435547\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] Epoch[68] Batch[5] avg_epoch_loss=2.986371\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.9863709211349487\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] Epoch[68] Batch [5]#011Speed: 2601.92 samples/sec#011loss=2.986371\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] Epoch[68] Batch[10] avg_epoch_loss=2.879612\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.7515023231506346\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] Epoch[68] Batch [10]#011Speed: 2453.59 samples/sec#011loss=2.751502\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747846339.6672747, \"EndTime\": 1747846340.4774437, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.8366260528564, \"count\": 1, \"min\": 809.8366260528564, \"max\": 809.8366260528564}}}\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1670.5047232753222 records/second\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.8796124675057153\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] Epoch[69] Batch[0] avg_epoch_loss=2.901951\n",
      "[05/21/2025 16:52:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.9019508361816406\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] Epoch[69] Batch[5] avg_epoch_loss=2.897892\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.8978919188181558\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] Epoch[69] Batch [5]#011Speed: 2799.44 samples/sec#011loss=2.897892\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] Epoch[69] Batch[10] avg_epoch_loss=2.939613\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.98967924118042\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] Epoch[69] Batch [10]#011Speed: 2651.48 samples/sec#011loss=2.989679\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747846340.4775083, \"EndTime\": 1747846341.2589061, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 781.0847759246826, \"count\": 1, \"min\": 781.0847759246826, \"max\": 781.0847759246826}}}\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1687.364266333522 records/second\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.9396134289828213\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] Epoch[70] Batch[0] avg_epoch_loss=2.901056\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.9010558128356934\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] Epoch[70] Batch[5] avg_epoch_loss=2.942617\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.942616621653239\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] Epoch[70] Batch [5]#011Speed: 2825.58 samples/sec#011loss=2.942617\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747846341.2594805, \"EndTime\": 1747846341.986628, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 726.8717288970947, \"count\": 1, \"min\": 726.8717288970947, \"max\": 726.8717288970947}}}\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1752.4789976432653 records/second\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.945637011528015\n",
      "[05/21/2025 16:52:21 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:22 INFO 140202337613632] Epoch[71] Batch[0] avg_epoch_loss=3.077457\n",
      "[05/21/2025 16:52:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=3.0774571895599365\n",
      "[05/21/2025 16:52:22 INFO 140202337613632] Epoch[71] Batch[5] avg_epoch_loss=2.931403\n",
      "[05/21/2025 16:52:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.9314027627309165\n",
      "[05/21/2025 16:52:22 INFO 140202337613632] Epoch[71] Batch [5]#011Speed: 2706.54 samples/sec#011loss=2.931403\n",
      "[05/21/2025 16:52:22 INFO 140202337613632] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747846341.9866948, \"EndTime\": 1747846342.7174306, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 730.4203510284424, \"count\": 1, \"min\": 730.4203510284424, \"max\": 730.4203510284424}}}\n",
      "[05/21/2025 16:52:22 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1746.7055167810863 records/second\n",
      "[05/21/2025 16:52:22 INFO 140202337613632] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/21/2025 16:52:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.918402099609375\n",
      "[05/21/2025 16:52:22 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] Epoch[72] Batch[0] avg_epoch_loss=2.784935\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.784935474395752\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] Epoch[72] Batch[5] avg_epoch_loss=2.873275\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.8732749223709106\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] Epoch[72] Batch [5]#011Speed: 2760.11 samples/sec#011loss=2.873275\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] Epoch[72] Batch[10] avg_epoch_loss=2.902462\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.9374866485595703\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] Epoch[72] Batch [10]#011Speed: 2702.71 samples/sec#011loss=2.937487\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747846342.7174973, \"EndTime\": 1747846343.4950438, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 777.252197265625, \"count\": 1, \"min\": 777.252197265625, \"max\": 777.252197265625}}}\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1676.2329302019725 records/second\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.9024620706384834\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] Epoch[73] Batch[0] avg_epoch_loss=3.009300\n",
      "[05/21/2025 16:52:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=3.0093002319335938\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] Epoch[73] Batch[5] avg_epoch_loss=2.932633\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.932632644971212\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] Epoch[73] Batch [5]#011Speed: 2516.61 samples/sec#011loss=2.932633\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] Epoch[73] Batch[10] avg_epoch_loss=2.938570\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=2.9456939697265625\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] Epoch[73] Batch [10]#011Speed: 2643.05 samples/sec#011loss=2.945694\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747846343.4951026, \"EndTime\": 1747846344.2986069, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.2436370849609, \"count\": 1, \"min\": 803.2436370849609, \"max\": 803.2436370849609}}}\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1626.9594687319704 records/second\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.9385696107690986\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] Epoch[74] Batch[0] avg_epoch_loss=2.819988\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.8199880123138428\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] Epoch[74] Batch[5] avg_epoch_loss=2.901371\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.901371161142985\n",
      "[05/21/2025 16:52:24 INFO 140202337613632] Epoch[74] Batch [5]#011Speed: 2707.46 samples/sec#011loss=2.901371\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] Epoch[74] Batch[10] avg_epoch_loss=3.031930\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=3.188600540161133\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] Epoch[74] Batch [10]#011Speed: 2358.27 samples/sec#011loss=3.188601\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747846344.2986672, \"EndTime\": 1747846345.1165004, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.5778388977051, \"count\": 1, \"min\": 817.5778388977051, \"max\": 817.5778388977051}}}\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1605.7905018721176 records/second\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=74, train loss <loss>=3.0319299697875977\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] Epoch[75] Batch[0] avg_epoch_loss=2.954078\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.95407772064209\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] Epoch[75] Batch[5] avg_epoch_loss=2.973775\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.9737751881281533\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] Epoch[75] Batch [5]#011Speed: 2620.56 samples/sec#011loss=2.973775\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] Epoch[75] Batch[10] avg_epoch_loss=2.913414\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=2.8409804821014406\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] Epoch[75] Batch [10]#011Speed: 2557.31 samples/sec#011loss=2.840980\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747846345.1165605, \"EndTime\": 1747846345.9291477, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.2920989990234, \"count\": 1, \"min\": 812.2920989990234, \"max\": 812.2920989990234}}}\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1617.474253813584 records/second\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.9134139581160112\n",
      "[05/21/2025 16:52:25 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] Epoch[76] Batch[0] avg_epoch_loss=3.029591\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=3.0295910835266113\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] Epoch[76] Batch[5] avg_epoch_loss=2.937006\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.93700635433197\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] Epoch[76] Batch [5]#011Speed: 2704.24 samples/sec#011loss=2.937006\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] Epoch[76] Batch[10] avg_epoch_loss=2.956539\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.97997841835022\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] Epoch[76] Batch [10]#011Speed: 2629.10 samples/sec#011loss=2.979978\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747846345.9292045, \"EndTime\": 1747846346.718445, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.9895439147949, \"count\": 1, \"min\": 788.9895439147949, \"max\": 788.9895439147949}}}\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1651.2533894912401 records/second\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.956539110703902\n",
      "[05/21/2025 16:52:26 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] Epoch[77] Batch[0] avg_epoch_loss=2.893637\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.8936374187469482\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] Epoch[77] Batch[5] avg_epoch_loss=2.927506\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.9275060494740806\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] Epoch[77] Batch [5]#011Speed: 2660.63 samples/sec#011loss=2.927506\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] Epoch[77] Batch[10] avg_epoch_loss=2.907081\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.882570266723633\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] Epoch[77] Batch [10]#011Speed: 2412.19 samples/sec#011loss=2.882570\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747846346.718524, \"EndTime\": 1747846347.5262187, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.4097633361816, \"count\": 1, \"min\": 807.4097633361816, \"max\": 807.4097633361816}}}\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1696.5110167587472 records/second\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.9070806936784224\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] Epoch[78] Batch[0] avg_epoch_loss=2.860216\n",
      "[05/21/2025 16:52:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.860215663909912\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] Epoch[78] Batch[5] avg_epoch_loss=2.862526\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.8625258604685464\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] Epoch[78] Batch [5]#011Speed: 2651.30 samples/sec#011loss=2.862526\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747846347.5263202, \"EndTime\": 1747846348.2667449, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 739.9678230285645, \"count\": 1, \"min\": 739.9678230285645, \"max\": 739.9678230285645}}}\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1710.6608751063527 records/second\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.8604697704315187\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] Epoch[79] Batch[0] avg_epoch_loss=2.831561\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.8315610885620117\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] Epoch[79] Batch[5] avg_epoch_loss=2.848504\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.848504145940145\n",
      "[05/21/2025 16:52:28 INFO 140202337613632] Epoch[79] Batch [5]#011Speed: 2656.45 samples/sec#011loss=2.848504\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] Epoch[79] Batch[10] avg_epoch_loss=2.858466\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.870421123504639\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] Epoch[79] Batch [10]#011Speed: 2513.85 samples/sec#011loss=2.870421\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747846348.2668083, \"EndTime\": 1747846349.0678413, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.7111549377441, \"count\": 1, \"min\": 800.7111549377441, \"max\": 800.7111549377441}}}\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1693.3095382775896 records/second\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.8584664084694604\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] Epoch[80] Batch[0] avg_epoch_loss=2.873184\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.8731837272644043\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] Epoch[80] Batch[5] avg_epoch_loss=2.833479\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.833478569984436\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] Epoch[80] Batch [5]#011Speed: 2653.10 samples/sec#011loss=2.833479\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] Epoch[80] Batch[10] avg_epoch_loss=2.766781\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.6867440938949585\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] Epoch[80] Batch [10]#011Speed: 2584.87 samples/sec#011loss=2.686744\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747846349.0679, \"EndTime\": 1747846349.8640535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.9024906158447, \"count\": 1, \"min\": 795.9024906158447, \"max\": 795.9024906158447}}}\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1644.4945191442814 records/second\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.7667810808528555\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:52:29 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_179a5f54-80c1-46c0-b03b-aad2089f9d8b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846349.8641117, \"EndTime\": 1747846349.8742676, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.880304336547852, \"count\": 1, \"min\": 9.880304336547852, \"max\": 9.880304336547852}}}\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] Epoch[81] Batch[0] avg_epoch_loss=2.869915\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.86991548538208\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] Epoch[81] Batch[5] avg_epoch_loss=2.847979\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.847978949546814\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] Epoch[81] Batch [5]#011Speed: 2611.42 samples/sec#011loss=2.847979\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] Epoch[81] Batch[10] avg_epoch_loss=2.826530\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.800791072845459\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] Epoch[81] Batch [10]#011Speed: 2571.49 samples/sec#011loss=2.800791\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747846349.87433, \"EndTime\": 1747846350.674624, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.2378940582275, \"count\": 1, \"min\": 800.2378940582275, \"max\": 800.2378940582275}}}\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1615.586132359714 records/second\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.8265299146825615\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] Epoch[82] Batch[0] avg_epoch_loss=2.853906\n",
      "[05/21/2025 16:52:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.85390567779541\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] Epoch[82] Batch[5] avg_epoch_loss=2.886728\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.886728127797445\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] Epoch[82] Batch [5]#011Speed: 2730.06 samples/sec#011loss=2.886728\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] Epoch[82] Batch[10] avg_epoch_loss=2.794888\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=2.684679460525513\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] Epoch[82] Batch [10]#011Speed: 2649.75 samples/sec#011loss=2.684679\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747846350.6746852, \"EndTime\": 1747846351.4640923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.1497611999512, \"count\": 1, \"min\": 789.1497611999512, \"max\": 789.1497611999512}}}\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1653.4906760998215 records/second\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.794887824492021\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] Epoch[83] Batch[0] avg_epoch_loss=2.761281\n",
      "[05/21/2025 16:52:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.7612812519073486\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] Epoch[83] Batch[5] avg_epoch_loss=2.800183\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.8001830180486045\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] Epoch[83] Batch [5]#011Speed: 2684.91 samples/sec#011loss=2.800183\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] Epoch[83] Batch[10] avg_epoch_loss=2.845923\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.900811290740967\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] Epoch[83] Batch [10]#011Speed: 2607.82 samples/sec#011loss=2.900811\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747846351.4641526, \"EndTime\": 1747846352.2538245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.4191741943359, \"count\": 1, \"min\": 789.4191741943359, \"max\": 789.4191741943359}}}\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1671.9286206519591 records/second\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.845923141999678\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] Epoch[84] Batch[0] avg_epoch_loss=2.794238\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.7942380905151367\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] Epoch[84] Batch[5] avg_epoch_loss=2.810480\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.8104803959528604\n",
      "[05/21/2025 16:52:32 INFO 140202337613632] Epoch[84] Batch [5]#011Speed: 2739.95 samples/sec#011loss=2.810480\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] Epoch[84] Batch[10] avg_epoch_loss=2.918787\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=3.048755931854248\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] Epoch[84] Batch [10]#011Speed: 2408.04 samples/sec#011loss=3.048756\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747846352.2538831, \"EndTime\": 1747846353.0622835, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 808.0887794494629, \"count\": 1, \"min\": 808.0887794494629, \"max\": 808.0887794494629}}}\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1635.779327158232 records/second\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.9187874577262183\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] Epoch[85] Batch[0] avg_epoch_loss=3.012714\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=3.012714385986328\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] Epoch[85] Batch[5] avg_epoch_loss=2.984867\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.9848670959472656\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] Epoch[85] Batch [5]#011Speed: 2706.84 samples/sec#011loss=2.984867\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] Epoch[85] Batch[10] avg_epoch_loss=2.964241\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=2.939489221572876\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] Epoch[85] Batch [10]#011Speed: 2554.18 samples/sec#011loss=2.939489\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747846353.0623436, \"EndTime\": 1747846353.8606656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.9145050048828, \"count\": 1, \"min\": 797.9145050048828, \"max\": 797.9145050048828}}}\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1631.5758236853167 records/second\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.964240789413452\n",
      "[05/21/2025 16:52:33 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] Epoch[86] Batch[0] avg_epoch_loss=2.995220\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.9952199459075928\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] Epoch[86] Batch[5] avg_epoch_loss=2.963958\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.9639576276143393\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] Epoch[86] Batch [5]#011Speed: 2856.05 samples/sec#011loss=2.963958\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] Epoch[86] Batch[10] avg_epoch_loss=2.883895\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.7878191471099854\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] Epoch[86] Batch [10]#011Speed: 2579.18 samples/sec#011loss=2.787819\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747846353.8607233, \"EndTime\": 1747846354.6420572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 781.0845375061035, \"count\": 1, \"min\": 781.0845375061035, \"max\": 781.0845375061035}}}\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1651.3673138269623 records/second\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.883894681930542\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] Epoch[87] Batch[0] avg_epoch_loss=2.855119\n",
      "[05/21/2025 16:52:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.8551185131073\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] Epoch[87] Batch[5] avg_epoch_loss=2.871401\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.8714009126027427\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] Epoch[87] Batch [5]#011Speed: 2761.16 samples/sec#011loss=2.871401\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] Epoch[87] Batch[10] avg_epoch_loss=2.865306\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.85799126625061\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] Epoch[87] Batch [10]#011Speed: 2539.60 samples/sec#011loss=2.857991\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] processed a total of 1375 examples\n",
      "#metrics {\"StartTime\": 1747846354.6421154, \"EndTime\": 1747846355.4263887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.0225696563721, \"count\": 1, \"min\": 784.0225696563721, \"max\": 784.0225696563721}}}\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1753.4059991067527 records/second\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.865305618806319\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] Epoch[88] Batch[0] avg_epoch_loss=2.953691\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.953691005706787\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] Epoch[88] Batch[5] avg_epoch_loss=2.898771\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.8987712462743125\n",
      "[05/21/2025 16:52:35 INFO 140202337613632] Epoch[88] Batch [5]#011Speed: 2769.52 samples/sec#011loss=2.898771\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] Epoch[88] Batch[10] avg_epoch_loss=2.907923\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=2.918905735015869\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] Epoch[88] Batch [10]#011Speed: 2766.28 samples/sec#011loss=2.918906\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747846355.4265177, \"EndTime\": 1747846356.227676, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.7416725158691, \"count\": 1, \"min\": 800.7416725158691, \"max\": 800.7416725158691}}}\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1630.800497776084 records/second\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.9079232866113838\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] Epoch[89] Batch[0] avg_epoch_loss=2.767331\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.76733136177063\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] Epoch[89] Batch[5] avg_epoch_loss=2.783282\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.7832815647125244\n",
      "[05/21/2025 16:52:36 INFO 140202337613632] Epoch[89] Batch [5]#011Speed: 2758.42 samples/sec#011loss=2.783282\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] Epoch[89] Batch[10] avg_epoch_loss=2.712098\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=2.6266777515411377\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] Epoch[89] Batch [10]#011Speed: 2570.26 samples/sec#011loss=2.626678\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747846356.2277362, \"EndTime\": 1747846357.0147665, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.7765426635742, \"count\": 1, \"min\": 786.7765426635742, \"max\": 786.7765426635742}}}\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1683.895459730847 records/second\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.712098013270985\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_65d060de-0ea5-4718-8d9b-ec28a2a02486-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846357.0148275, \"EndTime\": 1747846357.024638, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.529590606689453, \"count\": 1, \"min\": 9.529590606689453, \"max\": 9.529590606689453}}}\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] Epoch[90] Batch[0] avg_epoch_loss=2.748056\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.748056173324585\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] Epoch[90] Batch[5] avg_epoch_loss=2.803495\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.803495486577352\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] Epoch[90] Batch [5]#011Speed: 2833.76 samples/sec#011loss=2.803495\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747846357.0246959, \"EndTime\": 1747846357.7481787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 723.4249114990234, \"count\": 1, \"min\": 723.4249114990234, \"max\": 723.4249114990234}}}\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1763.5983347096517 records/second\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.801363134384155\n",
      "[05/21/2025 16:52:37 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] Epoch[91] Batch[0] avg_epoch_loss=2.839749\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.8397490978240967\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] Epoch[91] Batch[5] avg_epoch_loss=2.805376\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.8053762118021646\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] Epoch[91] Batch [5]#011Speed: 2762.09 samples/sec#011loss=2.805376\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747846357.7482426, \"EndTime\": 1747846358.4992917, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 750.7197856903076, \"count\": 1, \"min\": 750.7197856903076, \"max\": 750.7197856903076}}}\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1698.1575610618895 records/second\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.7966851711273195\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] Epoch[92] Batch[0] avg_epoch_loss=2.862464\n",
      "[05/21/2025 16:52:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.862464427947998\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] Epoch[92] Batch[5] avg_epoch_loss=2.792413\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.792413314183553\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] Epoch[92] Batch [5]#011Speed: 2651.79 samples/sec#011loss=2.792413\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] Epoch[92] Batch[10] avg_epoch_loss=2.789048\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.7850101947784425\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] Epoch[92] Batch [10]#011Speed: 2400.41 samples/sec#011loss=2.785010\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] processed a total of 1415 examples\n",
      "#metrics {\"StartTime\": 1747846358.499353, \"EndTime\": 1747846359.3495245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 849.7893810272217, \"count\": 1, \"min\": 849.7893810272217, \"max\": 849.7893810272217}}}\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1664.919486935931 records/second\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.8019971450169883\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] Epoch[93] Batch[0] avg_epoch_loss=2.770737\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.7707366943359375\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] Epoch[93] Batch[5] avg_epoch_loss=2.791499\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.7914987802505493\n",
      "[05/21/2025 16:52:39 INFO 140202337613632] Epoch[93] Batch [5]#011Speed: 2690.60 samples/sec#011loss=2.791499\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] Epoch[93] Batch[10] avg_epoch_loss=2.821941\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.858471632003784\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] Epoch[93] Batch [10]#011Speed: 2356.46 samples/sec#011loss=2.858472\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747846359.349592, \"EndTime\": 1747846360.168347, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 818.4080123901367, \"count\": 1, \"min\": 818.4080123901367, \"max\": 818.4080123901367}}}\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1604.1599324211154 records/second\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.8219409855929287\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] Epoch[94] Batch[0] avg_epoch_loss=2.773769\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.7737693786621094\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] Epoch[94] Batch[5] avg_epoch_loss=2.755843\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.755843202273051\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] Epoch[94] Batch [5]#011Speed: 2709.44 samples/sec#011loss=2.755843\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747846360.1684055, \"EndTime\": 1747846360.9068358, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 738.1315231323242, \"count\": 1, \"min\": 738.1315231323242, \"max\": 738.1315231323242}}}\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1733.8904389283207 records/second\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.756926488876343\n",
      "[05/21/2025 16:52:40 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] Epoch[95] Batch[0] avg_epoch_loss=2.824144\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.824143648147583\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] Epoch[95] Batch[5] avg_epoch_loss=2.787271\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.7872706254323325\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] Epoch[95] Batch [5]#011Speed: 2641.42 samples/sec#011loss=2.787271\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] Epoch[95] Batch[10] avg_epoch_loss=2.805476\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.8273218631744386\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] Epoch[95] Batch [10]#011Speed: 2733.40 samples/sec#011loss=2.827322\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747846360.906897, \"EndTime\": 1747846361.694154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.9200706481934, \"count\": 1, \"min\": 786.9200706481934, \"max\": 786.9200706481934}}}\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1634.0425993936876 records/second\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.8054757334969262\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] Epoch[96] Batch[0] avg_epoch_loss=2.802111\n",
      "[05/21/2025 16:52:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.8021106719970703\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] Epoch[96] Batch[5] avg_epoch_loss=2.805527\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.805527448654175\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] Epoch[96] Batch [5]#011Speed: 2360.73 samples/sec#011loss=2.805527\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] Epoch[96] Batch[10] avg_epoch_loss=2.755646\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.695789098739624\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] Epoch[96] Batch [10]#011Speed: 2663.95 samples/sec#011loss=2.695789\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747846361.6942105, \"EndTime\": 1747846362.5105846, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 816.0738945007324, \"count\": 1, \"min\": 816.0738945007324, \"max\": 816.0738945007324}}}\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1606.2727267681616 records/second\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.7556463805111973\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] Epoch[97] Batch[0] avg_epoch_loss=2.782447\n",
      "[05/21/2025 16:52:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.782447099685669\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] Epoch[97] Batch[5] avg_epoch_loss=2.811569\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.8115689357121787\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] Epoch[97] Batch [5]#011Speed: 2606.48 samples/sec#011loss=2.811569\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] Epoch[97] Batch[10] avg_epoch_loss=2.823477\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.837765693664551\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] Epoch[97] Batch [10]#011Speed: 2528.04 samples/sec#011loss=2.837766\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747846362.5106547, \"EndTime\": 1747846363.311642, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.7256984710693, \"count\": 1, \"min\": 800.7256984710693, \"max\": 800.7256984710693}}}\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1658.3098840292087 records/second\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.823476552963257\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] Epoch[98] Batch[0] avg_epoch_loss=2.780719\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.7807185649871826\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] Epoch[98] Batch[5] avg_epoch_loss=2.789874\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.7898736000061035\n",
      "[05/21/2025 16:52:43 INFO 140202337613632] Epoch[98] Batch [5]#011Speed: 2653.20 samples/sec#011loss=2.789874\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] Epoch[98] Batch[10] avg_epoch_loss=2.780718\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=2.769731950759888\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] Epoch[98] Batch [10]#011Speed: 2603.86 samples/sec#011loss=2.769732\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747846363.3117018, \"EndTime\": 1747846364.1043177, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 792.335033416748, \"count\": 1, \"min\": 792.335033416748, \"max\": 792.335033416748}}}\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1656.9418082322352 records/second\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.780718304894187\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] Epoch[99] Batch[0] avg_epoch_loss=2.692527\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.6925270557403564\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] Epoch[99] Batch[5] avg_epoch_loss=2.740301\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.740301171938578\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] Epoch[99] Batch [5]#011Speed: 2678.87 samples/sec#011loss=2.740301\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] Epoch[99] Batch[10] avg_epoch_loss=2.737666\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=2.7345040321350096\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] Epoch[99] Batch [10]#011Speed: 2462.31 samples/sec#011loss=2.734504\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747846364.1043766, \"EndTime\": 1747846364.906413, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.7828464508057, \"count\": 1, \"min\": 801.7828464508057, \"max\": 801.7828464508057}}}\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1704.6949368575188 records/second\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.7376661083915015\n",
      "[05/21/2025 16:52:44 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] Epoch[100] Batch[0] avg_epoch_loss=2.702219\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.702218532562256\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] Epoch[100] Batch[5] avg_epoch_loss=2.731322\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.7313223282496133\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] Epoch[100] Batch [5]#011Speed: 2676.76 samples/sec#011loss=2.731322\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] Epoch[100] Batch[10] avg_epoch_loss=2.670861\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.598306894302368\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] Epoch[100] Batch [10]#011Speed: 2482.27 samples/sec#011loss=2.598307\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747846364.906504, \"EndTime\": 1747846365.711143, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 804.3274879455566, \"count\": 1, \"min\": 804.3274879455566, \"max\": 804.3274879455566}}}\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1648.4029021082342 records/second\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.670860767364502\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:52:45 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_4276ac13-6e14-4d0e-9c0a-0af624964222-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846365.7112014, \"EndTime\": 1747846365.7204132, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.943557739257812, \"count\": 1, \"min\": 8.943557739257812, \"max\": 8.943557739257812}}}\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] Epoch[101] Batch[0] avg_epoch_loss=2.777862\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.7778618335723877\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] Epoch[101] Batch[5] avg_epoch_loss=2.739410\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.739410161972046\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] Epoch[101] Batch [5]#011Speed: 2678.85 samples/sec#011loss=2.739410\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] Epoch[101] Batch[10] avg_epoch_loss=2.739972\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=2.7406460285186767\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] Epoch[101] Batch [10]#011Speed: 2533.09 samples/sec#011loss=2.740646\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747846365.7204728, \"EndTime\": 1747846366.519214, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.6865043640137, \"count\": 1, \"min\": 798.6865043640137, \"max\": 798.6865043640137}}}\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1658.7911003870397 records/second\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.7399719194932417\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] Epoch[102] Batch[0] avg_epoch_loss=2.853476\n",
      "[05/21/2025 16:52:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.8534762859344482\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] Epoch[102] Batch[5] avg_epoch_loss=2.774710\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.774710496266683\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] Epoch[102] Batch [5]#011Speed: 2747.54 samples/sec#011loss=2.774710\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] Epoch[102] Batch[10] avg_epoch_loss=2.808352\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=2.848721218109131\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] Epoch[102] Batch [10]#011Speed: 2431.74 samples/sec#011loss=2.848721\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747846366.5192728, \"EndTime\": 1747846367.316994, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.4720001220703, \"count\": 1, \"min\": 797.4720001220703, \"max\": 797.4720001220703}}}\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1687.5550560293084 records/second\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.8083517334677954\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] Epoch[103] Batch[0] avg_epoch_loss=2.735467\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.735466957092285\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] Epoch[103] Batch[5] avg_epoch_loss=2.752274\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.75227419535319\n",
      "[05/21/2025 16:52:47 INFO 140202337613632] Epoch[103] Batch [5]#011Speed: 2627.09 samples/sec#011loss=2.752274\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] Epoch[103] Batch[10] avg_epoch_loss=2.786898\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.828446054458618\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] Epoch[103] Batch [10]#011Speed: 2596.24 samples/sec#011loss=2.828446\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747846367.3170965, \"EndTime\": 1747846368.118219, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.8604049682617, \"count\": 1, \"min\": 800.8604049682617, \"max\": 800.8604049682617}}}\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1600.6063344995093 records/second\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.7868977676738393\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] Epoch[104] Batch[0] avg_epoch_loss=2.726522\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.7265219688415527\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] Epoch[104] Batch[5] avg_epoch_loss=2.779977\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.779977003733317\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] Epoch[104] Batch [5]#011Speed: 2760.49 samples/sec#011loss=2.779977\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] Epoch[104] Batch[10] avg_epoch_loss=2.778760\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=2.777300500869751\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] Epoch[104] Batch [10]#011Speed: 2387.97 samples/sec#011loss=2.777301\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747846368.118277, \"EndTime\": 1747846368.9261858, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.6357841491699, \"count\": 1, \"min\": 807.6357841491699, \"max\": 807.6357841491699}}}\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1626.7995549949865 records/second\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.778760411522605\n",
      "[05/21/2025 16:52:48 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] Epoch[105] Batch[0] avg_epoch_loss=2.749063\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.74906325340271\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] Epoch[105] Batch[5] avg_epoch_loss=2.788175\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.7881747484207153\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] Epoch[105] Batch [5]#011Speed: 2622.86 samples/sec#011loss=2.788175\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] Epoch[105] Batch[10] avg_epoch_loss=2.699706\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.593543028831482\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] Epoch[105] Batch [10]#011Speed: 2352.70 samples/sec#011loss=2.593543\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747846368.9262435, \"EndTime\": 1747846369.751285, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 824.7549533843994, \"count\": 1, \"min\": 824.7549533843994, \"max\": 824.7549533843994}}}\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1629.4011276311248 records/second\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.699705784971064\n",
      "[05/21/2025 16:52:49 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] Epoch[106] Batch[0] avg_epoch_loss=2.756419\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.7564194202423096\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] Epoch[106] Batch[5] avg_epoch_loss=2.760998\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.7609976132710776\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] Epoch[106] Batch [5]#011Speed: 2712.29 samples/sec#011loss=2.760998\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] Epoch[106] Batch[10] avg_epoch_loss=2.729870\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=2.6925164699554442\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] Epoch[106] Batch [10]#011Speed: 2580.51 samples/sec#011loss=2.692516\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747846369.751343, \"EndTime\": 1747846370.5368342, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.1877212524414, \"count\": 1, \"min\": 785.1877212524414, \"max\": 785.1877212524414}}}\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1731.8747774150975 records/second\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.7298698208548804\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] Epoch[107] Batch[0] avg_epoch_loss=2.854593\n",
      "[05/21/2025 16:52:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.8545925617218018\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] Epoch[107] Batch[5] avg_epoch_loss=2.747245\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.747244636217753\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] Epoch[107] Batch [5]#011Speed: 2667.86 samples/sec#011loss=2.747245\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] Epoch[107] Batch[10] avg_epoch_loss=2.759876\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.7750333309173585\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] Epoch[107] Batch [10]#011Speed: 2421.89 samples/sec#011loss=2.775033\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747846370.5368931, \"EndTime\": 1747846371.3508723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.6587142944336, \"count\": 1, \"min\": 813.6587142944336, \"max\": 813.6587142944336}}}\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1677.4217531811164 records/second\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.75987586108121\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] Epoch[108] Batch[0] avg_epoch_loss=2.693631\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.693631172180176\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] Epoch[108] Batch[5] avg_epoch_loss=2.683649\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.6836485068003335\n",
      "[05/21/2025 16:52:51 INFO 140202337613632] Epoch[108] Batch [5]#011Speed: 2541.98 samples/sec#011loss=2.683649\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] Epoch[108] Batch[10] avg_epoch_loss=2.618850\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.5410909414291383\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] Epoch[108] Batch [10]#011Speed: 2534.70 samples/sec#011loss=2.541091\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747846371.350932, \"EndTime\": 1747846372.1578033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 806.6122531890869, \"count\": 1, \"min\": 806.6122531890869, \"max\": 806.6122531890869}}}\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1662.3285123527285 records/second\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.61884961344979\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_c160bbb7-4811-44c0-8ded-6318a81de65d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846372.1578612, \"EndTime\": 1747846372.1674333, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.305715560913086, \"count\": 1, \"min\": 9.305715560913086, \"max\": 9.305715560913086}}}\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] Epoch[109] Batch[0] avg_epoch_loss=2.679771\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.6797711849212646\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] Epoch[109] Batch[5] avg_epoch_loss=2.714049\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.714049458503723\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] Epoch[109] Batch [5]#011Speed: 2656.87 samples/sec#011loss=2.714049\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] Epoch[109] Batch[10] avg_epoch_loss=2.724824\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.737753391265869\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] Epoch[109] Batch [10]#011Speed: 2417.26 samples/sec#011loss=2.737753\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747846372.1674926, \"EndTime\": 1747846372.9761677, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 808.6199760437012, \"count\": 1, \"min\": 808.6199760437012, \"max\": 808.6199760437012}}}\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1687.873074573641 records/second\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.724823973395608\n",
      "[05/21/2025 16:52:52 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] Epoch[110] Batch[0] avg_epoch_loss=2.747420\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.747420072555542\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] Epoch[110] Batch[5] avg_epoch_loss=2.676887\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.6768874327341714\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] Epoch[110] Batch [5]#011Speed: 2695.35 samples/sec#011loss=2.676887\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] Epoch[110] Batch[10] avg_epoch_loss=2.720262\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.7723119258880615\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] Epoch[110] Batch [10]#011Speed: 2510.03 samples/sec#011loss=2.772312\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747846372.9762287, \"EndTime\": 1747846373.7788374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.8412590026855, \"count\": 1, \"min\": 801.8412590026855, \"max\": 801.8412590026855}}}\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1623.585136347663 records/second\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.720262202349576\n",
      "[05/21/2025 16:52:53 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] Epoch[111] Batch[0] avg_epoch_loss=2.636669\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.636669397354126\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] Epoch[111] Batch[5] avg_epoch_loss=2.658720\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.6587202151616416\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] Epoch[111] Batch [5]#011Speed: 2675.08 samples/sec#011loss=2.658720\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] Epoch[111] Batch[10] avg_epoch_loss=2.602882\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=2.5358770847320558\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] Epoch[111] Batch [10]#011Speed: 2573.26 samples/sec#011loss=2.535877\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747846373.7788963, \"EndTime\": 1747846374.5749567, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.2446937561035, \"count\": 1, \"min\": 795.2446937561035, \"max\": 795.2446937561035}}}\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1681.0535310825496 records/second\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.6028824286027388\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_1176b9c9-462a-437b-aa2b-c4e422b59790-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846374.5750165, \"EndTime\": 1747846374.5850437, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.753942489624023, \"count\": 1, \"min\": 9.753942489624023, \"max\": 9.753942489624023}}}\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] Epoch[112] Batch[0] avg_epoch_loss=2.754033\n",
      "[05/21/2025 16:52:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.754033327102661\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] Epoch[112] Batch[5] avg_epoch_loss=2.719723\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.7197229464848838\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] Epoch[112] Batch [5]#011Speed: 2748.22 samples/sec#011loss=2.719723\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] Epoch[112] Batch[10] avg_epoch_loss=2.610040\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.4784196615219116\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] Epoch[112] Batch [10]#011Speed: 2714.82 samples/sec#011loss=2.478420\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747846374.5851326, \"EndTime\": 1747846375.3600628, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 774.8725414276123, \"count\": 1, \"min\": 774.8725414276123, \"max\": 774.8725414276123}}}\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1682.6689564255641 records/second\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.610039635138078\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] Epoch[113] Batch[0] avg_epoch_loss=2.755483\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.755483388900757\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] Epoch[113] Batch[5] avg_epoch_loss=2.660357\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.660356561342875\n",
      "[05/21/2025 16:52:55 INFO 140202337613632] Epoch[113] Batch [5]#011Speed: 2807.14 samples/sec#011loss=2.660357\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] Epoch[113] Batch[10] avg_epoch_loss=2.703859\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.756062889099121\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] Epoch[113] Batch [10]#011Speed: 2636.85 samples/sec#011loss=2.756063\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747846375.36012, \"EndTime\": 1747846376.1617706, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.3975620269775, \"count\": 1, \"min\": 801.3975620269775, \"max\": 801.3975620269775}}}\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1635.710174588353 records/second\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.7038594375957143\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] Epoch[114] Batch[0] avg_epoch_loss=2.675913\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.675913095474243\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] Epoch[114] Batch[5] avg_epoch_loss=2.692877\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.692877491315206\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] Epoch[114] Batch [5]#011Speed: 2776.57 samples/sec#011loss=2.692877\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] Epoch[114] Batch[10] avg_epoch_loss=2.701483\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=2.711809778213501\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] Epoch[114] Batch [10]#011Speed: 2563.14 samples/sec#011loss=2.711810\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747846376.161831, \"EndTime\": 1747846376.9502723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.1913185119629, \"count\": 1, \"min\": 788.1913185119629, \"max\": 788.1913185119629}}}\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1724.011890114437 records/second\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.7014830762689765\n",
      "[05/21/2025 16:52:56 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:57 INFO 140202337613632] Epoch[115] Batch[0] avg_epoch_loss=2.773700\n",
      "[05/21/2025 16:52:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.773699998855591\n",
      "[05/21/2025 16:52:57 INFO 140202337613632] Epoch[115] Batch[5] avg_epoch_loss=2.718192\n",
      "[05/21/2025 16:52:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.718192219734192\n",
      "[05/21/2025 16:52:57 INFO 140202337613632] Epoch[115] Batch [5]#011Speed: 2688.63 samples/sec#011loss=2.718192\n",
      "[05/21/2025 16:52:57 INFO 140202337613632] processed a total of 1277 examples\n",
      "#metrics {\"StartTime\": 1747846376.95033, \"EndTime\": 1747846377.6988614, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 748.2528686523438, \"count\": 1, \"min\": 748.2528686523438, \"max\": 748.2528686523438}}}\n",
      "[05/21/2025 16:52:57 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1706.4242709238335 records/second\n",
      "[05/21/2025 16:52:57 INFO 140202337613632] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[05/21/2025 16:52:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.695316457748413\n",
      "[05/21/2025 16:52:57 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] Epoch[116] Batch[0] avg_epoch_loss=2.597595\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.597594738006592\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] Epoch[116] Batch[5] avg_epoch_loss=2.639630\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.63962988058726\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] Epoch[116] Batch [5]#011Speed: 2813.22 samples/sec#011loss=2.639630\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] processed a total of 1256 examples\n",
      "#metrics {\"StartTime\": 1747846377.6989267, \"EndTime\": 1747846378.4207547, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 721.4875221252441, \"count\": 1, \"min\": 721.4875221252441, \"max\": 721.4875221252441}}}\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1740.6160445207913 records/second\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.6426390171051026\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] Epoch[117] Batch[0] avg_epoch_loss=2.659474\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.6594736576080322\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] Epoch[117] Batch[5] avg_epoch_loss=2.578838\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.578838070233663\n",
      "[05/21/2025 16:52:58 INFO 140202337613632] Epoch[117] Batch [5]#011Speed: 2540.87 samples/sec#011loss=2.578838\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] processed a total of 1235 examples\n",
      "#metrics {\"StartTime\": 1747846378.4208198, \"EndTime\": 1747846379.1679409, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 746.8233108520508, \"count\": 1, \"min\": 746.8233108520508, \"max\": 746.8233108520508}}}\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1653.4518719402556 records/second\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.61690890789032\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] Epoch[118] Batch[0] avg_epoch_loss=2.649346\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.649345636367798\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] Epoch[118] Batch[5] avg_epoch_loss=2.697303\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.6973034540812173\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] Epoch[118] Batch [5]#011Speed: 2700.64 samples/sec#011loss=2.697303\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] Epoch[118] Batch[10] avg_epoch_loss=2.687100\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.6748547554016113\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] Epoch[118] Batch [10]#011Speed: 2517.77 samples/sec#011loss=2.674855\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747846379.1680076, \"EndTime\": 1747846379.965026, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.7193126678467, \"count\": 1, \"min\": 796.7193126678467, \"max\": 796.7193126678467}}}\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1656.6138297875523 records/second\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.687099500135942\n",
      "[05/21/2025 16:52:59 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] Epoch[119] Batch[0] avg_epoch_loss=2.676411\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.676410675048828\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] Epoch[119] Batch[5] avg_epoch_loss=2.639222\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.6392220656077066\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] Epoch[119] Batch [5]#011Speed: 2783.63 samples/sec#011loss=2.639222\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] Epoch[119] Batch[10] avg_epoch_loss=2.643478\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=2.6485846042633057\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] Epoch[119] Batch [10]#011Speed: 2491.57 samples/sec#011loss=2.648585\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747846379.9650848, \"EndTime\": 1747846380.7530704, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 787.7304553985596, \"count\": 1, \"min\": 787.7304553985596, \"max\": 787.7304553985596}}}\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1712.326590693947 records/second\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.6434777649966152\n",
      "[05/21/2025 16:53:00 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] Epoch[120] Batch[0] avg_epoch_loss=2.647143\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.6471426486968994\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] Epoch[120] Batch[5] avg_epoch_loss=2.637319\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.637318730354309\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] Epoch[120] Batch [5]#011Speed: 2789.33 samples/sec#011loss=2.637319\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] Epoch[120] Batch[10] avg_epoch_loss=2.689207\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=2.75147385597229\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] Epoch[120] Batch [10]#011Speed: 2751.31 samples/sec#011loss=2.751474\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747846380.7531288, \"EndTime\": 1747846381.53184, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 778.46360206604, \"count\": 1, \"min\": 778.46360206604, \"max\": 778.46360206604}}}\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1669.775523615925 records/second\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.689207423817028\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] Epoch[121] Batch[0] avg_epoch_loss=3.240335\n",
      "[05/21/2025 16:53:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=3.240335464477539\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] Epoch[121] Batch[5] avg_epoch_loss=3.167001\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=3.167000691095988\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] Epoch[121] Batch [5]#011Speed: 2435.49 samples/sec#011loss=3.167001\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] Epoch[121] Batch[10] avg_epoch_loss=3.080628\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=2.9769798278808595\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] Epoch[121] Batch [10]#011Speed: 2543.51 samples/sec#011loss=2.976980\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747846381.5318973, \"EndTime\": 1747846382.349861, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.7146911621094, \"count\": 1, \"min\": 817.7146911621094, \"max\": 817.7146911621094}}}\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1633.6478356810235 records/second\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=121, train loss <loss>=3.0806275714527476\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] Epoch[122] Batch[0] avg_epoch_loss=3.197017\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=3.1970174312591553\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] Epoch[122] Batch[5] avg_epoch_loss=3.111925\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=3.1119246085484824\n",
      "[05/21/2025 16:53:02 INFO 140202337613632] Epoch[122] Batch [5]#011Speed: 2628.52 samples/sec#011loss=3.111925\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] processed a total of 1270 examples\n",
      "#metrics {\"StartTime\": 1747846382.349919, \"EndTime\": 1747846383.1097374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 759.5696449279785, \"count\": 1, \"min\": 759.5696449279785, \"max\": 759.5696449279785}}}\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1671.787937553295 records/second\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=122, train loss <loss>=3.0604992628097536\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] Epoch[123] Batch[0] avg_epoch_loss=3.037943\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=3.0379433631896973\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] Epoch[123] Batch[5] avg_epoch_loss=2.938281\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.9382814168930054\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] Epoch[123] Batch [5]#011Speed: 2596.48 samples/sec#011loss=2.938281\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] Epoch[123] Batch[10] avg_epoch_loss=2.942588\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=2.94775595664978\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] Epoch[123] Batch [10]#011Speed: 2483.45 samples/sec#011loss=2.947756\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747846383.109803, \"EndTime\": 1747846383.921316, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.159610748291, \"count\": 1, \"min\": 811.159610748291, \"max\": 811.159610748291}}}\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1633.2868299389381 records/second\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] #progress_metric: host=algo-1, completed 31.0 % of epochs\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.9425880258733574\n",
      "[05/21/2025 16:53:03 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] Epoch[124] Batch[0] avg_epoch_loss=2.865557\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.8655567169189453\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] Epoch[124] Batch[5] avg_epoch_loss=2.856834\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.856834053993225\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] Epoch[124] Batch [5]#011Speed: 2681.11 samples/sec#011loss=2.856834\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] Epoch[124] Batch[10] avg_epoch_loss=2.694123\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=2.4988704204559324\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] Epoch[124] Batch [10]#011Speed: 2628.99 samples/sec#011loss=2.498870\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747846383.9213755, \"EndTime\": 1747846384.716674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.0026988983154, \"count\": 1, \"min\": 795.0026988983154, \"max\": 795.0026988983154}}}\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1629.9983669484275 records/second\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] #progress_metric: host=algo-1, completed 31.25 % of epochs\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.694123311476274\n",
      "[05/21/2025 16:53:04 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] Epoch[125] Batch[0] avg_epoch_loss=2.851324\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.8513240814208984\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] Epoch[125] Batch[5] avg_epoch_loss=2.779476\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.7794755697250366\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] Epoch[125] Batch [5]#011Speed: 2645.46 samples/sec#011loss=2.779476\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] Epoch[125] Batch[10] avg_epoch_loss=2.766507\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=2.7509445190429687\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] Epoch[125] Batch [10]#011Speed: 2641.69 samples/sec#011loss=2.750945\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747846384.7167337, \"EndTime\": 1747846385.5057662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.7740135192871, \"count\": 1, \"min\": 788.7740135192871, \"max\": 788.7740135192871}}}\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1682.1593569531435 records/second\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] #progress_metric: host=algo-1, completed 31.5 % of epochs\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.7665069103240967\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] Epoch[126] Batch[0] avg_epoch_loss=2.721181\n",
      "[05/21/2025 16:53:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.7211813926696777\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] Epoch[126] Batch[5] avg_epoch_loss=2.707716\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.7077163457870483\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] Epoch[126] Batch [5]#011Speed: 2726.21 samples/sec#011loss=2.707716\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] Epoch[126] Batch[10] avg_epoch_loss=2.709079\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=2.710714101791382\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] Epoch[126] Batch [10]#011Speed: 2720.59 samples/sec#011loss=2.710714\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747846385.5058289, \"EndTime\": 1747846386.3041103, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.0380058288574, \"count\": 1, \"min\": 798.0380058288574, \"max\": 798.0380058288574}}}\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1613.790921808445 records/second\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] #progress_metric: host=algo-1, completed 31.75 % of epochs\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.7090789621526543\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] Epoch[127] Batch[0] avg_epoch_loss=2.702460\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.7024598121643066\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] Epoch[127] Batch[5] avg_epoch_loss=2.719261\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.7192614873250327\n",
      "[05/21/2025 16:53:06 INFO 140202337613632] Epoch[127] Batch [5]#011Speed: 2742.40 samples/sec#011loss=2.719261\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] Epoch[127] Batch[10] avg_epoch_loss=2.659138\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=2.5869893550872805\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] Epoch[127] Batch [10]#011Speed: 2481.60 samples/sec#011loss=2.586989\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747846386.304166, \"EndTime\": 1747846387.1030946, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.691987991333, \"count\": 1, \"min\": 798.691987991333, \"max\": 798.691987991333}}}\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1647.513021572534 records/second\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] #progress_metric: host=algo-1, completed 32.0 % of epochs\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.659137790853327\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] Epoch[128] Batch[0] avg_epoch_loss=2.807003\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.8070027828216553\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] Epoch[128] Batch[5] avg_epoch_loss=2.707262\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.707261880238851\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] Epoch[128] Batch [5]#011Speed: 2769.33 samples/sec#011loss=2.707262\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] Epoch[128] Batch[10] avg_epoch_loss=2.688787\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=2.666616201400757\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] Epoch[128] Batch [10]#011Speed: 2576.28 samples/sec#011loss=2.666616\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747846387.1031556, \"EndTime\": 1747846387.8902483, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.832332611084, \"count\": 1, \"min\": 786.832332611084, \"max\": 786.832332611084}}}\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1657.0923254793697 records/second\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] #progress_metric: host=algo-1, completed 32.25 % of epochs\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.688786571676081\n",
      "[05/21/2025 16:53:07 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] Epoch[129] Batch[0] avg_epoch_loss=2.784858\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.7848575115203857\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] Epoch[129] Batch[5] avg_epoch_loss=2.753676\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.7536761363347373\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] Epoch[129] Batch [5]#011Speed: 2832.04 samples/sec#011loss=2.753676\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] Epoch[129] Batch[10] avg_epoch_loss=2.729767\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=2.7010758399963377\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] Epoch[129] Batch [10]#011Speed: 2789.89 samples/sec#011loss=2.701076\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747846387.8903089, \"EndTime\": 1747846388.6600246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 769.4387435913086, \"count\": 1, \"min\": 769.4387435913086, \"max\": 769.4387435913086}}}\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1664.6554194291366 records/second\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] #progress_metric: host=algo-1, completed 32.5 % of epochs\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.729766910726374\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] Epoch[130] Batch[0] avg_epoch_loss=2.580950\n",
      "[05/21/2025 16:53:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.5809497833251953\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] Epoch[130] Batch[5] avg_epoch_loss=2.697901\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.697901407877604\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] Epoch[130] Batch [5]#011Speed: 2421.38 samples/sec#011loss=2.697901\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] processed a total of 1257 examples\n",
      "#metrics {\"StartTime\": 1747846388.6600842, \"EndTime\": 1747846389.4247973, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 764.411211013794, \"count\": 1, \"min\": 764.411211013794, \"max\": 764.411211013794}}}\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1644.1921147239555 records/second\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] #progress_metric: host=algo-1, completed 32.75 % of epochs\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.6957187175750734\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] Epoch[131] Batch[0] avg_epoch_loss=2.589195\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.5891945362091064\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] Epoch[131] Batch[5] avg_epoch_loss=2.652962\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.6529616117477417\n",
      "[05/21/2025 16:53:09 INFO 140202337613632] Epoch[131] Batch [5]#011Speed: 2654.64 samples/sec#011loss=2.652962\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] Epoch[131] Batch[10] avg_epoch_loss=2.664380\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=2.67808313369751\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] Epoch[131] Batch [10]#011Speed: 2331.42 samples/sec#011loss=2.678083\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747846389.4248633, \"EndTime\": 1747846390.2452517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 820.0311660766602, \"count\": 1, \"min\": 820.0311660766602, \"max\": 820.0311660766602}}}\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1643.6602768271512 records/second\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] #progress_metric: host=algo-1, completed 33.0 % of epochs\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.6643804853612725\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] Epoch[132] Batch[0] avg_epoch_loss=2.676171\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.676171064376831\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] Epoch[132] Batch[5] avg_epoch_loss=2.620118\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.6201178630193076\n",
      "[05/21/2025 16:53:10 INFO 140202337613632] Epoch[132] Batch [5]#011Speed: 2572.07 samples/sec#011loss=2.620118\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] Epoch[132] Batch[10] avg_epoch_loss=2.617870\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=2.6151726245880127\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] Epoch[132] Batch [10]#011Speed: 2437.05 samples/sec#011loss=2.615173\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747846390.245312, \"EndTime\": 1747846391.0632076, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.6040649414062, \"count\": 1, \"min\": 817.6040649414062, \"max\": 817.6040649414062}}}\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1594.7231105975534 records/second\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] #progress_metric: host=algo-1, completed 33.25 % of epochs\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.6178700273687188\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] Epoch[133] Batch[0] avg_epoch_loss=2.629585\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.6295852661132812\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] Epoch[133] Batch[5] avg_epoch_loss=2.602740\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.6027397314707437\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] Epoch[133] Batch [5]#011Speed: 2616.91 samples/sec#011loss=2.602740\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] Epoch[133] Batch[10] avg_epoch_loss=2.625557\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=2.6529377460479737\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] Epoch[133] Batch [10]#011Speed: 2620.61 samples/sec#011loss=2.652938\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747846391.0632684, \"EndTime\": 1747846391.8598228, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.2162494659424, \"count\": 1, \"min\": 796.2162494659424, \"max\": 796.2162494659424}}}\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1642.5873104459235 records/second\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] #progress_metric: host=algo-1, completed 33.5 % of epochs\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.6255570108240303\n",
      "[05/21/2025 16:53:11 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] Epoch[134] Batch[0] avg_epoch_loss=2.727801\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.7278013229370117\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] Epoch[134] Batch[5] avg_epoch_loss=2.712534\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.7125344276428223\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] Epoch[134] Batch [5]#011Speed: 2691.43 samples/sec#011loss=2.712534\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] Epoch[134] Batch[10] avg_epoch_loss=2.750136\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.795258092880249\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] Epoch[134] Batch [10]#011Speed: 2558.01 samples/sec#011loss=2.795258\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747846391.8598824, \"EndTime\": 1747846392.6590908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.8772392272949, \"count\": 1, \"min\": 798.8772392272949, \"max\": 798.8772392272949}}}\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1608.3140259559666 records/second\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] #progress_metric: host=algo-1, completed 33.75 % of epochs\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.7501360936598345\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] Epoch[135] Batch[0] avg_epoch_loss=2.832005\n",
      "[05/21/2025 16:53:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.8320045471191406\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] Epoch[135] Batch[5] avg_epoch_loss=2.729605\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.7296045621236167\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] Epoch[135] Batch [5]#011Speed: 2638.08 samples/sec#011loss=2.729605\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] Epoch[135] Batch[10] avg_epoch_loss=2.741470\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=2.7557082653045653\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] Epoch[135] Batch [10]#011Speed: 2485.12 samples/sec#011loss=2.755708\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747846392.659154, \"EndTime\": 1747846393.4736488, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.1720294952393, \"count\": 1, \"min\": 814.1720294952393, \"max\": 814.1720294952393}}}\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1598.9809966357177 records/second\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] #progress_metric: host=algo-1, completed 34.0 % of epochs\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.741469881751321\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] Epoch[136] Batch[0] avg_epoch_loss=2.687347\n",
      "[05/21/2025 16:53:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.687347173690796\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] Epoch[136] Batch[5] avg_epoch_loss=2.681918\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.6819178263346353\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] Epoch[136] Batch [5]#011Speed: 2678.63 samples/sec#011loss=2.681918\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] Epoch[136] Batch[10] avg_epoch_loss=2.716948\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=2.758984375\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] Epoch[136] Batch [10]#011Speed: 2667.18 samples/sec#011loss=2.758984\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747846393.473714, \"EndTime\": 1747846394.2743962, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.9553680419922, \"count\": 1, \"min\": 799.9553680419922, \"max\": 799.9553680419922}}}\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1604.8757401951245 records/second\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] #progress_metric: host=algo-1, completed 34.25 % of epochs\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.716948075727983\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] Epoch[137] Batch[0] avg_epoch_loss=2.644881\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.6448814868927\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] Epoch[137] Batch[5] avg_epoch_loss=2.635423\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.6354233821233115\n",
      "[05/21/2025 16:53:14 INFO 140202337613632] Epoch[137] Batch [5]#011Speed: 2640.09 samples/sec#011loss=2.635423\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] Epoch[137] Batch[10] avg_epoch_loss=2.634303\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=2.632957696914673\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] Epoch[137] Batch [10]#011Speed: 2481.85 samples/sec#011loss=2.632958\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747846394.2744737, \"EndTime\": 1747846395.0816152, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 806.8671226501465, \"count\": 1, \"min\": 806.8671226501465, \"max\": 806.8671226501465}}}\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1656.8460828915793 records/second\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] #progress_metric: host=algo-1, completed 34.5 % of epochs\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.6343026161193848\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] Epoch[138] Batch[0] avg_epoch_loss=2.663297\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.663297414779663\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] Epoch[138] Batch[5] avg_epoch_loss=2.649527\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.649527072906494\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] Epoch[138] Batch [5]#011Speed: 2717.93 samples/sec#011loss=2.649527\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] Epoch[138] Batch[10] avg_epoch_loss=2.657310\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.6666492938995363\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] Epoch[138] Batch [10]#011Speed: 2463.64 samples/sec#011loss=2.666649\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747846395.0816746, \"EndTime\": 1747846395.8810153, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.044132232666, \"count\": 1, \"min\": 799.044132232666, \"max\": 799.044132232666}}}\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1698.0967589296956 records/second\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] #progress_metric: host=algo-1, completed 34.75 % of epochs\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.657309900630604\n",
      "[05/21/2025 16:53:15 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] Epoch[139] Batch[0] avg_epoch_loss=2.640483\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.6404831409454346\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] Epoch[139] Batch[5] avg_epoch_loss=2.614566\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.6145657698313394\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] Epoch[139] Batch [5]#011Speed: 2672.39 samples/sec#011loss=2.614566\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] Epoch[139] Batch[10] avg_epoch_loss=2.639658\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=2.6697693347930906\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] Epoch[139] Batch [10]#011Speed: 2612.19 samples/sec#011loss=2.669769\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747846395.8810706, \"EndTime\": 1747846396.6681123, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.6458892822266, \"count\": 1, \"min\": 786.6458892822266, \"max\": 786.6458892822266}}}\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1676.5486514817383 records/second\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] #progress_metric: host=algo-1, completed 35.0 % of epochs\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.639658299359408\n",
      "[05/21/2025 16:53:16 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] Epoch[140] Batch[0] avg_epoch_loss=2.554303\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.554302930831909\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] Epoch[140] Batch[5] avg_epoch_loss=2.600200\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.6002001762390137\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] Epoch[140] Batch [5]#011Speed: 2645.94 samples/sec#011loss=2.600200\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] Epoch[140] Batch[10] avg_epoch_loss=2.664449\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=2.741548538208008\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] Epoch[140] Batch [10]#011Speed: 2568.20 samples/sec#011loss=2.741549\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747846396.6681714, \"EndTime\": 1747846397.4986763, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 830.2075862884521, \"count\": 1, \"min\": 830.2075862884521, \"max\": 830.2075862884521}}}\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1600.63437408561 records/second\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] #progress_metric: host=algo-1, completed 35.25 % of epochs\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.6644494316794654\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] Epoch[141] Batch[0] avg_epoch_loss=2.499347\n",
      "[05/21/2025 16:53:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.49934720993042\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] Epoch[141] Batch[5] avg_epoch_loss=2.587610\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.5876097281773887\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] Epoch[141] Batch [5]#011Speed: 2488.12 samples/sec#011loss=2.587610\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] Epoch[141] Batch[10] avg_epoch_loss=2.529085\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=2.4588563442230225\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] Epoch[141] Batch [10]#011Speed: 2539.58 samples/sec#011loss=2.458856\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747846397.4987338, \"EndTime\": 1747846398.315895, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 816.8175220489502, \"count\": 1, \"min\": 816.8175220489502, \"max\": 816.8175220489502}}}\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1568.111923118232 records/second\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] #progress_metric: host=algo-1, completed 35.5 % of epochs\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.529085462743586\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_7a7d284a-0c3b-4be7-8ad7-d9e2a1ac88d4-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846398.3159542, \"EndTime\": 1747846398.32573, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.500980377197266, \"count\": 1, \"min\": 9.500980377197266, \"max\": 9.500980377197266}}}\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] Epoch[142] Batch[0] avg_epoch_loss=2.700492\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.7004916667938232\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] Epoch[142] Batch[5] avg_epoch_loss=2.595962\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.5959622065226235\n",
      "[05/21/2025 16:53:18 INFO 140202337613632] Epoch[142] Batch [5]#011Speed: 2682.10 samples/sec#011loss=2.595962\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] Epoch[142] Batch[10] avg_epoch_loss=2.590554\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=2.5840638637542725\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] Epoch[142] Batch [10]#011Speed: 2526.51 samples/sec#011loss=2.584064\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747846398.3257897, \"EndTime\": 1747846399.1224833, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.6103553771973, \"count\": 1, \"min\": 796.6103553771973, \"max\": 796.6103553771973}}}\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1689.411423352553 records/second\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] #progress_metric: host=algo-1, completed 35.75 % of epochs\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.590553868900646\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] Epoch[143] Batch[0] avg_epoch_loss=2.664739\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.6647393703460693\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] Epoch[143] Batch[5] avg_epoch_loss=2.609753\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.609753211339315\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] Epoch[143] Batch [5]#011Speed: 2793.28 samples/sec#011loss=2.609753\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] Epoch[143] Batch[10] avg_epoch_loss=2.574253\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=2.53165225982666\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] Epoch[143] Batch [10]#011Speed: 2659.78 samples/sec#011loss=2.531652\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747846399.1225452, \"EndTime\": 1747846399.8991325, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 776.2517929077148, \"count\": 1, \"min\": 776.2517929077148, \"max\": 776.2517929077148}}}\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1682.250537895283 records/second\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] #progress_metric: host=algo-1, completed 36.0 % of epochs\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.5742527788335625\n",
      "[05/21/2025 16:53:19 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] Epoch[144] Batch[0] avg_epoch_loss=2.466247\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.466247081756592\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] Epoch[144] Batch[5] avg_epoch_loss=2.633528\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.6335277954737344\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] Epoch[144] Batch [5]#011Speed: 2582.61 samples/sec#011loss=2.633528\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] Epoch[144] Batch[10] avg_epoch_loss=2.648961\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=2.6674803256988526\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] Epoch[144] Batch [10]#011Speed: 2591.41 samples/sec#011loss=2.667480\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747846399.8991926, \"EndTime\": 1747846400.6975634, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.1162071228027, \"count\": 1, \"min\": 798.1162071228027, \"max\": 798.1162071228027}}}\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1668.7379766643658 records/second\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] #progress_metric: host=algo-1, completed 36.25 % of epochs\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.648960763757879\n",
      "[05/21/2025 16:53:20 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] Epoch[145] Batch[0] avg_epoch_loss=2.893862\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.893862009048462\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] Epoch[145] Batch[5] avg_epoch_loss=2.999583\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.999582807223002\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] Epoch[145] Batch [5]#011Speed: 2524.96 samples/sec#011loss=2.999583\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747846400.6976254, \"EndTime\": 1747846401.4496253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 751.7483234405518, \"count\": 1, \"min\": 751.7483234405518, \"max\": 751.7483234405518}}}\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1699.8241015571487 records/second\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] #progress_metric: host=algo-1, completed 36.5 % of epochs\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.9597572088241577\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] Epoch[146] Batch[0] avg_epoch_loss=2.762645\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.7626450061798096\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] Epoch[146] Batch[5] avg_epoch_loss=2.784628\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.78462815284729\n",
      "[05/21/2025 16:53:21 INFO 140202337613632] Epoch[146] Batch [5]#011Speed: 2690.65 samples/sec#011loss=2.784628\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] Epoch[146] Batch[10] avg_epoch_loss=2.751665\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=2.712109851837158\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] Epoch[146] Batch [10]#011Speed: 2425.03 samples/sec#011loss=2.712110\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747846401.4496899, \"EndTime\": 1747846402.257829, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.8494071960449, \"count\": 1, \"min\": 807.8494071960449, \"max\": 807.8494071960449}}}\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1628.8371763065848 records/second\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] #progress_metric: host=algo-1, completed 36.75 % of epochs\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.7516652887517754\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] Epoch[147] Batch[0] avg_epoch_loss=3.129359\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=3.1293585300445557\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] Epoch[147] Batch[5] avg_epoch_loss=3.052673\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=3.0526732206344604\n",
      "[05/21/2025 16:53:22 INFO 140202337613632] Epoch[147] Batch [5]#011Speed: 2608.40 samples/sec#011loss=3.052673\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] Epoch[147] Batch[10] avg_epoch_loss=2.976392\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=2.884855031967163\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] Epoch[147] Batch [10]#011Speed: 2606.20 samples/sec#011loss=2.884855\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747846402.2578888, \"EndTime\": 1747846403.0583365, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.1937866210938, \"count\": 1, \"min\": 800.1937866210938, \"max\": 800.1937866210938}}}\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1613.1741416493453 records/second\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] #progress_metric: host=algo-1, completed 37.0 % of epochs\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.976392225785689\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] Epoch[148] Batch[0] avg_epoch_loss=2.914554\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.9145541191101074\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] Epoch[148] Batch[5] avg_epoch_loss=2.887633\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.8876327673594155\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] Epoch[148] Batch [5]#011Speed: 2670.31 samples/sec#011loss=2.887633\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] Epoch[148] Batch[10] avg_epoch_loss=2.804051\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=2.7037521839141845\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] Epoch[148] Batch [10]#011Speed: 2557.61 samples/sec#011loss=2.703752\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747846403.0583982, \"EndTime\": 1747846403.8565063, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.8110313415527, \"count\": 1, \"min\": 797.8110313415527, \"max\": 797.8110313415527}}}\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1645.5701914221872 records/second\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] #progress_metric: host=algo-1, completed 37.25 % of epochs\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.8040506839752197\n",
      "[05/21/2025 16:53:23 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] Epoch[149] Batch[0] avg_epoch_loss=2.869610\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.86961030960083\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] Epoch[149] Batch[5] avg_epoch_loss=2.740095\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.7400952577590942\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] Epoch[149] Batch [5]#011Speed: 2564.30 samples/sec#011loss=2.740095\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] Epoch[149] Batch[10] avg_epoch_loss=2.667976\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=2.581431818008423\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] Epoch[149] Batch [10]#011Speed: 2469.36 samples/sec#011loss=2.581432\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747846403.8565657, \"EndTime\": 1747846404.674506, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.6918029785156, \"count\": 1, \"min\": 817.6918029785156, \"max\": 817.6918029785156}}}\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1627.5694713230248 records/second\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] #progress_metric: host=algo-1, completed 37.5 % of epochs\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.66797551241788\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] Epoch[150] Batch[0] avg_epoch_loss=2.733560\n",
      "[05/21/2025 16:53:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.7335596084594727\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] Epoch[150] Batch[5] avg_epoch_loss=2.722878\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.722877542177836\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] Epoch[150] Batch [5]#011Speed: 2732.26 samples/sec#011loss=2.722878\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] Epoch[150] Batch[10] avg_epoch_loss=2.717433\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=2.710899305343628\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] Epoch[150] Batch [10]#011Speed: 2519.81 samples/sec#011loss=2.710899\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747846404.6745684, \"EndTime\": 1747846405.4650412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.1999950408936, \"count\": 1, \"min\": 790.1999950408936, \"max\": 790.1999950408936}}}\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1728.4775981078342 records/second\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] #progress_metric: host=algo-1, completed 37.75 % of epochs\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.717432889071378\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] Epoch[151] Batch[0] avg_epoch_loss=2.635220\n",
      "[05/21/2025 16:53:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.6352200508117676\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] Epoch[151] Batch[5] avg_epoch_loss=2.653820\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.6538195610046387\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] Epoch[151] Batch [5]#011Speed: 2527.97 samples/sec#011loss=2.653820\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] Epoch[151] Batch[10] avg_epoch_loss=2.621853\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=2.58349347114563\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] Epoch[151] Batch [10]#011Speed: 2423.40 samples/sec#011loss=2.583493\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747846405.4651036, \"EndTime\": 1747846406.2831783, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.8174495697021, \"count\": 1, \"min\": 817.8174495697021, \"max\": 817.8174495697021}}}\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1655.4447422586052 records/second\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] #progress_metric: host=algo-1, completed 38.0 % of epochs\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.621853156523271\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] Epoch[152] Batch[0] avg_epoch_loss=2.651620\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.6516201496124268\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] Epoch[152] Batch[5] avg_epoch_loss=2.605677\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.605676809946696\n",
      "[05/21/2025 16:53:26 INFO 140202337613632] Epoch[152] Batch [5]#011Speed: 2697.53 samples/sec#011loss=2.605677\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] Epoch[152] Batch[10] avg_epoch_loss=2.495504\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=2.363297390937805\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] Epoch[152] Batch [10]#011Speed: 2607.39 samples/sec#011loss=2.363297\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747846406.283239, \"EndTime\": 1747846407.072935, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.40749168396, \"count\": 1, \"min\": 789.40749168396, \"max\": 789.40749168396}}}\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1647.8853749891662 records/second\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] #progress_metric: host=algo-1, completed 38.25 % of epochs\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.4955043467608364\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_0bcbeb3f-dda9-4765-80fc-8edadb2458ed-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846407.0729952, \"EndTime\": 1747846407.0827444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.475469589233398, \"count\": 1, \"min\": 9.475469589233398, \"max\": 9.475469589233398}}}\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] Epoch[153] Batch[0] avg_epoch_loss=2.664067\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.664066791534424\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] Epoch[153] Batch[5] avg_epoch_loss=2.602991\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.6029911438624063\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] Epoch[153] Batch [5]#011Speed: 2727.05 samples/sec#011loss=2.602991\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] Epoch[153] Batch[10] avg_epoch_loss=2.587995\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=2.570000696182251\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] Epoch[153] Batch [10]#011Speed: 2414.39 samples/sec#011loss=2.570001\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747846407.0828052, \"EndTime\": 1747846407.8841288, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.2685775756836, \"count\": 1, \"min\": 801.2685775756836, \"max\": 801.2685775756836}}}\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1682.1420897170726 records/second\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] #progress_metric: host=algo-1, completed 38.5 % of epochs\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.587995485825972\n",
      "[05/21/2025 16:53:27 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] Epoch[154] Batch[0] avg_epoch_loss=2.528228\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.5282275676727295\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] Epoch[154] Batch[5] avg_epoch_loss=2.602864\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.6028637886047363\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] Epoch[154] Batch [5]#011Speed: 2574.36 samples/sec#011loss=2.602864\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] Epoch[154] Batch[10] avg_epoch_loss=2.599410\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=2.595264768600464\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] Epoch[154] Batch [10]#011Speed: 2648.64 samples/sec#011loss=2.595265\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747846407.8841908, \"EndTime\": 1747846408.6816902, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.2507476806641, \"count\": 1, \"min\": 797.2507476806641, \"max\": 797.2507476806641}}}\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1653.0122030204643 records/second\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] #progress_metric: host=algo-1, completed 38.75 % of epochs\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.5994096886027944\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] Epoch[155] Batch[0] avg_epoch_loss=2.708365\n",
      "[05/21/2025 16:53:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.708364725112915\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] Epoch[155] Batch[5] avg_epoch_loss=2.667070\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.6670696338017783\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] Epoch[155] Batch [5]#011Speed: 2593.95 samples/sec#011loss=2.667070\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] Epoch[155] Batch[10] avg_epoch_loss=2.688832\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=2.7149465560913084\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] Epoch[155] Batch [10]#011Speed: 2475.01 samples/sec#011loss=2.714947\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747846408.6817443, \"EndTime\": 1747846409.5032544, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 821.2380409240723, \"count\": 1, \"min\": 821.2380409240723, \"max\": 821.2380409240723}}}\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1624.2018361673352 records/second\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] #progress_metric: host=algo-1, completed 39.0 % of epochs\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.6888318712061103\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] Epoch[156] Batch[0] avg_epoch_loss=2.693296\n",
      "[05/21/2025 16:53:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.69329571723938\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] Epoch[156] Batch[5] avg_epoch_loss=2.589395\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.5893950859705606\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] Epoch[156] Batch [5]#011Speed: 2704.77 samples/sec#011loss=2.589395\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] Epoch[156] Batch[10] avg_epoch_loss=2.601164\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=2.6152860641479494\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] Epoch[156] Batch [10]#011Speed: 2571.37 samples/sec#011loss=2.615286\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747846409.5033138, \"EndTime\": 1747846410.2976642, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.0967082977295, \"count\": 1, \"min\": 794.0967082977295, \"max\": 794.0967082977295}}}\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1629.344424927748 records/second\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] #progress_metric: host=algo-1, completed 39.25 % of epochs\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.601163712414828\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] Epoch[157] Batch[0] avg_epoch_loss=2.526788\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.526787519454956\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] Epoch[157] Batch[5] avg_epoch_loss=2.570730\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.5707298119862876\n",
      "[05/21/2025 16:53:30 INFO 140202337613632] Epoch[157] Batch [5]#011Speed: 2671.14 samples/sec#011loss=2.570730\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] Epoch[157] Batch[10] avg_epoch_loss=2.521840\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=2.463171887397766\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] Epoch[157] Batch [10]#011Speed: 2517.00 samples/sec#011loss=2.463172\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747846410.2977247, \"EndTime\": 1747846411.0956213, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.6493835449219, \"count\": 1, \"min\": 797.6493835449219, \"max\": 797.6493835449219}}}\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1647.1522591682044 records/second\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] #progress_metric: host=algo-1, completed 39.5 % of epochs\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.5218398462642324\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] Epoch[158] Batch[0] avg_epoch_loss=2.572758\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.5727579593658447\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] Epoch[158] Batch[5] avg_epoch_loss=2.549502\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.549502452214559\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] Epoch[158] Batch [5]#011Speed: 2646.98 samples/sec#011loss=2.549502\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] processed a total of 1265 examples\n",
      "#metrics {\"StartTime\": 1747846411.0956833, \"EndTime\": 1747846411.8484821, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 752.5322437286377, \"count\": 1, \"min\": 752.5322437286377, \"max\": 752.5322437286377}}}\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1680.7732996954471 records/second\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] #progress_metric: host=algo-1, completed 39.75 % of epochs\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.550574517250061\n",
      "[05/21/2025 16:53:31 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] Epoch[159] Batch[0] avg_epoch_loss=2.419064\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.4190640449523926\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] Epoch[159] Batch[5] avg_epoch_loss=2.507147\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.5071470737457275\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] Epoch[159] Batch [5]#011Speed: 2566.66 samples/sec#011loss=2.507147\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] Epoch[159] Batch[10] avg_epoch_loss=2.479450\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=2.4462140560150147\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] Epoch[159] Batch [10]#011Speed: 2474.56 samples/sec#011loss=2.446214\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747846411.8485487, \"EndTime\": 1747846412.6616547, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.7596378326416, \"count\": 1, \"min\": 812.7596378326416, \"max\": 812.7596378326416}}}\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1633.7625609723905 records/second\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] #progress_metric: host=algo-1, completed 40.0 % of epochs\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.4794502475044946\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_57115675-4ebe-4239-8df4-ceb6f42904fb-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846412.6617148, \"EndTime\": 1747846412.671012, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.025812149047852, \"count\": 1, \"min\": 9.025812149047852, \"max\": 9.025812149047852}}}\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] Epoch[160] Batch[0] avg_epoch_loss=2.522310\n",
      "[05/21/2025 16:53:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.5223095417022705\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] Epoch[160] Batch[5] avg_epoch_loss=2.498428\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.4984278678894043\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] Epoch[160] Batch [5]#011Speed: 2742.27 samples/sec#011loss=2.498428\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] Epoch[160] Batch[10] avg_epoch_loss=2.529749\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=2.5673349857330323\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] Epoch[160] Batch [10]#011Speed: 2561.93 samples/sec#011loss=2.567335\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747846412.671069, \"EndTime\": 1747846413.4612753, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.1508808135986, \"count\": 1, \"min\": 790.1508808135986, \"max\": 790.1508808135986}}}\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1685.5561459540772 records/second\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] #progress_metric: host=algo-1, completed 40.25 % of epochs\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.5297492850910532\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] Epoch[161] Batch[0] avg_epoch_loss=2.530850\n",
      "[05/21/2025 16:53:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.5308496952056885\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] Epoch[161] Batch[5] avg_epoch_loss=2.524861\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.5248610178629556\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] Epoch[161] Batch [5]#011Speed: 2619.88 samples/sec#011loss=2.524861\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] Epoch[161] Batch[10] avg_epoch_loss=2.563730\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=2.610372304916382\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] Epoch[161] Batch [10]#011Speed: 2492.15 samples/sec#011loss=2.610372\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747846413.4613397, \"EndTime\": 1747846414.2623715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.7558116912842, \"count\": 1, \"min\": 799.7558116912842, \"max\": 799.7558116912842}}}\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1712.8344563054357 records/second\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] #progress_metric: host=algo-1, completed 40.5 % of epochs\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.5637297847054223\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] Epoch[162] Batch[0] avg_epoch_loss=2.637808\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.637807846069336\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] Epoch[162] Batch[5] avg_epoch_loss=2.535269\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.535269339879354\n",
      "[05/21/2025 16:53:34 INFO 140202337613632] Epoch[162] Batch [5]#011Speed: 2770.25 samples/sec#011loss=2.535269\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] Epoch[162] Batch[10] avg_epoch_loss=2.502570\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=2.4633318424224853\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] Epoch[162] Batch [10]#011Speed: 2504.36 samples/sec#011loss=2.463332\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747846414.2624319, \"EndTime\": 1747846415.0521057, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.3831729888916, \"count\": 1, \"min\": 789.3831729888916, \"max\": 789.3831729888916}}}\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1659.3341509399204 records/second\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] #progress_metric: host=algo-1, completed 40.75 % of epochs\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.502570477398959\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] Epoch[163] Batch[0] avg_epoch_loss=2.561475\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.5614752769470215\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] Epoch[163] Batch[5] avg_epoch_loss=2.525919\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.525919040044149\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] Epoch[163] Batch [5]#011Speed: 2711.00 samples/sec#011loss=2.525919\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] Epoch[163] Batch[10] avg_epoch_loss=2.538033\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=2.552568769454956\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] Epoch[163] Batch [10]#011Speed: 2596.22 samples/sec#011loss=2.552569\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747846415.0521665, \"EndTime\": 1747846415.8612387, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 808.7418079376221, \"count\": 1, \"min\": 808.7418079376221, \"max\": 808.7418079376221}}}\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1586.2455513989655 records/second\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] #progress_metric: host=algo-1, completed 41.0 % of epochs\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.5380325534126977\n",
      "[05/21/2025 16:53:35 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] Epoch[164] Batch[0] avg_epoch_loss=2.483627\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.4836268424987793\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] Epoch[164] Batch[5] avg_epoch_loss=2.512573\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.5125728448232016\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] Epoch[164] Batch [5]#011Speed: 2677.67 samples/sec#011loss=2.512573\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] Epoch[164] Batch[10] avg_epoch_loss=2.465169\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=2.40828423500061\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] Epoch[164] Batch [10]#011Speed: 2511.02 samples/sec#011loss=2.408284\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747846415.8612955, \"EndTime\": 1747846416.6578324, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.107292175293, \"count\": 1, \"min\": 796.107292175293, \"max\": 796.107292175293}}}\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1704.3496454705603 records/second\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] #progress_metric: host=algo-1, completed 41.25 % of epochs\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.465168931267478\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_8eec2d4d-dbf6-453e-a39e-642489f75318-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846416.657893, \"EndTime\": 1747846416.6670623, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.862972259521484, \"count\": 1, \"min\": 8.862972259521484, \"max\": 8.862972259521484}}}\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] Epoch[165] Batch[0] avg_epoch_loss=2.622020\n",
      "[05/21/2025 16:53:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.6220197677612305\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] Epoch[165] Batch[5] avg_epoch_loss=2.561996\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.5619956254959106\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] Epoch[165] Batch [5]#011Speed: 2779.97 samples/sec#011loss=2.561996\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] Epoch[165] Batch[10] avg_epoch_loss=2.551512\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=2.538931131362915\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] Epoch[165] Batch [10]#011Speed: 2645.28 samples/sec#011loss=2.538931\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747846416.6671228, \"EndTime\": 1747846417.44761, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.4288864135742, \"count\": 1, \"min\": 780.4288864135742, \"max\": 780.4288864135742}}}\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1654.0321694705572 records/second\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] #progress_metric: host=algo-1, completed 41.5 % of epochs\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.551511764526367\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] Epoch[166] Batch[0] avg_epoch_loss=2.925612\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.925611972808838\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] Epoch[166] Batch[5] avg_epoch_loss=2.923968\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.9239683548609414\n",
      "[05/21/2025 16:53:37 INFO 140202337613632] Epoch[166] Batch [5]#011Speed: 2775.13 samples/sec#011loss=2.923968\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] Epoch[166] Batch[10] avg_epoch_loss=2.847452\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=2.7556316375732424\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] Epoch[166] Batch [10]#011Speed: 2567.27 samples/sec#011loss=2.755632\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747846417.4476676, \"EndTime\": 1747846418.2297564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 781.8210124969482, \"count\": 1, \"min\": 781.8210124969482, \"max\": 781.8210124969482}}}\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1702.2462232738537 records/second\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] #progress_metric: host=algo-1, completed 41.75 % of epochs\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.8474516651847144\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] Epoch[167] Batch[0] avg_epoch_loss=2.814012\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=2.814011812210083\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] Epoch[167] Batch[5] avg_epoch_loss=2.772591\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.772591312726339\n",
      "[05/21/2025 16:53:38 INFO 140202337613632] Epoch[167] Batch [5]#011Speed: 2766.54 samples/sec#011loss=2.772591\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] Epoch[167] Batch[10] avg_epoch_loss=2.710333\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=2.6356223106384276\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] Epoch[167] Batch [10]#011Speed: 2635.96 samples/sec#011loss=2.635622\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747846418.2298148, \"EndTime\": 1747846419.0092826, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 779.2181968688965, \"count\": 1, \"min\": 779.2181968688965, \"max\": 779.2181968688965}}}\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1700.2360617701083 records/second\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] #progress_metric: host=algo-1, completed 42.0 % of epochs\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.710332675413652\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] Epoch[168] Batch[0] avg_epoch_loss=2.676568\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.676567554473877\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] Epoch[168] Batch[5] avg_epoch_loss=2.606485\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.6064847310384116\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] Epoch[168] Batch [5]#011Speed: 2742.20 samples/sec#011loss=2.606485\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] Epoch[168] Batch[10] avg_epoch_loss=2.616166\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=2.6277843952178954\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] Epoch[168] Batch [10]#011Speed: 2680.85 samples/sec#011loss=2.627784\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747846419.0093398, \"EndTime\": 1747846419.7874198, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 777.8313159942627, \"count\": 1, \"min\": 777.8313159942627, \"max\": 777.8313159942627}}}\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1696.835682676403 records/second\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] #progress_metric: host=algo-1, completed 42.25 % of epochs\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.6161663965745405\n",
      "[05/21/2025 16:53:39 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] Epoch[169] Batch[0] avg_epoch_loss=2.713533\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.7135326862335205\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] Epoch[169] Batch[5] avg_epoch_loss=2.730867\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.7308665911356607\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] Epoch[169] Batch [5]#011Speed: 2840.89 samples/sec#011loss=2.730867\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] Epoch[169] Batch[10] avg_epoch_loss=2.645000\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.541959047317505\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] Epoch[169] Batch [10]#011Speed: 2626.37 samples/sec#011loss=2.541959\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747846419.787479, \"EndTime\": 1747846420.5602078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 772.4733352661133, \"count\": 1, \"min\": 772.4733352661133, \"max\": 772.4733352661133}}}\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1742.2581557447118 records/second\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] #progress_metric: host=algo-1, completed 42.5 % of epochs\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.644999525763772\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] Epoch[170] Batch[0] avg_epoch_loss=2.648584\n",
      "[05/21/2025 16:53:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.6485843658447266\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] Epoch[170] Batch[5] avg_epoch_loss=2.669273\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.669273018836975\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] Epoch[170] Batch [5]#011Speed: 2621.94 samples/sec#011loss=2.669273\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] Epoch[170] Batch[10] avg_epoch_loss=2.626849\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=2.575939893722534\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] Epoch[170] Batch [10]#011Speed: 2468.39 samples/sec#011loss=2.575940\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747846420.5602658, \"EndTime\": 1747846421.3695064, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 808.9878559112549, \"count\": 1, \"min\": 808.9878559112549, \"max\": 808.9878559112549}}}\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1657.4475922850336 records/second\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] #progress_metric: host=algo-1, completed 42.75 % of epochs\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.6268488710576836\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] Epoch[171] Batch[0] avg_epoch_loss=2.572471\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.5724713802337646\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] Epoch[171] Batch[5] avg_epoch_loss=2.569549\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.569549004236857\n",
      "[05/21/2025 16:53:41 INFO 140202337613632] Epoch[171] Batch [5]#011Speed: 2776.92 samples/sec#011loss=2.569549\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] Epoch[171] Batch[10] avg_epoch_loss=2.537500\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=2.4990421295166017\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] Epoch[171] Batch [10]#011Speed: 2293.38 samples/sec#011loss=2.499042\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] processed a total of 1387 examples\n",
      "#metrics {\"StartTime\": 1747846421.369566, \"EndTime\": 1747846422.18841, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 818.5470104217529, \"count\": 1, \"min\": 818.5470104217529, \"max\": 818.5470104217529}}}\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1694.282817539345 records/second\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] #progress_metric: host=algo-1, completed 43.0 % of epochs\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.537500424818559\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] Epoch[172] Batch[0] avg_epoch_loss=2.425383\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.4253833293914795\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] Epoch[172] Batch[5] avg_epoch_loss=2.496552\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.4965523878733316\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] Epoch[172] Batch [5]#011Speed: 2783.15 samples/sec#011loss=2.496552\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] Epoch[172] Batch[10] avg_epoch_loss=2.563159\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=2.6430858612060546\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] Epoch[172] Batch [10]#011Speed: 2590.76 samples/sec#011loss=2.643086\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747846422.1884682, \"EndTime\": 1747846422.9714427, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.7212810516357, \"count\": 1, \"min\": 782.7212810516357, \"max\": 782.7212810516357}}}\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1668.3161801141314 records/second\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] #progress_metric: host=algo-1, completed 43.25 % of epochs\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.5631585121154785\n",
      "[05/21/2025 16:53:42 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] Epoch[173] Batch[0] avg_epoch_loss=2.426874\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.4268739223480225\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] Epoch[173] Batch[5] avg_epoch_loss=2.476898\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.476898471514384\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] Epoch[173] Batch [5]#011Speed: 2816.74 samples/sec#011loss=2.476898\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] Epoch[173] Batch[10] avg_epoch_loss=2.509947\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=2.5496051788330076\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] Epoch[173] Batch [10]#011Speed: 2592.94 samples/sec#011loss=2.549605\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747846422.971519, \"EndTime\": 1747846423.7491553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 777.3716449737549, \"count\": 1, \"min\": 777.3716449737549, \"max\": 777.3716449737549}}}\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1714.5563938365594 records/second\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] #progress_metric: host=algo-1, completed 43.5 % of epochs\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.5099469748410312\n",
      "[05/21/2025 16:53:43 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] Epoch[174] Batch[0] avg_epoch_loss=2.553606\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.5536062717437744\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] Epoch[174] Batch[5] avg_epoch_loss=2.496085\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.4960854053497314\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] Epoch[174] Batch [5]#011Speed: 2736.46 samples/sec#011loss=2.496085\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] Epoch[174] Batch[10] avg_epoch_loss=2.549556\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=2.6137202262878416\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] Epoch[174] Batch [10]#011Speed: 2574.27 samples/sec#011loss=2.613720\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747846423.7492158, \"EndTime\": 1747846424.5380366, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.4886264801025, \"count\": 1, \"min\": 788.4886264801025, \"max\": 788.4886264801025}}}\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1662.490599169712 records/second\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] #progress_metric: host=algo-1, completed 43.75 % of epochs\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.549555778503418\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] Epoch[175] Batch[0] avg_epoch_loss=2.469362\n",
      "[05/21/2025 16:53:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.4693615436553955\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] Epoch[175] Batch[5] avg_epoch_loss=2.486067\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.486067016919454\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] Epoch[175] Batch [5]#011Speed: 2761.30 samples/sec#011loss=2.486067\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] Epoch[175] Batch[10] avg_epoch_loss=2.534800\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=2.593279790878296\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] Epoch[175] Batch [10]#011Speed: 2689.42 samples/sec#011loss=2.593280\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747846424.538095, \"EndTime\": 1747846425.3134983, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 775.1526832580566, \"count\": 1, \"min\": 775.1526832580566, \"max\": 775.1526832580566}}}\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1692.286095177059 records/second\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] #progress_metric: host=algo-1, completed 44.0 % of epochs\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.534800095991655\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] Epoch[176] Batch[0] avg_epoch_loss=2.487603\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.4876034259796143\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] Epoch[176] Batch[5] avg_epoch_loss=2.510568\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.510568300882975\n",
      "[05/21/2025 16:53:45 INFO 140202337613632] Epoch[176] Batch [5]#011Speed: 2766.19 samples/sec#011loss=2.510568\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] Epoch[176] Batch[10] avg_epoch_loss=2.547798\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.592474269866943\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] Epoch[176] Batch [10]#011Speed: 2531.29 samples/sec#011loss=2.592474\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747846425.3135996, \"EndTime\": 1747846426.099975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.1142158508301, \"count\": 1, \"min\": 786.1142158508301, \"max\": 786.1142158508301}}}\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1731.1015996271205 records/second\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] #progress_metric: host=algo-1, completed 44.25 % of epochs\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.547798286784779\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] Epoch[177] Batch[0] avg_epoch_loss=2.537158\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.537158250808716\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] Epoch[177] Batch[5] avg_epoch_loss=2.471485\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.471484621365865\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] Epoch[177] Batch [5]#011Speed: 2726.11 samples/sec#011loss=2.471485\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] Epoch[177] Batch[10] avg_epoch_loss=2.468871\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=2.4657350063323973\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] Epoch[177] Batch [10]#011Speed: 2426.82 samples/sec#011loss=2.465735\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] processed a total of 1387 examples\n",
      "#metrics {\"StartTime\": 1747846426.1000354, \"EndTime\": 1747846426.8935418, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 793.2572364807129, \"count\": 1, \"min\": 793.2572364807129, \"max\": 793.2572364807129}}}\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1748.3078596773616 records/second\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] #progress_metric: host=algo-1, completed 44.5 % of epochs\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.468871159987016\n",
      "[05/21/2025 16:53:46 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] Epoch[178] Batch[0] avg_epoch_loss=2.603044\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.603043794631958\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] Epoch[178] Batch[5] avg_epoch_loss=2.490965\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.490965247154236\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] Epoch[178] Batch [5]#011Speed: 2837.41 samples/sec#011loss=2.490965\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] processed a total of 1259 examples\n",
      "#metrics {\"StartTime\": 1747846426.8935947, \"EndTime\": 1747846427.6189842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 725.1365184783936, \"count\": 1, \"min\": 725.1365184783936, \"max\": 725.1365184783936}}}\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1736.0033269435417 records/second\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] #progress_metric: host=algo-1, completed 44.75 % of epochs\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.496872568130493\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] Epoch[179] Batch[0] avg_epoch_loss=2.523899\n",
      "[05/21/2025 16:53:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.5238986015319824\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] Epoch[179] Batch[5] avg_epoch_loss=2.479462\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.479461987813314\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] Epoch[179] Batch [5]#011Speed: 2625.89 samples/sec#011loss=2.479462\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] Epoch[179] Batch[10] avg_epoch_loss=2.476554\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=2.473063659667969\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] Epoch[179] Batch [10]#011Speed: 2364.13 samples/sec#011loss=2.473064\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747846427.6190467, \"EndTime\": 1747846428.4328377, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.4872913360596, \"count\": 1, \"min\": 813.4872913360596, \"max\": 813.4872913360596}}}\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1677.7776488357413 records/second\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] #progress_metric: host=algo-1, completed 45.0 % of epochs\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.4765536568381568\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] Epoch[180] Batch[0] avg_epoch_loss=2.433397\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.4333972930908203\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] Epoch[180] Batch[5] avg_epoch_loss=2.420930\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.4209304650624595\n",
      "[05/21/2025 16:53:48 INFO 140202337613632] Epoch[180] Batch [5]#011Speed: 2559.28 samples/sec#011loss=2.420930\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] Epoch[180] Batch[10] avg_epoch_loss=2.535594\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=2.673190116882324\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] Epoch[180] Batch [10]#011Speed: 2514.14 samples/sec#011loss=2.673190\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747846428.4328947, \"EndTime\": 1747846429.2432423, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.0409507751465, \"count\": 1, \"min\": 810.0409507751465, \"max\": 810.0409507751465}}}\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1600.9486446852598 records/second\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] #progress_metric: host=algo-1, completed 45.25 % of epochs\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.535593943162398\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] Epoch[181] Batch[0] avg_epoch_loss=2.470753\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.4707534313201904\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] Epoch[181] Batch[5] avg_epoch_loss=2.496213\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.496212681134542\n",
      "[05/21/2025 16:53:49 INFO 140202337613632] Epoch[181] Batch [5]#011Speed: 2664.57 samples/sec#011loss=2.496213\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] Epoch[181] Batch[10] avg_epoch_loss=2.508427\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=2.5230835914611816\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] Epoch[181] Batch [10]#011Speed: 2625.31 samples/sec#011loss=2.523084\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747846429.2433145, \"EndTime\": 1747846430.0341825, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.6105518341064, \"count\": 1, \"min\": 790.6105518341064, \"max\": 790.6105518341064}}}\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1645.3800799715116 records/second\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] #progress_metric: host=algo-1, completed 45.5 % of epochs\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.5084267312830146\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] Epoch[182] Batch[0] avg_epoch_loss=2.493748\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.4937479496002197\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] Epoch[182] Batch[5] avg_epoch_loss=2.504327\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.504327178001404\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] Epoch[182] Batch [5]#011Speed: 2684.76 samples/sec#011loss=2.504327\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] Epoch[182] Batch[10] avg_epoch_loss=2.588729\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=2.6900111198425294\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] Epoch[182] Batch [10]#011Speed: 2623.13 samples/sec#011loss=2.690011\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747846430.0342412, \"EndTime\": 1747846430.82305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.5284423828125, \"count\": 1, \"min\": 788.5284423828125, \"max\": 788.5284423828125}}}\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1664.9382220834216 records/second\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] #progress_metric: host=algo-1, completed 45.75 % of epochs\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.58872896974737\n",
      "[05/21/2025 16:53:50 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] Epoch[183] Batch[0] avg_epoch_loss=2.493957\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.493957281112671\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] Epoch[183] Batch[5] avg_epoch_loss=2.485806\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.485805948575338\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] Epoch[183] Batch [5]#011Speed: 2649.03 samples/sec#011loss=2.485806\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] Epoch[183] Batch[10] avg_epoch_loss=2.481657\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=2.476678657531738\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] Epoch[183] Batch [10]#011Speed: 2578.09 samples/sec#011loss=2.476679\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747846430.8231099, \"EndTime\": 1747846431.6194108, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.0541248321533, \"count\": 1, \"min\": 796.0541248321533, \"max\": 796.0541248321533}}}\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1686.9166144335811 records/second\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] #progress_metric: host=algo-1, completed 46.0 % of epochs\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.4816571799191562\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] Epoch[184] Batch[0] avg_epoch_loss=2.553453\n",
      "[05/21/2025 16:53:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.553453207015991\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] Epoch[184] Batch[5] avg_epoch_loss=2.513327\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.5133273204167685\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] Epoch[184] Batch [5]#011Speed: 2764.85 samples/sec#011loss=2.513327\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] Epoch[184] Batch[10] avg_epoch_loss=2.433086\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=2.3367954015731813\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] Epoch[184] Batch [10]#011Speed: 2602.38 samples/sec#011loss=2.336795\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747846431.6194587, \"EndTime\": 1747846432.3996773, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 779.9768447875977, \"count\": 1, \"min\": 779.9768447875977, \"max\": 779.9768447875977}}}\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1712.675041375864 records/second\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] #progress_metric: host=algo-1, completed 46.25 % of epochs\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.4330855391242285\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_e8d8b953-44f0-4b87-adfd-6e8d32e8c9ae-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846432.3997364, \"EndTime\": 1747846432.4090784, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.073257446289062, \"count\": 1, \"min\": 9.073257446289062, \"max\": 9.073257446289062}}}\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] Epoch[185] Batch[0] avg_epoch_loss=2.476665\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.4766645431518555\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] Epoch[185] Batch[5] avg_epoch_loss=2.511774\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.511773943901062\n",
      "[05/21/2025 16:53:52 INFO 140202337613632] Epoch[185] Batch [5]#011Speed: 2784.55 samples/sec#011loss=2.511774\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] Epoch[185] Batch[10] avg_epoch_loss=2.550713\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=2.597440242767334\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] Epoch[185] Batch [10]#011Speed: 2587.57 samples/sec#011loss=2.597440\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747846432.409136, \"EndTime\": 1747846433.1899292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.7388305664062, \"count\": 1, \"min\": 780.7388305664062, \"max\": 780.7388305664062}}}\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1654.6593372435398 records/second\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] #progress_metric: host=algo-1, completed 46.5 % of epochs\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.5507131706584585\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] Epoch[186] Batch[0] avg_epoch_loss=2.697553\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.6975533962249756\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] Epoch[186] Batch[5] avg_epoch_loss=2.681951\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.6819514433542886\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] Epoch[186] Batch [5]#011Speed: 2745.49 samples/sec#011loss=2.681951\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] Epoch[186] Batch[10] avg_epoch_loss=2.694859\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=2.710348033905029\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] Epoch[186] Batch [10]#011Speed: 2466.00 samples/sec#011loss=2.710348\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747846433.1899872, \"EndTime\": 1747846433.9916034, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.3124465942383, \"count\": 1, \"min\": 801.3124465942383, \"max\": 801.3124465942383}}}\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1644.6137043291171 records/second\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] #progress_metric: host=algo-1, completed 46.75 % of epochs\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.6948589845137163\n",
      "[05/21/2025 16:53:53 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] Epoch[187] Batch[0] avg_epoch_loss=2.639569\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.639568567276001\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] Epoch[187] Batch[5] avg_epoch_loss=2.634279\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.634278893470764\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] Epoch[187] Batch [5]#011Speed: 2831.52 samples/sec#011loss=2.634279\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] Epoch[187] Batch[10] avg_epoch_loss=2.830469\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=3.0658971309661864\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] Epoch[187] Batch [10]#011Speed: 2702.25 samples/sec#011loss=3.065897\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747846433.991664, \"EndTime\": 1747846434.7620625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 770.1172828674316, \"count\": 1, \"min\": 770.1172828674316, \"max\": 770.1172828674316}}}\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1733.2961377376187 records/second\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] #progress_metric: host=algo-1, completed 47.0 % of epochs\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.830469001423229\n",
      "[05/21/2025 16:53:54 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] Epoch[188] Batch[0] avg_epoch_loss=2.639638\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.6396384239196777\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] Epoch[188] Batch[5] avg_epoch_loss=2.697124\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.697124481201172\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] Epoch[188] Batch [5]#011Speed: 2802.64 samples/sec#011loss=2.697124\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] Epoch[188] Batch[10] avg_epoch_loss=2.690997\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=2.6836435317993166\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] Epoch[188] Batch [10]#011Speed: 2372.10 samples/sec#011loss=2.683644\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747846434.762125, \"EndTime\": 1747846435.5599108, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.5361347198486, \"count\": 1, \"min\": 797.5361347198486, \"max\": 797.5361347198486}}}\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1718.8537321998638 records/second\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] #progress_metric: host=algo-1, completed 47.25 % of epochs\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.690996776927601\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] Epoch[189] Batch[0] avg_epoch_loss=2.733223\n",
      "[05/21/2025 16:53:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.7332234382629395\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] Epoch[189] Batch[5] avg_epoch_loss=2.639699\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.639699339866638\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] Epoch[189] Batch [5]#011Speed: 2723.62 samples/sec#011loss=2.639699\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] Epoch[189] Batch[10] avg_epoch_loss=2.582442\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=2.513732576370239\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] Epoch[189] Batch [10]#011Speed: 2616.53 samples/sec#011loss=2.513733\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747846435.55997, \"EndTime\": 1747846436.354506, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.2380905151367, \"count\": 1, \"min\": 794.2380905151367, \"max\": 794.2380905151367}}}\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1657.9032983998718 records/second\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] #progress_metric: host=algo-1, completed 47.5 % of epochs\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.582441720095548\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] Epoch[190] Batch[0] avg_epoch_loss=2.555284\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.555284023284912\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] Epoch[190] Batch[5] avg_epoch_loss=2.516777\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.5167768796284995\n",
      "[05/21/2025 16:53:56 INFO 140202337613632] Epoch[190] Batch [5]#011Speed: 2756.70 samples/sec#011loss=2.516777\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] Epoch[190] Batch[10] avg_epoch_loss=2.480122\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=2.4361361503601073\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] Epoch[190] Batch [10]#011Speed: 2467.64 samples/sec#011loss=2.436136\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747846436.354572, \"EndTime\": 1747846437.1563396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.4814853668213, \"count\": 1, \"min\": 801.4814853668213, \"max\": 801.4814853668213}}}\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1619.3154612583662 records/second\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] #progress_metric: host=algo-1, completed 47.75 % of epochs\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.4801220026883213\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] Epoch[191] Batch[0] avg_epoch_loss=2.615653\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.615652561187744\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] Epoch[191] Batch[5] avg_epoch_loss=2.508745\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.5087446769078574\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] Epoch[191] Batch [5]#011Speed: 2742.56 samples/sec#011loss=2.508745\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] Epoch[191] Batch[10] avg_epoch_loss=2.556472\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=2.613744354248047\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] Epoch[191] Batch [10]#011Speed: 2540.12 samples/sec#011loss=2.613744\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747846437.1564019, \"EndTime\": 1747846437.9434822, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.8247032165527, \"count\": 1, \"min\": 786.8247032165527, \"max\": 786.8247032165527}}}\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1739.7223038253273 records/second\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] #progress_metric: host=algo-1, completed 48.0 % of epochs\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.5564718029715796\n",
      "[05/21/2025 16:53:57 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] Epoch[192] Batch[0] avg_epoch_loss=2.416879\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.416879177093506\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] Epoch[192] Batch[5] avg_epoch_loss=2.476392\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.4763921896616616\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] Epoch[192] Batch [5]#011Speed: 2760.52 samples/sec#011loss=2.476392\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] Epoch[192] Batch[10] avg_epoch_loss=2.496340\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=2.5202770709991453\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] Epoch[192] Batch [10]#011Speed: 2357.92 samples/sec#011loss=2.520277\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747846437.943536, \"EndTime\": 1747846438.760921, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.1308040618896, \"count\": 1, \"min\": 817.1308040618896, \"max\": 817.1308040618896}}}\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1637.2633302388979 records/second\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] #progress_metric: host=algo-1, completed 48.25 % of epochs\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.496339862996882\n",
      "[05/21/2025 16:53:58 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] Epoch[193] Batch[0] avg_epoch_loss=2.528512\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.5285115242004395\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] Epoch[193] Batch[5] avg_epoch_loss=2.502533\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.5025329987208047\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] Epoch[193] Batch [5]#011Speed: 2526.86 samples/sec#011loss=2.502533\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] Epoch[193] Batch[10] avg_epoch_loss=2.490199\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=2.475399112701416\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] Epoch[193] Batch [10]#011Speed: 2434.00 samples/sec#011loss=2.475399\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747846438.7609801, \"EndTime\": 1747846439.581084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 819.8537826538086, \"count\": 1, \"min\": 819.8537826538086, \"max\": 819.8537826538086}}}\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1654.9903021026455 records/second\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] #progress_metric: host=algo-1, completed 48.5 % of epochs\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.490199414166537\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] Epoch[194] Batch[0] avg_epoch_loss=2.443514\n",
      "[05/21/2025 16:53:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.443514108657837\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] Epoch[194] Batch[5] avg_epoch_loss=2.488544\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.4885441064834595\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] Epoch[194] Batch [5]#011Speed: 2722.52 samples/sec#011loss=2.488544\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] Epoch[194] Batch[10] avg_epoch_loss=2.463242\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=2.4328797340393065\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] Epoch[194] Batch [10]#011Speed: 2485.89 samples/sec#011loss=2.432880\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] processed a total of 1382 examples\n",
      "#metrics {\"StartTime\": 1747846439.581145, \"EndTime\": 1747846440.3760247, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.2245006561279, \"count\": 1, \"min\": 794.2245006561279, \"max\": 794.2245006561279}}}\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1739.8657784034374 records/second\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] #progress_metric: host=algo-1, completed 48.75 % of epochs\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.4632421190088447\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] Epoch[195] Batch[0] avg_epoch_loss=2.502414\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.5024144649505615\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] Epoch[195] Batch[5] avg_epoch_loss=2.425483\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.4254833459854126\n",
      "[05/21/2025 16:54:00 INFO 140202337613632] Epoch[195] Batch [5]#011Speed: 2748.15 samples/sec#011loss=2.425483\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747846440.3760846, \"EndTime\": 1747846441.1236506, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 746.7889785766602, \"count\": 1, \"min\": 746.7889785766602, \"max\": 746.7889785766602}}}\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1711.9744747528741 records/second\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] #progress_metric: host=algo-1, completed 49.0 % of epochs\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.454801607131958\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] Epoch[196] Batch[0] avg_epoch_loss=2.471330\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.471330404281616\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] Epoch[196] Batch[5] avg_epoch_loss=2.454010\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.4540099700291953\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] Epoch[196] Batch [5]#011Speed: 2580.22 samples/sec#011loss=2.454010\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] Epoch[196] Batch[10] avg_epoch_loss=2.474898\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.499963331222534\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] Epoch[196] Batch [10]#011Speed: 2209.69 samples/sec#011loss=2.499963\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] processed a total of 1384 examples\n",
      "#metrics {\"StartTime\": 1747846441.1239107, \"EndTime\": 1747846441.9740186, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 849.64919090271, \"count\": 1, \"min\": 849.64919090271, \"max\": 849.64919090271}}}\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1628.7316126049082 records/second\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] #progress_metric: host=algo-1, completed 49.25 % of epochs\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.474897861480713\n",
      "[05/21/2025 16:54:01 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] Epoch[197] Batch[0] avg_epoch_loss=2.440122\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.44012188911438\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] Epoch[197] Batch[5] avg_epoch_loss=2.408161\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.4081613222757974\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] Epoch[197] Batch [5]#011Speed: 2726.13 samples/sec#011loss=2.408161\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] Epoch[197] Batch[10] avg_epoch_loss=2.455444\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=2.5121827602386473\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] Epoch[197] Batch [10]#011Speed: 2528.85 samples/sec#011loss=2.512183\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747846441.9740787, \"EndTime\": 1747846442.7730224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.661470413208, \"count\": 1, \"min\": 798.661470413208, \"max\": 798.661470413208}}}\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1628.765005244366 records/second\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] #progress_metric: host=algo-1, completed 49.5 % of epochs\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.455443794077093\n",
      "[05/21/2025 16:54:02 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] Epoch[198] Batch[0] avg_epoch_loss=2.452350\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.4523496627807617\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] Epoch[198] Batch[5] avg_epoch_loss=2.477163\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.4771634340286255\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] Epoch[198] Batch [5]#011Speed: 2535.12 samples/sec#011loss=2.477163\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] Epoch[198] Batch[10] avg_epoch_loss=2.469586\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.460492467880249\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] Epoch[198] Batch [10]#011Speed: 2571.99 samples/sec#011loss=2.460492\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747846442.7730932, \"EndTime\": 1747846443.5866807, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.2688999176025, \"count\": 1, \"min\": 813.2688999176025, \"max\": 813.2688999176025}}}\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1587.2635603492372 records/second\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] #progress_metric: host=algo-1, completed 49.75 % of epochs\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.469585722143\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] Epoch[199] Batch[0] avg_epoch_loss=2.489457\n",
      "[05/21/2025 16:54:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.489457368850708\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] Epoch[199] Batch[5] avg_epoch_loss=2.475217\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.47521710395813\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] Epoch[199] Batch [5]#011Speed: 2646.96 samples/sec#011loss=2.475217\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] Epoch[199] Batch[10] avg_epoch_loss=2.722930\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=3.0201847553253174\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] Epoch[199] Batch [10]#011Speed: 2524.20 samples/sec#011loss=3.020185\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747846443.5867343, \"EndTime\": 1747846444.3889484, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.9487857818604, \"count\": 1, \"min\": 801.9487857818604, \"max\": 801.9487857818604}}}\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1627.1060101563946 records/second\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] #progress_metric: host=algo-1, completed 50.0 % of epochs\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.722929672761397\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] Epoch[200] Batch[0] avg_epoch_loss=2.580791\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.5807905197143555\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] Epoch[200] Batch[5] avg_epoch_loss=2.584310\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.584310213724772\n",
      "[05/21/2025 16:54:04 INFO 140202337613632] Epoch[200] Batch [5]#011Speed: 2705.15 samples/sec#011loss=2.584310\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] Epoch[200] Batch[10] avg_epoch_loss=2.635431\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=2.696775770187378\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] Epoch[200] Batch [10]#011Speed: 2467.02 samples/sec#011loss=2.696776\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747846444.3890092, \"EndTime\": 1747846445.1859968, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.7393398284912, \"count\": 1, \"min\": 796.7393398284912, \"max\": 796.7393398284912}}}\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1695.4694377413307 records/second\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] #progress_metric: host=algo-1, completed 50.25 % of epochs\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.635430921207775\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] Epoch[201] Batch[0] avg_epoch_loss=2.418854\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.4188544750213623\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] Epoch[201] Batch[5] avg_epoch_loss=2.556893\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.556893229484558\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] Epoch[201] Batch [5]#011Speed: 2579.10 samples/sec#011loss=2.556893\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] Epoch[201] Batch[10] avg_epoch_loss=2.520749\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=2.477375793457031\n",
      "[05/21/2025 16:54:05 INFO 140202337613632] Epoch[201] Batch [10]#011Speed: 2473.77 samples/sec#011loss=2.477376\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747846445.186059, \"EndTime\": 1747846446.0002038, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.8926029205322, \"count\": 1, \"min\": 813.8926029205322, \"max\": 813.8926029205322}}}\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1632.7180429281095 records/second\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] #progress_metric: host=algo-1, completed 50.5 % of epochs\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.5207489403811367\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] Epoch[202] Batch[0] avg_epoch_loss=2.380136\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.380136489868164\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] Epoch[202] Batch[5] avg_epoch_loss=2.450680\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.450679580370585\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] Epoch[202] Batch [5]#011Speed: 2649.51 samples/sec#011loss=2.450680\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] processed a total of 1263 examples\n",
      "#metrics {\"StartTime\": 1747846446.0002642, \"EndTime\": 1747846446.7521596, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 751.5695095062256, \"count\": 1, \"min\": 751.5695095062256, \"max\": 751.5695095062256}}}\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1680.2674113367648 records/second\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] #progress_metric: host=algo-1, completed 50.75 % of epochs\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.4436107635498048\n",
      "[05/21/2025 16:54:06 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] Epoch[203] Batch[0] avg_epoch_loss=2.461155\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.461155414581299\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] Epoch[203] Batch[5] avg_epoch_loss=2.454649\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.4546488523483276\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] Epoch[203] Batch [5]#011Speed: 2739.59 samples/sec#011loss=2.454649\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] Epoch[203] Batch[10] avg_epoch_loss=2.381894\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=2.2945891618728638\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] Epoch[203] Batch [10]#011Speed: 2518.35 samples/sec#011loss=2.294589\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747846446.7522237, \"EndTime\": 1747846447.548327, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.8118915557861, \"count\": 1, \"min\": 795.8118915557861, \"max\": 795.8118915557861}}}\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1622.0613986370104 records/second\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] #progress_metric: host=algo-1, completed 51.0 % of epochs\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.381894447586753\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_8e09724e-3745-4adc-9383-2f69f0e8d54a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846447.548387, \"EndTime\": 1747846447.5579174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.25588607788086, \"count\": 1, \"min\": 9.25588607788086, \"max\": 9.25588607788086}}}\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] Epoch[204] Batch[0] avg_epoch_loss=2.404747\n",
      "[05/21/2025 16:54:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.404747247695923\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] Epoch[204] Batch[5] avg_epoch_loss=2.435731\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.435730536778768\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] Epoch[204] Batch [5]#011Speed: 2415.22 samples/sec#011loss=2.435731\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] Epoch[204] Batch[10] avg_epoch_loss=2.444673\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=2.455403184890747\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] Epoch[204] Batch [10]#011Speed: 1692.86 samples/sec#011loss=2.455403\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] processed a total of 1383 examples\n",
      "#metrics {\"StartTime\": 1747846447.5579774, \"EndTime\": 1747846448.4989183, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.8869743347168, \"count\": 1, \"min\": 940.8869743347168, \"max\": 940.8869743347168}}}\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1469.7469821364368 records/second\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] #progress_metric: host=algo-1, completed 51.25 % of epochs\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.4446726495569404\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] Epoch[205] Batch[0] avg_epoch_loss=2.431407\n",
      "[05/21/2025 16:54:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.4314067363739014\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] Epoch[205] Batch[5] avg_epoch_loss=2.402745\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.4027454455693564\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] Epoch[205] Batch [5]#011Speed: 2585.72 samples/sec#011loss=2.402745\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] Epoch[205] Batch[10] avg_epoch_loss=2.437977\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=2.4802538394927978\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] Epoch[205] Batch [10]#011Speed: 2402.71 samples/sec#011loss=2.480254\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747846448.4989822, \"EndTime\": 1747846449.3225045, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 823.2581615447998, \"count\": 1, \"min\": 823.2581615447998, \"max\": 823.2581615447998}}}\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1588.63696060282 records/second\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] #progress_metric: host=algo-1, completed 51.5 % of epochs\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.437976533716375\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] Epoch[206] Batch[0] avg_epoch_loss=2.345659\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.345658540725708\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] Epoch[206] Batch[5] avg_epoch_loss=2.392776\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.392776052157084\n",
      "[05/21/2025 16:54:09 INFO 140202337613632] Epoch[206] Batch [5]#011Speed: 2652.81 samples/sec#011loss=2.392776\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] processed a total of 1259 examples\n",
      "#metrics {\"StartTime\": 1747846449.3225665, \"EndTime\": 1747846450.07667, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 753.8304328918457, \"count\": 1, \"min\": 753.8304328918457, \"max\": 753.8304328918457}}}\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1669.9319444611347 records/second\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] #progress_metric: host=algo-1, completed 51.75 % of epochs\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.4142293453216555\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] Epoch[207] Batch[0] avg_epoch_loss=2.431411\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.431410789489746\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] Epoch[207] Batch[5] avg_epoch_loss=2.426686\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.426686445871989\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] Epoch[207] Batch [5]#011Speed: 2596.32 samples/sec#011loss=2.426686\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] Epoch[207] Batch[10] avg_epoch_loss=2.418523\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=2.4087267875671388\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] Epoch[207] Batch [10]#011Speed: 2546.06 samples/sec#011loss=2.408727\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747846450.0767312, \"EndTime\": 1747846450.882904, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 805.9036731719971, \"count\": 1, \"min\": 805.9036731719971, \"max\": 805.9036731719971}}}\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1658.8280816548688 records/second\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] #progress_metric: host=algo-1, completed 52.0 % of epochs\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.4185229648243296\n",
      "[05/21/2025 16:54:10 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] Epoch[208] Batch[0] avg_epoch_loss=2.369722\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.3697221279144287\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] Epoch[208] Batch[5] avg_epoch_loss=2.385420\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.3854202032089233\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] Epoch[208] Batch [5]#011Speed: 2680.19 samples/sec#011loss=2.385420\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] Epoch[208] Batch[10] avg_epoch_loss=2.462047\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.5540000915527346\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] Epoch[208] Batch [10]#011Speed: 2544.89 samples/sec#011loss=2.554000\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747846450.882964, \"EndTime\": 1747846451.6792443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.0302829742432, \"count\": 1, \"min\": 796.0302829742432, \"max\": 796.0302829742432}}}\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1690.7056162062413 records/second\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] #progress_metric: host=algo-1, completed 52.25 % of epochs\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.462047425183383\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] Epoch[209] Batch[0] avg_epoch_loss=2.448410\n",
      "[05/21/2025 16:54:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.4484100341796875\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] Epoch[209] Batch[5] avg_epoch_loss=2.371813\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.3718129793802896\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] Epoch[209] Batch [5]#011Speed: 2713.36 samples/sec#011loss=2.371813\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] Epoch[209] Batch[10] avg_epoch_loss=2.349437\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=2.322586917877197\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] Epoch[209] Batch [10]#011Speed: 2615.52 samples/sec#011loss=2.322587\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747846451.6793022, \"EndTime\": 1747846452.4662235, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.6685390472412, \"count\": 1, \"min\": 786.6685390472412, \"max\": 786.6685390472412}}}\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1648.5310342842165 records/second\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] #progress_metric: host=algo-1, completed 52.5 % of epochs\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.3494374968788843\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_15871419-3a1d-4dbf-9324-3804b935c0a0-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846452.4662857, \"EndTime\": 1747846452.4756327, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.07444953918457, \"count\": 1, \"min\": 9.07444953918457, \"max\": 9.07444953918457}}}\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] Epoch[210] Batch[0] avg_epoch_loss=2.424793\n",
      "[05/21/2025 16:54:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.424793004989624\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] Epoch[210] Batch[5] avg_epoch_loss=2.432293\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.43229341506958\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] Epoch[210] Batch [5]#011Speed: 2556.87 samples/sec#011loss=2.432293\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] Epoch[210] Batch[10] avg_epoch_loss=2.405424\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=2.3731812953948976\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] Epoch[210] Batch [10]#011Speed: 2431.53 samples/sec#011loss=2.373181\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] processed a total of 1407 examples\n",
      "#metrics {\"StartTime\": 1747846452.475692, \"EndTime\": 1747846453.2858078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.0602626800537, \"count\": 1, \"min\": 810.0602626800537, \"max\": 810.0602626800537}}}\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1736.7232866391996 records/second\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] #progress_metric: host=algo-1, completed 52.75 % of epochs\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.4054242697629062\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] Epoch[211] Batch[0] avg_epoch_loss=2.382830\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.3828299045562744\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] Epoch[211] Batch[5] avg_epoch_loss=2.388817\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.388816793759664\n",
      "[05/21/2025 16:54:13 INFO 140202337613632] Epoch[211] Batch [5]#011Speed: 2700.87 samples/sec#011loss=2.388817\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] Epoch[211] Batch[10] avg_epoch_loss=2.352634\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=2.30921528339386\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] Epoch[211] Batch [10]#011Speed: 2630.05 samples/sec#011loss=2.309215\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747846453.2858663, \"EndTime\": 1747846454.082023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.9117889404297, \"count\": 1, \"min\": 795.9117889404297, \"max\": 795.9117889404297}}}\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1648.22836248447 records/second\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] #progress_metric: host=algo-1, completed 53.0 % of epochs\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.3526342890479346\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] Epoch[212] Batch[0] avg_epoch_loss=2.290798\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.290797710418701\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] Epoch[212] Batch[5] avg_epoch_loss=2.385372\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.3853721221288047\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] Epoch[212] Batch [5]#011Speed: 2806.08 samples/sec#011loss=2.385372\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] Epoch[212] Batch[10] avg_epoch_loss=2.445899\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.518532133102417\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] Epoch[212] Batch [10]#011Speed: 2698.42 samples/sec#011loss=2.518532\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747846454.0820873, \"EndTime\": 1747846454.8567362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 774.3315696716309, \"count\": 1, \"min\": 774.3315696716309, \"max\": 774.3315696716309}}}\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1659.2991185490155 records/second\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] #progress_metric: host=algo-1, completed 53.25 % of epochs\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.445899399844083\n",
      "[05/21/2025 16:54:14 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] Epoch[213] Batch[0] avg_epoch_loss=2.470495\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.4704947471618652\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] Epoch[213] Batch[5] avg_epoch_loss=2.409513\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.409512678782145\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] Epoch[213] Batch [5]#011Speed: 2648.46 samples/sec#011loss=2.409513\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] Epoch[213] Batch[10] avg_epoch_loss=2.410031\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=2.410652828216553\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] Epoch[213] Batch [10]#011Speed: 2564.70 samples/sec#011loss=2.410653\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747846454.8567986, \"EndTime\": 1747846455.6525583, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.5155372619629, \"count\": 1, \"min\": 795.5155372619629, \"max\": 795.5155372619629}}}\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1670.4315301168715 records/second\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] #progress_metric: host=algo-1, completed 53.5 % of epochs\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.4100309285250576\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] Epoch[214] Batch[0] avg_epoch_loss=2.357300\n",
      "[05/21/2025 16:54:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.357300281524658\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] Epoch[214] Batch[5] avg_epoch_loss=2.359839\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.3598390022913613\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] Epoch[214] Batch [5]#011Speed: 2667.84 samples/sec#011loss=2.359839\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] Epoch[214] Batch[10] avg_epoch_loss=2.359664\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=2.3594533443450927\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] Epoch[214] Batch [10]#011Speed: 2660.90 samples/sec#011loss=2.359453\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747846455.652618, \"EndTime\": 1747846456.4404752, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 787.6005172729492, \"count\": 1, \"min\": 787.6005172729492, \"max\": 787.6005172729492}}}\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1638.9707952245424 records/second\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] #progress_metric: host=algo-1, completed 53.75 % of epochs\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.3596637032248755\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] Epoch[215] Batch[0] avg_epoch_loss=2.467808\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.4678075313568115\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] Epoch[215] Batch[5] avg_epoch_loss=2.506413\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.5064130624135337\n",
      "[05/21/2025 16:54:16 INFO 140202337613632] Epoch[215] Batch [5]#011Speed: 2719.63 samples/sec#011loss=2.506413\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] processed a total of 1247 examples\n",
      "#metrics {\"StartTime\": 1747846456.4405353, \"EndTime\": 1747846457.1861594, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 745.3351020812988, \"count\": 1, \"min\": 745.3351020812988, \"max\": 745.3351020812988}}}\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1672.852485819942 records/second\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] #progress_metric: host=algo-1, completed 54.0 % of epochs\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.489737319946289\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] Epoch[216] Batch[0] avg_epoch_loss=2.285481\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.2854807376861572\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] Epoch[216] Batch[5] avg_epoch_loss=2.384244\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.3842438459396362\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] Epoch[216] Batch [5]#011Speed: 2724.87 samples/sec#011loss=2.384244\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] Epoch[216] Batch[10] avg_epoch_loss=2.390069\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=2.397059965133667\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] Epoch[216] Batch [10]#011Speed: 2427.78 samples/sec#011loss=2.397060\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747846457.1862254, \"EndTime\": 1747846457.9884264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.8589019775391, \"count\": 1, \"min\": 801.8589019775391, \"max\": 801.8589019775391}}}\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1678.4194034904854 records/second\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] #progress_metric: host=algo-1, completed 54.25 % of epochs\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.390069354664196\n",
      "[05/21/2025 16:54:17 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] Epoch[217] Batch[0] avg_epoch_loss=2.322912\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.3229122161865234\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] Epoch[217] Batch[5] avg_epoch_loss=2.400771\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.4007707039515176\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] Epoch[217] Batch [5]#011Speed: 2657.72 samples/sec#011loss=2.400771\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] Epoch[217] Batch[10] avg_epoch_loss=2.428033\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=2.4607473850250243\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] Epoch[217] Batch [10]#011Speed: 2678.86 samples/sec#011loss=2.460747\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747846457.9884837, \"EndTime\": 1747846458.7752323, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.4725589752197, \"count\": 1, \"min\": 786.4725589752197, \"max\": 786.4725589752197}}}\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1660.3965192593787 records/second\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] #progress_metric: host=algo-1, completed 54.5 % of epochs\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.4280328317122026\n",
      "[05/21/2025 16:54:18 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] Epoch[218] Batch[0] avg_epoch_loss=2.341881\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=2.3418807983398438\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] Epoch[218] Batch[5] avg_epoch_loss=2.384221\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.384221156438192\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] Epoch[218] Batch [5]#011Speed: 2670.03 samples/sec#011loss=2.384221\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] Epoch[218] Batch[10] avg_epoch_loss=2.368405\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=2.3494245529174806\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] Epoch[218] Batch [10]#011Speed: 2513.97 samples/sec#011loss=2.349425\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747846458.775291, \"EndTime\": 1747846459.5748205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.2732524871826, \"count\": 1, \"min\": 799.2732524871826, \"max\": 799.2732524871826}}}\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1683.8404711086826 records/second\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] #progress_metric: host=algo-1, completed 54.75 % of epochs\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.368404518474232\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] Epoch[219] Batch[0] avg_epoch_loss=2.409262\n",
      "[05/21/2025 16:54:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.40926194190979\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] Epoch[219] Batch[5] avg_epoch_loss=2.399013\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.399012883504232\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] Epoch[219] Batch [5]#011Speed: 2562.84 samples/sec#011loss=2.399013\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] Epoch[219] Batch[10] avg_epoch_loss=2.405931\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=2.414232873916626\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] Epoch[219] Batch [10]#011Speed: 2516.60 samples/sec#011loss=2.414233\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747846459.5748806, \"EndTime\": 1747846460.383731, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 808.598518371582, \"count\": 1, \"min\": 808.598518371582, \"max\": 808.598518371582}}}\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1648.3495687644795 records/second\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] #progress_metric: host=algo-1, completed 55.0 % of epochs\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.405931060964411\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] Epoch[220] Batch[0] avg_epoch_loss=2.318887\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.3188867568969727\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] Epoch[220] Batch[5] avg_epoch_loss=2.355796\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.3557960589726767\n",
      "[05/21/2025 16:54:20 INFO 140202337613632] Epoch[220] Batch [5]#011Speed: 2557.16 samples/sec#011loss=2.355796\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] Epoch[220] Batch[10] avg_epoch_loss=2.454626\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=2.573221778869629\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] Epoch[220] Batch [10]#011Speed: 2597.22 samples/sec#011loss=2.573222\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747846460.3837895, \"EndTime\": 1747846461.1899786, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 805.9329986572266, \"count\": 1, \"min\": 805.9329986572266, \"max\": 805.9329986572266}}}\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1593.0130091709034 records/second\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] #progress_metric: host=algo-1, completed 55.25 % of epochs\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.4546259316531094\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] Epoch[221] Batch[0] avg_epoch_loss=2.398679\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.3986785411834717\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] Epoch[221] Batch[5] avg_epoch_loss=2.378293\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.3782928784688315\n",
      "[05/21/2025 16:54:21 INFO 140202337613632] Epoch[221] Batch [5]#011Speed: 2707.91 samples/sec#011loss=2.378293\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] Epoch[221] Batch[10] avg_epoch_loss=2.379960\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=2.3819595336914063\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] Epoch[221] Batch [10]#011Speed: 2353.49 samples/sec#011loss=2.381960\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747846461.1900375, \"EndTime\": 1747846462.0086787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 818.3574676513672, \"count\": 1, \"min\": 818.3574676513672, \"max\": 818.3574676513672}}}\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1623.8087072638991 records/second\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] #progress_metric: host=algo-1, completed 55.5 % of epochs\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.379959539933638\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] Epoch[222] Batch[0] avg_epoch_loss=2.371226\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=2.3712260723114014\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] Epoch[222] Batch[5] avg_epoch_loss=2.360753\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.360752542813619\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] Epoch[222] Batch [5]#011Speed: 2679.97 samples/sec#011loss=2.360753\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] Epoch[222] Batch[10] avg_epoch_loss=2.318908\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=2.2686944961547852\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] Epoch[222] Batch [10]#011Speed: 2250.97 samples/sec#011loss=2.268694\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] processed a total of 1376 examples\n",
      "#metrics {\"StartTime\": 1747846462.0087383, \"EndTime\": 1747846462.836932, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 827.9469013214111, \"count\": 1, \"min\": 827.9469013214111, \"max\": 827.9469013214111}}}\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1661.7647934139393 records/second\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] #progress_metric: host=algo-1, completed 55.75 % of epochs\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.3189079761505127\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:54:22 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_cbd27cfe-3e82-47e6-b763-052218464cbb-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846462.836992, \"EndTime\": 1747846462.8465602, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.300708770751953, \"count\": 1, \"min\": 9.300708770751953, \"max\": 9.300708770751953}}}\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] Epoch[223] Batch[0] avg_epoch_loss=2.460044\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.4600436687469482\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] Epoch[223] Batch[5] avg_epoch_loss=2.374304\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.374303658803304\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] Epoch[223] Batch [5]#011Speed: 2756.57 samples/sec#011loss=2.374304\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747846462.8466244, \"EndTime\": 1747846463.5824392, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 735.7594966888428, \"count\": 1, \"min\": 735.7594966888428, \"max\": 735.7594966888428}}}\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1733.9808533938117 records/second\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] #progress_metric: host=algo-1, completed 56.0 % of epochs\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.35422887802124\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] Epoch[224] Batch[0] avg_epoch_loss=2.309474\n",
      "[05/21/2025 16:54:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.309474468231201\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] Epoch[224] Batch[5] avg_epoch_loss=2.358616\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.3586162328720093\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] Epoch[224] Batch [5]#011Speed: 2681.43 samples/sec#011loss=2.358616\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] Epoch[224] Batch[10] avg_epoch_loss=2.410999\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=2.4738576412200928\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] Epoch[224] Batch [10]#011Speed: 2499.91 samples/sec#011loss=2.473858\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747846463.5825286, \"EndTime\": 1747846464.382858, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.0171184539795, \"count\": 1, \"min\": 800.0171184539795, \"max\": 800.0171184539795}}}\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1601.034902771065 records/second\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] #progress_metric: host=algo-1, completed 56.25 % of epochs\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.4109986912120474\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] Epoch[225] Batch[0] avg_epoch_loss=2.616182\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.6161816120147705\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] Epoch[225] Batch[5] avg_epoch_loss=2.534744\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.5347444216410318\n",
      "[05/21/2025 16:54:24 INFO 140202337613632] Epoch[225] Batch [5]#011Speed: 2594.03 samples/sec#011loss=2.534744\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] Epoch[225] Batch[10] avg_epoch_loss=2.502707\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=2.4642623901367187\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] Epoch[225] Batch [10]#011Speed: 2537.40 samples/sec#011loss=2.464262\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747846464.382919, \"EndTime\": 1747846465.1901355, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 806.9653511047363, \"count\": 1, \"min\": 806.9653511047363, \"max\": 806.9653511047363}}}\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1641.782788889017 records/second\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] #progress_metric: host=algo-1, completed 56.5 % of epochs\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.5027071345936167\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] Epoch[226] Batch[0] avg_epoch_loss=2.488562\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=2.4885616302490234\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] Epoch[226] Batch[5] avg_epoch_loss=2.435336\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.4353355964024863\n",
      "[05/21/2025 16:54:25 INFO 140202337613632] Epoch[226] Batch [5]#011Speed: 2517.99 samples/sec#011loss=2.435336\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] Epoch[226] Batch[10] avg_epoch_loss=2.430402\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=2.4244811058044435\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] Epoch[226] Batch [10]#011Speed: 2496.09 samples/sec#011loss=2.424481\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747846465.1901922, \"EndTime\": 1747846466.0056636, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 815.2222633361816, \"count\": 1, \"min\": 815.2222633361816, \"max\": 815.2222633361816}}}\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1623.9022417171097 records/second\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] #progress_metric: host=algo-1, completed 56.75 % of epochs\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.4304017370397393\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] Epoch[227] Batch[0] avg_epoch_loss=2.383274\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.3832743167877197\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] Epoch[227] Batch[5] avg_epoch_loss=2.390861\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.3908609549204507\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] Epoch[227] Batch [5]#011Speed: 2645.71 samples/sec#011loss=2.390861\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] Epoch[227] Batch[10] avg_epoch_loss=2.478425\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=2.58350248336792\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] Epoch[227] Batch [10]#011Speed: 2455.10 samples/sec#011loss=2.583502\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747846466.0057306, \"EndTime\": 1747846466.8117318, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 805.6795597076416, \"count\": 1, \"min\": 805.6795597076416, \"max\": 805.6795597076416}}}\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1700.2346930110198 records/second\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] #progress_metric: host=algo-1, completed 57.0 % of epochs\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.478425286032937\n",
      "[05/21/2025 16:54:26 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] Epoch[228] Batch[0] avg_epoch_loss=2.361360\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.3613598346710205\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] Epoch[228] Batch[5] avg_epoch_loss=2.400783\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.400783061981201\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] Epoch[228] Batch [5]#011Speed: 2612.77 samples/sec#011loss=2.400783\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] Epoch[228] Batch[10] avg_epoch_loss=2.387760\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=2.372132110595703\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] Epoch[228] Batch [10]#011Speed: 2519.53 samples/sec#011loss=2.372132\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747846466.8117921, \"EndTime\": 1747846467.6450734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 833.0051898956299, \"count\": 1, \"min\": 833.0051898956299, \"max\": 833.0051898956299}}}\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1625.260960969727 records/second\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] #progress_metric: host=algo-1, completed 57.25 % of epochs\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.38775990226052\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] Epoch[229] Batch[0] avg_epoch_loss=2.361338\n",
      "[05/21/2025 16:54:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.3613383769989014\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] Epoch[229] Batch[5] avg_epoch_loss=2.327511\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.327510873476664\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] Epoch[229] Batch [5]#011Speed: 2580.94 samples/sec#011loss=2.327511\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] Epoch[229] Batch[10] avg_epoch_loss=2.305453\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=229, batch=10 train loss <loss>=2.2789825916290285\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] Epoch[229] Batch [10]#011Speed: 2578.19 samples/sec#011loss=2.278983\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747846467.6451354, \"EndTime\": 1747846468.4557316, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.2667331695557, \"count\": 1, \"min\": 810.2667331695557, \"max\": 810.2667331695557}}}\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1604.2324517981065 records/second\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] #progress_metric: host=algo-1, completed 57.5 % of epochs\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.3054525635459204\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_7d4d019a-5702-431c-bbcc-c31f522b164a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846468.455791, \"EndTime\": 1747846468.4648042, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.69607925415039, \"count\": 1, \"min\": 8.69607925415039, \"max\": 8.69607925415039}}}\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] Epoch[230] Batch[0] avg_epoch_loss=2.408468\n",
      "[05/21/2025 16:54:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.4084675312042236\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] Epoch[230] Batch[5] avg_epoch_loss=2.364371\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.364371101061503\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] Epoch[230] Batch [5]#011Speed: 2616.91 samples/sec#011loss=2.364371\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] Epoch[230] Batch[10] avg_epoch_loss=2.353740\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=2.3409823894500734\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] Epoch[230] Batch [10]#011Speed: 2599.04 samples/sec#011loss=2.340982\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747846468.4648566, \"EndTime\": 1747846469.2667646, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.8543720245361, \"count\": 1, \"min\": 801.8543720245361, \"max\": 801.8543720245361}}}\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1665.9318897966696 records/second\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] #progress_metric: host=algo-1, completed 57.75 % of epochs\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.353739868510853\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] Epoch[231] Batch[0] avg_epoch_loss=2.292809\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.2928085327148438\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] Epoch[231] Batch[5] avg_epoch_loss=2.316654\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.316654086112976\n",
      "[05/21/2025 16:54:29 INFO 140202337613632] Epoch[231] Batch [5]#011Speed: 2689.08 samples/sec#011loss=2.316654\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] Epoch[231] Batch[10] avg_epoch_loss=2.349900\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=2.3897953033447266\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] Epoch[231] Batch [10]#011Speed: 2274.17 samples/sec#011loss=2.389795\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747846469.2668338, \"EndTime\": 1747846470.08941, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 822.2298622131348, \"count\": 1, \"min\": 822.2298622131348, \"max\": 822.2298622131348}}}\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1659.9396936437101 records/second\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] #progress_metric: host=algo-1, completed 58.0 % of epochs\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.34990009394559\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] Epoch[232] Batch[0] avg_epoch_loss=2.375190\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.375190496444702\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] Epoch[232] Batch[5] avg_epoch_loss=2.382201\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.382200558980306\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] Epoch[232] Batch [5]#011Speed: 2745.15 samples/sec#011loss=2.382201\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] Epoch[232] Batch[10] avg_epoch_loss=2.364040\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=2.3422483444213866\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] Epoch[232] Batch [10]#011Speed: 2609.69 samples/sec#011loss=2.342248\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747846470.08947, \"EndTime\": 1747846470.871628, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 781.9080352783203, \"count\": 1, \"min\": 781.9080352783203, \"max\": 781.9080352783203}}}\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1705.8915732296562 records/second\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] #progress_metric: host=algo-1, completed 58.25 % of epochs\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.3640404614535244\n",
      "[05/21/2025 16:54:30 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] Epoch[233] Batch[0] avg_epoch_loss=2.815491\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.815491199493408\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] Epoch[233] Batch[5] avg_epoch_loss=2.751681\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.7516814470291138\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] Epoch[233] Batch [5]#011Speed: 2579.17 samples/sec#011loss=2.751681\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] Epoch[233] Batch[10] avg_epoch_loss=2.696145\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=2.6295007705688476\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] Epoch[233] Batch [10]#011Speed: 2556.65 samples/sec#011loss=2.629501\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747846470.8716867, \"EndTime\": 1747846471.681648, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.7107410430908, \"count\": 1, \"min\": 809.7107410430908, \"max\": 809.7107410430908}}}\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1626.3501745914912 records/second\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] #progress_metric: host=algo-1, completed 58.5 % of epochs\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.696144775910811\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] Epoch[234] Batch[0] avg_epoch_loss=2.775378\n",
      "[05/21/2025 16:54:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.7753777503967285\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] Epoch[234] Batch[5] avg_epoch_loss=2.643828\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.643828272819519\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] Epoch[234] Batch [5]#011Speed: 2667.25 samples/sec#011loss=2.643828\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] Epoch[234] Batch[10] avg_epoch_loss=2.649477\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=2.656255340576172\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] Epoch[234] Batch [10]#011Speed: 2588.13 samples/sec#011loss=2.656255\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747846471.6817, \"EndTime\": 1747846472.4779112, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.9568500518799, \"count\": 1, \"min\": 795.9568500518799, \"max\": 795.9568500518799}}}\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1626.791835287296 records/second\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] #progress_metric: host=algo-1, completed 58.75 % of epochs\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.649476939981634\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] Epoch[235] Batch[0] avg_epoch_loss=2.546191\n",
      "[05/21/2025 16:54:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.5461912155151367\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] Epoch[235] Batch[5] avg_epoch_loss=2.462472\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.462472399075826\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] Epoch[235] Batch [5]#011Speed: 2576.10 samples/sec#011loss=2.462472\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] Epoch[235] Batch[10] avg_epoch_loss=2.484503\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=2.5109396457672117\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] Epoch[235] Batch [10]#011Speed: 2549.60 samples/sec#011loss=2.510940\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747846472.4779701, \"EndTime\": 1747846473.2823653, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 804.142951965332, \"count\": 1, \"min\": 804.142951965332, \"max\": 804.142951965332}}}\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1646.292337433605 records/second\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] #progress_metric: host=algo-1, completed 59.0 % of epochs\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.4845029657537285\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] Epoch[236] Batch[0] avg_epoch_loss=2.419026\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.4190263748168945\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] Epoch[236] Batch[5] avg_epoch_loss=2.423503\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.423502524693807\n",
      "[05/21/2025 16:54:33 INFO 140202337613632] Epoch[236] Batch [5]#011Speed: 2720.92 samples/sec#011loss=2.423503\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] Epoch[236] Batch[10] avg_epoch_loss=2.286849\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=2.1228641748428343\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] Epoch[236] Batch [10]#011Speed: 2435.71 samples/sec#011loss=2.122864\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747846473.282426, \"EndTime\": 1747846474.0888262, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 806.1072826385498, \"count\": 1, \"min\": 806.1072826385498, \"max\": 806.1072826385498}}}\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1601.3438255133392 records/second\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] #progress_metric: host=algo-1, completed 59.25 % of epochs\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.2868487293070014\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_6690f2e1-91da-4601-9223-63672c3e6741-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846474.0888875, \"EndTime\": 1747846474.0979748, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.810758590698242, \"count\": 1, \"min\": 8.810758590698242, \"max\": 8.810758590698242}}}\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] Epoch[237] Batch[0] avg_epoch_loss=2.382331\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.382331132888794\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] Epoch[237] Batch[5] avg_epoch_loss=2.342618\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.3426175117492676\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] Epoch[237] Batch [5]#011Speed: 2702.92 samples/sec#011loss=2.342618\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] Epoch[237] Batch[10] avg_epoch_loss=2.348067\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=2.354606294631958\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] Epoch[237] Batch [10]#011Speed: 2511.65 samples/sec#011loss=2.354606\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747846474.098033, \"EndTime\": 1747846474.8924673, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.3787574768066, \"count\": 1, \"min\": 794.3787574768066, \"max\": 794.3787574768066}}}\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1720.6510249127086 records/second\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] #progress_metric: host=algo-1, completed 59.5 % of epochs\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.348066958514127\n",
      "[05/21/2025 16:54:34 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] Epoch[238] Batch[0] avg_epoch_loss=2.407902\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.4079020023345947\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] Epoch[238] Batch[5] avg_epoch_loss=2.347729\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.3477285305658975\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] Epoch[238] Batch [5]#011Speed: 2649.81 samples/sec#011loss=2.347729\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] Epoch[238] Batch[10] avg_epoch_loss=2.419273\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=2.5051257610321045\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] Epoch[238] Batch [10]#011Speed: 2502.63 samples/sec#011loss=2.505126\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747846474.8925261, \"EndTime\": 1747846475.6929362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.1697063446045, \"count\": 1, \"min\": 800.1697063446045, \"max\": 800.1697063446045}}}\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1674.4596526289383 records/second\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] #progress_metric: host=algo-1, completed 59.75 % of epochs\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.4192727262323555\n",
      "[05/21/2025 16:54:35 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] Epoch[239] Batch[0] avg_epoch_loss=2.332777\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.3327767848968506\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] Epoch[239] Batch[5] avg_epoch_loss=2.324753\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.324753204981486\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] Epoch[239] Batch [5]#011Speed: 2475.12 samples/sec#011loss=2.324753\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] Epoch[239] Batch[10] avg_epoch_loss=2.275930\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=2.217341089248657\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] Epoch[239] Batch [10]#011Speed: 2612.96 samples/sec#011loss=2.217341\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747846475.6929972, \"EndTime\": 1747846476.5220506, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 828.803300857544, \"count\": 1, \"min\": 828.803300857544, \"max\": 828.803300857544}}}\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1569.5737463491694 records/second\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] #progress_metric: host=algo-1, completed 60.0 % of epochs\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.2759295160120185\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_7219137d-fa5f-49c1-be1d-eff4dca9b63b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846476.5221066, \"EndTime\": 1747846476.5327866, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.393857955932617, \"count\": 1, \"min\": 10.393857955932617, \"max\": 10.393857955932617}}}\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] Epoch[240] Batch[0] avg_epoch_loss=2.507976\n",
      "[05/21/2025 16:54:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.5079758167266846\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] Epoch[240] Batch[5] avg_epoch_loss=2.491087\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.491086959838867\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] Epoch[240] Batch [5]#011Speed: 2396.39 samples/sec#011loss=2.491087\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] Epoch[240] Batch[10] avg_epoch_loss=2.471485\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=2.447962522506714\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] Epoch[240] Batch [10]#011Speed: 2506.73 samples/sec#011loss=2.447963\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747846476.532848, \"EndTime\": 1747846477.3600652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 827.1603584289551, \"count\": 1, \"min\": 827.1603584289551, \"max\": 827.1603584289551}}}\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1636.7256124729306 records/second\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] #progress_metric: host=algo-1, completed 60.25 % of epochs\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.4714849428697065\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] Epoch[241] Batch[0] avg_epoch_loss=2.466352\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.4663524627685547\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] Epoch[241] Batch[5] avg_epoch_loss=2.534436\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.534435828526815\n",
      "[05/21/2025 16:54:37 INFO 140202337613632] Epoch[241] Batch [5]#011Speed: 2667.25 samples/sec#011loss=2.534436\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] Epoch[241] Batch[10] avg_epoch_loss=2.514852\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.4913522720336916\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] Epoch[241] Batch [10]#011Speed: 2602.36 samples/sec#011loss=2.491352\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747846477.360134, \"EndTime\": 1747846478.158272, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.8086471557617, \"count\": 1, \"min\": 797.8086471557617, \"max\": 797.8086471557617}}}\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1606.6937067575825 records/second\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] #progress_metric: host=algo-1, completed 60.5 % of epochs\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.5148523937572134\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] Epoch[242] Batch[0] avg_epoch_loss=2.566995\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.5669946670532227\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] Epoch[242] Batch[5] avg_epoch_loss=2.547021\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.54702091217041\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] Epoch[242] Batch [5]#011Speed: 2675.17 samples/sec#011loss=2.547021\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747846478.1583314, \"EndTime\": 1747846478.9090111, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 750.389814376831, \"count\": 1, \"min\": 750.389814376831, \"max\": 750.389814376831}}}\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1696.2063855025926 records/second\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] #progress_metric: host=algo-1, completed 60.75 % of epochs\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.5115536212921143\n",
      "[05/21/2025 16:54:38 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] Epoch[243] Batch[0] avg_epoch_loss=2.371913\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=2.371913194656372\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] Epoch[243] Batch[5] avg_epoch_loss=2.427908\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.427907665570577\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] Epoch[243] Batch [5]#011Speed: 2603.84 samples/sec#011loss=2.427908\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] Epoch[243] Batch[10] avg_epoch_loss=2.375490\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=2.3125887393951414\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] Epoch[243] Batch [10]#011Speed: 2516.55 samples/sec#011loss=2.312589\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747846478.9090862, \"EndTime\": 1747846479.7206123, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.0880851745605, \"count\": 1, \"min\": 811.0880851745605, \"max\": 811.0880851745605}}}\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1608.7516433402727 records/second\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] #progress_metric: host=algo-1, completed 61.0 % of epochs\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.37548997185447\n",
      "[05/21/2025 16:54:39 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] Epoch[244] Batch[0] avg_epoch_loss=2.401595\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.401594877243042\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] Epoch[244] Batch[5] avg_epoch_loss=2.299983\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.2999832232793174\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] Epoch[244] Batch [5]#011Speed: 2546.43 samples/sec#011loss=2.299983\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] Epoch[244] Batch[10] avg_epoch_loss=2.348042\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=2.4057125091552733\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] Epoch[244] Batch [10]#011Speed: 2465.26 samples/sec#011loss=2.405713\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747846479.7206805, \"EndTime\": 1747846480.539336, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 818.2950019836426, \"count\": 1, \"min\": 818.2950019836426, \"max\": 818.2950019836426}}}\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1649.5838539589445 records/second\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] #progress_metric: host=algo-1, completed 61.25 % of epochs\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.34804198958657\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] Epoch[245] Batch[0] avg_epoch_loss=2.320230\n",
      "[05/21/2025 16:54:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.32023024559021\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] Epoch[245] Batch[5] avg_epoch_loss=2.332184\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.3321839570999146\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] Epoch[245] Batch [5]#011Speed: 2589.72 samples/sec#011loss=2.332184\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] Epoch[245] Batch[10] avg_epoch_loss=2.326108\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=2.318817949295044\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] Epoch[245] Batch [10]#011Speed: 2537.90 samples/sec#011loss=2.318818\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747846480.5393968, \"EndTime\": 1747846481.3521311, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.4268054962158, \"count\": 1, \"min\": 812.4268054962158, \"max\": 812.4268054962158}}}\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1614.7360629963773 records/second\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] #progress_metric: host=algo-1, completed 61.5 % of epochs\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.3261084990067915\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] Epoch[246] Batch[0] avg_epoch_loss=2.269365\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.269365072250366\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] Epoch[246] Batch[5] avg_epoch_loss=2.270689\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.270689050356547\n",
      "[05/21/2025 16:54:41 INFO 140202337613632] Epoch[246] Batch [5]#011Speed: 2627.59 samples/sec#011loss=2.270689\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] Epoch[246] Batch[10] avg_epoch_loss=2.337054\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=2.416692924499512\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] Epoch[246] Batch [10]#011Speed: 2151.70 samples/sec#011loss=2.416693\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747846481.3521912, \"EndTime\": 1747846482.2036903, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 851.1857986450195, \"count\": 1, \"min\": 851.1857986450195, \"max\": 851.1857986450195}}}\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1536.5201015095072 records/second\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] #progress_metric: host=algo-1, completed 61.75 % of epochs\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=246, train loss <loss>=2.3370544476942583\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] Epoch[247] Batch[0] avg_epoch_loss=2.329479\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.329479217529297\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] Epoch[247] Batch[5] avg_epoch_loss=2.347772\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.3477716048558555\n",
      "[05/21/2025 16:54:42 INFO 140202337613632] Epoch[247] Batch [5]#011Speed: 2579.11 samples/sec#011loss=2.347772\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] Epoch[247] Batch[10] avg_epoch_loss=2.332583\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=2.314355754852295\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] Epoch[247] Batch [10]#011Speed: 2406.43 samples/sec#011loss=2.314356\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747846482.20375, \"EndTime\": 1747846483.022208, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 818.2101249694824, \"count\": 1, \"min\": 818.2101249694824, \"max\": 818.2101249694824}}}\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1632.657324914996 records/second\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] #progress_metric: host=algo-1, completed 62.0 % of epochs\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=247, train loss <loss>=2.3325825821269643\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] Epoch[248] Batch[0] avg_epoch_loss=2.407898\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.407897710800171\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] Epoch[248] Batch[5] avg_epoch_loss=2.333905\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.333904981613159\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] Epoch[248] Batch [5]#011Speed: 2645.79 samples/sec#011loss=2.333905\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] processed a total of 1250 examples\n",
      "#metrics {\"StartTime\": 1747846483.022267, \"EndTime\": 1747846483.7889047, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 766.324520111084, \"count\": 1, \"min\": 766.324520111084, \"max\": 766.324520111084}}}\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1630.916640925404 records/second\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] #progress_metric: host=algo-1, completed 62.25 % of epochs\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.3544663906097414\n",
      "[05/21/2025 16:54:43 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] Epoch[249] Batch[0] avg_epoch_loss=2.314567\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.3145670890808105\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] Epoch[249] Batch[5] avg_epoch_loss=2.317251\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.3172510862350464\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] Epoch[249] Batch [5]#011Speed: 2560.56 samples/sec#011loss=2.317251\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] Epoch[249] Batch[10] avg_epoch_loss=2.372518\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=2.4388383865356444\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] Epoch[249] Batch [10]#011Speed: 2594.13 samples/sec#011loss=2.438838\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747846483.7889879, \"EndTime\": 1747846484.6001585, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.89186668396, \"count\": 1, \"min\": 810.89186668396, \"max\": 810.89186668396}}}\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1593.1336040767922 records/second\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] #progress_metric: host=algo-1, completed 62.5 % of epochs\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.3725180409171363\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] Epoch[250] Batch[0] avg_epoch_loss=2.847979\n",
      "[05/21/2025 16:54:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.8479793071746826\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] Epoch[250] Batch[5] avg_epoch_loss=2.926843\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.9268433650334678\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] Epoch[250] Batch [5]#011Speed: 2607.02 samples/sec#011loss=2.926843\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747846484.6002183, \"EndTime\": 1747846485.3491752, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 748.6965656280518, \"count\": 1, \"min\": 748.6965656280518, \"max\": 748.6965656280518}}}\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1706.7600251031556 records/second\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] #progress_metric: host=algo-1, completed 62.75 % of epochs\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.817936730384827\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] Epoch[251] Batch[0] avg_epoch_loss=2.630636\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.63063645362854\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] Epoch[251] Batch[5] avg_epoch_loss=2.657623\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.6576230923334756\n",
      "[05/21/2025 16:54:45 INFO 140202337613632] Epoch[251] Batch [5]#011Speed: 2620.04 samples/sec#011loss=2.657623\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] Epoch[251] Batch[10] avg_epoch_loss=2.684067\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=2.7158002853393555\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] Epoch[251] Batch [10]#011Speed: 2363.54 samples/sec#011loss=2.715800\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747846485.3492358, \"EndTime\": 1747846486.1705678, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 821.0606575012207, \"count\": 1, \"min\": 821.0606575012207, \"max\": 821.0606575012207}}}\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1614.7914948918308 records/second\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] #progress_metric: host=algo-1, completed 63.0 % of epochs\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.684067270972512\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] Epoch[252] Batch[0] avg_epoch_loss=2.653087\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=2.6530866622924805\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] Epoch[252] Batch[5] avg_epoch_loss=2.530162\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.5301624139149985\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] Epoch[252] Batch [5]#011Speed: 2664.14 samples/sec#011loss=2.530162\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] Epoch[252] Batch[10] avg_epoch_loss=2.644870\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=2.7825180530548095\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] Epoch[252] Batch [10]#011Speed: 2509.64 samples/sec#011loss=2.782518\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747846486.170636, \"EndTime\": 1747846486.9705236, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.6270656585693, \"count\": 1, \"min\": 799.6270656585693, \"max\": 799.6270656585693}}}\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1639.3363700840994 records/second\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] #progress_metric: host=algo-1, completed 63.25 % of epochs\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.6448695226149126\n",
      "[05/21/2025 16:54:46 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] Epoch[253] Batch[0] avg_epoch_loss=2.366975\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=2.3669753074645996\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] Epoch[253] Batch[5] avg_epoch_loss=2.482216\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.4822164376576743\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] Epoch[253] Batch [5]#011Speed: 2518.31 samples/sec#011loss=2.482216\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] Epoch[253] Batch[10] avg_epoch_loss=2.420237\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=2.3458614587783813\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] Epoch[253] Batch [10]#011Speed: 2677.46 samples/sec#011loss=2.345861\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747846486.9705777, \"EndTime\": 1747846487.776573, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 805.6304454803467, \"count\": 1, \"min\": 805.6304454803467, \"max\": 805.6304454803467}}}\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1593.6097834365955 records/second\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] #progress_metric: host=algo-1, completed 63.5 % of epochs\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.42023690180345\n",
      "[05/21/2025 16:54:47 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] Epoch[254] Batch[0] avg_epoch_loss=2.380831\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.380831480026245\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] Epoch[254] Batch[5] avg_epoch_loss=2.375032\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.3750321865081787\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] Epoch[254] Batch [5]#011Speed: 2573.70 samples/sec#011loss=2.375032\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] Epoch[254] Batch[10] avg_epoch_loss=2.359172\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=254, batch=10 train loss <loss>=2.3401387214660643\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] Epoch[254] Batch [10]#011Speed: 2558.06 samples/sec#011loss=2.340139\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747846487.7766318, \"EndTime\": 1747846488.583734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 806.8516254425049, \"count\": 1, \"min\": 806.8516254425049, \"max\": 806.8516254425049}}}\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1643.2408064859244 records/second\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] #progress_metric: host=algo-1, completed 63.75 % of epochs\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.359171520579945\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] Epoch[255] Batch[0] avg_epoch_loss=2.344599\n",
      "[05/21/2025 16:54:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=2.3445990085601807\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] Epoch[255] Batch[5] avg_epoch_loss=2.349216\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.349215785662333\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] Epoch[255] Batch [5]#011Speed: 2639.85 samples/sec#011loss=2.349216\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] Epoch[255] Batch[10] avg_epoch_loss=2.408152\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=2.4788748741149904\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] Epoch[255] Batch [10]#011Speed: 2627.40 samples/sec#011loss=2.478875\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747846488.5837958, \"EndTime\": 1747846489.3740368, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.9982929229736, \"count\": 1, \"min\": 789.9982929229736, \"max\": 789.9982929229736}}}\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1668.1762902046983 records/second\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] #progress_metric: host=algo-1, completed 64.0 % of epochs\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.4081517349589956\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] Epoch[256] Batch[0] avg_epoch_loss=2.378905\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.3789050579071045\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] Epoch[256] Batch[5] avg_epoch_loss=2.408000\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.408000349998474\n",
      "[05/21/2025 16:54:49 INFO 140202337613632] Epoch[256] Batch [5]#011Speed: 2685.61 samples/sec#011loss=2.408000\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] Epoch[256] Batch[10] avg_epoch_loss=2.302952\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=2.1768930912017823\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] Epoch[256] Batch [10]#011Speed: 2574.24 samples/sec#011loss=2.176893\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747846489.3740954, \"EndTime\": 1747846490.1693552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.973611831665, \"count\": 1, \"min\": 794.973611831665, \"max\": 794.973611831665}}}\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1626.2608213775509 records/second\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] #progress_metric: host=algo-1, completed 64.25 % of epochs\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.302951595999978\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] Epoch[257] Batch[0] avg_epoch_loss=2.407516\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.4075162410736084\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] Epoch[257] Batch[5] avg_epoch_loss=2.356336\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.356335679690043\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] Epoch[257] Batch [5]#011Speed: 2684.04 samples/sec#011loss=2.356336\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] Epoch[257] Batch[10] avg_epoch_loss=2.375194\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=2.3978244781494142\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] Epoch[257] Batch [10]#011Speed: 2553.30 samples/sec#011loss=2.397824\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747846490.169428, \"EndTime\": 1747846490.984203, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.5158290863037, \"count\": 1, \"min\": 814.5158290863037, \"max\": 814.5158290863037}}}\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1630.241312801205 records/second\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] #progress_metric: host=algo-1, completed 64.5 % of epochs\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.3751942244443027\n",
      "[05/21/2025 16:54:50 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] Epoch[258] Batch[0] avg_epoch_loss=2.335110\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.3351101875305176\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] Epoch[258] Batch[5] avg_epoch_loss=2.298158\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.2981576919555664\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] Epoch[258] Batch [5]#011Speed: 2713.08 samples/sec#011loss=2.298158\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] Epoch[258] Batch[10] avg_epoch_loss=2.397146\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=2.5159324169158936\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] Epoch[258] Batch [10]#011Speed: 2449.89 samples/sec#011loss=2.515932\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] processed a total of 1381 examples\n",
      "#metrics {\"StartTime\": 1747846490.984261, \"EndTime\": 1747846491.7820582, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.5506782531738, \"count\": 1, \"min\": 797.5506782531738, \"max\": 797.5506782531738}}}\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1731.3671524298422 records/second\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] #progress_metric: host=algo-1, completed 64.75 % of epochs\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.3971462033011695\n",
      "[05/21/2025 16:54:51 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] Epoch[259] Batch[0] avg_epoch_loss=2.269925\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.2699246406555176\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] Epoch[259] Batch[5] avg_epoch_loss=2.298511\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.2985106309254966\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] Epoch[259] Batch [5]#011Speed: 2711.32 samples/sec#011loss=2.298511\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] Epoch[259] Batch[10] avg_epoch_loss=2.270468\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=2.2368171215057373\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] Epoch[259] Batch [10]#011Speed: 2681.30 samples/sec#011loss=2.236817\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747846491.782115, \"EndTime\": 1747846492.5627117, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.3463935852051, \"count\": 1, \"min\": 780.3463935852051, \"max\": 780.3463935852051}}}\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1674.625528747005 records/second\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] #progress_metric: host=algo-1, completed 65.0 % of epochs\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.2704681266437876\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_c9585135-d439-46af-9ee7-649f6db577c8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846492.562809, \"EndTime\": 1747846492.5729933, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.9029541015625, \"count\": 1, \"min\": 9.9029541015625, \"max\": 9.9029541015625}}}\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] Epoch[260] Batch[0] avg_epoch_loss=2.370939\n",
      "[05/21/2025 16:54:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=2.370939016342163\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] Epoch[260] Batch[5] avg_epoch_loss=2.308859\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.3088586727778115\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] Epoch[260] Batch [5]#011Speed: 2703.69 samples/sec#011loss=2.308859\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] Epoch[260] Batch[10] avg_epoch_loss=2.407586\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=260, batch=10 train loss <loss>=2.526059055328369\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] Epoch[260] Batch [10]#011Speed: 2648.22 samples/sec#011loss=2.526059\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747846492.5730524, \"EndTime\": 1747846493.3549738, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 781.8682193756104, \"count\": 1, \"min\": 781.8682193756104, \"max\": 781.8682193756104}}}\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1693.193087898334 records/second\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] #progress_metric: host=algo-1, completed 65.25 % of epochs\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.4075861193917016\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] Epoch[261] Batch[0] avg_epoch_loss=2.449196\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.4491963386535645\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] Epoch[261] Batch[5] avg_epoch_loss=2.398777\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.3987766901652017\n",
      "[05/21/2025 16:54:53 INFO 140202337613632] Epoch[261] Batch [5]#011Speed: 2681.51 samples/sec#011loss=2.398777\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] Epoch[261] Batch[10] avg_epoch_loss=2.404183\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=2.410670852661133\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] Epoch[261] Batch [10]#011Speed: 2555.61 samples/sec#011loss=2.410671\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747846493.355031, \"EndTime\": 1747846494.1575608, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.2780418395996, \"count\": 1, \"min\": 802.2780418395996, \"max\": 802.2780418395996}}}\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1640.1487338086058 records/second\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] #progress_metric: host=algo-1, completed 65.5 % of epochs\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=261, train loss <loss>=2.404183127663352\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] Epoch[262] Batch[0] avg_epoch_loss=2.362022\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.3620221614837646\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] Epoch[262] Batch[5] avg_epoch_loss=2.362480\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.3624804814656577\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] Epoch[262] Batch [5]#011Speed: 2296.14 samples/sec#011loss=2.362480\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] Epoch[262] Batch[10] avg_epoch_loss=2.356226\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=2.348721504211426\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] Epoch[262] Batch [10]#011Speed: 2557.37 samples/sec#011loss=2.348722\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747846494.1576211, \"EndTime\": 1747846494.9930418, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 835.1664543151855, \"count\": 1, \"min\": 835.1664543151855, \"max\": 835.1664543151855}}}\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1600.7121410462003 records/second\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] #progress_metric: host=algo-1, completed 65.75 % of epochs\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.3562264008955522\n",
      "[05/21/2025 16:54:54 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] Epoch[263] Batch[0] avg_epoch_loss=2.333357\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.333357334136963\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] Epoch[263] Batch[5] avg_epoch_loss=2.362828\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.3628282149632773\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] Epoch[263] Batch [5]#011Speed: 2726.24 samples/sec#011loss=2.362828\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] Epoch[263] Batch[10] avg_epoch_loss=2.350574\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=263, batch=10 train loss <loss>=2.335868310928345\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] Epoch[263] Batch [10]#011Speed: 2504.15 samples/sec#011loss=2.335868\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747846494.9931, \"EndTime\": 1747846495.7874362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.0866947174072, \"count\": 1, \"min\": 794.0866947174072, \"max\": 794.0866947174072}}}\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1686.028596157258 records/second\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] #progress_metric: host=algo-1, completed 66.0 % of epochs\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=263, train loss <loss>=2.350573713129217\n",
      "[05/21/2025 16:54:55 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] Epoch[264] Batch[0] avg_epoch_loss=2.257989\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.2579894065856934\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] Epoch[264] Batch[5] avg_epoch_loss=2.320325\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.3203248580296836\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] Epoch[264] Batch [5]#011Speed: 2581.38 samples/sec#011loss=2.320325\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] Epoch[264] Batch[10] avg_epoch_loss=2.337377\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=2.357838821411133\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] Epoch[264] Batch [10]#011Speed: 2384.18 samples/sec#011loss=2.357839\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747846495.7874942, \"EndTime\": 1747846496.612031, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 824.2537975311279, \"count\": 1, \"min\": 824.2537975311279, \"max\": 824.2537975311279}}}\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1574.5859759575283 records/second\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] #progress_metric: host=algo-1, completed 66.25 % of epochs\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.337376659566706\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] Epoch[265] Batch[0] avg_epoch_loss=2.308836\n",
      "[05/21/2025 16:54:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.3088362216949463\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] Epoch[265] Batch[5] avg_epoch_loss=2.285880\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.2858802477518716\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] Epoch[265] Batch [5]#011Speed: 2651.42 samples/sec#011loss=2.285880\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] Epoch[265] Batch[10] avg_epoch_loss=2.229277\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=2.1613524198532104\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] Epoch[265] Batch [10]#011Speed: 2560.94 samples/sec#011loss=2.161352\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747846496.6120913, \"EndTime\": 1747846497.4171398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 804.7275543212891, \"count\": 1, \"min\": 804.7275543212891, \"max\": 804.7275543212891}}}\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1655.011659232146 records/second\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] #progress_metric: host=algo-1, completed 66.5 % of epochs\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.2292766896161167\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_b9d2283b-1595-461b-8ee3-409e33571d85-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846497.4172063, \"EndTime\": 1747846497.427302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.71364974975586, \"count\": 1, \"min\": 9.71364974975586, \"max\": 9.71364974975586}}}\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] Epoch[266] Batch[0] avg_epoch_loss=2.244232\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.244232416152954\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] Epoch[266] Batch[5] avg_epoch_loss=2.273192\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.2731922467549643\n",
      "[05/21/2025 16:54:57 INFO 140202337613632] Epoch[266] Batch [5]#011Speed: 2634.40 samples/sec#011loss=2.273192\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] Epoch[266] Batch[10] avg_epoch_loss=2.250768\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=2.2238581657409666\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] Epoch[266] Batch [10]#011Speed: 2516.85 samples/sec#011loss=2.223858\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747846497.4273608, \"EndTime\": 1747846498.2303803, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.9646873474121, \"count\": 1, \"min\": 802.9646873474121, \"max\": 802.9646873474121}}}\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1633.755641771973 records/second\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] #progress_metric: host=algo-1, completed 66.75 % of epochs\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.2507676644758745\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] Epoch[267] Batch[0] avg_epoch_loss=2.218032\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.218031644821167\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] Epoch[267] Batch[5] avg_epoch_loss=2.238965\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.2389649550120034\n",
      "[05/21/2025 16:54:58 INFO 140202337613632] Epoch[267] Batch [5]#011Speed: 2653.50 samples/sec#011loss=2.238965\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] Epoch[267] Batch[10] avg_epoch_loss=2.255869\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=2.2761537551879885\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] Epoch[267] Batch [10]#011Speed: 2397.58 samples/sec#011loss=2.276154\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747846498.2304435, \"EndTime\": 1747846499.04519, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.4450187683105, \"count\": 1, \"min\": 814.4450187683105, \"max\": 814.4450187683105}}}\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1640.2002993789379 records/second\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] #progress_metric: host=algo-1, completed 67.0 % of epochs\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.2558689550919966\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] Epoch[268] Batch[0] avg_epoch_loss=2.330259\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.33025860786438\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] Epoch[268] Batch[5] avg_epoch_loss=2.324054\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.324053724606832\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] Epoch[268] Batch [5]#011Speed: 2602.62 samples/sec#011loss=2.324054\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] processed a total of 1271 examples\n",
      "#metrics {\"StartTime\": 1747846499.045251, \"EndTime\": 1747846499.795531, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 750.030517578125, \"count\": 1, \"min\": 750.030517578125, \"max\": 750.030517578125}}}\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1694.3758077824266 records/second\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] #progress_metric: host=algo-1, completed 67.25 % of epochs\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.2921571016311644\n",
      "[05/21/2025 16:54:59 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] Epoch[269] Batch[0] avg_epoch_loss=2.250597\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=2.250596761703491\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] Epoch[269] Batch[5] avg_epoch_loss=2.283741\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=2.2837409178415933\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] Epoch[269] Batch [5]#011Speed: 2708.42 samples/sec#011loss=2.283741\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747846499.7955973, \"EndTime\": 1747846500.5362458, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 740.302324295044, \"count\": 1, \"min\": 740.302324295044, \"max\": 740.302324295044}}}\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1727.4411098613446 records/second\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] #progress_metric: host=algo-1, completed 67.5 % of epochs\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=269, train loss <loss>=2.28211669921875\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] Epoch[270] Batch[0] avg_epoch_loss=2.321556\n",
      "[05/21/2025 16:55:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=2.3215556144714355\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] Epoch[270] Batch[5] avg_epoch_loss=2.251383\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=2.2513828674952188\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] Epoch[270] Batch [5]#011Speed: 2662.45 samples/sec#011loss=2.251383\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] Epoch[270] Batch[10] avg_epoch_loss=2.505737\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=2.810962963104248\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] Epoch[270] Batch [10]#011Speed: 2016.48 samples/sec#011loss=2.810963\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747846500.5363123, \"EndTime\": 1747846501.439248, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 902.0693302154541, \"count\": 1, \"min\": 902.0693302154541, \"max\": 902.0693302154541}}}\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1493.0825947063045 records/second\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] #progress_metric: host=algo-1, completed 67.75 % of epochs\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=270, train loss <loss>=2.505737456408414\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] Epoch[271] Batch[0] avg_epoch_loss=2.335405\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=2.3354053497314453\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] Epoch[271] Batch[5] avg_epoch_loss=2.387009\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=2.387008627255758\n",
      "[05/21/2025 16:55:01 INFO 140202337613632] Epoch[271] Batch [5]#011Speed: 2596.32 samples/sec#011loss=2.387009\n",
      "[05/21/2025 16:55:02 INFO 140202337613632] processed a total of 1277 examples\n",
      "#metrics {\"StartTime\": 1747846501.439309, \"EndTime\": 1747846502.1995077, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 759.943962097168, \"count\": 1, \"min\": 759.943962097168, \"max\": 759.943962097168}}}\n",
      "[05/21/2025 16:55:02 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1680.1798992354986 records/second\n",
      "[05/21/2025 16:55:02 INFO 140202337613632] #progress_metric: host=algo-1, completed 68.0 % of epochs\n",
      "[05/21/2025 16:55:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=271, train loss <loss>=2.396125864982605\n",
      "[05/21/2025 16:55:02 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:02 INFO 140202337613632] Epoch[272] Batch[0] avg_epoch_loss=2.431621\n",
      "[05/21/2025 16:55:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=2.4316210746765137\n",
      "[05/21/2025 16:55:02 INFO 140202337613632] Epoch[272] Batch[5] avg_epoch_loss=2.365704\n",
      "[05/21/2025 16:55:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=2.3657038609186807\n",
      "[05/21/2025 16:55:02 INFO 140202337613632] Epoch[272] Batch [5]#011Speed: 2655.30 samples/sec#011loss=2.365704\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] Epoch[272] Batch[10] avg_epoch_loss=2.265117\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=2.1444128274917604\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] Epoch[272] Batch [10]#011Speed: 2489.91 samples/sec#011loss=2.144413\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747846502.1995707, \"EndTime\": 1747846503.007924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.8892230987549, \"count\": 1, \"min\": 807.8892230987549, \"max\": 807.8892230987549}}}\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1617.5993791578205 records/second\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] #progress_metric: host=algo-1, completed 68.25 % of epochs\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=272, train loss <loss>=2.2651170275428076\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] Epoch[273] Batch[0] avg_epoch_loss=2.448719\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=2.4487192630767822\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] Epoch[273] Batch[5] avg_epoch_loss=2.305065\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=2.3050650358200073\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] Epoch[273] Batch [5]#011Speed: 2580.16 samples/sec#011loss=2.305065\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] processed a total of 1256 examples\n",
      "#metrics {\"StartTime\": 1747846503.007991, \"EndTime\": 1747846503.756296, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 747.9791641235352, \"count\": 1, \"min\": 747.9791641235352, \"max\": 747.9791641235352}}}\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1678.8583046992965 records/second\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] #progress_metric: host=algo-1, completed 68.5 % of epochs\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=273, train loss <loss>=2.3068699836730957\n",
      "[05/21/2025 16:55:03 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] Epoch[274] Batch[0] avg_epoch_loss=2.226515\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=2.226515293121338\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] Epoch[274] Batch[5] avg_epoch_loss=2.240457\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=2.2404566605885825\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] Epoch[274] Batch [5]#011Speed: 2741.51 samples/sec#011loss=2.240457\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] Epoch[274] Batch[10] avg_epoch_loss=2.351735\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=274, batch=10 train loss <loss>=2.4852689266204835\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] Epoch[274] Batch [10]#011Speed: 2547.17 samples/sec#011loss=2.485269\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747846503.756411, \"EndTime\": 1747846504.5561907, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.304723739624, \"count\": 1, \"min\": 799.304723739624, \"max\": 799.304723739624}}}\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1672.509674563872 records/second\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] #progress_metric: host=algo-1, completed 68.75 % of epochs\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=274, train loss <loss>=2.3517349633303555\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] Epoch[275] Batch[0] avg_epoch_loss=2.253148\n",
      "[05/21/2025 16:55:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=2.253148078918457\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] Epoch[275] Batch[5] avg_epoch_loss=2.267693\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=2.2676930030186973\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] Epoch[275] Batch [5]#011Speed: 2595.52 samples/sec#011loss=2.267693\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] Epoch[275] Batch[10] avg_epoch_loss=2.479043\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=275, batch=10 train loss <loss>=2.7326619148254396\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] Epoch[275] Batch [10]#011Speed: 2307.34 samples/sec#011loss=2.732662\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747846504.5562532, \"EndTime\": 1747846505.3882375, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 831.5532207489014, \"count\": 1, \"min\": 831.5532207489014, \"max\": 831.5532207489014}}}\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1554.7548040357083 records/second\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] #progress_metric: host=algo-1, completed 69.0 % of epochs\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=275, train loss <loss>=2.479042508385398\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] Epoch[276] Batch[0] avg_epoch_loss=2.321222\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=2.3212215900421143\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] Epoch[276] Batch[5] avg_epoch_loss=2.354483\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=2.3544826110204062\n",
      "[05/21/2025 16:55:05 INFO 140202337613632] Epoch[276] Batch [5]#011Speed: 2716.50 samples/sec#011loss=2.354483\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] Epoch[276] Batch[10] avg_epoch_loss=2.385958\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=2.423728275299072\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] Epoch[276] Batch [10]#011Speed: 2702.07 samples/sec#011loss=2.423728\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747846505.3882957, \"EndTime\": 1747846506.181874, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 793.3306694030762, \"count\": 1, \"min\": 793.3306694030762, \"max\": 793.3306694030762}}}\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1624.6176510006208 records/second\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] #progress_metric: host=algo-1, completed 69.25 % of epochs\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=276, train loss <loss>=2.3859579129652544\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] Epoch[277] Batch[0] avg_epoch_loss=2.406019\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=2.4060192108154297\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] Epoch[277] Batch[5] avg_epoch_loss=2.351263\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=2.351262927055359\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] Epoch[277] Batch [5]#011Speed: 2764.92 samples/sec#011loss=2.351263\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] Epoch[277] Batch[10] avg_epoch_loss=2.255270\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=277, batch=10 train loss <loss>=2.140078830718994\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] Epoch[277] Batch [10]#011Speed: 2455.56 samples/sec#011loss=2.140079\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747846506.181932, \"EndTime\": 1747846506.983732, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.5532493591309, \"count\": 1, \"min\": 801.5532493591309, \"max\": 801.5532493591309}}}\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1611.6925999805492 records/second\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] #progress_metric: host=algo-1, completed 69.5 % of epochs\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=277, train loss <loss>=2.255270155993375\n",
      "[05/21/2025 16:55:06 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] Epoch[278] Batch[0] avg_epoch_loss=2.227778\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=2.2277777194976807\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] Epoch[278] Batch[5] avg_epoch_loss=2.308088\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=2.308087706565857\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] Epoch[278] Batch [5]#011Speed: 2618.74 samples/sec#011loss=2.308088\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] Epoch[278] Batch[10] avg_epoch_loss=2.319594\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=2.333401393890381\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] Epoch[278] Batch [10]#011Speed: 2569.78 samples/sec#011loss=2.333401\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747846506.983792, \"EndTime\": 1747846507.7799554, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.9091663360596, \"count\": 1, \"min\": 795.9091663360596, \"max\": 795.9091663360596}}}\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1680.8974660644326 records/second\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] #progress_metric: host=algo-1, completed 69.75 % of epochs\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=278, train loss <loss>=2.3195939280770044\n",
      "[05/21/2025 16:55:07 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] Epoch[279] Batch[0] avg_epoch_loss=2.252249\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=2.2522494792938232\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] Epoch[279] Batch[5] avg_epoch_loss=2.345499\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=2.3454988400141397\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] Epoch[279] Batch [5]#011Speed: 2675.20 samples/sec#011loss=2.345499\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] Epoch[279] Batch[10] avg_epoch_loss=2.351229\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=2.3581047534942625\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] Epoch[279] Batch [10]#011Speed: 2562.81 samples/sec#011loss=2.358105\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747846507.7800193, \"EndTime\": 1747846508.577628, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.3449230194092, \"count\": 1, \"min\": 797.3449230194092, \"max\": 797.3449230194092}}}\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1621.45934343759 records/second\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] #progress_metric: host=algo-1, completed 70.0 % of epochs\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=279, train loss <loss>=2.351228800686923\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] Epoch[280] Batch[0] avg_epoch_loss=2.406112\n",
      "[05/21/2025 16:55:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=2.4061119556427\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] Epoch[280] Batch[5] avg_epoch_loss=2.293281\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=2.293280839920044\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] Epoch[280] Batch [5]#011Speed: 2549.44 samples/sec#011loss=2.293281\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] Epoch[280] Batch[10] avg_epoch_loss=2.295311\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=2.297746992111206\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] Epoch[280] Batch [10]#011Speed: 2643.58 samples/sec#011loss=2.297747\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747846508.5776832, \"EndTime\": 1747846509.3776276, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.6480464935303, \"count\": 1, \"min\": 799.6480464935303, \"max\": 799.6480464935303}}}\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1633.0383691322606 records/second\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] #progress_metric: host=algo-1, completed 70.25 % of epochs\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=280, train loss <loss>=2.2953109090978447\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] Epoch[281] Batch[0] avg_epoch_loss=2.194818\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=2.1948182582855225\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] Epoch[281] Batch[5] avg_epoch_loss=2.280835\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=2.280834515889486\n",
      "[05/21/2025 16:55:09 INFO 140202337613632] Epoch[281] Batch [5]#011Speed: 2736.18 samples/sec#011loss=2.280835\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] Epoch[281] Batch[10] avg_epoch_loss=2.260231\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=281, batch=10 train loss <loss>=2.2355064868927004\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] Epoch[281] Batch [10]#011Speed: 2705.93 samples/sec#011loss=2.235506\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747846509.3776875, \"EndTime\": 1747846510.1580613, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.1210880279541, \"count\": 1, \"min\": 780.1210880279541, \"max\": 780.1210880279541}}}\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1655.9684295767977 records/second\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] #progress_metric: host=algo-1, completed 70.5 % of epochs\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=281, train loss <loss>=2.260230866345492\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] Epoch[282] Batch[0] avg_epoch_loss=2.376222\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=2.3762218952178955\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] Epoch[282] Batch[5] avg_epoch_loss=2.329194\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=2.3291940291722617\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] Epoch[282] Batch [5]#011Speed: 2813.72 samples/sec#011loss=2.329194\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] Epoch[282] Batch[10] avg_epoch_loss=2.326548\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=282, batch=10 train loss <loss>=2.3233723640441895\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] Epoch[282] Batch [10]#011Speed: 2528.51 samples/sec#011loss=2.323372\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747846510.1581204, \"EndTime\": 1747846510.942571, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.2006683349609, \"count\": 1, \"min\": 784.2006683349609, \"max\": 784.2006683349609}}}\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1688.1380749373172 records/second\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] #progress_metric: host=algo-1, completed 70.75 % of epochs\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=282, train loss <loss>=2.3265478177504106\n",
      "[05/21/2025 16:55:10 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] Epoch[283] Batch[0] avg_epoch_loss=2.397095\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=2.397094964981079\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] Epoch[283] Batch[5] avg_epoch_loss=2.303842\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=2.3038421074549356\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] Epoch[283] Batch [5]#011Speed: 2737.58 samples/sec#011loss=2.303842\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] processed a total of 1241 examples\n",
      "#metrics {\"StartTime\": 1747846510.942639, \"EndTime\": 1747846511.6862037, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 743.3104515075684, \"count\": 1, \"min\": 743.3104515075684, \"max\": 743.3104515075684}}}\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1668.1551803485058 records/second\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] #progress_metric: host=algo-1, completed 71.0 % of epochs\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=283, train loss <loss>=2.3043891906738283\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] Epoch[284] Batch[0] avg_epoch_loss=2.164416\n",
      "[05/21/2025 16:55:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=2.1644160747528076\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] Epoch[284] Batch[5] avg_epoch_loss=2.252118\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=2.252117872238159\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] Epoch[284] Batch [5]#011Speed: 2723.71 samples/sec#011loss=2.252118\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] processed a total of 1243 examples\n",
      "#metrics {\"StartTime\": 1747846511.6867971, \"EndTime\": 1747846512.4186027, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 731.4281463623047, \"count\": 1, \"min\": 731.4281463623047, \"max\": 731.4281463623047}}}\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1699.168025843812 records/second\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] #progress_metric: host=algo-1, completed 71.25 % of epochs\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=284, train loss <loss>=2.2835503101348875\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] Epoch[285] Batch[0] avg_epoch_loss=2.198808\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=2.198807954788208\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] Epoch[285] Batch[5] avg_epoch_loss=2.247257\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=2.2472567160924277\n",
      "[05/21/2025 16:55:12 INFO 140202337613632] Epoch[285] Batch [5]#011Speed: 2785.22 samples/sec#011loss=2.247257\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] Epoch[285] Batch[10] avg_epoch_loss=2.235358\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=2.221079921722412\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] Epoch[285] Batch [10]#011Speed: 2295.42 samples/sec#011loss=2.221080\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747846512.4186769, \"EndTime\": 1747846513.2319295, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.9353523254395, \"count\": 1, \"min\": 812.9353523254395, \"max\": 812.9353523254395}}}\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1639.5583878214782 records/second\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] #progress_metric: host=algo-1, completed 71.5 % of epochs\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=285, train loss <loss>=2.235358173196966\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] Epoch[286] Batch[0] avg_epoch_loss=2.765250\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=2.7652504444122314\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] Epoch[286] Batch[5] avg_epoch_loss=2.479969\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=2.479968706766764\n",
      "[05/21/2025 16:55:13 INFO 140202337613632] Epoch[286] Batch [5]#011Speed: 2833.96 samples/sec#011loss=2.479969\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] Epoch[286] Batch[10] avg_epoch_loss=2.445968\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=286, batch=10 train loss <loss>=2.4051669120788572\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] Epoch[286] Batch [10]#011Speed: 2659.36 samples/sec#011loss=2.405167\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747846513.231989, \"EndTime\": 1747846514.0025105, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 770.2667713165283, \"count\": 1, \"min\": 770.2667713165283, \"max\": 770.2667713165283}}}\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1723.8837806478728 records/second\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] #progress_metric: host=algo-1, completed 71.75 % of epochs\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=286, train loss <loss>=2.4459678909995337\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] Epoch[287] Batch[0] avg_epoch_loss=2.429113\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=2.4291129112243652\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] Epoch[287] Batch[5] avg_epoch_loss=2.482571\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=2.4825706084569297\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] Epoch[287] Batch [5]#011Speed: 2684.01 samples/sec#011loss=2.482571\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] Epoch[287] Batch[10] avg_epoch_loss=2.513354\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=2.5502935886383056\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] Epoch[287] Batch [10]#011Speed: 2703.91 samples/sec#011loss=2.550294\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747846514.0025692, \"EndTime\": 1747846514.7831135, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.2777290344238, \"count\": 1, \"min\": 780.2777290344238, \"max\": 780.2777290344238}}}\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1660.7628533936638 records/second\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] #progress_metric: host=algo-1, completed 72.0 % of epochs\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=287, train loss <loss>=2.513353781266646\n",
      "[05/21/2025 16:55:14 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] Epoch[288] Batch[0] avg_epoch_loss=2.491070\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=2.491069793701172\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] Epoch[288] Batch[5] avg_epoch_loss=2.445923\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=2.445922533671061\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] Epoch[288] Batch [5]#011Speed: 2724.38 samples/sec#011loss=2.445923\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] Epoch[288] Batch[10] avg_epoch_loss=2.439921\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=288, batch=10 train loss <loss>=2.4327201366424562\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] Epoch[288] Batch [10]#011Speed: 2667.17 samples/sec#011loss=2.432720\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747846514.783172, \"EndTime\": 1747846515.5686572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.2089405059814, \"count\": 1, \"min\": 785.2089405059814, \"max\": 785.2089405059814}}}\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1652.8785049850126 records/second\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] #progress_metric: host=algo-1, completed 72.25 % of epochs\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=288, train loss <loss>=2.4399214441126045\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] Epoch[289] Batch[0] avg_epoch_loss=2.412214\n",
      "[05/21/2025 16:55:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=2.4122140407562256\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] Epoch[289] Batch[5] avg_epoch_loss=2.393437\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=2.3934369881947837\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] Epoch[289] Batch [5]#011Speed: 2518.89 samples/sec#011loss=2.393437\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] Epoch[289] Batch[10] avg_epoch_loss=2.345646\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=289, batch=10 train loss <loss>=2.2882978916168213\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] Epoch[289] Batch [10]#011Speed: 2589.61 samples/sec#011loss=2.288298\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747846515.5687168, \"EndTime\": 1747846516.382411, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.4441375732422, \"count\": 1, \"min\": 813.4441375732422, \"max\": 813.4441375732422}}}\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1584.4033175287395 records/second\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] #progress_metric: host=algo-1, completed 72.5 % of epochs\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=289, train loss <loss>=2.3456464897502554\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] Epoch[290] Batch[0] avg_epoch_loss=2.359927\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=2.35992693901062\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] Epoch[290] Batch[5] avg_epoch_loss=2.382544\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=2.3825443983078003\n",
      "[05/21/2025 16:55:16 INFO 140202337613632] Epoch[290] Batch [5]#011Speed: 2627.08 samples/sec#011loss=2.382544\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] Epoch[290] Batch[10] avg_epoch_loss=2.426822\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=290, batch=10 train loss <loss>=2.4799551486968996\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] Epoch[290] Batch [10]#011Speed: 2463.23 samples/sec#011loss=2.479955\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747846516.382492, \"EndTime\": 1747846517.1902692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.5010776519775, \"count\": 1, \"min\": 807.5010776519775, \"max\": 807.5010776519775}}}\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1665.4480527148626 records/second\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] #progress_metric: host=algo-1, completed 72.75 % of epochs\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=290, train loss <loss>=2.4268220121210273\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] Epoch[291] Batch[0] avg_epoch_loss=2.271783\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=2.2717833518981934\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] Epoch[291] Batch[5] avg_epoch_loss=2.327214\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=2.3272143602371216\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] Epoch[291] Batch [5]#011Speed: 2643.98 samples/sec#011loss=2.327214\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] Epoch[291] Batch[10] avg_epoch_loss=2.311324\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=291, batch=10 train loss <loss>=2.2922564506530763\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] Epoch[291] Batch [10]#011Speed: 2521.36 samples/sec#011loss=2.292256\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747846517.190329, \"EndTime\": 1747846517.9944887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.8854598999023, \"count\": 1, \"min\": 803.8854598999023, \"max\": 803.8854598999023}}}\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1674.1806953910555 records/second\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] #progress_metric: host=algo-1, completed 73.0 % of epochs\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=291, train loss <loss>=2.3113244013352827\n",
      "[05/21/2025 16:55:17 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] Epoch[292] Batch[0] avg_epoch_loss=2.354615\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=2.3546154499053955\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] Epoch[292] Batch[5] avg_epoch_loss=2.315175\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=2.3151745796203613\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] Epoch[292] Batch [5]#011Speed: 2724.46 samples/sec#011loss=2.315175\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] Epoch[292] Batch[10] avg_epoch_loss=2.346026\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=292, batch=10 train loss <loss>=2.3830475330352785\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] Epoch[292] Batch [10]#011Speed: 2490.29 samples/sec#011loss=2.383048\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747846517.994549, \"EndTime\": 1747846518.790942, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.1232662200928, \"count\": 1, \"min\": 796.1232662200928, \"max\": 796.1232662200928}}}\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1662.870807270776 records/second\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] #progress_metric: host=algo-1, completed 73.25 % of epochs\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=292, train loss <loss>=2.346025922081687\n",
      "[05/21/2025 16:55:18 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] Epoch[293] Batch[0] avg_epoch_loss=2.221365\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=2.221364736557007\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] Epoch[293] Batch[5] avg_epoch_loss=2.258264\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=2.258263866106669\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] Epoch[293] Batch [5]#011Speed: 2747.29 samples/sec#011loss=2.258264\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] Epoch[293] Batch[10] avg_epoch_loss=2.147105\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=293, batch=10 train loss <loss>=2.0137145638465883\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] Epoch[293] Batch [10]#011Speed: 2644.79 samples/sec#011loss=2.013715\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747846518.7910032, \"EndTime\": 1747846519.5747294, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 783.4491729736328, \"count\": 1, \"min\": 783.4491729736328, \"max\": 783.4491729736328}}}\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1664.253399635222 records/second\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] #progress_metric: host=algo-1, completed 73.5 % of epochs\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=293, train loss <loss>=2.1471050923520867\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_923694a1-9247-428b-ad7e-3eb8969bbaed-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846519.5747867, \"EndTime\": 1747846519.5850177, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.956121444702148, \"count\": 1, \"min\": 9.956121444702148, \"max\": 9.956121444702148}}}\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] Epoch[294] Batch[0] avg_epoch_loss=2.250113\n",
      "[05/21/2025 16:55:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=2.250113010406494\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] Epoch[294] Batch[5] avg_epoch_loss=2.246424\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=2.246423880259196\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] Epoch[294] Batch [5]#011Speed: 2743.37 samples/sec#011loss=2.246424\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] Epoch[294] Batch[10] avg_epoch_loss=2.218969\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=294, batch=10 train loss <loss>=2.186023783683777\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] Epoch[294] Batch [10]#011Speed: 2609.22 samples/sec#011loss=2.186024\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747846519.5850775, \"EndTime\": 1747846520.3686953, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 783.5638523101807, \"count\": 1, \"min\": 783.5638523101807, \"max\": 783.5638523101807}}}\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1692.074886822762 records/second\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] #progress_metric: host=algo-1, completed 73.75 % of epochs\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=294, train loss <loss>=2.218969290906733\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] Epoch[295] Batch[0] avg_epoch_loss=2.135145\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=295, batch=0 train loss <loss>=2.1351451873779297\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] Epoch[295] Batch[5] avg_epoch_loss=2.193840\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=295, batch=5 train loss <loss>=2.1938400665918985\n",
      "[05/21/2025 16:55:20 INFO 140202337613632] Epoch[295] Batch [5]#011Speed: 2716.12 samples/sec#011loss=2.193840\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] Epoch[295] Batch[10] avg_epoch_loss=2.253885\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=295, batch=10 train loss <loss>=2.325939416885376\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] Epoch[295] Batch [10]#011Speed: 2701.50 samples/sec#011loss=2.325939\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747846520.368757, \"EndTime\": 1747846521.1528485, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 783.8432788848877, \"count\": 1, \"min\": 783.8432788848877, \"max\": 783.8432788848877}}}\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1646.8300782045972 records/second\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] #progress_metric: host=algo-1, completed 74.0 % of epochs\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=295, train loss <loss>=2.2538852258162065\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] Epoch[296] Batch[0] avg_epoch_loss=2.227006\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=296, batch=0 train loss <loss>=2.227006435394287\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] Epoch[296] Batch[5] avg_epoch_loss=2.217770\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=296, batch=5 train loss <loss>=2.2177697022755942\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] Epoch[296] Batch [5]#011Speed: 2754.00 samples/sec#011loss=2.217770\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] Epoch[296] Batch[10] avg_epoch_loss=2.219522\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=296, batch=10 train loss <loss>=2.221623659133911\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] Epoch[296] Batch [10]#011Speed: 2721.18 samples/sec#011loss=2.221624\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747846521.1529067, \"EndTime\": 1747846521.924355, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 771.2008953094482, \"count\": 1, \"min\": 771.2008953094482, \"max\": 771.2008953094482}}}\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1715.3095688375536 records/second\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] #progress_metric: host=algo-1, completed 74.25 % of epochs\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=296, train loss <loss>=2.219521500847556\n",
      "[05/21/2025 16:55:21 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] Epoch[297] Batch[0] avg_epoch_loss=2.191910\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=297, batch=0 train loss <loss>=2.1919102668762207\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] Epoch[297] Batch[5] avg_epoch_loss=2.183301\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=297, batch=5 train loss <loss>=2.1833011706670127\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] Epoch[297] Batch [5]#011Speed: 2782.82 samples/sec#011loss=2.183301\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] processed a total of 1270 examples\n",
      "#metrics {\"StartTime\": 1747846521.9244142, \"EndTime\": 1747846522.6873846, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 762.718915939331, \"count\": 1, \"min\": 762.718915939331, \"max\": 762.718915939331}}}\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1664.9094011345135 records/second\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] #progress_metric: host=algo-1, completed 74.5 % of epochs\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=297, train loss <loss>=2.1810017585754395\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] Epoch[298] Batch[0] avg_epoch_loss=2.213784\n",
      "[05/21/2025 16:55:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=298, batch=0 train loss <loss>=2.2137837409973145\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] Epoch[298] Batch[5] avg_epoch_loss=2.196246\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=298, batch=5 train loss <loss>=2.1962462663650513\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] Epoch[298] Batch [5]#011Speed: 2596.84 samples/sec#011loss=2.196246\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] Epoch[298] Batch[10] avg_epoch_loss=2.264657\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=298, batch=10 train loss <loss>=2.3467501163482667\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] Epoch[298] Batch [10]#011Speed: 2547.89 samples/sec#011loss=2.346750\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747846522.6874404, \"EndTime\": 1747846523.492812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 804.9938678741455, \"count\": 1, \"min\": 804.9938678741455, \"max\": 804.9938678741455}}}\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1632.1143143128322 records/second\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] #progress_metric: host=algo-1, completed 74.75 % of epochs\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=298, train loss <loss>=2.2646571072665127\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] Epoch[299] Batch[0] avg_epoch_loss=2.218578\n",
      "[05/21/2025 16:55:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=299, batch=0 train loss <loss>=2.218578338623047\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] Epoch[299] Batch[5] avg_epoch_loss=2.214551\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=299, batch=5 train loss <loss>=2.2145511706670127\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] Epoch[299] Batch [5]#011Speed: 2514.94 samples/sec#011loss=2.214551\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] Epoch[299] Batch[10] avg_epoch_loss=2.188594\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=299, batch=10 train loss <loss>=2.157446193695068\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] Epoch[299] Batch [10]#011Speed: 2345.09 samples/sec#011loss=2.157446\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747846523.4928772, \"EndTime\": 1747846524.3248832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 831.6476345062256, \"count\": 1, \"min\": 831.6476345062256, \"max\": 831.6476345062256}}}\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1599.0653775361877 records/second\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] #progress_metric: host=algo-1, completed 75.0 % of epochs\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=299, train loss <loss>=2.1885943629524927\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] Epoch[300] Batch[0] avg_epoch_loss=2.315188\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=300, batch=0 train loss <loss>=2.315188407897949\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] Epoch[300] Batch[5] avg_epoch_loss=2.202624\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=300, batch=5 train loss <loss>=2.202624281247457\n",
      "[05/21/2025 16:55:24 INFO 140202337613632] Epoch[300] Batch [5]#011Speed: 2414.56 samples/sec#011loss=2.202624\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] Epoch[300] Batch[10] avg_epoch_loss=2.204994\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=300, batch=10 train loss <loss>=2.207836961746216\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] Epoch[300] Batch [10]#011Speed: 2694.38 samples/sec#011loss=2.207837\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747846524.3249407, \"EndTime\": 1747846525.1470745, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 821.8874931335449, \"count\": 1, \"min\": 821.8874931335449, \"max\": 821.8874931335449}}}\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1608.323301163212 records/second\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] #progress_metric: host=algo-1, completed 75.25 % of epochs\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=300, train loss <loss>=2.2049936814741655\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] Epoch[301] Batch[0] avg_epoch_loss=2.230026\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=301, batch=0 train loss <loss>=2.23002552986145\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] Epoch[301] Batch[5] avg_epoch_loss=2.249046\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=301, batch=5 train loss <loss>=2.2490460872650146\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] Epoch[301] Batch [5]#011Speed: 2705.14 samples/sec#011loss=2.249046\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] Epoch[301] Batch[10] avg_epoch_loss=2.244365\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=301, batch=10 train loss <loss>=2.238747406005859\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] Epoch[301] Batch [10]#011Speed: 2534.17 samples/sec#011loss=2.238747\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747846525.1471329, \"EndTime\": 1747846525.9417756, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.3367958068848, \"count\": 1, \"min\": 794.3367958068848, \"max\": 794.3367958068848}}}\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1656.542527557252 records/second\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] #progress_metric: host=algo-1, completed 75.5 % of epochs\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=301, train loss <loss>=2.244364868510853\n",
      "[05/21/2025 16:55:25 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] Epoch[302] Batch[0] avg_epoch_loss=2.501186\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=302, batch=0 train loss <loss>=2.5011863708496094\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] Epoch[302] Batch[5] avg_epoch_loss=2.423883\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=302, batch=5 train loss <loss>=2.4238826831181846\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] Epoch[302] Batch [5]#011Speed: 2655.57 samples/sec#011loss=2.423883\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] Epoch[302] Batch[10] avg_epoch_loss=2.408204\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=302, batch=10 train loss <loss>=2.3893898487091065\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] Epoch[302] Batch [10]#011Speed: 2474.24 samples/sec#011loss=2.389390\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747846525.9418318, \"EndTime\": 1747846526.7477095, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 805.5546283721924, \"count\": 1, \"min\": 805.5546283721924, \"max\": 805.5546283721924}}}\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1689.3221916259633 records/second\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] #progress_metric: host=algo-1, completed 75.75 % of epochs\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=302, train loss <loss>=2.408204122023149\n",
      "[05/21/2025 16:55:26 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] Epoch[303] Batch[0] avg_epoch_loss=2.326063\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=303, batch=0 train loss <loss>=2.3260626792907715\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] Epoch[303] Batch[5] avg_epoch_loss=2.284793\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=303, batch=5 train loss <loss>=2.284793496131897\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] Epoch[303] Batch [5]#011Speed: 2587.53 samples/sec#011loss=2.284793\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] Epoch[303] Batch[10] avg_epoch_loss=2.273390\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=303, batch=10 train loss <loss>=2.259705829620361\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] Epoch[303] Batch [10]#011Speed: 2543.77 samples/sec#011loss=2.259706\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747846526.747774, \"EndTime\": 1747846527.5501049, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.0215034484863, \"count\": 1, \"min\": 802.0215034484863, \"max\": 802.0215034484863}}}\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1634.412535207416 records/second\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] #progress_metric: host=algo-1, completed 76.0 % of epochs\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=303, train loss <loss>=2.2733900113539263\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] Epoch[304] Batch[0] avg_epoch_loss=2.251456\n",
      "[05/21/2025 16:55:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=304, batch=0 train loss <loss>=2.251455783843994\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] Epoch[304] Batch[5] avg_epoch_loss=2.250033\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=304, batch=5 train loss <loss>=2.250033179918925\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] Epoch[304] Batch [5]#011Speed: 2349.13 samples/sec#011loss=2.250033\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] Epoch[304] Batch[10] avg_epoch_loss=2.249570\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=304, batch=10 train loss <loss>=2.2490134239196777\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] Epoch[304] Batch [10]#011Speed: 2529.83 samples/sec#011loss=2.249013\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] processed a total of 1375 examples\n",
      "#metrics {\"StartTime\": 1747846527.5501719, \"EndTime\": 1747846528.377495, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 826.948881149292, \"count\": 1, \"min\": 826.948881149292, \"max\": 826.948881149292}}}\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1662.5624163445852 records/second\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] #progress_metric: host=algo-1, completed 76.25 % of epochs\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=304, train loss <loss>=2.2495696544647217\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] Epoch[305] Batch[0] avg_epoch_loss=2.250850\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=305, batch=0 train loss <loss>=2.250850200653076\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] Epoch[305] Batch[5] avg_epoch_loss=2.189728\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=305, batch=5 train loss <loss>=2.189727862675985\n",
      "[05/21/2025 16:55:28 INFO 140202337613632] Epoch[305] Batch [5]#011Speed: 2814.61 samples/sec#011loss=2.189728\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] Epoch[305] Batch[10] avg_epoch_loss=2.234786\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=305, batch=10 train loss <loss>=2.288855457305908\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] Epoch[305] Batch [10]#011Speed: 2546.37 samples/sec#011loss=2.288855\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747846528.3775535, \"EndTime\": 1747846529.1625369, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.6815586090088, \"count\": 1, \"min\": 784.6815586090088, \"max\": 784.6815586090088}}}\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1665.4338329473012 records/second\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] #progress_metric: host=algo-1, completed 76.5 % of epochs\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=305, train loss <loss>=2.234785860235041\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] Epoch[306] Batch[0] avg_epoch_loss=2.536975\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=306, batch=0 train loss <loss>=2.536975145339966\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] Epoch[306] Batch[5] avg_epoch_loss=2.516128\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=306, batch=5 train loss <loss>=2.516127586364746\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] Epoch[306] Batch [5]#011Speed: 2649.92 samples/sec#011loss=2.516128\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] Epoch[306] Batch[10] avg_epoch_loss=2.630701\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=306, batch=10 train loss <loss>=2.768189239501953\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] Epoch[306] Batch [10]#011Speed: 2669.32 samples/sec#011loss=2.768189\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747846529.1625996, \"EndTime\": 1747846529.9474103, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.5442295074463, \"count\": 1, \"min\": 784.5442295074463, \"max\": 784.5442295074463}}}\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1679.7628049380796 records/second\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] #progress_metric: host=algo-1, completed 76.75 % of epochs\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=306, train loss <loss>=2.6307010650634766\n",
      "[05/21/2025 16:55:29 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] Epoch[307] Batch[0] avg_epoch_loss=2.532680\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=307, batch=0 train loss <loss>=2.532679557800293\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] Epoch[307] Batch[5] avg_epoch_loss=2.540245\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=307, batch=5 train loss <loss>=2.5402445793151855\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] Epoch[307] Batch [5]#011Speed: 2778.71 samples/sec#011loss=2.540245\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] Epoch[307] Batch[10] avg_epoch_loss=2.530333\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=307, batch=10 train loss <loss>=2.518438482284546\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] Epoch[307] Batch [10]#011Speed: 2615.07 samples/sec#011loss=2.518438\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747846529.9474716, \"EndTime\": 1747846530.7298732, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.1488380432129, \"count\": 1, \"min\": 782.1488380432129, \"max\": 782.1488380432129}}}\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1686.1896212670758 records/second\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] #progress_metric: host=algo-1, completed 77.0 % of epochs\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=307, train loss <loss>=2.5303327170285312\n",
      "[05/21/2025 16:55:30 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] Epoch[308] Batch[0] avg_epoch_loss=2.534242\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=308, batch=0 train loss <loss>=2.5342416763305664\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] Epoch[308] Batch[5] avg_epoch_loss=2.395012\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=308, batch=5 train loss <loss>=2.395012299219767\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] Epoch[308] Batch [5]#011Speed: 2779.74 samples/sec#011loss=2.395012\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] Epoch[308] Batch[10] avg_epoch_loss=2.399255\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=308, batch=10 train loss <loss>=2.4043456077575684\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] Epoch[308] Batch [10]#011Speed: 2653.73 samples/sec#011loss=2.404346\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747846530.7299333, \"EndTime\": 1747846531.5071757, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 776.9896984100342, \"count\": 1, \"min\": 776.9896984100342, \"max\": 776.9896984100342}}}\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1679.3703427456903 records/second\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] #progress_metric: host=algo-1, completed 77.25 % of epochs\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=308, train loss <loss>=2.399254712191495\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] Epoch[309] Batch[0] avg_epoch_loss=2.388517\n",
      "[05/21/2025 16:55:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=309, batch=0 train loss <loss>=2.388517141342163\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] Epoch[309] Batch[5] avg_epoch_loss=2.583916\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=309, batch=5 train loss <loss>=2.583916107813517\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] Epoch[309] Batch [5]#011Speed: 2815.58 samples/sec#011loss=2.583916\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] Epoch[309] Batch[10] avg_epoch_loss=2.562128\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=309, batch=10 train loss <loss>=2.5359817504882813\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] Epoch[309] Batch [10]#011Speed: 2515.64 samples/sec#011loss=2.535982\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747846531.5072348, \"EndTime\": 1747846532.290353, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.8562259674072, \"count\": 1, \"min\": 782.8562259674072, \"max\": 782.8562259674072}}}\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1694.8695415713162 records/second\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] #progress_metric: host=algo-1, completed 77.5 % of epochs\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=309, train loss <loss>=2.5621277635747735\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] Epoch[310] Batch[0] avg_epoch_loss=2.412195\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=310, batch=0 train loss <loss>=2.4121947288513184\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] Epoch[310] Batch[5] avg_epoch_loss=2.371495\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=310, batch=5 train loss <loss>=2.3714948892593384\n",
      "[05/21/2025 16:55:32 INFO 140202337613632] Epoch[310] Batch [5]#011Speed: 2711.99 samples/sec#011loss=2.371495\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] Epoch[310] Batch[10] avg_epoch_loss=2.314135\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=310, batch=10 train loss <loss>=2.245304226875305\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] Epoch[310] Batch [10]#011Speed: 2626.78 samples/sec#011loss=2.245304\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747846532.2904153, \"EndTime\": 1747846533.0799508, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.1919612884521, \"count\": 1, \"min\": 789.1919612884521, \"max\": 789.1919612884521}}}\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1642.0039595490439 records/second\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] #progress_metric: host=algo-1, completed 77.75 % of epochs\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=310, train loss <loss>=2.314135497266596\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] Epoch[311] Batch[0] avg_epoch_loss=2.266603\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=311, batch=0 train loss <loss>=2.2666025161743164\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] Epoch[311] Batch[5] avg_epoch_loss=2.293412\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=311, batch=5 train loss <loss>=2.293411652247111\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] Epoch[311] Batch [5]#011Speed: 2736.10 samples/sec#011loss=2.293412\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] Epoch[311] Batch[10] avg_epoch_loss=2.287162\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=311, batch=10 train loss <loss>=2.279663419723511\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] Epoch[311] Batch [10]#011Speed: 2572.37 samples/sec#011loss=2.279663\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747846533.0800092, \"EndTime\": 1747846533.8629086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.6485633850098, \"count\": 1, \"min\": 782.6485633850098, \"max\": 782.6485633850098}}}\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1702.996469431847 records/second\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] #progress_metric: host=algo-1, completed 78.0 % of epochs\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=311, train loss <loss>=2.2871624556454746\n",
      "[05/21/2025 16:55:33 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] Epoch[312] Batch[0] avg_epoch_loss=2.235827\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=312, batch=0 train loss <loss>=2.2358274459838867\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] Epoch[312] Batch[5] avg_epoch_loss=2.206454\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=312, batch=5 train loss <loss>=2.2064536015192666\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] Epoch[312] Batch [5]#011Speed: 2813.16 samples/sec#011loss=2.206454\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747846533.8629694, \"EndTime\": 1747846534.5988915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 735.6657981872559, \"count\": 1, \"min\": 735.6657981872559, \"max\": 735.6657981872559}}}\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1713.8724849352107 records/second\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] #progress_metric: host=algo-1, completed 78.25 % of epochs\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=312, train loss <loss>=2.1852581024169924\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] Epoch[313] Batch[0] avg_epoch_loss=2.260503\n",
      "[05/21/2025 16:55:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=313, batch=0 train loss <loss>=2.2605032920837402\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] Epoch[313] Batch[5] avg_epoch_loss=2.204709\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=313, batch=5 train loss <loss>=2.2047094901402793\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] Epoch[313] Batch [5]#011Speed: 2749.40 samples/sec#011loss=2.204709\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] Epoch[313] Batch[10] avg_epoch_loss=2.256122\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=313, batch=10 train loss <loss>=2.3178169250488283\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] Epoch[313] Batch [10]#011Speed: 2596.13 samples/sec#011loss=2.317817\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747846534.5989544, \"EndTime\": 1747846535.3857121, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.4656448364258, \"count\": 1, \"min\": 786.4656448364258, \"max\": 786.4656448364258}}}\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1699.823629850996 records/second\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] #progress_metric: host=algo-1, completed 78.5 % of epochs\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=313, train loss <loss>=2.256121960553256\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] Epoch[314] Batch[0] avg_epoch_loss=2.265974\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=314, batch=0 train loss <loss>=2.2659740447998047\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] Epoch[314] Batch[5] avg_epoch_loss=2.196003\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=314, batch=5 train loss <loss>=2.1960031191507974\n",
      "[05/21/2025 16:55:35 INFO 140202337613632] Epoch[314] Batch [5]#011Speed: 2717.81 samples/sec#011loss=2.196003\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] Epoch[314] Batch[10] avg_epoch_loss=2.179740\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=314, batch=10 train loss <loss>=2.1602251529693604\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] Epoch[314] Batch [10]#011Speed: 2497.45 samples/sec#011loss=2.160225\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] processed a total of 1387 examples\n",
      "#metrics {\"StartTime\": 1747846535.3857713, \"EndTime\": 1747846536.1946878, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 808.5837364196777, \"count\": 1, \"min\": 808.5837364196777, \"max\": 808.5837364196777}}}\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1715.153242870726 records/second\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] #progress_metric: host=algo-1, completed 78.75 % of epochs\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=314, train loss <loss>=2.179740407250144\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] Epoch[315] Batch[0] avg_epoch_loss=2.256889\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=315, batch=0 train loss <loss>=2.2568888664245605\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] Epoch[315] Batch[5] avg_epoch_loss=2.215419\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=315, batch=5 train loss <loss>=2.2154187758763633\n",
      "[05/21/2025 16:55:36 INFO 140202337613632] Epoch[315] Batch [5]#011Speed: 2485.00 samples/sec#011loss=2.215419\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] Epoch[315] Batch[10] avg_epoch_loss=2.190580\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=315, batch=10 train loss <loss>=2.160774564743042\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] Epoch[315] Batch [10]#011Speed: 2534.87 samples/sec#011loss=2.160775\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747846536.1947467, \"EndTime\": 1747846537.0059326, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.9264373779297, \"count\": 1, \"min\": 810.9264373779297, \"max\": 810.9264373779297}}}\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1614.0237637617038 records/second\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] #progress_metric: host=algo-1, completed 79.0 % of epochs\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=315, train loss <loss>=2.1905804980884898\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] Epoch[316] Batch[0] avg_epoch_loss=2.189281\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=316, batch=0 train loss <loss>=2.1892805099487305\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] Epoch[316] Batch[5] avg_epoch_loss=2.135111\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=316, batch=5 train loss <loss>=2.1351107358932495\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] Epoch[316] Batch [5]#011Speed: 2629.71 samples/sec#011loss=2.135111\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] Epoch[316] Batch[10] avg_epoch_loss=2.111939\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=316, batch=10 train loss <loss>=2.0841320753097534\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] Epoch[316] Batch [10]#011Speed: 2512.41 samples/sec#011loss=2.084132\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747846537.0059912, \"EndTime\": 1747846537.8132846, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 806.9727420806885, \"count\": 1, \"min\": 806.9727420806885, \"max\": 806.9727420806885}}}\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1635.5627400620726 records/second\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] #progress_metric: host=algo-1, completed 79.25 % of epochs\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=316, train loss <loss>=2.111938617446206\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:55:37 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_f3069aca-d0b2-41d1-8801-24865a8212ef-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846537.8133445, \"EndTime\": 1747846537.8226173, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.99195671081543, \"count\": 1, \"min\": 8.99195671081543, \"max\": 8.99195671081543}}}\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] Epoch[317] Batch[0] avg_epoch_loss=2.168838\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=317, batch=0 train loss <loss>=2.168837547302246\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] Epoch[317] Batch[5] avg_epoch_loss=2.157914\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=317, batch=5 train loss <loss>=2.1579136848449707\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] Epoch[317] Batch [5]#011Speed: 2691.41 samples/sec#011loss=2.157914\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] Epoch[317] Batch[10] avg_epoch_loss=2.166058\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=317, batch=10 train loss <loss>=2.1758304119110106\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] Epoch[317] Batch [10]#011Speed: 2537.32 samples/sec#011loss=2.175830\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] processed a total of 1362 examples\n",
      "#metrics {\"StartTime\": 1747846537.8226779, \"EndTime\": 1747846538.617189, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.4543361663818, \"count\": 1, \"min\": 794.4543361663818, \"max\": 794.4543361663818}}}\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1714.2011085241613 records/second\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] #progress_metric: host=algo-1, completed 79.5 % of epochs\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=317, train loss <loss>=2.166057651693171\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] Epoch[318] Batch[0] avg_epoch_loss=2.083616\n",
      "[05/21/2025 16:55:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=318, batch=0 train loss <loss>=2.083616256713867\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] Epoch[318] Batch[5] avg_epoch_loss=2.127485\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=318, batch=5 train loss <loss>=2.1274850765864053\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] Epoch[318] Batch [5]#011Speed: 2624.55 samples/sec#011loss=2.127485\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] Epoch[318] Batch[10] avg_epoch_loss=2.177449\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=318, batch=10 train loss <loss>=2.2374053478240965\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] Epoch[318] Batch [10]#011Speed: 2508.40 samples/sec#011loss=2.237405\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747846538.617244, \"EndTime\": 1747846539.420871, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.321361541748, \"count\": 1, \"min\": 803.321361541748, \"max\": 803.321361541748}}}\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1693.945138643045 records/second\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] #progress_metric: host=algo-1, completed 79.75 % of epochs\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=318, train loss <loss>=2.1774488362399014\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] Epoch[319] Batch[0] avg_epoch_loss=2.182828\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=319, batch=0 train loss <loss>=2.182828187942505\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] Epoch[319] Batch[5] avg_epoch_loss=2.207854\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=319, batch=5 train loss <loss>=2.2078535159428916\n",
      "[05/21/2025 16:55:39 INFO 140202337613632] Epoch[319] Batch [5]#011Speed: 2525.35 samples/sec#011loss=2.207854\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] Epoch[319] Batch[10] avg_epoch_loss=2.182764\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=319, batch=10 train loss <loss>=2.152656412124634\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] Epoch[319] Batch [10]#011Speed: 2707.96 samples/sec#011loss=2.152656\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747846539.4209666, \"EndTime\": 1747846540.221386, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.0771999359131, \"count\": 1, \"min\": 800.0771999359131, \"max\": 800.0771999359131}}}\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1622.0824233301662 records/second\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] #progress_metric: host=algo-1, completed 80.0 % of epochs\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=319, train loss <loss>=2.182763923298229\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] Epoch[320] Batch[0] avg_epoch_loss=2.440174\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=320, batch=0 train loss <loss>=2.440174102783203\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] Epoch[320] Batch[5] avg_epoch_loss=2.384937\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=320, batch=5 train loss <loss>=2.384936571121216\n",
      "[05/21/2025 16:55:40 INFO 140202337613632] Epoch[320] Batch [5]#011Speed: 2689.17 samples/sec#011loss=2.384937\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] Epoch[320] Batch[10] avg_epoch_loss=2.383826\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=320, batch=10 train loss <loss>=2.382493782043457\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] Epoch[320] Batch [10]#011Speed: 2413.77 samples/sec#011loss=2.382494\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747846540.2214837, \"EndTime\": 1747846541.0322216, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.4743957519531, \"count\": 1, \"min\": 810.4743957519531, \"max\": 810.4743957519531}}}\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1618.6278653594325 records/second\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] #progress_metric: host=algo-1, completed 80.25 % of epochs\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=320, train loss <loss>=2.3838262124495073\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] Epoch[321] Batch[0] avg_epoch_loss=2.306587\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=321, batch=0 train loss <loss>=2.306586742401123\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] Epoch[321] Batch[5] avg_epoch_loss=2.471104\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=321, batch=5 train loss <loss>=2.4711036682128906\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] Epoch[321] Batch [5]#011Speed: 2691.35 samples/sec#011loss=2.471104\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] Epoch[321] Batch[10] avg_epoch_loss=2.449942\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=321, batch=10 train loss <loss>=2.424547815322876\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] Epoch[321] Batch [10]#011Speed: 2599.41 samples/sec#011loss=2.424548\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747846541.032281, \"EndTime\": 1747846541.8255742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 793.0395603179932, \"count\": 1, \"min\": 793.0395603179932, \"max\": 793.0395603179932}}}\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1639.0841009062976 records/second\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] #progress_metric: host=algo-1, completed 80.5 % of epochs\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] #quality_metric: host=algo-1, epoch=321, train loss <loss>=2.4499419168992476\n",
      "[05/21/2025 16:55:41 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] Epoch[322] Batch[0] avg_epoch_loss=2.367352\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=322, batch=0 train loss <loss>=2.367351531982422\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] Epoch[322] Batch[5] avg_epoch_loss=2.434795\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=322, batch=5 train loss <loss>=2.4347949425379434\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] Epoch[322] Batch [5]#011Speed: 2474.06 samples/sec#011loss=2.434795\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] Epoch[322] Batch[10] avg_epoch_loss=2.420832\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=322, batch=10 train loss <loss>=2.404076862335205\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] Epoch[322] Batch [10]#011Speed: 2595.47 samples/sec#011loss=2.404077\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747846541.8256319, \"EndTime\": 1747846542.6383224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.4361038208008, \"count\": 1, \"min\": 812.4361038208008, \"max\": 812.4361038208008}}}\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1622.1105311295926 records/second\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] #progress_metric: host=algo-1, completed 80.75 % of epochs\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=322, train loss <loss>=2.4208321788094262\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] Epoch[323] Batch[0] avg_epoch_loss=2.220477\n",
      "[05/21/2025 16:55:42 INFO 140202337613632] #quality_metric: host=algo-1, epoch=323, batch=0 train loss <loss>=2.220477342605591\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] Epoch[323] Batch[5] avg_epoch_loss=2.299126\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=323, batch=5 train loss <loss>=2.299126148223877\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] Epoch[323] Batch [5]#011Speed: 2657.56 samples/sec#011loss=2.299126\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] Epoch[323] Batch[10] avg_epoch_loss=2.296042\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=323, batch=10 train loss <loss>=2.29234094619751\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] Epoch[323] Batch [10]#011Speed: 2664.58 samples/sec#011loss=2.292341\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747846542.6383796, \"EndTime\": 1747846543.4324563, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 793.7674522399902, \"count\": 1, \"min\": 793.7674522399902, \"max\": 793.7674522399902}}}\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1614.8992479757815 records/second\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] #progress_metric: host=algo-1, completed 81.0 % of epochs\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=323, train loss <loss>=2.296041965484619\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] Epoch[324] Batch[0] avg_epoch_loss=2.222372\n",
      "[05/21/2025 16:55:43 INFO 140202337613632] #quality_metric: host=algo-1, epoch=324, batch=0 train loss <loss>=2.2223715782165527\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] Epoch[324] Batch[5] avg_epoch_loss=2.253249\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=324, batch=5 train loss <loss>=2.2532489697138467\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] Epoch[324] Batch [5]#011Speed: 2274.87 samples/sec#011loss=2.253249\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] Epoch[324] Batch[10] avg_epoch_loss=2.214381\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=324, batch=10 train loss <loss>=2.1677385807037353\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] Epoch[324] Batch [10]#011Speed: 2541.14 samples/sec#011loss=2.167739\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747846543.4325173, \"EndTime\": 1747846544.27142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 838.6352062225342, \"count\": 1, \"min\": 838.6352062225342, \"max\": 838.6352062225342}}}\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1591.701971677724 records/second\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] #progress_metric: host=algo-1, completed 81.25 % of epochs\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=324, train loss <loss>=2.214380611072887\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] Epoch[325] Batch[0] avg_epoch_loss=2.144218\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=325, batch=0 train loss <loss>=2.1442184448242188\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] Epoch[325] Batch[5] avg_epoch_loss=2.196249\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] #quality_metric: host=algo-1, epoch=325, batch=5 train loss <loss>=2.196248730023702\n",
      "[05/21/2025 16:55:44 INFO 140202337613632] Epoch[325] Batch [5]#011Speed: 2656.97 samples/sec#011loss=2.196249\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] Epoch[325] Batch[10] avg_epoch_loss=2.227890\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=325, batch=10 train loss <loss>=2.2658596992492677\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] Epoch[325] Batch [10]#011Speed: 2489.01 samples/sec#011loss=2.265860\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747846544.2714825, \"EndTime\": 1747846545.0742486, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.4702072143555, \"count\": 1, \"min\": 802.4702072143555, \"max\": 802.4702072143555}}}\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1641.001055203293 records/second\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] #progress_metric: host=algo-1, completed 81.5 % of epochs\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=325, train loss <loss>=2.2278900796716865\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] Epoch[326] Batch[0] avg_epoch_loss=2.253657\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=326, batch=0 train loss <loss>=2.2536566257476807\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] Epoch[326] Batch[5] avg_epoch_loss=2.164209\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=326, batch=5 train loss <loss>=2.1642094055811563\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] Epoch[326] Batch [5]#011Speed: 2578.47 samples/sec#011loss=2.164209\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] Epoch[326] Batch[10] avg_epoch_loss=2.283623\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=326, batch=10 train loss <loss>=2.4269198417663573\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] Epoch[326] Batch [10]#011Speed: 2203.75 samples/sec#011loss=2.426920\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747846545.0743086, \"EndTime\": 1747846545.9173958, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 842.810869216919, \"count\": 1, \"min\": 842.810869216919, \"max\": 842.810869216919}}}\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1566.0250972174922 records/second\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] #progress_metric: host=algo-1, completed 81.75 % of epochs\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] #quality_metric: host=algo-1, epoch=326, train loss <loss>=2.2836232402107934\n",
      "[05/21/2025 16:55:45 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] Epoch[327] Batch[0] avg_epoch_loss=2.377260\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=327, batch=0 train loss <loss>=2.377260208129883\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] Epoch[327] Batch[5] avg_epoch_loss=2.575925\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=327, batch=5 train loss <loss>=2.575925429662069\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] Epoch[327] Batch [5]#011Speed: 2630.48 samples/sec#011loss=2.575925\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] Epoch[327] Batch[10] avg_epoch_loss=2.721706\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=327, batch=10 train loss <loss>=2.8966434001922607\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] Epoch[327] Batch [10]#011Speed: 2561.57 samples/sec#011loss=2.896643\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747846545.9174533, \"EndTime\": 1747846546.717509, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.8046875, \"count\": 1, \"min\": 799.8046875, \"max\": 799.8046875}}}\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1623.9698240441326 records/second\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] #progress_metric: host=algo-1, completed 82.0 % of epochs\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] #quality_metric: host=algo-1, epoch=327, train loss <loss>=2.7217063253576104\n",
      "[05/21/2025 16:55:46 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] Epoch[328] Batch[0] avg_epoch_loss=2.498794\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=328, batch=0 train loss <loss>=2.498793601989746\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] Epoch[328] Batch[5] avg_epoch_loss=2.530397\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=328, batch=5 train loss <loss>=2.5303972959518433\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] Epoch[328] Batch [5]#011Speed: 2625.60 samples/sec#011loss=2.530397\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] Epoch[328] Batch[10] avg_epoch_loss=2.481552\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=328, batch=10 train loss <loss>=2.4229370594024657\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] Epoch[328] Batch [10]#011Speed: 2521.02 samples/sec#011loss=2.422937\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747846546.7175672, \"EndTime\": 1747846547.516658, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.837423324585, \"count\": 1, \"min\": 798.837423324585, \"max\": 798.837423324585}}}\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1686.0152429098148 records/second\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] #progress_metric: host=algo-1, completed 82.25 % of epochs\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=328, train loss <loss>=2.4815517338839443\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] Epoch[329] Batch[0] avg_epoch_loss=2.444304\n",
      "[05/21/2025 16:55:47 INFO 140202337613632] #quality_metric: host=algo-1, epoch=329, batch=0 train loss <loss>=2.4443039894104004\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] Epoch[329] Batch[5] avg_epoch_loss=2.382545\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=329, batch=5 train loss <loss>=2.3825445969899497\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] Epoch[329] Batch [5]#011Speed: 2486.27 samples/sec#011loss=2.382545\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] Epoch[329] Batch[10] avg_epoch_loss=2.466620\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=329, batch=10 train loss <loss>=2.567510652542114\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] Epoch[329] Batch [10]#011Speed: 2572.42 samples/sec#011loss=2.567511\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747846547.516718, \"EndTime\": 1747846548.327025, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.0216388702393, \"count\": 1, \"min\": 810.0216388702393, \"max\": 810.0216388702393}}}\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1649.16633429787 records/second\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] #progress_metric: host=algo-1, completed 82.5 % of epochs\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=329, train loss <loss>=2.466620076786388\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] Epoch[330] Batch[0] avg_epoch_loss=2.283147\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=330, batch=0 train loss <loss>=2.283146619796753\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] Epoch[330] Batch[5] avg_epoch_loss=2.294487\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] #quality_metric: host=algo-1, epoch=330, batch=5 train loss <loss>=2.2944870789845786\n",
      "[05/21/2025 16:55:48 INFO 140202337613632] Epoch[330] Batch [5]#011Speed: 2670.46 samples/sec#011loss=2.294487\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] Epoch[330] Batch[10] avg_epoch_loss=2.153578\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=330, batch=10 train loss <loss>=1.9844862222671509\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] Epoch[330] Batch [10]#011Speed: 2621.40 samples/sec#011loss=1.984486\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747846548.32708, \"EndTime\": 1747846549.1205027, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 793.1253910064697, \"count\": 1, \"min\": 793.1253910064697, \"max\": 793.1253910064697}}}\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1637.6425981776856 records/second\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] #progress_metric: host=algo-1, completed 82.75 % of epochs\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=330, train loss <loss>=2.153577598658475\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] Epoch[331] Batch[0] avg_epoch_loss=2.221433\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=331, batch=0 train loss <loss>=2.221433401107788\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] Epoch[331] Batch[5] avg_epoch_loss=2.243753\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=331, batch=5 train loss <loss>=2.2437528371810913\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] Epoch[331] Batch [5]#011Speed: 2697.37 samples/sec#011loss=2.243753\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] Epoch[331] Batch[10] avg_epoch_loss=2.276161\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=331, batch=10 train loss <loss>=2.315050745010376\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] Epoch[331] Batch [10]#011Speed: 2505.41 samples/sec#011loss=2.315051\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747846549.1205623, \"EndTime\": 1747846549.9336534, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.8395080566406, \"count\": 1, \"min\": 812.8395080566406, \"max\": 812.8395080566406}}}\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1647.1319365991058 records/second\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] #progress_metric: host=algo-1, completed 83.0 % of epochs\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] #quality_metric: host=algo-1, epoch=331, train loss <loss>=2.2761609771034936\n",
      "[05/21/2025 16:55:49 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:50 INFO 140202337613632] Epoch[332] Batch[0] avg_epoch_loss=2.255297\n",
      "[05/21/2025 16:55:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=332, batch=0 train loss <loss>=2.2552969455718994\n",
      "[05/21/2025 16:55:50 INFO 140202337613632] Epoch[332] Batch[5] avg_epoch_loss=2.221198\n",
      "[05/21/2025 16:55:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=332, batch=5 train loss <loss>=2.221198320388794\n",
      "[05/21/2025 16:55:50 INFO 140202337613632] Epoch[332] Batch [5]#011Speed: 2754.60 samples/sec#011loss=2.221198\n",
      "[05/21/2025 16:55:50 INFO 140202337613632] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747846549.9337127, \"EndTime\": 1747846550.6941416, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 760.1728439331055, \"count\": 1, \"min\": 760.1728439331055, \"max\": 760.1728439331055}}}\n",
      "[05/21/2025 16:55:50 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1658.6220605732185 records/second\n",
      "[05/21/2025 16:55:50 INFO 140202337613632] #progress_metric: host=algo-1, completed 83.25 % of epochs\n",
      "[05/21/2025 16:55:50 INFO 140202337613632] #quality_metric: host=algo-1, epoch=332, train loss <loss>=2.2455816745758055\n",
      "[05/21/2025 16:55:50 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] Epoch[333] Batch[0] avg_epoch_loss=2.151153\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=333, batch=0 train loss <loss>=2.151153326034546\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] Epoch[333] Batch[5] avg_epoch_loss=2.163662\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=333, batch=5 train loss <loss>=2.1636618773142495\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] Epoch[333] Batch [5]#011Speed: 2704.62 samples/sec#011loss=2.163662\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] Epoch[333] Batch[10] avg_epoch_loss=2.128240\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=333, batch=10 train loss <loss>=2.0857330560684204\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] Epoch[333] Batch [10]#011Speed: 2618.54 samples/sec#011loss=2.085733\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747846550.6942074, \"EndTime\": 1747846551.4831944, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.6180877685547, \"count\": 1, \"min\": 788.6180877685547, \"max\": 788.6180877685547}}}\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1643.1917511188497 records/second\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] #progress_metric: host=algo-1, completed 83.5 % of epochs\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=333, train loss <loss>=2.1282396858388726\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] Epoch[334] Batch[0] avg_epoch_loss=2.234117\n",
      "[05/21/2025 16:55:51 INFO 140202337613632] #quality_metric: host=algo-1, epoch=334, batch=0 train loss <loss>=2.234117269515991\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] Epoch[334] Batch[5] avg_epoch_loss=2.203185\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=334, batch=5 train loss <loss>=2.2031849225362143\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] Epoch[334] Batch [5]#011Speed: 2634.94 samples/sec#011loss=2.203185\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] Epoch[334] Batch[10] avg_epoch_loss=2.245211\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=334, batch=10 train loss <loss>=2.2956418991088867\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] Epoch[334] Batch [10]#011Speed: 2464.82 samples/sec#011loss=2.295642\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747846551.483256, \"EndTime\": 1747846552.2840998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.5425930023193, \"count\": 1, \"min\": 800.5425930023193, \"max\": 800.5425930023193}}}\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1711.1736713396251 records/second\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] #progress_metric: host=algo-1, completed 83.75 % of epochs\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=334, train loss <loss>=2.245210820978338\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] Epoch[335] Batch[0] avg_epoch_loss=2.097000\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=335, batch=0 train loss <loss>=2.0970001220703125\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] Epoch[335] Batch[5] avg_epoch_loss=2.160368\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] #quality_metric: host=algo-1, epoch=335, batch=5 train loss <loss>=2.1603676875432334\n",
      "[05/21/2025 16:55:52 INFO 140202337613632] Epoch[335] Batch [5]#011Speed: 2646.69 samples/sec#011loss=2.160368\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] Epoch[335] Batch[10] avg_epoch_loss=2.207641\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=335, batch=10 train loss <loss>=2.2643686294555665\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] Epoch[335] Batch [10]#011Speed: 2661.29 samples/sec#011loss=2.264369\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747846552.284151, \"EndTime\": 1747846553.076381, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.9838428497314, \"count\": 1, \"min\": 791.9838428497314, \"max\": 791.9838428497314}}}\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1632.426744751658 records/second\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] #progress_metric: host=algo-1, completed 84.0 % of epochs\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=335, train loss <loss>=2.20764084295793\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] Epoch[336] Batch[0] avg_epoch_loss=2.159266\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=336, batch=0 train loss <loss>=2.1592659950256348\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] Epoch[336] Batch[5] avg_epoch_loss=2.230238\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=336, batch=5 train loss <loss>=2.2302375634511313\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] Epoch[336] Batch [5]#011Speed: 2687.52 samples/sec#011loss=2.230238\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] Epoch[336] Batch[10] avg_epoch_loss=2.223262\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=336, batch=10 train loss <loss>=2.2148908615112304\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] Epoch[336] Batch [10]#011Speed: 2230.85 samples/sec#011loss=2.214891\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747846553.0764399, \"EndTime\": 1747846553.905429, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 828.7353515625, \"count\": 1, \"min\": 828.7353515625, \"max\": 828.7353515625}}}\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1662.596077887641 records/second\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] #progress_metric: host=algo-1, completed 84.25 % of epochs\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] #quality_metric: host=algo-1, epoch=336, train loss <loss>=2.2232617898420854\n",
      "[05/21/2025 16:55:53 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] Epoch[337] Batch[0] avg_epoch_loss=2.221088\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=337, batch=0 train loss <loss>=2.221088409423828\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] Epoch[337] Batch[5] avg_epoch_loss=2.215192\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=337, batch=5 train loss <loss>=2.2151918411254883\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] Epoch[337] Batch [5]#011Speed: 2779.47 samples/sec#011loss=2.215192\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] Epoch[337] Batch[10] avg_epoch_loss=2.223094\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=337, batch=10 train loss <loss>=2.2325761795043944\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] Epoch[337] Batch [10]#011Speed: 2660.47 samples/sec#011loss=2.232576\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747846553.9054887, \"EndTime\": 1747846554.6871183, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 781.3732624053955, \"count\": 1, \"min\": 781.3732624053955, \"max\": 781.3732624053955}}}\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1663.5400490464979 records/second\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] #progress_metric: host=algo-1, completed 84.5 % of epochs\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] #quality_metric: host=algo-1, epoch=337, train loss <loss>=2.2230938131159004\n",
      "[05/21/2025 16:55:54 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] Epoch[338] Batch[0] avg_epoch_loss=2.184280\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=338, batch=0 train loss <loss>=2.1842801570892334\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] Epoch[338] Batch[5] avg_epoch_loss=2.167711\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=338, batch=5 train loss <loss>=2.1677114168802896\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] Epoch[338] Batch [5]#011Speed: 2726.69 samples/sec#011loss=2.167711\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] Epoch[338] Batch[10] avg_epoch_loss=2.267119\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=338, batch=10 train loss <loss>=2.386407804489136\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] Epoch[338] Batch [10]#011Speed: 2650.37 samples/sec#011loss=2.386408\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747846554.6871805, \"EndTime\": 1747846555.4897654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.3197650909424, \"count\": 1, \"min\": 802.3197650909424, \"max\": 802.3197650909424}}}\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1655.0184359552084 records/second\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] #progress_metric: host=algo-1, completed 84.75 % of epochs\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=338, train loss <loss>=2.2671188657934014\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] Epoch[339] Batch[0] avg_epoch_loss=2.328193\n",
      "[05/21/2025 16:55:55 INFO 140202337613632] #quality_metric: host=algo-1, epoch=339, batch=0 train loss <loss>=2.328192949295044\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] Epoch[339] Batch[5] avg_epoch_loss=2.452455\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=339, batch=5 train loss <loss>=2.452455163002014\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] Epoch[339] Batch [5]#011Speed: 2691.07 samples/sec#011loss=2.452455\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] Epoch[339] Batch[10] avg_epoch_loss=2.453016\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=339, batch=10 train loss <loss>=2.4536894798278808\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] Epoch[339] Batch [10]#011Speed: 2611.96 samples/sec#011loss=2.453689\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747846555.489824, \"EndTime\": 1747846556.2805681, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.320873260498, \"count\": 1, \"min\": 790.320873260498, \"max\": 790.320873260498}}}\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1645.9404012062853 records/second\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] #progress_metric: host=algo-1, completed 85.0 % of epochs\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=339, train loss <loss>=2.4530162161046807\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] Epoch[340] Batch[0] avg_epoch_loss=2.338674\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=340, batch=0 train loss <loss>=2.3386740684509277\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] Epoch[340] Batch[5] avg_epoch_loss=2.384138\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] #quality_metric: host=algo-1, epoch=340, batch=5 train loss <loss>=2.3841382265090942\n",
      "[05/21/2025 16:55:56 INFO 140202337613632] Epoch[340] Batch [5]#011Speed: 2755.04 samples/sec#011loss=2.384138\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] Epoch[340] Batch[10] avg_epoch_loss=2.424147\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=340, batch=10 train loss <loss>=2.472158432006836\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] Epoch[340] Batch [10]#011Speed: 2393.38 samples/sec#011loss=2.472158\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747846556.280642, \"EndTime\": 1747846557.0842493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.2622337341309, \"count\": 1, \"min\": 803.2622337341309, \"max\": 803.2622337341309}}}\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1652.997830936502 records/second\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] #progress_metric: host=algo-1, completed 85.25 % of epochs\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=340, train loss <loss>=2.4241474108262495\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] Epoch[341] Batch[0] avg_epoch_loss=2.314034\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=341, batch=0 train loss <loss>=2.3140339851379395\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] Epoch[341] Batch[5] avg_epoch_loss=2.283635\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=341, batch=5 train loss <loss>=2.283635139465332\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] Epoch[341] Batch [5]#011Speed: 2620.36 samples/sec#011loss=2.283635\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] Epoch[341] Batch[10] avg_epoch_loss=2.305241\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=341, batch=10 train loss <loss>=2.3311681270599367\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] Epoch[341] Batch [10]#011Speed: 2525.83 samples/sec#011loss=2.331168\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747846557.0843406, \"EndTime\": 1747846557.8850498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.3506660461426, \"count\": 1, \"min\": 800.3506660461426, \"max\": 800.3506660461426}}}\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1686.5646959584237 records/second\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] #progress_metric: host=algo-1, completed 85.5 % of epochs\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] #quality_metric: host=algo-1, epoch=341, train loss <loss>=2.305241042917425\n",
      "[05/21/2025 16:55:57 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] Epoch[342] Batch[0] avg_epoch_loss=2.233449\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=342, batch=0 train loss <loss>=2.2334492206573486\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] Epoch[342] Batch[5] avg_epoch_loss=2.263334\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=342, batch=5 train loss <loss>=2.2633338371912637\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] Epoch[342] Batch [5]#011Speed: 2628.46 samples/sec#011loss=2.263334\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] Epoch[342] Batch[10] avg_epoch_loss=2.267291\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=342, batch=10 train loss <loss>=2.2720394134521484\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] Epoch[342] Batch [10]#011Speed: 2545.97 samples/sec#011loss=2.272039\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747846557.885111, \"EndTime\": 1747846558.6886475, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.2875061035156, \"count\": 1, \"min\": 803.2875061035156, \"max\": 803.2875061035156}}}\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1699.0779518204943 records/second\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] #progress_metric: host=algo-1, completed 85.75 % of epochs\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] #quality_metric: host=algo-1, epoch=342, train loss <loss>=2.2672909173098477\n",
      "[05/21/2025 16:55:58 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] Epoch[343] Batch[0] avg_epoch_loss=2.269052\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=343, batch=0 train loss <loss>=2.269052267074585\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] Epoch[343] Batch[5] avg_epoch_loss=2.221369\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=343, batch=5 train loss <loss>=2.2213693459828696\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] Epoch[343] Batch [5]#011Speed: 2472.59 samples/sec#011loss=2.221369\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] Epoch[343] Batch[10] avg_epoch_loss=2.168328\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=343, batch=10 train loss <loss>=2.1046793699264525\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] Epoch[343] Batch [10]#011Speed: 2417.09 samples/sec#011loss=2.104679\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747846558.6887069, \"EndTime\": 1747846559.5255709, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 836.5683555603027, \"count\": 1, \"min\": 836.5683555603027, \"max\": 836.5683555603027}}}\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1556.1670269997633 records/second\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] #progress_metric: host=algo-1, completed 86.0 % of epochs\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=343, train loss <loss>=2.1683284477754072\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] Epoch[344] Batch[0] avg_epoch_loss=2.215753\n",
      "[05/21/2025 16:55:59 INFO 140202337613632] #quality_metric: host=algo-1, epoch=344, batch=0 train loss <loss>=2.2157533168792725\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] Epoch[344] Batch[5] avg_epoch_loss=2.203355\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=344, batch=5 train loss <loss>=2.2033554712931314\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] Epoch[344] Batch [5]#011Speed: 2485.83 samples/sec#011loss=2.203355\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747846559.5256383, \"EndTime\": 1747846560.3062317, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.2770137786865, \"count\": 1, \"min\": 780.2770137786865, \"max\": 780.2770137786865}}}\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1623.5888166266384 records/second\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] #progress_metric: host=algo-1, completed 86.25 % of epochs\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=344, train loss <loss>=2.1793577671051025\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] Epoch[345] Batch[0] avg_epoch_loss=2.113207\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=345, batch=0 train loss <loss>=2.1132073402404785\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] Epoch[345] Batch[5] avg_epoch_loss=2.121033\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] #quality_metric: host=algo-1, epoch=345, batch=5 train loss <loss>=2.1210333506266275\n",
      "[05/21/2025 16:56:00 INFO 140202337613632] Epoch[345] Batch [5]#011Speed: 2621.85 samples/sec#011loss=2.121033\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] Epoch[345] Batch[10] avg_epoch_loss=2.156893\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=345, batch=10 train loss <loss>=2.1999252796173097\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] Epoch[345] Batch [10]#011Speed: 2526.60 samples/sec#011loss=2.199925\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747846560.306291, \"EndTime\": 1747846561.1094127, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.6828765869141, \"count\": 1, \"min\": 802.6828765869141, \"max\": 802.6828765869141}}}\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1651.7406905498221 records/second\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] #progress_metric: host=algo-1, completed 86.5 % of epochs\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=345, train loss <loss>=2.156893318349665\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] Epoch[346] Batch[0] avg_epoch_loss=2.117586\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=346, batch=0 train loss <loss>=2.117586374282837\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] Epoch[346] Batch[5] avg_epoch_loss=2.107192\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=346, batch=5 train loss <loss>=2.1071924765904746\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] Epoch[346] Batch [5]#011Speed: 2325.85 samples/sec#011loss=2.107192\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] Epoch[346] Batch[10] avg_epoch_loss=2.145927\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=346, batch=10 train loss <loss>=2.1924073696136475\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] Epoch[346] Batch [10]#011Speed: 2683.74 samples/sec#011loss=2.192407\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747846561.109484, \"EndTime\": 1747846561.9313312, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 821.5320110321045, \"count\": 1, \"min\": 821.5320110321045, \"max\": 821.5320110321045}}}\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1590.7560499713882 records/second\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] #progress_metric: host=algo-1, completed 86.75 % of epochs\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] #quality_metric: host=algo-1, epoch=346, train loss <loss>=2.145926518873735\n",
      "[05/21/2025 16:56:01 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] Epoch[347] Batch[0] avg_epoch_loss=2.114177\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=347, batch=0 train loss <loss>=2.1141769886016846\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] Epoch[347] Batch[5] avg_epoch_loss=2.129013\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=347, batch=5 train loss <loss>=2.1290129820505777\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] Epoch[347] Batch [5]#011Speed: 2719.97 samples/sec#011loss=2.129013\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] Epoch[347] Batch[10] avg_epoch_loss=2.212739\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=347, batch=10 train loss <loss>=2.31321005821228\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] Epoch[347] Batch [10]#011Speed: 2600.72 samples/sec#011loss=2.313210\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747846561.9313905, \"EndTime\": 1747846562.7177448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.5732440948486, \"count\": 1, \"min\": 785.5732440948486, \"max\": 785.5732440948486}}}\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1728.4714566328782 records/second\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] #progress_metric: host=algo-1, completed 87.0 % of epochs\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] #quality_metric: host=algo-1, epoch=347, train loss <loss>=2.2127389257604424\n",
      "[05/21/2025 16:56:02 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] Epoch[348] Batch[0] avg_epoch_loss=2.156982\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=348, batch=0 train loss <loss>=2.156982421875\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] Epoch[348] Batch[5] avg_epoch_loss=2.101119\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=348, batch=5 train loss <loss>=2.1011186440785727\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] Epoch[348] Batch [5]#011Speed: 2610.62 samples/sec#011loss=2.101119\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] Epoch[348] Batch[10] avg_epoch_loss=2.258716\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=348, batch=10 train loss <loss>=2.4478337287902834\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] Epoch[348] Batch [10]#011Speed: 2538.98 samples/sec#011loss=2.447834\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747846562.7178063, \"EndTime\": 1747846563.523963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 805.9020042419434, \"count\": 1, \"min\": 805.9020042419434, \"max\": 805.9020042419434}}}\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1662.536438819404 records/second\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] #progress_metric: host=algo-1, completed 87.25 % of epochs\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=348, train loss <loss>=2.258716409856623\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] Epoch[349] Batch[0] avg_epoch_loss=2.153730\n",
      "[05/21/2025 16:56:03 INFO 140202337613632] #quality_metric: host=algo-1, epoch=349, batch=0 train loss <loss>=2.1537296772003174\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] Epoch[349] Batch[5] avg_epoch_loss=2.139289\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=349, batch=5 train loss <loss>=2.139288862546285\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] Epoch[349] Batch [5]#011Speed: 2616.53 samples/sec#011loss=2.139289\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] Epoch[349] Batch[10] avg_epoch_loss=2.199668\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=349, batch=10 train loss <loss>=2.2721221923828123\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] Epoch[349] Batch [10]#011Speed: 2430.14 samples/sec#011loss=2.272122\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747846563.5240254, \"EndTime\": 1747846564.335502, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.1622333526611, \"count\": 1, \"min\": 811.1622333526611, \"max\": 811.1622333526611}}}\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1683.7792609076166 records/second\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] #progress_metric: host=algo-1, completed 87.5 % of epochs\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=349, train loss <loss>=2.1996676488356157\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] Epoch[350] Batch[0] avg_epoch_loss=2.060866\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=350, batch=0 train loss <loss>=2.060866355895996\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] Epoch[350] Batch[5] avg_epoch_loss=2.118508\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] #quality_metric: host=algo-1, epoch=350, batch=5 train loss <loss>=2.1185078223546348\n",
      "[05/21/2025 16:56:04 INFO 140202337613632] Epoch[350] Batch [5]#011Speed: 2529.94 samples/sec#011loss=2.118508\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] Epoch[350] Batch[10] avg_epoch_loss=2.108694\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=350, batch=10 train loss <loss>=2.0969176292419434\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] Epoch[350] Batch [10]#011Speed: 2478.44 samples/sec#011loss=2.096918\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747846564.3355734, \"EndTime\": 1747846565.1490152, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.0896091461182, \"count\": 1, \"min\": 813.0896091461182, \"max\": 813.0896091461182}}}\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1652.7968334667382 records/second\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] #progress_metric: host=algo-1, completed 87.75 % of epochs\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=350, train loss <loss>=2.1086940982125024\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_78ee4917-929a-4603-9d5e-4a101aae4a8d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846565.1490643, \"EndTime\": 1747846565.1579318, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.630514144897461, \"count\": 1, \"min\": 8.630514144897461, \"max\": 8.630514144897461}}}\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] Epoch[351] Batch[0] avg_epoch_loss=2.131907\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=351, batch=0 train loss <loss>=2.131906509399414\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] Epoch[351] Batch[5] avg_epoch_loss=2.119259\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=351, batch=5 train loss <loss>=2.1192586421966553\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] Epoch[351] Batch [5]#011Speed: 2700.01 samples/sec#011loss=2.119259\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] Epoch[351] Batch[10] avg_epoch_loss=2.169453\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=351, batch=10 train loss <loss>=2.2296869277954103\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] Epoch[351] Batch [10]#011Speed: 2342.91 samples/sec#011loss=2.229687\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747846565.1579833, \"EndTime\": 1747846565.9683712, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.3375434875488, \"count\": 1, \"min\": 810.3375434875488, \"max\": 810.3375434875488}}}\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1690.4709592256224 records/second\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] #progress_metric: host=algo-1, completed 88.0 % of epochs\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] #quality_metric: host=algo-1, epoch=351, train loss <loss>=2.1694533174688164\n",
      "[05/21/2025 16:56:05 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] Epoch[352] Batch[0] avg_epoch_loss=2.120092\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=352, batch=0 train loss <loss>=2.1200919151306152\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] Epoch[352] Batch[5] avg_epoch_loss=2.122745\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=352, batch=5 train loss <loss>=2.1227449973424277\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] Epoch[352] Batch [5]#011Speed: 2720.03 samples/sec#011loss=2.122745\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] Epoch[352] Batch[10] avg_epoch_loss=2.469053\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=352, batch=10 train loss <loss>=2.884623098373413\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] Epoch[352] Batch [10]#011Speed: 2733.37 samples/sec#011loss=2.884623\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747846565.9684296, \"EndTime\": 1747846566.7481802, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 779.5045375823975, \"count\": 1, \"min\": 779.5045375823975, \"max\": 779.5045375823975}}}\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1667.5367983240822 records/second\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] #progress_metric: host=algo-1, completed 88.25 % of epochs\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] #quality_metric: host=algo-1, epoch=352, train loss <loss>=2.4690532250837847\n",
      "[05/21/2025 16:56:06 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] Epoch[353] Batch[0] avg_epoch_loss=2.166869\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=353, batch=0 train loss <loss>=2.1668686866760254\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] Epoch[353] Batch[5] avg_epoch_loss=2.178476\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=353, batch=5 train loss <loss>=2.178476254145304\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] Epoch[353] Batch [5]#011Speed: 2481.09 samples/sec#011loss=2.178476\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] Epoch[353] Batch[10] avg_epoch_loss=2.142650\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=353, batch=10 train loss <loss>=2.0996574640274046\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] Epoch[353] Batch [10]#011Speed: 2565.50 samples/sec#011loss=2.099657\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747846566.7482398, \"EndTime\": 1747846567.560562, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.0708465576172, \"count\": 1, \"min\": 812.0708465576172, \"max\": 812.0708465576172}}}\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1599.4413217317785 records/second\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] #progress_metric: host=algo-1, completed 88.5 % of epochs\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=353, train loss <loss>=2.142649531364441\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] Epoch[354] Batch[0] avg_epoch_loss=2.173445\n",
      "[05/21/2025 16:56:07 INFO 140202337613632] #quality_metric: host=algo-1, epoch=354, batch=0 train loss <loss>=2.173445224761963\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] Epoch[354] Batch[5] avg_epoch_loss=2.140793\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=354, batch=5 train loss <loss>=2.140792647997538\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] Epoch[354] Batch [5]#011Speed: 2529.32 samples/sec#011loss=2.140793\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] Epoch[354] Batch[10] avg_epoch_loss=2.180909\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=354, batch=10 train loss <loss>=2.2290485858917237\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] Epoch[354] Batch [10]#011Speed: 2427.38 samples/sec#011loss=2.229049\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747846567.5606205, \"EndTime\": 1747846568.3751388, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.277172088623, \"count\": 1, \"min\": 814.277172088623, \"max\": 814.277172088623}}}\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1692.1116713016324 records/second\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] #progress_metric: host=algo-1, completed 88.75 % of epochs\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=354, train loss <loss>=2.1809089834039863\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] Epoch[355] Batch[0] avg_epoch_loss=2.106593\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=355, batch=0 train loss <loss>=2.1065926551818848\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] Epoch[355] Batch[5] avg_epoch_loss=2.127693\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] #quality_metric: host=algo-1, epoch=355, batch=5 train loss <loss>=2.1276928583780923\n",
      "[05/21/2025 16:56:08 INFO 140202337613632] Epoch[355] Batch [5]#011Speed: 2686.21 samples/sec#011loss=2.127693\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] Epoch[355] Batch[10] avg_epoch_loss=2.021955\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=355, batch=10 train loss <loss>=1.8950694799423218\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] Epoch[355] Batch [10]#011Speed: 2551.83 samples/sec#011loss=1.895069\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747846568.375199, \"EndTime\": 1747846569.1707366, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.2864170074463, \"count\": 1, \"min\": 795.2864170074463, \"max\": 795.2864170074463}}}\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1654.567710219302 records/second\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] #progress_metric: host=algo-1, completed 89.0 % of epochs\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=355, train loss <loss>=2.021954959089106\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] best epoch loss so far\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/state_458d20d9-b17f-411b-a085-fc439947fbca-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846569.1707957, \"EndTime\": 1747846569.1806374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.555339813232422, \"count\": 1, \"min\": 9.555339813232422, \"max\": 9.555339813232422}}}\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] Epoch[356] Batch[0] avg_epoch_loss=2.030653\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=356, batch=0 train loss <loss>=2.030653238296509\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] Epoch[356] Batch[5] avg_epoch_loss=2.097667\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=356, batch=5 train loss <loss>=2.0976668993631997\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] Epoch[356] Batch [5]#011Speed: 2711.90 samples/sec#011loss=2.097667\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] processed a total of 1263 examples\n",
      "#metrics {\"StartTime\": 1747846569.1806967, \"EndTime\": 1747846569.9130802, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 732.3248386383057, \"count\": 1, \"min\": 732.3248386383057, \"max\": 732.3248386383057}}}\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1724.4176840016446 records/second\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] #progress_metric: host=algo-1, completed 89.25 % of epochs\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] #quality_metric: host=algo-1, epoch=356, train loss <loss>=2.100768303871155\n",
      "[05/21/2025 16:56:09 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] Epoch[357] Batch[0] avg_epoch_loss=2.080607\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=357, batch=0 train loss <loss>=2.0806071758270264\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] Epoch[357] Batch[5] avg_epoch_loss=2.096435\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=357, batch=5 train loss <loss>=2.096434791882833\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] Epoch[357] Batch [5]#011Speed: 2774.77 samples/sec#011loss=2.096435\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] Epoch[357] Batch[10] avg_epoch_loss=2.052785\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=357, batch=10 train loss <loss>=2.000405216217041\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] Epoch[357] Batch [10]#011Speed: 2604.46 samples/sec#011loss=2.000405\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747846569.9131453, \"EndTime\": 1747846570.6952274, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 781.7928791046143, \"count\": 1, \"min\": 781.7928791046143, \"max\": 781.7928791046143}}}\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1681.8434593923419 records/second\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] #progress_metric: host=algo-1, completed 89.5 % of epochs\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] #quality_metric: host=algo-1, epoch=357, train loss <loss>=2.0527849847620185\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:10 INFO 140202337613632] Epoch[358] Batch[0] avg_epoch_loss=2.207289\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=358, batch=0 train loss <loss>=2.207288980484009\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] Epoch[358] Batch[5] avg_epoch_loss=2.233071\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=358, batch=5 train loss <loss>=2.2330711682637534\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] Epoch[358] Batch [5]#011Speed: 2547.53 samples/sec#011loss=2.233071\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] Epoch[358] Batch[10] avg_epoch_loss=2.213676\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=358, batch=10 train loss <loss>=2.190400743484497\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] Epoch[358] Batch [10]#011Speed: 2537.75 samples/sec#011loss=2.190401\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747846570.6952858, \"EndTime\": 1747846571.5039656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 808.4280490875244, \"count\": 1, \"min\": 808.4280490875244, \"max\": 808.4280490875244}}}\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1635.0938860797903 records/second\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] #progress_metric: host=algo-1, completed 89.75 % of epochs\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=358, train loss <loss>=2.213675520636819\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] Epoch[359] Batch[0] avg_epoch_loss=2.128615\n",
      "[05/21/2025 16:56:11 INFO 140202337613632] #quality_metric: host=algo-1, epoch=359, batch=0 train loss <loss>=2.128614902496338\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] Epoch[359] Batch[5] avg_epoch_loss=2.142107\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=359, batch=5 train loss <loss>=2.1421071688334146\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] Epoch[359] Batch [5]#011Speed: 2754.11 samples/sec#011loss=2.142107\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] Epoch[359] Batch[10] avg_epoch_loss=2.435006\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=359, batch=10 train loss <loss>=2.7864851474761965\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] Epoch[359] Batch [10]#011Speed: 2643.42 samples/sec#011loss=2.786485\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747846571.504026, \"EndTime\": 1747846572.2844255, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.0605297088623, \"count\": 1, \"min\": 780.0605297088623, \"max\": 780.0605297088623}}}\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1650.9475377572412 records/second\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] #progress_metric: host=algo-1, completed 90.0 % of epochs\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=359, train loss <loss>=2.435006250034679\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] Epoch[360] Batch[0] avg_epoch_loss=2.155157\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=360, batch=0 train loss <loss>=2.1551568508148193\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] Epoch[360] Batch[5] avg_epoch_loss=2.225102\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] #quality_metric: host=algo-1, epoch=360, batch=5 train loss <loss>=2.2251023054122925\n",
      "[05/21/2025 16:56:12 INFO 140202337613632] Epoch[360] Batch [5]#011Speed: 2634.93 samples/sec#011loss=2.225102\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] Epoch[360] Batch[10] avg_epoch_loss=2.240981\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=360, batch=10 train loss <loss>=2.2600362300872803\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] Epoch[360] Batch [10]#011Speed: 2405.96 samples/sec#011loss=2.260036\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747846572.2844882, \"EndTime\": 1747846573.0949028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.0066184997559, \"count\": 1, \"min\": 810.0066184997559, \"max\": 810.0066184997559}}}\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1684.9755121609248 records/second\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] #progress_metric: host=algo-1, completed 90.25 % of epochs\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=360, train loss <loss>=2.2409813620827417\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] Epoch[361] Batch[0] avg_epoch_loss=2.115921\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=361, batch=0 train loss <loss>=2.1159207820892334\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] Epoch[361] Batch[5] avg_epoch_loss=2.168784\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=361, batch=5 train loss <loss>=2.168783982594808\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] Epoch[361] Batch [5]#011Speed: 2630.39 samples/sec#011loss=2.168784\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] Epoch[361] Batch[10] avg_epoch_loss=2.129663\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=361, batch=10 train loss <loss>=2.0827174186706543\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] Epoch[361] Batch [10]#011Speed: 2540.38 samples/sec#011loss=2.082717\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747846573.0949652, \"EndTime\": 1747846573.895297, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.9417781829834, \"count\": 1, \"min\": 799.9417781829834, \"max\": 799.9417781829834}}}\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1632.4178790634912 records/second\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] #progress_metric: host=algo-1, completed 90.5 % of epochs\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] #quality_metric: host=algo-1, epoch=361, train loss <loss>=2.1296628171747383\n",
      "[05/21/2025 16:56:13 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] Epoch[362] Batch[0] avg_epoch_loss=2.097744\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=362, batch=0 train loss <loss>=2.0977444648742676\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] Epoch[362] Batch[5] avg_epoch_loss=2.105490\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=362, batch=5 train loss <loss>=2.1054904460906982\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] Epoch[362] Batch [5]#011Speed: 2640.75 samples/sec#011loss=2.105490\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] Epoch[362] Batch[10] avg_epoch_loss=2.136258\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=362, batch=10 train loss <loss>=2.1731783390045165\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] Epoch[362] Batch [10]#011Speed: 2501.95 samples/sec#011loss=2.173178\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747846573.8953612, \"EndTime\": 1747846574.7010362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 805.3090572357178, \"count\": 1, \"min\": 805.3090572357178, \"max\": 805.3090572357178}}}\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1651.3579802509294 records/second\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] #progress_metric: host=algo-1, completed 90.75 % of epochs\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] #quality_metric: host=algo-1, epoch=362, train loss <loss>=2.136257670142434\n",
      "[05/21/2025 16:56:14 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] Epoch[363] Batch[0] avg_epoch_loss=2.260055\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=363, batch=0 train loss <loss>=2.260054588317871\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] Epoch[363] Batch[5] avg_epoch_loss=2.169177\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=363, batch=5 train loss <loss>=2.1691768169403076\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] Epoch[363] Batch [5]#011Speed: 2645.22 samples/sec#011loss=2.169177\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] Epoch[363] Batch[10] avg_epoch_loss=2.166220\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=363, batch=10 train loss <loss>=2.162672281265259\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] Epoch[363] Batch [10]#011Speed: 2532.67 samples/sec#011loss=2.162672\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747846574.7010915, \"EndTime\": 1747846575.501152, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.6914386749268, \"count\": 1, \"min\": 799.6914386749268, \"max\": 799.6914386749268}}}\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1664.2019286147815 records/second\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] #progress_metric: host=algo-1, completed 91.0 % of epochs\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=363, train loss <loss>=2.1662202098152856\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] Epoch[364] Batch[0] avg_epoch_loss=2.059988\n",
      "[05/21/2025 16:56:15 INFO 140202337613632] #quality_metric: host=algo-1, epoch=364, batch=0 train loss <loss>=2.059988498687744\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] Epoch[364] Batch[5] avg_epoch_loss=2.095914\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=364, batch=5 train loss <loss>=2.0959139664967856\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] Epoch[364] Batch [5]#011Speed: 2599.65 samples/sec#011loss=2.095914\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] Epoch[364] Batch[10] avg_epoch_loss=2.115379\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=364, batch=10 train loss <loss>=2.1387372970581056\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] Epoch[364] Batch [10]#011Speed: 2319.92 samples/sec#011loss=2.138737\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] processed a total of 1372 examples\n",
      "#metrics {\"StartTime\": 1747846575.501212, \"EndTime\": 1747846576.326365, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 824.9013423919678, \"count\": 1, \"min\": 824.9013423919678, \"max\": 824.9013423919678}}}\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1663.0451057287437 records/second\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] #progress_metric: host=algo-1, completed 91.25 % of epochs\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=364, train loss <loss>=2.115379116751931\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] Epoch[365] Batch[0] avg_epoch_loss=2.097434\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=365, batch=0 train loss <loss>=2.0974338054656982\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] Epoch[365] Batch[5] avg_epoch_loss=2.081083\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] #quality_metric: host=algo-1, epoch=365, batch=5 train loss <loss>=2.081083138783773\n",
      "[05/21/2025 16:56:16 INFO 140202337613632] Epoch[365] Batch [5]#011Speed: 2602.04 samples/sec#011loss=2.081083\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] Epoch[365] Batch[10] avg_epoch_loss=2.149133\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=365, batch=10 train loss <loss>=2.2307921648025513\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] Epoch[365] Batch [10]#011Speed: 2359.44 samples/sec#011loss=2.230792\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] processed a total of 1383 examples\n",
      "#metrics {\"StartTime\": 1747846576.3264246, \"EndTime\": 1747846577.1457784, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 818.9890384674072, \"count\": 1, \"min\": 818.9890384674072, \"max\": 818.9890384674072}}}\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1688.4849283647604 records/second\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] #progress_metric: host=algo-1, completed 91.5 % of epochs\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=365, train loss <loss>=2.1491326960650357\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] Epoch[366] Batch[0] avg_epoch_loss=2.054345\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=366, batch=0 train loss <loss>=2.0543453693389893\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] Epoch[366] Batch[5] avg_epoch_loss=2.072023\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=366, batch=5 train loss <loss>=2.072022795677185\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] Epoch[366] Batch [5]#011Speed: 2652.69 samples/sec#011loss=2.072023\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] Epoch[366] Batch[10] avg_epoch_loss=2.205479\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=366, batch=10 train loss <loss>=2.365626335144043\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] Epoch[366] Batch [10]#011Speed: 2518.21 samples/sec#011loss=2.365626\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747846577.1458378, \"EndTime\": 1747846577.9515588, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 805.3402900695801, \"count\": 1, \"min\": 805.3402900695801, \"max\": 805.3402900695801}}}\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1605.3632948690397 records/second\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] #progress_metric: host=algo-1, completed 91.75 % of epochs\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] #quality_metric: host=algo-1, epoch=366, train loss <loss>=2.2054789499803023\n",
      "[05/21/2025 16:56:17 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] Epoch[367] Batch[0] avg_epoch_loss=2.236342\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=367, batch=0 train loss <loss>=2.236342191696167\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] Epoch[367] Batch[5] avg_epoch_loss=2.203625\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=367, batch=5 train loss <loss>=2.203625202178955\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] Epoch[367] Batch [5]#011Speed: 2694.51 samples/sec#011loss=2.203625\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] Epoch[367] Batch[10] avg_epoch_loss=2.201944\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=367, batch=10 train loss <loss>=2.1999276161193846\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] Epoch[367] Batch [10]#011Speed: 2613.58 samples/sec#011loss=2.199928\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747846577.951614, \"EndTime\": 1747846578.7422915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.4481887817383, \"count\": 1, \"min\": 790.4481887817383, \"max\": 790.4481887817383}}}\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1635.6017556246065 records/second\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] #progress_metric: host=algo-1, completed 92.0 % of epochs\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] #quality_metric: host=algo-1, epoch=367, train loss <loss>=2.2019444812427866\n",
      "[05/21/2025 16:56:18 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] Epoch[368] Batch[0] avg_epoch_loss=2.173903\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=368, batch=0 train loss <loss>=2.173902750015259\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] Epoch[368] Batch[5] avg_epoch_loss=2.203950\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=368, batch=5 train loss <loss>=2.2039496501286826\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] Epoch[368] Batch [5]#011Speed: 2535.23 samples/sec#011loss=2.203950\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] Epoch[368] Batch[10] avg_epoch_loss=2.288027\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=368, batch=10 train loss <loss>=2.3889198780059813\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] Epoch[368] Batch [10]#011Speed: 2589.49 samples/sec#011loss=2.388920\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747846578.7423499, \"EndTime\": 1747846579.5440176, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.3765811920166, \"count\": 1, \"min\": 801.3765811920166, \"max\": 801.3765811920166}}}\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1656.96610321256 records/second\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] #progress_metric: host=algo-1, completed 92.25 % of epochs\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=368, train loss <loss>=2.2880270264365454\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] Epoch[369] Batch[0] avg_epoch_loss=2.089865\n",
      "[05/21/2025 16:56:19 INFO 140202337613632] #quality_metric: host=algo-1, epoch=369, batch=0 train loss <loss>=2.089864730834961\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] Epoch[369] Batch[5] avg_epoch_loss=2.139043\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=369, batch=5 train loss <loss>=2.1390434900919595\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] Epoch[369] Batch [5]#011Speed: 2710.54 samples/sec#011loss=2.139043\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] Epoch[369] Batch[10] avg_epoch_loss=2.110162\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=369, batch=10 train loss <loss>=2.0755040884017943\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] Epoch[369] Batch [10]#011Speed: 2465.54 samples/sec#011loss=2.075504\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747846579.5440772, \"EndTime\": 1747846580.3418207, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.4953651428223, \"count\": 1, \"min\": 797.4953651428223, \"max\": 797.4953651428223}}}\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1685.092878311136 records/second\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] #progress_metric: host=algo-1, completed 92.5 % of epochs\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=369, train loss <loss>=2.1101619438691572\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] Epoch[370] Batch[0] avg_epoch_loss=2.096184\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=370, batch=0 train loss <loss>=2.096184492111206\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] Epoch[370] Batch[5] avg_epoch_loss=2.094150\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] #quality_metric: host=algo-1, epoch=370, batch=5 train loss <loss>=2.0941502253214517\n",
      "[05/21/2025 16:56:20 INFO 140202337613632] Epoch[370] Batch [5]#011Speed: 2714.06 samples/sec#011loss=2.094150\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] Epoch[370] Batch[10] avg_epoch_loss=2.124596\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=370, batch=10 train loss <loss>=2.161131763458252\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] Epoch[370] Batch [10]#011Speed: 2464.58 samples/sec#011loss=2.161132\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747846580.341879, \"EndTime\": 1747846581.1431715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.0027408599854, \"count\": 1, \"min\": 801.0027408599854, \"max\": 801.0027408599854}}}\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1626.5314230272438 records/second\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] #progress_metric: host=algo-1, completed 92.75 % of epochs\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=370, train loss <loss>=2.1245963790199975\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] Epoch[371] Batch[0] avg_epoch_loss=2.066695\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=371, batch=0 train loss <loss>=2.066694736480713\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] Epoch[371] Batch[5] avg_epoch_loss=2.102464\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=371, batch=5 train loss <loss>=2.1024643580118814\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] Epoch[371] Batch [5]#011Speed: 2746.83 samples/sec#011loss=2.102464\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] Epoch[371] Batch[10] avg_epoch_loss=2.243564\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=371, batch=10 train loss <loss>=2.412882661819458\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] Epoch[371] Batch [10]#011Speed: 2625.86 samples/sec#011loss=2.412883\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747846581.1432312, \"EndTime\": 1747846581.9261072, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.6104164123535, \"count\": 1, \"min\": 782.6104164123535, \"max\": 782.6104164123535}}}\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1685.1988233462864 records/second\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] #progress_metric: host=algo-1, completed 93.0 % of epochs\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] #quality_metric: host=algo-1, epoch=371, train loss <loss>=2.243563587015325\n",
      "[05/21/2025 16:56:21 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:22 INFO 140202337613632] Epoch[372] Batch[0] avg_epoch_loss=2.071423\n",
      "[05/21/2025 16:56:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=372, batch=0 train loss <loss>=2.071422815322876\n",
      "[05/21/2025 16:56:22 INFO 140202337613632] Epoch[372] Batch[5] avg_epoch_loss=2.127902\n",
      "[05/21/2025 16:56:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=372, batch=5 train loss <loss>=2.1279019514719644\n",
      "[05/21/2025 16:56:22 INFO 140202337613632] Epoch[372] Batch [5]#011Speed: 2383.99 samples/sec#011loss=2.127902\n",
      "[05/21/2025 16:56:22 INFO 140202337613632] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747846581.9261637, \"EndTime\": 1747846582.715929, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.5119190216064, \"count\": 1, \"min\": 789.5119190216064, \"max\": 789.5119190216064}}}\n",
      "[05/21/2025 16:56:22 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1618.5280524564978 records/second\n",
      "[05/21/2025 16:56:22 INFO 140202337613632] #progress_metric: host=algo-1, completed 93.25 % of epochs\n",
      "[05/21/2025 16:56:22 INFO 140202337613632] #quality_metric: host=algo-1, epoch=372, train loss <loss>=2.11904399394989\n",
      "[05/21/2025 16:56:22 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] Epoch[373] Batch[0] avg_epoch_loss=2.038130\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=373, batch=0 train loss <loss>=2.0381298065185547\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] Epoch[373] Batch[5] avg_epoch_loss=2.076853\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=373, batch=5 train loss <loss>=2.076852639516195\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] Epoch[373] Batch [5]#011Speed: 2611.44 samples/sec#011loss=2.076853\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] Epoch[373] Batch[10] avg_epoch_loss=2.101039\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=373, batch=10 train loss <loss>=2.1300620555877687\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] Epoch[373] Batch [10]#011Speed: 2444.58 samples/sec#011loss=2.130062\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747846582.7159932, \"EndTime\": 1747846583.5243077, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.9738616943359, \"count\": 1, \"min\": 807.9738616943359, \"max\": 807.9738616943359}}}\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1705.3361654542423 records/second\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] #progress_metric: host=algo-1, completed 93.5 % of epochs\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=373, train loss <loss>=2.1010387377305464\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] Epoch[374] Batch[0] avg_epoch_loss=2.148129\n",
      "[05/21/2025 16:56:23 INFO 140202337613632] #quality_metric: host=algo-1, epoch=374, batch=0 train loss <loss>=2.1481289863586426\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] Epoch[374] Batch[5] avg_epoch_loss=2.108577\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=374, batch=5 train loss <loss>=2.1085772116978965\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] Epoch[374] Batch [5]#011Speed: 2700.86 samples/sec#011loss=2.108577\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747846583.5243578, \"EndTime\": 1747846584.2726588, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 748.051643371582, \"count\": 1, \"min\": 748.051643371582, \"max\": 748.051643371582}}}\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1701.52964878568 records/second\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] #progress_metric: host=algo-1, completed 93.75 % of epochs\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=374, train loss <loss>=2.0898109674453735\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] Epoch[375] Batch[0] avg_epoch_loss=2.043891\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=375, batch=0 train loss <loss>=2.043890953063965\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] Epoch[375] Batch[5] avg_epoch_loss=2.053188\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] #quality_metric: host=algo-1, epoch=375, batch=5 train loss <loss>=2.0531877279281616\n",
      "[05/21/2025 16:56:24 INFO 140202337613632] Epoch[375] Batch [5]#011Speed: 2674.25 samples/sec#011loss=2.053188\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] Epoch[375] Batch[10] avg_epoch_loss=2.237890\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=375, batch=10 train loss <loss>=2.4595319271087646\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] Epoch[375] Batch [10]#011Speed: 2441.53 samples/sec#011loss=2.459532\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747846584.272726, \"EndTime\": 1747846585.075438, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.4168014526367, \"count\": 1, \"min\": 802.4168014526367, \"max\": 802.4168014526367}}}\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1666.0317146436685 records/second\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] #progress_metric: host=algo-1, completed 94.0 % of epochs\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=375, train loss <loss>=2.2378896366466177\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] Epoch[376] Batch[0] avg_epoch_loss=2.339625\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=376, batch=0 train loss <loss>=2.339625358581543\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] Epoch[376] Batch[5] avg_epoch_loss=2.209794\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=376, batch=5 train loss <loss>=2.209794044494629\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] Epoch[376] Batch [5]#011Speed: 2665.71 samples/sec#011loss=2.209794\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] Epoch[376] Batch[10] avg_epoch_loss=2.231993\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=376, batch=10 train loss <loss>=2.258632278442383\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] Epoch[376] Batch [10]#011Speed: 2500.98 samples/sec#011loss=2.258632\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] processed a total of 1379 examples\n",
      "#metrics {\"StartTime\": 1747846585.0754983, \"EndTime\": 1747846585.884293, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 808.5470199584961, \"count\": 1, \"min\": 808.5470199584961, \"max\": 808.5470199584961}}}\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1705.341453634558 records/second\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] #progress_metric: host=algo-1, completed 94.25 % of epochs\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] #quality_metric: host=algo-1, epoch=376, train loss <loss>=2.231993241743608\n",
      "[05/21/2025 16:56:25 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] Epoch[377] Batch[0] avg_epoch_loss=2.260870\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=377, batch=0 train loss <loss>=2.2608697414398193\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] Epoch[377] Batch[5] avg_epoch_loss=2.206090\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=377, batch=5 train loss <loss>=2.2060904502868652\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] Epoch[377] Batch [5]#011Speed: 2652.84 samples/sec#011loss=2.206090\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] Epoch[377] Batch[10] avg_epoch_loss=2.227542\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=377, batch=10 train loss <loss>=2.253284740447998\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] Epoch[377] Batch [10]#011Speed: 2693.38 samples/sec#011loss=2.253285\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747846585.884353, \"EndTime\": 1747846586.6713836, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.7798805236816, \"count\": 1, \"min\": 786.7798805236816, \"max\": 786.7798805236816}}}\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1627.9705160241174 records/second\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] #progress_metric: host=algo-1, completed 94.5 % of epochs\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=377, train loss <loss>=2.2275424003601074\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] Epoch[378] Batch[0] avg_epoch_loss=2.186417\n",
      "[05/21/2025 16:56:26 INFO 140202337613632] #quality_metric: host=algo-1, epoch=378, batch=0 train loss <loss>=2.1864171028137207\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] Epoch[378] Batch[5] avg_epoch_loss=2.082255\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=378, batch=5 train loss <loss>=2.082255164782206\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] Epoch[378] Batch [5]#011Speed: 2747.48 samples/sec#011loss=2.082255\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] Epoch[378] Batch[10] avg_epoch_loss=2.066683\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=378, batch=10 train loss <loss>=2.047996187210083\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] Epoch[378] Batch [10]#011Speed: 2575.10 samples/sec#011loss=2.047996\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747846586.6714432, \"EndTime\": 1747846587.457448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.7496738433838, \"count\": 1, \"min\": 785.7496738433838, \"max\": 785.7496738433838}}}\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1691.1890127613665 records/second\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] #progress_metric: host=algo-1, completed 94.75 % of epochs\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=378, train loss <loss>=2.066682902249423\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] Epoch[379] Batch[0] avg_epoch_loss=2.060784\n",
      "[05/21/2025 16:56:27 INFO 140202337613632] #quality_metric: host=algo-1, epoch=379, batch=0 train loss <loss>=2.060784101486206\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] Epoch[379] Batch[5] avg_epoch_loss=2.083835\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=379, batch=5 train loss <loss>=2.0838347673416138\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] Epoch[379] Batch [5]#011Speed: 2630.73 samples/sec#011loss=2.083835\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] Epoch[379] Batch[10] avg_epoch_loss=2.051145\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=379, batch=10 train loss <loss>=2.0119179487228394\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] Epoch[379] Batch [10]#011Speed: 2455.38 samples/sec#011loss=2.011918\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747846587.457508, \"EndTime\": 1747846588.2617817, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 804.0246963500977, \"count\": 1, \"min\": 804.0246963500977, \"max\": 804.0246963500977}}}\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1702.5002538034944 records/second\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] #progress_metric: host=algo-1, completed 95.0 % of epochs\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=379, train loss <loss>=2.05114530433308\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] Epoch[380] Batch[0] avg_epoch_loss=2.020510\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=380, batch=0 train loss <loss>=2.020509958267212\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] Epoch[380] Batch[5] avg_epoch_loss=2.075328\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] #quality_metric: host=algo-1, epoch=380, batch=5 train loss <loss>=2.0753283898035684\n",
      "[05/21/2025 16:56:28 INFO 140202337613632] Epoch[380] Batch [5]#011Speed: 2519.76 samples/sec#011loss=2.075328\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] Epoch[380] Batch[10] avg_epoch_loss=2.367202\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=380, batch=10 train loss <loss>=2.7174493789672853\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] Epoch[380] Batch [10]#011Speed: 2682.51 samples/sec#011loss=2.717449\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747846588.2618408, \"EndTime\": 1747846589.0597558, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.6655960083008, \"count\": 1, \"min\": 797.6655960083008, \"max\": 797.6655960083008}}}\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1665.9259915870323 records/second\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] #progress_metric: host=algo-1, completed 95.25 % of epochs\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=380, train loss <loss>=2.367201566696167\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] Epoch[381] Batch[0] avg_epoch_loss=2.131960\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=381, batch=0 train loss <loss>=2.131960391998291\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] Epoch[381] Batch[5] avg_epoch_loss=2.149828\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=381, batch=5 train loss <loss>=2.1498283545176187\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] Epoch[381] Batch [5]#011Speed: 2655.82 samples/sec#011loss=2.149828\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] Epoch[381] Batch[10] avg_epoch_loss=2.184957\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=381, batch=10 train loss <loss>=2.227111291885376\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] Epoch[381] Batch [10]#011Speed: 2592.90 samples/sec#011loss=2.227111\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747846589.0598161, \"EndTime\": 1747846589.8497672, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.7050380706787, \"count\": 1, \"min\": 789.7050380706787, \"max\": 789.7050380706787}}}\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1708.0414244374717 records/second\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] #progress_metric: host=algo-1, completed 95.5 % of epochs\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] #quality_metric: host=algo-1, epoch=381, train loss <loss>=2.1849569624120537\n",
      "[05/21/2025 16:56:29 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] Epoch[382] Batch[0] avg_epoch_loss=2.141961\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=382, batch=0 train loss <loss>=2.141960620880127\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] Epoch[382] Batch[5] avg_epoch_loss=2.119475\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=382, batch=5 train loss <loss>=2.1194753646850586\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] Epoch[382] Batch [5]#011Speed: 2755.20 samples/sec#011loss=2.119475\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] Epoch[382] Batch[10] avg_epoch_loss=2.152720\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=382, batch=10 train loss <loss>=2.192613983154297\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] Epoch[382] Batch [10]#011Speed: 2739.44 samples/sec#011loss=2.192614\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747846589.8498273, \"EndTime\": 1747846590.6263611, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 776.235818862915, \"count\": 1, \"min\": 776.235818862915, \"max\": 776.235818862915}}}\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1659.0969486328474 records/second\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] #progress_metric: host=algo-1, completed 95.75 % of epochs\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=382, train loss <loss>=2.152720191261985\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] Epoch[383] Batch[0] avg_epoch_loss=2.178944\n",
      "[05/21/2025 16:56:30 INFO 140202337613632] #quality_metric: host=algo-1, epoch=383, batch=0 train loss <loss>=2.1789441108703613\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] Epoch[383] Batch[5] avg_epoch_loss=2.113295\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=383, batch=5 train loss <loss>=2.113294839859009\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] Epoch[383] Batch [5]#011Speed: 2704.34 samples/sec#011loss=2.113295\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] Epoch[383] Batch[10] avg_epoch_loss=2.060380\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=383, batch=10 train loss <loss>=1.9968826293945312\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] Epoch[383] Batch [10]#011Speed: 2495.24 samples/sec#011loss=1.996883\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747846590.6264215, \"EndTime\": 1747846591.4252253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.3970642089844, \"count\": 1, \"min\": 798.3970642089844, \"max\": 798.3970642089844}}}\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1658.1385330710532 records/second\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] #progress_metric: host=algo-1, completed 96.0 % of epochs\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=383, train loss <loss>=2.0603801987387915\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] Epoch[384] Batch[0] avg_epoch_loss=2.103901\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=384, batch=0 train loss <loss>=2.1039013862609863\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] Epoch[384] Batch[5] avg_epoch_loss=2.104324\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] #quality_metric: host=algo-1, epoch=384, batch=5 train loss <loss>=2.1043235063552856\n",
      "[05/21/2025 16:56:31 INFO 140202337613632] Epoch[384] Batch [5]#011Speed: 2703.03 samples/sec#011loss=2.104324\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] Epoch[384] Batch[10] avg_epoch_loss=2.124417\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=384, batch=10 train loss <loss>=2.1485290050506594\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] Epoch[384] Batch [10]#011Speed: 2478.79 samples/sec#011loss=2.148529\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747846591.4252841, \"EndTime\": 1747846592.224098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.529863357544, \"count\": 1, \"min\": 798.529863357544, \"max\": 798.529863357544}}}\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1644.1052204192958 records/second\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] #progress_metric: host=algo-1, completed 96.25 % of epochs\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=384, train loss <loss>=2.1244169148531826\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] Epoch[385] Batch[0] avg_epoch_loss=2.099333\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=385, batch=0 train loss <loss>=2.099332809448242\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] Epoch[385] Batch[5] avg_epoch_loss=2.072531\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] #quality_metric: host=algo-1, epoch=385, batch=5 train loss <loss>=2.0725311040878296\n",
      "[05/21/2025 16:56:32 INFO 140202337613632] Epoch[385] Batch [5]#011Speed: 2734.60 samples/sec#011loss=2.072531\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] Epoch[385] Batch[10] avg_epoch_loss=2.125703\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=385, batch=10 train loss <loss>=2.189508628845215\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] Epoch[385] Batch [10]#011Speed: 2622.99 samples/sec#011loss=2.189509\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747846592.224152, \"EndTime\": 1747846593.0053308, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.9102535247803, \"count\": 1, \"min\": 780.9102535247803, \"max\": 780.9102535247803}}}\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1704.2286942359676 records/second\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] #progress_metric: host=algo-1, completed 96.5 % of epochs\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=385, train loss <loss>=2.1257027062502774\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] Epoch[386] Batch[0] avg_epoch_loss=2.074963\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=386, batch=0 train loss <loss>=2.074962854385376\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] Epoch[386] Batch[5] avg_epoch_loss=2.076469\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=386, batch=5 train loss <loss>=2.076468547185262\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] Epoch[386] Batch [5]#011Speed: 2466.29 samples/sec#011loss=2.076469\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] Epoch[386] Batch[10] avg_epoch_loss=2.049577\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=386, batch=10 train loss <loss>=2.0173068761825563\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] Epoch[386] Batch [10]#011Speed: 2534.90 samples/sec#011loss=2.017307\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747846593.0053904, \"EndTime\": 1747846593.821249, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 815.6061172485352, \"count\": 1, \"min\": 815.6061172485352, \"max\": 815.6061172485352}}}\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1662.391797644202 records/second\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] #progress_metric: host=algo-1, completed 96.75 % of epochs\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] #quality_metric: host=algo-1, epoch=386, train loss <loss>=2.0495768785476685\n",
      "[05/21/2025 16:56:33 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] Epoch[387] Batch[0] avg_epoch_loss=2.042129\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=387, batch=0 train loss <loss>=2.042128562927246\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] Epoch[387] Batch[5] avg_epoch_loss=2.038329\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=387, batch=5 train loss <loss>=2.0383287469546\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] Epoch[387] Batch [5]#011Speed: 2549.30 samples/sec#011loss=2.038329\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] Epoch[387] Batch[10] avg_epoch_loss=2.046643\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=387, batch=10 train loss <loss>=2.0566192388534548\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] Epoch[387] Batch [10]#011Speed: 2569.45 samples/sec#011loss=2.056619\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747846593.8213058, \"EndTime\": 1747846594.6315792, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.9706172943115, \"count\": 1, \"min\": 809.9706172943115, \"max\": 809.9706172943115}}}\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1589.9976754555717 records/second\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] #progress_metric: host=algo-1, completed 97.0 % of epochs\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=387, train loss <loss>=2.046642606908625\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] Epoch[388] Batch[0] avg_epoch_loss=2.087613\n",
      "[05/21/2025 16:56:34 INFO 140202337613632] #quality_metric: host=algo-1, epoch=388, batch=0 train loss <loss>=2.087613344192505\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] Epoch[388] Batch[5] avg_epoch_loss=2.104006\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=388, batch=5 train loss <loss>=2.1040058930714927\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] Epoch[388] Batch [5]#011Speed: 2667.71 samples/sec#011loss=2.104006\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] Epoch[388] Batch[10] avg_epoch_loss=2.170502\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=388, batch=10 train loss <loss>=2.250297498703003\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] Epoch[388] Batch [10]#011Speed: 2410.18 samples/sec#011loss=2.250297\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747846594.6316407, \"EndTime\": 1747846595.439547, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.5921535491943, \"count\": 1, \"min\": 807.5921535491943, \"max\": 807.5921535491943}}}\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1693.7233234809926 records/second\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] #progress_metric: host=algo-1, completed 97.25 % of epochs\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=388, train loss <loss>=2.1705020774494517\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] Epoch[389] Batch[0] avg_epoch_loss=2.145052\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=389, batch=0 train loss <loss>=2.145052194595337\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] Epoch[389] Batch[5] avg_epoch_loss=2.101818\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] #quality_metric: host=algo-1, epoch=389, batch=5 train loss <loss>=2.101818323135376\n",
      "[05/21/2025 16:56:35 INFO 140202337613632] Epoch[389] Batch [5]#011Speed: 2581.41 samples/sec#011loss=2.101818\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] Epoch[389] Batch[10] avg_epoch_loss=2.154700\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=389, batch=10 train loss <loss>=2.2181573152542113\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] Epoch[389] Batch [10]#011Speed: 2369.84 samples/sec#011loss=2.218157\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747846595.4396143, \"EndTime\": 1747846596.2617955, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 821.8770027160645, \"count\": 1, \"min\": 821.8770027160645, \"max\": 821.8770027160645}}}\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1648.484420956149 records/second\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] #progress_metric: host=algo-1, completed 97.5 % of epochs\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=389, train loss <loss>=2.154699683189392\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] Epoch[390] Batch[0] avg_epoch_loss=2.047561\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=390, batch=0 train loss <loss>=2.0475614070892334\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] Epoch[390] Batch[5] avg_epoch_loss=2.076444\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=390, batch=5 train loss <loss>=2.0764441887537637\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] Epoch[390] Batch [5]#011Speed: 2706.72 samples/sec#011loss=2.076444\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] processed a total of 1272 examples\n",
      "#metrics {\"StartTime\": 1747846596.261856, \"EndTime\": 1747846596.9901128, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 727.9658317565918, \"count\": 1, \"min\": 727.9658317565918, \"max\": 727.9658317565918}}}\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1747.1070213655005 records/second\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] #progress_metric: host=algo-1, completed 97.75 % of epochs\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] #quality_metric: host=algo-1, epoch=390, train loss <loss>=2.0788748979568483\n",
      "[05/21/2025 16:56:36 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:37 INFO 140202337613632] Epoch[391] Batch[0] avg_epoch_loss=2.013372\n",
      "[05/21/2025 16:56:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=391, batch=0 train loss <loss>=2.0133724212646484\n",
      "[05/21/2025 16:56:37 INFO 140202337613632] Epoch[391] Batch[5] avg_epoch_loss=2.065017\n",
      "[05/21/2025 16:56:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=391, batch=5 train loss <loss>=2.0650167067845664\n",
      "[05/21/2025 16:56:37 INFO 140202337613632] Epoch[391] Batch [5]#011Speed: 2674.61 samples/sec#011loss=2.065017\n",
      "[05/21/2025 16:56:37 INFO 140202337613632] processed a total of 1242 examples\n",
      "#metrics {\"StartTime\": 1747846596.990178, \"EndTime\": 1747846597.7170396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 726.487398147583, \"count\": 1, \"min\": 726.487398147583, \"max\": 726.487398147583}}}\n",
      "[05/21/2025 16:56:37 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1709.3873819065648 records/second\n",
      "[05/21/2025 16:56:37 INFO 140202337613632] #progress_metric: host=algo-1, completed 98.0 % of epochs\n",
      "[05/21/2025 16:56:37 INFO 140202337613632] #quality_metric: host=algo-1, epoch=391, train loss <loss>=2.0385165929794313\n",
      "[05/21/2025 16:56:37 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] Epoch[392] Batch[0] avg_epoch_loss=2.051486\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=392, batch=0 train loss <loss>=2.051485776901245\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] Epoch[392] Batch[5] avg_epoch_loss=2.058064\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=392, batch=5 train loss <loss>=2.0580643812815347\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] Epoch[392] Batch [5]#011Speed: 2718.96 samples/sec#011loss=2.058064\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] Epoch[392] Batch[10] avg_epoch_loss=2.086920\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=392, batch=10 train loss <loss>=2.1215473651885985\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] Epoch[392] Batch [10]#011Speed: 2653.54 samples/sec#011loss=2.121547\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747846597.7170975, \"EndTime\": 1747846598.5035803, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.1096858978271, \"count\": 1, \"min\": 786.1096858978271, \"max\": 786.1096858978271}}}\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1666.2314712832183 records/second\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] #progress_metric: host=algo-1, completed 98.25 % of epochs\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=392, train loss <loss>=2.086920283057473\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] Epoch[393] Batch[0] avg_epoch_loss=2.061061\n",
      "[05/21/2025 16:56:38 INFO 140202337613632] #quality_metric: host=algo-1, epoch=393, batch=0 train loss <loss>=2.061060905456543\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] Epoch[393] Batch[5] avg_epoch_loss=2.100933\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=393, batch=5 train loss <loss>=2.1009327173233032\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] Epoch[393] Batch [5]#011Speed: 2763.78 samples/sec#011loss=2.100933\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] Epoch[393] Batch[10] avg_epoch_loss=2.094730\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=393, batch=10 train loss <loss>=2.087285804748535\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] Epoch[393] Batch [10]#011Speed: 2284.52 samples/sec#011loss=2.087286\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] processed a total of 1410 examples\n",
      "#metrics {\"StartTime\": 1747846598.5036438, \"EndTime\": 1747846599.3624318, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 858.4880828857422, \"count\": 1, \"min\": 858.4880828857422, \"max\": 858.4880828857422}}}\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1642.1920186378952 records/second\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] #progress_metric: host=algo-1, completed 98.5 % of epochs\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=393, train loss <loss>=2.111746887365977\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] Epoch[394] Batch[0] avg_epoch_loss=1.968189\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=394, batch=0 train loss <loss>=1.9681888818740845\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] Epoch[394] Batch[5] avg_epoch_loss=2.043791\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] #quality_metric: host=algo-1, epoch=394, batch=5 train loss <loss>=2.043791194756826\n",
      "[05/21/2025 16:56:39 INFO 140202337613632] Epoch[394] Batch [5]#011Speed: 2803.82 samples/sec#011loss=2.043791\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Epoch[394] Batch[10] avg_epoch_loss=2.039690\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=394, batch=10 train loss <loss>=2.034767508506775\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Epoch[394] Batch [10]#011Speed: 2696.72 samples/sec#011loss=2.034768\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747846599.362518, \"EndTime\": 1747846600.1361005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 773.2648849487305, \"count\": 1, \"min\": 773.2648849487305, \"max\": 773.2648849487305}}}\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1674.5215182599306 records/second\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #progress_metric: host=algo-1, completed 98.75 % of epochs\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=394, train loss <loss>=2.0396895191886206\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Epoch[395] Batch[0] avg_epoch_loss=2.142861\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=395, batch=0 train loss <loss>=2.1428608894348145\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Epoch[395] Batch[5] avg_epoch_loss=2.068843\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=395, batch=5 train loss <loss>=2.068842649459839\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Epoch[395] Batch [5]#011Speed: 2760.81 samples/sec#011loss=2.068843\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] processed a total of 1246 examples\n",
      "#metrics {\"StartTime\": 1747846600.1361613, \"EndTime\": 1747846600.8732498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 736.7799282073975, \"count\": 1, \"min\": 736.7799282073975, \"max\": 736.7799282073975}}}\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #throughput_metric: host=algo-1, train throughput=1690.9205512693788 records/second\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #progress_metric: host=algo-1, completed 99.0 % of epochs\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #quality_metric: host=algo-1, epoch=395, train loss <loss>=2.0602167725563048\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] loss did not improve\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Loading parameters from best epoch (355)\n",
      "#metrics {\"StartTime\": 1747846600.873315, \"EndTime\": 1747846600.878228, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 4.585504531860352, \"count\": 1, \"min\": 4.585504531860352, \"max\": 4.585504531860352}}}\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] stopping training now\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Final loss: 2.021954959089106 (occurred at epoch 355)\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #quality_metric: host=algo-1, train final_loss <loss>=2.021954959089106\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Worker algo-1 finished training.\n",
      "[05/21/2025 16:56:40 WARNING 140202337613632] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747846600.8782856, \"EndTime\": 1747846600.9208863, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 42.114973068237305, \"count\": 1, \"min\": 42.114973068237305, \"max\": 42.114973068237305}}}\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747846600.920948, \"EndTime\": 1747846600.9403663, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 61.625003814697266, \"count\": 1, \"min\": 61.625003814697266, \"max\": 61.625003814697266}}}\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747846600.9404268, \"EndTime\": 1747846600.9438055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 3.3485889434814453, \"count\": 1, \"min\": 3.3485889434814453, \"max\": 3.3485889434814453}}}\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Successfully serialized the model for prediction.\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] #memory_usage::<batchbuffer> = 1.875 mb\n",
      "[05/21/2025 16:56:40 INFO 140202337613632] Evaluating model accuracy on testset using 100 samples\n",
      "#metrics {\"StartTime\": 1747846600.943851, \"EndTime\": 1747846600.945567, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}}}\n",
      "#metrics {\"StartTime\": 1747846600.94561, \"EndTime\": 1747846601.133384, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 187.83950805664062, \"count\": 1, \"min\": 187.83950805664062, \"max\": 187.83950805664062}}}\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, RMSE): 31.039336965641336\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, mean_absolute_QuantileLoss): 1490.7499346441693\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, mean_wQuantileLoss): 0.562759507226942\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, wQuantileLoss[0.1]): 0.25740831304199524\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, wQuantileLoss[0.2]): 0.3854067028401346\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, wQuantileLoss[0.3]): 0.45601314826027856\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, wQuantileLoss[0.4]): 0.5528640711789043\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, wQuantileLoss[0.5]): 0.6368819260516226\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, wQuantileLoss[0.6]): 0.6793993433991573\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, wQuantileLoss[0.7]): 0.7340681646310326\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, wQuantileLoss[0.8]): 0.7145202827525617\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #test_score (algo-1, wQuantileLoss[0.9]): 0.6482736128867909\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #quality_metric: host=algo-1, test RMSE <loss>=31.039336965641336\n",
      "[05/21/2025 16:56:41 INFO 140202337613632] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.562759507226942\n",
      "#metrics {\"StartTime\": 1747846601.133448, \"EndTime\": 1747846601.1425693, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 4.215240478515625, \"count\": 1, \"min\": 4.215240478515625, \"max\": 4.215240478515625}, \"totaltime\": {\"sum\": 315940.58632850647, \"count\": 1, \"min\": 315940.58632850647, \"max\": 315940.58632850647}}}\n",
      "\n",
      "2025-05-21 16:57:18 Uploading - Uploading generated training model\n",
      "2025-05-21 16:57:18 Completed - Training job completed\n",
      "Training seconds: 471\n",
      "Billable seconds: 471\n",
      "CPU times: total: 13.5 s\n",
      "Wall time: 8min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "bade9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-21 16:57:18 Starting - Preparing the instances for training\n",
      "2025-05-21 16:57:18 Downloading - Downloading the training image\n",
      "2025-05-21 16:57:18 Training - Training image download completed. Training in progress.\n",
      "2025-05-21 16:57:18 Uploading - Uploading generated training model\n",
      "2025-05-21 16:57:18 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-21-16-48-49-177',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ec135f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "62e6bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.Predictor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            # serializer=JSONSerializer(),\n",
    "            serializer=IdentitySerializer(content_type=\"application/json\"),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        ts,\n",
    "        cat=None,\n",
    "        dynamic_feat=None,\n",
    "        num_samples=100,\n",
    "        return_samples=False,\n",
    "        quantiles=[\"0.1\", \"0.5\", \"0.9\"],\n",
    "    ):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "\n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "\n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + ts.index.freq\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "\n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(\n",
    "            ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None\n",
    "        )\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles,\n",
    "        }\n",
    "\n",
    "        http_request_data = {\"instances\": [instance], \"configuration\": configuration}\n",
    "\n",
    "        return json.dumps(http_request_data).encode(\"utf-8\")\n",
    "\n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode(\"utf-8\"))[\"predictions\"][0]\n",
    "        prediction_length = len(next(iter(predictions[\"quantiles\"].values())))\n",
    "        prediction_index = pd.date_range(\n",
    "            start=prediction_time, freq=freq, periods=prediction_length\n",
    "        )\n",
    "        if return_samples:\n",
    "            dict_of_samples = {\"sample_\" + str(i): s for i, s in enumerate(predictions[\"samples\"])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(\n",
    "            data={**predictions[\"quantiles\"], **dict_of_samples}, index=prediction_index\n",
    "        )\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "\n",
    "\n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]\n",
    "\n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "04c071b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 15:49:09] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-20-49-09-481 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 15:49:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-20-49-09-481 \u001b]8;id=963120;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=898420;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 15:49:10] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-20-49-09-481                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 15:49:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=209213;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=274638;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-20-49-09-481                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-20-49-09-481                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=469188;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=914457;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-20-49-09-481                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "49cd1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_a_series(timeseries):\n",
    "    series_list = []\n",
    "    \n",
    "    for ts in timeseries:\n",
    "        # Verificar que la columna 'cantidad' existe\n",
    "        if 'cantidad' in ts.columns:\n",
    "            # Extraer la columna 'cantidad' como una serie\n",
    "            serie = ts['cantidad']\n",
    "\n",
    "            # Asegurarse de que el índice esté ordenado\n",
    "            serie = serie.sort_index()\n",
    "\n",
    "            # Intentar inferir la frecuencia del índice\n",
    "            try:\n",
    "                freq = pd.infer_freq(serie.index)\n",
    "                if freq is not None:\n",
    "                    serie.index.freq = freq\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo inferir frecuencia para una serie: {e}\")\n",
    "\n",
    "            series_list.append(serie)\n",
    "        else:\n",
    "            print(f\"Advertencia: Un dataframe no contiene la columna 'cantidad'\")\n",
    "    \n",
    "    return series_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "6fce0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_list = convertir_a_series(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "2ef79e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_lista_features_dinamicas(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Crea una lista de listas con los vectores de 'month' y 'quarter' para cada dataframe.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con columnas 'month' y 'quarter'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de listas donde cada elemento es [month_vector, quarter_vector] para un dataframe\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    lista_features = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío. Se añadirá una lista vacía.\")\n",
    "            lista_features.append([[], []])\n",
    "            continue\n",
    "        \n",
    "        # Verificar que existan las columnas necesarias\n",
    "        columnas_faltantes = []\n",
    "        if 'month' not in df.columns:\n",
    "            columnas_faltantes.append('month')\n",
    "        if 'quarter' not in df.columns:\n",
    "            columnas_faltantes.append('quarter')\n",
    "        \n",
    "        if columnas_faltantes:\n",
    "            # Si faltan columnas, intentar generarlas a partir del índice si es posible\n",
    "            df_temp = df.copy()\n",
    "                \n",
    "            # Generar columnas de fechas si el índice es de tipo datetime\n",
    "            if ('month' in columnas_faltantes or 'quarter' in columnas_faltantes) and isinstance(df_temp.index, pd.DatetimeIndex):\n",
    "                if 'month' not in df_temp.columns:\n",
    "                    df_temp['month'] = df_temp.index.month\n",
    "                if 'quarter' not in df_temp.columns:\n",
    "                    df_temp['quarter'] = df_temp.index.quarter\n",
    "                df = df_temp\n",
    "            elif 'month' in columnas_faltantes or 'quarter' in columnas_faltantes:\n",
    "                # Intentar convertir el índice a datetime si no lo es\n",
    "                try:\n",
    "                    df_temp.index = pd.to_datetime(df_temp.index)\n",
    "                    if 'month' not in df_temp.columns:\n",
    "                        df_temp['month'] = df_temp.index.month\n",
    "                    if 'quarter' not in df_temp.columns:\n",
    "                        df_temp['quarter'] = df_temp.index.quarter\n",
    "                    df = df_temp\n",
    "                except:\n",
    "                    print(f\"Error: No se pueden generar las columnas {columnas_faltantes} para el Dataframe {i}. Se añadirá una lista vacía.\")\n",
    "                    lista_features.append([[], []])\n",
    "                    continue\n",
    "        \n",
    "        # Crear los vectores de características dinámicas\n",
    "        month_vector = df['month'].tolist()\n",
    "        quarter_vector = df['quarter'].tolist()\n",
    "        \n",
    "        # Añadir los vectores a la lista\n",
    "        lista_features.append([month_vector, quarter_vector])\n",
    "        \n",
    "    return lista_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "bf2f1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_list = crear_lista_features_dinamicas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "f1877063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>-2.262016</td>\n",
       "      <td>30.743887</td>\n",
       "      <td>73.115250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>21.628677</td>\n",
       "      <td>46.169594</td>\n",
       "      <td>74.851982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>7.283086</td>\n",
       "      <td>28.431248</td>\n",
       "      <td>52.060368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>5.084124</td>\n",
       "      <td>16.180649</td>\n",
       "      <td>30.046261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>1.593655</td>\n",
       "      <td>25.579025</td>\n",
       "      <td>45.848190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>8.498167</td>\n",
       "      <td>21.814901</td>\n",
       "      <td>35.918530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01  -2.262016  30.743887  73.115250\n",
       "2024-12-01  21.628677  46.169594  74.851982\n",
       "2025-01-01   7.283086  28.431248  52.060368\n",
       "2025-02-01   5.084124  16.180649  30.046261\n",
       "2025-03-01   1.593655  25.579025  45.848190\n",
       "2025-04-01   8.498167  21.814901  35.918530"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=13\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "75e29775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    15.0\n",
       "2024-12-01    53.0\n",
       "2025-01-01    11.0\n",
       "2025-02-01     8.0\n",
       "2025-03-01     8.0\n",
       "2025-04-01     4.0\n",
       "Freq: MS, Name: cantidad, dtype: float64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[13].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2DO ENTRENAMIENTO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "5649ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    #\"learning_rate\": \"1E-3\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "35de1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "df473ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 15:56:51] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 15:56:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=936025;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=512990;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-20-56-51-092                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=596683;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=558191;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-20-56-51-092                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 20:56:53 Starting - Starting the training job...\n",
      "2025-05-21 20:57:07 Starting - Preparing the instances for training...\n",
      "2025-05-21 20:57:49 Downloading - Downloading the training image.........\n",
      "2025-05-21 20:59:10 Training - Training image download completed. Training in progress.Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '18', 'early_stopping_patience': '40', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '18', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Detected entry point for worker worker\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Using early stopping with patience 40\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] random_seed is None\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] [cardinality=auto] Inferred value of cardinality=[2, 4, 5, 6, 6] from dataset.\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Training set statistics:\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Real time series\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] number of time series: 15\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] number of observations: 582\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] mean target length: 38.8\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] min/mean/max target: 1.0/28.5893470790378/343.0\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] mean abs(target): 28.5893470790378\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] contains missing values: no\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Small number of time series. Doing 86 passes over dataset with prob 0.9922480620155039 per epoch.\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Test set statistics:\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Real time series\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] number of time series: 15\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] number of observations: 672\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] mean target length: 44.8\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] min/mean/max target: 1.0/28.702380952380953/368.0\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] mean abs(target): 28.702380952380953\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] contains missing values: no\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] nvidia-smi: took 0.031 seconds to run.\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] nvidia-smi identified 0 GPUs.\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Number of GPUs being used: 0\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Create Store: local\n",
      "#metrics {\"StartTime\": 1747861168.537641, \"EndTime\": 1747861168.588328, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 49.79443550109863, \"count\": 1, \"min\": 49.79443550109863, \"max\": 49.79443550109863}}}\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] Number of GPUs being used: 0\n",
      "[05/21/2025 20:59:28 INFO 140363140085568] #memory_usage::<model> = 21 mb\n",
      "#metrics {\"StartTime\": 1747861168.5884173, \"EndTime\": 1747861168.6698472, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 132.0822238922119, \"count\": 1, \"min\": 132.0822238922119, \"max\": 132.0822238922119}}}\n",
      "[20:59:28] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 20480 bytes with malloc directly\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] Epoch[0] Batch[0] avg_epoch_loss=3.530411\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.5304107666015625\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] Epoch[0] Batch[5] avg_epoch_loss=3.431790\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.4317895571390786\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] Epoch[0] Batch [5]#011Speed: 2045.84 samples/sec#011loss=3.431790\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] Epoch[0] Batch[10] avg_epoch_loss=3.283852\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.10632643699646\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] Epoch[0] Batch [10]#011Speed: 1625.78 samples/sec#011loss=3.106326\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747861168.6698997, \"EndTime\": 1747861169.762415, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 1092.4484729766846, \"count\": 1, \"min\": 1092.4484729766846, \"max\": 1092.4484729766846}}}\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1203.6135533345744 records/second\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.2838517752560703\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 20:59:29 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_abf83e29-3981-424f-ae7c-d12f4733216d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861169.7624795, \"EndTime\": 1747861169.7745016, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.706352233886719, \"count\": 1, \"min\": 11.706352233886719, \"max\": 11.706352233886719}}}\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] Epoch[1] Batch[0] avg_epoch_loss=3.338310\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.3383100032806396\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] Epoch[1] Batch[5] avg_epoch_loss=3.303402\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.3034017086029053\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] Epoch[1] Batch [5]#011Speed: 1540.68 samples/sec#011loss=3.303402\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] Epoch[1] Batch[10] avg_epoch_loss=3.292503\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.2794246673583984\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] Epoch[1] Batch [10]#011Speed: 1787.34 samples/sec#011loss=3.279425\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747861169.7745605, \"EndTime\": 1747861170.8815446, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1106.931447982788, \"count\": 1, \"min\": 1106.931447982788, \"max\": 1106.931447982788}}}\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1244.7322002623525 records/second\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.2925030534917656\n",
      "[05/21/2025 20:59:30 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:31 INFO 140363140085568] Epoch[2] Batch[0] avg_epoch_loss=3.357512\n",
      "[05/21/2025 20:59:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.3575119972229004\n",
      "[05/21/2025 20:59:31 INFO 140363140085568] Epoch[2] Batch[5] avg_epoch_loss=3.323843\n",
      "[05/21/2025 20:59:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.3238425254821777\n",
      "[05/21/2025 20:59:31 INFO 140363140085568] Epoch[2] Batch [5]#011Speed: 2133.95 samples/sec#011loss=3.323843\n",
      "[05/21/2025 20:59:31 INFO 140363140085568] processed a total of 1258 examples\n",
      "#metrics {\"StartTime\": 1747861170.8816502, \"EndTime\": 1747861171.7656262, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 883.683443069458, \"count\": 1, \"min\": 883.683443069458, \"max\": 883.683443069458}}}\n",
      "[05/21/2025 20:59:31 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1423.433086483166 records/second\n",
      "[05/21/2025 20:59:31 INFO 140363140085568] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/21/2025 20:59:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.300208497047424\n",
      "[05/21/2025 20:59:31 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] Epoch[3] Batch[0] avg_epoch_loss=3.082727\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.0827274322509766\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] Epoch[3] Batch[5] avg_epoch_loss=3.229615\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.2296146949132285\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] Epoch[3] Batch [5]#011Speed: 2031.21 samples/sec#011loss=3.229615\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] Epoch[3] Batch[10] avg_epoch_loss=3.111248\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=2.969207191467285\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] Epoch[3] Batch [10]#011Speed: 2098.53 samples/sec#011loss=2.969207\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747861171.7656894, \"EndTime\": 1747861172.7049584, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.9786720275879, \"count\": 1, \"min\": 938.9786720275879, \"max\": 938.9786720275879}}}\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1397.1390254324322 records/second\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.111247647892345\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 20:59:32 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_ef12de2d-074d-4832-a0eb-5f90b4602c41-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861172.7050147, \"EndTime\": 1747861172.7162046, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.932445526123047, \"count\": 1, \"min\": 10.932445526123047, \"max\": 10.932445526123047}}}\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] Epoch[4] Batch[0] avg_epoch_loss=3.149480\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.1494803428649902\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] Epoch[4] Batch[5] avg_epoch_loss=3.205538\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.2055383920669556\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] Epoch[4] Batch [5]#011Speed: 2157.90 samples/sec#011loss=3.205538\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] Epoch[4] Batch[10] avg_epoch_loss=3.239770\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.2808478355407713\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] Epoch[4] Batch [10]#011Speed: 2016.15 samples/sec#011loss=3.280848\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747861172.716263, \"EndTime\": 1747861173.64748, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.1623573303223, \"count\": 1, \"min\": 931.1623573303223, \"max\": 931.1623573303223}}}\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1447.5166302862353 records/second\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.2397699572823266\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] Epoch[5] Batch[0] avg_epoch_loss=3.136334\n",
      "[05/21/2025 20:59:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.1363344192504883\n",
      "[05/21/2025 20:59:34 INFO 140363140085568] Epoch[5] Batch[5] avg_epoch_loss=3.140173\n",
      "[05/21/2025 20:59:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.140173157056173\n",
      "[05/21/2025 20:59:34 INFO 140363140085568] Epoch[5] Batch [5]#011Speed: 2055.49 samples/sec#011loss=3.140173\n",
      "[05/21/2025 20:59:34 INFO 140363140085568] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747861173.6475372, \"EndTime\": 1747861174.5482097, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 900.3911018371582, \"count\": 1, \"min\": 900.3911018371582, \"max\": 900.3911018371582}}}\n",
      "[05/21/2025 20:59:34 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1421.4576595010094 records/second\n",
      "[05/21/2025 20:59:34 INFO 140363140085568] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/21/2025 20:59:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.186817669868469\n",
      "[05/21/2025 20:59:34 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:34 INFO 140363140085568] Epoch[6] Batch[0] avg_epoch_loss=3.036905\n",
      "[05/21/2025 20:59:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.036905288696289\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] Epoch[6] Batch[5] avg_epoch_loss=3.119095\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.1190949281056723\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] Epoch[6] Batch [5]#011Speed: 2144.43 samples/sec#011loss=3.119095\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] Epoch[6] Batch[10] avg_epoch_loss=3.174546\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.24108829498291\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] Epoch[6] Batch [10]#011Speed: 2121.97 samples/sec#011loss=3.241088\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747861174.548273, \"EndTime\": 1747861175.47132, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.7311611175537, \"count\": 1, \"min\": 922.7311611175537, \"max\": 922.7311611175537}}}\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1395.721671229281 records/second\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.1745464585044165\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] Epoch[7] Batch[0] avg_epoch_loss=3.241424\n",
      "[05/21/2025 20:59:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.241424322128296\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] Epoch[7] Batch[5] avg_epoch_loss=3.154409\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.1544093688329062\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] Epoch[7] Batch [5]#011Speed: 1910.06 samples/sec#011loss=3.154409\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] Epoch[7] Batch[10] avg_epoch_loss=3.182614\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.2164587020874023\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] Epoch[7] Batch [10]#011Speed: 1977.26 samples/sec#011loss=3.216459\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747861175.47138, \"EndTime\": 1747861176.447655, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 976.0222434997559, \"count\": 1, \"min\": 976.0222434997559, \"max\": 976.0222434997559}}}\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1391.2390484343914 records/second\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.1826136112213135\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] Epoch[8] Batch[0] avg_epoch_loss=3.197325\n",
      "[05/21/2025 20:59:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.1973254680633545\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] Epoch[8] Batch[5] avg_epoch_loss=3.224478\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.2244776487350464\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] Epoch[8] Batch [5]#011Speed: 2133.02 samples/sec#011loss=3.224478\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] Epoch[8] Batch[10] avg_epoch_loss=3.182025\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.131082010269165\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] Epoch[8] Batch [10]#011Speed: 2025.75 samples/sec#011loss=3.131082\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] processed a total of 1373 examples\n",
      "#metrics {\"StartTime\": 1747861176.4477124, \"EndTime\": 1747861177.3820603, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.0949058532715, \"count\": 1, \"min\": 934.0949058532715, \"max\": 934.0949058532715}}}\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1469.6709923964133 records/second\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.1820250857960093\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] Epoch[9] Batch[0] avg_epoch_loss=3.115796\n",
      "[05/21/2025 20:59:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.1157960891723633\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] Epoch[9] Batch[5] avg_epoch_loss=3.130223\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.130223194758097\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] Epoch[9] Batch [5]#011Speed: 2102.78 samples/sec#011loss=3.130223\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] Epoch[9] Batch[10] avg_epoch_loss=3.125565\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.119974899291992\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] Epoch[9] Batch [10]#011Speed: 2019.66 samples/sec#011loss=3.119975\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747861177.38216, \"EndTime\": 1747861178.3220847, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.6398067474365, \"count\": 1, \"min\": 939.6398067474365, \"max\": 939.6398067474365}}}\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1433.394186938333 records/second\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.1255648786371406\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] Epoch[10] Batch[0] avg_epoch_loss=3.129147\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.1291465759277344\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] Epoch[10] Batch[5] avg_epoch_loss=3.147475\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.147475004196167\n",
      "[05/21/2025 20:59:38 INFO 140363140085568] Epoch[10] Batch [5]#011Speed: 2096.60 samples/sec#011loss=3.147475\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] Epoch[10] Batch[10] avg_epoch_loss=3.091700\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.0247710227966307\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] Epoch[10] Batch [10]#011Speed: 2023.18 samples/sec#011loss=3.024771\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747861178.3221433, \"EndTime\": 1747861179.2668905, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.4949626922607, \"count\": 1, \"min\": 944.4949626922607, \"max\": 944.4949626922607}}}\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1398.505746047179 records/second\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.091700467196378\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_6f7c9951-fefa-4c8d-973d-d6fa1662cc86-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861179.2669485, \"EndTime\": 1747861179.278325, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.098623275756836, \"count\": 1, \"min\": 11.098623275756836, \"max\": 11.098623275756836}}}\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] Epoch[11] Batch[0] avg_epoch_loss=3.120934\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.120934247970581\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] Epoch[11] Batch[5] avg_epoch_loss=3.096632\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.096632242202759\n",
      "[05/21/2025 20:59:39 INFO 140363140085568] Epoch[11] Batch [5]#011Speed: 2019.25 samples/sec#011loss=3.096632\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] Epoch[11] Batch[10] avg_epoch_loss=2.987108\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=2.855679082870483\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] Epoch[11] Batch [10]#011Speed: 2125.91 samples/sec#011loss=2.855679\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747861179.27838, \"EndTime\": 1747861180.2183256, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.8961067199707, \"count\": 1, \"min\": 939.8961067199707, \"max\": 939.8961067199707}}}\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1368.1148654681222 records/second\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.9871080788699063\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_68918172-9f2f-417d-b9b9-8e202cfd9bad-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861180.2183821, \"EndTime\": 1747861180.2294142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.764360427856445, \"count\": 1, \"min\": 10.764360427856445, \"max\": 10.764360427856445}}}\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] Epoch[12] Batch[0] avg_epoch_loss=2.881065\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.8810651302337646\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] Epoch[12] Batch[5] avg_epoch_loss=3.036363\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.0363626877466836\n",
      "[05/21/2025 20:59:40 INFO 140363140085568] Epoch[12] Batch [5]#011Speed: 2114.13 samples/sec#011loss=3.036363\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] Epoch[12] Batch[10] avg_epoch_loss=2.991768\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=2.9382536888122557\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] Epoch[12] Batch [10]#011Speed: 2003.27 samples/sec#011loss=2.938254\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747861180.2294695, \"EndTime\": 1747861181.1687303, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.208984375, \"count\": 1, \"min\": 939.208984375, \"max\": 939.208984375}}}\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1391.4634034781793 records/second\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.9917676882310347\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] Epoch[13] Batch[0] avg_epoch_loss=3.232299\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.2322990894317627\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] Epoch[13] Batch[5] avg_epoch_loss=3.059811\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.0598111550013223\n",
      "[05/21/2025 20:59:41 INFO 140363140085568] Epoch[13] Batch [5]#011Speed: 1994.95 samples/sec#011loss=3.059811\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] Epoch[13] Batch[10] avg_epoch_loss=3.028975\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=2.991970682144165\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] Epoch[13] Batch [10]#011Speed: 2071.75 samples/sec#011loss=2.991971\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747861181.1687913, \"EndTime\": 1747861182.1201613, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.1022567749023, \"count\": 1, \"min\": 951.1022567749023, \"max\": 951.1022567749023}}}\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1363.549664677827 records/second\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.028974576429887\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] Epoch[14] Batch[0] avg_epoch_loss=3.014572\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.0145723819732666\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] Epoch[14] Batch[5] avg_epoch_loss=3.059253\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.059252699216207\n",
      "[05/21/2025 20:59:42 INFO 140363140085568] Epoch[14] Batch [5]#011Speed: 2126.72 samples/sec#011loss=3.059253\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] Epoch[14] Batch[10] avg_epoch_loss=2.969380\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=2.861533212661743\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] Epoch[14] Batch [10]#011Speed: 2120.97 samples/sec#011loss=2.861533\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747861182.120222, \"EndTime\": 1747861183.0479033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.2732734680176, \"count\": 1, \"min\": 927.2732734680176, \"max\": 927.2732734680176}}}\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1393.1978233472387 records/second\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.9693802053278144\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_a021c719-8c4e-4013-a6dd-bb6ea20efa9b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861183.0479639, \"EndTime\": 1747861183.0589244, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.624408721923828, \"count\": 1, \"min\": 10.624408721923828, \"max\": 10.624408721923828}}}\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] Epoch[15] Batch[0] avg_epoch_loss=2.976616\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=2.976616382598877\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] Epoch[15] Batch[5] avg_epoch_loss=2.994744\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.9947444200515747\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] Epoch[15] Batch [5]#011Speed: 2156.93 samples/sec#011loss=2.994744\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] Epoch[15] Batch[10] avg_epoch_loss=2.963073\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=2.92506799697876\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] Epoch[15] Batch [10]#011Speed: 2075.04 samples/sec#011loss=2.925068\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747861183.0589795, \"EndTime\": 1747861183.98354, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.5104789733887, \"count\": 1, \"min\": 924.5104789733887, \"max\": 924.5104789733887}}}\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1438.4615356845673 records/second\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.963073318654841\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 20:59:43 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_cc87d8b8-19c0-4802-9e68-e79a1f457e24-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861183.9836013, \"EndTime\": 1747861183.9938264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.845495223999023, \"count\": 1, \"min\": 9.845495223999023, \"max\": 9.845495223999023}}}\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] Epoch[16] Batch[0] avg_epoch_loss=3.065875\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.0658750534057617\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] Epoch[16] Batch[5] avg_epoch_loss=2.995659\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.9956589937210083\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] Epoch[16] Batch [5]#011Speed: 2104.17 samples/sec#011loss=2.995659\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] Epoch[16] Batch[10] avg_epoch_loss=2.989941\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=2.983078956604004\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] Epoch[16] Batch [10]#011Speed: 2030.60 samples/sec#011loss=2.983079\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] processed a total of 1380 examples\n",
      "#metrics {\"StartTime\": 1747861183.9943883, \"EndTime\": 1747861184.9297209, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.279369354248, \"count\": 1, \"min\": 935.279369354248, \"max\": 935.279369354248}}}\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1475.365963760604 records/second\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=16, train loss <loss>=2.989940795031461\n",
      "[05/21/2025 20:59:44 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] Epoch[17] Batch[0] avg_epoch_loss=3.104652\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.104652166366577\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] Epoch[17] Batch[5] avg_epoch_loss=3.023809\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.023809313774109\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] Epoch[17] Batch [5]#011Speed: 2123.53 samples/sec#011loss=3.023809\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] Epoch[17] Batch[10] avg_epoch_loss=3.026811\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.0304126739501953\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] Epoch[17] Batch [10]#011Speed: 2011.39 samples/sec#011loss=3.030413\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747861184.9297755, \"EndTime\": 1747861185.8670712, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.0067119598389, \"count\": 1, \"min\": 937.0067119598389, \"max\": 937.0067119598389}}}\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1395.7924422165067 records/second\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.0268108411268755\n",
      "[05/21/2025 20:59:45 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] Epoch[18] Batch[0] avg_epoch_loss=3.064899\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.064899206161499\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] Epoch[18] Batch[5] avg_epoch_loss=3.047039\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.0470393101374307\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] Epoch[18] Batch [5]#011Speed: 1871.46 samples/sec#011loss=3.047039\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] Epoch[18] Batch[10] avg_epoch_loss=2.933773\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=2.797852897644043\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] Epoch[18] Batch [10]#011Speed: 2010.36 samples/sec#011loss=2.797853\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747861185.8671372, \"EndTime\": 1747861186.8480191, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 980.621337890625, \"count\": 1, \"min\": 980.621337890625, \"max\": 980.621337890625}}}\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1364.3222905142288 records/second\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=18, train loss <loss>=2.9337727590040727\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 20:59:46 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_59a5db0c-85e3-488f-a49e-41c38b550748-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861186.8480766, \"EndTime\": 1747861186.8585334, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.117053985595703, \"count\": 1, \"min\": 10.117053985595703, \"max\": 10.117053985595703}}}\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] Epoch[19] Batch[0] avg_epoch_loss=2.939144\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=2.9391441345214844\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] Epoch[19] Batch[5] avg_epoch_loss=2.966465\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=2.9664647976557412\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] Epoch[19] Batch [5]#011Speed: 2147.33 samples/sec#011loss=2.966465\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] Epoch[19] Batch[10] avg_epoch_loss=2.986914\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=3.011453866958618\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] Epoch[19] Batch [10]#011Speed: 1968.18 samples/sec#011loss=3.011454\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747861186.8585846, \"EndTime\": 1747861187.7952294, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.5928173065186, \"count\": 1, \"min\": 936.5928173065186, \"max\": 936.5928173065186}}}\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1431.6539205175432 records/second\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.9869143746115943\n",
      "[05/21/2025 20:59:47 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] Epoch[20] Batch[0] avg_epoch_loss=2.840595\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=2.8405954837799072\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] Epoch[20] Batch[5] avg_epoch_loss=2.928366\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=2.9283660252889\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] Epoch[20] Batch [5]#011Speed: 2231.57 samples/sec#011loss=2.928366\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] Epoch[20] Batch[10] avg_epoch_loss=2.990204\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=3.0644099712371826\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] Epoch[20] Batch [10]#011Speed: 2145.04 samples/sec#011loss=3.064410\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747861187.795287, \"EndTime\": 1747861188.6985908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 903.0306339263916, \"count\": 1, \"min\": 903.0306339263916, \"max\": 903.0306339263916}}}\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1440.567628243712 records/second\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=20, train loss <loss>=2.990204182538119\n",
      "[05/21/2025 20:59:48 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] Epoch[21] Batch[0] avg_epoch_loss=2.940146\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=2.9401464462280273\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] Epoch[21] Batch[5] avg_epoch_loss=3.035644\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.0356443325678506\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] Epoch[21] Batch [5]#011Speed: 2143.95 samples/sec#011loss=3.035644\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747861188.6986473, \"EndTime\": 1747861189.565135, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 866.229772567749, \"count\": 1, \"min\": 866.229772567749, \"max\": 866.229772567749}}}\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1471.7354312922048 records/second\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=21, train loss <loss>=3.017876887321472\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] Epoch[22] Batch[0] avg_epoch_loss=2.988377\n",
      "[05/21/2025 20:59:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.988377094268799\n",
      "[05/21/2025 20:59:50 INFO 140363140085568] Epoch[22] Batch[5] avg_epoch_loss=2.966179\n",
      "[05/21/2025 20:59:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.9661792119344077\n",
      "[05/21/2025 20:59:50 INFO 140363140085568] Epoch[22] Batch [5]#011Speed: 2114.25 samples/sec#011loss=2.966179\n",
      "[05/21/2025 20:59:50 INFO 140363140085568] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747861189.5651987, \"EndTime\": 1747861190.4418278, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 876.2476444244385, \"count\": 1, \"min\": 876.2476444244385, \"max\": 876.2476444244385}}}\n",
      "[05/21/2025 20:59:50 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1454.9137170434856 records/second\n",
      "[05/21/2025 20:59:50 INFO 140363140085568] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/21/2025 20:59:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.978661370277405\n",
      "[05/21/2025 20:59:50 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:50 INFO 140363140085568] Epoch[23] Batch[0] avg_epoch_loss=3.100531\n",
      "[05/21/2025 20:59:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=3.1005306243896484\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] Epoch[23] Batch[5] avg_epoch_loss=2.900480\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.9004801511764526\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] Epoch[23] Batch [5]#011Speed: 1910.53 samples/sec#011loss=2.900480\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] Epoch[23] Batch[10] avg_epoch_loss=2.944857\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=2.9981082916259765\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] Epoch[23] Batch [10]#011Speed: 2026.26 samples/sec#011loss=2.998108\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747861190.4418898, \"EndTime\": 1747861191.416325, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.9358425140381, \"count\": 1, \"min\": 973.9358425140381, \"max\": 973.9358425140381}}}\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1373.6507604551568 records/second\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.944856578653509\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] Epoch[24] Batch[0] avg_epoch_loss=2.981439\n",
      "[05/21/2025 20:59:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.9814391136169434\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] Epoch[24] Batch[5] avg_epoch_loss=2.901360\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.9013603130976358\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] Epoch[24] Batch [5]#011Speed: 1935.12 samples/sec#011loss=2.901360\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] Epoch[24] Batch[10] avg_epoch_loss=2.776297\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.626220226287842\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] Epoch[24] Batch [10]#011Speed: 1950.23 samples/sec#011loss=2.626220\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747861191.416406, \"EndTime\": 1747861192.3968492, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 980.1805019378662, \"count\": 1, \"min\": 980.1805019378662, \"max\": 980.1805019378662}}}\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1337.3939187572114 records/second\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.7762966372750024\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_5be5b3a3-276e-4ce0-84ba-372a68d62dcc-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861192.3969057, \"EndTime\": 1747861192.4078586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.684490203857422, \"count\": 1, \"min\": 10.684490203857422, \"max\": 10.684490203857422}}}\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] Epoch[25] Batch[0] avg_epoch_loss=2.965890\n",
      "[05/21/2025 20:59:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.9658899307250977\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] Epoch[25] Batch[5] avg_epoch_loss=2.953689\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.9536885420481362\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] Epoch[25] Batch [5]#011Speed: 2153.98 samples/sec#011loss=2.953689\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] Epoch[25] Batch[10] avg_epoch_loss=2.944146\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=2.932695436477661\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] Epoch[25] Batch [10]#011Speed: 1972.74 samples/sec#011loss=2.932695\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] processed a total of 1382 examples\n",
      "#metrics {\"StartTime\": 1747861192.4079082, \"EndTime\": 1747861193.3532171, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.2614784240723, \"count\": 1, \"min\": 945.2614784240723, \"max\": 945.2614784240723}}}\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1461.899900253842 records/second\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.944146221334284\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] Epoch[26] Batch[0] avg_epoch_loss=2.820510\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.8205103874206543\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] Epoch[26] Batch[5] avg_epoch_loss=2.872187\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.8721871376037598\n",
      "[05/21/2025 20:59:53 INFO 140363140085568] Epoch[26] Batch [5]#011Speed: 2135.65 samples/sec#011loss=2.872187\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] Epoch[26] Batch[10] avg_epoch_loss=2.816735\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=2.750192165374756\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] Epoch[26] Batch [10]#011Speed: 2093.65 samples/sec#011loss=2.750192\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747861193.3532743, \"EndTime\": 1747861194.2787068, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.1797199249268, \"count\": 1, \"min\": 925.1797199249268, \"max\": 925.1797199249268}}}\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1423.3773593802784 records/second\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.816734877499667\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] Epoch[27] Batch[0] avg_epoch_loss=2.911744\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.911743640899658\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] Epoch[27] Batch[5] avg_epoch_loss=2.875194\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.8751935958862305\n",
      "[05/21/2025 20:59:54 INFO 140363140085568] Epoch[27] Batch [5]#011Speed: 2139.18 samples/sec#011loss=2.875194\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] Epoch[27] Batch[10] avg_epoch_loss=2.883866\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.8942718505859375\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] Epoch[27] Batch [10]#011Speed: 1884.43 samples/sec#011loss=2.894272\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747861194.2787642, \"EndTime\": 1747861195.2343042, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.2583694458008, \"count\": 1, \"min\": 955.2583694458008, \"max\": 955.2583694458008}}}\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1422.5200394807607 records/second\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.8838655298406426\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] Epoch[28] Batch[0] avg_epoch_loss=2.734574\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.734574317932129\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] Epoch[28] Batch[5] avg_epoch_loss=2.876071\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.876071015993754\n",
      "[05/21/2025 20:59:55 INFO 140363140085568] Epoch[28] Batch [5]#011Speed: 2051.80 samples/sec#011loss=2.876071\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] Epoch[28] Batch[10] avg_epoch_loss=2.894623\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=2.9168864727020263\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] Epoch[28] Batch [10]#011Speed: 1881.25 samples/sec#011loss=2.916886\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747861195.2343652, \"EndTime\": 1747861196.2021196, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 967.5033092498779, \"count\": 1, \"min\": 967.5033092498779, \"max\": 967.5033092498779}}}\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1410.6935386861032 records/second\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.894623496315696\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] Epoch[29] Batch[0] avg_epoch_loss=2.821946\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.821946144104004\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] Epoch[29] Batch[5] avg_epoch_loss=2.910989\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.9109885692596436\n",
      "[05/21/2025 20:59:56 INFO 140363140085568] Epoch[29] Batch [5]#011Speed: 1980.67 samples/sec#011loss=2.910989\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] Epoch[29] Batch[10] avg_epoch_loss=2.943235\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=2.981931686401367\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] Epoch[29] Batch [10]#011Speed: 1899.40 samples/sec#011loss=2.981932\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747861196.2021923, \"EndTime\": 1747861197.1876047, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 985.0585460662842, \"count\": 1, \"min\": 985.0585460662842, \"max\": 985.0585460662842}}}\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1344.9655509226554 records/second\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.9432354406876997\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] Epoch[30] Batch[0] avg_epoch_loss=2.730797\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.730797052383423\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] Epoch[30] Batch[5] avg_epoch_loss=2.851652\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.8516520261764526\n",
      "[05/21/2025 20:59:57 INFO 140363140085568] Epoch[30] Batch [5]#011Speed: 2139.50 samples/sec#011loss=2.851652\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] Epoch[30] Batch[10] avg_epoch_loss=2.820577\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=2.7832878112792967\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] Epoch[30] Batch [10]#011Speed: 2090.72 samples/sec#011loss=2.783288\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747861197.1876686, \"EndTime\": 1747861198.1211386, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.1521987915039, \"count\": 1, \"min\": 933.1521987915039, \"max\": 933.1521987915039}}}\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1392.9972485431585 records/second\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.820577383041382\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] Epoch[31] Batch[0] avg_epoch_loss=2.776408\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.7764079570770264\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] Epoch[31] Batch[5] avg_epoch_loss=2.869408\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.8694080909093223\n",
      "[05/21/2025 20:59:58 INFO 140363140085568] Epoch[31] Batch [5]#011Speed: 2170.35 samples/sec#011loss=2.869408\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] Epoch[31] Batch[10] avg_epoch_loss=2.848544\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=2.823507881164551\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] Epoch[31] Batch [10]#011Speed: 2076.57 samples/sec#011loss=2.823508\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747861198.1211967, \"EndTime\": 1747861199.065555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.1065788269043, \"count\": 1, \"min\": 944.1065788269043, \"max\": 944.1065788269043}}}\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1395.9005129494874 records/second\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.8485443592071533\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] Epoch[32] Batch[0] avg_epoch_loss=2.888622\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.888622283935547\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] Epoch[32] Batch[5] avg_epoch_loss=2.879311\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.879310925801595\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] Epoch[32] Batch [5]#011Speed: 2121.18 samples/sec#011loss=2.879311\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] Epoch[32] Batch[10] avg_epoch_loss=2.729144\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=2.548943114280701\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] Epoch[32] Batch [10]#011Speed: 2067.86 samples/sec#011loss=2.548943\n",
      "[05/21/2025 20:59:59 INFO 140363140085568] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747861199.0656135, \"EndTime\": 1747861200.0000498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.1840744018555, \"count\": 1, \"min\": 934.1840744018555, \"max\": 934.1840744018555}}}\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1405.3776143863404 records/second\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.729143738746643\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_d86d3d78-e5e9-4ee0-b012-37f433e80549-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861200.0001063, \"EndTime\": 1747861200.011459, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.06119155883789, \"count\": 1, \"min\": 11.06119155883789, \"max\": 11.06119155883789}}}\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] Epoch[33] Batch[0] avg_epoch_loss=2.938468\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.9384679794311523\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] Epoch[33] Batch[5] avg_epoch_loss=2.860105\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.8601049979527793\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] Epoch[33] Batch [5]#011Speed: 1977.22 samples/sec#011loss=2.860105\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] processed a total of 1258 examples\n",
      "#metrics {\"StartTime\": 1747861200.0115178, \"EndTime\": 1747861200.9188645, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.294750213623, \"count\": 1, \"min\": 907.294750213623, \"max\": 907.294750213623}}}\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1386.4116131578442 records/second\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.852186679840088\n",
      "[05/21/2025 21:00:00 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] Epoch[34] Batch[0] avg_epoch_loss=2.866680\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.8666799068450928\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] Epoch[34] Batch[5] avg_epoch_loss=2.824948\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.82494846979777\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] Epoch[34] Batch [5]#011Speed: 1688.58 samples/sec#011loss=2.824948\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] Epoch[34] Batch[10] avg_epoch_loss=2.806797\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=2.7850149631500245\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] Epoch[34] Batch [10]#011Speed: 2013.11 samples/sec#011loss=2.785015\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747861200.9189203, \"EndTime\": 1747861201.9475863, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1028.322458267212, \"count\": 1, \"min\": 1028.322458267212, \"max\": 1028.322458267212}}}\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1263.1152500902408 records/second\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.8067968758669766\n",
      "[05/21/2025 21:00:01 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:02 INFO 140363140085568] Epoch[35] Batch[0] avg_epoch_loss=2.803286\n",
      "[05/21/2025 21:00:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.803285598754883\n",
      "[05/21/2025 21:00:02 INFO 140363140085568] Epoch[35] Batch[5] avg_epoch_loss=2.793184\n",
      "[05/21/2025 21:00:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.7931841214497886\n",
      "[05/21/2025 21:00:02 INFO 140363140085568] Epoch[35] Batch [5]#011Speed: 2144.27 samples/sec#011loss=2.793184\n",
      "[05/21/2025 21:00:02 INFO 140363140085568] processed a total of 1224 examples\n",
      "#metrics {\"StartTime\": 1747861201.9476457, \"EndTime\": 1747861202.806488, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 858.5741519927979, \"count\": 1, \"min\": 858.5741519927979, \"max\": 858.5741519927979}}}\n",
      "[05/21/2025 21:00:02 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1425.4650606370492 records/second\n",
      "[05/21/2025 21:00:02 INFO 140363140085568] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/21/2025 21:00:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.8486104249954223\n",
      "[05/21/2025 21:00:02 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] Epoch[36] Batch[0] avg_epoch_loss=2.719324\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.7193238735198975\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] Epoch[36] Batch[5] avg_epoch_loss=2.769409\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.7694088220596313\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] Epoch[36] Batch [5]#011Speed: 2143.41 samples/sec#011loss=2.769409\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] Epoch[36] Batch[10] avg_epoch_loss=2.781985\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.797075939178467\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] Epoch[36] Batch [10]#011Speed: 2101.44 samples/sec#011loss=2.797076\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747861202.8065512, \"EndTime\": 1747861203.7362626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.4166564941406, \"count\": 1, \"min\": 929.4166564941406, \"max\": 929.4166564941406}}}\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1419.042338723123 records/second\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.7819847843863745\n",
      "[05/21/2025 21:00:03 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] Epoch[37] Batch[0] avg_epoch_loss=2.768806\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.768805503845215\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] Epoch[37] Batch[5] avg_epoch_loss=2.777050\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.7770502169926963\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] Epoch[37] Batch [5]#011Speed: 1907.42 samples/sec#011loss=2.777050\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] Epoch[37] Batch[10] avg_epoch_loss=2.730959\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=2.6756486892700195\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] Epoch[37] Batch [10]#011Speed: 1799.17 samples/sec#011loss=2.675649\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] processed a total of 1382 examples\n",
      "#metrics {\"StartTime\": 1747861203.7363183, \"EndTime\": 1747861204.7497363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1013.1304264068604, \"count\": 1, \"min\": 1013.1304264068604, \"max\": 1013.1304264068604}}}\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1363.9711304963312 records/second\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.7309586134823887\n",
      "[05/21/2025 21:00:04 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] Epoch[38] Batch[0] avg_epoch_loss=2.824054\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.8240535259246826\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] Epoch[38] Batch[5] avg_epoch_loss=2.740123\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.7401233911514282\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] Epoch[38] Batch [5]#011Speed: 1739.84 samples/sec#011loss=2.740123\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] Epoch[38] Batch[10] avg_epoch_loss=2.718499\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=2.692549133300781\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] Epoch[38] Batch [10]#011Speed: 1723.37 samples/sec#011loss=2.692549\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747861204.7497938, \"EndTime\": 1747861205.8407168, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1090.6078815460205, \"count\": 1, \"min\": 1090.6078815460205, \"max\": 1090.6078815460205}}}\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1220.3039894622186 records/second\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.7184987284920434\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:05 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_f91ae4e1-2867-4bcf-a66e-758db4014e86-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861205.8407874, \"EndTime\": 1747861205.851551, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.373592376708984, \"count\": 1, \"min\": 10.373592376708984, \"max\": 10.373592376708984}}}\n",
      "[05/21/2025 21:00:06 INFO 140363140085568] Epoch[39] Batch[0] avg_epoch_loss=2.876742\n",
      "[05/21/2025 21:00:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.876742362976074\n",
      "[05/21/2025 21:00:06 INFO 140363140085568] Epoch[39] Batch[5] avg_epoch_loss=2.797631\n",
      "[05/21/2025 21:00:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.7976306676864624\n",
      "[05/21/2025 21:00:06 INFO 140363140085568] Epoch[39] Batch [5]#011Speed: 1990.51 samples/sec#011loss=2.797631\n",
      "[05/21/2025 21:00:06 INFO 140363140085568] processed a total of 1272 examples\n",
      "#metrics {\"StartTime\": 1747861205.8516042, \"EndTime\": 1747861206.7860544, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.3934059143066, \"count\": 1, \"min\": 934.3934059143066, \"max\": 934.3934059143066}}}\n",
      "[05/21/2025 21:00:06 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1361.1710088931513 records/second\n",
      "[05/21/2025 21:00:06 INFO 140363140085568] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/21/2025 21:00:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.773002099990845\n",
      "[05/21/2025 21:00:06 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] Epoch[40] Batch[0] avg_epoch_loss=2.708310\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.7083096504211426\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] Epoch[40] Batch[5] avg_epoch_loss=2.711263\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.7112629413604736\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] Epoch[40] Batch [5]#011Speed: 1711.50 samples/sec#011loss=2.711263\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] Epoch[40] Batch[10] avg_epoch_loss=2.746989\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=2.7898604393005373\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] Epoch[40] Batch [10]#011Speed: 1628.77 samples/sec#011loss=2.789860\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747861206.7861187, \"EndTime\": 1747861207.9346302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1148.1819152832031, \"count\": 1, \"min\": 1148.1819152832031, \"max\": 1148.1819152832031}}}\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1147.801383027649 records/second\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.7469890767877754\n",
      "[05/21/2025 21:00:07 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:08 INFO 140363140085568] Epoch[41] Batch[0] avg_epoch_loss=2.590697\n",
      "[05/21/2025 21:00:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.5906970500946045\n",
      "[05/21/2025 21:00:08 INFO 140363140085568] Epoch[41] Batch[5] avg_epoch_loss=2.721291\n",
      "[05/21/2025 21:00:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.721291104952494\n",
      "[05/21/2025 21:00:08 INFO 140363140085568] Epoch[41] Batch [5]#011Speed: 1806.51 samples/sec#011loss=2.721291\n",
      "[05/21/2025 21:00:08 INFO 140363140085568] processed a total of 1233 examples\n",
      "#metrics {\"StartTime\": 1747861207.9346898, \"EndTime\": 1747861208.9119673, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 977.0255088806152, \"count\": 1, \"min\": 977.0255088806152, \"max\": 977.0255088806152}}}\n",
      "[05/21/2025 21:00:08 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1261.8831149786217 records/second\n",
      "[05/21/2025 21:00:08 INFO 140363140085568] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/21/2025 21:00:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.776847243309021\n",
      "[05/21/2025 21:00:08 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] Epoch[42] Batch[0] avg_epoch_loss=2.826026\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.82602596282959\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] Epoch[42] Batch[5] avg_epoch_loss=2.875230\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.875229756037394\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] Epoch[42] Batch [5]#011Speed: 1788.93 samples/sec#011loss=2.875230\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] Epoch[42] Batch[10] avg_epoch_loss=2.781569\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.6691752433776856\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] Epoch[42] Batch [10]#011Speed: 1851.70 samples/sec#011loss=2.669175\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747861208.9120266, \"EndTime\": 1747861209.956638, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1044.2969799041748, \"count\": 1, \"min\": 1044.2969799041748, \"max\": 1044.2969799041748}}}\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1274.4348715410642 records/second\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.7815686139193447\n",
      "[05/21/2025 21:00:09 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] Epoch[43] Batch[0] avg_epoch_loss=2.756545\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.756545066833496\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] Epoch[43] Batch[5] avg_epoch_loss=2.809099\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.809098998705546\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] Epoch[43] Batch [5]#011Speed: 2143.01 samples/sec#011loss=2.809099\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] Epoch[43] Batch[10] avg_epoch_loss=2.783828\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.7535030841827393\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] Epoch[43] Batch [10]#011Speed: 1965.46 samples/sec#011loss=2.753503\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747861209.9566982, \"EndTime\": 1747861210.9037123, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.7568397521973, \"count\": 1, \"min\": 946.7568397521973, \"max\": 946.7568397521973}}}\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1423.6800477823244 records/second\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.7838281284679067\n",
      "[05/21/2025 21:00:10 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] Epoch[44] Batch[0] avg_epoch_loss=2.622274\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.622274398803711\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] Epoch[44] Batch[5] avg_epoch_loss=2.714499\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.7144991954167685\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] Epoch[44] Batch [5]#011Speed: 2135.60 samples/sec#011loss=2.714499\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] Epoch[44] Batch[10] avg_epoch_loss=2.781725\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=2.8623965263366697\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] Epoch[44] Batch [10]#011Speed: 1990.55 samples/sec#011loss=2.862397\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747861210.903771, \"EndTime\": 1747861211.8627026, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.1201076507568, \"count\": 1, \"min\": 958.1201076507568, \"max\": 958.1201076507568}}}\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1361.9174648514625 records/second\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.7817252549258145\n",
      "[05/21/2025 21:00:11 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] Epoch[45] Batch[0] avg_epoch_loss=2.582828\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.5828278064727783\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] Epoch[45] Batch[5] avg_epoch_loss=2.703028\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.7030278046925864\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] Epoch[45] Batch [5]#011Speed: 1960.82 samples/sec#011loss=2.703028\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] Epoch[45] Batch[10] avg_epoch_loss=2.867827\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=3.0655853271484377\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] Epoch[45] Batch [10]#011Speed: 2074.49 samples/sec#011loss=3.065585\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747861211.8627627, \"EndTime\": 1747861212.8430512, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 980.0403118133545, \"count\": 1, \"min\": 980.0403118133545, \"max\": 980.0403118133545}}}\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1317.1668225094745 records/second\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.867826678536155\n",
      "[05/21/2025 21:00:12 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] Epoch[46] Batch[0] avg_epoch_loss=2.888059\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.888059139251709\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] Epoch[46] Batch[5] avg_epoch_loss=2.978540\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.97853950659434\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] Epoch[46] Batch [5]#011Speed: 2071.34 samples/sec#011loss=2.978540\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] Epoch[46] Batch[10] avg_epoch_loss=2.997956\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=3.0212563991546633\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] Epoch[46] Batch [10]#011Speed: 1994.35 samples/sec#011loss=3.021256\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747861212.8431165, \"EndTime\": 1747861213.803664, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.2618217468262, \"count\": 1, \"min\": 960.2618217468262, \"max\": 960.2618217468262}}}\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1357.8426186579054 records/second\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.9979562759399414\n",
      "[05/21/2025 21:00:13 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] Epoch[47] Batch[0] avg_epoch_loss=2.934215\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.9342148303985596\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] Epoch[47] Batch[5] avg_epoch_loss=2.876909\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.8769091765085855\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] Epoch[47] Batch [5]#011Speed: 2001.20 samples/sec#011loss=2.876909\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] Epoch[47] Batch[10] avg_epoch_loss=2.890040\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=2.9057960987091063\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] Epoch[47] Batch [10]#011Speed: 2042.36 samples/sec#011loss=2.905796\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747861213.803721, \"EndTime\": 1747861214.7631917, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 959.2239856719971, \"count\": 1, \"min\": 959.2239856719971, \"max\": 959.2239856719971}}}\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1347.844020720557 records/second\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.8900395956906406\n",
      "[05/21/2025 21:00:14 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] Epoch[48] Batch[0] avg_epoch_loss=2.866084\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.866084337234497\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] Epoch[48] Batch[5] avg_epoch_loss=2.833617\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.8336174488067627\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] Epoch[48] Batch [5]#011Speed: 2144.35 samples/sec#011loss=2.833617\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] Epoch[48] Batch[10] avg_epoch_loss=2.805785\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=2.772386884689331\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] Epoch[48] Batch [10]#011Speed: 1935.99 samples/sec#011loss=2.772387\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747861214.7632506, \"EndTime\": 1747861215.716227, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.7010917663574, \"count\": 1, \"min\": 952.7010917663574, \"max\": 952.7010917663574}}}\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1389.5927018875611 records/second\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.80578537420793\n",
      "[05/21/2025 21:00:15 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] Epoch[49] Batch[0] avg_epoch_loss=2.725348\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.725348472595215\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] Epoch[49] Batch[5] avg_epoch_loss=2.722072\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.7220720052719116\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] Epoch[49] Batch [5]#011Speed: 2118.26 samples/sec#011loss=2.722072\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] Epoch[49] Batch[10] avg_epoch_loss=2.718088\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=2.713306760787964\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] Epoch[49] Batch [10]#011Speed: 2033.63 samples/sec#011loss=2.713307\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747861215.7162912, \"EndTime\": 1747861216.6593502, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.52610206604, \"count\": 1, \"min\": 942.52610206604, \"max\": 942.52610206604}}}\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1396.1164292003289 records/second\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.7180878032337534\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_3451456e-b103-40dc-82f1-5d00c235f7fc-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861216.6594088, \"EndTime\": 1747861216.670686, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.998010635375977, \"count\": 1, \"min\": 10.998010635375977, \"max\": 10.998010635375977}}}\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] Epoch[50] Batch[0] avg_epoch_loss=2.757049\n",
      "[05/21/2025 21:00:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.757049322128296\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] Epoch[50] Batch[5] avg_epoch_loss=2.702782\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.7027817567189536\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] Epoch[50] Batch [5]#011Speed: 2061.13 samples/sec#011loss=2.702782\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] Epoch[50] Batch[10] avg_epoch_loss=2.798294\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.9129093647003175\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] Epoch[50] Batch [10]#011Speed: 1934.66 samples/sec#011loss=2.912909\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747861216.670746, \"EndTime\": 1747861217.6343777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.5765552520752, \"count\": 1, \"min\": 963.5765552520752, \"max\": 963.5765552520752}}}\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1389.4883732897895 records/second\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.7982943058013916\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] Epoch[51] Batch[0] avg_epoch_loss=2.859154\n",
      "[05/21/2025 21:00:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.859154462814331\n",
      "[05/21/2025 21:00:18 INFO 140363140085568] Epoch[51] Batch[5] avg_epoch_loss=2.833912\n",
      "[05/21/2025 21:00:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.833911975224813\n",
      "[05/21/2025 21:00:18 INFO 140363140085568] Epoch[51] Batch [5]#011Speed: 1971.10 samples/sec#011loss=2.833912\n",
      "[05/21/2025 21:00:18 INFO 140363140085568] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747861217.6344368, \"EndTime\": 1747861218.5321338, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.3755836486816, \"count\": 1, \"min\": 897.3755836486816, \"max\": 897.3755836486816}}}\n",
      "[05/21/2025 21:00:18 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1421.7719041864436 records/second\n",
      "[05/21/2025 21:00:18 INFO 140363140085568] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/21/2025 21:00:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.824135756492615\n",
      "[05/21/2025 21:00:18 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:18 INFO 140363140085568] Epoch[52] Batch[0] avg_epoch_loss=2.811680\n",
      "[05/21/2025 21:00:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.8116796016693115\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] Epoch[52] Batch[5] avg_epoch_loss=2.791652\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.7916515668233237\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] Epoch[52] Batch [5]#011Speed: 2040.35 samples/sec#011loss=2.791652\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] Epoch[52] Batch[10] avg_epoch_loss=2.857621\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=2.9367841243743897\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] Epoch[52] Batch [10]#011Speed: 1973.75 samples/sec#011loss=2.936784\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747861218.5321982, \"EndTime\": 1747861219.5128365, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 980.323314666748, \"count\": 1, \"min\": 980.323314666748, \"max\": 980.323314666748}}}\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1343.2925494041158 records/second\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.8576209111647173\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] Epoch[53] Batch[0] avg_epoch_loss=2.773363\n",
      "[05/21/2025 21:00:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.7733633518218994\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] Epoch[53] Batch[5] avg_epoch_loss=2.770102\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.770102381706238\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] Epoch[53] Batch [5]#011Speed: 2114.84 samples/sec#011loss=2.770102\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] Epoch[53] Batch[10] avg_epoch_loss=2.816090\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.8712754249572754\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] Epoch[53] Batch [10]#011Speed: 2021.92 samples/sec#011loss=2.871275\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747861219.5129073, \"EndTime\": 1747861220.4735374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.2470397949219, \"count\": 1, \"min\": 960.2470397949219, \"max\": 960.2470397949219}}}\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1394.3133965405907 records/second\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.816090128638528\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] Epoch[54] Batch[0] avg_epoch_loss=2.807888\n",
      "[05/21/2025 21:00:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.807887554168701\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] Epoch[54] Batch[5] avg_epoch_loss=2.737817\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.7378165324529014\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] Epoch[54] Batch [5]#011Speed: 1953.42 samples/sec#011loss=2.737817\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] Epoch[54] Batch[10] avg_epoch_loss=2.705572\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=2.666878843307495\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] Epoch[54] Batch [10]#011Speed: 1895.08 samples/sec#011loss=2.666879\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747861220.4735897, \"EndTime\": 1747861221.4765303, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1002.6803016662598, \"count\": 1, \"min\": 1002.6803016662598, \"max\": 1002.6803016662598}}}\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1338.2777261844474 records/second\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.7055721282958984\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_35ab6d7a-e71c-452e-91c3-838588711211-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861221.4765897, \"EndTime\": 1747861221.4878416, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.927677154541016, \"count\": 1, \"min\": 10.927677154541016, \"max\": 10.927677154541016}}}\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] Epoch[55] Batch[0] avg_epoch_loss=2.663378\n",
      "[05/21/2025 21:00:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.6633784770965576\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] Epoch[55] Batch[5] avg_epoch_loss=2.714292\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.7142922083536782\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] Epoch[55] Batch [5]#011Speed: 2103.48 samples/sec#011loss=2.714292\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] Epoch[55] Batch[10] avg_epoch_loss=2.730919\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.750871706008911\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] Epoch[55] Batch [10]#011Speed: 1958.75 samples/sec#011loss=2.750872\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747861221.487893, \"EndTime\": 1747861222.448028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.085391998291, \"count\": 1, \"min\": 960.085391998291, \"max\": 960.085391998291}}}\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1412.250921101836 records/second\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.7309192527424204\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] Epoch[56] Batch[0] avg_epoch_loss=2.618389\n",
      "[05/21/2025 21:00:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.618389129638672\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] Epoch[56] Batch[5] avg_epoch_loss=2.694039\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.69403870900472\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] Epoch[56] Batch [5]#011Speed: 1994.31 samples/sec#011loss=2.694039\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747861222.4480846, \"EndTime\": 1747861223.3359532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 887.5513076782227, \"count\": 1, \"min\": 887.5513076782227, \"max\": 887.5513076782227}}}\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1442.0244982858076 records/second\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.6795764207839965\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_83b92464-56b9-4b9e-81c9-0b46c025cdd6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861223.336014, \"EndTime\": 1747861223.3472447, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.91909408569336, \"count\": 1, \"min\": 10.91909408569336, \"max\": 10.91909408569336}}}\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] Epoch[57] Batch[0] avg_epoch_loss=2.751043\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.751042604446411\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] Epoch[57] Batch[5] avg_epoch_loss=2.621385\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.621384859085083\n",
      "[05/21/2025 21:00:23 INFO 140363140085568] Epoch[57] Batch [5]#011Speed: 2114.99 samples/sec#011loss=2.621385\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] Epoch[57] Batch[10] avg_epoch_loss=2.668949\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=2.7260263919830323\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] Epoch[57] Batch [10]#011Speed: 2004.57 samples/sec#011loss=2.726026\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747861223.3472958, \"EndTime\": 1747861224.2987628, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.4060020446777, \"count\": 1, \"min\": 951.4060020446777, \"max\": 951.4060020446777}}}\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1375.6802327635435 records/second\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.6689491922205146\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_f0a2368a-1dc9-432d-bee7-2f69492e1a22-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861224.2988591, \"EndTime\": 1747861224.3097901, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.698080062866211, \"count\": 1, \"min\": 10.698080062866211, \"max\": 10.698080062866211}}}\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] Epoch[58] Batch[0] avg_epoch_loss=2.641846\n",
      "[05/21/2025 21:00:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.641845941543579\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] Epoch[58] Batch[5] avg_epoch_loss=2.666394\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.666393836339315\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] Epoch[58] Batch [5]#011Speed: 1616.18 samples/sec#011loss=2.666394\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] Epoch[58] Batch[10] avg_epoch_loss=2.744870\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.839042329788208\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] Epoch[58] Batch [10]#011Speed: 1900.27 samples/sec#011loss=2.839042\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747861224.3098392, \"EndTime\": 1747861225.367742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1057.854413986206, \"count\": 1, \"min\": 1057.854413986206, \"max\": 1057.854413986206}}}\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1248.6499399526697 records/second\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.74487042427063\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] Epoch[59] Batch[0] avg_epoch_loss=2.673641\n",
      "[05/21/2025 21:00:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.673640727996826\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] Epoch[59] Batch[5] avg_epoch_loss=2.691321\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.6913211345672607\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] Epoch[59] Batch [5]#011Speed: 1870.46 samples/sec#011loss=2.691321\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747861225.3678021, \"EndTime\": 1747861226.3059945, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.9312992095947, \"count\": 1, \"min\": 937.9312992095947, \"max\": 937.9312992095947}}}\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1349.639743034154 records/second\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.6882427453994753\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] Epoch[60] Batch[0] avg_epoch_loss=2.631674\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.631673574447632\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] Epoch[60] Batch[5] avg_epoch_loss=2.648487\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.648486773173014\n",
      "[05/21/2025 21:00:26 INFO 140363140085568] Epoch[60] Batch [5]#011Speed: 1895.49 samples/sec#011loss=2.648487\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] Epoch[60] Batch[10] avg_epoch_loss=2.653626\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.6597930908203127\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] Epoch[60] Batch [10]#011Speed: 1958.30 samples/sec#011loss=2.659793\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747861226.3060613, \"EndTime\": 1747861227.300169, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 993.7586784362793, \"count\": 1, \"min\": 993.7586784362793, \"max\": 993.7586784362793}}}\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1352.3258414755878 records/second\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.6536260084672407\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_75bd82bb-5a7d-4076-81f9-d338d49b8b17-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861227.3002262, \"EndTime\": 1747861227.3111923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.674476623535156, \"count\": 1, \"min\": 10.674476623535156, \"max\": 10.674476623535156}}}\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] Epoch[61] Batch[0] avg_epoch_loss=2.619561\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.619560956954956\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] Epoch[61] Batch[5] avg_epoch_loss=2.618793\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.6187928915023804\n",
      "[05/21/2025 21:00:27 INFO 140363140085568] Epoch[61] Batch [5]#011Speed: 2165.68 samples/sec#011loss=2.618793\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] Epoch[61] Batch[10] avg_epoch_loss=2.666406\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=2.723542404174805\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] Epoch[61] Batch [10]#011Speed: 1917.97 samples/sec#011loss=2.723542\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747861227.3112404, \"EndTime\": 1747861228.2617648, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.4756927490234, \"count\": 1, \"min\": 950.4756927490234, \"max\": 950.4756927490234}}}\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1387.576859167502 records/second\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.6664063063534824\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] Epoch[62] Batch[0] avg_epoch_loss=2.676504\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.676504135131836\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] Epoch[62] Batch[5] avg_epoch_loss=2.651660\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.651659925778707\n",
      "[05/21/2025 21:00:28 INFO 140363140085568] Epoch[62] Batch [5]#011Speed: 2142.72 samples/sec#011loss=2.651660\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] Epoch[62] Batch[10] avg_epoch_loss=2.614236\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.5693270206451415\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] Epoch[62] Batch [10]#011Speed: 2049.32 samples/sec#011loss=2.569327\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747861228.2618387, \"EndTime\": 1747861229.1973486, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.2505207061768, \"count\": 1, \"min\": 935.2505207061768, \"max\": 935.2505207061768}}}\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1413.3996201447183 records/second\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.6142358779907227\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_ae9a70bf-be5a-4623-90b8-2f395a5596ea-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861229.1974041, \"EndTime\": 1747861229.2077804, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.113716125488281, \"count\": 1, \"min\": 10.113716125488281, \"max\": 10.113716125488281}}}\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] Epoch[63] Batch[0] avg_epoch_loss=2.616477\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.6164772510528564\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] Epoch[63] Batch[5] avg_epoch_loss=2.649149\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.64914878209432\n",
      "[05/21/2025 21:00:29 INFO 140363140085568] Epoch[63] Batch [5]#011Speed: 2128.98 samples/sec#011loss=2.649149\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] Epoch[63] Batch[10] avg_epoch_loss=2.653965\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.6597447872161863\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] Epoch[63] Batch [10]#011Speed: 1905.81 samples/sec#011loss=2.659745\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747861229.2078323, \"EndTime\": 1747861230.1591854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.3044357299805, \"count\": 1, \"min\": 951.3044357299805, \"max\": 951.3044357299805}}}\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1440.9905081514426 records/second\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.6539651480588047\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] Epoch[64] Batch[0] avg_epoch_loss=2.599788\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.599787950515747\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] Epoch[64] Batch[5] avg_epoch_loss=2.624546\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.6245456536610923\n",
      "[05/21/2025 21:00:30 INFO 140363140085568] Epoch[64] Batch [5]#011Speed: 2111.29 samples/sec#011loss=2.624546\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] Epoch[64] Batch[10] avg_epoch_loss=2.580750\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=2.528195381164551\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] Epoch[64] Batch [10]#011Speed: 2057.74 samples/sec#011loss=2.528195\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747861230.159282, \"EndTime\": 1747861231.0974374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.8960132598877, \"count\": 1, \"min\": 937.8960132598877, \"max\": 937.8960132598877}}}\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1373.1619545429821 records/second\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.5807500752535733\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_4655425f-3a42-4a50-a732-7d874242d388-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861231.0974948, \"EndTime\": 1747861231.1082377, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.468721389770508, \"count\": 1, \"min\": 10.468721389770508, \"max\": 10.468721389770508}}}\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] Epoch[65] Batch[0] avg_epoch_loss=2.758550\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.758549690246582\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] Epoch[65] Batch[5] avg_epoch_loss=2.627949\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.6279485623041787\n",
      "[05/21/2025 21:00:31 INFO 140363140085568] Epoch[65] Batch [5]#011Speed: 2107.40 samples/sec#011loss=2.627949\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] Epoch[65] Batch[10] avg_epoch_loss=2.594572\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.5545201301574707\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] Epoch[65] Batch [10]#011Speed: 1995.81 samples/sec#011loss=2.554520\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747861231.1082983, \"EndTime\": 1747861232.0505261, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.1727657318115, \"count\": 1, \"min\": 942.1727657318115, \"max\": 942.1727657318115}}}\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1414.686310479596 records/second\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.594572002237493\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] Epoch[66] Batch[0] avg_epoch_loss=2.770064\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.770064115524292\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] Epoch[66] Batch[5] avg_epoch_loss=2.583533\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.583532969156901\n",
      "[05/21/2025 21:00:32 INFO 140363140085568] Epoch[66] Batch [5]#011Speed: 1988.37 samples/sec#011loss=2.583533\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] Epoch[66] Batch[10] avg_epoch_loss=2.600248\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.6203070640563966\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] Epoch[66] Batch [10]#011Speed: 2078.01 samples/sec#011loss=2.620307\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747861232.0505831, \"EndTime\": 1747861233.009194, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.3642482757568, \"count\": 1, \"min\": 958.3642482757568, \"max\": 958.3642482757568}}}\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1357.4055970949355 records/second\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.6002484668384898\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] Epoch[67] Batch[0] avg_epoch_loss=2.786592\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.7865922451019287\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] Epoch[67] Batch[5] avg_epoch_loss=2.646813\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.646812915802002\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] Epoch[67] Batch [5]#011Speed: 2031.83 samples/sec#011loss=2.646813\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] Epoch[67] Batch[10] avg_epoch_loss=2.649563\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.6528637409210205\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] Epoch[67] Batch [10]#011Speed: 2110.38 samples/sec#011loss=2.652864\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747861233.0092504, \"EndTime\": 1747861233.9519172, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.3930644989014, \"count\": 1, \"min\": 942.3930644989014, \"max\": 942.3930644989014}}}\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1374.0329446716107 records/second\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.649563290856101\n",
      "[05/21/2025 21:00:33 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] Epoch[68] Batch[0] avg_epoch_loss=2.690135\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.6901350021362305\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] Epoch[68] Batch[5] avg_epoch_loss=2.629837\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.6298370361328125\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] Epoch[68] Batch [5]#011Speed: 2086.57 samples/sec#011loss=2.629837\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] Epoch[68] Batch[10] avg_epoch_loss=2.639033\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.650068187713623\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] Epoch[68] Batch [10]#011Speed: 2084.43 samples/sec#011loss=2.650068\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747861233.9519763, \"EndTime\": 1747861234.8925958, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.3598308563232, \"count\": 1, \"min\": 940.3598308563232, \"max\": 940.3598308563232}}}\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1370.628160499489 records/second\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.63903301412409\n",
      "[05/21/2025 21:00:34 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] Epoch[69] Batch[0] avg_epoch_loss=2.739104\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.7391040325164795\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] Epoch[69] Batch[5] avg_epoch_loss=2.671291\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.671290556589762\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] Epoch[69] Batch [5]#011Speed: 2121.33 samples/sec#011loss=2.671291\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] Epoch[69] Batch[10] avg_epoch_loss=2.565826\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.4392694234848022\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] Epoch[69] Batch [10]#011Speed: 2086.45 samples/sec#011loss=2.439269\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747861234.8926535, \"EndTime\": 1747861235.8246484, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.7326545715332, \"count\": 1, \"min\": 931.7326545715332, \"max\": 931.7326545715332}}}\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1415.509198925272 records/second\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.565826405178417\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:35 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_0bfe17b7-f68f-4455-85b9-039edf221705-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861235.8247077, \"EndTime\": 1747861235.8359594, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.971784591674805, \"count\": 1, \"min\": 10.971784591674805, \"max\": 10.971784591674805}}}\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] Epoch[70] Batch[0] avg_epoch_loss=2.628992\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.6289918422698975\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] Epoch[70] Batch[5] avg_epoch_loss=2.619813\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.6198129256566367\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] Epoch[70] Batch [5]#011Speed: 2048.49 samples/sec#011loss=2.619813\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] Epoch[70] Batch[10] avg_epoch_loss=2.633028\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.648886871337891\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] Epoch[70] Batch [10]#011Speed: 2089.56 samples/sec#011loss=2.648887\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747861235.8360105, \"EndTime\": 1747861236.774961, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.8997554779053, \"count\": 1, \"min\": 938.8997554779053, \"max\": 938.8997554779053}}}\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1397.244385176368 records/second\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.633028355511752\n",
      "[05/21/2025 21:00:36 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] Epoch[71] Batch[0] avg_epoch_loss=2.667775\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.6677749156951904\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] Epoch[71] Batch[5] avg_epoch_loss=2.613420\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.6134198109308877\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] Epoch[71] Batch [5]#011Speed: 2044.03 samples/sec#011loss=2.613420\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] Epoch[71] Batch[10] avg_epoch_loss=2.642284\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.6769216537475584\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] Epoch[71] Batch [10]#011Speed: 1842.82 samples/sec#011loss=2.676922\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747861236.7750223, \"EndTime\": 1747861237.758841, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 983.5262298583984, \"count\": 1, \"min\": 983.5262298583984, \"max\": 983.5262298583984}}}\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1347.0725314125682 records/second\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.6422842849384653\n",
      "[05/21/2025 21:00:37 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] Epoch[72] Batch[0] avg_epoch_loss=2.579591\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.5795912742614746\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] Epoch[72] Batch[5] avg_epoch_loss=2.557804\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.557804306348165\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] Epoch[72] Batch [5]#011Speed: 2156.70 samples/sec#011loss=2.557804\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] Epoch[72] Batch[10] avg_epoch_loss=2.550532\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.541806221008301\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] Epoch[72] Batch [10]#011Speed: 1906.83 samples/sec#011loss=2.541806\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747861237.7589004, \"EndTime\": 1747861238.7126014, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.3929824829102, \"count\": 1, \"min\": 953.3929824829102, \"max\": 953.3929824829102}}}\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1407.4771729511617 records/second\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.5505324493754995\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:38 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_930f803a-0fde-4d9e-a67a-104f0ed661c0-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861238.712658, \"EndTime\": 1747861238.7228544, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.927749633789062, \"count\": 1, \"min\": 9.927749633789062, \"max\": 9.927749633789062}}}\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] Epoch[73] Batch[0] avg_epoch_loss=2.505185\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.5051846504211426\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] Epoch[73] Batch[5] avg_epoch_loss=2.600568\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.600567857424418\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] Epoch[73] Batch [5]#011Speed: 2068.44 samples/sec#011loss=2.600568\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] processed a total of 1271 examples\n",
      "#metrics {\"StartTime\": 1747861238.7229075, \"EndTime\": 1747861239.6092253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 886.2671852111816, \"count\": 1, \"min\": 886.2671852111816, \"max\": 886.2671852111816}}}\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1433.9473854945097 records/second\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.6085107564926147\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] Epoch[74] Batch[0] avg_epoch_loss=2.586171\n",
      "[05/21/2025 21:00:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.5861706733703613\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] Epoch[74] Batch[5] avg_epoch_loss=2.546085\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.5460845232009888\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] Epoch[74] Batch [5]#011Speed: 2125.36 samples/sec#011loss=2.546085\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] Epoch[74] Batch[10] avg_epoch_loss=2.464184\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.365904116630554\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] Epoch[74] Batch [10]#011Speed: 2058.43 samples/sec#011loss=2.365904\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747861239.6092913, \"EndTime\": 1747861240.5491936, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.6052360534668, \"count\": 1, \"min\": 939.6052360534668, \"max\": 939.6052360534668}}}\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1408.9719134663078 records/second\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.4641843383962456\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_7cad8ebc-1b1c-41c4-9b85-a94725db764e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861240.5492527, \"EndTime\": 1747861240.559976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.454177856445312, \"count\": 1, \"min\": 10.454177856445312, \"max\": 10.454177856445312}}}\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] Epoch[75] Batch[0] avg_epoch_loss=2.584427\n",
      "[05/21/2025 21:00:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.5844271183013916\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] Epoch[75] Batch[5] avg_epoch_loss=2.530530\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.530530055363973\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] Epoch[75] Batch [5]#011Speed: 1972.72 samples/sec#011loss=2.530530\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] Epoch[75] Batch[10] avg_epoch_loss=2.559623\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=2.5945343017578124\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] Epoch[75] Batch [10]#011Speed: 2050.70 samples/sec#011loss=2.594534\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747861240.5600326, \"EndTime\": 1747861241.5403907, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 980.3037643432617, \"count\": 1, \"min\": 980.3037643432617, \"max\": 980.3037643432617}}}\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1315.796718589383 records/second\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.5596228946339\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] Epoch[76] Batch[0] avg_epoch_loss=2.470823\n",
      "[05/21/2025 21:00:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.470822811126709\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] Epoch[76] Batch[5] avg_epoch_loss=2.557099\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.557098627090454\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] Epoch[76] Batch [5]#011Speed: 2169.65 samples/sec#011loss=2.557099\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] Epoch[76] Batch[10] avg_epoch_loss=2.562377\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.5687111377716065\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] Epoch[76] Batch [10]#011Speed: 2052.82 samples/sec#011loss=2.568711\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747861241.5404515, \"EndTime\": 1747861242.472942, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.1925640106201, \"count\": 1, \"min\": 932.1925640106201, \"max\": 932.1925640106201}}}\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1469.5154958767512 records/second\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.5623770410364326\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] Epoch[77] Batch[0] avg_epoch_loss=2.541709\n",
      "[05/21/2025 21:00:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.5417091846466064\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] Epoch[77] Batch[5] avg_epoch_loss=2.529617\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.5296167135238647\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] Epoch[77] Batch [5]#011Speed: 2022.22 samples/sec#011loss=2.529617\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] Epoch[77] Batch[10] avg_epoch_loss=2.510648\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.487885570526123\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] Epoch[77] Batch [10]#011Speed: 2097.44 samples/sec#011loss=2.487886\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747861242.473002, \"EndTime\": 1747861243.4332259, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 959.9728584289551, \"count\": 1, \"min\": 959.9728584289551, \"max\": 959.9728584289551}}}\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1373.8746834006452 records/second\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.510648012161255\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] Epoch[78] Batch[0] avg_epoch_loss=2.451711\n",
      "[05/21/2025 21:00:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.4517107009887695\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] Epoch[78] Batch[5] avg_epoch_loss=2.565409\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.565409262975057\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] Epoch[78] Batch [5]#011Speed: 2060.42 samples/sec#011loss=2.565409\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] Epoch[78] Batch[10] avg_epoch_loss=2.678605\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.814438819885254\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] Epoch[78] Batch [10]#011Speed: 2002.09 samples/sec#011loss=2.814439\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747861243.4332843, \"EndTime\": 1747861244.3891854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.655574798584, \"count\": 1, \"min\": 955.655574798584, \"max\": 955.655574798584}}}\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1389.484367902169 records/second\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.6786045161160557\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] Epoch[79] Batch[0] avg_epoch_loss=2.625437\n",
      "[05/21/2025 21:00:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.6254374980926514\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] Epoch[79] Batch[5] avg_epoch_loss=2.639215\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.639215350151062\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] Epoch[79] Batch [5]#011Speed: 2143.21 samples/sec#011loss=2.639215\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] Epoch[79] Batch[10] avg_epoch_loss=2.635579\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.6312164783477785\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] Epoch[79] Batch [10]#011Speed: 2042.49 samples/sec#011loss=2.631216\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747861244.3892498, \"EndTime\": 1747861245.3221793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.6441287994385, \"count\": 1, \"min\": 932.6441287994385, \"max\": 932.6441287994385}}}\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1464.5189472492243 records/second\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.6355794993313877\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] Epoch[80] Batch[0] avg_epoch_loss=2.598769\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.598769187927246\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] Epoch[80] Batch[5] avg_epoch_loss=2.595627\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.5956273078918457\n",
      "[05/21/2025 21:00:45 INFO 140363140085568] Epoch[80] Batch [5]#011Speed: 2034.27 samples/sec#011loss=2.595627\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] Epoch[80] Batch[10] avg_epoch_loss=2.582947\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.567730760574341\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] Epoch[80] Batch [10]#011Speed: 2011.40 samples/sec#011loss=2.567731\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747861245.322237, \"EndTime\": 1747861246.277987, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.496072769165, \"count\": 1, \"min\": 955.496072769165, \"max\": 955.496072769165}}}\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1397.0339366177152 records/second\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.5829470591111616\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] Epoch[81] Batch[0] avg_epoch_loss=2.585048\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.585047960281372\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] Epoch[81] Batch[5] avg_epoch_loss=2.501893\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.501892924308777\n",
      "[05/21/2025 21:00:46 INFO 140363140085568] Epoch[81] Batch [5]#011Speed: 2015.20 samples/sec#011loss=2.501893\n",
      "[05/21/2025 21:00:47 INFO 140363140085568] processed a total of 1258 examples\n",
      "#metrics {\"StartTime\": 1747861246.2780569, \"EndTime\": 1747861247.1886528, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.2518558502197, \"count\": 1, \"min\": 910.2518558502197, \"max\": 910.2518558502197}}}\n",
      "[05/21/2025 21:00:47 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1381.8888551040168 records/second\n",
      "[05/21/2025 21:00:47 INFO 140363140085568] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/21/2025 21:00:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.525664043426514\n",
      "[05/21/2025 21:00:47 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:47 INFO 140363140085568] Epoch[82] Batch[0] avg_epoch_loss=2.572961\n",
      "[05/21/2025 21:00:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.5729613304138184\n",
      "[05/21/2025 21:00:47 INFO 140363140085568] Epoch[82] Batch[5] avg_epoch_loss=2.469762\n",
      "[05/21/2025 21:00:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.469761530558268\n",
      "[05/21/2025 21:00:47 INFO 140363140085568] Epoch[82] Batch [5]#011Speed: 1974.45 samples/sec#011loss=2.469762\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] Epoch[82] Batch[10] avg_epoch_loss=2.515518\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=2.5704252243041994\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] Epoch[82] Batch [10]#011Speed: 1439.14 samples/sec#011loss=2.570425\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747861247.188714, \"EndTime\": 1747861248.270808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1081.4194679260254, \"count\": 1, \"min\": 1081.4194679260254, \"max\": 1081.4194679260254}}}\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1266.7526453524708 records/second\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.515517754988237\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] Epoch[83] Batch[0] avg_epoch_loss=2.536398\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.536397933959961\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] Epoch[83] Batch[5] avg_epoch_loss=2.492405\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.492404659589132\n",
      "[05/21/2025 21:00:48 INFO 140363140085568] Epoch[83] Batch [5]#011Speed: 2129.86 samples/sec#011loss=2.492405\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] Epoch[83] Batch[10] avg_epoch_loss=2.508945\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.528792953491211\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] Epoch[83] Batch [10]#011Speed: 1976.79 samples/sec#011loss=2.528793\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747861248.2708654, \"EndTime\": 1747861249.2332299, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 962.1100425720215, \"count\": 1, \"min\": 962.1100425720215, \"max\": 962.1100425720215}}}\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1404.0838460244254 records/second\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.508944793180986\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] Epoch[84] Batch[0] avg_epoch_loss=2.451847\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.4518473148345947\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] Epoch[84] Batch[5] avg_epoch_loss=2.480767\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.480766852696737\n",
      "[05/21/2025 21:00:49 INFO 140363140085568] Epoch[84] Batch [5]#011Speed: 2129.16 samples/sec#011loss=2.480767\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] Epoch[84] Batch[10] avg_epoch_loss=2.524607\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.5772141933441164\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] Epoch[84] Batch [10]#011Speed: 1949.59 samples/sec#011loss=2.577214\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] processed a total of 1392 examples\n",
      "#metrics {\"StartTime\": 1747861249.2332869, \"EndTime\": 1747861250.1817641, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.2324123382568, \"count\": 1, \"min\": 948.2324123382568, \"max\": 948.2324123382568}}}\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1467.8668366552936 records/second\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.524606552991\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] Epoch[85] Batch[0] avg_epoch_loss=2.547412\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.547412395477295\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] Epoch[85] Batch[5] avg_epoch_loss=2.508717\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.5087172985076904\n",
      "[05/21/2025 21:00:50 INFO 140363140085568] Epoch[85] Batch [5]#011Speed: 1804.73 samples/sec#011loss=2.508717\n",
      "[05/21/2025 21:00:51 INFO 140363140085568] processed a total of 1271 examples\n",
      "#metrics {\"StartTime\": 1747861250.1818213, \"EndTime\": 1747861251.1432524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.1678123474121, \"count\": 1, \"min\": 961.1678123474121, \"max\": 961.1678123474121}}}\n",
      "[05/21/2025 21:00:51 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1322.2185419524137 records/second\n",
      "[05/21/2025 21:00:51 INFO 140363140085568] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/21/2025 21:00:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.497562050819397\n",
      "[05/21/2025 21:00:51 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:51 INFO 140363140085568] Epoch[86] Batch[0] avg_epoch_loss=2.379496\n",
      "[05/21/2025 21:00:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.379495620727539\n",
      "[05/21/2025 21:00:51 INFO 140363140085568] Epoch[86] Batch[5] avg_epoch_loss=2.461039\n",
      "[05/21/2025 21:00:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.461038867632548\n",
      "[05/21/2025 21:00:51 INFO 140363140085568] Epoch[86] Batch [5]#011Speed: 1942.28 samples/sec#011loss=2.461039\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] Epoch[86] Batch[10] avg_epoch_loss=2.460536\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.459932565689087\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] Epoch[86] Batch [10]#011Speed: 2001.10 samples/sec#011loss=2.459933\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747861251.1433165, \"EndTime\": 1747861252.1257665, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 982.1536540985107, \"count\": 1, \"min\": 982.1536540985107, \"max\": 982.1536540985107}}}\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1343.866153245679 records/second\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.460536003112793\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_e4e762b3-c6fb-4ac8-82ae-db9eb76e6b63-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861252.1258242, \"EndTime\": 1747861252.1364734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.344982147216797, \"count\": 1, \"min\": 10.344982147216797, \"max\": 10.344982147216797}}}\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] Epoch[87] Batch[0] avg_epoch_loss=2.577242\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.577242374420166\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] Epoch[87] Batch[5] avg_epoch_loss=2.480382\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.4803820053736367\n",
      "[05/21/2025 21:00:52 INFO 140363140085568] Epoch[87] Batch [5]#011Speed: 2079.90 samples/sec#011loss=2.480382\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] Epoch[87] Batch[10] avg_epoch_loss=2.492155\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.5062818050384523\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] Epoch[87] Batch [10]#011Speed: 2001.49 samples/sec#011loss=2.506282\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747861252.1365407, \"EndTime\": 1747861253.108006, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 971.4093208312988, \"count\": 1, \"min\": 971.4093208312988, \"max\": 971.4093208312988}}}\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1360.776062540723 records/second\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.4921546415849165\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] Epoch[88] Batch[0] avg_epoch_loss=2.473748\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.473747968673706\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] Epoch[88] Batch[5] avg_epoch_loss=2.493769\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.4937692880630493\n",
      "[05/21/2025 21:00:53 INFO 140363140085568] Epoch[88] Batch [5]#011Speed: 1882.85 samples/sec#011loss=2.493769\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] processed a total of 1242 examples\n",
      "#metrics {\"StartTime\": 1747861253.1080725, \"EndTime\": 1747861254.0348766, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.4471530914307, \"count\": 1, \"min\": 926.4471530914307, \"max\": 926.4471530914307}}}\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1340.472182115786 records/second\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.4391225576400757\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_cfaf8c1f-56dd-4428-ba9a-2eec4d599c54-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861254.0349398, \"EndTime\": 1747861254.0460193, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.76197624206543, \"count\": 1, \"min\": 10.76197624206543, \"max\": 10.76197624206543}}}\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] Epoch[89] Batch[0] avg_epoch_loss=2.516642\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.5166420936584473\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] Epoch[89] Batch[5] avg_epoch_loss=2.458377\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.458376924196879\n",
      "[05/21/2025 21:00:54 INFO 140363140085568] Epoch[89] Batch [5]#011Speed: 2078.63 samples/sec#011loss=2.458377\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] Epoch[89] Batch[10] avg_epoch_loss=2.555780\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=2.672663116455078\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] Epoch[89] Batch [10]#011Speed: 1710.70 samples/sec#011loss=2.672663\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747861254.0460737, \"EndTime\": 1747861255.0515053, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1005.3832530975342, \"count\": 1, \"min\": 1005.3832530975342, \"max\": 1005.3832530975342}}}\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1323.759930419013 records/second\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.555779738859697\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] Epoch[90] Batch[0] avg_epoch_loss=2.519145\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.5191452503204346\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] Epoch[90] Batch[5] avg_epoch_loss=2.535330\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.535329580307007\n",
      "[05/21/2025 21:00:55 INFO 140363140085568] Epoch[90] Batch [5]#011Speed: 2158.37 samples/sec#011loss=2.535330\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] Epoch[90] Batch[10] avg_epoch_loss=2.460413\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.3705138683319094\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] Epoch[90] Batch [10]#011Speed: 1834.49 samples/sec#011loss=2.370514\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747861255.0515637, \"EndTime\": 1747861256.014936, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.1221294403076, \"count\": 1, \"min\": 963.1221294403076, \"max\": 963.1221294403076}}}\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1380.7984407916933 records/second\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.4604133475910532\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] Epoch[91] Batch[0] avg_epoch_loss=2.599958\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.5999579429626465\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] Epoch[91] Batch[5] avg_epoch_loss=2.488880\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.4888797601064048\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] Epoch[91] Batch [5]#011Speed: 2124.12 samples/sec#011loss=2.488880\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] Epoch[91] Batch[10] avg_epoch_loss=2.552381\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=2.6285826683044435\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] Epoch[91] Batch [10]#011Speed: 1912.64 samples/sec#011loss=2.628583\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747861256.0149956, \"EndTime\": 1747861256.9795868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 964.3268585205078, \"count\": 1, \"min\": 964.3268585205078, \"max\": 964.3268585205078}}}\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1339.6734593376689 records/second\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.552381082014604\n",
      "[05/21/2025 21:00:56 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] Epoch[92] Batch[0] avg_epoch_loss=2.512619\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.5126194953918457\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] Epoch[92] Batch[5] avg_epoch_loss=2.460805\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.460805376370748\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] Epoch[92] Batch [5]#011Speed: 2039.63 samples/sec#011loss=2.460805\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] Epoch[92] Batch[10] avg_epoch_loss=2.496464\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.5392550945281984\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] Epoch[92] Batch [10]#011Speed: 1985.02 samples/sec#011loss=2.539255\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747861256.979647, \"EndTime\": 1747861257.9477992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 967.9069519042969, \"count\": 1, \"min\": 967.9069519042969, \"max\": 967.9069519042969}}}\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1337.8192331242558 records/second\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.496464339169589\n",
      "[05/21/2025 21:00:57 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] Epoch[93] Batch[0] avg_epoch_loss=2.526752\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.5267515182495117\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] Epoch[93] Batch[5] avg_epoch_loss=2.509496\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.5094964106877646\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] Epoch[93] Batch [5]#011Speed: 2062.74 samples/sec#011loss=2.509496\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] Epoch[93] Batch[10] avg_epoch_loss=2.515006\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.5216166973114014\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] Epoch[93] Batch [10]#011Speed: 1915.12 samples/sec#011loss=2.521617\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747861257.9478564, \"EndTime\": 1747861258.9123282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 964.2224311828613, \"count\": 1, \"min\": 964.2224311828613, \"max\": 964.2224311828613}}}\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1407.137290851743 records/second\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.5150056318803267\n",
      "[05/21/2025 21:00:58 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] Epoch[94] Batch[0] avg_epoch_loss=2.406330\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.406330108642578\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] Epoch[94] Batch[5] avg_epoch_loss=2.445181\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.4451813300450644\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] Epoch[94] Batch [5]#011Speed: 2005.54 samples/sec#011loss=2.445181\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] Epoch[94] Batch[10] avg_epoch_loss=2.493240\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=2.5509105205535887\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] Epoch[94] Batch [10]#011Speed: 1898.58 samples/sec#011loss=2.550911\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747861258.9124439, \"EndTime\": 1747861259.9236338, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1010.7994079589844, \"count\": 1, \"min\": 1010.7994079589844, \"max\": 1010.7994079589844}}}\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1295.8935801532136 records/second\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.4932400530034844\n",
      "[05/21/2025 21:00:59 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] Epoch[95] Batch[0] avg_epoch_loss=2.451080\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.4510796070098877\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] Epoch[95] Batch[5] avg_epoch_loss=2.504305\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.5043051640192666\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] Epoch[95] Batch [5]#011Speed: 2171.35 samples/sec#011loss=2.504305\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] Epoch[95] Batch[10] avg_epoch_loss=2.391413\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.2559420108795165\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] Epoch[95] Batch [10]#011Speed: 2021.66 samples/sec#011loss=2.255942\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747861259.9236913, \"EndTime\": 1747861260.8600473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.83083152771, \"count\": 1, \"min\": 935.83083152771, \"max\": 935.83083152771}}}\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1420.9689619080393 records/second\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.3914128216830166\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:01:00 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_15c6e296-9cd0-412c-a88f-5946240f4832-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861260.86014, \"EndTime\": 1747861260.8708985, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.415792465209961, \"count\": 1, \"min\": 10.415792465209961, \"max\": 10.415792465209961}}}\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] Epoch[96] Batch[0] avg_epoch_loss=2.427270\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.427269697189331\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] Epoch[96] Batch[5] avg_epoch_loss=2.458327\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.4583268960316977\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] Epoch[96] Batch [5]#011Speed: 2173.90 samples/sec#011loss=2.458327\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] Epoch[96] Batch[10] avg_epoch_loss=2.489237\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.5263296604156493\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] Epoch[96] Batch [10]#011Speed: 1848.67 samples/sec#011loss=2.526330\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747861260.8709505, \"EndTime\": 1747861261.8515468, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 980.5479049682617, \"count\": 1, \"min\": 980.5479049682617, \"max\": 980.5479049682617}}}\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1329.7154801990669 records/second\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.4892372434789483\n",
      "[05/21/2025 21:01:01 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] Epoch[97] Batch[0] avg_epoch_loss=2.570617\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.5706169605255127\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] Epoch[97] Batch[5] avg_epoch_loss=2.479437\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.4794368346532187\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] Epoch[97] Batch [5]#011Speed: 1987.61 samples/sec#011loss=2.479437\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] Epoch[97] Batch[10] avg_epoch_loss=2.460568\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.4379262924194336\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] Epoch[97] Batch [10]#011Speed: 1973.12 samples/sec#011loss=2.437926\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747861261.851631, \"EndTime\": 1747861262.823438, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 971.5242385864258, \"count\": 1, \"min\": 971.5242385864258, \"max\": 971.5242385864258}}}\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1418.2612967049524 records/second\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.4605684063651343\n",
      "[05/21/2025 21:01:02 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:03 INFO 140363140085568] Epoch[98] Batch[0] avg_epoch_loss=2.352874\n",
      "[05/21/2025 21:01:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.3528735637664795\n",
      "[05/21/2025 21:01:03 INFO 140363140085568] Epoch[98] Batch[5] avg_epoch_loss=2.417849\n",
      "[05/21/2025 21:01:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.417848984400431\n",
      "[05/21/2025 21:01:03 INFO 140363140085568] Epoch[98] Batch [5]#011Speed: 2129.83 samples/sec#011loss=2.417849\n",
      "[05/21/2025 21:01:03 INFO 140363140085568] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747861262.823498, \"EndTime\": 1747861263.7262533, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 902.484655380249, \"count\": 1, \"min\": 902.484655380249, \"max\": 902.484655380249}}}\n",
      "[05/21/2025 21:01:03 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1409.6025682182985 records/second\n",
      "[05/21/2025 21:01:03 INFO 140363140085568] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/21/2025 21:01:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.4086316585540772\n",
      "[05/21/2025 21:01:03 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] Epoch[99] Batch[0] avg_epoch_loss=2.522444\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.5224437713623047\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] Epoch[99] Batch[5] avg_epoch_loss=2.473640\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.4736400842666626\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] Epoch[99] Batch [5]#011Speed: 2028.59 samples/sec#011loss=2.473640\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] Epoch[99] Batch[10] avg_epoch_loss=2.464723\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=2.454022741317749\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] Epoch[99] Batch [10]#011Speed: 1966.26 samples/sec#011loss=2.454023\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747861263.7268305, \"EndTime\": 1747861264.6955676, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 968.3723449707031, \"count\": 1, \"min\": 968.3723449707031, \"max\": 968.3723449707031}}}\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1345.4296056751891 records/second\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.4647231101989746\n",
      "[05/21/2025 21:01:04 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] Epoch[100] Batch[0] avg_epoch_loss=2.399538\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.399538278579712\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] Epoch[100] Batch[5] avg_epoch_loss=2.443320\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.4433199564615884\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] Epoch[100] Batch [5]#011Speed: 1924.14 samples/sec#011loss=2.443320\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] Epoch[100] Batch[10] avg_epoch_loss=2.430591\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.4153165340423586\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] Epoch[100] Batch [10]#011Speed: 1908.54 samples/sec#011loss=2.415317\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747861264.6956298, \"EndTime\": 1747861265.6876674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 991.7385578155518, \"count\": 1, \"min\": 991.7385578155518, \"max\": 991.7385578155518}}}\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1350.0380301879009 records/second\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.4305911280892114\n",
      "[05/21/2025 21:01:05 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] Epoch[101] Batch[0] avg_epoch_loss=2.412704\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.4127037525177\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] Epoch[101] Batch[5] avg_epoch_loss=2.425968\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.4259680112202964\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] Epoch[101] Batch [5]#011Speed: 2015.98 samples/sec#011loss=2.425968\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] Epoch[101] Batch[10] avg_epoch_loss=2.440139\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=2.457144021987915\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] Epoch[101] Batch [10]#011Speed: 1962.16 samples/sec#011loss=2.457144\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747861265.687724, \"EndTime\": 1747861266.6761663, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 988.1548881530762, \"count\": 1, \"min\": 988.1548881530762, \"max\": 988.1548881530762}}}\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1372.1313526629954 records/second\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.4401389252055776\n",
      "[05/21/2025 21:01:06 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] Epoch[102] Batch[0] avg_epoch_loss=2.410966\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.410966157913208\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] Epoch[102] Batch[5] avg_epoch_loss=2.439564\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.4395638704299927\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] Epoch[102] Batch [5]#011Speed: 2008.93 samples/sec#011loss=2.439564\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] Epoch[102] Batch[10] avg_epoch_loss=2.372685\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=2.2924309253692625\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] Epoch[102] Batch [10]#011Speed: 1935.16 samples/sec#011loss=2.292431\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747861266.676226, \"EndTime\": 1747861267.655754, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 979.2277812957764, \"count\": 1, \"min\": 979.2277812957764, \"max\": 979.2277812957764}}}\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1348.9029653257348 records/second\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.372685259038752\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:01:07 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_26db3bc0-290b-4edc-86b2-6e166973e362-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861267.6558113, \"EndTime\": 1747861267.6670032, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.882377624511719, \"count\": 1, \"min\": 10.882377624511719, \"max\": 10.882377624511719}}}\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] Epoch[103] Batch[0] avg_epoch_loss=2.532825\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.5328245162963867\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] Epoch[103] Batch[5] avg_epoch_loss=2.469017\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.4690165917078652\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] Epoch[103] Batch [5]#011Speed: 2142.43 samples/sec#011loss=2.469017\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747861267.6670635, \"EndTime\": 1747861268.5398023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 872.678279876709, \"count\": 1, \"min\": 872.678279876709, \"max\": 872.678279876709}}}\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1466.598351005039 records/second\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.4530391693115234\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] Epoch[104] Batch[0] avg_epoch_loss=2.396707\n",
      "[05/21/2025 21:01:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.39670729637146\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] Epoch[104] Batch[5] avg_epoch_loss=2.413874\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.4138737122217813\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] Epoch[104] Batch [5]#011Speed: 2057.68 samples/sec#011loss=2.413874\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] Epoch[104] Batch[10] avg_epoch_loss=2.377380\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=2.333586645126343\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] Epoch[104] Batch [10]#011Speed: 2041.63 samples/sec#011loss=2.333587\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747861268.5398638, \"EndTime\": 1747861269.4855683, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.3723430633545, \"count\": 1, \"min\": 945.3723430633545, \"max\": 945.3723430633545}}}\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1409.8995021101814 records/second\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.3773795908147637\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] Epoch[105] Batch[0] avg_epoch_loss=2.393630\n",
      "[05/21/2025 21:01:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.393629550933838\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] Epoch[105] Batch[5] avg_epoch_loss=2.458260\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.458260416984558\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] Epoch[105] Batch [5]#011Speed: 2097.27 samples/sec#011loss=2.458260\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] Epoch[105] Batch[10] avg_epoch_loss=2.478776\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.5033950328826906\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] Epoch[105] Batch [10]#011Speed: 2002.72 samples/sec#011loss=2.503395\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747861269.4856262, \"EndTime\": 1747861270.4328187, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.9428062438965, \"count\": 1, \"min\": 946.9428062438965, \"max\": 946.9428062438965}}}\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1408.6127806298678 records/second\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.478776151483709\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] Epoch[106] Batch[0] avg_epoch_loss=2.509018\n",
      "[05/21/2025 21:01:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.5090181827545166\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] Epoch[106] Batch[5] avg_epoch_loss=2.461181\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.461181124051412\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] Epoch[106] Batch [5]#011Speed: 2028.92 samples/sec#011loss=2.461181\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] processed a total of 1250 examples\n",
      "#metrics {\"StartTime\": 1747861270.4328773, \"EndTime\": 1747861271.3258634, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 892.7357196807861, \"count\": 1, \"min\": 892.7357196807861, \"max\": 892.7357196807861}}}\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1400.0442213674658 records/second\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.473985719680786\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] Epoch[107] Batch[0] avg_epoch_loss=2.513023\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.5130228996276855\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] Epoch[107] Batch[5] avg_epoch_loss=2.449314\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.4493136405944824\n",
      "[05/21/2025 21:01:11 INFO 140363140085568] Epoch[107] Batch [5]#011Speed: 2021.99 samples/sec#011loss=2.449314\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] Epoch[107] Batch[10] avg_epoch_loss=2.573692\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.7229465007781983\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] Epoch[107] Batch [10]#011Speed: 1985.30 samples/sec#011loss=2.722947\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747861271.325927, \"EndTime\": 1747861272.2892737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 962.9993438720703, \"count\": 1, \"min\": 962.9993438720703, \"max\": 962.9993438720703}}}\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1363.3252898828239 records/second\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.573692213405262\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] Epoch[108] Batch[0] avg_epoch_loss=2.659316\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.659316062927246\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] Epoch[108] Batch[5] avg_epoch_loss=2.509686\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.5096855560938516\n",
      "[05/21/2025 21:01:12 INFO 140363140085568] Epoch[108] Batch [5]#011Speed: 2074.88 samples/sec#011loss=2.509686\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] Epoch[108] Batch[10] avg_epoch_loss=2.465739\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.4130035877227782\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] Epoch[108] Batch [10]#011Speed: 2072.29 samples/sec#011loss=2.413004\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747861272.2893326, \"EndTime\": 1747861273.2299182, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.3367042541504, \"count\": 1, \"min\": 940.3367042541504, \"max\": 940.3367042541504}}}\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1390.8666292635326 records/second\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.465739206834273\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] Epoch[109] Batch[0] avg_epoch_loss=2.392555\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.392554998397827\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] Epoch[109] Batch[5] avg_epoch_loss=2.446209\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.446209271748861\n",
      "[05/21/2025 21:01:13 INFO 140363140085568] Epoch[109] Batch [5]#011Speed: 2164.57 samples/sec#011loss=2.446209\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] Epoch[109] Batch[10] avg_epoch_loss=2.419964\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.388468933105469\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] Epoch[109] Batch [10]#011Speed: 2052.25 samples/sec#011loss=2.388469\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747861273.2299745, \"EndTime\": 1747861274.158296, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.0567169189453, \"count\": 1, \"min\": 928.0567169189453, \"max\": 928.0567169189453}}}\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1426.5072149186237 records/second\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.419963663274592\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] Epoch[110] Batch[0] avg_epoch_loss=2.295902\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.2959022521972656\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] Epoch[110] Batch[5] avg_epoch_loss=2.351090\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.351089914639791\n",
      "[05/21/2025 21:01:14 INFO 140363140085568] Epoch[110] Batch [5]#011Speed: 2044.64 samples/sec#011loss=2.351090\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] Epoch[110] Batch[10] avg_epoch_loss=2.385697\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.427225637435913\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] Epoch[110] Batch [10]#011Speed: 2017.64 samples/sec#011loss=2.427226\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747861274.158353, \"EndTime\": 1747861275.115934, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.3345184326172, \"count\": 1, \"min\": 957.3345184326172, \"max\": 957.3345184326172}}}\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1390.1967435846866 records/second\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.385697061365301\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] Epoch[111] Batch[0] avg_epoch_loss=2.368448\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.368447780609131\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] Epoch[111] Batch[5] avg_epoch_loss=2.362811\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.3628105322519937\n",
      "[05/21/2025 21:01:15 INFO 140363140085568] Epoch[111] Batch [5]#011Speed: 2023.42 samples/sec#011loss=2.362811\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] Epoch[111] Batch[10] avg_epoch_loss=2.413203\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=2.4736730575561525\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] Epoch[111] Batch [10]#011Speed: 1985.14 samples/sec#011loss=2.473673\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747861275.1159916, \"EndTime\": 1747861276.0893667, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.1314182281494, \"count\": 1, \"min\": 973.1314182281494, \"max\": 973.1314182281494}}}\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1316.2535179730753 records/second\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.4132025892084297\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] Epoch[112] Batch[0] avg_epoch_loss=2.497416\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.4974164962768555\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] Epoch[112] Batch[5] avg_epoch_loss=2.433900\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.433900157610575\n",
      "[05/21/2025 21:01:16 INFO 140363140085568] Epoch[112] Batch [5]#011Speed: 2046.44 samples/sec#011loss=2.433900\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] Epoch[112] Batch[10] avg_epoch_loss=2.386716\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.330094242095947\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] Epoch[112] Batch [10]#011Speed: 1988.61 samples/sec#011loss=2.330094\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747861276.0894246, \"EndTime\": 1747861277.0515108, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.8384838104248, \"count\": 1, \"min\": 961.8384838104248, \"max\": 961.8384838104248}}}\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1355.613992830532 records/second\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.3867156505584717\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] Epoch[113] Batch[0] avg_epoch_loss=2.226144\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.2261435985565186\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] Epoch[113] Batch[5] avg_epoch_loss=2.354019\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.354018807411194\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] Epoch[113] Batch [5]#011Speed: 2153.03 samples/sec#011loss=2.354019\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] Epoch[113] Batch[10] avg_epoch_loss=2.589516\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.8721132278442383\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] Epoch[113] Batch [10]#011Speed: 2021.84 samples/sec#011loss=2.872113\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747861277.0515697, \"EndTime\": 1747861277.9870791, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.2641105651855, \"count\": 1, \"min\": 935.2641105651855, \"max\": 935.2641105651855}}}\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1415.4992878226337 records/second\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.589516271244396\n",
      "[05/21/2025 21:01:17 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] Epoch[114] Batch[0] avg_epoch_loss=2.615130\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.6151297092437744\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] Epoch[114] Batch[5] avg_epoch_loss=2.655344\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.6553442080815635\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] Epoch[114] Batch [5]#011Speed: 2132.55 samples/sec#011loss=2.655344\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] Epoch[114] Batch[10] avg_epoch_loss=2.685154\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=2.720925283432007\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] Epoch[114] Batch [10]#011Speed: 2128.94 samples/sec#011loss=2.720925\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747861277.9871454, \"EndTime\": 1747861278.909244, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.8423366546631, \"count\": 1, \"min\": 921.8423366546631, \"max\": 921.8423366546631}}}\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1430.6930784631863 records/second\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.6851537877863105\n",
      "[05/21/2025 21:01:18 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] Epoch[115] Batch[0] avg_epoch_loss=2.531081\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.531080961227417\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] Epoch[115] Batch[5] avg_epoch_loss=2.509920\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.5099196831385293\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] Epoch[115] Batch [5]#011Speed: 2170.46 samples/sec#011loss=2.509920\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] Epoch[115] Batch[10] avg_epoch_loss=2.492247\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=2.471040630340576\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] Epoch[115] Batch [10]#011Speed: 1995.36 samples/sec#011loss=2.471041\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747861278.9093037, \"EndTime\": 1747861279.847507, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.9560947418213, \"count\": 1, \"min\": 937.9560947418213, \"max\": 937.9560947418213}}}\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1431.7086415422839 records/second\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.492247386412187\n",
      "[05/21/2025 21:01:19 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] Epoch[116] Batch[0] avg_epoch_loss=2.303685\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.303685426712036\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] Epoch[116] Batch[5] avg_epoch_loss=2.464947\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.4649465084075928\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] Epoch[116] Batch [5]#011Speed: 2076.76 samples/sec#011loss=2.464947\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] Epoch[116] Batch[10] avg_epoch_loss=2.478587\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=2.4949549198150636\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] Epoch[116] Batch [10]#011Speed: 1797.55 samples/sec#011loss=2.494955\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747861279.8475635, \"EndTime\": 1747861280.833957, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 986.107349395752, \"count\": 1, \"min\": 986.107349395752, \"max\": 986.107349395752}}}\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1354.719221883652 records/second\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.4785866954109887\n",
      "[05/21/2025 21:01:20 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:21 INFO 140363140085568] Epoch[117] Batch[0] avg_epoch_loss=2.327785\n",
      "[05/21/2025 21:01:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.327785015106201\n",
      "[05/21/2025 21:01:21 INFO 140363140085568] Epoch[117] Batch[5] avg_epoch_loss=2.386188\n",
      "[05/21/2025 21:01:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.386187791824341\n",
      "[05/21/2025 21:01:21 INFO 140363140085568] Epoch[117] Batch [5]#011Speed: 1866.10 samples/sec#011loss=2.386188\n",
      "[05/21/2025 21:01:21 INFO 140363140085568] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747861280.8340044, \"EndTime\": 1747861281.768287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.079647064209, \"count\": 1, \"min\": 934.079647064209, \"max\": 934.079647064209}}}\n",
      "[05/21/2025 21:01:21 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1349.8262239060612 records/second\n",
      "[05/21/2025 21:01:21 INFO 140363140085568] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[05/21/2025 21:01:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.410868263244629\n",
      "[05/21/2025 21:01:21 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] Epoch[118] Batch[0] avg_epoch_loss=2.403275\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.40327525138855\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] Epoch[118] Batch[5] avg_epoch_loss=2.447459\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.447458505630493\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] Epoch[118] Batch [5]#011Speed: 1920.39 samples/sec#011loss=2.447459\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] Epoch[118] Batch[10] avg_epoch_loss=2.374546\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.28705039024353\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] Epoch[118] Batch [10]#011Speed: 1939.00 samples/sec#011loss=2.287050\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747861281.7683723, \"EndTime\": 1747861282.7605004, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 991.8258190155029, \"count\": 1, \"min\": 991.8258190155029, \"max\": 991.8258190155029}}}\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1320.672299124365 records/second\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.3745457259091465\n",
      "[05/21/2025 21:01:22 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:23 INFO 140363140085568] Epoch[119] Batch[0] avg_epoch_loss=2.398623\n",
      "[05/21/2025 21:01:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.398622512817383\n",
      "[05/21/2025 21:01:23 INFO 140363140085568] Epoch[119] Batch[5] avg_epoch_loss=2.374688\n",
      "[05/21/2025 21:01:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.3746877908706665\n",
      "[05/21/2025 21:01:23 INFO 140363140085568] Epoch[119] Batch [5]#011Speed: 2079.76 samples/sec#011loss=2.374688\n",
      "[05/21/2025 21:01:23 INFO 140363140085568] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747861282.7605646, \"EndTime\": 1747861283.6523771, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 891.4437294006348, \"count\": 1, \"min\": 891.4437294006348, \"max\": 891.4437294006348}}}\n",
      "[05/21/2025 21:01:23 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1431.2416055889732 records/second\n",
      "[05/21/2025 21:01:23 INFO 140363140085568] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[05/21/2025 21:01:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.396373820304871\n",
      "[05/21/2025 21:01:23 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] Epoch[120] Batch[0] avg_epoch_loss=2.226658\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.226658344268799\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] Epoch[120] Batch[5] avg_epoch_loss=2.356561\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.3565613428751626\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] Epoch[120] Batch [5]#011Speed: 1880.89 samples/sec#011loss=2.356561\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] Epoch[120] Batch[10] avg_epoch_loss=2.336831\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=2.3131555557250976\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] Epoch[120] Batch [10]#011Speed: 2051.54 samples/sec#011loss=2.313156\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747861283.6524355, \"EndTime\": 1747861284.6539354, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1001.0933876037598, \"count\": 1, \"min\": 1001.0933876037598, \"max\": 1001.0933876037598}}}\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1315.4456661411773 records/second\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.3368314396251333\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_38675ec4-843f-49e2-b027-c9c20b3d8819-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861284.6539931, \"EndTime\": 1747861284.6651497, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.886430740356445, \"count\": 1, \"min\": 10.886430740356445, \"max\": 10.886430740356445}}}\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] Epoch[121] Batch[0] avg_epoch_loss=2.380599\n",
      "[05/21/2025 21:01:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.380598545074463\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] Epoch[121] Batch[5] avg_epoch_loss=2.354738\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.3547380367914834\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] Epoch[121] Batch [5]#011Speed: 2080.07 samples/sec#011loss=2.354738\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] processed a total of 1251 examples\n",
      "#metrics {\"StartTime\": 1747861284.665205, \"EndTime\": 1747861285.555241, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 889.9846076965332, \"count\": 1, \"min\": 889.9846076965332, \"max\": 889.9846076965332}}}\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1405.493562866352 records/second\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.3355136632919313\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_9f888351-303d-4c1a-aabf-e7a611c2fb79-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861285.5553057, \"EndTime\": 1747861285.5666196, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.00611686706543, \"count\": 1, \"min\": 11.00611686706543, \"max\": 11.00611686706543}}}\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] Epoch[122] Batch[0] avg_epoch_loss=2.336786\n",
      "[05/21/2025 21:01:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.3367855548858643\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] Epoch[122] Batch[5] avg_epoch_loss=2.368556\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.3685563007990518\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] Epoch[122] Batch [5]#011Speed: 2159.92 samples/sec#011loss=2.368556\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] Epoch[122] Batch[10] avg_epoch_loss=2.341755\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=2.309592342376709\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] Epoch[122] Batch [10]#011Speed: 1929.99 samples/sec#011loss=2.309592\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747861285.5666728, \"EndTime\": 1747861286.5233638, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.6388130187988, \"count\": 1, \"min\": 956.6388130187988, \"max\": 956.6388130187988}}}\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1354.6149868894995 records/second\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.341754501516169\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] Epoch[123] Batch[0] avg_epoch_loss=2.425800\n",
      "[05/21/2025 21:01:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.425800323486328\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] Epoch[123] Batch[5] avg_epoch_loss=2.415984\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.4159844319025674\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] Epoch[123] Batch [5]#011Speed: 1942.59 samples/sec#011loss=2.415984\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] Epoch[123] Batch[10] avg_epoch_loss=2.401436\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=2.383977842330933\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] Epoch[123] Batch [10]#011Speed: 1966.84 samples/sec#011loss=2.383978\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747861286.5234227, \"EndTime\": 1747861287.5003376, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 976.5903949737549, \"count\": 1, \"min\": 976.5903949737549, \"max\": 976.5903949737549}}}\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1368.8908209022627 records/second\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] #progress_metric: host=algo-1, completed 31.0 % of epochs\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.401435982097279\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] Epoch[124] Batch[0] avg_epoch_loss=2.239438\n",
      "[05/21/2025 21:01:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.23943829536438\n",
      "[05/21/2025 21:01:28 INFO 140363140085568] Epoch[124] Batch[5] avg_epoch_loss=2.367691\n",
      "[05/21/2025 21:01:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.3676911989847818\n",
      "[05/21/2025 21:01:28 INFO 140363140085568] Epoch[124] Batch [5]#011Speed: 2029.66 samples/sec#011loss=2.367691\n",
      "[05/21/2025 21:01:28 INFO 140363140085568] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747861287.5004182, \"EndTime\": 1747861288.3905096, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 889.6961212158203, \"count\": 1, \"min\": 889.6961212158203, \"max\": 889.6961212158203}}}\n",
      "[05/21/2025 21:01:28 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1422.799148569481 records/second\n",
      "[05/21/2025 21:01:28 INFO 140363140085568] #progress_metric: host=algo-1, completed 31.25 % of epochs\n",
      "[05/21/2025 21:01:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.3502619743347166\n",
      "[05/21/2025 21:01:28 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:28 INFO 140363140085568] Epoch[125] Batch[0] avg_epoch_loss=2.382386\n",
      "[05/21/2025 21:01:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.3823864459991455\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] Epoch[125] Batch[5] avg_epoch_loss=2.356275\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.3562753995259604\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] Epoch[125] Batch [5]#011Speed: 2124.10 samples/sec#011loss=2.356275\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747861288.3905754, \"EndTime\": 1747861289.2617931, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 870.8629608154297, \"count\": 1, \"min\": 870.8629608154297, \"max\": 870.8629608154297}}}\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1467.3528079922148 records/second\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] #progress_metric: host=algo-1, completed 31.5 % of epochs\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.3584905862808228\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] Epoch[126] Batch[0] avg_epoch_loss=2.338922\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.338921546936035\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] Epoch[126] Batch[5] avg_epoch_loss=2.262414\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.2624139388402305\n",
      "[05/21/2025 21:01:29 INFO 140363140085568] Epoch[126] Batch [5]#011Speed: 2131.13 samples/sec#011loss=2.262414\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] Epoch[126] Batch[10] avg_epoch_loss=2.317093\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=2.3827081680297852\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] Epoch[126] Batch [10]#011Speed: 2030.55 samples/sec#011loss=2.382708\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747861289.2618568, \"EndTime\": 1747861290.2015774, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.3930435180664, \"count\": 1, \"min\": 939.3930435180664, \"max\": 939.3930435180664}}}\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1399.5288882753916 records/second\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] #progress_metric: host=algo-1, completed 31.75 % of epochs\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.3170931339263916\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_b2d475b2-3202-4b4c-b96e-f86e4a955155-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861290.2017581, \"EndTime\": 1747861290.2129812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.470390319824219, \"count\": 1, \"min\": 10.470390319824219, \"max\": 10.470390319824219}}}\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] Epoch[127] Batch[0] avg_epoch_loss=2.488773\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.4887731075286865\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] Epoch[127] Batch[5] avg_epoch_loss=2.418822\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.4188215732574463\n",
      "[05/21/2025 21:01:30 INFO 140363140085568] Epoch[127] Batch [5]#011Speed: 2169.80 samples/sec#011loss=2.418822\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] Epoch[127] Batch[10] avg_epoch_loss=2.440875\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=2.467339277267456\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] Epoch[127] Batch [10]#011Speed: 1837.71 samples/sec#011loss=2.467339\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747861290.2130294, \"EndTime\": 1747861291.1880682, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 974.9939441680908, \"count\": 1, \"min\": 974.9939441680908, \"max\": 974.9939441680908}}}\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1353.7360527304777 records/second\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] #progress_metric: host=algo-1, completed 32.0 % of epochs\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.440875075080178\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] Epoch[128] Batch[0] avg_epoch_loss=2.423581\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.4235806465148926\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] Epoch[128] Batch[5] avg_epoch_loss=2.377923\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.377922693888346\n",
      "[05/21/2025 21:01:31 INFO 140363140085568] Epoch[128] Batch [5]#011Speed: 2132.00 samples/sec#011loss=2.377923\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] Epoch[128] Batch[10] avg_epoch_loss=2.320382\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=2.2513328552246095\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] Epoch[128] Batch [10]#011Speed: 1826.14 samples/sec#011loss=2.251333\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747861291.188127, \"EndTime\": 1747861292.1683223, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 979.8941612243652, \"count\": 1, \"min\": 979.8941612243652, \"max\": 979.8941612243652}}}\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1369.3793997386656 records/second\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] #progress_metric: host=algo-1, completed 32.25 % of epochs\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.320381858132102\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] Epoch[129] Batch[0] avg_epoch_loss=2.423640\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.423640012741089\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] Epoch[129] Batch[5] avg_epoch_loss=2.328658\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.3286582628885903\n",
      "[05/21/2025 21:01:32 INFO 140363140085568] Epoch[129] Batch [5]#011Speed: 2120.47 samples/sec#011loss=2.328658\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] Epoch[129] Batch[10] avg_epoch_loss=2.367294\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=2.413656234741211\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] Epoch[129] Batch [10]#011Speed: 1785.68 samples/sec#011loss=2.413656\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747861292.1684046, \"EndTime\": 1747861293.1575413, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 988.7983798980713, \"count\": 1, \"min\": 988.7983798980713, \"max\": 988.7983798980713}}}\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1320.6769027208384 records/second\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] #progress_metric: host=algo-1, completed 32.5 % of epochs\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.3672937046397817\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] Epoch[130] Batch[0] avg_epoch_loss=2.374467\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.374467372894287\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] Epoch[130] Batch[5] avg_epoch_loss=2.376100\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.376100460688273\n",
      "[05/21/2025 21:01:33 INFO 140363140085568] Epoch[130] Batch [5]#011Speed: 1985.45 samples/sec#011loss=2.376100\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747861293.1576002, \"EndTime\": 1747861294.069121, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.2660884857178, \"count\": 1, \"min\": 911.2660884857178, \"max\": 911.2660884857178}}}\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1383.6395025297315 records/second\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] #progress_metric: host=algo-1, completed 32.75 % of epochs\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.363539958000183\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] Epoch[131] Batch[0] avg_epoch_loss=2.294266\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.2942662239074707\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] Epoch[131] Batch[5] avg_epoch_loss=2.314802\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.314802328745524\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] Epoch[131] Batch [5]#011Speed: 2115.70 samples/sec#011loss=2.314802\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] Epoch[131] Batch[10] avg_epoch_loss=2.281129\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=2.2407211542129515\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] Epoch[131] Batch [10]#011Speed: 2111.67 samples/sec#011loss=2.240721\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747861294.0691905, \"EndTime\": 1747861294.996924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.3269176483154, \"count\": 1, \"min\": 927.3269176483154, \"max\": 927.3269176483154}}}\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1433.014483029351 records/second\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] #progress_metric: host=algo-1, completed 33.0 % of epochs\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.281129067594355\n",
      "[05/21/2025 21:01:34 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_984f383e-4a5d-4552-b84a-5d15089c910c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861294.996983, \"EndTime\": 1747861295.007577, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.32257080078125, \"count\": 1, \"min\": 10.32257080078125, \"max\": 10.32257080078125}}}\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] Epoch[132] Batch[0] avg_epoch_loss=2.233936\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.233936071395874\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] Epoch[132] Batch[5] avg_epoch_loss=2.246903\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.2469030221303306\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] Epoch[132] Batch [5]#011Speed: 2132.11 samples/sec#011loss=2.246903\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747861295.0076306, \"EndTime\": 1747861295.8954582, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 887.7770900726318, \"count\": 1, \"min\": 887.7770900726318, \"max\": 887.7770900726318}}}\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1441.6485038830485 records/second\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] #progress_metric: host=algo-1, completed 33.25 % of epochs\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.268145132064819\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:01:35 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_326d26c5-b25e-4604-8310-732b19e0ac23-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861295.895525, \"EndTime\": 1747861295.9065683, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.675191879272461, \"count\": 1, \"min\": 10.675191879272461, \"max\": 10.675191879272461}}}\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] Epoch[133] Batch[0] avg_epoch_loss=2.315916\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.3159162998199463\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] Epoch[133] Batch[5] avg_epoch_loss=2.329171\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.32917050520579\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] Epoch[133] Batch [5]#011Speed: 2124.49 samples/sec#011loss=2.329171\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] Epoch[133] Batch[10] avg_epoch_loss=2.326144\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=2.3225111961364746\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] Epoch[133] Batch [10]#011Speed: 1967.43 samples/sec#011loss=2.322511\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747861295.906617, \"EndTime\": 1747861296.8504136, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.7479972839355, \"count\": 1, \"min\": 943.7479972839355, \"max\": 943.7479972839355}}}\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1450.4631593359195 records/second\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] #progress_metric: host=algo-1, completed 33.5 % of epochs\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.3261435465379194\n",
      "[05/21/2025 21:01:36 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] Epoch[134] Batch[0] avg_epoch_loss=2.319040\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.319040060043335\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] Epoch[134] Batch[5] avg_epoch_loss=2.287161\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.287161389986674\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] Epoch[134] Batch [5]#011Speed: 2129.65 samples/sec#011loss=2.287161\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] Epoch[134] Batch[10] avg_epoch_loss=2.305270\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.3269994258880615\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] Epoch[134] Batch [10]#011Speed: 1931.61 samples/sec#011loss=2.326999\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747861296.8504739, \"EndTime\": 1747861297.8031669, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.4414539337158, \"count\": 1, \"min\": 952.4414539337158, \"max\": 952.4414539337158}}}\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1420.435663191978 records/second\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] #progress_metric: host=algo-1, completed 33.75 % of epochs\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.3052695881236684\n",
      "[05/21/2025 21:01:37 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:38 INFO 140363140085568] Epoch[135] Batch[0] avg_epoch_loss=2.274618\n",
      "[05/21/2025 21:01:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.274617910385132\n",
      "[05/21/2025 21:01:38 INFO 140363140085568] Epoch[135] Batch[5] avg_epoch_loss=2.310853\n",
      "[05/21/2025 21:01:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.3108527263005576\n",
      "[05/21/2025 21:01:38 INFO 140363140085568] Epoch[135] Batch [5]#011Speed: 1990.51 samples/sec#011loss=2.310853\n",
      "[05/21/2025 21:01:38 INFO 140363140085568] processed a total of 1256 examples\n",
      "#metrics {\"StartTime\": 1747861297.8032217, \"EndTime\": 1747861298.6911762, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 887.7074718475342, \"count\": 1, \"min\": 887.7074718475342, \"max\": 887.7074718475342}}}\n",
      "[05/21/2025 21:01:38 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1414.7273837599946 records/second\n",
      "[05/21/2025 21:01:38 INFO 140363140085568] #progress_metric: host=algo-1, completed 34.0 % of epochs\n",
      "[05/21/2025 21:01:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.2849687576293944\n",
      "[05/21/2025 21:01:38 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] Epoch[136] Batch[0] avg_epoch_loss=2.330069\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.330068826675415\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] Epoch[136] Batch[5] avg_epoch_loss=2.356736\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.3567360639572144\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] Epoch[136] Batch [5]#011Speed: 2104.07 samples/sec#011loss=2.356736\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747861298.6912422, \"EndTime\": 1747861299.559493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 867.4435615539551, \"count\": 1, \"min\": 867.4435615539551, \"max\": 867.4435615539551}}}\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1468.5211892960278 records/second\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] #progress_metric: host=algo-1, completed 34.25 % of epochs\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.354176902770996\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] Epoch[137] Batch[0] avg_epoch_loss=2.259827\n",
      "[05/21/2025 21:01:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.259826898574829\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] Epoch[137] Batch[5] avg_epoch_loss=2.291416\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.2914164463678994\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] Epoch[137] Batch [5]#011Speed: 2093.55 samples/sec#011loss=2.291416\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] Epoch[137] Batch[10] avg_epoch_loss=2.334670\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=2.3865737438201906\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] Epoch[137] Batch [10]#011Speed: 2000.61 samples/sec#011loss=2.386574\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747861299.5595567, \"EndTime\": 1747861300.505644, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.793628692627, \"count\": 1, \"min\": 945.793628692627, \"max\": 945.793628692627}}}\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1387.0671716938753 records/second\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] #progress_metric: host=algo-1, completed 34.5 % of epochs\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.334669763391668\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] Epoch[138] Batch[0] avg_epoch_loss=2.275499\n",
      "[05/21/2025 21:01:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.275498628616333\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] Epoch[138] Batch[5] avg_epoch_loss=2.277153\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.277152935663859\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] Epoch[138] Batch [5]#011Speed: 2161.59 samples/sec#011loss=2.277153\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] Epoch[138] Batch[10] avg_epoch_loss=2.398317\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.543712854385376\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] Epoch[138] Batch [10]#011Speed: 2105.19 samples/sec#011loss=2.543713\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747861300.505704, \"EndTime\": 1747861301.4373589, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.4091205596924, \"count\": 1, \"min\": 931.4091205596924, \"max\": 931.4091205596924}}}\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1412.781666434603 records/second\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] #progress_metric: host=algo-1, completed 34.75 % of epochs\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.3983165350827305\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] Epoch[139] Batch[0] avg_epoch_loss=2.189444\n",
      "[05/21/2025 21:01:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.189443588256836\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] Epoch[139] Batch[5] avg_epoch_loss=2.260182\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.2601816654205322\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] Epoch[139] Batch [5]#011Speed: 2092.34 samples/sec#011loss=2.260182\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] processed a total of 1259 examples\n",
      "#metrics {\"StartTime\": 1747861301.437418, \"EndTime\": 1747861302.3114214, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 873.753547668457, \"count\": 1, \"min\": 873.753547668457, \"max\": 873.753547668457}}}\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1440.754848190349 records/second\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] #progress_metric: host=algo-1, completed 35.0 % of epochs\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.2561275482177736\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_855bda8b-0559-41a4-8ca4-9ed72fba3179-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861302.311486, \"EndTime\": 1747861302.3226895, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.85519790649414, \"count\": 1, \"min\": 10.85519790649414, \"max\": 10.85519790649414}}}\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] Epoch[140] Batch[0] avg_epoch_loss=2.232518\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.232518434524536\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] Epoch[140] Batch[5] avg_epoch_loss=2.263155\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.263154983520508\n",
      "[05/21/2025 21:01:42 INFO 140363140085568] Epoch[140] Batch [5]#011Speed: 2155.30 samples/sec#011loss=2.263155\n",
      "[05/21/2025 21:01:43 INFO 140363140085568] processed a total of 1255 examples\n",
      "#metrics {\"StartTime\": 1747861302.322742, \"EndTime\": 1747861303.177416, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 854.6221256256104, \"count\": 1, \"min\": 854.6221256256104, \"max\": 854.6221256256104}}}\n",
      "[05/21/2025 21:01:43 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1468.324693014131 records/second\n",
      "[05/21/2025 21:01:43 INFO 140363140085568] #progress_metric: host=algo-1, completed 35.25 % of epochs\n",
      "[05/21/2025 21:01:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.280800700187683\n",
      "[05/21/2025 21:01:43 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:43 INFO 140363140085568] Epoch[141] Batch[0] avg_epoch_loss=2.275492\n",
      "[05/21/2025 21:01:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.275491714477539\n",
      "[05/21/2025 21:01:43 INFO 140363140085568] Epoch[141] Batch[5] avg_epoch_loss=2.272147\n",
      "[05/21/2025 21:01:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.2721468210220337\n",
      "[05/21/2025 21:01:43 INFO 140363140085568] Epoch[141] Batch [5]#011Speed: 2164.26 samples/sec#011loss=2.272147\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] Epoch[141] Batch[10] avg_epoch_loss=2.309314\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=2.3539137840270996\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] Epoch[141] Batch [10]#011Speed: 2029.77 samples/sec#011loss=2.353914\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747861303.1774786, \"EndTime\": 1747861304.1068923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.0804862976074, \"count\": 1, \"min\": 929.0804862976074, \"max\": 929.0804862976074}}}\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1424.9292497697716 records/second\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] #progress_metric: host=algo-1, completed 35.5 % of epochs\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.3093136223879727\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] Epoch[142] Batch[0] avg_epoch_loss=2.286973\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.286973476409912\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] Epoch[142] Batch[5] avg_epoch_loss=2.311912\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.3119119008382163\n",
      "[05/21/2025 21:01:44 INFO 140363140085568] Epoch[142] Batch [5]#011Speed: 2092.10 samples/sec#011loss=2.311912\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] Epoch[142] Batch[10] avg_epoch_loss=2.344146\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=2.382827949523926\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] Epoch[142] Batch [10]#011Speed: 2075.04 samples/sec#011loss=2.382828\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747861304.1069531, \"EndTime\": 1747861305.046249, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.035177230835, \"count\": 1, \"min\": 939.035177230835, \"max\": 939.035177230835}}}\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1403.4378756856179 records/second\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] #progress_metric: host=algo-1, completed 35.75 % of epochs\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.3441464684226294\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] Epoch[143] Batch[0] avg_epoch_loss=2.687063\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.6870627403259277\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] Epoch[143] Batch[5] avg_epoch_loss=2.612802\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.6128016312917075\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] Epoch[143] Batch [5]#011Speed: 2183.52 samples/sec#011loss=2.612802\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] Epoch[143] Batch[10] avg_epoch_loss=2.616105\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=2.6200699329376222\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] Epoch[143] Batch [10]#011Speed: 1897.16 samples/sec#011loss=2.620070\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] processed a total of 1381 examples\n",
      "#metrics {\"StartTime\": 1747861305.0463073, \"EndTime\": 1747861305.9931931, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.6371536254883, \"count\": 1, \"min\": 946.6371536254883, \"max\": 946.6371536254883}}}\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1458.7200781297022 records/second\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] #progress_metric: host=algo-1, completed 36.0 % of epochs\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.616105404767123\n",
      "[05/21/2025 21:01:45 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] Epoch[144] Batch[0] avg_epoch_loss=2.616410\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.6164095401763916\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] Epoch[144] Batch[5] avg_epoch_loss=2.521708\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.5217084089914956\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] Epoch[144] Batch [5]#011Speed: 2067.45 samples/sec#011loss=2.521708\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] Epoch[144] Batch[10] avg_epoch_loss=2.538081\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=2.5577275276184084\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] Epoch[144] Batch [10]#011Speed: 1970.07 samples/sec#011loss=2.557728\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747861305.9932506, \"EndTime\": 1747861306.9500237, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.5200805664062, \"count\": 1, \"min\": 956.5200805664062, \"max\": 956.5200805664062}}}\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1406.0094833269156 records/second\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] #progress_metric: host=algo-1, completed 36.25 % of epochs\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.5380807356400923\n",
      "[05/21/2025 21:01:46 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:47 INFO 140363140085568] Epoch[145] Batch[0] avg_epoch_loss=2.413445\n",
      "[05/21/2025 21:01:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.4134445190429688\n",
      "[05/21/2025 21:01:47 INFO 140363140085568] Epoch[145] Batch[5] avg_epoch_loss=2.527033\n",
      "[05/21/2025 21:01:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.5270328919092813\n",
      "[05/21/2025 21:01:47 INFO 140363140085568] Epoch[145] Batch [5]#011Speed: 2169.01 samples/sec#011loss=2.527033\n",
      "[05/21/2025 21:01:47 INFO 140363140085568] processed a total of 1247 examples\n",
      "#metrics {\"StartTime\": 1747861306.9500833, \"EndTime\": 1747861307.8167524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 866.4140701293945, \"count\": 1, \"min\": 866.4140701293945, \"max\": 866.4140701293945}}}\n",
      "[05/21/2025 21:01:47 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1439.1028784549922 records/second\n",
      "[05/21/2025 21:01:47 INFO 140363140085568] #progress_metric: host=algo-1, completed 36.5 % of epochs\n",
      "[05/21/2025 21:01:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.4852510929107665\n",
      "[05/21/2025 21:01:47 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] Epoch[146] Batch[0] avg_epoch_loss=2.448808\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.448807954788208\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] Epoch[146] Batch[5] avg_epoch_loss=2.386190\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.386189858118693\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] Epoch[146] Batch [5]#011Speed: 2081.20 samples/sec#011loss=2.386190\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] Epoch[146] Batch[10] avg_epoch_loss=2.468540\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=2.567359733581543\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] Epoch[146] Batch [10]#011Speed: 2073.52 samples/sec#011loss=2.567360\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747861307.8168197, \"EndTime\": 1747861308.755905, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.7969970703125, \"count\": 1, \"min\": 938.7969970703125, \"max\": 938.7969970703125}}}\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1430.422709005318 records/second\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] #progress_metric: host=algo-1, completed 36.75 % of epochs\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.4685398015108975\n",
      "[05/21/2025 21:01:48 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] Epoch[147] Batch[0] avg_epoch_loss=2.503156\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=2.5031564235687256\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] Epoch[147] Batch[5] avg_epoch_loss=2.419339\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=2.4193392594655356\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] Epoch[147] Batch [5]#011Speed: 2116.76 samples/sec#011loss=2.419339\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] Epoch[147] Batch[10] avg_epoch_loss=2.312499\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=2.1842900276184083\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] Epoch[147] Batch [10]#011Speed: 2095.11 samples/sec#011loss=2.184290\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747861308.7559636, \"EndTime\": 1747861309.6875722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.3337802886963, \"count\": 1, \"min\": 931.3337802886963, \"max\": 931.3337802886963}}}\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1398.9401964237445 records/second\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] #progress_metric: host=algo-1, completed 37.0 % of epochs\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.312498699535023\n",
      "[05/21/2025 21:01:49 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] Epoch[148] Batch[0] avg_epoch_loss=2.463465\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.4634649753570557\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] Epoch[148] Batch[5] avg_epoch_loss=2.376045\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.3760454654693604\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] Epoch[148] Batch [5]#011Speed: 2144.87 samples/sec#011loss=2.376045\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] Epoch[148] Batch[10] avg_epoch_loss=2.367749\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=2.357792520523071\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] Epoch[148] Batch [10]#011Speed: 2032.60 samples/sec#011loss=2.357793\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747861309.687629, \"EndTime\": 1747861310.620067, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.1873188018799, \"count\": 1, \"min\": 932.1873188018799, \"max\": 932.1873188018799}}}\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1465.2358064229866 records/second\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] #progress_metric: host=algo-1, completed 37.25 % of epochs\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.367748672311956\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] Epoch[149] Batch[0] avg_epoch_loss=2.177753\n",
      "[05/21/2025 21:01:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.17775297164917\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] Epoch[149] Batch[5] avg_epoch_loss=2.289831\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.2898305654525757\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] Epoch[149] Batch [5]#011Speed: 1623.76 samples/sec#011loss=2.289831\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] Epoch[149] Batch[10] avg_epoch_loss=2.328593\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=2.3751076221466065\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] Epoch[149] Batch [10]#011Speed: 1748.10 samples/sec#011loss=2.375108\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747861310.6201262, \"EndTime\": 1747861311.7066314, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1086.2171649932861, \"count\": 1, \"min\": 1086.2171649932861, \"max\": 1086.2171649932861}}}\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1216.048474473229 records/second\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] #progress_metric: host=algo-1, completed 37.5 % of epochs\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.3285928639498623\n",
      "[05/21/2025 21:01:51 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] Epoch[150] Batch[0] avg_epoch_loss=2.316216\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.3162155151367188\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] Epoch[150] Batch[5] avg_epoch_loss=2.325154\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.325153867403666\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] Epoch[150] Batch [5]#011Speed: 2069.54 samples/sec#011loss=2.325154\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] Epoch[150] Batch[10] avg_epoch_loss=2.333075\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=2.3425795078277587\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] Epoch[150] Batch [10]#011Speed: 1831.07 samples/sec#011loss=2.342580\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747861311.7066915, \"EndTime\": 1747861312.6852236, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 978.2760143280029, \"count\": 1, \"min\": 978.2760143280029, \"max\": 978.2760143280029}}}\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1398.253969244206 records/second\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] #progress_metric: host=algo-1, completed 37.75 % of epochs\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.333074613050981\n",
      "[05/21/2025 21:01:52 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] Epoch[151] Batch[0] avg_epoch_loss=2.300518\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.3005175590515137\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] Epoch[151] Batch[5] avg_epoch_loss=2.287527\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.2875268856684365\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] Epoch[151] Batch [5]#011Speed: 2107.94 samples/sec#011loss=2.287527\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] Epoch[151] Batch[10] avg_epoch_loss=2.201586\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=2.0984579801559446\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] Epoch[151] Batch [10]#011Speed: 2033.69 samples/sec#011loss=2.098458\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747861312.6852837, \"EndTime\": 1747861313.6246736, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.1016960144043, \"count\": 1, \"min\": 939.1016960144043, \"max\": 939.1016960144043}}}\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1418.2474748282473 records/second\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] #progress_metric: host=algo-1, completed 38.0 % of epochs\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.2015864740718496\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_b1434c3a-d655-4556-a178-c97c059eb9f5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861313.6247323, \"EndTime\": 1747861313.6355762, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.577201843261719, \"count\": 1, \"min\": 10.577201843261719, \"max\": 10.577201843261719}}}\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] Epoch[152] Batch[0] avg_epoch_loss=2.168244\n",
      "[05/21/2025 21:01:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.168243646621704\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] Epoch[152] Batch[5] avg_epoch_loss=2.221676\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.221675713857015\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] Epoch[152] Batch [5]#011Speed: 2114.49 samples/sec#011loss=2.221676\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] Epoch[152] Batch[10] avg_epoch_loss=2.259651\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=2.305222177505493\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] Epoch[152] Batch [10]#011Speed: 1967.81 samples/sec#011loss=2.305222\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747861313.6356277, \"EndTime\": 1747861314.578555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.8794384002686, \"count\": 1, \"min\": 942.8794384002686, \"max\": 942.8794384002686}}}\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1449.6815031788192 records/second\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] #progress_metric: host=algo-1, completed 38.25 % of epochs\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.259651379151778\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] Epoch[153] Batch[0] avg_epoch_loss=2.364610\n",
      "[05/21/2025 21:01:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.364609956741333\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] Epoch[153] Batch[5] avg_epoch_loss=2.302544\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.3025436401367188\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] Epoch[153] Batch [5]#011Speed: 2192.88 samples/sec#011loss=2.302544\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] Epoch[153] Batch[10] avg_epoch_loss=2.352879\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=2.4132816791534424\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] Epoch[153] Batch [10]#011Speed: 1849.39 samples/sec#011loss=2.413282\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747861314.578614, \"EndTime\": 1747861315.539004, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.1397514343262, \"count\": 1, \"min\": 960.1397514343262, \"max\": 960.1397514343262}}}\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1338.200294520825 records/second\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] #progress_metric: host=algo-1, completed 38.5 % of epochs\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.352879112417048\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] Epoch[154] Batch[0] avg_epoch_loss=2.268655\n",
      "[05/21/2025 21:01:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.2686548233032227\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] Epoch[154] Batch[5] avg_epoch_loss=2.294323\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.2943225701649985\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] Epoch[154] Batch [5]#011Speed: 2102.98 samples/sec#011loss=2.294323\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] Epoch[154] Batch[10] avg_epoch_loss=2.368915\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=2.4584253311157225\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] Epoch[154] Batch [10]#011Speed: 1970.53 samples/sec#011loss=2.458425\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747861315.5390768, \"EndTime\": 1747861316.4905822, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.0984420776367, \"count\": 1, \"min\": 951.0984420776367, \"max\": 951.0984420776367}}}\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1379.3283105698108 records/second\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] #progress_metric: host=algo-1, completed 38.75 % of epochs\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.3689147342335093\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] Epoch[155] Batch[0] avg_epoch_loss=2.427216\n",
      "[05/21/2025 21:01:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.427215814590454\n",
      "[05/21/2025 21:01:57 INFO 140363140085568] Epoch[155] Batch[5] avg_epoch_loss=2.334149\n",
      "[05/21/2025 21:01:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.334149201711019\n",
      "[05/21/2025 21:01:57 INFO 140363140085568] Epoch[155] Batch [5]#011Speed: 2107.16 samples/sec#011loss=2.334149\n",
      "[05/21/2025 21:01:57 INFO 140363140085568] processed a total of 1258 examples\n",
      "#metrics {\"StartTime\": 1747861316.4906425, \"EndTime\": 1747861317.3803039, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 889.3764019012451, \"count\": 1, \"min\": 889.3764019012451, \"max\": 889.3764019012451}}}\n",
      "[05/21/2025 21:01:57 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1414.21756787471 records/second\n",
      "[05/21/2025 21:01:57 INFO 140363140085568] #progress_metric: host=algo-1, completed 39.0 % of epochs\n",
      "[05/21/2025 21:01:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.313355541229248\n",
      "[05/21/2025 21:01:57 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:57 INFO 140363140085568] Epoch[156] Batch[0] avg_epoch_loss=2.297638\n",
      "[05/21/2025 21:01:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.297637701034546\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] Epoch[156] Batch[5] avg_epoch_loss=2.274496\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.2744960387547812\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] Epoch[156] Batch [5]#011Speed: 2125.10 samples/sec#011loss=2.274496\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] Epoch[156] Batch[10] avg_epoch_loss=2.278662\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=2.2836613178253176\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] Epoch[156] Batch [10]#011Speed: 2038.06 samples/sec#011loss=2.283661\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747861317.3804321, \"EndTime\": 1747861318.316912, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.1226558685303, \"count\": 1, \"min\": 936.1226558685303, \"max\": 936.1226558685303}}}\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1424.8324286800926 records/second\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] #progress_metric: host=algo-1, completed 39.25 % of epochs\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.278662074695934\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] Epoch[157] Batch[0] avg_epoch_loss=2.223108\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.2231075763702393\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] Epoch[157] Batch[5] avg_epoch_loss=2.260893\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.260892868041992\n",
      "[05/21/2025 21:01:58 INFO 140363140085568] Epoch[157] Batch [5]#011Speed: 2166.28 samples/sec#011loss=2.260893\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] Epoch[157] Batch[10] avg_epoch_loss=2.221781\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=2.1748461961746215\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] Epoch[157] Batch [10]#011Speed: 2110.77 samples/sec#011loss=2.174846\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747861318.3170116, \"EndTime\": 1747861319.2392273, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.9541549682617, \"count\": 1, \"min\": 921.9541549682617, \"max\": 921.9541549682617}}}\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1431.6052340067706 records/second\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] #progress_metric: host=algo-1, completed 39.5 % of epochs\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.2217807444659146\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] Epoch[158] Batch[0] avg_epoch_loss=2.234820\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.2348196506500244\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] Epoch[158] Batch[5] avg_epoch_loss=2.285220\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.28521990776062\n",
      "[05/21/2025 21:01:59 INFO 140363140085568] Epoch[158] Batch [5]#011Speed: 2138.12 samples/sec#011loss=2.285220\n",
      "[05/21/2025 21:02:00 INFO 140363140085568] processed a total of 1277 examples\n",
      "#metrics {\"StartTime\": 1747861319.239286, \"EndTime\": 1747861320.1164742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 876.8987655639648, \"count\": 1, \"min\": 876.8987655639648, \"max\": 876.8987655639648}}}\n",
      "[05/21/2025 21:02:00 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1456.1081039641037 records/second\n",
      "[05/21/2025 21:02:00 INFO 140363140085568] #progress_metric: host=algo-1, completed 39.75 % of epochs\n",
      "[05/21/2025 21:02:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.287985587120056\n",
      "[05/21/2025 21:02:00 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:00 INFO 140363140085568] Epoch[159] Batch[0] avg_epoch_loss=2.250835\n",
      "[05/21/2025 21:02:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.250835418701172\n",
      "[05/21/2025 21:02:00 INFO 140363140085568] Epoch[159] Batch[5] avg_epoch_loss=2.212818\n",
      "[05/21/2025 21:02:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.2128179470698037\n",
      "[05/21/2025 21:02:00 INFO 140363140085568] Epoch[159] Batch [5]#011Speed: 2123.64 samples/sec#011loss=2.212818\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] Epoch[159] Batch[10] avg_epoch_loss=2.193381\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=2.1700571537017823\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] Epoch[159] Batch [10]#011Speed: 1968.14 samples/sec#011loss=2.170057\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747861320.11654, \"EndTime\": 1747861321.069379, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.3537158966064, \"count\": 1, \"min\": 952.3537158966064, \"max\": 952.3537158966064}}}\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1406.846177182947 records/second\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] #progress_metric: host=algo-1, completed 40.0 % of epochs\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.1933812228116123\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_28f481d7-70df-49b8-a10e-250565844853-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861321.0694816, \"EndTime\": 1747861321.080324, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.446310043334961, \"count\": 1, \"min\": 10.446310043334961, \"max\": 10.446310043334961}}}\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] Epoch[160] Batch[0] avg_epoch_loss=2.359436\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.359435558319092\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] Epoch[160] Batch[5] avg_epoch_loss=2.253253\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.2532531023025513\n",
      "[05/21/2025 21:02:01 INFO 140363140085568] Epoch[160] Batch [5]#011Speed: 2081.32 samples/sec#011loss=2.253253\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] Epoch[160] Batch[10] avg_epoch_loss=2.231825\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=2.206110191345215\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] Epoch[160] Batch [10]#011Speed: 1994.47 samples/sec#011loss=2.206110\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747861321.080415, \"EndTime\": 1747861322.0357735, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.3067684173584, \"count\": 1, \"min\": 955.3067684173584, \"max\": 955.3067684173584}}}\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1376.39270706557 records/second\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] #progress_metric: host=algo-1, completed 40.25 % of epochs\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.231824506412853\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] Epoch[161] Batch[0] avg_epoch_loss=2.297482\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.297482490539551\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] Epoch[161] Batch[5] avg_epoch_loss=2.231783\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.231782635052999\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] Epoch[161] Batch [5]#011Speed: 2021.04 samples/sec#011loss=2.231783\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747861322.0358331, \"EndTime\": 1747861322.920546, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 884.4587802886963, \"count\": 1, \"min\": 884.4587802886963, \"max\": 884.4587802886963}}}\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1431.2279676008122 records/second\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] #progress_metric: host=algo-1, completed 40.5 % of epochs\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.2304205894470215\n",
      "[05/21/2025 21:02:02 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] Epoch[162] Batch[0] avg_epoch_loss=2.286108\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.2861082553863525\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] Epoch[162] Batch[5] avg_epoch_loss=2.241917\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.2419170141220093\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] Epoch[162] Batch [5]#011Speed: 2078.54 samples/sec#011loss=2.241917\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] Epoch[162] Batch[10] avg_epoch_loss=2.246563\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=2.2521378993988037\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] Epoch[162] Batch [10]#011Speed: 2017.79 samples/sec#011loss=2.252138\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747861322.9206119, \"EndTime\": 1747861323.869395, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.4710693359375, \"count\": 1, \"min\": 948.4710693359375, \"max\": 948.4710693359375}}}\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1406.342245879088 records/second\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] #progress_metric: host=algo-1, completed 40.75 % of epochs\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.246562871066007\n",
      "[05/21/2025 21:02:03 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] Epoch[163] Batch[0] avg_epoch_loss=2.203187\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.2031869888305664\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] Epoch[163] Batch[5] avg_epoch_loss=2.210852\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.2108524640401206\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] Epoch[163] Batch [5]#011Speed: 2141.48 samples/sec#011loss=2.210852\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] Epoch[163] Batch[10] avg_epoch_loss=2.311198\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=2.4316134452819824\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] Epoch[163] Batch [10]#011Speed: 2062.33 samples/sec#011loss=2.431613\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747861323.8694546, \"EndTime\": 1747861324.8019493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.2011470794678, \"count\": 1, \"min\": 932.2011470794678, \"max\": 932.2011470794678}}}\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1395.483059583569 records/second\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] #progress_metric: host=algo-1, completed 41.0 % of epochs\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.311198364604603\n",
      "[05/21/2025 21:02:04 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] Epoch[164] Batch[0] avg_epoch_loss=2.346757\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.346756935119629\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] Epoch[164] Batch[5] avg_epoch_loss=2.380173\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.3801729679107666\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] Epoch[164] Batch [5]#011Speed: 2134.80 samples/sec#011loss=2.380173\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] Epoch[164] Batch[10] avg_epoch_loss=2.367678\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=2.3526833057403564\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] Epoch[164] Batch [10]#011Speed: 1972.79 samples/sec#011loss=2.352683\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747861324.8020113, \"EndTime\": 1747861325.7514825, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 949.1758346557617, \"count\": 1, \"min\": 949.1758346557617, \"max\": 949.1758346557617}}}\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1428.4750388170094 records/second\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] #progress_metric: host=algo-1, completed 41.25 % of epochs\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.3676776669242163\n",
      "[05/21/2025 21:02:05 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] Epoch[165] Batch[0] avg_epoch_loss=2.361170\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.3611702919006348\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] Epoch[165] Batch[5] avg_epoch_loss=2.308275\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.308275024096171\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] Epoch[165] Batch [5]#011Speed: 1990.04 samples/sec#011loss=2.308275\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] Epoch[165] Batch[10] avg_epoch_loss=2.273724\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=2.2322620868682863\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] Epoch[165] Batch [10]#011Speed: 1794.78 samples/sec#011loss=2.232262\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747861325.75154, \"EndTime\": 1747861326.7578254, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1005.9363842010498, \"count\": 1, \"min\": 1005.9363842010498, \"max\": 1005.9363842010498}}}\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1334.9545694336548 records/second\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] #progress_metric: host=algo-1, completed 41.5 % of epochs\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.273723688992587\n",
      "[05/21/2025 21:02:06 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] Epoch[166] Batch[0] avg_epoch_loss=2.320024\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.320024013519287\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] Epoch[166] Batch[5] avg_epoch_loss=2.231379\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.231379230817159\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] Epoch[166] Batch [5]#011Speed: 2074.85 samples/sec#011loss=2.231379\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] processed a total of 1271 examples\n",
      "#metrics {\"StartTime\": 1747861326.7578862, \"EndTime\": 1747861327.6400523, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 881.8666934967041, \"count\": 1, \"min\": 881.8666934967041, \"max\": 881.8666934967041}}}\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1441.107799773465 records/second\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] #progress_metric: host=algo-1, completed 41.75 % of epochs\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.244871973991394\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] Epoch[167] Batch[0] avg_epoch_loss=2.228995\n",
      "[05/21/2025 21:02:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=2.228994607925415\n",
      "[05/21/2025 21:02:08 INFO 140363140085568] Epoch[167] Batch[5] avg_epoch_loss=2.185886\n",
      "[05/21/2025 21:02:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.185885508855184\n",
      "[05/21/2025 21:02:08 INFO 140363140085568] Epoch[167] Batch [5]#011Speed: 2098.70 samples/sec#011loss=2.185886\n",
      "[05/21/2025 21:02:08 INFO 140363140085568] processed a total of 1269 examples\n",
      "#metrics {\"StartTime\": 1747861327.640116, \"EndTime\": 1747861328.5131075, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 872.6818561553955, \"count\": 1, \"min\": 872.6818561553955, \"max\": 872.6818561553955}}}\n",
      "[05/21/2025 21:02:08 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1453.977295040454 records/second\n",
      "[05/21/2025 21:02:08 INFO 140363140085568] #progress_metric: host=algo-1, completed 42.0 % of epochs\n",
      "[05/21/2025 21:02:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.205726146697998\n",
      "[05/21/2025 21:02:08 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:08 INFO 140363140085568] Epoch[168] Batch[0] avg_epoch_loss=2.257814\n",
      "[05/21/2025 21:02:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.2578141689300537\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] Epoch[168] Batch[5] avg_epoch_loss=2.211834\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.2118339935938516\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] Epoch[168] Batch [5]#011Speed: 2142.89 samples/sec#011loss=2.211834\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] Epoch[168] Batch[10] avg_epoch_loss=2.173053\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=2.1265161514282225\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] Epoch[168] Batch [10]#011Speed: 2020.44 samples/sec#011loss=2.126516\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747861328.513174, \"EndTime\": 1747861329.453903, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.3581619262695, \"count\": 1, \"min\": 940.3581619262695, \"max\": 940.3581619262695}}}\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1398.2782004618582 records/second\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] #progress_metric: host=algo-1, completed 42.25 % of epochs\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.1730531562458384\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_fe414f48-397f-420c-a268-6b26952c5e89-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861329.4539602, \"EndTime\": 1747861329.4650657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.840654373168945, \"count\": 1, \"min\": 10.840654373168945, \"max\": 10.840654373168945}}}\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] Epoch[169] Batch[0] avg_epoch_loss=2.256145\n",
      "[05/21/2025 21:02:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.2561452388763428\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] Epoch[169] Batch[5] avg_epoch_loss=2.205655\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.205654819806417\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] Epoch[169] Batch [5]#011Speed: 2128.73 samples/sec#011loss=2.205655\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] Epoch[169] Batch[10] avg_epoch_loss=2.152796\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.0893652200698853\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] Epoch[169] Batch [10]#011Speed: 1969.04 samples/sec#011loss=2.089365\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747861329.4651175, \"EndTime\": 1747861330.4112697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.1004734039307, \"count\": 1, \"min\": 946.1004734039307, \"max\": 946.1004734039307}}}\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1404.5771137458935 records/second\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] #progress_metric: host=algo-1, completed 42.5 % of epochs\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.152795910835266\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_071071b2-c8c0-4845-84b0-a90623f34540-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861330.41133, \"EndTime\": 1747861330.4219928, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.283946990966797, \"count\": 1, \"min\": 10.283946990966797, \"max\": 10.283946990966797}}}\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] Epoch[170] Batch[0] avg_epoch_loss=2.270843\n",
      "[05/21/2025 21:02:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.2708425521850586\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] Epoch[170] Batch[5] avg_epoch_loss=2.208818\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.2088175614674888\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] Epoch[170] Batch [5]#011Speed: 2070.14 samples/sec#011loss=2.208818\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] Epoch[170] Batch[10] avg_epoch_loss=2.204960\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=2.200331449508667\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] Epoch[170] Batch [10]#011Speed: 1974.62 samples/sec#011loss=2.200331\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747861330.4220583, \"EndTime\": 1747861331.3733492, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.2355327606201, \"count\": 1, \"min\": 951.2355327606201, \"max\": 951.2355327606201}}}\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1437.9912238998234 records/second\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] #progress_metric: host=algo-1, completed 42.75 % of epochs\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.2049602378498423\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] Epoch[171] Batch[0] avg_epoch_loss=2.233905\n",
      "[05/21/2025 21:02:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.23390531539917\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] Epoch[171] Batch[5] avg_epoch_loss=2.197292\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.1972919702529907\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] Epoch[171] Batch [5]#011Speed: 2035.84 samples/sec#011loss=2.197292\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747861331.3734102, \"EndTime\": 1747861332.27581, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 902.1475315093994, \"count\": 1, \"min\": 902.1475315093994, \"max\": 902.1475315093994}}}\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1414.2312540627956 records/second\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] #progress_metric: host=algo-1, completed 43.0 % of epochs\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.1924655199050904\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] Epoch[172] Batch[0] avg_epoch_loss=2.248968\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.2489683628082275\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] Epoch[172] Batch[5] avg_epoch_loss=2.191444\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.1914440393447876\n",
      "[05/21/2025 21:02:12 INFO 140363140085568] Epoch[172] Batch [5]#011Speed: 2130.02 samples/sec#011loss=2.191444\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] Epoch[172] Batch[10] avg_epoch_loss=2.132544\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=2.061863827705383\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] Epoch[172] Batch [10]#011Speed: 2031.25 samples/sec#011loss=2.061864\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747861332.2758873, \"EndTime\": 1747861333.2184703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.2335624694824, \"count\": 1, \"min\": 942.2335624694824, \"max\": 942.2335624694824}}}\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1384.880062018391 records/second\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] #progress_metric: host=algo-1, completed 43.25 % of epochs\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.1325439431450586\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_0353b00f-505e-4a53-8f85-451e80623e04-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861333.218528, \"EndTime\": 1747861333.2293828, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.589361190795898, \"count\": 1, \"min\": 10.589361190795898, \"max\": 10.589361190795898}}}\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] Epoch[173] Batch[0] avg_epoch_loss=2.141510\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.141510486602783\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] Epoch[173] Batch[5] avg_epoch_loss=2.176247\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.1762466430664062\n",
      "[05/21/2025 21:02:13 INFO 140363140085568] Epoch[173] Batch [5]#011Speed: 2065.89 samples/sec#011loss=2.176247\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] Epoch[173] Batch[10] avg_epoch_loss=2.154698\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=2.128840517997742\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] Epoch[173] Batch [10]#011Speed: 2145.94 samples/sec#011loss=2.128841\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747861333.2294352, \"EndTime\": 1747861334.166412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.9263648986816, \"count\": 1, \"min\": 936.9263648986816, \"max\": 936.9263648986816}}}\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1367.1061239974565 records/second\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] #progress_metric: host=algo-1, completed 43.5 % of epochs\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.1546984043988315\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] Epoch[174] Batch[0] avg_epoch_loss=2.161946\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.1619458198547363\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] Epoch[174] Batch[5] avg_epoch_loss=2.279192\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.2791916131973267\n",
      "[05/21/2025 21:02:14 INFO 140363140085568] Epoch[174] Batch [5]#011Speed: 1957.48 samples/sec#011loss=2.279192\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] Epoch[174] Batch[10] avg_epoch_loss=2.294086\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=2.3119587898254395\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] Epoch[174] Batch [10]#011Speed: 2080.25 samples/sec#011loss=2.311959\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747861334.1664727, \"EndTime\": 1747861335.1246445, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.8783512115479, \"count\": 1, \"min\": 957.8783512115479, \"max\": 957.8783512115479}}}\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1362.2648936408502 records/second\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] #progress_metric: host=algo-1, completed 43.75 % of epochs\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.2940857843919233\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] Epoch[175] Batch[0] avg_epoch_loss=2.197170\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.1971700191497803\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] Epoch[175] Batch[5] avg_epoch_loss=2.191022\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.1910222371419272\n",
      "[05/21/2025 21:02:15 INFO 140363140085568] Epoch[175] Batch [5]#011Speed: 2103.38 samples/sec#011loss=2.191022\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] Epoch[175] Batch[10] avg_epoch_loss=2.201992\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=2.2151565074920656\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] Epoch[175] Batch [10]#011Speed: 1905.83 samples/sec#011loss=2.215157\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747861335.1247034, \"EndTime\": 1747861336.0804405, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.4893970489502, \"count\": 1, \"min\": 955.4893970489502, \"max\": 955.4893970489502}}}\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1419.0370128815416 records/second\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] #progress_metric: host=algo-1, completed 44.0 % of epochs\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.2019923600283535\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] Epoch[176] Batch[0] avg_epoch_loss=2.353582\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.3535823822021484\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] Epoch[176] Batch[5] avg_epoch_loss=2.212596\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.212595582008362\n",
      "[05/21/2025 21:02:16 INFO 140363140085568] Epoch[176] Batch [5]#011Speed: 2064.88 samples/sec#011loss=2.212596\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] Epoch[176] Batch[10] avg_epoch_loss=2.314204\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.4361348152160645\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] Epoch[176] Batch [10]#011Speed: 2009.98 samples/sec#011loss=2.436135\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747861336.0805, \"EndTime\": 1747861337.0337703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.9855251312256, \"count\": 1, \"min\": 952.9855251312256, \"max\": 952.9855251312256}}}\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1376.5965587880587 records/second\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] #progress_metric: host=algo-1, completed 44.25 % of epochs\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.3142043243754995\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] Epoch[177] Batch[0] avg_epoch_loss=2.141840\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.1418399810791016\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] Epoch[177] Batch[5] avg_epoch_loss=2.235150\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.2351495027542114\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] Epoch[177] Batch [5]#011Speed: 2058.93 samples/sec#011loss=2.235150\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] Epoch[177] Batch[10] avg_epoch_loss=2.258160\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=2.285772132873535\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] Epoch[177] Batch [10]#011Speed: 1986.10 samples/sec#011loss=2.285772\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] processed a total of 1362 examples\n",
      "#metrics {\"StartTime\": 1747861337.0338302, \"EndTime\": 1747861337.9871948, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.0794620513916, \"count\": 1, \"min\": 953.0794620513916, \"max\": 953.0794620513916}}}\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1428.9160513621578 records/second\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] #progress_metric: host=algo-1, completed 44.5 % of epochs\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.258159789172086\n",
      "[05/21/2025 21:02:17 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] Epoch[178] Batch[0] avg_epoch_loss=2.343477\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.343477487564087\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] Epoch[178] Batch[5] avg_epoch_loss=2.222279\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.2222787539164224\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] Epoch[178] Batch [5]#011Speed: 2128.03 samples/sec#011loss=2.222279\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] Epoch[178] Batch[10] avg_epoch_loss=2.220914\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=2.2192752361297607\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] Epoch[178] Batch [10]#011Speed: 1929.91 samples/sec#011loss=2.219275\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747861337.987256, \"EndTime\": 1747861338.9415936, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.0488719940186, \"count\": 1, \"min\": 954.0488719940186, \"max\": 954.0488719940186}}}\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1377.165758687192 records/second\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] #progress_metric: host=algo-1, completed 44.75 % of epochs\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.220913518558849\n",
      "[05/21/2025 21:02:18 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] Epoch[179] Batch[0] avg_epoch_loss=2.222349\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.2223494052886963\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] Epoch[179] Batch[5] avg_epoch_loss=2.218959\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.218958616256714\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] Epoch[179] Batch [5]#011Speed: 2215.88 samples/sec#011loss=2.218959\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] Epoch[179] Batch[10] avg_epoch_loss=2.131680\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=2.0269464254379272\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] Epoch[179] Batch [10]#011Speed: 2055.41 samples/sec#011loss=2.026946\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747861338.9416494, \"EndTime\": 1747861339.861044, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.0852642059326, \"count\": 1, \"min\": 919.0852642059326, \"max\": 919.0852642059326}}}\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1455.6397179492833 records/second\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] #progress_metric: host=algo-1, completed 45.0 % of epochs\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.1316803477027197\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:02:19 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_c520bb9e-3a23-49a5-9c09-8e5cfb3423e4-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861339.8611114, \"EndTime\": 1747861339.8713548, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.921073913574219, \"count\": 1, \"min\": 9.921073913574219, \"max\": 9.921073913574219}}}\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] Epoch[180] Batch[0] avg_epoch_loss=2.245532\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.2455317974090576\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] Epoch[180] Batch[5] avg_epoch_loss=2.198921\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.198920965194702\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] Epoch[180] Batch [5]#011Speed: 2190.72 samples/sec#011loss=2.198921\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] Epoch[180] Batch[10] avg_epoch_loss=2.224126\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=2.254371452331543\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] Epoch[180] Batch [10]#011Speed: 2054.36 samples/sec#011loss=2.254371\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747861339.871406, \"EndTime\": 1747861340.8055565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.1020584106445, \"count\": 1, \"min\": 934.1020584106445, \"max\": 934.1020584106445}}}\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1453.669398231412 records/second\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] #progress_metric: host=algo-1, completed 45.25 % of epochs\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.2241257320750845\n",
      "[05/21/2025 21:02:20 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] Epoch[181] Batch[0] avg_epoch_loss=2.184255\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.184255361557007\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] Epoch[181] Batch[5] avg_epoch_loss=2.188294\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.1882936557133994\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] Epoch[181] Batch [5]#011Speed: 1996.32 samples/sec#011loss=2.188294\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] Epoch[181] Batch[10] avg_epoch_loss=2.172556\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=2.153670597076416\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] Epoch[181] Batch [10]#011Speed: 1921.22 samples/sec#011loss=2.153671\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747861340.805614, \"EndTime\": 1747861341.7870643, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 981.2076091766357, \"count\": 1, \"min\": 981.2076091766357, \"max\": 981.2076091766357}}}\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1350.2436047230622 records/second\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] #progress_metric: host=algo-1, completed 45.5 % of epochs\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.1725559017874976\n",
      "[05/21/2025 21:02:21 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] Epoch[182] Batch[0] avg_epoch_loss=2.270625\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.270624876022339\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] Epoch[182] Batch[5] avg_epoch_loss=2.221897\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.2218974431355796\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] Epoch[182] Batch [5]#011Speed: 2068.29 samples/sec#011loss=2.221897\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] Epoch[182] Batch[10] avg_epoch_loss=2.197613\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=2.1684727668762207\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] Epoch[182] Batch [10]#011Speed: 1953.22 samples/sec#011loss=2.168473\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747861341.7871327, \"EndTime\": 1747861342.745118, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.7298164367676, \"count\": 1, \"min\": 957.7298164367676, \"max\": 957.7298164367676}}}\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1407.3710502707745 records/second\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] #progress_metric: host=algo-1, completed 45.75 % of epochs\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.1976134993813257\n",
      "[05/21/2025 21:02:22 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] Epoch[183] Batch[0] avg_epoch_loss=2.211027\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.211027145385742\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] Epoch[183] Batch[5] avg_epoch_loss=2.195416\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.19541605313619\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] Epoch[183] Batch [5]#011Speed: 2123.19 samples/sec#011loss=2.195416\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] Epoch[183] Batch[10] avg_epoch_loss=2.218977\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=2.247250032424927\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] Epoch[183] Batch [10]#011Speed: 1973.75 samples/sec#011loss=2.247250\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747861342.7451756, \"EndTime\": 1747861343.6957688, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.3505229949951, \"count\": 1, \"min\": 950.3505229949951, \"max\": 950.3505229949951}}}\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1367.7938278393424 records/second\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] #progress_metric: host=algo-1, completed 46.0 % of epochs\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.218976952812888\n",
      "[05/21/2025 21:02:23 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] Epoch[184] Batch[0] avg_epoch_loss=2.252273\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.252272844314575\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] Epoch[184] Batch[5] avg_epoch_loss=2.189775\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.189774672190348\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] Epoch[184] Batch [5]#011Speed: 2159.43 samples/sec#011loss=2.189775\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] Epoch[184] Batch[10] avg_epoch_loss=2.206462\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=2.2264862060546875\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] Epoch[184] Batch [10]#011Speed: 2085.32 samples/sec#011loss=2.226486\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747861343.695827, \"EndTime\": 1747861344.6218975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.82106590271, \"count\": 1, \"min\": 925.82106590271, \"max\": 925.82106590271}}}\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1433.1890854108215 records/second\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] #progress_metric: host=algo-1, completed 46.25 % of epochs\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.2064617330377754\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] Epoch[185] Batch[0] avg_epoch_loss=2.184007\n",
      "[05/21/2025 21:02:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.184006929397583\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] Epoch[185] Batch[5] avg_epoch_loss=2.273194\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.273193677266439\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] Epoch[185] Batch [5]#011Speed: 2131.55 samples/sec#011loss=2.273194\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] Epoch[185] Batch[10] avg_epoch_loss=2.293878\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=2.318700170516968\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] Epoch[185] Batch [10]#011Speed: 2095.40 samples/sec#011loss=2.318700\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747861344.621956, \"EndTime\": 1747861345.552239, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.0241470336914, \"count\": 1, \"min\": 930.0241470336914, \"max\": 930.0241470336914}}}\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1409.5078463600169 records/second\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] #progress_metric: host=algo-1, completed 46.5 % of epochs\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.29387844692577\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] Epoch[186] Batch[0] avg_epoch_loss=2.214863\n",
      "[05/21/2025 21:02:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.2148630619049072\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] Epoch[186] Batch[5] avg_epoch_loss=2.223002\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.223001559575399\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] Epoch[186] Batch [5]#011Speed: 2115.99 samples/sec#011loss=2.223002\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] Epoch[186] Batch[10] avg_epoch_loss=2.308909\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=2.411998987197876\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] Epoch[186] Batch [10]#011Speed: 1989.68 samples/sec#011loss=2.411999\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747861345.552298, \"EndTime\": 1747861346.4991004, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.5155601501465, \"count\": 1, \"min\": 946.5155601501465, \"max\": 946.5155601501465}}}\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1392.3302406892624 records/second\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] #progress_metric: host=algo-1, completed 46.75 % of epochs\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.3089094812219795\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] Epoch[187] Batch[0] avg_epoch_loss=2.253044\n",
      "[05/21/2025 21:02:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.253044366836548\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] Epoch[187] Batch[5] avg_epoch_loss=2.227131\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.227130651473999\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] Epoch[187] Batch [5]#011Speed: 2091.04 samples/sec#011loss=2.227131\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] Epoch[187] Batch[10] avg_epoch_loss=2.237321\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=2.2495492935180663\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] Epoch[187] Batch [10]#011Speed: 2004.16 samples/sec#011loss=2.249549\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747861346.4991615, \"EndTime\": 1747861347.4443057, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.852352142334, \"count\": 1, \"min\": 944.852352142334, \"max\": 944.852352142334}}}\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1421.2207750856007 records/second\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] #progress_metric: host=algo-1, completed 47.0 % of epochs\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.2373209433122114\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] Epoch[188] Batch[0] avg_epoch_loss=2.177366\n",
      "[05/21/2025 21:02:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.177366018295288\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] Epoch[188] Batch[5] avg_epoch_loss=2.220975\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.2209754387537637\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] Epoch[188] Batch [5]#011Speed: 2108.37 samples/sec#011loss=2.220975\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] Epoch[188] Batch[10] avg_epoch_loss=2.094235\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=1.9421458005905152\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] Epoch[188] Batch [10]#011Speed: 2137.33 samples/sec#011loss=1.942146\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747861347.4443862, \"EndTime\": 1747861348.375494, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.8421611785889, \"count\": 1, \"min\": 930.8421611785889, \"max\": 930.8421611785889}}}\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1394.3040568764318 records/second\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] #progress_metric: host=algo-1, completed 47.25 % of epochs\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.0942346941341055\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_816c6e16-f022-4f5d-abb8-d98ab2483f41-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861348.3755531, \"EndTime\": 1747861348.3867164, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.742425918579102, \"count\": 1, \"min\": 10.742425918579102, \"max\": 10.742425918579102}}}\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] Epoch[189] Batch[0] avg_epoch_loss=2.225889\n",
      "[05/21/2025 21:02:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.225888967514038\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] Epoch[189] Batch[5] avg_epoch_loss=2.152963\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.1529632012049356\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] Epoch[189] Batch [5]#011Speed: 2114.25 samples/sec#011loss=2.152963\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] Epoch[189] Batch[10] avg_epoch_loss=2.169795\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=2.1899922847747804\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] Epoch[189] Batch [10]#011Speed: 1904.34 samples/sec#011loss=2.189992\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] processed a total of 1404 examples\n",
      "#metrics {\"StartTime\": 1747861348.3867605, \"EndTime\": 1747861349.3381007, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.2948989868164, \"count\": 1, \"min\": 951.2948989868164, \"max\": 951.2948989868164}}}\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1475.7376782804185 records/second\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] #progress_metric: host=algo-1, completed 47.5 % of epochs\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.1697946028275923\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] Epoch[190] Batch[0] avg_epoch_loss=2.117418\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.117418050765991\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] Epoch[190] Batch[5] avg_epoch_loss=2.159649\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.159649213155111\n",
      "[05/21/2025 21:02:29 INFO 140363140085568] Epoch[190] Batch [5]#011Speed: 2040.67 samples/sec#011loss=2.159649\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] Epoch[190] Batch[10] avg_epoch_loss=2.247185\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=2.352226972579956\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] Epoch[190] Batch [10]#011Speed: 2020.92 samples/sec#011loss=2.352227\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747861349.3381653, \"EndTime\": 1747861350.2864122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.913408279419, \"count\": 1, \"min\": 947.913408279419, \"max\": 947.913408279419}}}\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1439.8738493722271 records/second\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] #progress_metric: host=algo-1, completed 47.75 % of epochs\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.247184558348222\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] Epoch[191] Batch[0] avg_epoch_loss=2.201941\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.2019407749176025\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] Epoch[191] Batch[5] avg_epoch_loss=2.169749\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.1697486639022827\n",
      "[05/21/2025 21:02:30 INFO 140363140085568] Epoch[191] Batch [5]#011Speed: 2012.44 samples/sec#011loss=2.169749\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] Epoch[191] Batch[10] avg_epoch_loss=2.189494\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=2.213188362121582\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] Epoch[191] Batch [10]#011Speed: 1956.88 samples/sec#011loss=2.213188\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] processed a total of 1373 examples\n",
      "#metrics {\"StartTime\": 1747861350.2864711, \"EndTime\": 1747861351.2480276, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.2984657287598, \"count\": 1, \"min\": 961.2984657287598, \"max\": 961.2984657287598}}}\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1428.1468525502785 records/second\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] #progress_metric: host=algo-1, completed 48.0 % of epochs\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.1894939812746914\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] Epoch[192] Batch[0] avg_epoch_loss=2.211364\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.2113640308380127\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] Epoch[192] Batch[5] avg_epoch_loss=2.219287\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.2192865212758384\n",
      "[05/21/2025 21:02:31 INFO 140363140085568] Epoch[192] Batch [5]#011Speed: 2080.01 samples/sec#011loss=2.219287\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] Epoch[192] Batch[10] avg_epoch_loss=2.199857\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=2.176540756225586\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] Epoch[192] Batch [10]#011Speed: 2024.17 samples/sec#011loss=2.176541\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747861351.2480862, \"EndTime\": 1747861352.2184162, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 969.9554443359375, \"count\": 1, \"min\": 969.9554443359375, \"max\": 969.9554443359375}}}\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1378.2854305845133 records/second\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] #progress_metric: host=algo-1, completed 48.25 % of epochs\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.199856628071178\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] Epoch[193] Batch[0] avg_epoch_loss=2.208657\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.2086570262908936\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] Epoch[193] Batch[5] avg_epoch_loss=2.144900\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.1449004411697388\n",
      "[05/21/2025 21:02:32 INFO 140363140085568] Epoch[193] Batch [5]#011Speed: 2179.10 samples/sec#011loss=2.144900\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] Epoch[193] Batch[10] avg_epoch_loss=2.158956\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=2.175822639465332\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] Epoch[193] Batch [10]#011Speed: 1991.19 samples/sec#011loss=2.175823\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] processed a total of 1382 examples\n",
      "#metrics {\"StartTime\": 1747861352.218475, \"EndTime\": 1747861353.1499276, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.196928024292, \"count\": 1, \"min\": 931.196928024292, \"max\": 931.196928024292}}}\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1483.9757833940932 records/second\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] #progress_metric: host=algo-1, completed 48.5 % of epochs\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.1589559858495537\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] Epoch[194] Batch[0] avg_epoch_loss=2.029089\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.0290889739990234\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] Epoch[194] Batch[5] avg_epoch_loss=2.161579\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.1615786949793496\n",
      "[05/21/2025 21:02:33 INFO 140363140085568] Epoch[194] Batch [5]#011Speed: 2175.42 samples/sec#011loss=2.161579\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] Epoch[194] Batch[10] avg_epoch_loss=2.147233\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=2.130017566680908\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] Epoch[194] Batch [10]#011Speed: 1961.82 samples/sec#011loss=2.130018\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747861353.1499825, \"EndTime\": 1747861354.0867834, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.4840984344482, \"count\": 1, \"min\": 936.4840984344482, \"max\": 936.4840984344482}}}\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1463.8526247512257 records/second\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] #progress_metric: host=algo-1, completed 48.75 % of epochs\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.1472327275709673\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] Epoch[195] Batch[0] avg_epoch_loss=2.149215\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.149214506149292\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] Epoch[195] Batch[5] avg_epoch_loss=2.161667\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.1616668701171875\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] Epoch[195] Batch [5]#011Speed: 2224.14 samples/sec#011loss=2.161667\n",
      "[05/21/2025 21:02:34 INFO 140363140085568] Epoch[195] Batch[10] avg_epoch_loss=2.114859\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=2.0586888551712037\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] Epoch[195] Batch [10]#011Speed: 2098.19 samples/sec#011loss=2.058689\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747861354.0868406, \"EndTime\": 1747861355.0004997, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 913.362979888916, \"count\": 1, \"min\": 913.362979888916, \"max\": 913.362979888916}}}\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1453.8254710677536 records/second\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] #progress_metric: host=algo-1, completed 49.0 % of epochs\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.1148586815053765\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] Epoch[196] Batch[0] avg_epoch_loss=2.071541\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.071540594100952\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] Epoch[196] Batch[5] avg_epoch_loss=2.130970\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.1309701204299927\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] Epoch[196] Batch [5]#011Speed: 2180.72 samples/sec#011loss=2.130970\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] Epoch[196] Batch[10] avg_epoch_loss=2.135648\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.1412603855133057\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] Epoch[196] Batch [10]#011Speed: 2006.54 samples/sec#011loss=2.141260\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747861355.0005598, \"EndTime\": 1747861355.933088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.1460723876953, \"count\": 1, \"min\": 932.1460723876953, \"max\": 932.1460723876953}}}\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1445.9910257292265 records/second\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] #progress_metric: host=algo-1, completed 49.25 % of epochs\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.13564751364968\n",
      "[05/21/2025 21:02:35 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] Epoch[197] Batch[0] avg_epoch_loss=2.132479\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.132479190826416\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] Epoch[197] Batch[5] avg_epoch_loss=2.157575\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.157574633757273\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] Epoch[197] Batch [5]#011Speed: 1897.10 samples/sec#011loss=2.157575\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] Epoch[197] Batch[10] avg_epoch_loss=2.187875\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=2.2242348194122314\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] Epoch[197] Batch [10]#011Speed: 1943.06 samples/sec#011loss=2.224235\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747861355.9331448, \"EndTime\": 1747861356.922924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 989.5350933074951, \"count\": 1, \"min\": 989.5350933074951, \"max\": 989.5350933074951}}}\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1331.8198844988449 records/second\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] #progress_metric: host=algo-1, completed 49.5 % of epochs\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.1878747181458906\n",
      "[05/21/2025 21:02:36 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] Epoch[198] Batch[0] avg_epoch_loss=2.158571\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.158571243286133\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] Epoch[198] Batch[5] avg_epoch_loss=2.179992\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.1799920797348022\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] Epoch[198] Batch [5]#011Speed: 2133.57 samples/sec#011loss=2.179992\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] Epoch[198] Batch[10] avg_epoch_loss=2.164753\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.146466851234436\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] Epoch[198] Batch [10]#011Speed: 2059.64 samples/sec#011loss=2.146467\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747861356.922983, \"EndTime\": 1747861357.8557847, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.5480461120605, \"count\": 1, \"min\": 932.5480461120605, \"max\": 932.5480461120605}}}\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1431.4306136284852 records/second\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] #progress_metric: host=algo-1, completed 49.75 % of epochs\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.1647533395073633\n",
      "[05/21/2025 21:02:37 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] Epoch[199] Batch[0] avg_epoch_loss=2.183410\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.1834096908569336\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] Epoch[199] Batch[5] avg_epoch_loss=2.107182\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.1071821451187134\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] Epoch[199] Batch [5]#011Speed: 2128.71 samples/sec#011loss=2.107182\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] Epoch[199] Batch[10] avg_epoch_loss=2.163149\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=2.230308675765991\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] Epoch[199] Batch [10]#011Speed: 1975.77 samples/sec#011loss=2.230309\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747861357.855842, \"EndTime\": 1747861358.8035774, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.4630355834961, \"count\": 1, \"min\": 947.4630355834961, \"max\": 947.4630355834961}}}\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1399.4004751016969 records/second\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] #progress_metric: host=algo-1, completed 50.0 % of epochs\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.1631487499583852\n",
      "[05/21/2025 21:02:38 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] Epoch[200] Batch[0] avg_epoch_loss=2.077149\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.077148914337158\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] Epoch[200] Batch[5] avg_epoch_loss=2.132527\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.1325265566507974\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] Epoch[200] Batch [5]#011Speed: 2108.77 samples/sec#011loss=2.132527\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] Epoch[200] Batch[10] avg_epoch_loss=2.141152\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=2.151501703262329\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] Epoch[200] Batch [10]#011Speed: 2087.51 samples/sec#011loss=2.151502\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747861358.8036342, \"EndTime\": 1747861359.7397246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.295581817627, \"count\": 1, \"min\": 935.295581817627, \"max\": 935.295581817627}}}\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1400.4939328919686 records/second\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] #progress_metric: host=algo-1, completed 50.25 % of epochs\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.141151623292403\n",
      "[05/21/2025 21:02:39 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] Epoch[201] Batch[0] avg_epoch_loss=2.094006\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.094006061553955\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] Epoch[201] Batch[5] avg_epoch_loss=2.070911\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.0709112087885537\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] Epoch[201] Batch [5]#011Speed: 2117.62 samples/sec#011loss=2.070911\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] processed a total of 1257 examples\n",
      "#metrics {\"StartTime\": 1747861359.739784, \"EndTime\": 1747861360.6047215, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.6936416625977, \"count\": 1, \"min\": 864.6936416625977, \"max\": 864.6936416625977}}}\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1453.536542014308 records/second\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] #progress_metric: host=algo-1, completed 50.5 % of epochs\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.10655734539032\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] Epoch[202] Batch[0] avg_epoch_loss=2.162035\n",
      "[05/21/2025 21:02:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.1620354652404785\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] Epoch[202] Batch[5] avg_epoch_loss=2.132590\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.1325904528299966\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] Epoch[202] Batch [5]#011Speed: 2080.89 samples/sec#011loss=2.132590\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] Epoch[202] Batch[10] avg_epoch_loss=2.175519\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=2.2270330429077148\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] Epoch[202] Batch [10]#011Speed: 2030.76 samples/sec#011loss=2.227033\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747861360.6047852, \"EndTime\": 1747861361.5585768, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.449010848999, \"count\": 1, \"min\": 953.449010848999, \"max\": 953.449010848999}}}\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1368.571989359598 records/second\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] #progress_metric: host=algo-1, completed 50.75 % of epochs\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.1755189028653232\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] Epoch[203] Batch[0] avg_epoch_loss=2.439597\n",
      "[05/21/2025 21:02:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.4395968914031982\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] Epoch[203] Batch[5] avg_epoch_loss=2.388616\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.388616442680359\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] Epoch[203] Batch [5]#011Speed: 2073.85 samples/sec#011loss=2.388616\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] Epoch[203] Batch[10] avg_epoch_loss=2.357438\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=2.320022964477539\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] Epoch[203] Batch [10]#011Speed: 1958.21 samples/sec#011loss=2.320023\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747861361.5586486, \"EndTime\": 1747861362.5129282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.0331363677979, \"count\": 1, \"min\": 954.0331363677979, \"max\": 954.0331363677979}}}\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1396.0540668589106 records/second\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] #progress_metric: host=algo-1, completed 51.0 % of epochs\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.357437588951804\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] Epoch[204] Batch[0] avg_epoch_loss=2.232751\n",
      "[05/21/2025 21:02:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.232750654220581\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] Epoch[204] Batch[5] avg_epoch_loss=2.186204\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.186204473177592\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] Epoch[204] Batch [5]#011Speed: 2026.48 samples/sec#011loss=2.186204\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] Epoch[204] Batch[10] avg_epoch_loss=2.575548\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=3.042760419845581\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] Epoch[204] Batch [10]#011Speed: 2115.39 samples/sec#011loss=3.042760\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747861362.5129864, \"EndTime\": 1747861363.4634483, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.1729011535645, \"count\": 1, \"min\": 950.1729011535645, \"max\": 950.1729011535645}}}\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1352.261933854165 records/second\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] #progress_metric: host=algo-1, completed 51.25 % of epochs\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.5755480852994053\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] Epoch[205] Batch[0] avg_epoch_loss=2.215142\n",
      "[05/21/2025 21:02:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.215142011642456\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] Epoch[205] Batch[5] avg_epoch_loss=2.413776\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.4137757619222007\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] Epoch[205] Batch [5]#011Speed: 2100.78 samples/sec#011loss=2.413776\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] Epoch[205] Batch[10] avg_epoch_loss=2.440483\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=2.472531223297119\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] Epoch[205] Batch [10]#011Speed: 2094.37 samples/sec#011loss=2.472531\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747861363.4635072, \"EndTime\": 1747861364.3950832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.3359260559082, \"count\": 1, \"min\": 931.3359260559082, \"max\": 931.3359260559082}}}\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1422.546588636476 records/second\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] #progress_metric: host=algo-1, completed 51.5 % of epochs\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.4404827898198906\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] Epoch[206] Batch[0] avg_epoch_loss=2.407216\n",
      "[05/21/2025 21:02:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.4072158336639404\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] Epoch[206] Batch[5] avg_epoch_loss=2.346084\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.346084475517273\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] Epoch[206] Batch [5]#011Speed: 2133.65 samples/sec#011loss=2.346084\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] Epoch[206] Batch[10] avg_epoch_loss=2.300941\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=2.2467679500579836\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] Epoch[206] Batch [10]#011Speed: 2089.09 samples/sec#011loss=2.246768\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747861364.3951495, \"EndTime\": 1747861365.326093, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.6707382202148, \"count\": 1, \"min\": 930.6707382202148, \"max\": 930.6707382202148}}}\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1414.9801012841103 records/second\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] #progress_metric: host=algo-1, completed 51.75 % of epochs\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.300940600308505\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] Epoch[207] Batch[0] avg_epoch_loss=2.188335\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.188335418701172\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] Epoch[207] Batch[5] avg_epoch_loss=2.213319\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.213318665822347\n",
      "[05/21/2025 21:02:45 INFO 140363140085568] Epoch[207] Batch [5]#011Speed: 2047.39 samples/sec#011loss=2.213319\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] Epoch[207] Batch[10] avg_epoch_loss=2.224765\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=2.238499879837036\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] Epoch[207] Batch [10]#011Speed: 2013.35 samples/sec#011loss=2.238500\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747861365.3261495, \"EndTime\": 1747861366.2767813, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.3388404846191, \"count\": 1, \"min\": 950.3388404846191, \"max\": 950.3388404846191}}}\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1423.572728499634 records/second\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] #progress_metric: host=algo-1, completed 52.0 % of epochs\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.22476467219266\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] Epoch[208] Batch[0] avg_epoch_loss=2.283283\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.283282995223999\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] Epoch[208] Batch[5] avg_epoch_loss=2.255047\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.2550474802652993\n",
      "[05/21/2025 21:02:46 INFO 140363140085568] Epoch[208] Batch [5]#011Speed: 2072.40 samples/sec#011loss=2.255047\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] Epoch[208] Batch[10] avg_epoch_loss=2.269705\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.287293243408203\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] Epoch[208] Batch [10]#011Speed: 1999.81 samples/sec#011loss=2.287293\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747861366.2768383, \"EndTime\": 1747861367.2291558, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.0740509033203, \"count\": 1, \"min\": 952.0740509033203, \"max\": 952.0740509033203}}}\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1411.5280033513227 records/second\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] #progress_metric: host=algo-1, completed 52.25 % of epochs\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.269704645330256\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] Epoch[209] Batch[0] avg_epoch_loss=2.141335\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.1413347721099854\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] Epoch[209] Batch[5] avg_epoch_loss=2.163109\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.1631094217300415\n",
      "[05/21/2025 21:02:47 INFO 140363140085568] Epoch[209] Batch [5]#011Speed: 2122.28 samples/sec#011loss=2.163109\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] Epoch[209] Batch[10] avg_epoch_loss=2.191559\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=2.2256982803344725\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] Epoch[209] Batch [10]#011Speed: 2081.39 samples/sec#011loss=2.225698\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747861367.2292137, \"EndTime\": 1747861368.1635501, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.0991973876953, \"count\": 1, \"min\": 934.0991973876953, \"max\": 934.0991973876953}}}\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1405.49310667629 records/second\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] #progress_metric: host=algo-1, completed 52.5 % of epochs\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.191558902913874\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] Epoch[210] Batch[0] avg_epoch_loss=2.117148\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.1171481609344482\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] Epoch[210] Batch[5] avg_epoch_loss=2.160448\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.160447597503662\n",
      "[05/21/2025 21:02:48 INFO 140363140085568] Epoch[210] Batch [5]#011Speed: 2173.18 samples/sec#011loss=2.160448\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] Epoch[210] Batch[10] avg_epoch_loss=2.211140\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=2.2719698905944825\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] Epoch[210] Batch [10]#011Speed: 2108.37 samples/sec#011loss=2.271970\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747861368.1636121, \"EndTime\": 1747861369.0820746, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.6774024963379, \"count\": 1, \"min\": 917.6774024963379, \"max\": 917.6774024963379}}}\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1396.8726229632125 records/second\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] #progress_metric: host=algo-1, completed 52.75 % of epochs\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.2111395489085806\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] Epoch[211] Batch[0] avg_epoch_loss=2.148082\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.1480820178985596\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] Epoch[211] Batch[5] avg_epoch_loss=2.143543\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.143543322881063\n",
      "[05/21/2025 21:02:49 INFO 140363140085568] Epoch[211] Batch [5]#011Speed: 2045.76 samples/sec#011loss=2.143543\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] Epoch[211] Batch[10] avg_epoch_loss=2.113780\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=2.078063797950745\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] Epoch[211] Batch [10]#011Speed: 2023.83 samples/sec#011loss=2.078064\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747861369.0821316, \"EndTime\": 1747861370.0264459, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.072961807251, \"count\": 1, \"min\": 944.072961807251, \"max\": 944.072961807251}}}\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1441.493354827778 records/second\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] #progress_metric: host=algo-1, completed 53.0 % of epochs\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.113779902458191\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] Epoch[212] Batch[0] avg_epoch_loss=2.191895\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.1918952465057373\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] Epoch[212] Batch[5] avg_epoch_loss=2.135377\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.1353766918182373\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] Epoch[212] Batch [5]#011Speed: 2119.10 samples/sec#011loss=2.135377\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] Epoch[212] Batch[10] avg_epoch_loss=2.229606\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.342682123184204\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] Epoch[212] Batch [10]#011Speed: 2049.80 samples/sec#011loss=2.342682\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747861370.0265057, \"EndTime\": 1747861370.958587, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.8540096282959, \"count\": 1, \"min\": 931.8540096282959, \"max\": 931.8540096282959}}}\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1446.4245757432727 records/second\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] #progress_metric: host=algo-1, completed 53.25 % of epochs\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.229606433348222\n",
      "[05/21/2025 21:02:50 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] Epoch[213] Batch[0] avg_epoch_loss=2.125769\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.1257693767547607\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] Epoch[213] Batch[5] avg_epoch_loss=2.138703\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.1387028296788535\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] Epoch[213] Batch [5]#011Speed: 1984.91 samples/sec#011loss=2.138703\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] Epoch[213] Batch[10] avg_epoch_loss=2.189035\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=2.2494341373443603\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] Epoch[213] Batch [10]#011Speed: 2077.13 samples/sec#011loss=2.249434\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747861370.9586577, \"EndTime\": 1747861371.9363909, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 977.4832725524902, \"count\": 1, \"min\": 977.4832725524902, \"max\": 977.4832725524902}}}\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1313.4781506727036 records/second\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] #progress_metric: host=algo-1, completed 53.5 % of epochs\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.189035242254084\n",
      "[05/21/2025 21:02:51 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] Epoch[214] Batch[0] avg_epoch_loss=2.257273\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.2572734355926514\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] Epoch[214] Batch[5] avg_epoch_loss=2.286691\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.2866913080215454\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] Epoch[214] Batch [5]#011Speed: 2085.08 samples/sec#011loss=2.286691\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] Epoch[214] Batch[10] avg_epoch_loss=2.341751\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=2.4078232288360595\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] Epoch[214] Batch [10]#011Speed: 2028.72 samples/sec#011loss=2.407823\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747861371.9364383, \"EndTime\": 1747861372.8800845, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.4266090393066, \"count\": 1, \"min\": 943.4266090393066, \"max\": 943.4266090393066}}}\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1428.7054476023748 records/second\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] #progress_metric: host=algo-1, completed 53.75 % of epochs\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.3417512720281426\n",
      "[05/21/2025 21:02:52 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] Epoch[215] Batch[0] avg_epoch_loss=2.171973\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.1719725131988525\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] Epoch[215] Batch[5] avg_epoch_loss=2.214495\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.214494506518046\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] Epoch[215] Batch [5]#011Speed: 2160.56 samples/sec#011loss=2.214495\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] Epoch[215] Batch[10] avg_epoch_loss=2.208941\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=2.2022767543792723\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] Epoch[215] Batch [10]#011Speed: 2054.84 samples/sec#011loss=2.202277\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747861372.880143, \"EndTime\": 1747861373.810422, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.0146102905273, \"count\": 1, \"min\": 930.0146102905273, \"max\": 930.0146102905273}}}\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1445.0026353895832 records/second\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] #progress_metric: host=algo-1, completed 54.0 % of epochs\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.2089409828186035\n",
      "[05/21/2025 21:02:53 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] Epoch[216] Batch[0] avg_epoch_loss=2.202444\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.202443838119507\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] Epoch[216] Batch[5] avg_epoch_loss=2.186705\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.1867045164108276\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] Epoch[216] Batch [5]#011Speed: 2136.95 samples/sec#011loss=2.186705\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747861373.8104825, \"EndTime\": 1747861374.6776867, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 866.9557571411133, \"count\": 1, \"min\": 866.9557571411133, \"max\": 866.9557571411133}}}\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1461.2808749564504 records/second\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] #progress_metric: host=algo-1, completed 54.25 % of epochs\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.1467941284179686\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] Epoch[217] Batch[0] avg_epoch_loss=2.168288\n",
      "[05/21/2025 21:02:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.168287754058838\n",
      "[05/21/2025 21:02:55 INFO 140363140085568] Epoch[217] Batch[5] avg_epoch_loss=2.137495\n",
      "[05/21/2025 21:02:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.137495477994283\n",
      "[05/21/2025 21:02:55 INFO 140363140085568] Epoch[217] Batch [5]#011Speed: 2125.95 samples/sec#011loss=2.137495\n",
      "[05/21/2025 21:02:55 INFO 140363140085568] processed a total of 1233 examples\n",
      "#metrics {\"StartTime\": 1747861374.6777503, \"EndTime\": 1747861375.5309103, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 852.874755859375, \"count\": 1, \"min\": 852.874755859375, \"max\": 852.874755859375}}}\n",
      "[05/21/2025 21:02:55 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1445.5161384454902 records/second\n",
      "[05/21/2025 21:02:55 INFO 140363140085568] #progress_metric: host=algo-1, completed 54.5 % of epochs\n",
      "[05/21/2025 21:02:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.175015115737915\n",
      "[05/21/2025 21:02:55 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:55 INFO 140363140085568] Epoch[218] Batch[0] avg_epoch_loss=2.113048\n",
      "[05/21/2025 21:02:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=2.1130478382110596\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] Epoch[218] Batch[5] avg_epoch_loss=2.103843\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.1038432717323303\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] Epoch[218] Batch [5]#011Speed: 2080.62 samples/sec#011loss=2.103843\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] Epoch[218] Batch[10] avg_epoch_loss=2.058798\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=2.0047438621520994\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] Epoch[218] Batch [10]#011Speed: 1997.71 samples/sec#011loss=2.004744\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747861375.5309875, \"EndTime\": 1747861376.493219, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.8794918060303, \"count\": 1, \"min\": 961.8794918060303, \"max\": 961.8794918060303}}}\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1384.6618662456613 records/second\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] #progress_metric: host=algo-1, completed 54.75 % of epochs\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.058798085559498\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_550e0eb6-d2a8-4d42-a1e9-15f237606ddd-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861376.4932783, \"EndTime\": 1747861376.504569, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.014461517333984, \"count\": 1, \"min\": 11.014461517333984, \"max\": 11.014461517333984}}}\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] Epoch[219] Batch[0] avg_epoch_loss=2.163871\n",
      "[05/21/2025 21:02:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.1638712882995605\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] Epoch[219] Batch[5] avg_epoch_loss=2.098944\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.098944067955017\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] Epoch[219] Batch [5]#011Speed: 2040.94 samples/sec#011loss=2.098944\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] Epoch[219] Batch[10] avg_epoch_loss=2.119785\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=2.144795036315918\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] Epoch[219] Batch [10]#011Speed: 1935.65 samples/sec#011loss=2.144795\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747861376.504635, \"EndTime\": 1747861377.4773524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 972.661018371582, \"count\": 1, \"min\": 972.661018371582, \"max\": 972.661018371582}}}\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1390.9076098905073 records/second\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] #progress_metric: host=algo-1, completed 55.0 % of epochs\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.119785417209972\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] Epoch[220] Batch[0] avg_epoch_loss=2.093018\n",
      "[05/21/2025 21:02:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.093017578125\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] Epoch[220] Batch[5] avg_epoch_loss=2.112966\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.1129655043284097\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] Epoch[220] Batch [5]#011Speed: 2051.10 samples/sec#011loss=2.112966\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] Epoch[220] Batch[10] avg_epoch_loss=2.137081\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=2.166018581390381\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] Epoch[220] Batch [10]#011Speed: 2037.25 samples/sec#011loss=2.166019\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747861377.4774082, \"EndTime\": 1747861378.4249067, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.2558498382568, \"count\": 1, \"min\": 947.2558498382568, \"max\": 947.2558498382568}}}\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1387.0405470329829 records/second\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] #progress_metric: host=algo-1, completed 55.25 % of epochs\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.1370805393565786\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] Epoch[221] Batch[0] avg_epoch_loss=2.051265\n",
      "[05/21/2025 21:02:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.051264524459839\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] Epoch[221] Batch[5] avg_epoch_loss=2.038403\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.0384033918380737\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] Epoch[221] Batch [5]#011Speed: 2119.30 samples/sec#011loss=2.038403\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] Epoch[221] Batch[10] avg_epoch_loss=2.091724\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=2.1557082176208495\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] Epoch[221] Batch [10]#011Speed: 2048.98 samples/sec#011loss=2.155708\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747861378.424964, \"EndTime\": 1747861379.3802717, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.9415111541748, \"count\": 1, \"min\": 954.9415111541748, \"max\": 954.9415111541748}}}\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1384.2504521075552 records/second\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] #progress_metric: host=algo-1, completed 55.5 % of epochs\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.091723767193881\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] Epoch[222] Batch[0] avg_epoch_loss=2.173458\n",
      "[05/21/2025 21:02:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=2.1734583377838135\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] Epoch[222] Batch[5] avg_epoch_loss=2.104100\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.1041003465652466\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] Epoch[222] Batch [5]#011Speed: 2095.27 samples/sec#011loss=2.104100\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] Epoch[222] Batch[10] avg_epoch_loss=2.091231\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=2.075788164138794\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] Epoch[222] Batch [10]#011Speed: 2007.90 samples/sec#011loss=2.075788\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747861379.3803303, \"EndTime\": 1747861380.323095, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.4746036529541, \"count\": 1, \"min\": 942.4746036529541, \"max\": 942.4746036529541}}}\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1424.8307911864597 records/second\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] #progress_metric: host=algo-1, completed 55.75 % of epochs\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.091231172735041\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] Epoch[223] Batch[0] avg_epoch_loss=2.054911\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.0549113750457764\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] Epoch[223] Batch[5] avg_epoch_loss=2.111065\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.1110651095708213\n",
      "[05/21/2025 21:03:00 INFO 140363140085568] Epoch[223] Batch [5]#011Speed: 2049.06 samples/sec#011loss=2.111065\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] Epoch[223] Batch[10] avg_epoch_loss=2.132802\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=2.1588852405548096\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] Epoch[223] Batch [10]#011Speed: 1921.42 samples/sec#011loss=2.158885\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747861380.3231537, \"EndTime\": 1747861381.2921324, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 968.7314033508301, \"count\": 1, \"min\": 968.7314033508301, \"max\": 968.7314033508301}}}\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1352.1163050630737 records/second\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] #progress_metric: host=algo-1, completed 56.0 % of epochs\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.1328015327453613\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] Epoch[224] Batch[0] avg_epoch_loss=2.096929\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.0969290733337402\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] Epoch[224] Batch[5] avg_epoch_loss=2.080124\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.080123702685038\n",
      "[05/21/2025 21:03:01 INFO 140363140085568] Epoch[224] Batch [5]#011Speed: 1993.62 samples/sec#011loss=2.080124\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] Epoch[224] Batch[10] avg_epoch_loss=2.148228\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=2.2299540519714354\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] Epoch[224] Batch [10]#011Speed: 1918.30 samples/sec#011loss=2.229954\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747861381.2922242, \"EndTime\": 1747861382.2712424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 978.6965847015381, \"count\": 1, \"min\": 978.6965847015381, \"max\": 978.6965847015381}}}\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1377.2152711755866 records/second\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] #progress_metric: host=algo-1, completed 56.25 % of epochs\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.148228406906128\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] Epoch[225] Batch[0] avg_epoch_loss=2.055927\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.055927276611328\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] Epoch[225] Batch[5] avg_epoch_loss=2.053826\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.053826173146566\n",
      "[05/21/2025 21:03:02 INFO 140363140085568] Epoch[225] Batch [5]#011Speed: 2112.74 samples/sec#011loss=2.053826\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] Epoch[225] Batch[10] avg_epoch_loss=2.098204\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=2.1514563083648683\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] Epoch[225] Batch [10]#011Speed: 2022.21 samples/sec#011loss=2.151456\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747861382.271303, \"EndTime\": 1747861383.2087083, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.1309280395508, \"count\": 1, \"min\": 937.1309280395508, \"max\": 937.1309280395508}}}\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1461.774970668832 records/second\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] #progress_metric: host=algo-1, completed 56.5 % of epochs\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.098203507336703\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] Epoch[226] Batch[0] avg_epoch_loss=1.992388\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=1.9923875331878662\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] Epoch[226] Batch[5] avg_epoch_loss=2.087067\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.0870666106541953\n",
      "[05/21/2025 21:03:03 INFO 140363140085568] Epoch[226] Batch [5]#011Speed: 2113.98 samples/sec#011loss=2.087067\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] Epoch[226] Batch[10] avg_epoch_loss=2.143055\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=2.2102404594421388\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] Epoch[226] Batch [10]#011Speed: 2059.80 samples/sec#011loss=2.210240\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747861383.2087674, \"EndTime\": 1747861384.139589, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.0398826599121, \"count\": 1, \"min\": 930.0398826599121, \"max\": 930.0398826599121}}}\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1453.5442262574106 records/second\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] #progress_metric: host=algo-1, completed 56.75 % of epochs\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.143054723739624\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] Epoch[227] Batch[0] avg_epoch_loss=2.120954\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.1209540367126465\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] Epoch[227] Batch[5] avg_epoch_loss=2.099660\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.09965988000234\n",
      "[05/21/2025 21:03:04 INFO 140363140085568] Epoch[227] Batch [5]#011Speed: 1990.88 samples/sec#011loss=2.099660\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] Epoch[227] Batch[10] avg_epoch_loss=2.052262\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=1.995385193824768\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] Epoch[227] Batch [10]#011Speed: 2052.74 samples/sec#011loss=1.995385\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747861384.1396565, \"EndTime\": 1747861385.0971935, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.2110176086426, \"count\": 1, \"min\": 957.2110176086426, \"max\": 957.2110176086426}}}\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1385.1247548108868 records/second\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] #progress_metric: host=algo-1, completed 57.0 % of epochs\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.052262295376171\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_1c103128-ab60-4230-9c8b-fcaa7df4c7d6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861385.0972662, \"EndTime\": 1747861385.1082404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.694742202758789, \"count\": 1, \"min\": 10.694742202758789, \"max\": 10.694742202758789}}}\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] Epoch[228] Batch[0] avg_epoch_loss=2.134739\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.1347391605377197\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] Epoch[228] Batch[5] avg_epoch_loss=2.039810\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.039810081322988\n",
      "[05/21/2025 21:03:05 INFO 140363140085568] Epoch[228] Batch [5]#011Speed: 2157.39 samples/sec#011loss=2.039810\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] Epoch[228] Batch[10] avg_epoch_loss=2.084395\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=2.1378961563110352\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] Epoch[228] Batch [10]#011Speed: 1928.09 samples/sec#011loss=2.137896\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] processed a total of 1386 examples\n",
      "#metrics {\"StartTime\": 1747861385.1082907, \"EndTime\": 1747861386.0551374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.7992782592773, \"count\": 1, \"min\": 946.7992782592773, \"max\": 946.7992782592773}}}\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1463.7434320701855 records/second\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] #progress_metric: host=algo-1, completed 57.25 % of epochs\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.0843946608630093\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] Epoch[229] Batch[0] avg_epoch_loss=2.079287\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.079287052154541\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] Epoch[229] Batch[5] avg_epoch_loss=2.078816\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.078815778096517\n",
      "[05/21/2025 21:03:06 INFO 140363140085568] Epoch[229] Batch [5]#011Speed: 2067.83 samples/sec#011loss=2.078816\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] Epoch[229] Batch[10] avg_epoch_loss=2.088463\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=229, batch=10 train loss <loss>=2.1000386238098145\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] Epoch[229] Batch [10]#011Speed: 1959.38 samples/sec#011loss=2.100039\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747861386.0551975, \"EndTime\": 1747861387.0143292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.885669708252, \"count\": 1, \"min\": 958.885669708252, \"max\": 958.885669708252}}}\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1383.7628253433215 records/second\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] #progress_metric: host=algo-1, completed 57.5 % of epochs\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.0884625261480156\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] Epoch[230] Batch[0] avg_epoch_loss=2.139285\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.1392853260040283\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] Epoch[230] Batch[5] avg_epoch_loss=2.097299\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.097299416859945\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] Epoch[230] Batch [5]#011Speed: 2066.54 samples/sec#011loss=2.097299\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] Epoch[230] Batch[10] avg_epoch_loss=2.116107\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=2.1386757373809813\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] Epoch[230] Batch [10]#011Speed: 1973.12 samples/sec#011loss=2.138676\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747861387.014391, \"EndTime\": 1747861387.9735656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.8449001312256, \"count\": 1, \"min\": 958.8449001312256, \"max\": 958.8449001312256}}}\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1407.8166587146707 records/second\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] #progress_metric: host=algo-1, completed 57.75 % of epochs\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.1161068352785977\n",
      "[05/21/2025 21:03:07 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] Epoch[231] Batch[0] avg_epoch_loss=2.174176\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.1741764545440674\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] Epoch[231] Batch[5] avg_epoch_loss=2.128383\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.12838343779246\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] Epoch[231] Batch [5]#011Speed: 2218.61 samples/sec#011loss=2.128383\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] Epoch[231] Batch[10] avg_epoch_loss=2.130358\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=2.1327284812927245\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] Epoch[231] Batch [10]#011Speed: 2106.97 samples/sec#011loss=2.132728\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747861387.9736226, \"EndTime\": 1747861388.8900628, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.1972999572754, \"count\": 1, \"min\": 916.1972999572754, \"max\": 916.1972999572754}}}\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1451.5175426933047 records/second\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] #progress_metric: host=algo-1, completed 58.0 % of epochs\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.1303584575653076\n",
      "[05/21/2025 21:03:08 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] Epoch[232] Batch[0] avg_epoch_loss=2.183182\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.1831815242767334\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] Epoch[232] Batch[5] avg_epoch_loss=2.197033\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.197032928466797\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] Epoch[232] Batch [5]#011Speed: 2014.62 samples/sec#011loss=2.197033\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] Epoch[232] Batch[10] avg_epoch_loss=2.230877\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=2.2714890956878664\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] Epoch[232] Batch [10]#011Speed: 2051.43 samples/sec#011loss=2.271489\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747861388.8901207, \"EndTime\": 1747861389.8443322, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.965425491333, \"count\": 1, \"min\": 953.965425491333, \"max\": 953.965425491333}}}\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1375.1582710009925 records/second\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] #progress_metric: host=algo-1, completed 58.25 % of epochs\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.2308766408400102\n",
      "[05/21/2025 21:03:09 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] Epoch[233] Batch[0] avg_epoch_loss=2.195971\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.1959707736968994\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] Epoch[233] Batch[5] avg_epoch_loss=2.152871\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.152870853741964\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] Epoch[233] Batch [5]#011Speed: 2148.90 samples/sec#011loss=2.152871\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] Epoch[233] Batch[10] avg_epoch_loss=2.163574\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=2.1764166831970213\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] Epoch[233] Batch [10]#011Speed: 2102.43 samples/sec#011loss=2.176417\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747861389.84441, \"EndTime\": 1747861390.7652018, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.5348491668701, \"count\": 1, \"min\": 920.5348491668701, \"max\": 920.5348491668701}}}\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1463.1395330106675 records/second\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] #progress_metric: host=algo-1, completed 58.5 % of epochs\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.1635735034942627\n",
      "[05/21/2025 21:03:10 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] Epoch[234] Batch[0] avg_epoch_loss=2.171105\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.17110538482666\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] Epoch[234] Batch[5] avg_epoch_loss=2.126296\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.1262961626052856\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] Epoch[234] Batch [5]#011Speed: 1990.01 samples/sec#011loss=2.126296\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] Epoch[234] Batch[10] avg_epoch_loss=2.158566\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=2.1972900867462157\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] Epoch[234] Batch [10]#011Speed: 1934.48 samples/sec#011loss=2.197290\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747861390.765262, \"EndTime\": 1747861391.734734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 969.224214553833, \"count\": 1, \"min\": 969.224214553833, \"max\": 969.224214553833}}}\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1381.3905313713076 records/second\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] #progress_metric: host=algo-1, completed 58.75 % of epochs\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.15856612812389\n",
      "[05/21/2025 21:03:11 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] Epoch[235] Batch[0] avg_epoch_loss=2.047940\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.047940254211426\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] Epoch[235] Batch[5] avg_epoch_loss=2.092031\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.092030962308248\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] Epoch[235] Batch [5]#011Speed: 1988.53 samples/sec#011loss=2.092031\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] Epoch[235] Batch[10] avg_epoch_loss=2.083641\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=2.073573613166809\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] Epoch[235] Batch [10]#011Speed: 2061.52 samples/sec#011loss=2.073574\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747861391.7347949, \"EndTime\": 1747861392.6917856, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.7365646362305, \"count\": 1, \"min\": 956.7365646362305, \"max\": 956.7365646362305}}}\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1385.820552509536 records/second\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] #progress_metric: host=algo-1, completed 59.0 % of epochs\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.0836412581530483\n",
      "[05/21/2025 21:03:12 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] Epoch[236] Batch[0] avg_epoch_loss=2.037672\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.0376720428466797\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] Epoch[236] Batch[5] avg_epoch_loss=2.144466\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.144465764363607\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] Epoch[236] Batch [5]#011Speed: 2093.17 samples/sec#011loss=2.144466\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] Epoch[236] Batch[10] avg_epoch_loss=2.149345\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=2.1552005767822267\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] Epoch[236] Batch [10]#011Speed: 1989.09 samples/sec#011loss=2.155201\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747861392.691851, \"EndTime\": 1747861393.6412437, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 949.0382671356201, \"count\": 1, \"min\": 949.0382671356201, \"max\": 949.0382671356201}}}\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1388.6184111437271 records/second\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] #progress_metric: host=algo-1, completed 59.25 % of epochs\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.1493452245538887\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] Epoch[237] Batch[0] avg_epoch_loss=2.075887\n",
      "[05/21/2025 21:03:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.075887441635132\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] Epoch[237] Batch[5] avg_epoch_loss=2.215528\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.2155277331670127\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] Epoch[237] Batch [5]#011Speed: 2176.54 samples/sec#011loss=2.215528\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] Epoch[237] Batch[10] avg_epoch_loss=2.234619\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=2.2575294971466064\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] Epoch[237] Batch [10]#011Speed: 2155.73 samples/sec#011loss=2.257529\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747861393.641316, \"EndTime\": 1747861394.5716727, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.0813674926758, \"count\": 1, \"min\": 930.0813674926758, \"max\": 930.0813674926758}}}\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1411.5756272107449 records/second\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] #progress_metric: host=algo-1, completed 59.5 % of epochs\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.234619444066828\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] Epoch[238] Batch[0] avg_epoch_loss=2.380219\n",
      "[05/21/2025 21:03:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.3802192211151123\n",
      "[05/21/2025 21:03:15 INFO 140363140085568] Epoch[238] Batch[5] avg_epoch_loss=2.386333\n",
      "[05/21/2025 21:03:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.386332869529724\n",
      "[05/21/2025 21:03:15 INFO 140363140085568] Epoch[238] Batch [5]#011Speed: 2049.45 samples/sec#011loss=2.386333\n",
      "[05/21/2025 21:03:15 INFO 140363140085568] processed a total of 1260 examples\n",
      "#metrics {\"StartTime\": 1747861394.5717306, \"EndTime\": 1747861395.4512212, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 879.2412281036377, \"count\": 1, \"min\": 879.2412281036377, \"max\": 879.2412281036377}}}\n",
      "[05/21/2025 21:03:15 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1432.9108314604548 records/second\n",
      "[05/21/2025 21:03:15 INFO 140363140085568] #progress_metric: host=algo-1, completed 59.75 % of epochs\n",
      "[05/21/2025 21:03:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.3239285707473756\n",
      "[05/21/2025 21:03:15 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:15 INFO 140363140085568] Epoch[239] Batch[0] avg_epoch_loss=2.254257\n",
      "[05/21/2025 21:03:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.2542572021484375\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] Epoch[239] Batch[5] avg_epoch_loss=2.238817\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.2388166983922324\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] Epoch[239] Batch [5]#011Speed: 2049.74 samples/sec#011loss=2.238817\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] Epoch[239] Batch[10] avg_epoch_loss=2.176681\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=2.1021172046661376\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] Epoch[239] Batch [10]#011Speed: 1986.58 samples/sec#011loss=2.102117\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747861395.4512806, \"EndTime\": 1747861396.4132156, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.5709781646729, \"count\": 1, \"min\": 961.5709781646729, \"max\": 961.5709781646729}}}\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1353.9053027081904 records/second\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] #progress_metric: host=algo-1, completed 60.0 % of epochs\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.176680564880371\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] Epoch[240] Batch[0] avg_epoch_loss=2.236404\n",
      "[05/21/2025 21:03:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.2364041805267334\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] Epoch[240] Batch[5] avg_epoch_loss=2.146943\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.146942973136902\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] Epoch[240] Batch [5]#011Speed: 1962.01 samples/sec#011loss=2.146943\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] Epoch[240] Batch[10] avg_epoch_loss=2.103728\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=2.051870250701904\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] Epoch[240] Batch [10]#011Speed: 1912.51 samples/sec#011loss=2.051870\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747861396.4132771, \"EndTime\": 1747861397.403222, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 989.6900653839111, \"count\": 1, \"min\": 989.6900653839111, \"max\": 989.6900653839111}}}\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1352.8282310364787 records/second\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] #progress_metric: host=algo-1, completed 60.25 % of epochs\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.103728099302812\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] Epoch[241] Batch[0] avg_epoch_loss=2.097302\n",
      "[05/21/2025 21:03:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.097302198410034\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] Epoch[241] Batch[5] avg_epoch_loss=2.071009\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.0710086822509766\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] Epoch[241] Batch [5]#011Speed: 2020.74 samples/sec#011loss=2.071009\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] Epoch[241] Batch[10] avg_epoch_loss=2.061063\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.0491286277770997\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] Epoch[241] Batch [10]#011Speed: 1942.77 samples/sec#011loss=2.049129\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747861397.4032822, \"EndTime\": 1747861398.3773074, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.7701416015625, \"count\": 1, \"min\": 973.7701416015625, \"max\": 973.7701416015625}}}\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1351.3232327930853 records/second\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] #progress_metric: host=algo-1, completed 60.5 % of epochs\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.061063202944669\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] Epoch[242] Batch[0] avg_epoch_loss=2.215539\n",
      "[05/21/2025 21:03:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.21553897857666\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] Epoch[242] Batch[5] avg_epoch_loss=2.134093\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.1340927282969155\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] Epoch[242] Batch [5]#011Speed: 2050.01 samples/sec#011loss=2.134093\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] Epoch[242] Batch[10] avg_epoch_loss=2.047103\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=1.9427154064178467\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] Epoch[242] Batch [10]#011Speed: 1946.61 samples/sec#011loss=1.942715\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747861398.3773682, \"EndTime\": 1747861399.3443644, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 966.7234420776367, \"count\": 1, \"min\": 966.7234420776367, \"max\": 966.7234420776367}}}\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1377.6900756879495 records/second\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] #progress_metric: host=algo-1, completed 60.75 % of epochs\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.0471030365337026\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_ef83dbd0-7837-4aa6-abbc-7b24ecde58b6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861399.3444252, \"EndTime\": 1747861399.3561747, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.408805847167969, \"count\": 1, \"min\": 11.408805847167969, \"max\": 11.408805847167969}}}\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] Epoch[243] Batch[0] avg_epoch_loss=2.037592\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=2.0375916957855225\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] Epoch[243] Batch[5] avg_epoch_loss=2.059569\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.05956894159317\n",
      "[05/21/2025 21:03:19 INFO 140363140085568] Epoch[243] Batch [5]#011Speed: 2007.71 samples/sec#011loss=2.059569\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] Epoch[243] Batch[10] avg_epoch_loss=2.079918\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=2.104335880279541\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] Epoch[243] Batch [10]#011Speed: 1965.72 samples/sec#011loss=2.104336\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747861399.3562367, \"EndTime\": 1747861400.3214898, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 965.1992321014404, \"count\": 1, \"min\": 965.1992321014404, \"max\": 965.1992321014404}}}\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1419.2586467216518 records/second\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] #progress_metric: host=algo-1, completed 61.0 % of epochs\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.079917550086975\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] Epoch[244] Batch[0] avg_epoch_loss=2.106931\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.106930732727051\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] Epoch[244] Batch[5] avg_epoch_loss=2.108393\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.108393351236979\n",
      "[05/21/2025 21:03:20 INFO 140363140085568] Epoch[244] Batch [5]#011Speed: 1903.89 samples/sec#011loss=2.108393\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] Epoch[244] Batch[10] avg_epoch_loss=2.171807\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=2.247904348373413\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] Epoch[244] Batch [10]#011Speed: 1982.49 samples/sec#011loss=2.247904\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747861400.321554, \"EndTime\": 1747861401.3103747, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 988.5263442993164, \"count\": 1, \"min\": 988.5263442993164, \"max\": 988.5263442993164}}}\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1348.3493008778125 records/second\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] #progress_metric: host=algo-1, completed 61.25 % of epochs\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.171807440844449\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] Epoch[245] Batch[0] avg_epoch_loss=2.228043\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.2280430793762207\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] Epoch[245] Batch[5] avg_epoch_loss=2.267629\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.2676294644673667\n",
      "[05/21/2025 21:03:21 INFO 140363140085568] Epoch[245] Batch [5]#011Speed: 1975.28 samples/sec#011loss=2.267629\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] Epoch[245] Batch[10] avg_epoch_loss=2.237026\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=2.2003007888793946\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] Epoch[245] Batch [10]#011Speed: 2002.95 samples/sec#011loss=2.200301\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747861401.3104367, \"EndTime\": 1747861402.2872086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 976.524829864502, \"count\": 1, \"min\": 976.524829864502, \"max\": 976.524829864502}}}\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1330.1061824147414 records/second\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] #progress_metric: host=algo-1, completed 61.5 % of epochs\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.2370255210182886\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] Epoch[246] Batch[0] avg_epoch_loss=2.231267\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.231267213821411\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] Epoch[246] Batch[5] avg_epoch_loss=2.125752\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.125752329826355\n",
      "[05/21/2025 21:03:22 INFO 140363140085568] Epoch[246] Batch [5]#011Speed: 2086.40 samples/sec#011loss=2.125752\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] Epoch[246] Batch[10] avg_epoch_loss=2.163695\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=2.209226942062378\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] Epoch[246] Batch [10]#011Speed: 2011.42 samples/sec#011loss=2.209227\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747861402.2872684, \"EndTime\": 1747861403.2416108, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.0805816650391, \"count\": 1, \"min\": 954.0805816650391, \"max\": 954.0805816650391}}}\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1375.0197955008794 records/second\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] #progress_metric: host=algo-1, completed 61.75 % of epochs\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=246, train loss <loss>=2.1636953353881836\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] Epoch[247] Batch[0] avg_epoch_loss=2.147835\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.147834539413452\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] Epoch[247] Batch[5] avg_epoch_loss=2.147339\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.1473388274510703\n",
      "[05/21/2025 21:03:23 INFO 140363140085568] Epoch[247] Batch [5]#011Speed: 1867.15 samples/sec#011loss=2.147339\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] Epoch[247] Batch[10] avg_epoch_loss=2.350616\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=2.594548153877258\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] Epoch[247] Batch [10]#011Speed: 1935.68 samples/sec#011loss=2.594548\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747861403.2416694, \"EndTime\": 1747861404.2421865, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1000.2331733703613, \"count\": 1, \"min\": 1000.2331733703613, \"max\": 1000.2331733703613}}}\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1292.5888916059964 records/second\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] #progress_metric: host=algo-1, completed 62.0 % of epochs\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=247, train loss <loss>=2.3506157940084282\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] Epoch[248] Batch[0] avg_epoch_loss=2.043922\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.043921947479248\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] Epoch[248] Batch[5] avg_epoch_loss=2.087001\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.0870014429092407\n",
      "[05/21/2025 21:03:24 INFO 140363140085568] Epoch[248] Batch [5]#011Speed: 2071.56 samples/sec#011loss=2.087001\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] Epoch[248] Batch[10] avg_epoch_loss=2.165579\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=2.259871578216553\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] Epoch[248] Batch [10]#011Speed: 1983.06 samples/sec#011loss=2.259872\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747861404.242244, \"EndTime\": 1747861405.1968915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.3898105621338, \"count\": 1, \"min\": 954.3898105621338, \"max\": 954.3898105621338}}}\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1394.4759751819774 records/second\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] #progress_metric: host=algo-1, completed 62.25 % of epochs\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.165578777139837\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] Epoch[249] Batch[0] avg_epoch_loss=2.141587\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.1415867805480957\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] Epoch[249] Batch[5] avg_epoch_loss=2.112326\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.1123263835906982\n",
      "[05/21/2025 21:03:25 INFO 140363140085568] Epoch[249] Batch [5]#011Speed: 2049.25 samples/sec#011loss=2.112326\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] Epoch[249] Batch[10] avg_epoch_loss=2.065637\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=2.0096094608306885\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] Epoch[249] Batch [10]#011Speed: 1949.78 samples/sec#011loss=2.009609\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747861405.1969538, \"EndTime\": 1747861406.1688366, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 971.5216159820557, \"count\": 1, \"min\": 971.5216159820557, \"max\": 971.5216159820557}}}\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1325.6154847499083 records/second\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] #progress_metric: host=algo-1, completed 62.5 % of epochs\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.0656368732452393\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] Epoch[250] Batch[0] avg_epoch_loss=2.081850\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.081850051879883\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] Epoch[250] Batch[5] avg_epoch_loss=2.036249\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.0362486044565835\n",
      "[05/21/2025 21:03:26 INFO 140363140085568] Epoch[250] Batch [5]#011Speed: 2003.19 samples/sec#011loss=2.036249\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] Epoch[250] Batch[10] avg_epoch_loss=2.039055\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=2.0424234867095947\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] Epoch[250] Batch [10]#011Speed: 1966.97 samples/sec#011loss=2.042423\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747861406.1689095, \"EndTime\": 1747861407.1440413, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 974.8537540435791, \"count\": 1, \"min\": 974.8537540435791, \"max\": 974.8537540435791}}}\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1350.844676903995 records/second\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] #progress_metric: host=algo-1, completed 62.75 % of epochs\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.0390553691170434\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_dac8d942-b391-4c13-8aed-34b2e3b4d8c6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861407.1441028, \"EndTime\": 1747861407.154852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.462045669555664, \"count\": 1, \"min\": 10.462045669555664, \"max\": 10.462045669555664}}}\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] Epoch[251] Batch[0] avg_epoch_loss=2.046491\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.0464911460876465\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] Epoch[251] Batch[5] avg_epoch_loss=2.066344\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.0663437445958457\n",
      "[05/21/2025 21:03:27 INFO 140363140085568] Epoch[251] Batch [5]#011Speed: 1952.41 samples/sec#011loss=2.066344\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] Epoch[251] Batch[10] avg_epoch_loss=2.069926\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=2.074224519729614\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] Epoch[251] Batch [10]#011Speed: 1985.57 samples/sec#011loss=2.074225\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747861407.1549113, \"EndTime\": 1747861408.1433768, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 988.4123802185059, \"count\": 1, \"min\": 988.4123802185059, \"max\": 988.4123802185059}}}\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1342.4369054765798 records/second\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] #progress_metric: host=algo-1, completed 63.0 % of epochs\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.069925915111195\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] Epoch[252] Batch[0] avg_epoch_loss=1.974670\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=1.9746696949005127\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] Epoch[252] Batch[5] avg_epoch_loss=2.041867\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.0418673356374106\n",
      "[05/21/2025 21:03:28 INFO 140363140085568] Epoch[252] Batch [5]#011Speed: 2088.75 samples/sec#011loss=2.041867\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] Epoch[252] Batch[10] avg_epoch_loss=2.121001\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=2.215961790084839\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] Epoch[252] Batch [10]#011Speed: 1900.99 samples/sec#011loss=2.215962\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747861408.1434362, \"EndTime\": 1747861409.1169455, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.2332229614258, \"count\": 1, \"min\": 973.2332229614258, \"max\": 973.2332229614258}}}\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1356.1437524586543 records/second\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] #progress_metric: host=algo-1, completed 63.25 % of epochs\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.1210011785680596\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] Epoch[253] Batch[0] avg_epoch_loss=2.106281\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=2.106281280517578\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] Epoch[253] Batch[5] avg_epoch_loss=2.048036\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.0480360984802246\n",
      "[05/21/2025 21:03:29 INFO 140363140085568] Epoch[253] Batch [5]#011Speed: 2100.92 samples/sec#011loss=2.048036\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] Epoch[253] Batch[10] avg_epoch_loss=2.167558\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=2.310984754562378\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] Epoch[253] Batch [10]#011Speed: 2087.61 samples/sec#011loss=2.310985\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747861409.1170306, \"EndTime\": 1747861410.0542743, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.9847774505615, \"count\": 1, \"min\": 936.9847774505615, \"max\": 936.9847774505615}}}\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1401.1733142273845 records/second\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] #progress_metric: host=algo-1, completed 63.5 % of epochs\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.1675582148812036\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] Epoch[254] Batch[0] avg_epoch_loss=2.236503\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.2365026473999023\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] Epoch[254] Batch[5] avg_epoch_loss=2.302963\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.302963217099508\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] Epoch[254] Batch [5]#011Speed: 2071.74 samples/sec#011loss=2.302963\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747861410.054333, \"EndTime\": 1747861410.939248, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 884.66477394104, \"count\": 1, \"min\": 884.66477394104, \"max\": 884.66477394104}}}\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1445.5930393991393 records/second\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] #progress_metric: host=algo-1, completed 63.75 % of epochs\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.2523617506027223\n",
      "[05/21/2025 21:03:30 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] Epoch[255] Batch[0] avg_epoch_loss=2.192600\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=2.1926004886627197\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] Epoch[255] Batch[5] avg_epoch_loss=2.200563\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.200563152631124\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] Epoch[255] Batch [5]#011Speed: 2001.50 samples/sec#011loss=2.200563\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] Epoch[255] Batch[10] avg_epoch_loss=2.215891\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=2.2342843532562258\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] Epoch[255] Batch [10]#011Speed: 1936.66 samples/sec#011loss=2.234284\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747861410.9393125, \"EndTime\": 1747861411.9186323, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 978.987455368042, \"count\": 1, \"min\": 978.987455368042, \"max\": 978.987455368042}}}\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1336.9733588827792 records/second\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] #progress_metric: host=algo-1, completed 64.0 % of epochs\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.215890971097079\n",
      "[05/21/2025 21:03:31 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] Epoch[256] Batch[0] avg_epoch_loss=2.209796\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.209796190261841\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] Epoch[256] Batch[5] avg_epoch_loss=2.161789\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.1617887814839682\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] Epoch[256] Batch [5]#011Speed: 2082.59 samples/sec#011loss=2.161789\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] Epoch[256] Batch[10] avg_epoch_loss=2.234225\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=2.3211483478546144\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] Epoch[256] Batch [10]#011Speed: 1983.51 samples/sec#011loss=2.321148\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747861411.918693, \"EndTime\": 1747861412.877404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.9224586486816, \"count\": 1, \"min\": 957.9224586486816, \"max\": 957.9224586486816}}}\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1351.7577876423557 records/second\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] #progress_metric: host=algo-1, completed 64.25 % of epochs\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.23422494801608\n",
      "[05/21/2025 21:03:32 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] Epoch[257] Batch[0] avg_epoch_loss=2.268420\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.2684199810028076\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] Epoch[257] Batch[5] avg_epoch_loss=2.285837\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.285836855570475\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] Epoch[257] Batch [5]#011Speed: 2103.10 samples/sec#011loss=2.285837\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] Epoch[257] Batch[10] avg_epoch_loss=2.276568\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=2.2654457569122313\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] Epoch[257] Batch [10]#011Speed: 1985.95 samples/sec#011loss=2.265446\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747861412.8774636, \"EndTime\": 1747861413.8457656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 968.0545330047607, \"count\": 1, \"min\": 968.0545330047607, \"max\": 968.0545330047607}}}\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1364.4692157622783 records/second\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] #progress_metric: host=algo-1, completed 64.5 % of epochs\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.2765681743621826\n",
      "[05/21/2025 21:03:33 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] Epoch[258] Batch[0] avg_epoch_loss=2.114846\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.1148464679718018\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] Epoch[258] Batch[5] avg_epoch_loss=2.122944\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.1229442755381265\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] Epoch[258] Batch [5]#011Speed: 2092.90 samples/sec#011loss=2.122944\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] Epoch[258] Batch[10] avg_epoch_loss=2.147140\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=2.1761739253997803\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] Epoch[258] Batch [10]#011Speed: 1884.84 samples/sec#011loss=2.176174\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747861413.8458233, \"EndTime\": 1747861414.816271, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 970.0965881347656, \"count\": 1, \"min\": 970.0965881347656, \"max\": 970.0965881347656}}}\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1363.6593992251635 records/second\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] #progress_metric: host=algo-1, completed 64.75 % of epochs\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.1471395709297876\n",
      "[05/21/2025 21:03:34 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] Epoch[259] Batch[0] avg_epoch_loss=2.084133\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.084132671356201\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] Epoch[259] Batch[5] avg_epoch_loss=2.106334\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.10633393128713\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] Epoch[259] Batch [5]#011Speed: 2160.27 samples/sec#011loss=2.106334\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] Epoch[259] Batch[10] avg_epoch_loss=2.150581\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=2.2036773920059205\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] Epoch[259] Batch [10]#011Speed: 1988.80 samples/sec#011loss=2.203677\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747861414.816329, \"EndTime\": 1747861415.7506504, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.0426921844482, \"count\": 1, \"min\": 934.0426921844482, \"max\": 934.0426921844482}}}\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1451.6240835587666 records/second\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] #progress_metric: host=algo-1, completed 65.0 % of epochs\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.15058095888658\n",
      "[05/21/2025 21:03:35 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] Epoch[260] Batch[0] avg_epoch_loss=2.009081\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=2.0090813636779785\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] Epoch[260] Batch[5] avg_epoch_loss=2.024518\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.0245181719462075\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] Epoch[260] Batch [5]#011Speed: 2107.85 samples/sec#011loss=2.024518\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] Epoch[260] Batch[10] avg_epoch_loss=2.027073\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=260, batch=10 train loss <loss>=2.030138063430786\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] Epoch[260] Batch [10]#011Speed: 1932.64 samples/sec#011loss=2.030138\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747861415.7507067, \"EndTime\": 1747861416.7103264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 959.3725204467773, \"count\": 1, \"min\": 959.3725204467773, \"max\": 959.3725204467773}}}\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1379.942169869857 records/second\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] #progress_metric: host=algo-1, completed 65.25 % of epochs\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.0270726680755615\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:03:36 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_cb987932-f31d-4d13-82fb-45244394a99e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861416.7103865, \"EndTime\": 1747861416.7221253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.46078109741211, \"count\": 1, \"min\": 11.46078109741211, \"max\": 11.46078109741211}}}\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] Epoch[261] Batch[0] avg_epoch_loss=2.048633\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.048632860183716\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] Epoch[261] Batch[5] avg_epoch_loss=2.056256\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.056256333986918\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] Epoch[261] Batch [5]#011Speed: 2045.65 samples/sec#011loss=2.056256\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] Epoch[261] Batch[10] avg_epoch_loss=1.966390\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=1.8585493564605713\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] Epoch[261] Batch [10]#011Speed: 1989.66 samples/sec#011loss=1.858549\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747861416.7221916, \"EndTime\": 1747861417.6885483, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 966.3031101226807, \"count\": 1, \"min\": 966.3031101226807, \"max\": 966.3031101226807}}}\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1348.3147507981073 records/second\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] #progress_metric: host=algo-1, completed 65.5 % of epochs\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=261, train loss <loss>=1.9663895260203967\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:03:37 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_747e4be2-975f-4483-ba54-fbfb3915ed01-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861417.6886082, \"EndTime\": 1747861417.699861, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.97726821899414, \"count\": 1, \"min\": 10.97726821899414, \"max\": 10.97726821899414}}}\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] Epoch[262] Batch[0] avg_epoch_loss=2.023325\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.023324728012085\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] Epoch[262] Batch[5] avg_epoch_loss=2.047793\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.0477929512659707\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] Epoch[262] Batch [5]#011Speed: 2093.48 samples/sec#011loss=2.047793\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] Epoch[262] Batch[10] avg_epoch_loss=2.035685\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=2.0211548089981077\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] Epoch[262] Batch [10]#011Speed: 1971.39 samples/sec#011loss=2.021155\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] processed a total of 1372 examples\n",
      "#metrics {\"StartTime\": 1747861417.6999211, \"EndTime\": 1747861418.6447685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.7920322418213, \"count\": 1, \"min\": 944.7920322418213, \"max\": 944.7920322418213}}}\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1451.9852979358118 records/second\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] #progress_metric: host=algo-1, completed 65.75 % of epochs\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.0356847047805786\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] Epoch[263] Batch[0] avg_epoch_loss=2.023633\n",
      "[05/21/2025 21:03:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.0236332416534424\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] Epoch[263] Batch[5] avg_epoch_loss=2.040503\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.0405026276906333\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] Epoch[263] Batch [5]#011Speed: 2099.93 samples/sec#011loss=2.040503\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] Epoch[263] Batch[10] avg_epoch_loss=1.994969\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=263, batch=10 train loss <loss>=1.9403281450271606\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] Epoch[263] Batch [10]#011Speed: 2019.94 samples/sec#011loss=1.940328\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747861418.6448605, \"EndTime\": 1747861419.5894697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.3235397338867, \"count\": 1, \"min\": 944.3235397338867, \"max\": 944.3235397338867}}}\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1389.2301669168476 records/second\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] #progress_metric: host=algo-1, completed 66.0 % of epochs\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=263, train loss <loss>=1.9949687719345093\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] Epoch[264] Batch[0] avg_epoch_loss=2.009148\n",
      "[05/21/2025 21:03:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.009147882461548\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] Epoch[264] Batch[5] avg_epoch_loss=2.027799\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.0277991890907288\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] Epoch[264] Batch [5]#011Speed: 2097.85 samples/sec#011loss=2.027799\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] Epoch[264] Batch[10] avg_epoch_loss=2.550830\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=3.1784658908843992\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] Epoch[264] Batch [10]#011Speed: 2121.23 samples/sec#011loss=3.178466\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747861419.5895264, \"EndTime\": 1747861420.522313, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.5363636016846, \"count\": 1, \"min\": 932.5363636016846, \"max\": 932.5363636016846}}}\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1386.4152715343932 records/second\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] #progress_metric: host=algo-1, completed 66.25 % of epochs\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.5508295080878516\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] Epoch[265] Batch[0] avg_epoch_loss=2.175354\n",
      "[05/21/2025 21:03:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.175354480743408\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] Epoch[265] Batch[5] avg_epoch_loss=2.264791\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.264790972073873\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] Epoch[265] Batch [5]#011Speed: 2045.64 samples/sec#011loss=2.264791\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] Epoch[265] Batch[10] avg_epoch_loss=2.257250\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=2.248199796676636\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] Epoch[265] Batch [10]#011Speed: 1994.50 samples/sec#011loss=2.248200\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747861420.5223713, \"EndTime\": 1747861421.477277, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.6544551849365, \"count\": 1, \"min\": 954.6544551849365, \"max\": 954.6544551849365}}}\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1387.8085075194513 records/second\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] #progress_metric: host=algo-1, completed 66.5 % of epochs\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.257249528711492\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] Epoch[266] Batch[0] avg_epoch_loss=2.241543\n",
      "[05/21/2025 21:03:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.2415432929992676\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] Epoch[266] Batch[5] avg_epoch_loss=2.246823\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.2468226750691733\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] Epoch[266] Batch [5]#011Speed: 1894.32 samples/sec#011loss=2.246823\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] Epoch[266] Batch[10] avg_epoch_loss=2.265393\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=2.2876775741577147\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] Epoch[266] Batch [10]#011Speed: 1959.84 samples/sec#011loss=2.287678\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747861421.4773355, \"EndTime\": 1747861422.4652405, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 987.654447555542, \"count\": 1, \"min\": 987.654447555542, \"max\": 987.654447555542}}}\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1374.8536846760037 records/second\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] #progress_metric: host=algo-1, completed 66.75 % of epochs\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.265393083745783\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] Epoch[267] Batch[0] avg_epoch_loss=2.283924\n",
      "[05/21/2025 21:03:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.2839243412017822\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] Epoch[267] Batch[5] avg_epoch_loss=2.191931\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.1919306914011636\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] Epoch[267] Batch [5]#011Speed: 2155.23 samples/sec#011loss=2.191931\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] Epoch[267] Batch[10] avg_epoch_loss=2.067770\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=1.9187774181365966\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] Epoch[267] Batch [10]#011Speed: 2094.43 samples/sec#011loss=1.918777\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747861422.465299, \"EndTime\": 1747861423.3927612, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.2162914276123, \"count\": 1, \"min\": 927.2162914276123, \"max\": 927.2162914276123}}}\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1414.85238031573 records/second\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] #progress_metric: host=algo-1, completed 67.0 % of epochs\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.0677701126445425\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] Epoch[268] Batch[0] avg_epoch_loss=2.151347\n",
      "[05/21/2025 21:03:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.1513473987579346\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] Epoch[268] Batch[5] avg_epoch_loss=2.136162\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.1361622412999473\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] Epoch[268] Batch [5]#011Speed: 1906.50 samples/sec#011loss=2.136162\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] Epoch[268] Batch[10] avg_epoch_loss=2.194813\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=268, batch=10 train loss <loss>=2.265194368362427\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] Epoch[268] Batch [10]#011Speed: 2102.65 samples/sec#011loss=2.265194\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747861423.392822, \"EndTime\": 1747861424.36044, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 967.3686027526855, \"count\": 1, \"min\": 967.3686027526855, \"max\": 967.3686027526855}}}\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1328.2259665572808 records/second\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] #progress_metric: host=algo-1, completed 67.25 % of epochs\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.194813208146529\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] Epoch[269] Batch[0] avg_epoch_loss=2.240276\n",
      "[05/21/2025 21:03:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=2.2402758598327637\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] Epoch[269] Batch[5] avg_epoch_loss=2.152168\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=2.1521682739257812\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] Epoch[269] Batch [5]#011Speed: 2005.36 samples/sec#011loss=2.152168\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] Epoch[269] Batch[10] avg_epoch_loss=2.086946\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=269, batch=10 train loss <loss>=2.0086796998977663\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] Epoch[269] Batch [10]#011Speed: 2015.72 samples/sec#011loss=2.008680\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747861424.3604994, \"EndTime\": 1747861425.3387845, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 978.0368804931641, \"count\": 1, \"min\": 978.0368804931641, \"max\": 978.0368804931641}}}\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1345.4334743757963 records/second\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] #progress_metric: host=algo-1, completed 67.5 % of epochs\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=269, train loss <loss>=2.086946194822138\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] Epoch[270] Batch[0] avg_epoch_loss=2.145991\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=2.1459908485412598\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] Epoch[270] Batch[5] avg_epoch_loss=2.100694\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=2.100694179534912\n",
      "[05/21/2025 21:03:45 INFO 140363140085568] Epoch[270] Batch [5]#011Speed: 2022.10 samples/sec#011loss=2.100694\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] Epoch[270] Batch[10] avg_epoch_loss=2.110852\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=2.1230405807495116\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] Epoch[270] Batch [10]#011Speed: 2043.47 samples/sec#011loss=2.123041\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747861425.3388426, \"EndTime\": 1747861426.2904723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.3838291168213, \"count\": 1, \"min\": 951.3838291168213, \"max\": 951.3838291168213}}}\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1369.4627801418583 records/second\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] #progress_metric: host=algo-1, completed 67.75 % of epochs\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=270, train loss <loss>=2.1108516346324575\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] Epoch[271] Batch[0] avg_epoch_loss=2.095165\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=2.0951645374298096\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] Epoch[271] Batch[5] avg_epoch_loss=2.147075\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=2.1470752159754434\n",
      "[05/21/2025 21:03:46 INFO 140363140085568] Epoch[271] Batch [5]#011Speed: 1758.98 samples/sec#011loss=2.147075\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] Epoch[271] Batch[10] avg_epoch_loss=2.123398\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=271, batch=10 train loss <loss>=2.0949845790863035\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] Epoch[271] Batch [10]#011Speed: 1909.78 samples/sec#011loss=2.094985\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747861426.2905285, \"EndTime\": 1747861427.312202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1021.4295387268066, \"count\": 1, \"min\": 1021.4295387268066, \"max\": 1021.4295387268066}}}\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1339.1828358531181 records/second\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] #progress_metric: host=algo-1, completed 68.0 % of epochs\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=271, train loss <loss>=2.1233976537531074\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] Epoch[272] Batch[0] avg_epoch_loss=2.073159\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=2.0731592178344727\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] Epoch[272] Batch[5] avg_epoch_loss=2.033525\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=2.0335254073143005\n",
      "[05/21/2025 21:03:47 INFO 140363140085568] Epoch[272] Batch [5]#011Speed: 2096.85 samples/sec#011loss=2.033525\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] Epoch[272] Batch[10] avg_epoch_loss=2.066990\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=2.107148265838623\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] Epoch[272] Batch [10]#011Speed: 2018.19 samples/sec#011loss=2.107148\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747861427.312263, \"EndTime\": 1747861428.2621691, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 949.6257305145264, \"count\": 1, \"min\": 949.6257305145264, \"max\": 949.6257305145264}}}\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1413.053872096135 records/second\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] #progress_metric: host=algo-1, completed 68.25 % of epochs\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=272, train loss <loss>=2.0669903430071743\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] Epoch[273] Batch[0] avg_epoch_loss=2.050025\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=2.050025224685669\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] Epoch[273] Batch[5] avg_epoch_loss=2.029610\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=2.02961003780365\n",
      "[05/21/2025 21:03:48 INFO 140363140085568] Epoch[273] Batch [5]#011Speed: 2107.19 samples/sec#011loss=2.029610\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] Epoch[273] Batch[10] avg_epoch_loss=2.038188\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=273, batch=10 train loss <loss>=2.0484817743301393\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] Epoch[273] Batch [10]#011Speed: 2029.57 samples/sec#011loss=2.048482\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747861428.2622302, \"EndTime\": 1747861429.2067556, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.2665576934814, \"count\": 1, \"min\": 944.2665576934814, \"max\": 944.2665576934814}}}\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1384.015158144334 records/second\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] #progress_metric: host=algo-1, completed 68.5 % of epochs\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=273, train loss <loss>=2.038188099861145\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] Epoch[274] Batch[0] avg_epoch_loss=2.045112\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=2.045111894607544\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] Epoch[274] Batch[5] avg_epoch_loss=2.067149\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=2.0671488642692566\n",
      "[05/21/2025 21:03:49 INFO 140363140085568] Epoch[274] Batch [5]#011Speed: 2163.46 samples/sec#011loss=2.067149\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] Epoch[274] Batch[10] avg_epoch_loss=2.040609\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=274, batch=10 train loss <loss>=2.0087618589401246\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] Epoch[274] Batch [10]#011Speed: 2125.52 samples/sec#011loss=2.008762\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747861429.2068148, \"EndTime\": 1747861430.1299052, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.8448867797852, \"count\": 1, \"min\": 922.8448867797852, \"max\": 922.8448867797852}}}\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1402.0568528212516 records/second\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] #progress_metric: host=algo-1, completed 68.75 % of epochs\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=274, train loss <loss>=2.0406093163923784\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] Epoch[275] Batch[0] avg_epoch_loss=2.041029\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=2.041029214859009\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] Epoch[275] Batch[5] avg_epoch_loss=2.047906\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=2.047905524571737\n",
      "[05/21/2025 21:03:50 INFO 140363140085568] Epoch[275] Batch [5]#011Speed: 2062.59 samples/sec#011loss=2.047906\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] Epoch[275] Batch[10] avg_epoch_loss=2.094261\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=275, batch=10 train loss <loss>=2.149887943267822\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] Epoch[275] Batch [10]#011Speed: 1939.63 samples/sec#011loss=2.149888\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747861430.1299636, \"EndTime\": 1747861431.0911376, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.925817489624, \"count\": 1, \"min\": 960.925817489624, \"max\": 960.925817489624}}}\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1414.110928160685 records/second\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] #progress_metric: host=algo-1, completed 69.0 % of epochs\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=275, train loss <loss>=2.0942611694335938\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] Epoch[276] Batch[0] avg_epoch_loss=1.943204\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=1.9432042837142944\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] Epoch[276] Batch[5] avg_epoch_loss=2.013053\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=2.0130531986554465\n",
      "[05/21/2025 21:03:51 INFO 140363140085568] Epoch[276] Batch [5]#011Speed: 2002.18 samples/sec#011loss=2.013053\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] Epoch[276] Batch[10] avg_epoch_loss=2.045912\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=2.0853435516357424\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] Epoch[276] Batch [10]#011Speed: 1697.82 samples/sec#011loss=2.085344\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] processed a total of 1372 examples\n",
      "#metrics {\"StartTime\": 1747861431.0912087, \"EndTime\": 1747861432.1108203, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1019.2873477935791, \"count\": 1, \"min\": 1019.2873477935791, \"max\": 1019.2873477935791}}}\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1345.9188559402803 records/second\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] #progress_metric: host=algo-1, completed 69.25 % of epochs\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=276, train loss <loss>=2.0459124500101264\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] Epoch[277] Batch[0] avg_epoch_loss=2.030837\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=2.030837297439575\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] Epoch[277] Batch[5] avg_epoch_loss=2.094737\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=2.0947365760803223\n",
      "[05/21/2025 21:03:52 INFO 140363140085568] Epoch[277] Batch [5]#011Speed: 2055.79 samples/sec#011loss=2.094737\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] Epoch[277] Batch[10] avg_epoch_loss=2.139641\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=277, batch=10 train loss <loss>=2.193527364730835\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] Epoch[277] Batch [10]#011Speed: 1985.55 samples/sec#011loss=2.193527\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747861432.1108809, \"EndTime\": 1747861433.0748253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.6900424957275, \"count\": 1, \"min\": 963.6900424957275, \"max\": 963.6900424957275}}}\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1373.7599804471574 records/second\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] #progress_metric: host=algo-1, completed 69.5 % of epochs\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=277, train loss <loss>=2.1396414800123735\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] Epoch[278] Batch[0] avg_epoch_loss=2.041871\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=2.0418708324432373\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] Epoch[278] Batch[5] avg_epoch_loss=2.064398\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=2.064398487408956\n",
      "[05/21/2025 21:03:53 INFO 140363140085568] Epoch[278] Batch [5]#011Speed: 2028.94 samples/sec#011loss=2.064398\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] Epoch[278] Batch[10] avg_epoch_loss=2.023726\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=1.974918246269226\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] Epoch[278] Batch [10]#011Speed: 1914.94 samples/sec#011loss=1.974918\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] processed a total of 1376 examples\n",
      "#metrics {\"StartTime\": 1747861433.0748851, \"EndTime\": 1747861434.0434203, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 968.273401260376, \"count\": 1, \"min\": 968.273401260376, \"max\": 968.273401260376}}}\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1420.961324013502 records/second\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] #progress_metric: host=algo-1, completed 69.75 % of epochs\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=278, train loss <loss>=2.0237256505272607\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] Epoch[279] Batch[0] avg_epoch_loss=1.985092\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=1.9850921630859375\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] Epoch[279] Batch[5] avg_epoch_loss=1.982037\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=1.9820372064908345\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] Epoch[279] Batch [5]#011Speed: 2095.33 samples/sec#011loss=1.982037\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] processed a total of 1269 examples\n",
      "#metrics {\"StartTime\": 1747861434.0434775, \"EndTime\": 1747861434.9402113, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 896.4524269104004, \"count\": 1, \"min\": 896.4524269104004, \"max\": 896.4524269104004}}}\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1415.4304102950996 records/second\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] #progress_metric: host=algo-1, completed 70.0 % of epochs\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=279, train loss <loss>=2.0019111156463625\n",
      "[05/21/2025 21:03:54 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] Epoch[280] Batch[0] avg_epoch_loss=2.144339\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=2.144338846206665\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] Epoch[280] Batch[5] avg_epoch_loss=2.023402\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=2.023402472337087\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] Epoch[280] Batch [5]#011Speed: 2092.30 samples/sec#011loss=2.023402\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] Epoch[280] Batch[10] avg_epoch_loss=2.046992\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=2.07530038356781\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] Epoch[280] Batch [10]#011Speed: 2048.32 samples/sec#011loss=2.075300\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747861434.940276, \"EndTime\": 1747861435.8846388, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.0474510192871, \"count\": 1, \"min\": 944.0474510192871, \"max\": 944.0474510192871}}}\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1373.7075216629903 records/second\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] #progress_metric: host=algo-1, completed 70.25 % of epochs\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=280, train loss <loss>=2.0469924319874155\n",
      "[05/21/2025 21:03:55 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] Epoch[281] Batch[0] avg_epoch_loss=2.022917\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=2.0229172706604004\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] Epoch[281] Batch[5] avg_epoch_loss=2.048380\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=2.0483800172805786\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] Epoch[281] Batch [5]#011Speed: 1785.04 samples/sec#011loss=2.048380\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] Epoch[281] Batch[10] avg_epoch_loss=2.064368\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=281, batch=10 train loss <loss>=2.0835542917251586\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] Epoch[281] Batch [10]#011Speed: 1869.93 samples/sec#011loss=2.083554\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747861435.884723, \"EndTime\": 1747861436.9119833, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1026.9932746887207, \"count\": 1, \"min\": 1026.9932746887207, \"max\": 1026.9932746887207}}}\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1302.7173672938707 records/second\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] #progress_metric: host=algo-1, completed 70.5 % of epochs\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=281, train loss <loss>=2.064368323846297\n",
      "[05/21/2025 21:03:56 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] Epoch[282] Batch[0] avg_epoch_loss=2.006276\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=2.0062761306762695\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] Epoch[282] Batch[5] avg_epoch_loss=1.999647\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=1.9996466437975566\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] Epoch[282] Batch [5]#011Speed: 2028.19 samples/sec#011loss=1.999647\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] Epoch[282] Batch[10] avg_epoch_loss=1.948573\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=282, batch=10 train loss <loss>=1.8872852325439453\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] Epoch[282] Batch [10]#011Speed: 1981.98 samples/sec#011loss=1.887285\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747861436.9120414, \"EndTime\": 1747861437.8859, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.5453128814697, \"count\": 1, \"min\": 973.5453128814697, \"max\": 973.5453128814697}}}\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1330.0682564271087 records/second\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] #progress_metric: host=algo-1, completed 70.75 % of epochs\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=282, train loss <loss>=1.948573275045915\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:03:57 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_71c8cfb3-d09f-4f32-a1e7-6b58180a6a61-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861437.8859596, \"EndTime\": 1747861437.896845, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.612249374389648, \"count\": 1, \"min\": 10.612249374389648, \"max\": 10.612249374389648}}}\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] Epoch[283] Batch[0] avg_epoch_loss=2.013907\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=2.013906955718994\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] Epoch[283] Batch[5] avg_epoch_loss=2.007085\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=2.0070850054423013\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] Epoch[283] Batch [5]#011Speed: 2046.16 samples/sec#011loss=2.007085\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] Epoch[283] Batch[10] avg_epoch_loss=2.008830\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=283, batch=10 train loss <loss>=2.010925030708313\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] Epoch[283] Batch [10]#011Speed: 1987.42 samples/sec#011loss=2.010925\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747861437.8969057, \"EndTime\": 1747861438.879798, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 982.8362464904785, \"count\": 1, \"min\": 982.8362464904785, \"max\": 982.8362464904785}}}\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1337.8252682740592 records/second\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] #progress_metric: host=algo-1, completed 71.0 % of epochs\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=283, train loss <loss>=2.0088304714723066\n",
      "[05/21/2025 21:03:58 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] Epoch[284] Batch[0] avg_epoch_loss=2.032066\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=2.0320658683776855\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] Epoch[284] Batch[5] avg_epoch_loss=2.032129\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=2.032129387060801\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] Epoch[284] Batch [5]#011Speed: 2073.99 samples/sec#011loss=2.032129\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] Epoch[284] Batch[10] avg_epoch_loss=2.041036\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=284, batch=10 train loss <loss>=2.0517236948013307\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] Epoch[284] Batch [10]#011Speed: 2071.56 samples/sec#011loss=2.051724\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747861438.8798695, \"EndTime\": 1747861439.8259947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.8141326904297, \"count\": 1, \"min\": 945.8141326904297, \"max\": 945.8141326904297}}}\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1366.9531956659657 records/second\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] #progress_metric: host=algo-1, completed 71.25 % of epochs\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=284, train loss <loss>=2.0410358905792236\n",
      "[05/21/2025 21:03:59 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] Epoch[285] Batch[0] avg_epoch_loss=2.052889\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=2.052889108657837\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] Epoch[285] Batch[5] avg_epoch_loss=2.003803\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=2.0038031935691833\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] Epoch[285] Batch [5]#011Speed: 2084.67 samples/sec#011loss=2.003803\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] Epoch[285] Batch[10] avg_epoch_loss=2.185874\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=2.404359531402588\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] Epoch[285] Batch [10]#011Speed: 2010.57 samples/sec#011loss=2.404360\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747861439.8260498, \"EndTime\": 1747861440.7738886, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.5908279418945, \"count\": 1, \"min\": 947.5908279418945, \"max\": 947.5908279418945}}}\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1404.4853576864537 records/second\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] #progress_metric: host=algo-1, completed 71.5 % of epochs\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=285, train loss <loss>=2.185874256220731\n",
      "[05/21/2025 21:04:00 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] Epoch[286] Batch[0] avg_epoch_loss=1.932948\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=1.9329475164413452\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] Epoch[286] Batch[5] avg_epoch_loss=2.050321\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=2.0503212610880532\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] Epoch[286] Batch [5]#011Speed: 1932.19 samples/sec#011loss=2.050321\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] Epoch[286] Batch[10] avg_epoch_loss=2.055058\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=286, batch=10 train loss <loss>=2.060742950439453\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] Epoch[286] Batch [10]#011Speed: 1933.05 samples/sec#011loss=2.060743\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747861440.7739472, \"EndTime\": 1747861441.7615795, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 987.384557723999, \"count\": 1, \"min\": 987.384557723999, \"max\": 987.384557723999}}}\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1335.7507693689508 records/second\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] #progress_metric: host=algo-1, completed 71.75 % of epochs\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=286, train loss <loss>=2.055058392611417\n",
      "[05/21/2025 21:04:01 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] Epoch[287] Batch[0] avg_epoch_loss=2.053823\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=2.0538229942321777\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] Epoch[287] Batch[5] avg_epoch_loss=2.061296\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=2.0612957874933877\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] Epoch[287] Batch [5]#011Speed: 2038.06 samples/sec#011loss=2.061296\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] Epoch[287] Batch[10] avg_epoch_loss=1.977416\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=1.8767606973648072\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] Epoch[287] Batch [10]#011Speed: 2014.21 samples/sec#011loss=1.876761\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747861441.7616293, \"EndTime\": 1747861442.730264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 968.4104919433594, \"count\": 1, \"min\": 968.4104919433594, \"max\": 968.4104919433594}}}\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1335.0576334390485 records/second\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] #progress_metric: host=algo-1, completed 72.0 % of epochs\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=287, train loss <loss>=1.9774162010713057\n",
      "[05/21/2025 21:04:02 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] Epoch[288] Batch[0] avg_epoch_loss=2.031796\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=2.0317959785461426\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] Epoch[288] Batch[5] avg_epoch_loss=2.021426\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=2.021425724029541\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] Epoch[288] Batch [5]#011Speed: 1889.07 samples/sec#011loss=2.021426\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] processed a total of 1233 examples\n",
      "#metrics {\"StartTime\": 1747861442.7303226, \"EndTime\": 1747861443.637143, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.5680503845215, \"count\": 1, \"min\": 906.5680503845215, \"max\": 906.5680503845215}}}\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1359.936350191753 records/second\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] #progress_metric: host=algo-1, completed 72.25 % of epochs\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=288, train loss <loss>=2.0301735162734986\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] Epoch[289] Batch[0] avg_epoch_loss=2.044772\n",
      "[05/21/2025 21:04:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=2.044772148132324\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] Epoch[289] Batch[5] avg_epoch_loss=1.961725\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=1.9617254535357158\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] Epoch[289] Batch [5]#011Speed: 2076.12 samples/sec#011loss=1.961725\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] Epoch[289] Batch[10] avg_epoch_loss=1.970651\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=289, batch=10 train loss <loss>=1.981361198425293\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] Epoch[289] Batch [10]#011Speed: 2060.98 samples/sec#011loss=1.981361\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747861443.6372044, \"EndTime\": 1747861444.591041, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.5470008850098, \"count\": 1, \"min\": 953.5470008850098, \"max\": 953.5470008850098}}}\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1408.2822809624206 records/second\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] #progress_metric: host=algo-1, completed 72.5 % of epochs\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=289, train loss <loss>=1.9706507921218872\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] Epoch[290] Batch[0] avg_epoch_loss=1.967432\n",
      "[05/21/2025 21:04:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=1.967431902885437\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] Epoch[290] Batch[5] avg_epoch_loss=1.979160\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=1.979159692923228\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] Epoch[290] Batch [5]#011Speed: 1915.51 samples/sec#011loss=1.979160\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] Epoch[290] Batch[10] avg_epoch_loss=1.947206\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=290, batch=10 train loss <loss>=1.908861470222473\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] Epoch[290] Batch [10]#011Speed: 2140.53 samples/sec#011loss=1.908861\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747861444.5911102, \"EndTime\": 1747861445.557978, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 966.6187763214111, \"count\": 1, \"min\": 966.6187763214111, \"max\": 966.6187763214111}}}\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1338.5681526877886 records/second\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] #progress_metric: host=algo-1, completed 72.75 % of epochs\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=290, train loss <loss>=1.9472059553319758\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_bdd8c805-b54f-4788-ae72-6a113e9fc283-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861445.5580356, \"EndTime\": 1747861445.5692575, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.954141616821289, \"count\": 1, \"min\": 10.954141616821289, \"max\": 10.954141616821289}}}\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] Epoch[291] Batch[0] avg_epoch_loss=1.986904\n",
      "[05/21/2025 21:04:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=1.9869036674499512\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] Epoch[291] Batch[5] avg_epoch_loss=1.971402\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=1.9714022874832153\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] Epoch[291] Batch [5]#011Speed: 2146.84 samples/sec#011loss=1.971402\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] Epoch[291] Batch[10] avg_epoch_loss=1.945641\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=291, batch=10 train loss <loss>=1.9147279977798461\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] Epoch[291] Batch [10]#011Speed: 1831.51 samples/sec#011loss=1.914728\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] processed a total of 1372 examples\n",
      "#metrics {\"StartTime\": 1747861445.5693147, \"EndTime\": 1747861446.5774286, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1008.0611705780029, \"count\": 1, \"min\": 1008.0611705780029, \"max\": 1008.0611705780029}}}\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1360.9087808476177 records/second\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] #progress_metric: host=algo-1, completed 73.0 % of epochs\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=291, train loss <loss>=1.9456412467089566\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_c20dd2a9-1ac2-4b79-84db-56f118420c5b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861446.5774877, \"EndTime\": 1747861446.5883086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.546445846557617, \"count\": 1, \"min\": 10.546445846557617, \"max\": 10.546445846557617}}}\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] Epoch[292] Batch[0] avg_epoch_loss=2.003809\n",
      "[05/21/2025 21:04:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=2.0038087368011475\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] Epoch[292] Batch[5] avg_epoch_loss=1.968378\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=1.9683781663576763\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] Epoch[292] Batch [5]#011Speed: 1984.45 samples/sec#011loss=1.968378\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] Epoch[292] Batch[10] avg_epoch_loss=1.976043\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=292, batch=10 train loss <loss>=1.98524010181427\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] Epoch[292] Batch [10]#011Speed: 1940.00 samples/sec#011loss=1.985240\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] processed a total of 1375 examples\n",
      "#metrics {\"StartTime\": 1747861446.588392, \"EndTime\": 1747861447.5689445, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 980.4959297180176, \"count\": 1, \"min\": 980.4959297180176, \"max\": 980.4959297180176}}}\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1402.1551763960483 records/second\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] #progress_metric: host=algo-1, completed 73.25 % of epochs\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=292, train loss <loss>=1.9760426824743098\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] Epoch[293] Batch[0] avg_epoch_loss=1.927781\n",
      "[05/21/2025 21:04:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=1.9277814626693726\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] Epoch[293] Batch[5] avg_epoch_loss=1.971103\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=1.9711032311121623\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] Epoch[293] Batch [5]#011Speed: 2078.84 samples/sec#011loss=1.971103\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] Epoch[293] Batch[10] avg_epoch_loss=1.986340\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=293, batch=10 train loss <loss>=2.004623031616211\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] Epoch[293] Batch [10]#011Speed: 1970.04 samples/sec#011loss=2.004623\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747861447.5690506, \"EndTime\": 1747861448.5317464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 962.4302387237549, \"count\": 1, \"min\": 962.4302387237549, \"max\": 962.4302387237549}}}\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1388.0222416861195 records/second\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] #progress_metric: host=algo-1, completed 73.5 % of epochs\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=293, train loss <loss>=1.986339504068548\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] Epoch[294] Batch[0] avg_epoch_loss=2.078566\n",
      "[05/21/2025 21:04:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=2.078565835952759\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] Epoch[294] Batch[5] avg_epoch_loss=2.025508\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=2.025507609049479\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] Epoch[294] Batch [5]#011Speed: 2032.97 samples/sec#011loss=2.025508\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] Epoch[294] Batch[10] avg_epoch_loss=2.019645\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=294, batch=10 train loss <loss>=2.0126102447509764\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] Epoch[294] Batch [10]#011Speed: 1980.40 samples/sec#011loss=2.012610\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747861448.5318067, \"EndTime\": 1747861449.4919415, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 959.8886966705322, \"count\": 1, \"min\": 959.8886966705322, \"max\": 959.8886966705322}}}\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1407.3276106445687 records/second\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] #progress_metric: host=algo-1, completed 73.75 % of epochs\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=294, train loss <loss>=2.019645170731978\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] Epoch[295] Batch[0] avg_epoch_loss=2.070389\n",
      "[05/21/2025 21:04:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=295, batch=0 train loss <loss>=2.0703885555267334\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] Epoch[295] Batch[5] avg_epoch_loss=1.998585\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=295, batch=5 train loss <loss>=1.9985851844151814\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] Epoch[295] Batch [5]#011Speed: 2083.98 samples/sec#011loss=1.998585\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] Epoch[295] Batch[10] avg_epoch_loss=1.971817\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=295, batch=10 train loss <loss>=1.9396941900253295\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] Epoch[295] Batch [10]#011Speed: 1960.82 samples/sec#011loss=1.939694\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747861449.492, \"EndTime\": 1747861450.4509022, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.6572647094727, \"count\": 1, \"min\": 958.6572647094727, \"max\": 958.6572647094727}}}\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1386.191628235464 records/second\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] #progress_metric: host=algo-1, completed 74.0 % of epochs\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=295, train loss <loss>=1.9718165506016125\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] Epoch[296] Batch[0] avg_epoch_loss=1.979984\n",
      "[05/21/2025 21:04:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=296, batch=0 train loss <loss>=1.9799838066101074\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] Epoch[296] Batch[5] avg_epoch_loss=1.959915\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=296, batch=5 train loss <loss>=1.9599151015281677\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] Epoch[296] Batch [5]#011Speed: 2059.29 samples/sec#011loss=1.959915\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] Epoch[296] Batch[10] avg_epoch_loss=1.970919\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=296, batch=10 train loss <loss>=1.9841243505477906\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] Epoch[296] Batch [10]#011Speed: 2042.87 samples/sec#011loss=1.984124\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747861450.4509592, \"EndTime\": 1747861451.4024377, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.2155055999756, \"count\": 1, \"min\": 951.2155055999756, \"max\": 951.2155055999756}}}\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1386.516891847017 records/second\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] #progress_metric: host=algo-1, completed 74.25 % of epochs\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=296, train loss <loss>=1.9709193056279963\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] Epoch[297] Batch[0] avg_epoch_loss=1.991902\n",
      "[05/21/2025 21:04:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=297, batch=0 train loss <loss>=1.991902232170105\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] Epoch[297] Batch[5] avg_epoch_loss=1.969930\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=297, batch=5 train loss <loss>=1.9699296752611797\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] Epoch[297] Batch [5]#011Speed: 2022.25 samples/sec#011loss=1.969930\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] Epoch[297] Batch[10] avg_epoch_loss=1.970685\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=297, batch=10 train loss <loss>=1.9715921878814697\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] Epoch[297] Batch [10]#011Speed: 1997.55 samples/sec#011loss=1.971592\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747861451.4024968, \"EndTime\": 1747861452.3643868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.6351127624512, \"count\": 1, \"min\": 961.6351127624512, \"max\": 961.6351127624512}}}\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1391.2483779450104 records/second\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] #progress_metric: host=algo-1, completed 74.5 % of epochs\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=297, train loss <loss>=1.970685362815857\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] Epoch[298] Batch[0] avg_epoch_loss=2.009974\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=298, batch=0 train loss <loss>=2.0099737644195557\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] Epoch[298] Batch[5] avg_epoch_loss=1.988086\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=298, batch=5 train loss <loss>=1.9880861043930054\n",
      "[05/21/2025 21:04:12 INFO 140363140085568] Epoch[298] Batch [5]#011Speed: 2101.13 samples/sec#011loss=1.988086\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] Epoch[298] Batch[10] avg_epoch_loss=2.010615\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=298, batch=10 train loss <loss>=2.037650203704834\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] Epoch[298] Batch [10]#011Speed: 1973.87 samples/sec#011loss=2.037650\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747861452.3644485, \"EndTime\": 1747861453.3160965, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.3866901397705, \"count\": 1, \"min\": 951.3866901397705, \"max\": 951.3866901397705}}}\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1414.6490132470808 records/second\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] #progress_metric: host=algo-1, completed 74.75 % of epochs\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=298, train loss <loss>=2.0106152404438364\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] Epoch[299] Batch[0] avg_epoch_loss=1.928370\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=299, batch=0 train loss <loss>=1.9283699989318848\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] Epoch[299] Batch[5] avg_epoch_loss=1.982535\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=299, batch=5 train loss <loss>=1.9825347860654194\n",
      "[05/21/2025 21:04:13 INFO 140363140085568] Epoch[299] Batch [5]#011Speed: 2071.25 samples/sec#011loss=1.982535\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] Epoch[299] Batch[10] avg_epoch_loss=1.963266\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=299, batch=10 train loss <loss>=1.9401436805725099\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] Epoch[299] Batch [10]#011Speed: 2042.47 samples/sec#011loss=1.940144\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747861453.3161535, \"EndTime\": 1747861454.263382, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.9547271728516, \"count\": 1, \"min\": 946.9547271728516, \"max\": 946.9547271728516}}}\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1390.6489893567073 records/second\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] #progress_metric: host=algo-1, completed 75.0 % of epochs\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=299, train loss <loss>=1.9632661017504605\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] Epoch[300] Batch[0] avg_epoch_loss=2.042745\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=300, batch=0 train loss <loss>=2.042745351791382\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] Epoch[300] Batch[5] avg_epoch_loss=1.995374\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=300, batch=5 train loss <loss>=1.9953736861546834\n",
      "[05/21/2025 21:04:14 INFO 140363140085568] Epoch[300] Batch [5]#011Speed: 2115.05 samples/sec#011loss=1.995374\n",
      "[05/21/2025 21:04:15 INFO 140363140085568] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747861454.2634392, \"EndTime\": 1747861455.1467934, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 883.1019401550293, \"count\": 1, \"min\": 883.1019401550293, \"max\": 883.1019401550293}}}\n",
      "[05/21/2025 21:04:15 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1442.4870602387002 records/second\n",
      "[05/21/2025 21:04:15 INFO 140363140085568] #progress_metric: host=algo-1, completed 75.25 % of epochs\n",
      "[05/21/2025 21:04:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=300, train loss <loss>=1.9709391117095947\n",
      "[05/21/2025 21:04:15 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:15 INFO 140363140085568] Epoch[301] Batch[0] avg_epoch_loss=1.959303\n",
      "[05/21/2025 21:04:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=301, batch=0 train loss <loss>=1.9593027830123901\n",
      "[05/21/2025 21:04:15 INFO 140363140085568] Epoch[301] Batch[5] avg_epoch_loss=1.949695\n",
      "[05/21/2025 21:04:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=301, batch=5 train loss <loss>=1.9496951897939045\n",
      "[05/21/2025 21:04:15 INFO 140363140085568] Epoch[301] Batch [5]#011Speed: 2112.67 samples/sec#011loss=1.949695\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] Epoch[301] Batch[10] avg_epoch_loss=1.932931\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=301, batch=10 train loss <loss>=1.912813663482666\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] Epoch[301] Batch [10]#011Speed: 1869.02 samples/sec#011loss=1.912814\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747861455.1468577, \"EndTime\": 1747861456.1163385, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 969.184160232544, \"count\": 1, \"min\": 969.184160232544, \"max\": 969.184160232544}}}\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1365.9455580549034 records/second\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] #progress_metric: host=algo-1, completed 75.5 % of epochs\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=301, train loss <loss>=1.9329308596524326\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_2eeeceac-1fa8-43ea-bc24-f0831a5b78d6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861456.1164176, \"EndTime\": 1747861456.12755, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.840415954589844, \"count\": 1, \"min\": 10.840415954589844, \"max\": 10.840415954589844}}}\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] Epoch[302] Batch[0] avg_epoch_loss=1.940159\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=302, batch=0 train loss <loss>=1.9401586055755615\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] Epoch[302] Batch[5] avg_epoch_loss=1.972634\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=302, batch=5 train loss <loss>=1.9726340373357136\n",
      "[05/21/2025 21:04:16 INFO 140363140085568] Epoch[302] Batch [5]#011Speed: 2141.85 samples/sec#011loss=1.972634\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747861456.1276078, \"EndTime\": 1747861457.004396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 876.7342567443848, \"count\": 1, \"min\": 876.7342567443848, \"max\": 876.7342567443848}}}\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1459.801120211306 records/second\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] #progress_metric: host=algo-1, completed 75.75 % of epochs\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=302, train loss <loss>=1.9595421433448792\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] Epoch[303] Batch[0] avg_epoch_loss=1.868726\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=303, batch=0 train loss <loss>=1.8687258958816528\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] Epoch[303] Batch[5] avg_epoch_loss=1.937766\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=303, batch=5 train loss <loss>=1.9377660353978474\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] Epoch[303] Batch [5]#011Speed: 2094.26 samples/sec#011loss=1.937766\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] processed a total of 1246 examples\n",
      "#metrics {\"StartTime\": 1747861457.0044613, \"EndTime\": 1747861457.891844, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 887.0747089385986, \"count\": 1, \"min\": 887.0747089385986, \"max\": 887.0747089385986}}}\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1404.4642552602547 records/second\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] #progress_metric: host=algo-1, completed 76.0 % of epochs\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=303, train loss <loss>=1.9590984225273131\n",
      "[05/21/2025 21:04:17 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] Epoch[304] Batch[0] avg_epoch_loss=2.025758\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=304, batch=0 train loss <loss>=2.0257580280303955\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] Epoch[304] Batch[5] avg_epoch_loss=1.923900\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=304, batch=5 train loss <loss>=1.923900067806244\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] Epoch[304] Batch [5]#011Speed: 2094.42 samples/sec#011loss=1.923900\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] Epoch[304] Batch[10] avg_epoch_loss=2.066125\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=304, batch=10 train loss <loss>=2.2367942094802857\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] Epoch[304] Batch [10]#011Speed: 2011.35 samples/sec#011loss=2.236794\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747861457.8919096, \"EndTime\": 1747861458.8455994, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.4025192260742, \"count\": 1, \"min\": 953.4025192260742, \"max\": 953.4025192260742}}}\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1373.9000661877908 records/second\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] #progress_metric: host=algo-1, completed 76.25 % of epochs\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=304, train loss <loss>=2.066124677658081\n",
      "[05/21/2025 21:04:18 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] Epoch[305] Batch[0] avg_epoch_loss=1.961625\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=305, batch=0 train loss <loss>=1.961625099182129\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] Epoch[305] Batch[5] avg_epoch_loss=2.037782\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=305, batch=5 train loss <loss>=2.0377817153930664\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] Epoch[305] Batch [5]#011Speed: 2107.85 samples/sec#011loss=2.037782\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] Epoch[305] Batch[10] avg_epoch_loss=2.105289\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=305, batch=10 train loss <loss>=2.1862972736358643\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] Epoch[305] Batch [10]#011Speed: 2048.37 samples/sec#011loss=2.186297\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747861458.8456588, \"EndTime\": 1747861459.790559, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.6585178375244, \"count\": 1, \"min\": 944.6585178375244, \"max\": 944.6585178375244}}}\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1397.2058514012988 records/second\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] #progress_metric: host=algo-1, completed 76.5 % of epochs\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=305, train loss <loss>=2.105288787321611\n",
      "[05/21/2025 21:04:19 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] Epoch[306] Batch[0] avg_epoch_loss=2.031503\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=306, batch=0 train loss <loss>=2.0315029621124268\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] Epoch[306] Batch[5] avg_epoch_loss=2.035899\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=306, batch=5 train loss <loss>=2.0358986059824624\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] Epoch[306] Batch [5]#011Speed: 2063.93 samples/sec#011loss=2.035899\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] Epoch[306] Batch[10] avg_epoch_loss=2.026539\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=306, batch=10 train loss <loss>=2.015306568145752\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] Epoch[306] Batch [10]#011Speed: 2023.77 samples/sec#011loss=2.015307\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747861459.7906158, \"EndTime\": 1747861460.7435756, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.7113437652588, \"count\": 1, \"min\": 952.7113437652588, \"max\": 952.7113437652588}}}\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1374.8626560675323 records/second\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] #progress_metric: host=algo-1, completed 76.75 % of epochs\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=306, train loss <loss>=2.0265385887839575\n",
      "[05/21/2025 21:04:20 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] Epoch[307] Batch[0] avg_epoch_loss=1.942848\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=307, batch=0 train loss <loss>=1.9428484439849854\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] Epoch[307] Batch[5] avg_epoch_loss=1.992689\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=307, batch=5 train loss <loss>=1.9926892518997192\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] Epoch[307] Batch [5]#011Speed: 2050.79 samples/sec#011loss=1.992689\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] Epoch[307] Batch[10] avg_epoch_loss=1.959600\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=307, batch=10 train loss <loss>=1.9198936700820923\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] Epoch[307] Batch [10]#011Speed: 1950.09 samples/sec#011loss=1.919894\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747861460.743651, \"EndTime\": 1747861461.707615, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.0434513092041, \"count\": 1, \"min\": 963.0434513092041, \"max\": 963.0434513092041}}}\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1409.9725826107342 records/second\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] #progress_metric: host=algo-1, completed 77.0 % of epochs\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=307, train loss <loss>=1.9596003510735251\n",
      "[05/21/2025 21:04:21 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] Epoch[308] Batch[0] avg_epoch_loss=1.857638\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=308, batch=0 train loss <loss>=1.8576377630233765\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] Epoch[308] Batch[5] avg_epoch_loss=1.965314\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=308, batch=5 train loss <loss>=1.9653143088022869\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] Epoch[308] Batch [5]#011Speed: 1933.86 samples/sec#011loss=1.965314\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] Epoch[308] Batch[10] avg_epoch_loss=1.993702\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=308, batch=10 train loss <loss>=2.027767562866211\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] Epoch[308] Batch [10]#011Speed: 1749.70 samples/sec#011loss=2.027768\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] processed a total of 1386 examples\n",
      "#metrics {\"StartTime\": 1747861461.707675, \"EndTime\": 1747861462.7351744, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1027.1389484405518, \"count\": 1, \"min\": 1027.1389484405518, \"max\": 1027.1389484405518}}}\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1349.2580617010017 records/second\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] #progress_metric: host=algo-1, completed 77.25 % of epochs\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=308, train loss <loss>=1.993702151558616\n",
      "[05/21/2025 21:04:22 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] Epoch[309] Batch[0] avg_epoch_loss=2.003820\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=309, batch=0 train loss <loss>=2.003819704055786\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] Epoch[309] Batch[5] avg_epoch_loss=1.918965\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=309, batch=5 train loss <loss>=1.9189645250638325\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] Epoch[309] Batch [5]#011Speed: 2060.15 samples/sec#011loss=1.918965\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] Epoch[309] Batch[10] avg_epoch_loss=1.934174\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=309, batch=10 train loss <loss>=1.9524256229400634\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] Epoch[309] Batch [10]#011Speed: 2008.49 samples/sec#011loss=1.952426\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747861462.735234, \"EndTime\": 1747861463.6911633, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.674409866333, \"count\": 1, \"min\": 955.674409866333, \"max\": 955.674409866333}}}\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1404.1167844755676 records/second\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] #progress_metric: host=algo-1, completed 77.5 % of epochs\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=309, train loss <loss>=1.934174115007574\n",
      "[05/21/2025 21:04:23 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] Epoch[310] Batch[0] avg_epoch_loss=1.888759\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=310, batch=0 train loss <loss>=1.8887594938278198\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] Epoch[310] Batch[5] avg_epoch_loss=1.951089\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=310, batch=5 train loss <loss>=1.951089342435201\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] Epoch[310] Batch [5]#011Speed: 2071.74 samples/sec#011loss=1.951089\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] Epoch[310] Batch[10] avg_epoch_loss=1.920198\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=310, batch=10 train loss <loss>=1.8831289529800415\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] Epoch[310] Batch [10]#011Speed: 2076.87 samples/sec#011loss=1.883129\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747861463.6912222, \"EndTime\": 1747861464.6401155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.6393928527832, \"count\": 1, \"min\": 948.6393928527832, \"max\": 948.6393928527832}}}\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1356.554779055043 records/second\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] #progress_metric: host=algo-1, completed 77.75 % of epochs\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=310, train loss <loss>=1.9201982563192195\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_fa898aa9-93f8-4cd2-829d-e9310176e1b2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861464.6401737, \"EndTime\": 1747861464.651287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.817766189575195, \"count\": 1, \"min\": 10.817766189575195, \"max\": 10.817766189575195}}}\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] Epoch[311] Batch[0] avg_epoch_loss=1.976953\n",
      "[05/21/2025 21:04:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=311, batch=0 train loss <loss>=1.9769530296325684\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] Epoch[311] Batch[5] avg_epoch_loss=1.993074\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=311, batch=5 train loss <loss>=1.993073542912801\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] Epoch[311] Batch [5]#011Speed: 1995.96 samples/sec#011loss=1.993074\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] Epoch[311] Batch[10] avg_epoch_loss=1.989995\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=311, batch=10 train loss <loss>=1.9863017559051515\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] Epoch[311] Batch [10]#011Speed: 2013.48 samples/sec#011loss=1.986302\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747861464.6513534, \"EndTime\": 1747861465.6154923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 964.092493057251, \"count\": 1, \"min\": 964.092493057251, \"max\": 964.092493057251}}}\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1358.6641194003869 records/second\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] #progress_metric: host=algo-1, completed 78.0 % of epochs\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=311, train loss <loss>=1.989995457909324\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] Epoch[312] Batch[0] avg_epoch_loss=2.100181\n",
      "[05/21/2025 21:04:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=312, batch=0 train loss <loss>=2.1001813411712646\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] Epoch[312] Batch[5] avg_epoch_loss=2.059757\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=312, batch=5 train loss <loss>=2.0597567160924277\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] Epoch[312] Batch [5]#011Speed: 2150.37 samples/sec#011loss=2.059757\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] Epoch[312] Batch[10] avg_epoch_loss=2.056142\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=312, batch=10 train loss <loss>=2.0518033266067506\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] Epoch[312] Batch [10]#011Speed: 2052.84 samples/sec#011loss=2.051803\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747861465.6155539, \"EndTime\": 1747861466.552877, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.0200634002686, \"count\": 1, \"min\": 937.0200634002686, \"max\": 937.0200634002686}}}\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1401.1234060568313 records/second\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] #progress_metric: host=algo-1, completed 78.25 % of epochs\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=312, train loss <loss>=2.0561415390534834\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] Epoch[313] Batch[0] avg_epoch_loss=1.984766\n",
      "[05/21/2025 21:04:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=313, batch=0 train loss <loss>=1.9847663640975952\n",
      "[05/21/2025 21:04:27 INFO 140363140085568] Epoch[313] Batch[5] avg_epoch_loss=1.995347\n",
      "[05/21/2025 21:04:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=313, batch=5 train loss <loss>=1.9953465263048809\n",
      "[05/21/2025 21:04:27 INFO 140363140085568] Epoch[313] Batch [5]#011Speed: 2036.75 samples/sec#011loss=1.995347\n",
      "[05/21/2025 21:04:27 INFO 140363140085568] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747861466.5529342, \"EndTime\": 1747861467.4386582, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 885.4751586914062, \"count\": 1, \"min\": 885.4751586914062, \"max\": 885.4751586914062}}}\n",
      "[05/21/2025 21:04:27 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1437.493704679101 records/second\n",
      "[05/21/2025 21:04:27 INFO 140363140085568] #progress_metric: host=algo-1, completed 78.5 % of epochs\n",
      "[05/21/2025 21:04:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=313, train loss <loss>=1.970259392261505\n",
      "[05/21/2025 21:04:27 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:27 INFO 140363140085568] Epoch[314] Batch[0] avg_epoch_loss=1.859555\n",
      "[05/21/2025 21:04:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=314, batch=0 train loss <loss>=1.8595551252365112\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] Epoch[314] Batch[5] avg_epoch_loss=1.934376\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=314, batch=5 train loss <loss>=1.9343757430712383\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] Epoch[314] Batch [5]#011Speed: 2078.81 samples/sec#011loss=1.934376\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] Epoch[314] Batch[10] avg_epoch_loss=1.939586\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=314, batch=10 train loss <loss>=1.9458375930786134\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] Epoch[314] Batch [10]#011Speed: 1993.43 samples/sec#011loss=1.945838\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747861467.4387245, \"EndTime\": 1747861468.392749, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.7291526794434, \"count\": 1, \"min\": 953.7291526794434, \"max\": 953.7291526794434}}}\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1362.943676976615 records/second\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] #progress_metric: host=algo-1, completed 78.75 % of epochs\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=314, train loss <loss>=1.9395856748927722\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] Epoch[315] Batch[0] avg_epoch_loss=1.966690\n",
      "[05/21/2025 21:04:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=315, batch=0 train loss <loss>=1.9666897058486938\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] Epoch[315] Batch[5] avg_epoch_loss=1.967346\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=315, batch=5 train loss <loss>=1.9673457145690918\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] Epoch[315] Batch [5]#011Speed: 2125.15 samples/sec#011loss=1.967346\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] Epoch[315] Batch[10] avg_epoch_loss=2.041549\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=315, batch=10 train loss <loss>=2.1305925607681275\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] Epoch[315] Batch [10]#011Speed: 1985.06 samples/sec#011loss=2.130593\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747861468.3928094, \"EndTime\": 1747861469.3370001, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.8586235046387, \"count\": 1, \"min\": 943.8586235046387, \"max\": 943.8586235046387}}}\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1418.432911276674 records/second\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] #progress_metric: host=algo-1, completed 79.0 % of epochs\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=315, train loss <loss>=2.041548826477744\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] Epoch[316] Batch[0] avg_epoch_loss=1.982999\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=316, batch=0 train loss <loss>=1.9829987287521362\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] Epoch[316] Batch[5] avg_epoch_loss=1.954703\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=316, batch=5 train loss <loss>=1.954702893892924\n",
      "[05/21/2025 21:04:29 INFO 140363140085568] Epoch[316] Batch [5]#011Speed: 2131.88 samples/sec#011loss=1.954703\n",
      "[05/21/2025 21:04:30 INFO 140363140085568] processed a total of 1269 examples\n",
      "#metrics {\"StartTime\": 1747861469.3371103, \"EndTime\": 1747861470.2064126, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 869.0407276153564, \"count\": 1, \"min\": 869.0407276153564, \"max\": 869.0407276153564}}}\n",
      "[05/21/2025 21:04:30 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1460.072533834273 records/second\n",
      "[05/21/2025 21:04:30 INFO 140363140085568] #progress_metric: host=algo-1, completed 79.25 % of epochs\n",
      "[05/21/2025 21:04:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=316, train loss <loss>=1.9482463479042054\n",
      "[05/21/2025 21:04:30 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:30 INFO 140363140085568] Epoch[317] Batch[0] avg_epoch_loss=1.963200\n",
      "[05/21/2025 21:04:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=317, batch=0 train loss <loss>=1.9632002115249634\n",
      "[05/21/2025 21:04:30 INFO 140363140085568] Epoch[317] Batch[5] avg_epoch_loss=1.922589\n",
      "[05/21/2025 21:04:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=317, batch=5 train loss <loss>=1.9225894808769226\n",
      "[05/21/2025 21:04:30 INFO 140363140085568] Epoch[317] Batch [5]#011Speed: 2073.50 samples/sec#011loss=1.922589\n",
      "[05/21/2025 21:04:31 INFO 140363140085568] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747861470.2064762, \"EndTime\": 1747861471.0997663, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 892.9646015167236, \"count\": 1, \"min\": 892.9646015167236, \"max\": 892.9646015167236}}}\n",
      "[05/21/2025 21:04:31 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1426.5586020239427 records/second\n",
      "[05/21/2025 21:04:31 INFO 140363140085568] #progress_metric: host=algo-1, completed 79.5 % of epochs\n",
      "[05/21/2025 21:04:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=317, train loss <loss>=1.9359049558639527\n",
      "[05/21/2025 21:04:31 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:31 INFO 140363140085568] Epoch[318] Batch[0] avg_epoch_loss=1.973833\n",
      "[05/21/2025 21:04:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=318, batch=0 train loss <loss>=1.973833441734314\n",
      "[05/21/2025 21:04:31 INFO 140363140085568] Epoch[318] Batch[5] avg_epoch_loss=1.922181\n",
      "[05/21/2025 21:04:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=318, batch=5 train loss <loss>=1.9221813281377156\n",
      "[05/21/2025 21:04:31 INFO 140363140085568] Epoch[318] Batch [5]#011Speed: 2082.00 samples/sec#011loss=1.922181\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] Epoch[318] Batch[10] avg_epoch_loss=1.909351\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=318, batch=10 train loss <loss>=1.893953514099121\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] Epoch[318] Batch [10]#011Speed: 1966.83 samples/sec#011loss=1.893954\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747861471.0998287, \"EndTime\": 1747861472.0584834, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.3685398101807, \"count\": 1, \"min\": 958.3685398101807, \"max\": 958.3685398101807}}}\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1385.5613768660494 records/second\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] #progress_metric: host=algo-1, completed 79.75 % of epochs\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=318, train loss <loss>=1.909350503574718\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_effb28d0-267e-45a4-b9ec-6920f5b870fc-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861472.0585432, \"EndTime\": 1747861472.070168, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.35563850402832, \"count\": 1, \"min\": 11.35563850402832, \"max\": 11.35563850402832}}}\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] Epoch[319] Batch[0] avg_epoch_loss=2.007289\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=319, batch=0 train loss <loss>=2.007288932800293\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] Epoch[319] Batch[5] avg_epoch_loss=1.945764\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=319, batch=5 train loss <loss>=1.94576362768809\n",
      "[05/21/2025 21:04:32 INFO 140363140085568] Epoch[319] Batch [5]#011Speed: 1887.41 samples/sec#011loss=1.945764\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] Epoch[319] Batch[10] avg_epoch_loss=1.948786\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=319, batch=10 train loss <loss>=1.952413010597229\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] Epoch[319] Batch [10]#011Speed: 1951.99 samples/sec#011loss=1.952413\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] processed a total of 1372 examples\n",
      "#metrics {\"StartTime\": 1747861472.0702305, \"EndTime\": 1747861473.0531836, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 982.9006195068359, \"count\": 1, \"min\": 982.9006195068359, \"max\": 982.9006195068359}}}\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1395.7482970279211 records/second\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] #progress_metric: host=algo-1, completed 80.0 % of epochs\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=319, train loss <loss>=1.9487860744649714\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] Epoch[320] Batch[0] avg_epoch_loss=1.990780\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=320, batch=0 train loss <loss>=1.9907798767089844\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] Epoch[320] Batch[5] avg_epoch_loss=1.926315\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=320, batch=5 train loss <loss>=1.926315466562907\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] Epoch[320] Batch [5]#011Speed: 2112.48 samples/sec#011loss=1.926315\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] Epoch[320] Batch[10] avg_epoch_loss=1.901207\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=320, batch=10 train loss <loss>=1.8710771799087524\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] Epoch[320] Batch [10]#011Speed: 1987.74 samples/sec#011loss=1.871077\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747861473.0532408, \"EndTime\": 1747861473.9978802, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.3929195404053, \"count\": 1, \"min\": 944.3929195404053, \"max\": 944.3929195404053}}}\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1427.1792278182131 records/second\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] #progress_metric: host=algo-1, completed 80.25 % of epochs\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=320, train loss <loss>=1.901207154447382\n",
      "[05/21/2025 21:04:33 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_452557dd-0141-4038-bd46-d7e3ec36f101-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861473.9979796, \"EndTime\": 1747861474.0088184, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.561227798461914, \"count\": 1, \"min\": 10.561227798461914, \"max\": 10.561227798461914}}}\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] Epoch[321] Batch[0] avg_epoch_loss=1.915567\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=321, batch=0 train loss <loss>=1.9155665636062622\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] Epoch[321] Batch[5] avg_epoch_loss=1.938914\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=321, batch=5 train loss <loss>=1.938913901646932\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] Epoch[321] Batch [5]#011Speed: 2128.48 samples/sec#011loss=1.938914\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] Epoch[321] Batch[10] avg_epoch_loss=1.902457\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=321, batch=10 train loss <loss>=1.8587076187133789\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] Epoch[321] Batch [10]#011Speed: 2109.67 samples/sec#011loss=1.858708\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747861474.0088756, \"EndTime\": 1747861474.9424691, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.5370063781738, \"count\": 1, \"min\": 933.5370063781738, \"max\": 933.5370063781738}}}\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1397.7782198495622 records/second\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] #progress_metric: host=algo-1, completed 80.5 % of epochs\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=321, train loss <loss>=1.9024565003134988\n",
      "[05/21/2025 21:04:34 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:35 INFO 140363140085568] Epoch[322] Batch[0] avg_epoch_loss=1.954307\n",
      "[05/21/2025 21:04:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=322, batch=0 train loss <loss>=1.9543068408966064\n",
      "[05/21/2025 21:04:35 INFO 140363140085568] Epoch[322] Batch[5] avg_epoch_loss=2.058418\n",
      "[05/21/2025 21:04:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=322, batch=5 train loss <loss>=2.0584184924761453\n",
      "[05/21/2025 21:04:35 INFO 140363140085568] Epoch[322] Batch [5]#011Speed: 2124.72 samples/sec#011loss=2.058418\n",
      "[05/21/2025 21:04:35 INFO 140363140085568] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747861474.9425273, \"EndTime\": 1747861475.8124352, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 869.6527481079102, \"count\": 1, \"min\": 869.6527481079102, \"max\": 869.6527481079102}}}\n",
      "[05/21/2025 21:04:35 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1449.8382935330408 records/second\n",
      "[05/21/2025 21:04:35 INFO 140363140085568] #progress_metric: host=algo-1, completed 80.75 % of epochs\n",
      "[05/21/2025 21:04:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=322, train loss <loss>=2.040384566783905\n",
      "[05/21/2025 21:04:35 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:36 INFO 140363140085568] Epoch[323] Batch[0] avg_epoch_loss=1.900108\n",
      "[05/21/2025 21:04:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=323, batch=0 train loss <loss>=1.900107979774475\n",
      "[05/21/2025 21:04:36 INFO 140363140085568] Epoch[323] Batch[5] avg_epoch_loss=1.981624\n",
      "[05/21/2025 21:04:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=323, batch=5 train loss <loss>=1.9816240668296814\n",
      "[05/21/2025 21:04:36 INFO 140363140085568] Epoch[323] Batch [5]#011Speed: 1967.96 samples/sec#011loss=1.981624\n",
      "[05/21/2025 21:04:36 INFO 140363140085568] processed a total of 1277 examples\n",
      "#metrics {\"StartTime\": 1747861475.8125029, \"EndTime\": 1747861476.711554, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 898.6937999725342, \"count\": 1, \"min\": 898.6937999725342, \"max\": 898.6937999725342}}}\n",
      "[05/21/2025 21:04:36 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1420.7958677990678 records/second\n",
      "[05/21/2025 21:04:36 INFO 140363140085568] #progress_metric: host=algo-1, completed 81.0 % of epochs\n",
      "[05/21/2025 21:04:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=323, train loss <loss>=1.9645956039428711\n",
      "[05/21/2025 21:04:36 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] Epoch[324] Batch[0] avg_epoch_loss=1.901634\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=324, batch=0 train loss <loss>=1.901633620262146\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] Epoch[324] Batch[5] avg_epoch_loss=1.905581\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=324, batch=5 train loss <loss>=1.90558127562205\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] Epoch[324] Batch [5]#011Speed: 2034.90 samples/sec#011loss=1.905581\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] processed a total of 1268 examples\n",
      "#metrics {\"StartTime\": 1747861476.7116206, \"EndTime\": 1747861477.5931973, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 881.2181949615479, \"count\": 1, \"min\": 881.2181949615479, \"max\": 881.2181949615479}}}\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1438.7606954580538 records/second\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] #progress_metric: host=algo-1, completed 81.25 % of epochs\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=324, train loss <loss>=1.911739456653595\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] Epoch[325] Batch[0] avg_epoch_loss=1.900893\n",
      "[05/21/2025 21:04:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=325, batch=0 train loss <loss>=1.9008928537368774\n",
      "[05/21/2025 21:04:38 INFO 140363140085568] Epoch[325] Batch[5] avg_epoch_loss=1.888923\n",
      "[05/21/2025 21:04:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=325, batch=5 train loss <loss>=1.8889228105545044\n",
      "[05/21/2025 21:04:38 INFO 140363140085568] Epoch[325] Batch [5]#011Speed: 2083.22 samples/sec#011loss=1.888923\n",
      "[05/21/2025 21:04:38 INFO 140363140085568] processed a total of 1269 examples\n",
      "#metrics {\"StartTime\": 1747861477.5932636, \"EndTime\": 1747861478.47695, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 883.389949798584, \"count\": 1, \"min\": 883.389949798584, \"max\": 883.389949798584}}}\n",
      "[05/21/2025 21:04:38 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1436.3558627895882 records/second\n",
      "[05/21/2025 21:04:38 INFO 140363140085568] #progress_metric: host=algo-1, completed 81.5 % of epochs\n",
      "[05/21/2025 21:04:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=325, train loss <loss>=1.9047080636024476\n",
      "[05/21/2025 21:04:38 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:38 INFO 140363140085568] Epoch[326] Batch[0] avg_epoch_loss=1.897983\n",
      "[05/21/2025 21:04:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=326, batch=0 train loss <loss>=1.8979829549789429\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] Epoch[326] Batch[5] avg_epoch_loss=1.906901\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=326, batch=5 train loss <loss>=1.906901478767395\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] Epoch[326] Batch [5]#011Speed: 2092.12 samples/sec#011loss=1.906901\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] Epoch[326] Batch[10] avg_epoch_loss=1.948723\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=326, batch=10 train loss <loss>=1.9989093542099\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] Epoch[326] Batch [10]#011Speed: 2028.06 samples/sec#011loss=1.998909\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747861478.4770153, \"EndTime\": 1747861479.4217532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.4186687469482, \"count\": 1, \"min\": 944.4186687469482, \"max\": 944.4186687469482}}}\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1388.0304366791063 records/second\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] #progress_metric: host=algo-1, completed 81.75 % of epochs\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=326, train loss <loss>=1.94872324033217\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] Epoch[327] Batch[0] avg_epoch_loss=1.899842\n",
      "[05/21/2025 21:04:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=327, batch=0 train loss <loss>=1.8998420238494873\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] Epoch[327] Batch[5] avg_epoch_loss=1.900384\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=327, batch=5 train loss <loss>=1.9003836313883464\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] Epoch[327] Batch [5]#011Speed: 2182.59 samples/sec#011loss=1.900384\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] Epoch[327] Batch[10] avg_epoch_loss=1.974092\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=327, batch=10 train loss <loss>=2.062541437149048\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] Epoch[327] Batch [10]#011Speed: 1989.20 samples/sec#011loss=2.062541\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747861479.4218104, \"EndTime\": 1747861480.3553402, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.2892894744873, \"count\": 1, \"min\": 933.2892894744873, \"max\": 933.2892894744873}}}\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1417.4361770280418 records/second\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] #progress_metric: host=algo-1, completed 82.0 % of epochs\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=327, train loss <loss>=1.974091724915938\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] Epoch[328] Batch[0] avg_epoch_loss=1.978096\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=328, batch=0 train loss <loss>=1.9780960083007812\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] Epoch[328] Batch[5] avg_epoch_loss=2.006286\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=328, batch=5 train loss <loss>=2.0062862237294516\n",
      "[05/21/2025 21:04:40 INFO 140363140085568] Epoch[328] Batch [5]#011Speed: 2040.25 samples/sec#011loss=2.006286\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] Epoch[328] Batch[10] avg_epoch_loss=1.987757\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=328, batch=10 train loss <loss>=1.9655223846435548\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] Epoch[328] Batch [10]#011Speed: 1939.28 samples/sec#011loss=1.965522\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747861480.3553984, \"EndTime\": 1747861481.3215342, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 965.8834934234619, \"count\": 1, \"min\": 965.8834934234619, \"max\": 965.8834934234619}}}\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1364.4059582668583 records/second\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] #progress_metric: host=algo-1, completed 82.25 % of epochs\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=328, train loss <loss>=1.9877572059631348\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] Epoch[329] Batch[0] avg_epoch_loss=2.011566\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=329, batch=0 train loss <loss>=2.011566400527954\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] Epoch[329] Batch[5] avg_epoch_loss=1.956880\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=329, batch=5 train loss <loss>=1.9568803707758586\n",
      "[05/21/2025 21:04:41 INFO 140363140085568] Epoch[329] Batch [5]#011Speed: 2059.66 samples/sec#011loss=1.956880\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] Epoch[329] Batch[10] avg_epoch_loss=1.904841\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=329, batch=10 train loss <loss>=1.842392659187317\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] Epoch[329] Batch [10]#011Speed: 1944.48 samples/sec#011loss=1.842393\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747861481.3216064, \"EndTime\": 1747861482.2843714, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 962.4001979827881, \"count\": 1, \"min\": 962.4001979827881, \"max\": 962.4001979827881}}}\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1385.9601561335012 records/second\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] #progress_metric: host=algo-1, completed 82.5 % of epochs\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=329, train loss <loss>=1.904840501871976\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] Epoch[330] Batch[0] avg_epoch_loss=1.987874\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=330, batch=0 train loss <loss>=1.9878742694854736\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] Epoch[330] Batch[5] avg_epoch_loss=1.949047\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=330, batch=5 train loss <loss>=1.9490468502044678\n",
      "[05/21/2025 21:04:42 INFO 140363140085568] Epoch[330] Batch [5]#011Speed: 2087.64 samples/sec#011loss=1.949047\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] Epoch[330] Batch[10] avg_epoch_loss=1.937078\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=330, batch=10 train loss <loss>=1.922715973854065\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] Epoch[330] Batch [10]#011Speed: 2030.12 samples/sec#011loss=1.922716\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747861482.2844477, \"EndTime\": 1747861483.2322166, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.4835395812988, \"count\": 1, \"min\": 947.4835395812988, \"max\": 947.4835395812988}}}\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1358.2115637725994 records/second\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] #progress_metric: host=algo-1, completed 82.75 % of epochs\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=330, train loss <loss>=1.9370782700451938\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] Epoch[331] Batch[0] avg_epoch_loss=1.908667\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=331, batch=0 train loss <loss>=1.9086674451828003\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] Epoch[331] Batch[5] avg_epoch_loss=1.981322\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=331, batch=5 train loss <loss>=1.9813217520713806\n",
      "[05/21/2025 21:04:43 INFO 140363140085568] Epoch[331] Batch [5]#011Speed: 2102.61 samples/sec#011loss=1.981322\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] Epoch[331] Batch[10] avg_epoch_loss=2.010417\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=331, batch=10 train loss <loss>=2.0453305721282957\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] Epoch[331] Batch [10]#011Speed: 2006.11 samples/sec#011loss=2.045331\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747861483.2322743, \"EndTime\": 1747861484.1806264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.0812549591064, \"count\": 1, \"min\": 948.0812549591064, \"max\": 948.0812549591064}}}\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1380.5333694747237 records/second\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] #progress_metric: host=algo-1, completed 83.0 % of epochs\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=331, train loss <loss>=2.0104166702790693\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] Epoch[332] Batch[0] avg_epoch_loss=2.013200\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=332, batch=0 train loss <loss>=2.013200283050537\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] Epoch[332] Batch[5] avg_epoch_loss=2.010849\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=332, batch=5 train loss <loss>=2.010849177837372\n",
      "[05/21/2025 21:04:44 INFO 140363140085568] Epoch[332] Batch [5]#011Speed: 2118.72 samples/sec#011loss=2.010849\n",
      "[05/21/2025 21:04:45 INFO 140363140085568] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747861484.1807003, \"EndTime\": 1747861485.0545046, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 873.5013008117676, \"count\": 1, \"min\": 873.5013008117676, \"max\": 873.5013008117676}}}\n",
      "[05/21/2025 21:04:45 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1449.1813510983507 records/second\n",
      "[05/21/2025 21:04:45 INFO 140363140085568] #progress_metric: host=algo-1, completed 83.25 % of epochs\n",
      "[05/21/2025 21:04:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=332, train loss <loss>=2.0219324231147766\n",
      "[05/21/2025 21:04:45 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:45 INFO 140363140085568] Epoch[333] Batch[0] avg_epoch_loss=2.054233\n",
      "[05/21/2025 21:04:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=333, batch=0 train loss <loss>=2.054232597351074\n",
      "[05/21/2025 21:04:45 INFO 140363140085568] Epoch[333] Batch[5] avg_epoch_loss=1.952884\n",
      "[05/21/2025 21:04:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=333, batch=5 train loss <loss>=1.9528836806615193\n",
      "[05/21/2025 21:04:45 INFO 140363140085568] Epoch[333] Batch [5]#011Speed: 2039.08 samples/sec#011loss=1.952884\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] Epoch[333] Batch[10] avg_epoch_loss=1.948405\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=333, batch=10 train loss <loss>=1.9430304527282716\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] Epoch[333] Batch [10]#011Speed: 1958.03 samples/sec#011loss=1.943030\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747861485.0545676, \"EndTime\": 1747861486.0157225, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.8707427978516, \"count\": 1, \"min\": 960.8707427978516, \"max\": 960.8707427978516}}}\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1400.6866025876884 records/second\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] #progress_metric: host=algo-1, completed 83.5 % of epochs\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=333, train loss <loss>=1.9484049406918613\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] Epoch[334] Batch[0] avg_epoch_loss=1.917314\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=334, batch=0 train loss <loss>=1.9173142910003662\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] Epoch[334] Batch[5] avg_epoch_loss=1.941003\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=334, batch=5 train loss <loss>=1.9410027066866558\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] Epoch[334] Batch [5]#011Speed: 2054.17 samples/sec#011loss=1.941003\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] processed a total of 1242 examples\n",
      "#metrics {\"StartTime\": 1747861486.0157819, \"EndTime\": 1747861486.8931744, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 877.1438598632812, \"count\": 1, \"min\": 877.1438598632812, \"max\": 877.1438598632812}}}\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1415.8026664564884 records/second\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] #progress_metric: host=algo-1, completed 83.75 % of epochs\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=334, train loss <loss>=1.928511095046997\n",
      "[05/21/2025 21:04:46 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] Epoch[335] Batch[0] avg_epoch_loss=1.947672\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=335, batch=0 train loss <loss>=1.9476722478866577\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] Epoch[335] Batch[5] avg_epoch_loss=1.902815\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=335, batch=5 train loss <loss>=1.9028146862983704\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] Epoch[335] Batch [5]#011Speed: 2085.98 samples/sec#011loss=1.902815\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] processed a total of 1246 examples\n",
      "#metrics {\"StartTime\": 1747861486.8932416, \"EndTime\": 1747861487.7928872, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 899.3029594421387, \"count\": 1, \"min\": 899.3029594421387, \"max\": 899.3029594421387}}}\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1385.3717020199892 records/second\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] #progress_metric: host=algo-1, completed 84.0 % of epochs\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=335, train loss <loss>=1.8740897536277772\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:04:47 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_e7a0d3f8-6b76-4138-8797-79e3a1aea028-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861487.792952, \"EndTime\": 1747861487.8039684, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.706663131713867, \"count\": 1, \"min\": 10.706663131713867, \"max\": 10.706663131713867}}}\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] Epoch[336] Batch[0] avg_epoch_loss=1.828786\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=336, batch=0 train loss <loss>=1.8287864923477173\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] Epoch[336] Batch[5] avg_epoch_loss=1.872715\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=336, batch=5 train loss <loss>=1.8727152943611145\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] Epoch[336] Batch [5]#011Speed: 2144.24 samples/sec#011loss=1.872715\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] Epoch[336] Batch[10] avg_epoch_loss=1.907182\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=336, batch=10 train loss <loss>=1.9485416173934937\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] Epoch[336] Batch [10]#011Speed: 2007.66 samples/sec#011loss=1.948542\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747861487.8040156, \"EndTime\": 1747861488.7421389, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.077449798584, \"count\": 1, \"min\": 938.077449798584, \"max\": 938.077449798584}}}\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1422.9888938981244 records/second\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] #progress_metric: host=algo-1, completed 84.25 % of epochs\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=336, train loss <loss>=1.9071818048303777\n",
      "[05/21/2025 21:04:48 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] Epoch[337] Batch[0] avg_epoch_loss=1.917389\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=337, batch=0 train loss <loss>=1.9173885583877563\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] Epoch[337] Batch[5] avg_epoch_loss=1.937892\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=337, batch=5 train loss <loss>=1.9378917614618938\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] Epoch[337] Batch [5]#011Speed: 2123.87 samples/sec#011loss=1.937892\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] Epoch[337] Batch[10] avg_epoch_loss=1.975394\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=337, batch=10 train loss <loss>=2.0203966379165648\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] Epoch[337] Batch [10]#011Speed: 1872.95 samples/sec#011loss=2.020397\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747861488.7422001, \"EndTime\": 1747861489.7087672, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 966.3188457489014, \"count\": 1, \"min\": 966.3188457489014, \"max\": 966.3188457489014}}}\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1396.8917285698533 records/second\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] #progress_metric: host=algo-1, completed 84.5 % of epochs\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] #quality_metric: host=algo-1, epoch=337, train loss <loss>=1.9753939780321987\n",
      "[05/21/2025 21:04:49 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] Epoch[338] Batch[0] avg_epoch_loss=1.881185\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=338, batch=0 train loss <loss>=1.8811854124069214\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] Epoch[338] Batch[5] avg_epoch_loss=1.892450\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=338, batch=5 train loss <loss>=1.8924502929051716\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] Epoch[338] Batch [5]#011Speed: 2148.57 samples/sec#011loss=1.892450\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] Epoch[338] Batch[10] avg_epoch_loss=1.955422\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=338, batch=10 train loss <loss>=2.030987334251404\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] Epoch[338] Batch [10]#011Speed: 2086.35 samples/sec#011loss=2.030987\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747861489.708849, \"EndTime\": 1747861490.6398897, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.6693077087402, \"count\": 1, \"min\": 930.6693077087402, \"max\": 930.6693077087402}}}\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1414.9768391899443 records/second\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] #progress_metric: host=algo-1, completed 84.75 % of epochs\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=338, train loss <loss>=1.955421675335277\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] Epoch[339] Batch[0] avg_epoch_loss=2.003933\n",
      "[05/21/2025 21:04:50 INFO 140363140085568] #quality_metric: host=algo-1, epoch=339, batch=0 train loss <loss>=2.0039334297180176\n",
      "[05/21/2025 21:04:51 INFO 140363140085568] Epoch[339] Batch[5] avg_epoch_loss=1.924089\n",
      "[05/21/2025 21:04:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=339, batch=5 train loss <loss>=1.924088756243388\n",
      "[05/21/2025 21:04:51 INFO 140363140085568] Epoch[339] Batch [5]#011Speed: 2162.86 samples/sec#011loss=1.924089\n",
      "[05/21/2025 21:04:51 INFO 140363140085568] processed a total of 1253 examples\n",
      "#metrics {\"StartTime\": 1747861490.639949, \"EndTime\": 1747861491.5125668, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 872.3447322845459, \"count\": 1, \"min\": 872.3447322845459, \"max\": 872.3447322845459}}}\n",
      "[05/21/2025 21:04:51 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1436.1978275014628 records/second\n",
      "[05/21/2025 21:04:51 INFO 140363140085568] #progress_metric: host=algo-1, completed 85.0 % of epochs\n",
      "[05/21/2025 21:04:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=339, train loss <loss>=1.9179710268974304\n",
      "[05/21/2025 21:04:51 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:51 INFO 140363140085568] Epoch[340] Batch[0] avg_epoch_loss=1.928961\n",
      "[05/21/2025 21:04:51 INFO 140363140085568] #quality_metric: host=algo-1, epoch=340, batch=0 train loss <loss>=1.928961157798767\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] Epoch[340] Batch[5] avg_epoch_loss=1.914781\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=340, batch=5 train loss <loss>=1.9147812525431316\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] Epoch[340] Batch [5]#011Speed: 2076.90 samples/sec#011loss=1.914781\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] Epoch[340] Batch[10] avg_epoch_loss=1.965665\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=340, batch=10 train loss <loss>=2.026725506782532\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] Epoch[340] Batch [10]#011Speed: 2060.30 samples/sec#011loss=2.026726\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747861491.5126336, \"EndTime\": 1747861492.4585326, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.5301761627197, \"count\": 1, \"min\": 945.5301761627197, \"max\": 945.5301761627197}}}\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1398.0340049180688 records/second\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] #progress_metric: host=algo-1, completed 85.25 % of epochs\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=340, train loss <loss>=1.9656650044701316\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] Epoch[341] Batch[0] avg_epoch_loss=1.912753\n",
      "[05/21/2025 21:04:52 INFO 140363140085568] #quality_metric: host=algo-1, epoch=341, batch=0 train loss <loss>=1.9127529859542847\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] Epoch[341] Batch[5] avg_epoch_loss=1.921024\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=341, batch=5 train loss <loss>=1.921024481455485\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] Epoch[341] Batch [5]#011Speed: 2140.27 samples/sec#011loss=1.921024\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] Epoch[341] Batch[10] avg_epoch_loss=1.948627\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=341, batch=10 train loss <loss>=1.9817508697509765\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] Epoch[341] Batch [10]#011Speed: 2061.61 samples/sec#011loss=1.981751\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747861492.4585888, \"EndTime\": 1747861493.3923163, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.4671497344971, \"count\": 1, \"min\": 933.4671497344971, \"max\": 933.4671497344971}}}\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1410.7070055252004 records/second\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] #progress_metric: host=algo-1, completed 85.5 % of epochs\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=341, train loss <loss>=1.948627385226163\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] Epoch[342] Batch[0] avg_epoch_loss=2.064143\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] #quality_metric: host=algo-1, epoch=342, batch=0 train loss <loss>=2.064143419265747\n",
      "[05/21/2025 21:04:53 INFO 140363140085568] Epoch[342] Batch[5] avg_epoch_loss=1.960734\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=342, batch=5 train loss <loss>=1.9607337514559429\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] Epoch[342] Batch [5]#011Speed: 2179.29 samples/sec#011loss=1.960734\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] Epoch[342] Batch[10] avg_epoch_loss=1.971649\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=342, batch=10 train loss <loss>=1.9847470045089721\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] Epoch[342] Batch [10]#011Speed: 2021.40 samples/sec#011loss=1.984747\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747861493.392395, \"EndTime\": 1747861494.3170564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.405574798584, \"count\": 1, \"min\": 924.405574798584, \"max\": 924.405574798584}}}\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1468.9097037508118 records/second\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] #progress_metric: host=algo-1, completed 85.75 % of epochs\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=342, train loss <loss>=1.9716488664800471\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] Epoch[343] Batch[0] avg_epoch_loss=1.931187\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=343, batch=0 train loss <loss>=1.9311872720718384\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] Epoch[343] Batch[5] avg_epoch_loss=1.948774\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] #quality_metric: host=algo-1, epoch=343, batch=5 train loss <loss>=1.9487741192181904\n",
      "[05/21/2025 21:04:54 INFO 140363140085568] Epoch[343] Batch [5]#011Speed: 2076.78 samples/sec#011loss=1.948774\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] Epoch[343] Batch[10] avg_epoch_loss=1.839761\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=343, batch=10 train loss <loss>=1.70894535779953\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] Epoch[343] Batch [10]#011Speed: 2118.50 samples/sec#011loss=1.708945\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747861494.3171172, \"EndTime\": 1747861495.253304, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.9352588653564, \"count\": 1, \"min\": 935.9352588653564, \"max\": 935.9352588653564}}}\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1370.698404895224 records/second\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] #progress_metric: host=algo-1, completed 86.0 % of epochs\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=343, train loss <loss>=1.839761045846072\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_13c68fcd-1542-471b-b84a-472fdb310e7f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861495.2533603, \"EndTime\": 1747861495.2643244, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.699272155761719, \"count\": 1, \"min\": 10.699272155761719, \"max\": 10.699272155761719}}}\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] Epoch[344] Batch[0] avg_epoch_loss=1.972923\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=344, batch=0 train loss <loss>=1.9729232788085938\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] Epoch[344] Batch[5] avg_epoch_loss=1.956865\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] #quality_metric: host=algo-1, epoch=344, batch=5 train loss <loss>=1.9568650325139363\n",
      "[05/21/2025 21:04:55 INFO 140363140085568] Epoch[344] Batch [5]#011Speed: 2053.74 samples/sec#011loss=1.956865\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] Epoch[344] Batch[10] avg_epoch_loss=1.870596\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=344, batch=10 train loss <loss>=1.767073965072632\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] Epoch[344] Batch [10]#011Speed: 2046.59 samples/sec#011loss=1.767074\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747861495.2643983, \"EndTime\": 1747861496.2079136, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.4661865234375, \"count\": 1, \"min\": 943.4661865234375, \"max\": 943.4661865234375}}}\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1419.1009898278155 records/second\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] #progress_metric: host=algo-1, completed 86.25 % of epochs\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=344, train loss <loss>=1.8705963654951616\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] Epoch[345] Batch[0] avg_epoch_loss=1.978945\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=345, batch=0 train loss <loss>=1.978945016860962\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] Epoch[345] Batch[5] avg_epoch_loss=1.901606\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] #quality_metric: host=algo-1, epoch=345, batch=5 train loss <loss>=1.9016055067380269\n",
      "[05/21/2025 21:04:56 INFO 140363140085568] Epoch[345] Batch [5]#011Speed: 2151.28 samples/sec#011loss=1.901606\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] Epoch[345] Batch[10] avg_epoch_loss=1.917296\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=345, batch=10 train loss <loss>=1.9361238718032836\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] Epoch[345] Batch [10]#011Speed: 2080.37 samples/sec#011loss=1.936124\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747861496.207975, \"EndTime\": 1747861497.1377451, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.5244216918945, \"count\": 1, \"min\": 929.5244216918945, \"max\": 929.5244216918945}}}\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1394.1290694877096 records/second\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] #progress_metric: host=algo-1, completed 86.5 % of epochs\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=345, train loss <loss>=1.91729567267678\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] Epoch[346] Batch[0] avg_epoch_loss=1.922617\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=346, batch=0 train loss <loss>=1.922616958618164\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] Epoch[346] Batch[5] avg_epoch_loss=1.951914\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] #quality_metric: host=algo-1, epoch=346, batch=5 train loss <loss>=1.9519137144088745\n",
      "[05/21/2025 21:04:57 INFO 140363140085568] Epoch[346] Batch [5]#011Speed: 2001.94 samples/sec#011loss=1.951914\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] Epoch[346] Batch[10] avg_epoch_loss=1.944306\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=346, batch=10 train loss <loss>=1.9351758718490601\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] Epoch[346] Batch [10]#011Speed: 2100.99 samples/sec#011loss=1.935176\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747861497.137805, \"EndTime\": 1747861498.0854685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.385311126709, \"count\": 1, \"min\": 947.385311126709, \"max\": 947.385311126709}}}\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1372.0703443968544 records/second\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] #progress_metric: host=algo-1, completed 86.75 % of epochs\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=346, train loss <loss>=1.9443056041544133\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] Epoch[347] Batch[0] avg_epoch_loss=1.836248\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=347, batch=0 train loss <loss>=1.8362479209899902\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] Epoch[347] Batch[5] avg_epoch_loss=1.889283\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] #quality_metric: host=algo-1, epoch=347, batch=5 train loss <loss>=1.8892827431360881\n",
      "[05/21/2025 21:04:58 INFO 140363140085568] Epoch[347] Batch [5]#011Speed: 2142.84 samples/sec#011loss=1.889283\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] Epoch[347] Batch[10] avg_epoch_loss=1.879459\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=347, batch=10 train loss <loss>=1.8676697969436646\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] Epoch[347] Batch [10]#011Speed: 2077.32 samples/sec#011loss=1.867670\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747861498.0855284, \"EndTime\": 1747861499.0170474, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.2143325805664, \"count\": 1, \"min\": 931.2143325805664, \"max\": 931.2143325805664}}}\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1442.070709961768 records/second\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] #progress_metric: host=algo-1, completed 87.0 % of epochs\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=347, train loss <loss>=1.8794586766849866\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] Epoch[348] Batch[0] avg_epoch_loss=1.900363\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=348, batch=0 train loss <loss>=1.9003626108169556\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] Epoch[348] Batch[5] avg_epoch_loss=1.885583\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=348, batch=5 train loss <loss>=1.88558296362559\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] Epoch[348] Batch [5]#011Speed: 2087.53 samples/sec#011loss=1.885583\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] Epoch[348] Batch[10] avg_epoch_loss=1.820599\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=348, batch=10 train loss <loss>=1.7426185131072998\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] Epoch[348] Batch [10]#011Speed: 2038.42 samples/sec#011loss=1.742619\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747861499.017104, \"EndTime\": 1747861499.9592168, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.8656826019287, \"count\": 1, \"min\": 941.8656826019287, \"max\": 941.8656826019287}}}\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1416.1510668713072 records/second\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] #progress_metric: host=algo-1, completed 87.25 % of epochs\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] #quality_metric: host=algo-1, epoch=348, train loss <loss>=1.8205991224809126\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:04:59 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_eb86a5cb-4c04-4f04-a1a7-62f63baaf062-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861499.9593132, \"EndTime\": 1747861499.9703696, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.783195495605469, \"count\": 1, \"min\": 10.783195495605469, \"max\": 10.783195495605469}}}\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] Epoch[349] Batch[0] avg_epoch_loss=1.913715\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=349, batch=0 train loss <loss>=1.9137154817581177\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] Epoch[349] Batch[5] avg_epoch_loss=1.928880\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=349, batch=5 train loss <loss>=1.9288795391718547\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] Epoch[349] Batch [5]#011Speed: 2178.32 samples/sec#011loss=1.928880\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] Epoch[349] Batch[10] avg_epoch_loss=1.923810\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=349, batch=10 train loss <loss>=1.9177262306213378\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] Epoch[349] Batch [10]#011Speed: 1979.41 samples/sec#011loss=1.917726\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747861499.9704175, \"EndTime\": 1747861500.9117908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.3230419158936, \"count\": 1, \"min\": 941.3230419158936, \"max\": 941.3230419158936}}}\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1362.828195463682 records/second\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] #progress_metric: host=algo-1, completed 87.5 % of epochs\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] #quality_metric: host=algo-1, epoch=349, train loss <loss>=1.9238098534670742\n",
      "[05/21/2025 21:05:00 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:01 INFO 140363140085568] Epoch[350] Batch[0] avg_epoch_loss=1.852510\n",
      "[05/21/2025 21:05:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=350, batch=0 train loss <loss>=1.8525100946426392\n",
      "[05/21/2025 21:05:01 INFO 140363140085568] Epoch[350] Batch[5] avg_epoch_loss=1.881411\n",
      "[05/21/2025 21:05:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=350, batch=5 train loss <loss>=1.8814106186230977\n",
      "[05/21/2025 21:05:01 INFO 140363140085568] Epoch[350] Batch [5]#011Speed: 1792.82 samples/sec#011loss=1.881411\n",
      "[05/21/2025 21:05:01 INFO 140363140085568] processed a total of 1268 examples\n",
      "#metrics {\"StartTime\": 1747861500.9118617, \"EndTime\": 1747861501.8794024, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 967.0922756195068, \"count\": 1, \"min\": 967.0922756195068, \"max\": 967.0922756195068}}}\n",
      "[05/21/2025 21:05:01 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1311.0094973653488 records/second\n",
      "[05/21/2025 21:05:01 INFO 140363140085568] #progress_metric: host=algo-1, completed 87.75 % of epochs\n",
      "[05/21/2025 21:05:01 INFO 140363140085568] #quality_metric: host=algo-1, epoch=350, train loss <loss>=1.8727855682373047\n",
      "[05/21/2025 21:05:01 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] Epoch[351] Batch[0] avg_epoch_loss=1.944534\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=351, batch=0 train loss <loss>=1.944534420967102\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] Epoch[351] Batch[5] avg_epoch_loss=1.874927\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=351, batch=5 train loss <loss>=1.8749271631240845\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] Epoch[351] Batch [5]#011Speed: 2103.29 samples/sec#011loss=1.874927\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] Epoch[351] Batch[10] avg_epoch_loss=1.834966\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=351, batch=10 train loss <loss>=1.7870125770568848\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] Epoch[351] Batch [10]#011Speed: 1921.99 samples/sec#011loss=1.787013\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747861501.8794699, \"EndTime\": 1747861502.844976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 965.0847911834717, \"count\": 1, \"min\": 965.0847911834717, \"max\": 965.0847911834717}}}\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1399.7452483054365 records/second\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] #progress_metric: host=algo-1, completed 88.0 % of epochs\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] #quality_metric: host=algo-1, epoch=351, train loss <loss>=1.8349659876389937\n",
      "[05/21/2025 21:05:02 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] Epoch[352] Batch[0] avg_epoch_loss=1.860674\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=352, batch=0 train loss <loss>=1.8606736660003662\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] Epoch[352] Batch[5] avg_epoch_loss=1.850881\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=352, batch=5 train loss <loss>=1.850880742073059\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] Epoch[352] Batch [5]#011Speed: 2001.28 samples/sec#011loss=1.850881\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] Epoch[352] Batch[10] avg_epoch_loss=1.920041\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=352, batch=10 train loss <loss>=2.003032684326172\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] Epoch[352] Batch [10]#011Speed: 2029.35 samples/sec#011loss=2.003033\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747861502.845036, \"EndTime\": 1747861503.8047867, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 959.4929218292236, \"count\": 1, \"min\": 959.4929218292236, \"max\": 959.4929218292236}}}\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1401.6549715884387 records/second\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] #progress_metric: host=algo-1, completed 88.25 % of epochs\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] #quality_metric: host=algo-1, epoch=352, train loss <loss>=1.9200407158244739\n",
      "[05/21/2025 21:05:03 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] Epoch[353] Batch[0] avg_epoch_loss=1.745010\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=353, batch=0 train loss <loss>=1.745010256767273\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] Epoch[353] Batch[5] avg_epoch_loss=1.872567\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=353, batch=5 train loss <loss>=1.872566819190979\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] Epoch[353] Batch [5]#011Speed: 2141.37 samples/sec#011loss=1.872567\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] Epoch[353] Batch[10] avg_epoch_loss=1.896335\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=353, batch=10 train loss <loss>=1.9248568296432496\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] Epoch[353] Batch [10]#011Speed: 1988.13 samples/sec#011loss=1.924857\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747861503.8048446, \"EndTime\": 1747861504.7481482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.9764747619629, \"count\": 1, \"min\": 942.9764747619629, \"max\": 942.9764747619629}}}\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1437.8584008824128 records/second\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] #progress_metric: host=algo-1, completed 88.5 % of epochs\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] #quality_metric: host=algo-1, epoch=353, train loss <loss>=1.8963350057601929\n",
      "[05/21/2025 21:05:04 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] Epoch[354] Batch[0] avg_epoch_loss=1.894773\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=354, batch=0 train loss <loss>=1.8947725296020508\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] Epoch[354] Batch[5] avg_epoch_loss=1.877621\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=354, batch=5 train loss <loss>=1.8776211341222127\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] Epoch[354] Batch [5]#011Speed: 2060.15 samples/sec#011loss=1.877621\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] Epoch[354] Batch[10] avg_epoch_loss=1.915939\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=354, batch=10 train loss <loss>=1.9619211435317994\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] Epoch[354] Batch [10]#011Speed: 1942.39 samples/sec#011loss=1.961921\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] processed a total of 1364 examples\n",
      "#metrics {\"StartTime\": 1747861504.7482107, \"EndTime\": 1747861505.7091932, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.5941772460938, \"count\": 1, \"min\": 960.5941772460938, \"max\": 960.5941772460938}}}\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1419.805411511803 records/second\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] #progress_metric: host=algo-1, completed 88.75 % of epochs\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] #quality_metric: host=algo-1, epoch=354, train loss <loss>=1.9159393202174793\n",
      "[05/21/2025 21:05:05 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] Epoch[355] Batch[0] avg_epoch_loss=1.880084\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=355, batch=0 train loss <loss>=1.8800835609436035\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] Epoch[355] Batch[5] avg_epoch_loss=1.826453\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=355, batch=5 train loss <loss>=1.8264533281326294\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] Epoch[355] Batch [5]#011Speed: 2112.54 samples/sec#011loss=1.826453\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] Epoch[355] Batch[10] avg_epoch_loss=1.884164\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=355, batch=10 train loss <loss>=1.9534170866012572\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] Epoch[355] Batch [10]#011Speed: 1965.58 samples/sec#011loss=1.953417\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747861505.7092621, \"EndTime\": 1747861506.6612277, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.6079425811768, \"count\": 1, \"min\": 951.6079425811768, \"max\": 951.6079425811768}}}\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1391.1954419614417 records/second\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] #progress_metric: host=algo-1, completed 89.0 % of epochs\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=355, train loss <loss>=1.8841641274365513\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] Epoch[356] Batch[0] avg_epoch_loss=1.824759\n",
      "[05/21/2025 21:05:06 INFO 140363140085568] #quality_metric: host=algo-1, epoch=356, batch=0 train loss <loss>=1.8247592449188232\n",
      "[05/21/2025 21:05:07 INFO 140363140085568] Epoch[356] Batch[5] avg_epoch_loss=1.850139\n",
      "[05/21/2025 21:05:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=356, batch=5 train loss <loss>=1.8501386642456055\n",
      "[05/21/2025 21:05:07 INFO 140363140085568] Epoch[356] Batch [5]#011Speed: 2004.95 samples/sec#011loss=1.850139\n",
      "[05/21/2025 21:05:07 INFO 140363140085568] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747861506.6612883, \"EndTime\": 1747861507.5587084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.0723152160645, \"count\": 1, \"min\": 897.0723152160645, \"max\": 897.0723152160645}}}\n",
      "[05/21/2025 21:05:07 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1421.1412845323982 records/second\n",
      "[05/21/2025 21:05:07 INFO 140363140085568] #progress_metric: host=algo-1, completed 89.25 % of epochs\n",
      "[05/21/2025 21:05:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=356, train loss <loss>=1.8834273219108582\n",
      "[05/21/2025 21:05:07 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:07 INFO 140363140085568] Epoch[357] Batch[0] avg_epoch_loss=1.876534\n",
      "[05/21/2025 21:05:07 INFO 140363140085568] #quality_metric: host=algo-1, epoch=357, batch=0 train loss <loss>=1.87653386592865\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] Epoch[357] Batch[5] avg_epoch_loss=1.890224\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=357, batch=5 train loss <loss>=1.890223741531372\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] Epoch[357] Batch [5]#011Speed: 2181.78 samples/sec#011loss=1.890224\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] Epoch[357] Batch[10] avg_epoch_loss=1.929842\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=357, batch=10 train loss <loss>=1.9773837089538575\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] Epoch[357] Batch [10]#011Speed: 2019.03 samples/sec#011loss=1.977384\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747861507.5587716, \"EndTime\": 1747861508.491714, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.1215152740479, \"count\": 1, \"min\": 932.1215152740479, \"max\": 932.1215152740479}}}\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1427.7972271782364 records/second\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] #progress_metric: host=algo-1, completed 89.5 % of epochs\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=357, train loss <loss>=1.9298419085415928\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] Epoch[358] Batch[0] avg_epoch_loss=1.856813\n",
      "[05/21/2025 21:05:08 INFO 140363140085568] #quality_metric: host=algo-1, epoch=358, batch=0 train loss <loss>=1.8568129539489746\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] Epoch[358] Batch[5] avg_epoch_loss=1.871484\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=358, batch=5 train loss <loss>=1.8714838027954102\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] Epoch[358] Batch [5]#011Speed: 2109.57 samples/sec#011loss=1.871484\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] Epoch[358] Batch[10] avg_epoch_loss=1.803334\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=358, batch=10 train loss <loss>=1.7215543031692504\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] Epoch[358] Batch [10]#011Speed: 2068.16 samples/sec#011loss=1.721554\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747861508.49177, \"EndTime\": 1747861509.4301336, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.117504119873, \"count\": 1, \"min\": 938.117504119873, \"max\": 938.117504119873}}}\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1386.6915936869937 records/second\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] #progress_metric: host=algo-1, completed 89.75 % of epochs\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=358, train loss <loss>=1.803334030238065\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_9b3ed7d1-1a34-4545-be37-4395d86839f3-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861509.4301918, \"EndTime\": 1747861509.4411488, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.65516471862793, \"count\": 1, \"min\": 10.65516471862793, \"max\": 10.65516471862793}}}\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] Epoch[359] Batch[0] avg_epoch_loss=1.884354\n",
      "[05/21/2025 21:05:09 INFO 140363140085568] #quality_metric: host=algo-1, epoch=359, batch=0 train loss <loss>=1.8843544721603394\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] Epoch[359] Batch[5] avg_epoch_loss=1.882129\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=359, batch=5 train loss <loss>=1.8821289936701457\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] Epoch[359] Batch [5]#011Speed: 2121.13 samples/sec#011loss=1.882129\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] Epoch[359] Batch[10] avg_epoch_loss=1.895371\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=359, batch=10 train loss <loss>=1.9112611055374145\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] Epoch[359] Batch [10]#011Speed: 2015.03 samples/sec#011loss=1.911261\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747861509.4412024, \"EndTime\": 1747861510.3807733, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.5225048065186, \"count\": 1, \"min\": 939.5225048065186, \"max\": 939.5225048065186}}}\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1439.9587598207668 records/second\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] #progress_metric: host=algo-1, completed 90.0 % of epochs\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=359, train loss <loss>=1.8953708627007224\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] Epoch[360] Batch[0] avg_epoch_loss=1.976518\n",
      "[05/21/2025 21:05:10 INFO 140363140085568] #quality_metric: host=algo-1, epoch=360, batch=0 train loss <loss>=1.976517915725708\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] Epoch[360] Batch[5] avg_epoch_loss=1.924459\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=360, batch=5 train loss <loss>=1.9244587222735088\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] Epoch[360] Batch [5]#011Speed: 2077.90 samples/sec#011loss=1.924459\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] Epoch[360] Batch[10] avg_epoch_loss=1.934822\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=360, batch=10 train loss <loss>=1.947257137298584\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] Epoch[360] Batch [10]#011Speed: 2053.43 samples/sec#011loss=1.947257\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747861510.3808334, \"EndTime\": 1747861511.3203268, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.2170906066895, \"count\": 1, \"min\": 939.2170906066895, \"max\": 939.2170906066895}}}\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1406.332084371667 records/second\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] #progress_metric: host=algo-1, completed 90.25 % of epochs\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=360, train loss <loss>=1.9348216381939976\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] Epoch[361] Batch[0] avg_epoch_loss=1.881796\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=361, batch=0 train loss <loss>=1.8817955255508423\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] Epoch[361] Batch[5] avg_epoch_loss=1.817677\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] #quality_metric: host=algo-1, epoch=361, batch=5 train loss <loss>=1.8176768620808919\n",
      "[05/21/2025 21:05:11 INFO 140363140085568] Epoch[361] Batch [5]#011Speed: 2013.80 samples/sec#011loss=1.817677\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] Epoch[361] Batch[10] avg_epoch_loss=1.853357\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=361, batch=10 train loss <loss>=1.8961724758148193\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] Epoch[361] Batch [10]#011Speed: 2006.49 samples/sec#011loss=1.896172\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747861511.3204029, \"EndTime\": 1747861512.2900493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 969.3586826324463, \"count\": 1, \"min\": 969.3586826324463, \"max\": 969.3586826324463}}}\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1334.773844437247 records/second\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] #progress_metric: host=algo-1, completed 90.5 % of epochs\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=361, train loss <loss>=1.8533566865054043\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] Epoch[362] Batch[0] avg_epoch_loss=1.876878\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=362, batch=0 train loss <loss>=1.876878261566162\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] Epoch[362] Batch[5] avg_epoch_loss=1.948465\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] #quality_metric: host=algo-1, epoch=362, batch=5 train loss <loss>=1.9484646519025166\n",
      "[05/21/2025 21:05:12 INFO 140363140085568] Epoch[362] Batch [5]#011Speed: 1953.28 samples/sec#011loss=1.948465\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] Epoch[362] Batch[10] avg_epoch_loss=1.864870\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=362, batch=10 train loss <loss>=1.764555811882019\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] Epoch[362] Batch [10]#011Speed: 2099.97 samples/sec#011loss=1.764556\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747861512.2901115, \"EndTime\": 1747861513.258072, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 967.6222801208496, \"count\": 1, \"min\": 967.6222801208496, \"max\": 967.6222801208496}}}\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1344.40901963992 records/second\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] #progress_metric: host=algo-1, completed 90.75 % of epochs\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=362, train loss <loss>=1.8648697246204724\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] Epoch[363] Batch[0] avg_epoch_loss=1.908542\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=363, batch=0 train loss <loss>=1.9085420370101929\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] Epoch[363] Batch[5] avg_epoch_loss=1.903268\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] #quality_metric: host=algo-1, epoch=363, batch=5 train loss <loss>=1.9032684564590454\n",
      "[05/21/2025 21:05:13 INFO 140363140085568] Epoch[363] Batch [5]#011Speed: 2111.89 samples/sec#011loss=1.903268\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] Epoch[363] Batch[10] avg_epoch_loss=1.912439\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=363, batch=10 train loss <loss>=1.9234431743621827\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] Epoch[363] Batch [10]#011Speed: 1993.16 samples/sec#011loss=1.923443\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747861513.258132, \"EndTime\": 1747861514.2048378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.4621543884277, \"count\": 1, \"min\": 946.4621543884277, \"max\": 946.4621543884277}}}\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1406.1016396572434 records/second\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] #progress_metric: host=algo-1, completed 91.0 % of epochs\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=363, train loss <loss>=1.9124387827786533\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] Epoch[364] Batch[0] avg_epoch_loss=1.817764\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=364, batch=0 train loss <loss>=1.8177635669708252\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] Epoch[364] Batch[5] avg_epoch_loss=1.876926\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] #quality_metric: host=algo-1, epoch=364, batch=5 train loss <loss>=1.8769256869951885\n",
      "[05/21/2025 21:05:14 INFO 140363140085568] Epoch[364] Batch [5]#011Speed: 2093.20 samples/sec#011loss=1.876926\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] Epoch[364] Batch[10] avg_epoch_loss=1.863975\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=364, batch=10 train loss <loss>=1.8484334707260133\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] Epoch[364] Batch [10]#011Speed: 2016.42 samples/sec#011loss=1.848433\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747861514.2049353, \"EndTime\": 1747861515.1527796, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.5862979888916, \"count\": 1, \"min\": 947.5862979888916, \"max\": 947.5862979888916}}}\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1399.2195130296434 records/second\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] #progress_metric: host=algo-1, completed 91.25 % of epochs\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=364, train loss <loss>=1.8639746796001087\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] Epoch[365] Batch[0] avg_epoch_loss=1.993220\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=365, batch=0 train loss <loss>=1.9932200908660889\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] Epoch[365] Batch[5] avg_epoch_loss=1.927434\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] #quality_metric: host=algo-1, epoch=365, batch=5 train loss <loss>=1.9274340669314067\n",
      "[05/21/2025 21:05:15 INFO 140363140085568] Epoch[365] Batch [5]#011Speed: 2022.39 samples/sec#011loss=1.927434\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] Epoch[365] Batch[10] avg_epoch_loss=1.906252\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=365, batch=10 train loss <loss>=1.880833101272583\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] Epoch[365] Batch [10]#011Speed: 1707.29 samples/sec#011loss=1.880833\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747861515.1528375, \"EndTime\": 1747861516.1727087, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1019.6211338043213, \"count\": 1, \"min\": 1019.6211338043213, \"max\": 1019.6211338043213}}}\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1273.8810921370518 records/second\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] #progress_metric: host=algo-1, completed 91.5 % of epochs\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=365, train loss <loss>=1.9062518098137595\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] Epoch[366] Batch[0] avg_epoch_loss=1.914047\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=366, batch=0 train loss <loss>=1.9140466451644897\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] Epoch[366] Batch[5] avg_epoch_loss=1.869984\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] #quality_metric: host=algo-1, epoch=366, batch=5 train loss <loss>=1.8699838717778523\n",
      "[05/21/2025 21:05:16 INFO 140363140085568] Epoch[366] Batch [5]#011Speed: 2060.72 samples/sec#011loss=1.869984\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] Epoch[366] Batch[10] avg_epoch_loss=1.915248\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=366, batch=10 train loss <loss>=1.9695649862289428\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] Epoch[366] Batch [10]#011Speed: 1903.35 samples/sec#011loss=1.969565\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747861516.1727736, \"EndTime\": 1747861517.1453226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 972.1112251281738, \"count\": 1, \"min\": 972.1112251281738, \"max\": 972.1112251281738}}}\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1326.8791248459927 records/second\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] #progress_metric: host=algo-1, completed 91.75 % of epochs\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=366, train loss <loss>=1.9152480147101663\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] Epoch[367] Batch[0] avg_epoch_loss=2.091148\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=367, batch=0 train loss <loss>=2.0911478996276855\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] Epoch[367] Batch[5] avg_epoch_loss=1.970219\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] #quality_metric: host=algo-1, epoch=367, batch=5 train loss <loss>=1.9702186187108357\n",
      "[05/21/2025 21:05:17 INFO 140363140085568] Epoch[367] Batch [5]#011Speed: 2154.38 samples/sec#011loss=1.970219\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] Epoch[367] Batch[10] avg_epoch_loss=1.979922\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=367, batch=10 train loss <loss>=1.9915663003921509\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] Epoch[367] Batch [10]#011Speed: 2014.28 samples/sec#011loss=1.991566\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747861517.1453865, \"EndTime\": 1747861518.0821795, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.4678859710693, \"count\": 1, \"min\": 936.4678859710693, \"max\": 936.4678859710693}}}\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1420.099348479059 records/second\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] #progress_metric: host=algo-1, completed 92.0 % of epochs\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=367, train loss <loss>=1.9799221103841609\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] Epoch[368] Batch[0] avg_epoch_loss=1.951216\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=368, batch=0 train loss <loss>=1.9512157440185547\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] Epoch[368] Batch[5] avg_epoch_loss=1.967999\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] #quality_metric: host=algo-1, epoch=368, batch=5 train loss <loss>=1.967998743057251\n",
      "[05/21/2025 21:05:18 INFO 140363140085568] Epoch[368] Batch [5]#011Speed: 2172.18 samples/sec#011loss=1.967999\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] Epoch[368] Batch[10] avg_epoch_loss=1.989355\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=368, batch=10 train loss <loss>=2.014983558654785\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] Epoch[368] Batch [10]#011Speed: 1996.63 samples/sec#011loss=2.014984\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747861518.0822382, \"EndTime\": 1747861519.0174031, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.9215030670166, \"count\": 1, \"min\": 934.9215030670166, \"max\": 934.9215030670166}}}\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1411.7547126222237 records/second\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] #progress_metric: host=algo-1, completed 92.25 % of epochs\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=368, train loss <loss>=1.9893554774197666\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] Epoch[369] Batch[0] avg_epoch_loss=1.943145\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=369, batch=0 train loss <loss>=1.9431451559066772\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] Epoch[369] Batch[5] avg_epoch_loss=1.903670\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=369, batch=5 train loss <loss>=1.903670032819112\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] Epoch[369] Batch [5]#011Speed: 2211.76 samples/sec#011loss=1.903670\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747861519.0174613, \"EndTime\": 1747861519.8690195, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 851.3133525848389, \"count\": 1, \"min\": 851.3133525848389, \"max\": 851.3133525848389}}}\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1481.0789477737264 records/second\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] #progress_metric: host=algo-1, completed 92.5 % of epochs\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] #quality_metric: host=algo-1, epoch=369, train loss <loss>=1.8775319695472716\n",
      "[05/21/2025 21:05:19 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] Epoch[370] Batch[0] avg_epoch_loss=1.801297\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=370, batch=0 train loss <loss>=1.8012973070144653\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] Epoch[370] Batch[5] avg_epoch_loss=1.867235\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=370, batch=5 train loss <loss>=1.8672353625297546\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] Epoch[370] Batch [5]#011Speed: 2023.91 samples/sec#011loss=1.867235\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] Epoch[370] Batch[10] avg_epoch_loss=1.895812\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=370, batch=10 train loss <loss>=1.93010413646698\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] Epoch[370] Batch [10]#011Speed: 2064.70 samples/sec#011loss=1.930104\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747861519.8690834, \"EndTime\": 1747861520.8177803, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.3709335327148, \"count\": 1, \"min\": 948.3709335327148, \"max\": 948.3709335327148}}}\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1389.6251121761597 records/second\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] #progress_metric: host=algo-1, completed 92.75 % of epochs\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] #quality_metric: host=algo-1, epoch=370, train loss <loss>=1.8958120779557661\n",
      "[05/21/2025 21:05:20 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] Epoch[371] Batch[0] avg_epoch_loss=1.858517\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=371, batch=0 train loss <loss>=1.8585174083709717\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] Epoch[371] Batch[5] avg_epoch_loss=1.872474\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=371, batch=5 train loss <loss>=1.8724737564722698\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] Epoch[371] Batch [5]#011Speed: 2095.29 samples/sec#011loss=1.872474\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] Epoch[371] Batch[10] avg_epoch_loss=1.843199\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=371, batch=10 train loss <loss>=1.808070135116577\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] Epoch[371] Batch [10]#011Speed: 2070.77 samples/sec#011loss=1.808070\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747861520.8178391, \"EndTime\": 1747861521.7590024, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.9196376800537, \"count\": 1, \"min\": 940.9196376800537, \"max\": 940.9196376800537}}}\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1372.9838060578052 records/second\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] #progress_metric: host=algo-1, completed 93.0 % of epochs\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] #quality_metric: host=algo-1, epoch=371, train loss <loss>=1.8431993831287732\n",
      "[05/21/2025 21:05:21 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] Epoch[372] Batch[0] avg_epoch_loss=1.874237\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=372, batch=0 train loss <loss>=1.874236822128296\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] Epoch[372] Batch[5] avg_epoch_loss=1.843559\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=372, batch=5 train loss <loss>=1.843559463818868\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] Epoch[372] Batch [5]#011Speed: 2093.01 samples/sec#011loss=1.843559\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] Epoch[372] Batch[10] avg_epoch_loss=1.847442\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=372, batch=10 train loss <loss>=1.8521011114120483\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] Epoch[372] Batch [10]#011Speed: 2059.35 samples/sec#011loss=1.852101\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747861521.7590632, \"EndTime\": 1747861522.7026625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.335771560669, \"count\": 1, \"min\": 943.335771560669, \"max\": 943.335771560669}}}\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1409.759942057158 records/second\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] #progress_metric: host=algo-1, completed 93.25 % of epochs\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] #quality_metric: host=algo-1, epoch=372, train loss <loss>=1.8474420309066772\n",
      "[05/21/2025 21:05:22 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] Epoch[373] Batch[0] avg_epoch_loss=1.794044\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=373, batch=0 train loss <loss>=1.794044017791748\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] Epoch[373] Batch[5] avg_epoch_loss=1.843745\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=373, batch=5 train loss <loss>=1.8437448143959045\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] Epoch[373] Batch [5]#011Speed: 2114.20 samples/sec#011loss=1.843745\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] Epoch[373] Batch[10] avg_epoch_loss=1.836373\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=373, batch=10 train loss <loss>=1.8275277614593506\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] Epoch[373] Batch [10]#011Speed: 2027.90 samples/sec#011loss=1.827528\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747861522.702722, \"EndTime\": 1747861523.6470208, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.0505504608154, \"count\": 1, \"min\": 944.0505504608154, \"max\": 944.0505504608154}}}\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1406.5629533895299 records/second\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] #progress_metric: host=algo-1, completed 93.5 % of epochs\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=373, train loss <loss>=1.836373426697471\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] Epoch[374] Batch[0] avg_epoch_loss=1.808450\n",
      "[05/21/2025 21:05:23 INFO 140363140085568] #quality_metric: host=algo-1, epoch=374, batch=0 train loss <loss>=1.8084495067596436\n",
      "[05/21/2025 21:05:24 INFO 140363140085568] Epoch[374] Batch[5] avg_epoch_loss=1.819919\n",
      "[05/21/2025 21:05:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=374, batch=5 train loss <loss>=1.8199193080266316\n",
      "[05/21/2025 21:05:24 INFO 140363140085568] Epoch[374] Batch [5]#011Speed: 2159.11 samples/sec#011loss=1.819919\n",
      "[05/21/2025 21:05:24 INFO 140363140085568] processed a total of 1244 examples\n",
      "#metrics {\"StartTime\": 1747861523.6470878, \"EndTime\": 1747861524.5110016, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 863.645076751709, \"count\": 1, \"min\": 863.645076751709, \"max\": 863.645076751709}}}\n",
      "[05/21/2025 21:05:24 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1440.2395311926377 records/second\n",
      "[05/21/2025 21:05:24 INFO 140363140085568] #progress_metric: host=algo-1, completed 93.75 % of epochs\n",
      "[05/21/2025 21:05:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=374, train loss <loss>=1.8420542478561401\n",
      "[05/21/2025 21:05:24 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:24 INFO 140363140085568] Epoch[375] Batch[0] avg_epoch_loss=1.728247\n",
      "[05/21/2025 21:05:24 INFO 140363140085568] #quality_metric: host=algo-1, epoch=375, batch=0 train loss <loss>=1.7282472848892212\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] Epoch[375] Batch[5] avg_epoch_loss=1.812596\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=375, batch=5 train loss <loss>=1.8125961422920227\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] Epoch[375] Batch [5]#011Speed: 2121.76 samples/sec#011loss=1.812596\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] Epoch[375] Batch[10] avg_epoch_loss=1.792452\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=375, batch=10 train loss <loss>=1.7682782649993896\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] Epoch[375] Batch [10]#011Speed: 2004.02 samples/sec#011loss=1.768278\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747861524.5110717, \"EndTime\": 1747861525.4556358, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.2663192749023, \"count\": 1, \"min\": 944.2663192749023, \"max\": 944.2663192749023}}}\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1417.9025524994054 records/second\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] #progress_metric: host=algo-1, completed 94.0 % of epochs\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=375, train loss <loss>=1.7924516526135532\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_32c511c5-a5bc-4766-ae97-bb80755c3453-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861525.4556937, \"EndTime\": 1747861525.466334, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.36977767944336, \"count\": 1, \"min\": 10.36977767944336, \"max\": 10.36977767944336}}}\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] Epoch[376] Batch[0] avg_epoch_loss=1.813562\n",
      "[05/21/2025 21:05:25 INFO 140363140085568] #quality_metric: host=algo-1, epoch=376, batch=0 train loss <loss>=1.8135617971420288\n",
      "[05/21/2025 21:05:26 INFO 140363140085568] Epoch[376] Batch[5] avg_epoch_loss=1.811217\n",
      "[05/21/2025 21:05:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=376, batch=5 train loss <loss>=1.8112170894940693\n",
      "[05/21/2025 21:05:26 INFO 140363140085568] Epoch[376] Batch [5]#011Speed: 1910.19 samples/sec#011loss=1.811217\n",
      "[05/21/2025 21:05:26 INFO 140363140085568] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747861525.4663904, \"EndTime\": 1747861526.37471, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.2667827606201, \"count\": 1, \"min\": 908.2667827606201, \"max\": 908.2667827606201}}}\n",
      "[05/21/2025 21:05:26 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1404.7293955964637 records/second\n",
      "[05/21/2025 21:05:26 INFO 140363140085568] #progress_metric: host=algo-1, completed 94.25 % of epochs\n",
      "[05/21/2025 21:05:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=376, train loss <loss>=1.806919002532959\n",
      "[05/21/2025 21:05:26 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:26 INFO 140363140085568] Epoch[377] Batch[0] avg_epoch_loss=1.753345\n",
      "[05/21/2025 21:05:26 INFO 140363140085568] #quality_metric: host=algo-1, epoch=377, batch=0 train loss <loss>=1.7533453702926636\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] Epoch[377] Batch[5] avg_epoch_loss=1.836650\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=377, batch=5 train loss <loss>=1.836650053660075\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] Epoch[377] Batch [5]#011Speed: 2074.75 samples/sec#011loss=1.836650\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] Epoch[377] Batch[10] avg_epoch_loss=1.854740\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=377, batch=10 train loss <loss>=1.8764485836029052\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] Epoch[377] Batch [10]#011Speed: 2005.15 samples/sec#011loss=1.876449\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747861526.3747723, \"EndTime\": 1747861527.324967, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 949.9073028564453, \"count\": 1, \"min\": 949.9073028564453, \"max\": 949.9073028564453}}}\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1392.6419942583357 records/second\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] #progress_metric: host=algo-1, completed 94.5 % of epochs\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=377, train loss <loss>=1.8547402945431797\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] Epoch[378] Batch[0] avg_epoch_loss=1.909881\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=378, batch=0 train loss <loss>=1.909881353378296\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] Epoch[378] Batch[5] avg_epoch_loss=1.868881\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] #quality_metric: host=algo-1, epoch=378, batch=5 train loss <loss>=1.8688806891441345\n",
      "[05/21/2025 21:05:27 INFO 140363140085568] Epoch[378] Batch [5]#011Speed: 2095.16 samples/sec#011loss=1.868881\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] Epoch[378] Batch[10] avg_epoch_loss=1.872551\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=378, batch=10 train loss <loss>=1.876954770088196\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] Epoch[378] Batch [10]#011Speed: 2025.96 samples/sec#011loss=1.876955\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747861527.325026, \"EndTime\": 1747861528.2767546, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.4443874359131, \"count\": 1, \"min\": 951.4443874359131, \"max\": 951.4443874359131}}}\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1389.3351400542817 records/second\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] #progress_metric: host=algo-1, completed 94.75 % of epochs\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=378, train loss <loss>=1.8725507259368896\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] Epoch[379] Batch[0] avg_epoch_loss=1.716353\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=379, batch=0 train loss <loss>=1.716353178024292\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] Epoch[379] Batch[5] avg_epoch_loss=1.774983\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] #quality_metric: host=algo-1, epoch=379, batch=5 train loss <loss>=1.774983028570811\n",
      "[05/21/2025 21:05:28 INFO 140363140085568] Epoch[379] Batch [5]#011Speed: 2122.34 samples/sec#011loss=1.774983\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] Epoch[379] Batch[10] avg_epoch_loss=1.845431\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=379, batch=10 train loss <loss>=1.9299688577651977\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] Epoch[379] Batch [10]#011Speed: 1956.02 samples/sec#011loss=1.929969\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747861528.2768161, \"EndTime\": 1747861529.2267354, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 949.6610164642334, \"count\": 1, \"min\": 949.6610164642334, \"max\": 949.6610164642334}}}\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1430.9094153364786 records/second\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] #progress_metric: host=algo-1, completed 95.0 % of epochs\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=379, train loss <loss>=1.8454311327500776\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] Epoch[380] Batch[0] avg_epoch_loss=1.767425\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=380, batch=0 train loss <loss>=1.7674250602722168\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] Epoch[380] Batch[5] avg_epoch_loss=1.834336\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] #quality_metric: host=algo-1, epoch=380, batch=5 train loss <loss>=1.8343358238538106\n",
      "[05/21/2025 21:05:29 INFO 140363140085568] Epoch[380] Batch [5]#011Speed: 2138.15 samples/sec#011loss=1.834336\n",
      "[05/21/2025 21:05:30 INFO 140363140085568] processed a total of 1271 examples\n",
      "#metrics {\"StartTime\": 1747861529.2267933, \"EndTime\": 1747861530.110229, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 883.1486701965332, \"count\": 1, \"min\": 883.1486701965332, \"max\": 883.1486701965332}}}\n",
      "[05/21/2025 21:05:30 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1439.0133936404368 records/second\n",
      "[05/21/2025 21:05:30 INFO 140363140085568] #progress_metric: host=algo-1, completed 95.25 % of epochs\n",
      "[05/21/2025 21:05:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=380, train loss <loss>=1.817468249797821\n",
      "[05/21/2025 21:05:30 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:30 INFO 140363140085568] Epoch[381] Batch[0] avg_epoch_loss=1.815070\n",
      "[05/21/2025 21:05:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=381, batch=0 train loss <loss>=1.815070390701294\n",
      "[05/21/2025 21:05:30 INFO 140363140085568] Epoch[381] Batch[5] avg_epoch_loss=1.798698\n",
      "[05/21/2025 21:05:30 INFO 140363140085568] #quality_metric: host=algo-1, epoch=381, batch=5 train loss <loss>=1.79869810740153\n",
      "[05/21/2025 21:05:30 INFO 140363140085568] Epoch[381] Batch [5]#011Speed: 2132.57 samples/sec#011loss=1.798698\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] Epoch[381] Batch[10] avg_epoch_loss=1.837607\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=381, batch=10 train loss <loss>=1.88429696559906\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] Epoch[381] Batch [10]#011Speed: 2018.42 samples/sec#011loss=1.884297\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747861530.1102934, \"EndTime\": 1747861531.053542, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.957878112793, \"count\": 1, \"min\": 942.957878112793, \"max\": 942.957878112793}}}\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1386.9979271443967 records/second\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] #progress_metric: host=algo-1, completed 95.5 % of epochs\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=381, train loss <loss>=1.8376066793094983\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] Epoch[382] Batch[0] avg_epoch_loss=1.852162\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=382, batch=0 train loss <loss>=1.8521618843078613\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] Epoch[382] Batch[5] avg_epoch_loss=1.883087\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=382, batch=5 train loss <loss>=1.8830873767534893\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] Epoch[382] Batch [5]#011Speed: 2131.58 samples/sec#011loss=1.883087\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] Epoch[382] Batch[10] avg_epoch_loss=1.898782\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=382, batch=10 train loss <loss>=1.9176156759262084\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] Epoch[382] Batch [10]#011Speed: 2052.98 samples/sec#011loss=1.917616\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747861531.0535998, \"EndTime\": 1747861531.9842288, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.3843975067139, \"count\": 1, \"min\": 930.3843975067139, \"max\": 930.3843975067139}}}\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1445.4997538877662 records/second\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] #progress_metric: host=algo-1, completed 95.75 % of epochs\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] #quality_metric: host=algo-1, epoch=382, train loss <loss>=1.8987820581956343\n",
      "[05/21/2025 21:05:31 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] Epoch[383] Batch[0] avg_epoch_loss=1.907166\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=383, batch=0 train loss <loss>=1.9071658849716187\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] Epoch[383] Batch[5] avg_epoch_loss=1.822567\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=383, batch=5 train loss <loss>=1.8225666681925456\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] Epoch[383] Batch [5]#011Speed: 2063.39 samples/sec#011loss=1.822567\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] Epoch[383] Batch[10] avg_epoch_loss=1.819542\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=383, batch=10 train loss <loss>=1.8159123420715333\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] Epoch[383] Batch [10]#011Speed: 2079.38 samples/sec#011loss=1.815912\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747861531.984289, \"EndTime\": 1747861532.9303894, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.8272457122803, \"count\": 1, \"min\": 945.8272457122803, \"max\": 945.8272457122803}}}\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1375.3875289354185 records/second\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] #progress_metric: host=algo-1, completed 96.0 % of epochs\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] #quality_metric: host=algo-1, epoch=383, train loss <loss>=1.8195419745011763\n",
      "[05/21/2025 21:05:32 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] Epoch[384] Batch[0] avg_epoch_loss=2.276894\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=384, batch=0 train loss <loss>=2.2768943309783936\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] Epoch[384] Batch[5] avg_epoch_loss=2.157066\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=384, batch=5 train loss <loss>=2.1570664842923484\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] Epoch[384] Batch [5]#011Speed: 1960.02 samples/sec#011loss=2.157066\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] Epoch[384] Batch[10] avg_epoch_loss=2.112593\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=384, batch=10 train loss <loss>=2.059223747253418\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] Epoch[384] Batch [10]#011Speed: 1787.16 samples/sec#011loss=2.059224\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747861532.9304497, \"EndTime\": 1747861533.9497905, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1019.0908908843994, \"count\": 1, \"min\": 1019.0908908843994, \"max\": 1019.0908908843994}}}\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1306.9344770426126 records/second\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] #progress_metric: host=algo-1, completed 96.25 % of epochs\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] #quality_metric: host=algo-1, epoch=384, train loss <loss>=2.112592512911016\n",
      "[05/21/2025 21:05:33 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] Epoch[385] Batch[0] avg_epoch_loss=2.038054\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=385, batch=0 train loss <loss>=2.0380539894104004\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] Epoch[385] Batch[5] avg_epoch_loss=2.011106\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=385, batch=5 train loss <loss>=2.01110577583313\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] Epoch[385] Batch [5]#011Speed: 2071.00 samples/sec#011loss=2.011106\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] Epoch[385] Batch[10] avg_epoch_loss=2.042699\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=385, batch=10 train loss <loss>=2.080611753463745\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] Epoch[385] Batch [10]#011Speed: 1851.68 samples/sec#011loss=2.080612\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747861533.9498513, \"EndTime\": 1747861534.9402452, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 990.1449680328369, \"count\": 1, \"min\": 990.1449680328369, \"max\": 990.1449680328369}}}\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1314.84181955771 records/second\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] #progress_metric: host=algo-1, completed 96.5 % of epochs\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] #quality_metric: host=algo-1, epoch=385, train loss <loss>=2.0426994020288642\n",
      "[05/21/2025 21:05:34 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:35 INFO 140363140085568] Epoch[386] Batch[0] avg_epoch_loss=1.947937\n",
      "[05/21/2025 21:05:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=386, batch=0 train loss <loss>=1.9479365348815918\n",
      "[05/21/2025 21:05:35 INFO 140363140085568] Epoch[386] Batch[5] avg_epoch_loss=1.914525\n",
      "[05/21/2025 21:05:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=386, batch=5 train loss <loss>=1.9145248532295227\n",
      "[05/21/2025 21:05:35 INFO 140363140085568] Epoch[386] Batch [5]#011Speed: 2119.57 samples/sec#011loss=1.914525\n",
      "[05/21/2025 21:05:35 INFO 140363140085568] processed a total of 1263 examples\n",
      "#metrics {\"StartTime\": 1747861534.9403057, \"EndTime\": 1747861535.8045962, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.0069961547852, \"count\": 1, \"min\": 864.0069961547852, \"max\": 864.0069961547852}}}\n",
      "[05/21/2025 21:05:35 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1461.6017375642316 records/second\n",
      "[05/21/2025 21:05:35 INFO 140363140085568] #progress_metric: host=algo-1, completed 96.75 % of epochs\n",
      "[05/21/2025 21:05:35 INFO 140363140085568] #quality_metric: host=algo-1, epoch=386, train loss <loss>=1.8972760438919067\n",
      "[05/21/2025 21:05:35 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] Epoch[387] Batch[0] avg_epoch_loss=1.899929\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=387, batch=0 train loss <loss>=1.899929404258728\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] Epoch[387] Batch[5] avg_epoch_loss=1.882407\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=387, batch=5 train loss <loss>=1.8824071288108826\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] Epoch[387] Batch [5]#011Speed: 2091.65 samples/sec#011loss=1.882407\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] Epoch[387] Batch[10] avg_epoch_loss=1.873743\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=387, batch=10 train loss <loss>=1.8633467197418212\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] Epoch[387] Batch [10]#011Speed: 1936.74 samples/sec#011loss=1.863347\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747861535.804678, \"EndTime\": 1747861536.7662838, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.2958431243896, \"count\": 1, \"min\": 961.2958431243896, \"max\": 961.2958431243896}}}\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1357.4173004799447 records/second\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] #progress_metric: host=algo-1, completed 97.0 % of epochs\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] #quality_metric: host=algo-1, epoch=387, train loss <loss>=1.873743306506764\n",
      "[05/21/2025 21:05:36 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] Epoch[388] Batch[0] avg_epoch_loss=1.944638\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=388, batch=0 train loss <loss>=1.9446381330490112\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] Epoch[388] Batch[5] avg_epoch_loss=1.907546\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=388, batch=5 train loss <loss>=1.9075462222099304\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] Epoch[388] Batch [5]#011Speed: 2039.01 samples/sec#011loss=1.907546\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] Epoch[388] Batch[10] avg_epoch_loss=1.956727\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=388, batch=10 train loss <loss>=2.015744137763977\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] Epoch[388] Batch [10]#011Speed: 1994.82 samples/sec#011loss=2.015744\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747861536.7663434, \"EndTime\": 1747861537.7292457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 962.6655578613281, \"count\": 1, \"min\": 962.6655578613281, \"max\": 962.6655578613281}}}\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1385.6083532705989 records/second\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] #progress_metric: host=algo-1, completed 97.25 % of epochs\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] #quality_metric: host=algo-1, epoch=388, train loss <loss>=1.9567270929163152\n",
      "[05/21/2025 21:05:37 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] Epoch[389] Batch[0] avg_epoch_loss=1.839076\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=389, batch=0 train loss <loss>=1.8390763998031616\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] Epoch[389] Batch[5] avg_epoch_loss=1.879022\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=389, batch=5 train loss <loss>=1.8790215253829956\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] Epoch[389] Batch [5]#011Speed: 2090.08 samples/sec#011loss=1.879022\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] Epoch[389] Batch[10] avg_epoch_loss=1.903220\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=389, batch=10 train loss <loss>=1.9322590112686158\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] Epoch[389] Batch [10]#011Speed: 1855.16 samples/sec#011loss=1.932259\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747861537.7293057, \"EndTime\": 1747861538.70271, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.1066226959229, \"count\": 1, \"min\": 973.1066226959229, \"max\": 973.1066226959229}}}\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1385.1326690778205 records/second\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] #progress_metric: host=algo-1, completed 97.5 % of epochs\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] #quality_metric: host=algo-1, epoch=389, train loss <loss>=1.903220382603732\n",
      "[05/21/2025 21:05:38 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] Epoch[390] Batch[0] avg_epoch_loss=1.893411\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=390, batch=0 train loss <loss>=1.8934106826782227\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] Epoch[390] Batch[5] avg_epoch_loss=1.892786\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=390, batch=5 train loss <loss>=1.892785867055257\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] Epoch[390] Batch [5]#011Speed: 2079.95 samples/sec#011loss=1.892786\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] Epoch[390] Batch[10] avg_epoch_loss=2.037668\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=390, batch=10 train loss <loss>=2.211526608467102\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] Epoch[390] Batch [10]#011Speed: 2019.81 samples/sec#011loss=2.211527\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747861538.7027674, \"EndTime\": 1747861539.6517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.6513137817383, \"count\": 1, \"min\": 948.6513137817383, \"max\": 948.6513137817383}}}\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1426.1138062725558 records/second\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] #progress_metric: host=algo-1, completed 97.75 % of epochs\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=390, train loss <loss>=2.0376680222424595\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] Epoch[391] Batch[0] avg_epoch_loss=1.927452\n",
      "[05/21/2025 21:05:39 INFO 140363140085568] #quality_metric: host=algo-1, epoch=391, batch=0 train loss <loss>=1.9274518489837646\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] Epoch[391] Batch[5] avg_epoch_loss=1.870776\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=391, batch=5 train loss <loss>=1.8707760572433472\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] Epoch[391] Batch [5]#011Speed: 1834.12 samples/sec#011loss=1.870776\n",
      "\n",
      "2025-05-21 21:05:52 Uploading - Uploading generated training model[05/21/2025 21:05:40 INFO 140363140085568] Epoch[391] Batch[10] avg_epoch_loss=1.883614\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=391, batch=10 train loss <loss>=1.8990195512771606\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] Epoch[391] Batch [10]#011Speed: 2013.95 samples/sec#011loss=1.899020\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747861539.6517527, \"EndTime\": 1747861540.6395292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 987.5578880310059, \"count\": 1, \"min\": 987.5578880310059, \"max\": 987.5578880310059}}}\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1347.6509907951297 records/second\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] #progress_metric: host=algo-1, completed 98.0 % of epochs\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=391, train loss <loss>=1.8836140090768987\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] Epoch[392] Batch[0] avg_epoch_loss=1.888831\n",
      "[05/21/2025 21:05:40 INFO 140363140085568] #quality_metric: host=algo-1, epoch=392, batch=0 train loss <loss>=1.888831377029419\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] Epoch[392] Batch[5] avg_epoch_loss=1.876826\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=392, batch=5 train loss <loss>=1.8768256505330403\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] Epoch[392] Batch [5]#011Speed: 1959.43 samples/sec#011loss=1.876826\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] Epoch[392] Batch[10] avg_epoch_loss=1.859368\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=392, batch=10 train loss <loss>=1.8384186983108521\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] Epoch[392] Batch [10]#011Speed: 2087.93 samples/sec#011loss=1.838419\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747861540.6395872, \"EndTime\": 1747861541.5960326, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.1991691589355, \"count\": 1, \"min\": 956.1991691589355, \"max\": 956.1991691589355}}}\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1381.3832152984746 records/second\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] #progress_metric: host=algo-1, completed 98.25 % of epochs\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=392, train loss <loss>=1.8593679449775002\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] Epoch[393] Batch[0] avg_epoch_loss=1.931172\n",
      "[05/21/2025 21:05:41 INFO 140363140085568] #quality_metric: host=algo-1, epoch=393, batch=0 train loss <loss>=1.9311720132827759\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] Epoch[393] Batch[5] avg_epoch_loss=1.975411\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=393, batch=5 train loss <loss>=1.9754106203715007\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] Epoch[393] Batch [5]#011Speed: 1973.43 samples/sec#011loss=1.975411\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] Epoch[393] Batch[10] avg_epoch_loss=1.859831\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=393, batch=10 train loss <loss>=1.7211357593536376\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] Epoch[393] Batch [10]#011Speed: 2120.64 samples/sec#011loss=1.721136\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747861541.5960927, \"EndTime\": 1747861542.5509279, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.5767307281494, \"count\": 1, \"min\": 954.5767307281494, \"max\": 954.5767307281494}}}\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1342.8785097890743 records/second\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] #progress_metric: host=algo-1, completed 98.5 % of epochs\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=393, train loss <loss>=1.8598311380906538\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] Epoch[394] Batch[0] avg_epoch_loss=1.884998\n",
      "[05/21/2025 21:05:42 INFO 140363140085568] #quality_metric: host=algo-1, epoch=394, batch=0 train loss <loss>=1.884997844696045\n",
      "[05/21/2025 21:05:43 INFO 140363140085568] Epoch[394] Batch[5] avg_epoch_loss=1.898630\n",
      "[05/21/2025 21:05:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=394, batch=5 train loss <loss>=1.8986299435297649\n",
      "[05/21/2025 21:05:43 INFO 140363140085568] Epoch[394] Batch [5]#011Speed: 2072.60 samples/sec#011loss=1.898630\n",
      "[05/21/2025 21:05:43 INFO 140363140085568] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747861542.5509882, \"EndTime\": 1747861543.4336975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 882.4470043182373, \"count\": 1, \"min\": 882.4470043182373, \"max\": 882.4470043182373}}}\n",
      "[05/21/2025 21:05:43 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1450.3686145811412 records/second\n",
      "[05/21/2025 21:05:43 INFO 140363140085568] #progress_metric: host=algo-1, completed 98.75 % of epochs\n",
      "[05/21/2025 21:05:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=394, train loss <loss>=1.8775763988494873\n",
      "[05/21/2025 21:05:43 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:43 INFO 140363140085568] Epoch[395] Batch[0] avg_epoch_loss=1.854620\n",
      "[05/21/2025 21:05:43 INFO 140363140085568] #quality_metric: host=algo-1, epoch=395, batch=0 train loss <loss>=1.8546202182769775\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] Epoch[395] Batch[5] avg_epoch_loss=1.841929\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=395, batch=5 train loss <loss>=1.8419287999471028\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] Epoch[395] Batch [5]#011Speed: 2099.90 samples/sec#011loss=1.841929\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] Epoch[395] Batch[10] avg_epoch_loss=1.861487\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=395, batch=10 train loss <loss>=1.8849563121795654\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] Epoch[395] Batch [10]#011Speed: 1889.14 samples/sec#011loss=1.884956\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747861543.4337533, \"EndTime\": 1747861544.4007115, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 966.559648513794, \"count\": 1, \"min\": 966.559648513794, \"max\": 966.559648513794}}}\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1350.026926215953 records/second\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] #progress_metric: host=algo-1, completed 99.0 % of epochs\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=395, train loss <loss>=1.8614867600527676\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] Epoch[396] Batch[0] avg_epoch_loss=1.804847\n",
      "[05/21/2025 21:05:44 INFO 140363140085568] #quality_metric: host=algo-1, epoch=396, batch=0 train loss <loss>=1.8048466444015503\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] Epoch[396] Batch[5] avg_epoch_loss=1.856809\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=396, batch=5 train loss <loss>=1.856809397538503\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] Epoch[396] Batch [5]#011Speed: 2170.86 samples/sec#011loss=1.856809\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] Epoch[396] Batch[10] avg_epoch_loss=1.784366\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=396, batch=10 train loss <loss>=1.6974341154098511\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] Epoch[396] Batch [10]#011Speed: 2116.99 samples/sec#011loss=1.697434\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747861544.400769, \"EndTime\": 1747861545.3248405, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.8286018371582, \"count\": 1, \"min\": 923.8286018371582, \"max\": 923.8286018371582}}}\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1403.7919038033126 records/second\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] #progress_metric: host=algo-1, completed 99.25 % of epochs\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=396, train loss <loss>=1.784366087480025\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] best epoch loss so far\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/state_d46c9fb9-52b6-4745-bf1b-0ee63a826ea6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861545.3249114, \"EndTime\": 1747861545.3360295, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.850667953491211, \"count\": 1, \"min\": 10.850667953491211, \"max\": 10.850667953491211}}}\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] Epoch[397] Batch[0] avg_epoch_loss=2.086029\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=397, batch=0 train loss <loss>=2.086028814315796\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] Epoch[397] Batch[5] avg_epoch_loss=2.088979\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] #quality_metric: host=algo-1, epoch=397, batch=5 train loss <loss>=2.088978926340739\n",
      "[05/21/2025 21:05:45 INFO 140363140085568] Epoch[397] Batch [5]#011Speed: 2087.87 samples/sec#011loss=2.088979\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] Epoch[397] Batch[10] avg_epoch_loss=2.053443\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=397, batch=10 train loss <loss>=2.0108001232147217\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] Epoch[397] Batch [10]#011Speed: 1954.92 samples/sec#011loss=2.010800\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747861545.336082, \"EndTime\": 1747861546.292619, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.4874172210693, \"count\": 1, \"min\": 956.4874172210693, \"max\": 956.4874172210693}}}\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1394.5577905616638 records/second\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] #progress_metric: host=algo-1, completed 99.5 % of epochs\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=397, train loss <loss>=2.053443106738004\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] Epoch[398] Batch[0] avg_epoch_loss=2.027076\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=398, batch=0 train loss <loss>=2.027076244354248\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] Epoch[398] Batch[5] avg_epoch_loss=2.039778\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] #quality_metric: host=algo-1, epoch=398, batch=5 train loss <loss>=2.0397777557373047\n",
      "[05/21/2025 21:05:46 INFO 140363140085568] Epoch[398] Batch [5]#011Speed: 2054.85 samples/sec#011loss=2.039778\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] Epoch[398] Batch[10] avg_epoch_loss=2.040472\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=398, batch=10 train loss <loss>=2.041304326057434\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] Epoch[398] Batch [10]#011Speed: 2034.96 samples/sec#011loss=2.041304\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747861546.2926779, \"EndTime\": 1747861547.2466645, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.7379741668701, \"count\": 1, \"min\": 953.7379741668701, \"max\": 953.7379741668701}}}\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1357.6886898096304 records/second\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] #progress_metric: host=algo-1, completed 99.75 % of epochs\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=398, train loss <loss>=2.0404716513373633\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] Epoch[399] Batch[0] avg_epoch_loss=1.951232\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=399, batch=0 train loss <loss>=1.9512323141098022\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] Epoch[399] Batch[5] avg_epoch_loss=1.903705\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] #quality_metric: host=algo-1, epoch=399, batch=5 train loss <loss>=1.9037054975827534\n",
      "[05/21/2025 21:05:47 INFO 140363140085568] Epoch[399] Batch [5]#011Speed: 2133.84 samples/sec#011loss=1.903705\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] Epoch[399] Batch[10] avg_epoch_loss=1.935175\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=399, batch=10 train loss <loss>=1.972938323020935\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] Epoch[399] Batch [10]#011Speed: 2118.31 samples/sec#011loss=1.972938\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747861547.2467246, \"EndTime\": 1747861548.176026, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.9348125457764, \"count\": 1, \"min\": 928.9348125457764, \"max\": 928.9348125457764}}}\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #throughput_metric: host=algo-1, train throughput=1389.6336457424422 records/second\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #progress_metric: host=algo-1, completed 100.0 % of epochs\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #quality_metric: host=algo-1, epoch=399, train loss <loss>=1.9351749636910178\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] loss did not improve\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] Final loss: 1.784366087480025 (occurred at epoch 396)\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #quality_metric: host=algo-1, train final_loss <loss>=1.784366087480025\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] Worker algo-1 finished training.\n",
      "[05/21/2025 21:05:48 WARNING 140363140085568] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747861548.1760848, \"EndTime\": 1747861548.2297614, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 53.16758155822754, \"count\": 1, \"min\": 53.16758155822754, \"max\": 53.16758155822754}}}\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747861548.2298253, \"EndTime\": 1747861548.258496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 81.93516731262207, \"count\": 1, \"min\": 81.93516731262207, \"max\": 81.93516731262207}}}\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747861548.2585454, \"EndTime\": 1747861548.2626045, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 4.028081893920898, \"count\": 1, \"min\": 4.028081893920898, \"max\": 4.028081893920898}}}\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] Successfully serialized the model for prediction.\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] Evaluating model accuracy on testset using 100 samples\n",
      "#metrics {\"StartTime\": 1747861548.2626493, \"EndTime\": 1747861548.2644377, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}}}\n",
      "#metrics {\"StartTime\": 1747861548.2644825, \"EndTime\": 1747861548.4517016, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 187.28327751159668, \"count\": 1, \"min\": 187.28327751159668, \"max\": 187.28327751159668}}}\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, RMSE): 28.090259257151867\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, mean_absolute_QuantileLoss): 1182.7762872298558\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, mean_wQuantileLoss): 0.4464991646771823\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, wQuantileLoss[0.1]): 0.19466119413782668\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, wQuantileLoss[0.2]): 0.3022140720737525\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, wQuantileLoss[0.3]): 0.38873037654708215\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, wQuantileLoss[0.4]): 0.4536135502516796\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, wQuantileLoss[0.5]): 0.5045274417325657\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, wQuantileLoss[0.6]): 0.536980193396612\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, wQuantileLoss[0.7]): 0.5537254141249175\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, wQuantileLoss[0.8]): 0.5543337845361291\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #test_score (algo-1, wQuantileLoss[0.9]): 0.5297064552940752\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #quality_metric: host=algo-1, test RMSE <loss>=28.090259257151867\n",
      "[05/21/2025 21:05:48 INFO 140363140085568] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.4464991646771823\n",
      "#metrics {\"StartTime\": 1747861548.4517777, \"EndTime\": 1747861548.4615827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 3.7717819213867188, \"count\": 1, \"min\": 3.7717819213867188, \"max\": 3.7717819213867188}, \"totaltime\": {\"sum\": 380076.8406391144, \"count\": 1, \"min\": 380076.8406391144, \"max\": 380076.8406391144}}}\n",
      "\n",
      "2025-05-21 21:06:04 Completed - Training job completed\n",
      "Training seconds: 511\n",
      "Billable seconds: 511\n",
      "CPU times: total: 19.5 s\n",
      "Wall time: 9min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "30028f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-21 21:06:04 Starting - Preparing the instances for training\n",
      "2025-05-21 21:06:04 Downloading - Downloading the training image\n",
      "2025-05-21 21:06:04 Training - Training image download completed. Training in progress.\n",
      "2025-05-21 21:06:04 Uploading - Uploading generated training model\n",
      "2025-05-21 21:06:04 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-21-20-56-51-092',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "0a66a95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 16:29:10] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-21-29-09-905 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 16:29:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-21-29-09-905 \u001b]8;id=919198;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=915512;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-21-29-09-905                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=90736;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=458673;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-21-29-09-905                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 16:29:11] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-21-29-09-905                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 16:29:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=410606;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=582601;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-21-29-09-905                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "9b524d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>Tipo_Producto</th>\n",
       "      <th>segmento_producto</th>\n",
       "      <th>supergrupo_producto</th>\n",
       "      <th>grupo_producto</th>\n",
       "      <th>subgrupo_producto</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-01</th>\n",
       "      <td>20003147001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               material  Tipo_Producto  segmento_producto  \\\n",
       "2021-08-01  20003147001              0                  3   \n",
       "\n",
       "            supergrupo_producto  grupo_producto  subgrupo_producto  cantidad  \\\n",
       "2021-08-01                    3               4                  5      32.0   \n",
       "\n",
       "            month  quarter  \n",
       "2021-08-01      8        3  "
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[6].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "c6ad49f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>173.897202</td>\n",
       "      <td>248.302963</td>\n",
       "      <td>307.395996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>174.623840</td>\n",
       "      <td>217.300766</td>\n",
       "      <td>261.455811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>157.604233</td>\n",
       "      <td>174.859070</td>\n",
       "      <td>204.639618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>49.222824</td>\n",
       "      <td>68.944542</td>\n",
       "      <td>89.268173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>66.526642</td>\n",
       "      <td>82.003136</td>\n",
       "      <td>93.593185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>93.374374</td>\n",
       "      <td>104.032745</td>\n",
       "      <td>116.947830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.1         0.5         0.9\n",
       "2024-11-01  173.897202  248.302963  307.395996\n",
       "2024-12-01  174.623840  217.300766  261.455811\n",
       "2025-01-01  157.604233  174.859070  204.639618\n",
       "2025-02-01   49.222824   68.944542   89.268173\n",
       "2025-03-01   66.526642   82.003136   93.593185\n",
       "2025-04-01   93.374374  104.032745  116.947830"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=6\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4d2af07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    182.0\n",
       "2024-12-01    368.0\n",
       "2025-01-01    130.0\n",
       "2025-02-01    173.0\n",
       "2025-03-01     74.0\n",
       "2025-04-01     95.0\n",
       "Freq: MS, Name: cantidad, dtype: float64"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[6].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d0707",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3ER ENTRENAMIENTO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "06c4235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_cantidad_a_entero(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Convierte los valores de la columna 'cantidad' de cada dataframe a enteros,\n",
    "    redondeando al entero más cercano.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con una columna 'cantidad'\n",
    "    \n",
    "    Returns:\n",
    "        Una nueva lista de dataframes con los valores de 'cantidad' convertidos a enteros\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Lista que almacenará los dataframes modificados\n",
    "    lista_modificada = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Crear una copia para no modificar el original\n",
    "        df_modificado = df.copy()\n",
    "        \n",
    "        # Verificar que exista la columna 'cantidad'\n",
    "        if 'cantidad' not in df_modificado.columns:\n",
    "            print(f\"Advertencia: Dataframe {i} no tiene la columna 'cantidad'. Se añadirá sin cambios.\")\n",
    "            lista_modificada.append(df_modificado)\n",
    "            continue\n",
    "        \n",
    "        # Convertir a entero redondeando al entero más cercano\n",
    "        try:\n",
    "            # Primero verificar si hay valores nulos y manejarlos\n",
    "            if df_modificado['cantidad'].isna().any():\n",
    "                # Mantener los valores nulos como son\n",
    "                mask = df_modificado['cantidad'].notna()\n",
    "                df_modificado.loc[mask, 'cantidad'] = np.round(df_modificado.loc[mask, 'cantidad']).astype(int)\n",
    "            else:\n",
    "                # Si no hay valores nulos, convertir directamente\n",
    "                df_modificado['cantidad'] = np.round(df_modificado['cantidad']).astype(int)\n",
    "                \n",
    "            lista_modificada.append(df_modificado)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al convertir valores en Dataframe {i}: {e}. Se añadirá sin cambios.\")\n",
    "            lista_modificada.append(df_modificado)\n",
    "    \n",
    "    return lista_modificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "79c82cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = convertir_cantidad_a_entero(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "ee08550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_target = extraer_vectores_cantidad(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "742a13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_test(start, vectores_target, vectores_cat, vectores_dynamic):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios con la estructura requerida para entrenamiento,\n",
    "    donde start son las fechas de inicio de cada serie (un valor por dataframe).\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie (como enteros)\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string, mantiene enteros como enteros\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else int(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic\n",
    "        if len(target_data) != len(month_vector) or len(target_data) != len(quarter_vector):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes - target: {len(target_data)}, \"\n",
    "                  f\"month: {len(month_vector)}, quarter: {len(quarter_vector)}\")\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector, quarter_vector]  # Usar valores originales sin normalizar\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "b2a5428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = crear_diccionarios_test(start,vectores_target,vectores_cat,vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "923ba370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_entrenamiento(start, vectores_target, vectores_cat, vectores_dynamic, puntos_a_excluir=6):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios excluyendo los últimos 'puntos_a_excluir' valores de \n",
    "    target y dynamic_feat para cada serie.\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "        puntos_a_excluir: Número de puntos a excluir del final de las series (default=6)\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string, mantiene enteros como enteros\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else int(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar que hay suficientes puntos para excluir\n",
    "        if len(target_data) <= puntos_a_excluir:\n",
    "            print(f\"Advertencia: Serie {i} tiene menos puntos ({len(target_data)}) que los requeridos a excluir ({puntos_a_excluir}). Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Excluir los últimos 'puntos_a_excluir' valores\n",
    "        target_data_recortado = target_data[:-puntos_a_excluir]\n",
    "        month_vector_recortado = month_vector[:-puntos_a_excluir]\n",
    "        quarter_vector_recortado = quarter_vector[:-puntos_a_excluir]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic después del recorte\n",
    "        if len(target_data_recortado) != len(month_vector_recortado) or len(target_data_recortado) != len(quarter_vector_recortado):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes después del recorte - target: {len(target_data_recortado)}, \"\n",
    "                  f\"month: {len(month_vector_recortado)}, quarter: {len(quarter_vector_recortado)}\")\n",
    "            # Ajustar a la longitud mínima\n",
    "            min_len = min(len(target_data_recortado), len(month_vector_recortado), len(quarter_vector_recortado))\n",
    "            target_data_recortado = target_data_recortado[:min_len]\n",
    "            month_vector_recortado = month_vector_recortado[:min_len]\n",
    "            quarter_vector_recortado = quarter_vector_recortado[:min_len]\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data_recortado),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector_recortado, quarter_vector_recortado]\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "a1a7be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = crear_diccionarios_entrenamiento(start,vectores_target, vectores_cat, vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb2cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"data_json/mensual_original_int/train.json\", train)\n",
    "write_dicts_to_file(\"data_json/mensual_original_int/test.json\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "fbab8abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket S3 'forecasting-mensual-15-v2' creado exitosamente en la región por defecto\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"forecasting-mensual-15-v2\"\n",
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "af4e7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = bucket_name  # replace with an existing bucket if needed\n",
    "s3_bucket_prefix = (\n",
    "        \"lilipink\"  \n",
    "    )\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "if default_bucket_prefix:\n",
    "    s3_prefix = f\"{default_bucket_prefix}/{s3_bucket_prefix}\"\n",
    "else:\n",
    "    s3_prefix = s3_bucket_prefix\n",
    "\n",
    "role = \"arn:aws:iam::844598627082:role/service-role/AmazonSageMaker-ExecutionRole-20250513T105052\"  # IAM role to use by SageMaker\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file\n",
      "Uploading file to s3://forecasting-mensual-15-v2/lilipink/data/train/train.json\n",
      "Overwriting existing file\n",
      "Uploading file to s3://forecasting-mensual-15-v2/lilipink/data/test/test.json\n"
     ]
    }
   ],
   "source": [
    "local_file = 'data_json/mensual_original_int/'\n",
    "copy_to_s3(local_file + 'train.json', s3_data_path + \"/train/train.json\",override=True)\n",
    "copy_to_s3(local_file + 'test.json', s3_data_path + \"/test/test.json\",override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "0e84683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"learning_rate\": \"1E-1\",\n",
    "    \"likelihood\":\"negative-binomial\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "42976f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "42949922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 16:58:04] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 16:58:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=285611;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=190861;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-21-58-04-946                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=358082;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=267948;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-21-58-04-946                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 21:58:07 Starting - Starting the training job...\n",
      "2025-05-21 21:58:42 Downloading - Downloading input data...\n",
      "2025-05-21 21:58:58 Downloading - Downloading the training image............\n",
      "2025-05-21 22:01:19 Training - Training image download completed. Training in progress...Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '18', 'early_stopping_patience': '40', 'epochs': '400', 'learning_rate': '1E-1', 'likelihood': 'negative-binomial', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '1E-1', 'likelihood': 'negative-binomial', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '18', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Detected entry point for worker worker\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Using early stopping with patience 40\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] random_seed is None\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] [cardinality=auto] Inferred value of cardinality=[2, 4, 5, 6, 6] from dataset.\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Training set statistics:\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Integer time series\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] number of time series: 15\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] number of observations: 582\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] mean target length: 38.8\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] min/mean/max target: 1.0/28.5893470790378/343.0\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] mean abs(target): 28.5893470790378\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] contains missing values: no\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Small number of time series. Doing 86 passes over dataset with prob 0.9922480620155039 per epoch.\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Test set statistics:\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Integer time series\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] number of time series: 15\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] number of observations: 672\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] mean target length: 44.8\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] min/mean/max target: 1.0/28.702380952380953/368.0\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] mean abs(target): 28.702380952380953\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] contains missing values: no\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] nvidia-smi: took 0.055 seconds to run.\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] nvidia-smi identified 0 GPUs.\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Number of GPUs being used: 0\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Create Store: local\n",
      "#metrics {\"StartTime\": 1747864897.3365097, \"EndTime\": 1747864897.3814795, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 43.69401931762695, \"count\": 1, \"min\": 43.69401931762695, \"max\": 43.69401931762695}}}\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Number of GPUs being used: 0\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] #memory_usage::<model> = 21 mb\n",
      "#metrics {\"StartTime\": 1747864897.3815346, \"EndTime\": 1747864897.4547477, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 118.13735961914062, \"count\": 1, \"min\": 118.13735961914062, \"max\": 118.13735961914062}}}\n",
      "[22:01:37] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 20480 bytes with malloc directly\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] Epoch[0] Batch[0] avg_epoch_loss=3.929693\n",
      "[05/21/2025 22:01:37 INFO 139996243154752] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.9296929836273193\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] Epoch[0] Batch[5] avg_epoch_loss=4.937060\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=4.93705952167511\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] Epoch[0] Batch [5]#011Speed: 2223.21 samples/sec#011loss=4.937060\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] Epoch[0] Batch[10] avg_epoch_loss=4.210974\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.3396703243255614\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] Epoch[0] Batch [10]#011Speed: 2042.04 samples/sec#011loss=3.339670\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747864897.4547956, \"EndTime\": 1747864898.433879, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 979.0165424346924, \"count\": 1, \"min\": 979.0165424346924, \"max\": 979.0165424346924}}}\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1346.1191417222 records/second\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] #quality_metric: host=algo-1, epoch=0, train loss <loss>=4.21097352287986\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_7de4aa25-68f3-4465-8dc0-2cd5d7209331-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864898.4339418, \"EndTime\": 1747864898.4448888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.60628890991211, \"count\": 1, \"min\": 10.60628890991211, \"max\": 10.60628890991211}}}\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] Epoch[1] Batch[0] avg_epoch_loss=3.489709\n",
      "[05/21/2025 22:01:38 INFO 139996243154752] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.4897093772888184\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] Epoch[1] Batch[5] avg_epoch_loss=3.362770\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.3627698024113974\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] Epoch[1] Batch [5]#011Speed: 2185.02 samples/sec#011loss=3.362770\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] Epoch[1] Batch[10] avg_epoch_loss=3.229256\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.0690391063690186\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] Epoch[1] Batch [10]#011Speed: 2112.13 samples/sec#011loss=3.069039\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747864898.4449422, \"EndTime\": 1747864899.3640747, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.0819263458252, \"count\": 1, \"min\": 919.0819263458252, \"max\": 919.0819263458252}}}\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1418.6816460670514 records/second\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.2292558496648613\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_42268bb6-3ca3-4313-9922-dcce763df852-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864899.36413, \"EndTime\": 1747864899.3740354, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.612798690795898, \"count\": 1, \"min\": 9.612798690795898, \"max\": 9.612798690795898}}}\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] Epoch[2] Batch[0] avg_epoch_loss=3.153369\n",
      "[05/21/2025 22:01:39 INFO 139996243154752] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.1533687114715576\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] Epoch[2] Batch[5] avg_epoch_loss=3.195592\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.1955917278925576\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] Epoch[2] Batch [5]#011Speed: 1954.16 samples/sec#011loss=3.195592\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] Epoch[2] Batch[10] avg_epoch_loss=3.295588\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.415584182739258\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] Epoch[2] Batch [10]#011Speed: 2155.84 samples/sec#011loss=3.415584\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747864899.374086, \"EndTime\": 1747864900.3244932, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.3612518310547, \"count\": 1, \"min\": 950.3612518310547, \"max\": 950.3612518310547}}}\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1354.1029817476885 records/second\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.2955882982774214\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] Epoch[3] Batch[0] avg_epoch_loss=3.034171\n",
      "[05/21/2025 22:01:40 INFO 139996243154752] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.0341708660125732\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] Epoch[3] Batch[5] avg_epoch_loss=3.200662\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.2006617387135825\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] Epoch[3] Batch [5]#011Speed: 1736.55 samples/sec#011loss=3.200662\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] Epoch[3] Batch[10] avg_epoch_loss=3.195758\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=3.1898738384246825\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] Epoch[3] Batch [10]#011Speed: 1621.23 samples/sec#011loss=3.189874\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747864900.3245502, \"EndTime\": 1747864901.4069974, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1082.167148590088, \"count\": 1, \"min\": 1082.167148590088, \"max\": 1082.167148590088}}}\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1245.5553046101163 records/second\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.1957581476731733\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_7ecf5a21-9102-436e-b87d-303e23a0d7d2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864901.407052, \"EndTime\": 1747864901.41702, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.652376174926758, \"count\": 1, \"min\": 9.652376174926758, \"max\": 9.652376174926758}}}\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] Epoch[4] Batch[0] avg_epoch_loss=3.149222\n",
      "[05/21/2025 22:01:41 INFO 139996243154752] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.1492223739624023\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] Epoch[4] Batch[5] avg_epoch_loss=3.193096\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.193096399307251\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] Epoch[4] Batch [5]#011Speed: 2117.94 samples/sec#011loss=3.193096\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] Epoch[4] Batch[10] avg_epoch_loss=3.222790\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.2584229946136474\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] Epoch[4] Batch [10]#011Speed: 2177.80 samples/sec#011loss=3.258423\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747864901.4170718, \"EndTime\": 1747864902.383388, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 966.2666320800781, \"count\": 1, \"min\": 966.2666320800781, \"max\": 966.2666320800781}}}\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1352.5122535105281 records/second\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.222790306264704\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] Epoch[5] Batch[0] avg_epoch_loss=3.239165\n",
      "[05/21/2025 22:01:42 INFO 139996243154752] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.2391650676727295\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] Epoch[5] Batch[5] avg_epoch_loss=3.306347\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.306346853574117\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] Epoch[5] Batch [5]#011Speed: 2138.93 samples/sec#011loss=3.306347\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] Epoch[5] Batch[10] avg_epoch_loss=3.261161\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.2069371700286866\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] Epoch[5] Batch [10]#011Speed: 2030.98 samples/sec#011loss=3.206937\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747864902.3834426, \"EndTime\": 1747864903.31651, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.7881336212158, \"count\": 1, \"min\": 932.7881336212158, \"max\": 932.7881336212158}}}\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1440.7146129236223 records/second\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.2611606337807397\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] Epoch[6] Batch[0] avg_epoch_loss=3.202982\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.202982187271118\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] Epoch[6] Batch[5] avg_epoch_loss=3.157250\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.1572495698928833\n",
      "[05/21/2025 22:01:43 INFO 139996243154752] Epoch[6] Batch [5]#011Speed: 2272.38 samples/sec#011loss=3.157250\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] Epoch[6] Batch[10] avg_epoch_loss=3.164991\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.174280881881714\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] Epoch[6] Batch [10]#011Speed: 2212.79 samples/sec#011loss=3.174281\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747864903.3165655, \"EndTime\": 1747864904.2120397, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 895.2264785766602, \"count\": 1, \"min\": 895.2264785766602, \"max\": 895.2264785766602}}}\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1474.2905074436412 records/second\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.1649910753423516\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_4e0aa66d-c810-4a0e-929d-3014ae183835-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864904.2121313, \"EndTime\": 1747864904.2222543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.83572006225586, \"count\": 1, \"min\": 9.83572006225586, \"max\": 9.83572006225586}}}\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] Epoch[7] Batch[0] avg_epoch_loss=2.974088\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=2.974087715148926\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] Epoch[7] Batch[5] avg_epoch_loss=3.071224\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.0712236166000366\n",
      "[05/21/2025 22:01:44 INFO 139996243154752] Epoch[7] Batch [5]#011Speed: 2167.23 samples/sec#011loss=3.071224\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] processed a total of 1260 examples\n",
      "#metrics {\"StartTime\": 1747864904.222294, \"EndTime\": 1747864905.0659995, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 843.6617851257324, \"count\": 1, \"min\": 843.6617851257324, \"max\": 843.6617851257324}}}\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1493.3303795390216 records/second\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.0942259788513184\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_e61a3e87-9168-4690-8a60-a3825e156a64-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864905.0660608, \"EndTime\": 1747864905.0764627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.070562362670898, \"count\": 1, \"min\": 10.070562362670898, \"max\": 10.070562362670898}}}\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] Epoch[8] Batch[0] avg_epoch_loss=3.190995\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.1909945011138916\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] Epoch[8] Batch[5] avg_epoch_loss=3.127001\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.1270012855529785\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] Epoch[8] Batch [5]#011Speed: 2305.54 samples/sec#011loss=3.127001\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] Epoch[8] Batch[10] avg_epoch_loss=3.149035\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.175475740432739\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] Epoch[8] Batch [10]#011Speed: 2129.55 samples/sec#011loss=3.175476\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] processed a total of 1377 examples\n",
      "#metrics {\"StartTime\": 1747864905.0765076, \"EndTime\": 1747864905.9723592, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 895.8075046539307, \"count\": 1, \"min\": 895.8075046539307, \"max\": 895.8075046539307}}}\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1537.0202851157323 records/second\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.1490351286801426\n",
      "[05/21/2025 22:01:45 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] Epoch[9] Batch[0] avg_epoch_loss=3.231790\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.23179030418396\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] Epoch[9] Batch[5] avg_epoch_loss=3.071563\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.071562925974528\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] Epoch[9] Batch [5]#011Speed: 2244.48 samples/sec#011loss=3.071563\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] Epoch[9] Batch[10] avg_epoch_loss=3.150823\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.245935344696045\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] Epoch[9] Batch [10]#011Speed: 2183.56 samples/sec#011loss=3.245935\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747864905.9724157, \"EndTime\": 1747864906.8750894, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 902.4262428283691, \"count\": 1, \"min\": 902.4262428283691, \"max\": 902.4262428283691}}}\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1429.3464024834343 records/second\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.1508231163024902\n",
      "[05/21/2025 22:01:46 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] Epoch[10] Batch[0] avg_epoch_loss=3.118052\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.118051528930664\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] Epoch[10] Batch[5] avg_epoch_loss=3.086008\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.0860084295272827\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] Epoch[10] Batch [5]#011Speed: 2208.64 samples/sec#011loss=3.086008\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] Epoch[10] Batch[10] avg_epoch_loss=3.114570\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.14884295463562\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] Epoch[10] Batch [10]#011Speed: 1977.68 samples/sec#011loss=3.148843\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] processed a total of 1381 examples\n",
      "#metrics {\"StartTime\": 1747864906.8751462, \"EndTime\": 1747864907.8044956, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.0602207183838, \"count\": 1, \"min\": 929.0602207183838, \"max\": 929.0602207183838}}}\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1486.3087151124405 records/second\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.1145695773038\n",
      "[05/21/2025 22:01:47 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] Epoch[11] Batch[0] avg_epoch_loss=2.970205\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.9702048301696777\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] Epoch[11] Batch[5] avg_epoch_loss=3.001688\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.0016878048578897\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] Epoch[11] Batch [5]#011Speed: 2240.22 samples/sec#011loss=3.001688\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747864907.8045547, \"EndTime\": 1747864908.6511674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 846.3618755340576, \"count\": 1, \"min\": 846.3618755340576, \"max\": 846.3618755340576}}}\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1505.1077187585292 records/second\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.993861532211304\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_63657360-c8ed-43b7-8ccd-74ab3d86de10-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864908.651228, \"EndTime\": 1747864908.6617136, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.107040405273438, \"count\": 1, \"min\": 10.107040405273438, \"max\": 10.107040405273438}}}\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] Epoch[12] Batch[0] avg_epoch_loss=3.040507\n",
      "[05/21/2025 22:01:48 INFO 139996243154752] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.040506601333618\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] Epoch[12] Batch[5] avg_epoch_loss=2.931904\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.931903521219889\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] Epoch[12] Batch [5]#011Speed: 2227.79 samples/sec#011loss=2.931904\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] Epoch[12] Batch[10] avg_epoch_loss=3.083934\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=3.266369676589966\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] Epoch[12] Batch [10]#011Speed: 2060.92 samples/sec#011loss=3.266370\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747864908.6617649, \"EndTime\": 1747864909.5818806, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.069694519043, \"count\": 1, \"min\": 920.069694519043, \"max\": 920.069694519043}}}\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1429.1184566221664 records/second\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.0839335918426514\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] Epoch[13] Batch[0] avg_epoch_loss=2.932802\n",
      "[05/21/2025 22:01:49 INFO 139996243154752] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.932802200317383\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] Epoch[13] Batch[5] avg_epoch_loss=3.036363\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.036362648010254\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] Epoch[13] Batch [5]#011Speed: 2198.16 samples/sec#011loss=3.036363\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] Epoch[13] Batch[10] avg_epoch_loss=3.049188\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.0645776271820067\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] Epoch[13] Batch [10]#011Speed: 2138.72 samples/sec#011loss=3.064578\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747864909.581932, \"EndTime\": 1747864910.5036035, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.4034080505371, \"count\": 1, \"min\": 921.4034080505371, \"max\": 921.4034080505371}}}\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1397.7356214510128 records/second\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.0491876385428687\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] Epoch[14] Batch[0] avg_epoch_loss=3.177873\n",
      "[05/21/2025 22:01:50 INFO 139996243154752] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.177873134613037\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] Epoch[14] Batch[5] avg_epoch_loss=3.027211\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.027210513750712\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] Epoch[14] Batch [5]#011Speed: 2216.12 samples/sec#011loss=3.027211\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] Epoch[14] Batch[10] avg_epoch_loss=2.870311\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=2.682031512260437\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] Epoch[14] Batch [10]#011Speed: 2189.82 samples/sec#011loss=2.682032\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747864910.5036638, \"EndTime\": 1747864911.40893, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.9606323242188, \"count\": 1, \"min\": 904.9606323242188, \"max\": 904.9606323242188}}}\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1440.8119039998314 records/second\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.870310967618769\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_7fb181ea-e11f-433e-96da-8e3db301af46-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864911.408987, \"EndTime\": 1747864911.4193292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.071516036987305, \"count\": 1, \"min\": 10.071516036987305, \"max\": 10.071516036987305}}}\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] Epoch[15] Batch[0] avg_epoch_loss=3.048182\n",
      "[05/21/2025 22:01:51 INFO 139996243154752] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.048182487487793\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] Epoch[15] Batch[5] avg_epoch_loss=2.991802\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.9918018579483032\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] Epoch[15] Batch [5]#011Speed: 2150.52 samples/sec#011loss=2.991802\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] Epoch[15] Batch[10] avg_epoch_loss=3.001438\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=3.013001728057861\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] Epoch[15] Batch [10]#011Speed: 2122.29 samples/sec#011loss=3.013002\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747864911.4193785, \"EndTime\": 1747864912.3401406, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.7158088684082, \"count\": 1, \"min\": 920.7158088684082, \"max\": 920.7158088684082}}}\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1460.6516118892644 records/second\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] #quality_metric: host=algo-1, epoch=15, train loss <loss>=3.001438162543557\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] Epoch[16] Batch[0] avg_epoch_loss=2.918578\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.9185779094696045\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] Epoch[16] Batch[5] avg_epoch_loss=2.901615\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.9016148249308267\n",
      "[05/21/2025 22:01:52 INFO 139996243154752] Epoch[16] Batch [5]#011Speed: 2233.40 samples/sec#011loss=2.901615\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] Epoch[16] Batch[10] avg_epoch_loss=2.887143\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=2.8697762489318848\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] Epoch[16] Batch [10]#011Speed: 2089.12 samples/sec#011loss=2.869776\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747864912.34022, \"EndTime\": 1747864913.255404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.919376373291, \"count\": 1, \"min\": 914.919376373291, \"max\": 914.919376373291}}}\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1456.8287638233746 records/second\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] #quality_metric: host=algo-1, epoch=16, train loss <loss>=2.8871427449313076\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] Epoch[17] Batch[0] avg_epoch_loss=2.696628\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=2.696627616882324\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] Epoch[17] Batch[5] avg_epoch_loss=2.886730\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=2.8867304722468057\n",
      "[05/21/2025 22:01:53 INFO 139996243154752] Epoch[17] Batch [5]#011Speed: 2282.67 samples/sec#011loss=2.886730\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] Epoch[17] Batch[10] avg_epoch_loss=2.949649\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.025150918960571\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] Epoch[17] Batch [10]#011Speed: 2076.90 samples/sec#011loss=3.025151\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747864913.25546, \"EndTime\": 1747864914.1669965, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.292314529419, \"count\": 1, \"min\": 911.292314529419, \"max\": 911.292314529419}}}\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1407.758873749377 records/second\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] #quality_metric: host=algo-1, epoch=17, train loss <loss>=2.949648857116699\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] Epoch[18] Batch[0] avg_epoch_loss=3.054302\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.0543019771575928\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] Epoch[18] Batch[5] avg_epoch_loss=2.985758\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=2.985758423805237\n",
      "[05/21/2025 22:01:54 INFO 139996243154752] Epoch[18] Batch [5]#011Speed: 2254.89 samples/sec#011loss=2.985758\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] Epoch[18] Batch[10] avg_epoch_loss=2.888121\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=2.7709557056427\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] Epoch[18] Batch [10]#011Speed: 2145.61 samples/sec#011loss=2.770956\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747864914.1670551, \"EndTime\": 1747864915.0710886, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 903.2528400421143, \"count\": 1, \"min\": 903.2528400421143, \"max\": 903.2528400421143}}}\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1452.3960757599712 records/second\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] #quality_metric: host=algo-1, epoch=18, train loss <loss>=2.8881208246404473\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] Epoch[19] Batch[0] avg_epoch_loss=2.890322\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=2.890321731567383\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] Epoch[19] Batch[5] avg_epoch_loss=2.924689\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=2.9246891339619956\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] Epoch[19] Batch [5]#011Speed: 2250.04 samples/sec#011loss=2.924689\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] Epoch[19] Batch[10] avg_epoch_loss=2.888251\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=2.844525671005249\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] Epoch[19] Batch [10]#011Speed: 2042.16 samples/sec#011loss=2.844526\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] processed a total of 1388 examples\n",
      "#metrics {\"StartTime\": 1747864915.0711448, \"EndTime\": 1747864915.9839714, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.5759601593018, \"count\": 1, \"min\": 912.5759601593018, \"max\": 912.5759601593018}}}\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1520.8286240113898 records/second\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.8882511962543833\n",
      "[05/21/2025 22:01:55 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] Epoch[20] Batch[0] avg_epoch_loss=2.893573\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=2.8935728073120117\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] Epoch[20] Batch[5] avg_epoch_loss=2.886490\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=2.8864904244740806\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] Epoch[20] Batch [5]#011Speed: 2253.29 samples/sec#011loss=2.886490\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] Epoch[20] Batch[10] avg_epoch_loss=2.865044\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=2.8393078804016114\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] Epoch[20] Batch [10]#011Speed: 2161.24 samples/sec#011loss=2.839308\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747864915.9840283, \"EndTime\": 1747864916.8935914, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.304141998291, \"count\": 1, \"min\": 909.304141998291, \"max\": 909.304141998291}}}\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1429.5293528834827 records/second\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] #quality_metric: host=algo-1, epoch=20, train loss <loss>=2.865043813532049\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:01:56 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_e20e41fe-6d4c-4004-ac59-1fba9bbd9f67-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864916.8936503, \"EndTime\": 1747864916.9037988, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.64212417602539, \"count\": 1, \"min\": 9.64212417602539, \"max\": 9.64212417602539}}}\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] Epoch[21] Batch[0] avg_epoch_loss=3.147027\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.147026538848877\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] Epoch[21] Batch[5] avg_epoch_loss=3.094856\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.0948562224706015\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] Epoch[21] Batch [5]#011Speed: 2116.22 samples/sec#011loss=3.094856\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] Epoch[21] Batch[10] avg_epoch_loss=2.973628\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=2.8281548500061033\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] Epoch[21] Batch [10]#011Speed: 2130.27 samples/sec#011loss=2.828155\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747864916.903849, \"EndTime\": 1747864917.8367717, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.8737258911133, \"count\": 1, \"min\": 932.8737258911133, \"max\": 932.8737258911133}}}\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1429.8112017008903 records/second\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] #quality_metric: host=algo-1, epoch=21, train loss <loss>=2.9736283258958296\n",
      "[05/21/2025 22:01:57 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] Epoch[22] Batch[0] avg_epoch_loss=3.064274\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=3.064274311065674\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] Epoch[22] Batch[5] avg_epoch_loss=2.970783\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.97078267733256\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] Epoch[22] Batch [5]#011Speed: 2185.59 samples/sec#011loss=2.970783\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] Epoch[22] Batch[10] avg_epoch_loss=2.963361\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=2.9544552326202393\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] Epoch[22] Batch [10]#011Speed: 2077.81 samples/sec#011loss=2.954455\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747864917.8368607, \"EndTime\": 1747864918.754946, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.8118705749512, \"count\": 1, \"min\": 917.8118705749512, \"max\": 917.8118705749512}}}\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1482.7441248794455 records/second\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.9633611115542324\n",
      "[05/21/2025 22:01:58 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] Epoch[23] Batch[0] avg_epoch_loss=2.824091\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.8240909576416016\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] Epoch[23] Batch[5] avg_epoch_loss=2.815286\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.815285603205363\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] Epoch[23] Batch [5]#011Speed: 2283.37 samples/sec#011loss=2.815286\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] Epoch[23] Batch[10] avg_epoch_loss=2.923562\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=3.05349440574646\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] Epoch[23] Batch [10]#011Speed: 2106.13 samples/sec#011loss=3.053494\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747864918.755, \"EndTime\": 1747864919.6562948, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 901.0519981384277, \"count\": 1, \"min\": 901.0519981384277, \"max\": 901.0519981384277}}}\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1467.0349609645775 records/second\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.9235623316331343\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] Epoch[24] Batch[0] avg_epoch_loss=2.717083\n",
      "[05/21/2025 22:01:59 INFO 139996243154752] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.71708345413208\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] Epoch[24] Batch[5] avg_epoch_loss=2.860923\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.860922654469808\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] Epoch[24] Batch [5]#011Speed: 2188.09 samples/sec#011loss=2.860923\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] Epoch[24] Batch[10] avg_epoch_loss=2.847861\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.832186460494995\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] Epoch[24] Batch [10]#011Speed: 2146.02 samples/sec#011loss=2.832186\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747864919.6563528, \"EndTime\": 1747864920.5755599, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.9267158508301, \"count\": 1, \"min\": 918.9267158508301, \"max\": 918.9267158508301}}}\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1427.6229510238136 records/second\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.84786074811762\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_098b1c17-8a97-4577-a84d-779a4d9fe7f7-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864920.575617, \"EndTime\": 1747864920.5858045, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.921789169311523, \"count\": 1, \"min\": 9.921789169311523, \"max\": 9.921789169311523}}}\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] Epoch[25] Batch[0] avg_epoch_loss=2.785750\n",
      "[05/21/2025 22:02:00 INFO 139996243154752] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.785750150680542\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] Epoch[25] Batch[5] avg_epoch_loss=2.941144\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.94114359219869\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] Epoch[25] Batch [5]#011Speed: 2265.65 samples/sec#011loss=2.941144\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] Epoch[25] Batch[10] avg_epoch_loss=2.915957\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=2.8857330799102785\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] Epoch[25] Batch [10]#011Speed: 2002.02 samples/sec#011loss=2.885733\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747864920.585854, \"EndTime\": 1747864921.513626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.7231693267822, \"count\": 1, \"min\": 927.7231693267822, \"max\": 927.7231693267822}}}\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1400.0712051367116 records/second\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.9159569957039575\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] Epoch[26] Batch[0] avg_epoch_loss=2.921179\n",
      "[05/21/2025 22:02:01 INFO 139996243154752] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.9211790561676025\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] Epoch[26] Batch[5] avg_epoch_loss=2.900147\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.9001471201578775\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] Epoch[26] Batch [5]#011Speed: 2215.30 samples/sec#011loss=2.900147\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] Epoch[26] Batch[10] avg_epoch_loss=2.776085\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=2.627209687232971\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] Epoch[26] Batch [10]#011Speed: 2227.70 samples/sec#011loss=2.627210\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747864921.5136852, \"EndTime\": 1747864922.410943, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.0067501068115, \"count\": 1, \"min\": 897.0067501068115, \"max\": 897.0067501068115}}}\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1444.6692508224871 records/second\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.7760846506465566\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_613f891a-ef16-4437-9c50-262e8a503ef0-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864922.411, \"EndTime\": 1747864922.4207892, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.516716003417969, \"count\": 1, \"min\": 9.516716003417969, \"max\": 9.516716003417969}}}\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] Epoch[27] Batch[0] avg_epoch_loss=2.992771\n",
      "[05/21/2025 22:02:02 INFO 139996243154752] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.9927706718444824\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] Epoch[27] Batch[5] avg_epoch_loss=2.950918\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.9509175221125283\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] Epoch[27] Batch [5]#011Speed: 2198.27 samples/sec#011loss=2.950918\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] Epoch[27] Batch[10] avg_epoch_loss=3.025127\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=3.114179229736328\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] Epoch[27] Batch [10]#011Speed: 2125.57 samples/sec#011loss=3.114179\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747864922.4208398, \"EndTime\": 1747864923.3321831, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.2966060638428, \"count\": 1, \"min\": 911.2966060638428, \"max\": 911.2966060638428}}}\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1427.5009774717164 records/second\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] #quality_metric: host=algo-1, epoch=27, train loss <loss>=3.0251273892142554\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] Epoch[28] Batch[0] avg_epoch_loss=2.747193\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.7471930980682373\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] Epoch[28] Batch[5] avg_epoch_loss=2.938845\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.9388454357783\n",
      "[05/21/2025 22:02:03 INFO 139996243154752] Epoch[28] Batch [5]#011Speed: 2177.49 samples/sec#011loss=2.938845\n",
      "[05/21/2025 22:02:04 INFO 139996243154752] processed a total of 1265 examples\n",
      "#metrics {\"StartTime\": 1747864923.3322432, \"EndTime\": 1747864924.1822083, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 849.7018814086914, \"count\": 1, \"min\": 849.7018814086914, \"max\": 849.7018814086914}}}\n",
      "[05/21/2025 22:02:04 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1488.5937098448503 records/second\n",
      "[05/21/2025 22:02:04 INFO 139996243154752] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/21/2025 22:02:04 INFO 139996243154752] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.8725198030471804\n",
      "[05/21/2025 22:02:04 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:04 INFO 139996243154752] Epoch[29] Batch[0] avg_epoch_loss=2.807826\n",
      "[05/21/2025 22:02:04 INFO 139996243154752] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.807825803756714\n",
      "[05/21/2025 22:02:04 INFO 139996243154752] Epoch[29] Batch[5] avg_epoch_loss=2.814180\n",
      "[05/21/2025 22:02:04 INFO 139996243154752] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.814179539680481\n",
      "[05/21/2025 22:02:04 INFO 139996243154752] Epoch[29] Batch [5]#011Speed: 2016.25 samples/sec#011loss=2.814180\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] Epoch[29] Batch[10] avg_epoch_loss=2.714090\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=2.593982195854187\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] Epoch[29] Batch [10]#011Speed: 2189.63 samples/sec#011loss=2.593982\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747864924.1822736, \"EndTime\": 1747864925.1166852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.1139793395996, \"count\": 1, \"min\": 934.1139793395996, \"max\": 934.1139793395996}}}\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1397.9942893601817 records/second\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.7140898379412564\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_c980e824-58aa-42de-8e49-467ea77fcab2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864925.1167397, \"EndTime\": 1747864925.1270876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.080814361572266, \"count\": 1, \"min\": 10.080814361572266, \"max\": 10.080814361572266}}}\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] Epoch[30] Batch[0] avg_epoch_loss=3.240074\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=3.2400739192962646\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] Epoch[30] Batch[5] avg_epoch_loss=2.929757\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.929757316907247\n",
      "[05/21/2025 22:02:05 INFO 139996243154752] Epoch[30] Batch [5]#011Speed: 2237.25 samples/sec#011loss=2.929757\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] Epoch[30] Batch[10] avg_epoch_loss=2.978977\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=3.03804030418396\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] Epoch[30] Batch [10]#011Speed: 2153.01 samples/sec#011loss=3.038040\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747864925.127138, \"EndTime\": 1747864926.0282469, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 901.06201171875, \"count\": 1, \"min\": 901.06201171875, \"max\": 901.06201171875}}}\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1482.5559779896828 records/second\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.97897685657848\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] Epoch[31] Batch[0] avg_epoch_loss=2.857700\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.8576998710632324\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] Epoch[31] Batch[5] avg_epoch_loss=2.809325\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.8093252976735434\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] Epoch[31] Batch [5]#011Speed: 2163.07 samples/sec#011loss=2.809325\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747864926.0283031, \"EndTime\": 1747864926.880765, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 852.1840572357178, \"count\": 1, \"min\": 852.1840572357178, \"max\": 852.1840572357178}}}\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1493.6014848320822 records/second\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.8522629022598265\n",
      "[05/21/2025 22:02:06 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] Epoch[32] Batch[0] avg_epoch_loss=2.950584\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.9505841732025146\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] Epoch[32] Batch[5] avg_epoch_loss=2.797827\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.797826806704203\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] Epoch[32] Batch [5]#011Speed: 2221.07 samples/sec#011loss=2.797827\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] Epoch[32] Batch[10] avg_epoch_loss=2.850724\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=2.9142003059387207\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] Epoch[32] Batch [10]#011Speed: 2214.20 samples/sec#011loss=2.914200\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747864926.8808284, \"EndTime\": 1747864927.7797387, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 898.6148834228516, \"count\": 1, \"min\": 898.6148834228516, \"max\": 898.6148834228516}}}\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1447.6485227419844 records/second\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.8507238518108022\n",
      "[05/21/2025 22:02:07 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] Epoch[33] Batch[0] avg_epoch_loss=2.661847\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.66184663772583\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] Epoch[33] Batch[5] avg_epoch_loss=2.807194\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.8071939945220947\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] Epoch[33] Batch [5]#011Speed: 2277.70 samples/sec#011loss=2.807194\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] Epoch[33] Batch[10] avg_epoch_loss=2.736201\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=2.651008415222168\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] Epoch[33] Batch [10]#011Speed: 2014.88 samples/sec#011loss=2.651008\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747864927.7797956, \"EndTime\": 1747864928.6987834, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.7369346618652, \"count\": 1, \"min\": 918.7369346618652, \"max\": 918.7369346618652}}}\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1467.1019229576602 records/second\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.736200549385764\n",
      "[05/21/2025 22:02:08 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] Epoch[34] Batch[0] avg_epoch_loss=3.026814\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=3.0268144607543945\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] Epoch[34] Batch[5] avg_epoch_loss=2.791303\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.7913028796513877\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] Epoch[34] Batch [5]#011Speed: 2242.96 samples/sec#011loss=2.791303\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] Epoch[34] Batch[10] avg_epoch_loss=2.798529\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=2.8072011947631834\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] Epoch[34] Batch [10]#011Speed: 2049.06 samples/sec#011loss=2.807201\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747864928.6988392, \"EndTime\": 1747864929.6142852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.1499271392822, \"count\": 1, \"min\": 915.1499271392822, \"max\": 915.1499271392822}}}\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1485.9617345383747 records/second\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.7985293865203857\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] Epoch[35] Batch[0] avg_epoch_loss=2.816485\n",
      "[05/21/2025 22:02:09 INFO 139996243154752] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.8164851665496826\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] Epoch[35] Batch[5] avg_epoch_loss=2.812174\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.8121740023295083\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] Epoch[35] Batch [5]#011Speed: 2230.63 samples/sec#011loss=2.812174\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] Epoch[35] Batch[10] avg_epoch_loss=2.742438\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=2.6587552547454836\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] Epoch[35] Batch [10]#011Speed: 2140.71 samples/sec#011loss=2.658755\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747864929.6143408, \"EndTime\": 1747864930.5354266, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.7901954650879, \"count\": 1, \"min\": 920.7901954650879, \"max\": 920.7901954650879}}}\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1432.3217699803313 records/second\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.7424382079731333\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] Epoch[36] Batch[0] avg_epoch_loss=2.752332\n",
      "[05/21/2025 22:02:10 INFO 139996243154752] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.7523322105407715\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] Epoch[36] Batch[5] avg_epoch_loss=2.809051\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.8090513149897256\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] Epoch[36] Batch [5]#011Speed: 2155.63 samples/sec#011loss=2.809051\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] Epoch[36] Batch[10] avg_epoch_loss=2.887311\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.9812236785888673\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] Epoch[36] Batch [10]#011Speed: 2160.37 samples/sec#011loss=2.981224\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747864930.5354922, \"EndTime\": 1747864931.4499166, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.177656173706, \"count\": 1, \"min\": 914.177656173706, \"max\": 914.177656173706}}}\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1416.4477035893478 records/second\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.887311480262063\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] Epoch[37] Batch[0] avg_epoch_loss=2.970896\n",
      "[05/21/2025 22:02:11 INFO 139996243154752] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.9708964824676514\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] Epoch[37] Batch[5] avg_epoch_loss=3.003304\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=3.003303647041321\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] Epoch[37] Batch [5]#011Speed: 2131.89 samples/sec#011loss=3.003304\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] Epoch[37] Batch[10] avg_epoch_loss=3.043376\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=3.0914626121520996\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] Epoch[37] Batch [10]#011Speed: 2092.48 samples/sec#011loss=3.091463\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747864931.4499726, \"EndTime\": 1747864932.3799381, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.6984672546387, \"count\": 1, \"min\": 929.6984672546387, \"max\": 929.6984672546387}}}\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1398.1816391505563 records/second\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] #quality_metric: host=algo-1, epoch=37, train loss <loss>=3.0433759039098565\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] Epoch[38] Batch[0] avg_epoch_loss=2.888294\n",
      "[05/21/2025 22:02:12 INFO 139996243154752] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.888293743133545\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] Epoch[38] Batch[5] avg_epoch_loss=2.948308\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.948307514190674\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] Epoch[38] Batch [5]#011Speed: 2148.52 samples/sec#011loss=2.948308\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747864932.3799932, \"EndTime\": 1747864933.238379, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 858.0701351165771, \"count\": 1, \"min\": 858.0701351165771, \"max\": 858.0701351165771}}}\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1483.3890159153154 records/second\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.947096061706543\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] Epoch[39] Batch[0] avg_epoch_loss=2.992871\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.9928712844848633\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] Epoch[39] Batch[5] avg_epoch_loss=2.908764\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.9087635278701782\n",
      "[05/21/2025 22:02:13 INFO 139996243154752] Epoch[39] Batch [5]#011Speed: 2208.21 samples/sec#011loss=2.908764\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] Epoch[39] Batch[10] avg_epoch_loss=2.953579\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=3.0073585987091063\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] Epoch[39] Batch [10]#011Speed: 2068.74 samples/sec#011loss=3.007359\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747864933.2384465, \"EndTime\": 1747864934.1709008, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.084321975708, \"count\": 1, \"min\": 932.084321975708, \"max\": 932.084321975708}}}\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1396.736422190604 records/second\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.9535794691606\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] Epoch[40] Batch[0] avg_epoch_loss=3.003117\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=3.003117084503174\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] Epoch[40] Batch[5] avg_epoch_loss=2.999461\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.99946129322052\n",
      "[05/21/2025 22:02:14 INFO 139996243154752] Epoch[40] Batch [5]#011Speed: 2204.07 samples/sec#011loss=2.999461\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] Epoch[40] Batch[10] avg_epoch_loss=2.911615\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=2.8061986923217774\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] Epoch[40] Batch [10]#011Speed: 2057.74 samples/sec#011loss=2.806199\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747864934.1709611, \"EndTime\": 1747864935.0890734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.7999496459961, \"count\": 1, \"min\": 917.7999496459961, \"max\": 917.7999496459961}}}\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1484.926885842296 records/second\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.9116146564483643\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] Epoch[41] Batch[0] avg_epoch_loss=2.993168\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.9931676387786865\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] Epoch[41] Batch[5] avg_epoch_loss=2.815917\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.815917213757833\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] Epoch[41] Batch [5]#011Speed: 2247.07 samples/sec#011loss=2.815917\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] Epoch[41] Batch[10] avg_epoch_loss=2.877553\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=2.9515169620513917\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] Epoch[41] Batch [10]#011Speed: 2175.12 samples/sec#011loss=2.951517\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747864935.0891316, \"EndTime\": 1747864935.9909897, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 901.5913009643555, \"count\": 1, \"min\": 901.5913009643555, \"max\": 901.5913009643555}}}\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1457.2913162466386 records/second\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.8775534629821777\n",
      "[05/21/2025 22:02:15 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] Epoch[42] Batch[0] avg_epoch_loss=2.686444\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.68644380569458\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] Epoch[42] Batch[5] avg_epoch_loss=2.860993\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.860993226369222\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] Epoch[42] Batch [5]#011Speed: 2205.59 samples/sec#011loss=2.860993\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] Epoch[42] Batch[10] avg_epoch_loss=2.897464\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.9412281036376955\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] Epoch[42] Batch [10]#011Speed: 2039.73 samples/sec#011loss=2.941228\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747864935.991046, \"EndTime\": 1747864936.9201455, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.8506507873535, \"count\": 1, \"min\": 928.8506507873535, \"max\": 928.8506507873535}}}\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1419.9076994941263 records/second\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.897463625127619\n",
      "[05/21/2025 22:02:16 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] Epoch[43] Batch[0] avg_epoch_loss=2.895588\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.895587921142578\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] Epoch[43] Batch[5] avg_epoch_loss=2.833732\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.8337316115697226\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] Epoch[43] Batch [5]#011Speed: 2038.07 samples/sec#011loss=2.833732\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] Epoch[43] Batch[10] avg_epoch_loss=2.835252\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.837075614929199\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] Epoch[43] Batch [10]#011Speed: 2141.24 samples/sec#011loss=2.837076\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747864936.9202013, \"EndTime\": 1747864937.8572385, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.7856979370117, \"count\": 1, \"min\": 936.7856979370117, \"max\": 936.7856979370117}}}\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1420.6741484279648 records/second\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.8352516130967573\n",
      "[05/21/2025 22:02:17 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] Epoch[44] Batch[0] avg_epoch_loss=3.253080\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=3.253080129623413\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] Epoch[44] Batch[5] avg_epoch_loss=3.070532\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=3.0705315272013345\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] Epoch[44] Batch [5]#011Speed: 2294.29 samples/sec#011loss=3.070532\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] Epoch[44] Batch[10] avg_epoch_loss=3.140557\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=3.2245864868164062\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] Epoch[44] Batch [10]#011Speed: 2083.88 samples/sec#011loss=3.224586\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747864937.8573053, \"EndTime\": 1747864938.7586734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 901.1132717132568, \"count\": 1, \"min\": 901.1132717132568, \"max\": 901.1132717132568}}}\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1512.4333815798489 records/second\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] #quality_metric: host=algo-1, epoch=44, train loss <loss>=3.140556508844549\n",
      "[05/21/2025 22:02:18 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] Epoch[45] Batch[0] avg_epoch_loss=2.988633\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.9886326789855957\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] Epoch[45] Batch[5] avg_epoch_loss=2.922079\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.9220789670944214\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] Epoch[45] Batch [5]#011Speed: 2166.64 samples/sec#011loss=2.922079\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] Epoch[45] Batch[10] avg_epoch_loss=2.896846\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=2.8665669918060304\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] Epoch[45] Batch [10]#011Speed: 1989.29 samples/sec#011loss=2.866567\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747864938.7587297, \"EndTime\": 1747864939.6937983, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.8225593566895, \"count\": 1, \"min\": 934.8225593566895, \"max\": 934.8225593566895}}}\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1466.459077096333 records/second\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.8968462510542436\n",
      "[05/21/2025 22:02:19 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] Epoch[46] Batch[0] avg_epoch_loss=2.896587\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.896587371826172\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] Epoch[46] Batch[5] avg_epoch_loss=2.873290\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.8732895056406655\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] Epoch[46] Batch [5]#011Speed: 2171.81 samples/sec#011loss=2.873290\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] Epoch[46] Batch[10] avg_epoch_loss=2.941885\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=3.0242000102996824\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] Epoch[46] Batch [10]#011Speed: 2027.00 samples/sec#011loss=3.024200\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747864939.693854, \"EndTime\": 1747864940.6323645, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.2202625274658, \"count\": 1, \"min\": 938.2202625274658, \"max\": 938.2202625274658}}}\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1405.7264311646495 records/second\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.9418851895765825\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] Epoch[47] Batch[0] avg_epoch_loss=3.223224\n",
      "[05/21/2025 22:02:20 INFO 139996243154752] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=3.2232236862182617\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] Epoch[47] Batch[5] avg_epoch_loss=3.085714\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=3.085713545481364\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] Epoch[47] Batch [5]#011Speed: 2199.79 samples/sec#011loss=3.085714\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] Epoch[47] Batch[10] avg_epoch_loss=2.897801\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=2.672305703163147\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] Epoch[47] Batch [10]#011Speed: 2123.96 samples/sec#011loss=2.672306\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747864940.632423, \"EndTime\": 1747864941.5459535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 913.1238460540771, \"count\": 1, \"min\": 913.1238460540771, \"max\": 913.1238460540771}}}\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1445.454571087678 records/second\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.8978008898821743\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] Epoch[48] Batch[0] avg_epoch_loss=2.855238\n",
      "[05/21/2025 22:02:21 INFO 139996243154752] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.855238437652588\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] Epoch[48] Batch[5] avg_epoch_loss=2.928894\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.9288944005966187\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] Epoch[48] Batch [5]#011Speed: 2180.78 samples/sec#011loss=2.928894\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] Epoch[48] Batch[10] avg_epoch_loss=2.921580\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=2.9128031730651855\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] Epoch[48] Batch [10]#011Speed: 2197.01 samples/sec#011loss=2.912803\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747864941.54601, \"EndTime\": 1747864942.4595351, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 913.2490158081055, \"count\": 1, \"min\": 913.2490158081055, \"max\": 913.2490158081055}}}\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1412.4130557018848 records/second\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.921580206264149\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] Epoch[49] Batch[0] avg_epoch_loss=2.832153\n",
      "[05/21/2025 22:02:22 INFO 139996243154752] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.8321533203125\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] Epoch[49] Batch[5] avg_epoch_loss=2.884307\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.8843066692352295\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] Epoch[49] Batch [5]#011Speed: 2183.08 samples/sec#011loss=2.884307\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] Epoch[49] Batch[10] avg_epoch_loss=2.862910\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=2.837233829498291\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] Epoch[49] Batch [10]#011Speed: 2130.61 samples/sec#011loss=2.837234\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747864942.4595902, \"EndTime\": 1747864943.3748965, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.0593280792236, \"count\": 1, \"min\": 915.0593280792236, \"max\": 915.0593280792236}}}\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1455.5109694543487 records/second\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.8629099239002573\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] Epoch[50] Batch[0] avg_epoch_loss=2.726479\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.7264790534973145\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] Epoch[50] Batch[5] avg_epoch_loss=2.826569\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.8265690406163535\n",
      "[05/21/2025 22:02:23 INFO 139996243154752] Epoch[50] Batch [5]#011Speed: 2210.35 samples/sec#011loss=2.826569\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] Epoch[50] Batch[10] avg_epoch_loss=2.864715\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.910489797592163\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] Epoch[50] Batch [10]#011Speed: 1999.34 samples/sec#011loss=2.910490\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747864943.3749537, \"EndTime\": 1747864944.313091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.8862380981445, \"count\": 1, \"min\": 937.8862380981445, \"max\": 937.8862380981445}}}\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1383.8400337558749 records/second\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.864714839241721\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] Epoch[51] Batch[0] avg_epoch_loss=2.658410\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.6584103107452393\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] Epoch[51] Batch[5] avg_epoch_loss=2.800174\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.8001736799875894\n",
      "[05/21/2025 22:02:24 INFO 139996243154752] Epoch[51] Batch [5]#011Speed: 2099.05 samples/sec#011loss=2.800174\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] Epoch[51] Batch[10] avg_epoch_loss=2.823208\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.850850009918213\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] Epoch[51] Batch [10]#011Speed: 2047.62 samples/sec#011loss=2.850850\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747864944.3131483, \"EndTime\": 1747864945.251243, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.840461730957, \"count\": 1, \"min\": 937.840461730957, \"max\": 937.840461730957}}}\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1447.815714307865 records/second\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.8232083754106\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] Epoch[52] Batch[0] avg_epoch_loss=2.817636\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.817636013031006\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] Epoch[52] Batch[5] avg_epoch_loss=2.805657\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.8056567112604776\n",
      "[05/21/2025 22:02:25 INFO 139996243154752] Epoch[52] Batch [5]#011Speed: 2195.74 samples/sec#011loss=2.805657\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] Epoch[52] Batch[10] avg_epoch_loss=2.761268\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=2.708002281188965\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] Epoch[52] Batch [10]#011Speed: 2135.20 samples/sec#011loss=2.708002\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747864945.2513373, \"EndTime\": 1747864946.168311, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.6722297668457, \"count\": 1, \"min\": 916.6722297668457, \"max\": 916.6722297668457}}}\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1404.9508322406182 records/second\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.7612683339552446\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] Epoch[53] Batch[0] avg_epoch_loss=2.692140\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.6921401023864746\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] Epoch[53] Batch[5] avg_epoch_loss=2.819419\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.8194192250569663\n",
      "[05/21/2025 22:02:26 INFO 139996243154752] Epoch[53] Batch [5]#011Speed: 2142.11 samples/sec#011loss=2.819419\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] Epoch[53] Batch[10] avg_epoch_loss=2.621221\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.383384132385254\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] Epoch[53] Batch [10]#011Speed: 2087.25 samples/sec#011loss=2.383384\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747864946.1683688, \"EndTime\": 1747864947.0968366, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.2150268554688, \"count\": 1, \"min\": 928.2150268554688, \"max\": 928.2150268554688}}}\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1404.724581006304 records/second\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.6212214556607334\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_a4411fc7-744c-4f7b-8acc-b7dd551f2c48-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864947.0968914, \"EndTime\": 1747864947.1071732, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.006427764892578, \"count\": 1, \"min\": 10.006427764892578, \"max\": 10.006427764892578}}}\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] Epoch[54] Batch[0] avg_epoch_loss=2.829164\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.8291640281677246\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] Epoch[54] Batch[5] avg_epoch_loss=2.753280\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.753279765446981\n",
      "[05/21/2025 22:02:27 INFO 139996243154752] Epoch[54] Batch [5]#011Speed: 2157.03 samples/sec#011loss=2.753280\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] Epoch[54] Batch[10] avg_epoch_loss=2.851444\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=2.96924204826355\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] Epoch[54] Batch [10]#011Speed: 2031.09 samples/sec#011loss=2.969242\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747864947.1072252, \"EndTime\": 1747864948.0442116, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.9399547576904, \"count\": 1, \"min\": 936.9399547576904, \"max\": 936.9399547576904}}}\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1392.7076593789263 records/second\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.851444439454512\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] Epoch[55] Batch[0] avg_epoch_loss=3.072825\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=3.0728249549865723\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] Epoch[55] Batch[5] avg_epoch_loss=3.010710\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=3.010709603627523\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] Epoch[55] Batch [5]#011Speed: 2154.86 samples/sec#011loss=3.010710\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] Epoch[55] Batch[10] avg_epoch_loss=2.993228\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.972250747680664\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] Epoch[55] Batch [10]#011Speed: 2012.81 samples/sec#011loss=2.972251\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747864948.0442684, \"EndTime\": 1747864948.979334, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.8182678222656, \"count\": 1, \"min\": 934.8182678222656, \"max\": 934.8182678222656}}}\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1402.2846554442735 records/second\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.99322830546986\n",
      "[05/21/2025 22:02:28 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:29 INFO 139996243154752] Epoch[56] Batch[0] avg_epoch_loss=2.841262\n",
      "[05/21/2025 22:02:29 INFO 139996243154752] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.841262102127075\n",
      "[05/21/2025 22:02:29 INFO 139996243154752] Epoch[56] Batch[5] avg_epoch_loss=2.803720\n",
      "[05/21/2025 22:02:29 INFO 139996243154752] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.803719917933146\n",
      "[05/21/2025 22:02:29 INFO 139996243154752] Epoch[56] Batch [5]#011Speed: 2253.28 samples/sec#011loss=2.803720\n",
      "[05/21/2025 22:02:29 INFO 139996243154752] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747864948.9793923, \"EndTime\": 1747864949.8263297, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 846.6908931732178, \"count\": 1, \"min\": 846.6908931732178, \"max\": 846.6908931732178}}}\n",
      "[05/21/2025 22:02:29 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1504.5157055694926 records/second\n",
      "[05/21/2025 22:02:29 INFO 139996243154752] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/21/2025 22:02:29 INFO 139996243154752] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.8153210639953614\n",
      "[05/21/2025 22:02:29 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] Epoch[57] Batch[0] avg_epoch_loss=2.791624\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.791623830795288\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] Epoch[57] Batch[5] avg_epoch_loss=2.786631\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.7866311073303223\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] Epoch[57] Batch [5]#011Speed: 2302.86 samples/sec#011loss=2.786631\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] Epoch[57] Batch[10] avg_epoch_loss=2.877770\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=2.9871357440948487\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] Epoch[57] Batch [10]#011Speed: 2108.81 samples/sec#011loss=2.987136\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747864949.8263938, \"EndTime\": 1747864950.7313695, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.6769142150879, \"count\": 1, \"min\": 904.6769142150879, \"max\": 904.6769142150879}}}\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1426.902060093912 records/second\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.8777695785869253\n",
      "[05/21/2025 22:02:30 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] Epoch[58] Batch[0] avg_epoch_loss=2.703111\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.703110694885254\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] Epoch[58] Batch[5] avg_epoch_loss=2.824524\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.8245240449905396\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] Epoch[58] Batch [5]#011Speed: 2257.76 samples/sec#011loss=2.824524\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] Epoch[58] Batch[10] avg_epoch_loss=2.907160\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=3.006323051452637\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] Epoch[58] Batch [10]#011Speed: 2147.75 samples/sec#011loss=3.006323\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747864950.7314239, \"EndTime\": 1747864951.639056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.3340892791748, \"count\": 1, \"min\": 907.3340892791748, \"max\": 907.3340892791748}}}\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1417.2112776269332 records/second\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.9071599570187656\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] Epoch[59] Batch[0] avg_epoch_loss=2.959602\n",
      "[05/21/2025 22:02:31 INFO 139996243154752] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.959601640701294\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] Epoch[59] Batch[5] avg_epoch_loss=2.905776\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.9057764212290444\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] Epoch[59] Batch [5]#011Speed: 2161.95 samples/sec#011loss=2.905776\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] Epoch[59] Batch[10] avg_epoch_loss=2.898406\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=2.8895620346069335\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] Epoch[59] Batch [10]#011Speed: 2031.61 samples/sec#011loss=2.889562\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747864951.6391113, \"EndTime\": 1747864952.575789, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.4273548126221, \"count\": 1, \"min\": 936.4273548126221, \"max\": 936.4273548126221}}}\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1439.385060941769 records/second\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.898406245491721\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] Epoch[60] Batch[0] avg_epoch_loss=3.031379\n",
      "[05/21/2025 22:02:32 INFO 139996243154752] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=3.031378746032715\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] Epoch[60] Batch[5] avg_epoch_loss=2.826729\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.826729496320089\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] Epoch[60] Batch [5]#011Speed: 2192.71 samples/sec#011loss=2.826729\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] Epoch[60] Batch[10] avg_epoch_loss=2.791621\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.749491310119629\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] Epoch[60] Batch [10]#011Speed: 2012.17 samples/sec#011loss=2.749491\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] processed a total of 1386 examples\n",
      "#metrics {\"StartTime\": 1747864952.575846, \"EndTime\": 1747864953.5014992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.4016876220703, \"count\": 1, \"min\": 925.4016876220703, \"max\": 925.4016876220703}}}\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1497.5227241580774 records/second\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.7916212298653345\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] Epoch[61] Batch[0] avg_epoch_loss=2.809943\n",
      "[05/21/2025 22:02:33 INFO 139996243154752] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.809943199157715\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] Epoch[61] Batch[5] avg_epoch_loss=2.725279\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.7252785762151084\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] Epoch[61] Batch [5]#011Speed: 2162.15 samples/sec#011loss=2.725279\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] Epoch[61] Batch[10] avg_epoch_loss=2.727600\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=2.7303849697113036\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] Epoch[61] Batch [10]#011Speed: 2113.10 samples/sec#011loss=2.730385\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747864953.5015996, \"EndTime\": 1747864954.4372864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.4264736175537, \"count\": 1, \"min\": 935.4264736175537, \"max\": 935.4264736175537}}}\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1369.2306263635533 records/second\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.7275996641679243\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] Epoch[62] Batch[0] avg_epoch_loss=2.621072\n",
      "[05/21/2025 22:02:34 INFO 139996243154752] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.621072292327881\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] Epoch[62] Batch[5] avg_epoch_loss=2.714594\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.7145938078562417\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] Epoch[62] Batch [5]#011Speed: 2107.89 samples/sec#011loss=2.714594\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] Epoch[62] Batch[10] avg_epoch_loss=2.680385\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.639335203170776\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] Epoch[62] Batch [10]#011Speed: 2092.80 samples/sec#011loss=2.639335\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747864954.4373932, \"EndTime\": 1747864955.3691902, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.5271377563477, \"count\": 1, \"min\": 931.5271377563477, \"max\": 931.5271377563477}}}\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1423.3429501665278 records/second\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.6803853511810303\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] Epoch[63] Batch[0] avg_epoch_loss=2.683163\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.6831634044647217\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] Epoch[63] Batch[5] avg_epoch_loss=2.719564\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.719563603401184\n",
      "[05/21/2025 22:02:35 INFO 139996243154752] Epoch[63] Batch [5]#011Speed: 2134.45 samples/sec#011loss=2.719564\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] Epoch[63] Batch[10] avg_epoch_loss=2.876322\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=3.064432907104492\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] Epoch[63] Batch [10]#011Speed: 2067.33 samples/sec#011loss=3.064433\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747864955.3692455, \"EndTime\": 1747864956.3020027, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.4953556060791, \"count\": 1, \"min\": 932.4953556060791, \"max\": 932.4953556060791}}}\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1402.5577783845306 records/second\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.876322377811779\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] Epoch[64] Batch[0] avg_epoch_loss=3.765842\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=3.7658424377441406\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] Epoch[64] Batch[5] avg_epoch_loss=3.388753\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=3.3887527783711753\n",
      "[05/21/2025 22:02:36 INFO 139996243154752] Epoch[64] Batch [5]#011Speed: 2051.00 samples/sec#011loss=3.388753\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] Epoch[64] Batch[10] avg_epoch_loss=3.218167\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=3.013463544845581\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] Epoch[64] Batch [10]#011Speed: 2152.87 samples/sec#011loss=3.013464\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747864956.302062, \"EndTime\": 1747864957.2316244, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.2700290679932, \"count\": 1, \"min\": 929.2700290679932, \"max\": 929.2700290679932}}}\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1430.039968660482 records/second\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] #quality_metric: host=algo-1, epoch=64, train loss <loss>=3.2181667631322686\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] Epoch[65] Batch[0] avg_epoch_loss=3.199572\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=3.1995718479156494\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] Epoch[65] Batch[5] avg_epoch_loss=3.167938\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=3.167938232421875\n",
      "[05/21/2025 22:02:37 INFO 139996243154752] Epoch[65] Batch [5]#011Speed: 2030.40 samples/sec#011loss=3.167938\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] Epoch[65] Batch[10] avg_epoch_loss=3.169297\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=3.1709264755249023\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] Epoch[65] Batch [10]#011Speed: 2034.11 samples/sec#011loss=3.170926\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] processed a total of 1391 examples\n",
      "#metrics {\"StartTime\": 1747864957.231673, \"EndTime\": 1747864958.1765404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.6473121643066, \"count\": 1, \"min\": 944.6473121643066, \"max\": 944.6473121643066}}}\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1472.3764259341979 records/second\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] #quality_metric: host=algo-1, epoch=65, train loss <loss>=3.169296524741433\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] Epoch[66] Batch[0] avg_epoch_loss=3.130728\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=3.1307284832000732\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] Epoch[66] Batch[5] avg_epoch_loss=2.988096\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.9880956013997397\n",
      "[05/21/2025 22:02:38 INFO 139996243154752] Epoch[66] Batch [5]#011Speed: 2230.51 samples/sec#011loss=2.988096\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] Epoch[66] Batch[10] avg_epoch_loss=2.940039\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.8823719024658203\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] Epoch[66] Batch [10]#011Speed: 1996.52 samples/sec#011loss=2.882372\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] processed a total of 1397 examples\n",
      "#metrics {\"StartTime\": 1747864958.1765985, \"EndTime\": 1747864959.0985038, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.6532707214355, \"count\": 1, \"min\": 921.6532707214355, \"max\": 921.6532707214355}}}\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1515.6234481488493 records/second\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.9400393746115943\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] Epoch[67] Batch[0] avg_epoch_loss=2.991617\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.99161696434021\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] Epoch[67] Batch[5] avg_epoch_loss=2.936120\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.936119556427002\n",
      "[05/21/2025 22:02:39 INFO 139996243154752] Epoch[67] Batch [5]#011Speed: 2186.86 samples/sec#011loss=2.936120\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] Epoch[67] Batch[10] avg_epoch_loss=2.865762\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.7813337326049803\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] Epoch[67] Batch [10]#011Speed: 2023.06 samples/sec#011loss=2.781334\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747864959.0985587, \"EndTime\": 1747864960.0302403, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.4324855804443, \"count\": 1, \"min\": 931.4324855804443, \"max\": 931.4324855804443}}}\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1423.489034830088 records/second\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.8657623637806284\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] Epoch[68] Batch[0] avg_epoch_loss=2.816062\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.8160617351531982\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] Epoch[68] Batch[5] avg_epoch_loss=2.818883\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.8188827435175576\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] Epoch[68] Batch [5]#011Speed: 2159.51 samples/sec#011loss=2.818883\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] Epoch[68] Batch[10] avg_epoch_loss=2.790836\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.7571796417236327\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] Epoch[68] Batch [10]#011Speed: 1905.40 samples/sec#011loss=2.757180\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747864960.0302963, \"EndTime\": 1747864960.9839897, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.4397125244141, \"count\": 1, \"min\": 953.4397125244141, \"max\": 953.4397125244141}}}\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1373.8533461453737 records/second\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.790835879065774\n",
      "[05/21/2025 22:02:40 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:41 INFO 139996243154752] Epoch[69] Batch[0] avg_epoch_loss=2.863723\n",
      "[05/21/2025 22:02:41 INFO 139996243154752] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.8637232780456543\n",
      "[05/21/2025 22:02:41 INFO 139996243154752] Epoch[69] Batch[5] avg_epoch_loss=2.839206\n",
      "[05/21/2025 22:02:41 INFO 139996243154752] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.8392063776652017\n",
      "[05/21/2025 22:02:41 INFO 139996243154752] Epoch[69] Batch [5]#011Speed: 2154.69 samples/sec#011loss=2.839206\n",
      "[05/21/2025 22:02:41 INFO 139996243154752] processed a total of 1246 examples\n",
      "#metrics {\"StartTime\": 1747864960.984047, \"EndTime\": 1747864961.8484578, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.1555309295654, \"count\": 1, \"min\": 864.1555309295654, \"max\": 864.1555309295654}}}\n",
      "[05/21/2025 22:02:41 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1441.7022190356674 records/second\n",
      "[05/21/2025 22:02:41 INFO 139996243154752] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/21/2025 22:02:41 INFO 139996243154752] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.8195681810379027\n",
      "[05/21/2025 22:02:41 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] Epoch[70] Batch[0] avg_epoch_loss=2.837147\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.8371472358703613\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] Epoch[70] Batch[5] avg_epoch_loss=2.759668\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.7596675554911294\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] Epoch[70] Batch [5]#011Speed: 2190.58 samples/sec#011loss=2.759668\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] Epoch[70] Batch[10] avg_epoch_loss=2.807606\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.8651318550109863\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] Epoch[70] Batch [10]#011Speed: 2069.48 samples/sec#011loss=2.865132\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747864961.8485188, \"EndTime\": 1747864962.7732444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.4375228881836, \"count\": 1, \"min\": 924.4375228881836, \"max\": 924.4375228881836}}}\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1403.9677842365984 records/second\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.8076058734547007\n",
      "[05/21/2025 22:02:42 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] Epoch[71] Batch[0] avg_epoch_loss=2.900386\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.900385856628418\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] Epoch[71] Batch[5] avg_epoch_loss=2.889121\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.8891210158665976\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] Epoch[71] Batch [5]#011Speed: 2222.47 samples/sec#011loss=2.889121\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] Epoch[71] Batch[10] avg_epoch_loss=3.000398\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=3.133931303024292\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] Epoch[71] Batch [10]#011Speed: 2097.37 samples/sec#011loss=3.133931\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747864962.7733033, \"EndTime\": 1747864963.6925526, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.9896583557129, \"count\": 1, \"min\": 918.9896583557129, \"max\": 918.9896583557129}}}\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1428.6143451307944 records/second\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] #quality_metric: host=algo-1, epoch=71, train loss <loss>=3.000398419120095\n",
      "[05/21/2025 22:02:43 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] Epoch[72] Batch[0] avg_epoch_loss=2.790559\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.7905588150024414\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] Epoch[72] Batch[5] avg_epoch_loss=2.774399\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.7743993202845254\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] Epoch[72] Batch [5]#011Speed: 2090.78 samples/sec#011loss=2.774399\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] Epoch[72] Batch[10] avg_epoch_loss=2.811254\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.8554791450500487\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] Epoch[72] Batch [10]#011Speed: 2085.94 samples/sec#011loss=2.855479\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747864963.6926084, \"EndTime\": 1747864964.6290648, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.2068176269531, \"count\": 1, \"min\": 936.2068176269531, \"max\": 936.2068176269531}}}\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1439.7259318751176 records/second\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.811253786087036\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] Epoch[73] Batch[0] avg_epoch_loss=2.684610\n",
      "[05/21/2025 22:02:44 INFO 139996243154752] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.684609889984131\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] Epoch[73] Batch[5] avg_epoch_loss=2.756015\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.756015419960022\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] Epoch[73] Batch [5]#011Speed: 2159.92 samples/sec#011loss=2.756015\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] Epoch[73] Batch[10] avg_epoch_loss=2.813612\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=2.8827274799346925\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] Epoch[73] Batch [10]#011Speed: 2135.03 samples/sec#011loss=2.882727\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747864964.6291215, \"EndTime\": 1747864965.552313, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.9364395141602, \"count\": 1, \"min\": 922.9364395141602, \"max\": 922.9364395141602}}}\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1414.9207614971847 records/second\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.8136118108575996\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] Epoch[74] Batch[0] avg_epoch_loss=2.732343\n",
      "[05/21/2025 22:02:45 INFO 139996243154752] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.7323429584503174\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] Epoch[74] Batch[5] avg_epoch_loss=2.788018\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.7880183458328247\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] Epoch[74] Batch [5]#011Speed: 2132.09 samples/sec#011loss=2.788018\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] Epoch[74] Batch[10] avg_epoch_loss=2.786601\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.784900426864624\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] Epoch[74] Batch [10]#011Speed: 2160.53 samples/sec#011loss=2.784900\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747864965.5523698, \"EndTime\": 1747864966.4714108, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.7827110290527, \"count\": 1, \"min\": 918.7827110290527, \"max\": 918.7827110290527}}}\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1444.1681572345908 records/second\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.786601109938188\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] Epoch[75] Batch[0] avg_epoch_loss=2.847165\n",
      "[05/21/2025 22:02:46 INFO 139996243154752] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.84716534614563\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] Epoch[75] Batch[5] avg_epoch_loss=2.733148\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.733148455619812\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] Epoch[75] Batch [5]#011Speed: 1957.68 samples/sec#011loss=2.733148\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] Epoch[75] Batch[10] avg_epoch_loss=2.706291\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=2.674062395095825\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] Epoch[75] Batch [10]#011Speed: 2059.23 samples/sec#011loss=2.674062\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747864966.471468, \"EndTime\": 1747864967.444751, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.0539321899414, \"count\": 1, \"min\": 973.0539321899414, \"max\": 973.0539321899414}}}\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1333.8311552416178 records/second\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.7062911553816362\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] Epoch[76] Batch[0] avg_epoch_loss=2.784517\n",
      "[05/21/2025 22:02:47 INFO 139996243154752] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.7845168113708496\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] Epoch[76] Batch[5] avg_epoch_loss=2.788727\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.7887272437413535\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] Epoch[76] Batch [5]#011Speed: 2161.58 samples/sec#011loss=2.788727\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] Epoch[76] Batch[10] avg_epoch_loss=2.793798\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.7998836040496826\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] Epoch[76] Batch [10]#011Speed: 2071.75 samples/sec#011loss=2.799884\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747864967.444806, \"EndTime\": 1747864968.3724535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.4032115936279, \"count\": 1, \"min\": 927.4032115936279, \"max\": 927.4032115936279}}}\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1419.971627807381 records/second\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.793798316608776\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] Epoch[77] Batch[0] avg_epoch_loss=2.795824\n",
      "[05/21/2025 22:02:48 INFO 139996243154752] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.7958240509033203\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] Epoch[77] Batch[5] avg_epoch_loss=2.752680\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.7526798248291016\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] Epoch[77] Batch [5]#011Speed: 1986.25 samples/sec#011loss=2.752680\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] Epoch[77] Batch[10] avg_epoch_loss=2.742936\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.731244134902954\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] Epoch[77] Batch [10]#011Speed: 2001.16 samples/sec#011loss=2.731244\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] processed a total of 1396 examples\n",
      "#metrics {\"StartTime\": 1747864968.3725088, \"EndTime\": 1747864969.3265643, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.7968635559082, \"count\": 1, \"min\": 953.7968635559082, \"max\": 953.7968635559082}}}\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1463.493054514116 records/second\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.7429363294081255\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] Epoch[78] Batch[0] avg_epoch_loss=2.531528\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.5315284729003906\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] Epoch[78] Batch[5] avg_epoch_loss=2.642679\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.6426787773768106\n",
      "[05/21/2025 22:02:49 INFO 139996243154752] Epoch[78] Batch [5]#011Speed: 2164.55 samples/sec#011loss=2.642679\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] Epoch[78] Batch[10] avg_epoch_loss=2.656075\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.6721514225006104\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] Epoch[78] Batch [10]#011Speed: 2059.64 samples/sec#011loss=2.672151\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747864969.3266215, \"EndTime\": 1747864970.2527652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.7941246032715, \"count\": 1, \"min\": 925.7941246032715, \"max\": 925.7941246032715}}}\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1448.3537729787968 records/second\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.656075434251265\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] Epoch[79] Batch[0] avg_epoch_loss=2.807329\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.8073291778564453\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] Epoch[79] Batch[5] avg_epoch_loss=2.756937\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.756936550140381\n",
      "[05/21/2025 22:02:50 INFO 139996243154752] Epoch[79] Batch [5]#011Speed: 2225.88 samples/sec#011loss=2.756937\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] Epoch[79] Batch[10] avg_epoch_loss=2.688800\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.607035779953003\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] Epoch[79] Batch [10]#011Speed: 2152.32 samples/sec#011loss=2.607036\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747864970.2528222, \"EndTime\": 1747864971.164924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.855936050415, \"count\": 1, \"min\": 911.855936050415, \"max\": 911.855936050415}}}\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1449.6566201841904 records/second\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.6887998364188452\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] Epoch[80] Batch[0] avg_epoch_loss=2.686393\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.6863930225372314\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] Epoch[80] Batch[5] avg_epoch_loss=2.718139\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.7181392908096313\n",
      "[05/21/2025 22:02:51 INFO 139996243154752] Epoch[80] Batch [5]#011Speed: 2172.59 samples/sec#011loss=2.718139\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] Epoch[80] Batch[10] avg_epoch_loss=2.794204\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.885481357574463\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] Epoch[80] Batch [10]#011Speed: 2019.37 samples/sec#011loss=2.885481\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747864971.164982, \"EndTime\": 1747864972.1071475, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.9190883636475, \"count\": 1, \"min\": 941.9190883636475, \"max\": 941.9190883636475}}}\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1386.4067552692968 records/second\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.7942038666118276\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] Epoch[81] Batch[0] avg_epoch_loss=2.934256\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.934255838394165\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] Epoch[81] Batch[5] avg_epoch_loss=2.907821\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.9078213373819985\n",
      "[05/21/2025 22:02:52 INFO 139996243154752] Epoch[81] Batch [5]#011Speed: 2257.27 samples/sec#011loss=2.907821\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] Epoch[81] Batch[10] avg_epoch_loss=2.888150\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.8645434856414793\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] Epoch[81] Batch [10]#011Speed: 2201.05 samples/sec#011loss=2.864543\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747864972.1072047, \"EndTime\": 1747864973.0048554, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.3958492279053, \"count\": 1, \"min\": 897.3958492279053, \"max\": 897.3958492279053}}}\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1474.154560488386 records/second\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.8881495865908535\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] Epoch[82] Batch[0] avg_epoch_loss=3.041651\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=3.0416505336761475\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] Epoch[82] Batch[5] avg_epoch_loss=2.810273\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.8102731307347617\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] Epoch[82] Batch [5]#011Speed: 2326.35 samples/sec#011loss=2.810273\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] Epoch[82] Batch[10] avg_epoch_loss=2.898725\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=3.0048680782318113\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] Epoch[82] Batch [10]#011Speed: 2144.06 samples/sec#011loss=3.004868\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747864973.0049005, \"EndTime\": 1747864973.903109, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 898.0152606964111, \"count\": 1, \"min\": 898.0152606964111, \"max\": 898.0152606964111}}}\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1436.36925372223 records/second\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.898725379597057\n",
      "[05/21/2025 22:02:53 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] Epoch[83] Batch[0] avg_epoch_loss=2.953943\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.9539425373077393\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] Epoch[83] Batch[5] avg_epoch_loss=2.954134\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.9541335900624595\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] Epoch[83] Batch [5]#011Speed: 2197.39 samples/sec#011loss=2.954134\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] Epoch[83] Batch[10] avg_epoch_loss=2.915696\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.869570732116699\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] Epoch[83] Batch [10]#011Speed: 2175.07 samples/sec#011loss=2.869571\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747864973.9031663, \"EndTime\": 1747864974.813131, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.6794128417969, \"count\": 1, \"min\": 909.6794128417969, \"max\": 909.6794128417969}}}\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1428.9467987695416 records/second\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.9156959273598413\n",
      "[05/21/2025 22:02:54 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] Epoch[84] Batch[0] avg_epoch_loss=2.882502\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.8825018405914307\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] Epoch[84] Batch[5] avg_epoch_loss=2.814311\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.814311385154724\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] Epoch[84] Batch [5]#011Speed: 2195.45 samples/sec#011loss=2.814311\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] Epoch[84] Batch[10] avg_epoch_loss=2.800833\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.7846580028533934\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] Epoch[84] Batch [10]#011Speed: 2099.78 samples/sec#011loss=2.784658\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747864974.8131864, \"EndTime\": 1747864975.7365563, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.1104850769043, \"count\": 1, \"min\": 923.1104850769043, \"max\": 923.1104850769043}}}\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1430.902322866724 records/second\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.800832575017756\n",
      "[05/21/2025 22:02:55 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] Epoch[85] Batch[0] avg_epoch_loss=3.004655\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=3.004655122756958\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] Epoch[85] Batch[5] avg_epoch_loss=2.906641\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.906640887260437\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] Epoch[85] Batch [5]#011Speed: 2159.67 samples/sec#011loss=2.906641\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747864975.736614, \"EndTime\": 1747864976.6064792, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 869.5731163024902, \"count\": 1, \"min\": 869.5731163024902, \"max\": 869.5731163024902}}}\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1471.8373165655232 records/second\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.855259418487549\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] Epoch[86] Batch[0] avg_epoch_loss=2.712574\n",
      "[05/21/2025 22:02:56 INFO 139996243154752] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.7125744819641113\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] Epoch[86] Batch[5] avg_epoch_loss=2.772654\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.7726539373397827\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] Epoch[86] Batch [5]#011Speed: 2172.17 samples/sec#011loss=2.772654\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] Epoch[86] Batch[10] avg_epoch_loss=2.658106\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.5206478118896483\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] Epoch[86] Batch [10]#011Speed: 2177.42 samples/sec#011loss=2.520648\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747864976.6065383, \"EndTime\": 1747864977.524345, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.4723625183105, \"count\": 1, \"min\": 917.4723625183105, \"max\": 917.4723625183105}}}\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1417.8970359689947 records/second\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.6581056984988125\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] Epoch[87] Batch[0] avg_epoch_loss=2.794916\n",
      "[05/21/2025 22:02:57 INFO 139996243154752] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.7949156761169434\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] Epoch[87] Batch[5] avg_epoch_loss=2.759064\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.7590636809666953\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] Epoch[87] Batch [5]#011Speed: 2161.78 samples/sec#011loss=2.759064\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] Epoch[87] Batch[10] avg_epoch_loss=2.791960\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.8314349174499513\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] Epoch[87] Batch [10]#011Speed: 2007.17 samples/sec#011loss=2.831435\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747864977.524402, \"EndTime\": 1747864978.4587727, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.1187477111816, \"count\": 1, \"min\": 934.1187477111816, \"max\": 934.1187477111816}}}\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1446.15669572674 records/second\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.791959697549993\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] Epoch[88] Batch[0] avg_epoch_loss=2.951073\n",
      "[05/21/2025 22:02:58 INFO 139996243154752] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.951073408126831\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] Epoch[88] Batch[5] avg_epoch_loss=2.714459\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.71445894241333\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] Epoch[88] Batch [5]#011Speed: 2112.50 samples/sec#011loss=2.714459\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] Epoch[88] Batch[10] avg_epoch_loss=2.600451\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=2.4636404752731322\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] Epoch[88] Batch [10]#011Speed: 2074.80 samples/sec#011loss=2.463640\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747864978.4588268, \"EndTime\": 1747864979.4007585, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.6446685791016, \"count\": 1, \"min\": 941.6446685791016, \"max\": 941.6446685791016}}}\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1382.5642980383022 records/second\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.600450548258695\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] best epoch loss so far\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/state_63f6622e-e9aa-4d56-befd-c37de2ecd948-0000.params\"\n",
      "#metrics {\"StartTime\": 1747864979.400816, \"EndTime\": 1747864979.411291, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.203361511230469, \"count\": 1, \"min\": 10.203361511230469, \"max\": 10.203361511230469}}}\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] Epoch[89] Batch[0] avg_epoch_loss=2.835654\n",
      "[05/21/2025 22:02:59 INFO 139996243154752] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.8356544971466064\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] Epoch[89] Batch[5] avg_epoch_loss=2.741513\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.7415133317311606\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] Epoch[89] Batch [5]#011Speed: 2110.63 samples/sec#011loss=2.741513\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] Epoch[89] Batch[10] avg_epoch_loss=2.759364\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=2.780783939361572\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] Epoch[89] Batch [10]#011Speed: 2043.74 samples/sec#011loss=2.780784\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747864979.4113429, \"EndTime\": 1747864980.3441122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.7247142791748, \"count\": 1, \"min\": 932.7247142791748, \"max\": 932.7247142791748}}}\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1447.2399539014677 records/second\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.7593636079268022\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] Epoch[90] Batch[0] avg_epoch_loss=2.846712\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.846712350845337\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] Epoch[90] Batch[5] avg_epoch_loss=2.762952\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.7629524866739907\n",
      "[05/21/2025 22:03:00 INFO 139996243154752] Epoch[90] Batch [5]#011Speed: 2034.46 samples/sec#011loss=2.762952\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] Epoch[90] Batch[10] avg_epoch_loss=2.676266\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.572242784500122\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] Epoch[90] Batch [10]#011Speed: 2045.35 samples/sec#011loss=2.572243\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747864980.3441703, \"EndTime\": 1747864981.2954593, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.9527683258057, \"count\": 1, \"min\": 950.9527683258057, \"max\": 950.9527683258057}}}\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1401.625901993109 records/second\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.6762662584131416\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] Epoch[91] Batch[0] avg_epoch_loss=2.609360\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.6093597412109375\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] Epoch[91] Batch[5] avg_epoch_loss=2.704907\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.7049069007237754\n",
      "[05/21/2025 22:03:01 INFO 139996243154752] Epoch[91] Batch [5]#011Speed: 2137.92 samples/sec#011loss=2.704907\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] Epoch[91] Batch[10] avg_epoch_loss=2.643376\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=2.5695385456085207\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] Epoch[91] Batch [10]#011Speed: 2060.09 samples/sec#011loss=2.569539\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747864981.2955155, \"EndTime\": 1747864982.2441933, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.4264850616455, \"count\": 1, \"min\": 948.4264850616455, \"max\": 948.4264850616455}}}\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1399.0354293321188 records/second\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.6433758302168413\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] Epoch[92] Batch[0] avg_epoch_loss=2.649635\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.649635076522827\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] Epoch[92] Batch[5] avg_epoch_loss=2.816506\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.816506028175354\n",
      "[05/21/2025 22:03:02 INFO 139996243154752] Epoch[92] Batch [5]#011Speed: 2204.04 samples/sec#011loss=2.816506\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] Epoch[92] Batch[10] avg_epoch_loss=2.814473\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.8120338916778564\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] Epoch[92] Batch [10]#011Speed: 2067.43 samples/sec#011loss=2.812034\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747864982.2442513, \"EndTime\": 1747864983.1658416, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.3216304779053, \"count\": 1, \"min\": 921.3216304779053, \"max\": 921.3216304779053}}}\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1435.8498215235254 records/second\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.8144732388583096\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] Epoch[93] Batch[0] avg_epoch_loss=2.821057\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.821057081222534\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] Epoch[93] Batch[5] avg_epoch_loss=2.753427\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.7534265915552774\n",
      "[05/21/2025 22:03:03 INFO 139996243154752] Epoch[93] Batch [5]#011Speed: 2159.12 samples/sec#011loss=2.753427\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] Epoch[93] Batch[10] avg_epoch_loss=2.750313\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.7465767860412598\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] Epoch[93] Batch [10]#011Speed: 2076.47 samples/sec#011loss=2.746577\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747864983.1658974, \"EndTime\": 1747864984.0926096, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.4674186706543, \"count\": 1, \"min\": 926.4674186706543, \"max\": 926.4674186706543}}}\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1435.4337636819653 records/second\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.7503130435943604\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] Epoch[94] Batch[0] avg_epoch_loss=2.837130\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.837130308151245\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] Epoch[94] Batch[5] avg_epoch_loss=2.794890\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.7948903242746987\n",
      "[05/21/2025 22:03:04 INFO 139996243154752] Epoch[94] Batch [5]#011Speed: 2119.63 samples/sec#011loss=2.794890\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] Epoch[94] Batch[10] avg_epoch_loss=2.805218\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=2.8176101207733155\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] Epoch[94] Batch [10]#011Speed: 2071.65 samples/sec#011loss=2.817610\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747864984.0926642, \"EndTime\": 1747864985.0266712, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.7596893310547, \"count\": 1, \"min\": 933.7596893310547, \"max\": 933.7596893310547}}}\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1404.947597285553 records/second\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.8052175045013428\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] Epoch[95] Batch[0] avg_epoch_loss=2.794371\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.7943711280822754\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] Epoch[95] Batch[5] avg_epoch_loss=2.753663\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.753663261731466\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] Epoch[95] Batch [5]#011Speed: 2230.46 samples/sec#011loss=2.753663\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] Epoch[95] Batch[10] avg_epoch_loss=2.718641\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.676613473892212\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] Epoch[95] Batch [10]#011Speed: 1982.84 samples/sec#011loss=2.676613\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] processed a total of 1377 examples\n",
      "#metrics {\"StartTime\": 1747864985.0267282, \"EndTime\": 1747864985.9517765, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.7753620147705, \"count\": 1, \"min\": 924.7753620147705, \"max\": 924.7753620147705}}}\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1488.8770612837498 records/second\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.7186406308954414\n",
      "[05/21/2025 22:03:05 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] Epoch[96] Batch[0] avg_epoch_loss=2.605830\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.6058297157287598\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] Epoch[96] Batch[5] avg_epoch_loss=2.701853\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.7018525997797647\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] Epoch[96] Batch [5]#011Speed: 2036.94 samples/sec#011loss=2.701853\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] Epoch[96] Batch[10] avg_epoch_loss=2.886208\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=3.1074344635009767\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] Epoch[96] Batch [10]#011Speed: 2188.27 samples/sec#011loss=3.107434\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747864985.9518316, \"EndTime\": 1747864986.8884177, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.3195896148682, \"count\": 1, \"min\": 936.3195896148682, \"max\": 936.3195896148682}}}\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1386.1587957273098 records/second\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.8862079923803154\n",
      "[05/21/2025 22:03:06 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] Epoch[97] Batch[0] avg_epoch_loss=2.796027\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.7960267066955566\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] Epoch[97] Batch[5] avg_epoch_loss=3.118455\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=3.1184547344843545\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] Epoch[97] Batch [5]#011Speed: 2202.30 samples/sec#011loss=3.118455\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] Epoch[97] Batch[10] avg_epoch_loss=3.096937\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=3.071114921569824\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] Epoch[97] Batch [10]#011Speed: 2070.92 samples/sec#011loss=3.071115\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747864986.8884737, \"EndTime\": 1747864987.821848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.1297874450684, \"count\": 1, \"min\": 933.1297874450684, \"max\": 933.1297874450684}}}\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1424.048155060029 records/second\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] #quality_metric: host=algo-1, epoch=97, train loss <loss>=3.0969366377050225\n",
      "[05/21/2025 22:03:07 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] Epoch[98] Batch[0] avg_epoch_loss=3.121587\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=3.1215872764587402\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] Epoch[98] Batch[5] avg_epoch_loss=3.068025\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=3.0680246353149414\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] Epoch[98] Batch [5]#011Speed: 2130.51 samples/sec#011loss=3.068025\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] Epoch[98] Batch[10] avg_epoch_loss=3.142272\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=3.2313679695129394\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] Epoch[98] Batch [10]#011Speed: 2027.24 samples/sec#011loss=3.231368\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747864987.8219452, \"EndTime\": 1747864988.7634022, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.1671161651611, \"count\": 1, \"min\": 941.1671161651611, \"max\": 941.1671161651611}}}\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1360.957085386964 records/second\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] #quality_metric: host=algo-1, epoch=98, train loss <loss>=3.1422716054049404\n",
      "[05/21/2025 22:03:08 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] Epoch[99] Batch[0] avg_epoch_loss=2.813628\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.8136279582977295\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] Epoch[99] Batch[5] avg_epoch_loss=2.907739\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.907739440600077\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] Epoch[99] Batch [5]#011Speed: 2154.72 samples/sec#011loss=2.907739\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] Epoch[99] Batch[10] avg_epoch_loss=2.776379\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=2.618746614456177\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] Epoch[99] Batch [10]#011Speed: 2063.44 samples/sec#011loss=2.618747\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747864988.7634583, \"EndTime\": 1747864989.698233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.4773292541504, \"count\": 1, \"min\": 934.4773292541504, \"max\": 934.4773292541504}}}\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1427.407412812019 records/second\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.7763790650801226\n",
      "[05/21/2025 22:03:09 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] Epoch[100] Batch[0] avg_epoch_loss=2.985545\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.9855446815490723\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] Epoch[100] Batch[5] avg_epoch_loss=2.847870\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.8478700319925943\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] Epoch[100] Batch [5]#011Speed: 2158.42 samples/sec#011loss=2.847870\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747864989.6982899, \"EndTime\": 1747864990.5539722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 855.4325103759766, \"count\": 1, \"min\": 855.4325103759766, \"max\": 855.4325103759766}}}\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1490.3195816644911 records/second\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.821801209449768\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] Epoch[101] Batch[0] avg_epoch_loss=2.710545\n",
      "[05/21/2025 22:03:10 INFO 139996243154752] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.7105448246002197\n",
      "[05/21/2025 22:03:11 INFO 139996243154752] Epoch[101] Batch[5] avg_epoch_loss=2.751073\n",
      "[05/21/2025 22:03:11 INFO 139996243154752] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.7510727643966675\n",
      "[05/21/2025 22:03:11 INFO 139996243154752] Epoch[101] Batch [5]#011Speed: 2082.39 samples/sec#011loss=2.751073\n",
      "[05/21/2025 22:03:11 INFO 139996243154752] processed a total of 1251 examples\n",
      "#metrics {\"StartTime\": 1747864990.5540323, \"EndTime\": 1747864991.430636, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 876.2767314910889, \"count\": 1, \"min\": 876.2767314910889, \"max\": 876.2767314910889}}}\n",
      "[05/21/2025 22:03:11 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1427.4447751010582 records/second\n",
      "[05/21/2025 22:03:11 INFO 139996243154752] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/21/2025 22:03:11 INFO 139996243154752] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.7691293954849243\n",
      "[05/21/2025 22:03:11 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:11 INFO 139996243154752] Epoch[102] Batch[0] avg_epoch_loss=2.775644\n",
      "[05/21/2025 22:03:11 INFO 139996243154752] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.7756435871124268\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] Epoch[102] Batch[5] avg_epoch_loss=2.729454\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.7294544776280723\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] Epoch[102] Batch [5]#011Speed: 2101.87 samples/sec#011loss=2.729454\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] Epoch[102] Batch[10] avg_epoch_loss=2.679822\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=2.6202629089355467\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] Epoch[102] Batch [10]#011Speed: 2117.00 samples/sec#011loss=2.620263\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747864991.430709, \"EndTime\": 1747864992.361808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.708646774292, \"count\": 1, \"min\": 930.708646774292, \"max\": 930.708646774292}}}\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1396.6513227677215 records/second\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.679821946404197\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] Epoch[103] Batch[0] avg_epoch_loss=2.717119\n",
      "[05/21/2025 22:03:12 INFO 139996243154752] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.717118978500366\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] Epoch[103] Batch[5] avg_epoch_loss=2.715482\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.715481956799825\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] Epoch[103] Batch [5]#011Speed: 2021.26 samples/sec#011loss=2.715482\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] Epoch[103] Batch[10] avg_epoch_loss=2.749570\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.7904762744903566\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] Epoch[103] Batch [10]#011Speed: 1983.95 samples/sec#011loss=2.790476\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747864992.3618658, \"EndTime\": 1747864993.3254037, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.1457328796387, \"count\": 1, \"min\": 963.1457328796387, \"max\": 963.1457328796387}}}\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1380.7690481759666 records/second\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.749570283022794\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] Epoch[104] Batch[0] avg_epoch_loss=2.889299\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.889298915863037\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] Epoch[104] Batch[5] avg_epoch_loss=2.752960\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.7529595295588174\n",
      "[05/21/2025 22:03:13 INFO 139996243154752] Epoch[104] Batch [5]#011Speed: 2140.29 samples/sec#011loss=2.752960\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] Epoch[104] Batch[10] avg_epoch_loss=2.758349\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=2.764816331863403\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] Epoch[104] Batch [10]#011Speed: 2000.38 samples/sec#011loss=2.764816\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747864993.3254607, \"EndTime\": 1747864994.2634897, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.7832412719727, \"count\": 1, \"min\": 937.7832412719727, \"max\": 937.7832412719727}}}\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1442.6390373006102 records/second\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.758348985151811\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] Epoch[105] Batch[0] avg_epoch_loss=2.727239\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.7272393703460693\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] Epoch[105] Batch[5] avg_epoch_loss=2.663450\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.6634499231974282\n",
      "[05/21/2025 22:03:14 INFO 139996243154752] Epoch[105] Batch [5]#011Speed: 2019.98 samples/sec#011loss=2.663450\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] Epoch[105] Batch[10] avg_epoch_loss=2.613377\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.5532888889312746\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] Epoch[105] Batch [10]#011Speed: 2015.50 samples/sec#011loss=2.553289\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747864994.2635443, \"EndTime\": 1747864995.2244833, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.6943130493164, \"count\": 1, \"min\": 960.6943130493164, \"max\": 960.6943130493164}}}\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1341.6207311734886 records/second\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.613376725803722\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] Epoch[106] Batch[0] avg_epoch_loss=2.938012\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.938011646270752\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] Epoch[106] Batch[5] avg_epoch_loss=2.806216\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.8062156438827515\n",
      "[05/21/2025 22:03:15 INFO 139996243154752] Epoch[106] Batch [5]#011Speed: 2144.76 samples/sec#011loss=2.806216\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] Epoch[106] Batch[10] avg_epoch_loss=2.889916\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=2.9903557300567627\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] Epoch[106] Batch [10]#011Speed: 2038.49 samples/sec#011loss=2.990356\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747864995.2245405, \"EndTime\": 1747864996.1604614, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.6751441955566, \"count\": 1, \"min\": 935.6751441955566, \"max\": 935.6751441955566}}}\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1408.481492843057 records/second\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.8899156830527564\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] Epoch[107] Batch[0] avg_epoch_loss=2.779201\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.779201030731201\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] Epoch[107] Batch[5] avg_epoch_loss=2.858562\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.8585619926452637\n",
      "[05/21/2025 22:03:16 INFO 139996243154752] Epoch[107] Batch [5]#011Speed: 2115.27 samples/sec#011loss=2.858562\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] Epoch[107] Batch[10] avg_epoch_loss=2.861356\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.864709568023682\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] Epoch[107] Batch [10]#011Speed: 1990.94 samples/sec#011loss=2.864710\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747864996.1605186, \"EndTime\": 1747864997.1037307, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.9647922515869, \"count\": 1, \"min\": 942.9647922515869, \"max\": 942.9647922515869}}}\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1418.8055018108041 records/second\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.861356345089999\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] Epoch[108] Batch[0] avg_epoch_loss=2.888918\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.8889176845550537\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] Epoch[108] Batch[5] avg_epoch_loss=2.839907\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.839906613032023\n",
      "[05/21/2025 22:03:17 INFO 139996243154752] Epoch[108] Batch [5]#011Speed: 2075.22 samples/sec#011loss=2.839907\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] Epoch[108] Batch[10] avg_epoch_loss=2.773715\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.694284772872925\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] Epoch[108] Batch [10]#011Speed: 2105.50 samples/sec#011loss=2.694285\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747864997.1037862, \"EndTime\": 1747864998.0389404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.9119663238525, \"count\": 1, \"min\": 934.9119663238525, \"max\": 934.9119663238525}}}\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1424.60628296122 records/second\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.77371486750516\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] Epoch[109] Batch[0] avg_epoch_loss=2.677132\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.6771321296691895\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] Epoch[109] Batch[5] avg_epoch_loss=2.750188\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.7501876751581826\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] Epoch[109] Batch [5]#011Speed: 2037.63 samples/sec#011loss=2.750188\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] Epoch[109] Batch[10] avg_epoch_loss=2.805284\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.8714005947113037\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] Epoch[109] Batch [10]#011Speed: 2050.16 samples/sec#011loss=2.871401\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747864998.0389977, \"EndTime\": 1747864998.9880495, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.7977027893066, \"count\": 1, \"min\": 948.7977027893066, \"max\": 948.7977027893066}}}\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1393.218394432021 records/second\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.805284456773238\n",
      "[05/21/2025 22:03:18 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] Epoch[110] Batch[0] avg_epoch_loss=2.809431\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.8094308376312256\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] Epoch[110] Batch[5] avg_epoch_loss=2.815267\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.815267244974772\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] Epoch[110] Batch [5]#011Speed: 2002.98 samples/sec#011loss=2.815267\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] Epoch[110] Batch[10] avg_epoch_loss=2.907079\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=3.0172538280487062\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] Epoch[110] Batch [10]#011Speed: 2052.10 samples/sec#011loss=3.017254\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747864998.9881067, \"EndTime\": 1747864999.950528, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 962.1791839599609, \"count\": 1, \"min\": 962.1791839599609, \"max\": 962.1791839599609}}}\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1362.4149301576629 records/second\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.9070793281901968\n",
      "[05/21/2025 22:03:19 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] Epoch[111] Batch[0] avg_epoch_loss=2.836103\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.8361034393310547\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] Epoch[111] Batch[5] avg_epoch_loss=2.872406\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.8724061250686646\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] Epoch[111] Batch [5]#011Speed: 2154.06 samples/sec#011loss=2.872406\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] Epoch[111] Batch[10] avg_epoch_loss=2.899419\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=2.9318355083465577\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] Epoch[111] Batch [10]#011Speed: 2049.56 samples/sec#011loss=2.931836\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747864999.9505851, \"EndTime\": 1747865000.9038975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.066349029541, \"count\": 1, \"min\": 953.066349029541, \"max\": 953.066349029541}}}\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1372.2890793432102 records/second\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.8994194811040703\n",
      "[05/21/2025 22:03:20 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] Epoch[112] Batch[0] avg_epoch_loss=2.763988\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.7639882564544678\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] Epoch[112] Batch[5] avg_epoch_loss=2.847499\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.847498814264933\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] Epoch[112] Batch [5]#011Speed: 2052.47 samples/sec#011loss=2.847499\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] Epoch[112] Batch[10] avg_epoch_loss=2.744726\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.6213990688323974\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] Epoch[112] Batch [10]#011Speed: 2023.92 samples/sec#011loss=2.621399\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747865000.9039557, \"EndTime\": 1747865001.8566003, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.392578125, \"count\": 1, \"min\": 952.392578125, \"max\": 952.392578125}}}\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1393.2081316010936 records/second\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.74472620270469\n",
      "[05/21/2025 22:03:21 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] Epoch[113] Batch[0] avg_epoch_loss=2.872963\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.8729631900787354\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] Epoch[113] Batch[5] avg_epoch_loss=2.782688\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.7826875845591226\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] Epoch[113] Batch [5]#011Speed: 2144.04 samples/sec#011loss=2.782688\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] Epoch[113] Batch[10] avg_epoch_loss=2.914595\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=3.0728829860687257\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] Epoch[113] Batch [10]#011Speed: 2023.46 samples/sec#011loss=3.072883\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747865001.8566573, \"EndTime\": 1747865002.807589, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.6855010986328, \"count\": 1, \"min\": 950.6855010986328, \"max\": 950.6855010986328}}}\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1391.5063156202739 records/second\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.9145945852453057\n",
      "[05/21/2025 22:03:22 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] Epoch[114] Batch[0] avg_epoch_loss=2.884538\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.884538173675537\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] Epoch[114] Batch[5] avg_epoch_loss=2.870499\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.870499014854431\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] Epoch[114] Batch [5]#011Speed: 2183.33 samples/sec#011loss=2.870499\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747865002.8076453, \"EndTime\": 1747865003.6555462, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 847.649097442627, \"count\": 1, \"min\": 847.649097442627, \"max\": 847.649097442627}}}\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1508.7169869054583 records/second\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.8765884399414063\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] Epoch[115] Batch[0] avg_epoch_loss=3.069339\n",
      "[05/21/2025 22:03:23 INFO 139996243154752] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=3.0693392753601074\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] Epoch[115] Batch[5] avg_epoch_loss=2.847441\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.8474411169687905\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] Epoch[115] Batch [5]#011Speed: 2152.05 samples/sec#011loss=2.847441\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] Epoch[115] Batch[10] avg_epoch_loss=2.877974\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=2.9146140575408936\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] Epoch[115] Batch [10]#011Speed: 2026.39 samples/sec#011loss=2.914614\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747865003.6556091, \"EndTime\": 1747865004.591412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.5144500732422, \"count\": 1, \"min\": 935.5144500732422, \"max\": 935.5144500732422}}}\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1418.3432758649249 records/second\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.877974271774292\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] Epoch[116] Batch[0] avg_epoch_loss=2.789025\n",
      "[05/21/2025 22:03:24 INFO 139996243154752] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.789024829864502\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] Epoch[116] Batch[5] avg_epoch_loss=2.860440\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.860439936319987\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] Epoch[116] Batch [5]#011Speed: 2157.37 samples/sec#011loss=2.860440\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] Epoch[116] Batch[10] avg_epoch_loss=2.845590\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=2.8277702808380125\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] Epoch[116] Batch [10]#011Speed: 1985.45 samples/sec#011loss=2.827770\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] processed a total of 1376 examples\n",
      "#metrics {\"StartTime\": 1747865004.59147, \"EndTime\": 1747865005.5313463, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.6383762359619, \"count\": 1, \"min\": 939.6383762359619, \"max\": 939.6383762359619}}}\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1464.2653403943145 records/second\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.8455900929190894\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] Epoch[117] Batch[0] avg_epoch_loss=2.792397\n",
      "[05/21/2025 22:03:25 INFO 139996243154752] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.7923974990844727\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] Epoch[117] Batch[5] avg_epoch_loss=2.733272\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.7332719961802163\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] Epoch[117] Batch [5]#011Speed: 2110.59 samples/sec#011loss=2.733272\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] Epoch[117] Batch[10] avg_epoch_loss=2.626545\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.4984732389450075\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] Epoch[117] Batch [10]#011Speed: 2048.89 samples/sec#011loss=2.498473\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747865005.5314028, \"EndTime\": 1747865006.4729753, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.3232803344727, \"count\": 1, \"min\": 941.3232803344727, \"max\": 941.3232803344727}}}\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1380.9146117082798 records/second\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.6265452883460303\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] Epoch[118] Batch[0] avg_epoch_loss=2.770954\n",
      "[05/21/2025 22:03:26 INFO 139996243154752] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.770954132080078\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] Epoch[118] Batch[5] avg_epoch_loss=2.747745\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.747744639714559\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] Epoch[118] Batch [5]#011Speed: 2129.02 samples/sec#011loss=2.747745\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] Epoch[118] Batch[10] avg_epoch_loss=2.747820\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.747911071777344\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] Epoch[118] Batch [10]#011Speed: 2001.77 samples/sec#011loss=2.747911\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747865006.4730308, \"EndTime\": 1747865007.4172285, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.8879489898682, \"count\": 1, \"min\": 943.8879489898682, \"max\": 943.8879489898682}}}\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1413.173774460033 records/second\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.7478202906521885\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] Epoch[119] Batch[0] avg_epoch_loss=2.890714\n",
      "[05/21/2025 22:03:27 INFO 139996243154752] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.890713691711426\n",
      "\n",
      "2025-05-21 22:03:40 Uploading - Uploading generated training model[05/21/2025 22:03:28 INFO 139996243154752] Epoch[119] Batch[5] avg_epoch_loss=3.068183\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=3.0681834618250527\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] Epoch[119] Batch [5]#011Speed: 2078.09 samples/sec#011loss=3.068183\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747865007.4172883, \"EndTime\": 1747865008.3032975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 885.7500553131104, \"count\": 1, \"min\": 885.7500553131104, \"max\": 885.7500553131104}}}\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1442.7028261019934 records/second\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] #quality_metric: host=algo-1, epoch=119, train loss <loss>=3.00882511138916\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] Epoch[120] Batch[0] avg_epoch_loss=2.915804\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.915803909301758\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] Epoch[120] Batch[5] avg_epoch_loss=2.889535\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.889535148938497\n",
      "[05/21/2025 22:03:28 INFO 139996243154752] Epoch[120] Batch [5]#011Speed: 2049.80 samples/sec#011loss=2.889535\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] Epoch[120] Batch[10] avg_epoch_loss=2.829493\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=2.757442855834961\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] Epoch[120] Batch [10]#011Speed: 1838.69 samples/sec#011loss=2.757443\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747865008.303359, \"EndTime\": 1747865009.292531, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 988.8062477111816, \"count\": 1, \"min\": 988.8062477111816, \"max\": 988.8062477111816}}}\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1361.120189907156 records/second\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.829493197527799\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] Epoch[121] Batch[0] avg_epoch_loss=2.920745\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.9207448959350586\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] Epoch[121] Batch[5] avg_epoch_loss=2.831213\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.8312127590179443\n",
      "[05/21/2025 22:03:29 INFO 139996243154752] Epoch[121] Batch [5]#011Speed: 1943.14 samples/sec#011loss=2.831213\n",
      "[05/21/2025 22:03:30 INFO 139996243154752] processed a total of 1268 examples\n",
      "#metrics {\"StartTime\": 1747865009.2925868, \"EndTime\": 1747865010.204218, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.2691879272461, \"count\": 1, \"min\": 911.2691879272461, \"max\": 911.2691879272461}}}\n",
      "[05/21/2025 22:03:30 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1391.307917649207 records/second\n",
      "[05/21/2025 22:03:30 INFO 139996243154752] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[05/21/2025 22:03:30 INFO 139996243154752] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.8768273830413817\n",
      "[05/21/2025 22:03:30 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:30 INFO 139996243154752] Epoch[122] Batch[0] avg_epoch_loss=2.737970\n",
      "[05/21/2025 22:03:30 INFO 139996243154752] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.7379701137542725\n",
      "[05/21/2025 22:03:30 INFO 139996243154752] Epoch[122] Batch[5] avg_epoch_loss=2.816091\n",
      "[05/21/2025 22:03:30 INFO 139996243154752] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.8160908222198486\n",
      "[05/21/2025 22:03:30 INFO 139996243154752] Epoch[122] Batch [5]#011Speed: 2039.07 samples/sec#011loss=2.816091\n",
      "[05/21/2025 22:03:31 INFO 139996243154752] processed a total of 1263 examples\n",
      "#metrics {\"StartTime\": 1747865010.204291, \"EndTime\": 1747865011.1009674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 896.3871002197266, \"count\": 1, \"min\": 896.3871002197266, \"max\": 896.3871002197266}}}\n",
      "[05/21/2025 22:03:31 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1408.842970859105 records/second\n",
      "[05/21/2025 22:03:31 INFO 139996243154752] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[05/21/2025 22:03:31 INFO 139996243154752] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.8151899337768556\n",
      "[05/21/2025 22:03:31 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:31 INFO 139996243154752] Epoch[123] Batch[0] avg_epoch_loss=2.604048\n",
      "[05/21/2025 22:03:31 INFO 139996243154752] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.6040477752685547\n",
      "[05/21/2025 22:03:31 INFO 139996243154752] Epoch[123] Batch[5] avg_epoch_loss=2.726033\n",
      "[05/21/2025 22:03:31 INFO 139996243154752] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.726032773653666\n",
      "[05/21/2025 22:03:31 INFO 139996243154752] Epoch[123] Batch [5]#011Speed: 2051.49 samples/sec#011loss=2.726033\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] Epoch[123] Batch[10] avg_epoch_loss=2.755124\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=2.7900335788726807\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] Epoch[123] Batch [10]#011Speed: 2038.65 samples/sec#011loss=2.790034\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747865011.1010308, \"EndTime\": 1747865012.0559793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.6597003936768, \"count\": 1, \"min\": 954.6597003936768, \"max\": 954.6597003936768}}}\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1386.7607585700223 records/second\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] #progress_metric: host=algo-1, completed 31.0 % of epochs\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.7551240487532183\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] Epoch[124] Batch[0] avg_epoch_loss=2.740548\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.7405476570129395\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] Epoch[124] Batch[5] avg_epoch_loss=2.774668\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.774667580922445\n",
      "[05/21/2025 22:03:32 INFO 139996243154752] Epoch[124] Batch [5]#011Speed: 1969.55 samples/sec#011loss=2.774668\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] Epoch[124] Batch[10] avg_epoch_loss=2.776329\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=2.7783220291137694\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] Epoch[124] Batch [10]#011Speed: 2054.07 samples/sec#011loss=2.778322\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747865012.056036, \"EndTime\": 1747865013.0200543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.7255668640137, \"count\": 1, \"min\": 963.7255668640137, \"max\": 963.7255668640137}}}\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1342.5893117368446 records/second\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] #progress_metric: host=algo-1, completed 31.25 % of epochs\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.776328693736683\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] Epoch[125] Batch[0] avg_epoch_loss=2.877650\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.8776497840881348\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] Epoch[125] Batch[5] avg_epoch_loss=2.786701\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.786700963973999\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] Epoch[125] Batch [5]#011Speed: 2006.16 samples/sec#011loss=2.786701\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] Epoch[125] Batch[10] avg_epoch_loss=2.835640\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=2.894366216659546\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] Epoch[125] Batch [10]#011Speed: 1887.00 samples/sec#011loss=2.894366\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] processed a total of 1376 examples\n",
      "#metrics {\"StartTime\": 1747865013.0201104, \"EndTime\": 1747865013.999485, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 979.130744934082, \"count\": 1, \"min\": 979.130744934082, \"max\": 979.130744934082}}}\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1405.2059976689313 records/second\n",
      "[05/21/2025 22:03:33 INFO 139996243154752] #progress_metric: host=algo-1, completed 31.5 % of epochs\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.835639715194702\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] Epoch[126] Batch[0] avg_epoch_loss=2.801322\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.801321506500244\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] Epoch[126] Batch[5] avg_epoch_loss=2.819040\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.819039781888326\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] Epoch[126] Batch [5]#011Speed: 1981.71 samples/sec#011loss=2.819040\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] Epoch[126] Batch[10] avg_epoch_loss=2.848879\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=2.8846857070922853\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] Epoch[126] Batch [10]#011Speed: 1885.46 samples/sec#011loss=2.884686\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747865013.999544, \"EndTime\": 1747865014.9850616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 984.708309173584, \"count\": 1, \"min\": 984.708309173584, \"max\": 984.708309173584}}}\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1381.001287973427 records/second\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] #progress_metric: host=algo-1, completed 31.75 % of epochs\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.8488788387992163\n",
      "[05/21/2025 22:03:34 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] Epoch[127] Batch[0] avg_epoch_loss=2.967324\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.9673244953155518\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] Epoch[127] Batch[5] avg_epoch_loss=2.849057\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.84905735651652\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] Epoch[127] Batch [5]#011Speed: 2062.39 samples/sec#011loss=2.849057\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] Epoch[127] Batch[10] avg_epoch_loss=2.914099\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=2.992148017883301\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] Epoch[127] Batch [10]#011Speed: 2016.25 samples/sec#011loss=2.992148\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747865014.9851182, \"EndTime\": 1747865015.9488044, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.4413719177246, \"count\": 1, \"min\": 963.4413719177246, \"max\": 963.4413719177246}}}\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1338.834883901622 records/second\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] #progress_metric: host=algo-1, completed 32.0 % of epochs\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.9140985662286933\n",
      "[05/21/2025 22:03:35 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Epoch[128] Batch[0] avg_epoch_loss=2.921510\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.9215102195739746\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Epoch[128] Batch[5] avg_epoch_loss=2.872542\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.872541666030884\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Epoch[128] Batch [5]#011Speed: 2004.80 samples/sec#011loss=2.872542\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] processed a total of 1251 examples\n",
      "#metrics {\"StartTime\": 1747865015.9488606, \"EndTime\": 1747865016.8417227, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 892.6093578338623, \"count\": 1, \"min\": 892.6093578338623, \"max\": 892.6093578338623}}}\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] #throughput_metric: host=algo-1, train throughput=1401.3551058866765 records/second\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] #progress_metric: host=algo-1, completed 32.25 % of epochs\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.8728232383728027\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] loss did not improve\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Loading parameters from best epoch (88)\n",
      "#metrics {\"StartTime\": 1747865016.8417833, \"EndTime\": 1747865016.8473341, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 5.183219909667969, \"count\": 1, \"min\": 5.183219909667969, \"max\": 5.183219909667969}}}\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] stopping training now\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Final loss: 2.600450548258695 (occurred at epoch 88)\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] #quality_metric: host=algo-1, train final_loss <loss>=2.600450548258695\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Worker algo-1 finished training.\n",
      "[05/21/2025 22:03:36 WARNING 139996243154752] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747865016.8473856, \"EndTime\": 1747865016.8967361, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 48.911094665527344, \"count\": 1, \"min\": 48.911094665527344, \"max\": 48.911094665527344}}}\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747865016.896782, \"EndTime\": 1747865016.9212034, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 73.40502738952637, \"count\": 1, \"min\": 73.40502738952637, \"max\": 73.40502738952637}}}\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747865016.9212437, \"EndTime\": 1747865016.9253206, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 4.047870635986328, \"count\": 1, \"min\": 4.047870635986328, \"max\": 4.047870635986328}}}\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Successfully serialized the model for prediction.\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "[05/21/2025 22:03:36 INFO 139996243154752] Evaluating model accuracy on testset using 100 samples\n",
      "#metrics {\"StartTime\": 1747865016.9253561, \"EndTime\": 1747865016.9269993, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}}}\n",
      "#metrics {\"StartTime\": 1747865016.9270346, \"EndTime\": 1747865017.1156757, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 188.69709968566895, \"count\": 1, \"min\": 188.69709968566895, \"max\": 188.69709968566895}}}\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, RMSE): 26.41033009003895\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, mean_absolute_QuantileLoss): 1198.3111111111111\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, mean_wQuantileLoss): 0.4523635753533828\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, wQuantileLoss[0.1]): 0.17674594186485468\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, wQuantileLoss[0.2]): 0.2958097395243488\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, wQuantileLoss[0.3]): 0.3970554926387316\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, wQuantileLoss[0.4]): 0.4774631936579841\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, wQuantileLoss[0.5]): 0.5334088335220838\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, wQuantileLoss[0.6]): 0.5750094375235939\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, wQuantileLoss[0.7]): 0.5877689694224234\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, wQuantileLoss[0.8]): 0.5540203850509625\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #test_score (algo-1, wQuantileLoss[0.9]): 0.47399018497546247\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #quality_metric: host=algo-1, test RMSE <loss>=26.41033009003895\n",
      "[05/21/2025 22:03:37 INFO 139996243154752] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.4523635753533828\n",
      "#metrics {\"StartTime\": 1747865017.1157534, \"EndTime\": 1747865017.1258695, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 3.5893917083740234, \"count\": 1, \"min\": 3.5893917083740234, \"max\": 3.5893917083740234}, \"totaltime\": {\"sum\": 119988.42310905457, \"count\": 1, \"min\": 119988.42310905457, \"max\": 119988.42310905457}}}\n",
      "\n",
      "2025-05-21 22:03:53 Completed - Training job completed\n",
      "Training seconds: 311\n",
      "Billable seconds: 311\n",
      "CPU times: total: 10.7 s\n",
      "Wall time: 6min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "ddb84337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-21 22:03:53 Starting - Preparing the instances for training\n",
      "2025-05-21 22:03:53 Downloading - Downloading the training image\n",
      "2025-05-21 22:03:53 Training - Training image download completed. Training in progress.\n",
      "2025-05-21 22:03:53 Uploading - Uploading generated training model\n",
      "2025-05-21 22:03:53 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-21-21-58-04-946',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "ce6db267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 17:15:15] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-15-15-445 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 17:15:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-15-15-445 \u001b]8;id=553497;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=47100;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 17:15:16] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-15-15-445                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 17:15:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=489701;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=467456;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-15-15-445                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-15-15-445                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=702543;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=130939;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-15-15-445                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "c6c75c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_list = convertir_a_series(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "4410c5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0.1   0.5   0.9\n",
       "2024-11-01  14.0  21.0  34.0\n",
       "2024-12-01  13.0  21.0  30.0\n",
       "2025-01-01  11.0  17.0  24.0\n",
       "2025-02-01   4.0   9.0  16.0\n",
       "2025-03-01   3.0   7.0  19.0\n",
       "2025-04-01   4.0  10.0  19.0"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=13\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "bd0d8d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    15\n",
       "2024-12-01    53\n",
       "2025-01-01    11\n",
       "2025-02-01     8\n",
       "2025-03-01     8\n",
       "2025-04-01     4\n",
       "Freq: MS, Name: cantidad, dtype: int32"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[i].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984afed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "96f049c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"forecasting-mensual-15-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "7713d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = bucket_name  # replace with an existing bucket if needed\n",
    "s3_bucket_prefix = (\n",
    "        \"lilipink\"  \n",
    "    )\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "if default_bucket_prefix:\n",
    "    s3_prefix = f\"{default_bucket_prefix}/{s3_bucket_prefix}\"\n",
    "else:\n",
    "    s3_prefix = s3_bucket_prefix\n",
    "\n",
    "role = \"arn:aws:iam::844598627082:role/service-role/AmazonSageMaker-ExecutionRole-20250513T105052\"  # IAM role to use by SageMaker\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "d57082f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"likelihood\": \"student-T\",\n",
    "    #\"learning_rate\": \"0.0001\",\n",
    "}\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "38fef521",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    #\"likelihood\": CategoricalParameter([\"gaussian\", \"negative-binomial\", \"student-T\"]),\n",
    "    \"mini_batch_size\": IntegerParameter(32,512),\n",
    "    \"num_cells\": IntegerParameter(30, 200),  # Rango amplio\n",
    "    \"learning_rate\": ContinuousParameter(0.0001, 0.1),\n",
    "    \"num_layers\": IntegerParameter(1, 4),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "f4e8268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"test:RMSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "8a685d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=10,\n",
    "    strategy=\"Bayesian\",\n",
    "    objective_type=\"Minimize\",\n",
    "    max_parallel_jobs=2,\n",
    "    early_stopping_type=\"Auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "98f4d962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 17:35:22] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating hyperparameter tuning job with name:                          <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#3383\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3383</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250521</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1735</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 17:35:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating hyperparameter tuning job with name:                          \u001b]8;id=315520;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=175570;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#3383\u001b\\\u001b[2m3383\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         forecasting-deepar-\u001b[1;36m250521\u001b[0m-\u001b[1;36m1735\u001b[0m                                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\"train\": \"{}/train/\".format(s3_data_path) , \"test\": \"{}/test/\".format(s3_data_path)}, include_cls_metadata=False)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "4f401839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-21 22:53:09 Starting - Preparing the instances for training\n",
      "2025-05-21 22:53:09 Downloading - Downloading the training image\n",
      "2025-05-21 22:53:09 Training - Training image download completed. Training in progress.\n",
      "2025-05-21 22:53:09 Uploading - Uploading generated training model\n",
      "2025-05-21 22:53:09 Completed - Resource reused by training job: forecasting-deepar-250521-1735-003-858ad257\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('forecasting-deepar-250521-1735-002-5edbf051',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "56e416d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 22:02:35] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-03-02-35-258   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 22:02:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: forecasting-deepar-\u001b[1;36m2025\u001b[0m-05-22-03-02-35-258   \u001b]8;id=237952;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=59293;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 22:02:36] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-03-02-35-258                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 22:02:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=893806;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=424825;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         forecasting-deepar-\u001b[1;36m2025\u001b[0m-05-22-03-02-35-258                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-03-02-35-258 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name forecasting-deepar-\u001b[1;36m2025\u001b[0m-05-22-03-02-35-258 \u001b]8;id=204695;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=13497;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "f321f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "materiales = [df['material'].unique()[0] for df in timeseries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "02afef32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>20.257246</td>\n",
       "      <td>21.715506</td>\n",
       "      <td>23.062975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>4.920360</td>\n",
       "      <td>5.989008</td>\n",
       "      <td>7.108116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>18.774708</td>\n",
       "      <td>23.098007</td>\n",
       "      <td>26.324074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>8.929207</td>\n",
       "      <td>14.016326</td>\n",
       "      <td>20.408501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>5.660460</td>\n",
       "      <td>6.118926</td>\n",
       "      <td>6.576430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>4.714138</td>\n",
       "      <td>5.352091</td>\n",
       "      <td>6.326006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-10-01  20.257246  21.715506  23.062975\n",
       "2024-11-01   4.920360   5.989008   7.108116\n",
       "2024-12-01  18.774708  23.098007  26.324074\n",
       "2025-01-01   8.929207  14.016326  20.408501\n",
       "2025-02-01   5.660460   6.118926   6.576430\n",
       "2025-03-01   4.714138   5.352091   6.326006"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=0\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "32b17236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fecha\n",
       "2024-10-01    24\n",
       "2024-11-01    10\n",
       "2024-12-01    22\n",
       "2025-01-01     7\n",
       "2025-02-01     6\n",
       "2025-03-01     3\n",
       "Freq: MS, Name: cantidad, dtype: int32"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[i].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "a95cd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_predicciones_por_material(materiales, timeseries_list, vectores_cat, dynamic_list, predictor, horizon_pred=6):\n",
    "    \"\"\"\n",
    "    Genera predicciones para cada material y las devuelve en un diccionario.\n",
    "    \n",
    "    Args:\n",
    "        materiales: Lista con los nombres de materiales\n",
    "        timeseries_list: Lista de series temporales\n",
    "        vectores_cat: Lista de vectores categóricos\n",
    "        dynamic_list: Lista de features dinámicas\n",
    "        predictor: Modelo predictor entrenado\n",
    "        horizon_pred: Horizonte de predicción (default: 6)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con materiales como keys y dataframes de predicciones como values\n",
    "    \"\"\"\n",
    "    predicciones_dict = {}\n",
    "    \n",
    "    for i in range(len(materiales)):\n",
    "        material = materiales[i]\n",
    "        \n",
    "        # Generar predicción para el índice i\n",
    "        prediccion = predictor.predict(\n",
    "            ts = timeseries_list[i][:-horizon_pred], \n",
    "            cat=vectores_cat[i],\n",
    "            dynamic_feat=dynamic_list[i],\n",
    "            quantiles=[0.1, 0.5, 0.9],\n",
    "        )\n",
    "        \n",
    "        # Guardar en el diccionario\n",
    "        predicciones_dict[material] = prediccion\n",
    "        \n",
    "    return predicciones_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "db8ada27",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_por_material = generar_predicciones_por_material(\n",
    "    materiales=materiales,\n",
    "    timeseries_list=timeseries_list,\n",
    "    vectores_cat=vectores_cat,\n",
    "    dynamic_list=dynamic_list,\n",
    "    predictor=predictor,\n",
    "    horizon_pred=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "46437d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([20008046001, 20001374001, 25109225001, 20000400003, 25109232001, 20003257004, 20003147001, 20001016001, 20003257001, 20003257002, 20000837001, 20000815002, 20000337001, 20000837002, 20000815003])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_por_material.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "0aef83d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>11.201364</td>\n",
       "      <td>11.943863</td>\n",
       "      <td>12.691624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>10.408160</td>\n",
       "      <td>11.251961</td>\n",
       "      <td>12.422890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>5.801578</td>\n",
       "      <td>7.736809</td>\n",
       "      <td>9.833155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>4.823981</td>\n",
       "      <td>6.063189</td>\n",
       "      <td>7.057480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>13.920343</td>\n",
       "      <td>15.615708</td>\n",
       "      <td>17.569654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>6.038536</td>\n",
       "      <td>7.483931</td>\n",
       "      <td>8.713497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01  11.201364  11.943863  12.691624\n",
       "2024-12-01  10.408160  11.251961  12.422890\n",
       "2025-01-01   5.801578   7.736809   9.833155\n",
       "2025-02-01   4.823981   6.063189   7.057480\n",
       "2025-03-01  13.920343  15.615708  17.569654\n",
       "2025-04-01   6.038536   7.483931   8.713497"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_por_material[20000337001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "fa5dc4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado: mensual_original_test.xlsx\n",
      "Orden de columnas: ['Material', 'Fecha', '0.1', '0.5', '0.9']\n",
      "Formato de fecha: YYYY-MM-DD\n"
     ]
    }
   ],
   "source": [
    "def exportar_predicciones_consolidado(predicciones_dict, nombre_archivo=\"mensual_original_test.xlsx\"):\n",
    "    \"\"\"\n",
    "    Exporta todas las predicciones con Material y Fecha como primeras dos columnas.\n",
    "    \"\"\"\n",
    "    \n",
    "    dfs_list = []\n",
    "    \n",
    "    for material, prediccion in predicciones_dict.items():\n",
    "        try:\n",
    "            # Convertir a DataFrame\n",
    "            if hasattr(prediccion, 'to_dataframe'):\n",
    "                df_pred = prediccion.to_dataframe()\n",
    "            elif hasattr(prediccion, 'to_pandas'):\n",
    "                df_pred = prediccion.to_pandas()\n",
    "            else:\n",
    "                df_pred = prediccion\n",
    "            \n",
    "            # Resetear índice y renombrar a 'Fecha'\n",
    "            df_pred = df_pred.reset_index()\n",
    "            date_col = df_pred.columns[0]\n",
    "            df_pred = df_pred.rename(columns={date_col: 'Fecha'})\n",
    "            \n",
    "            # Formatear fechas\n",
    "            df_pred['Fecha'] = pd.to_datetime(df_pred['Fecha']).dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Agregar columna de material\n",
    "            df_pred['Material'] = material\n",
    "            \n",
    "            dfs_list.append(df_pred)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {material}: {e}\")\n",
    "    \n",
    "    # Concatenar todos los DataFrames\n",
    "    if dfs_list:\n",
    "        df_final = pd.concat(dfs_list, ignore_index=True)\n",
    "        \n",
    "        # Reorganizar columnas: Material, Fecha, luego el resto en orden\n",
    "        other_cols = [col for col in df_final.columns if col not in ['Material', 'Fecha']]\n",
    "        cols = ['Material', 'Fecha'] + other_cols\n",
    "        df_final = df_final[cols]\n",
    "        \n",
    "        # Exportar\n",
    "        df_final.to_excel(nombre_archivo, index=False)\n",
    "        print(f\"Archivo guardado: {nombre_archivo}\")\n",
    "        print(f\"Orden de columnas: {list(df_final.columns)}\")\n",
    "        print(\"Formato de fecha: YYYY-MM-DD\")\n",
    "    else:\n",
    "        print(\"Error: No se pudieron procesar las predicciones\")\n",
    "\n",
    "# Ejecutar\n",
    "exportar_predicciones_consolidado(predicciones_por_material, \"mensual_original_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "982f5a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 01:26:13] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-06-15-03-653 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#5356\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5356</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 01:26:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-06-15-03-653 \u001b]8;id=605885;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=254672;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#5356\u001b\\\u001b[2m5356\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration with name:                             <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4995\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4995</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-06-15-03-653                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration with name:                             \u001b]8;id=569526;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=56011;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4995\u001b\\\u001b[2m4995\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-06-15-03-653                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 01:26:14] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint with name:                                           <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4985\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4985</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-06-15-03-653                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 01:26:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint with name:                                           \u001b]8;id=903220;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=828080;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4985\u001b\\\u001b[2m4985\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-06-15-03-653                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
