{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "293a981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:198: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 13:09:07] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 13:09:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=517352;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=932871;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\u001b\\\u001b[2m1352\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\Usuario\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "#importación de librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from pandas import DateOffset\n",
    "import boto3\n",
    "import sagemaker\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d70a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data_csv/15_materiales_mod.csv',sep=',',index_col=0,parse_dates=True,decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e02f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los materiales son [20000337001 20000400003 20000815002 20000815003 20000837001 20000837002\n",
      " 20001016001 20001374001 20003147001 20003257001 20003257002 20003257004\n",
      " 20008046001 25109225001 25109232001]\n"
     ]
    }
   ],
   "source": [
    "materiales = df['material'].unique()\n",
    "print(f'Los materiales son {materiales}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6478e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = []\n",
    "materiales = df['material'].unique()\n",
    "for mat in materiales:\n",
    "    serie = df[df['material'] == mat].sort_index()\n",
    "    timeseries.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d08a2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumar_cantidades_fechas(lista_dataframes, fechas=['2023-11-01', '2023-11-02']):\n",
    "    \"\"\"\n",
    "    Suma la columna 'cantidad' para las fechas especificadas en cada dataframe\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha\n",
    "        fechas: Lista de fechas a considerar (por defecto '2023-11-01' y '2023-11-02')\n",
    "    \n",
    "    Returns:\n",
    "        Un diccionario con las sumas por cada dataframe\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        suma = 0\n",
    "        for fecha in fechas:\n",
    "            if fecha in df.index:\n",
    "                suma += df.loc[fecha, 'cantidad']\n",
    "        resultados[f'dataframe_{i}'] = suma\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e31e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = sumar_cantidades_fechas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660f22ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataframe_0': 33.0,\n",
       " 'dataframe_1': 20.0,\n",
       " 'dataframe_2': 25.0,\n",
       " 'dataframe_3': 31.0,\n",
       " 'dataframe_4': 28.0,\n",
       " 'dataframe_5': 44.0,\n",
       " 'dataframe_6': 4.0,\n",
       " 'dataframe_7': 5.0,\n",
       " 'dataframe_8': 133.0,\n",
       " 'dataframe_9': 46.0,\n",
       " 'dataframe_10': 60.0,\n",
       " 'dataframe_11': 26.0,\n",
       " 'dataframe_12': 43.0,\n",
       " 'dataframe_13': 82.0,\n",
       " 'dataframe_14': 43.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1469fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_fechas(lista_dataframes, fechas=['2023-11-01', '2023-11-02']):\n",
    "    \"\"\"\n",
    "    Elimina los registros de las fechas especificadas en cada dataframe\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha\n",
    "        fechas: Lista de fechas a eliminar (por defecto '2023-11-01' y '2023-11-02')\n",
    "    \n",
    "    Returns:\n",
    "        Una nueva lista de dataframes sin los registros de las fechas indicadas\n",
    "    \"\"\"\n",
    "    nuevos_dataframes = []\n",
    "    \n",
    "    for df in lista_dataframes:\n",
    "        # Crear una copia para no modificar el original\n",
    "        df_nuevo = df.copy()\n",
    "        # Eliminar las fechas especificadas si existen en el índice\n",
    "        df_nuevo = df_nuevo.drop(fechas, errors='ignore')\n",
    "        nuevos_dataframes.append(df_nuevo)\n",
    "    \n",
    "    return nuevos_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a27fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = eliminar_fechas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61924e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_por_mes(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Agrupa los datos por mes-año, sumando la columna 'cantidad' y manteniendo las columnas categóricas.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha en formato 'YYYY-MM-DD'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con datos agrupados por mes-año\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    dataframes_agrupados = []\n",
    "    \n",
    "    for df in lista_dataframes:\n",
    "        # Verificar que el índice sea de tipo datetime\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Crear una columna con el mes-año para agrupar\n",
    "        df_copia = df.copy()\n",
    "        df_copia['mes_anio'] = df_copia.index.strftime('%Y-%m')\n",
    "        \n",
    "        # Identificar columnas categóricas (todas excepto 'cantidad')\n",
    "        cols_categoricas = [col for col in df_copia.columns if col != 'cantidad' and col != 'mes_anio']\n",
    "        \n",
    "        # Realizar la agrupación\n",
    "        if cols_categoricas:\n",
    "            # Si hay columnas categóricas, agrupar por mes_anio y columnas categóricas\n",
    "            grupos = df_copia.groupby(['mes_anio'] + cols_categoricas)\n",
    "            # Sumar la cantidad para cada grupo\n",
    "            agrupado = grupos['cantidad'].sum().reset_index()\n",
    "            # Convertir 'mes_anio' en índice de datetime (primer día del mes)\n",
    "            agrupado['fecha'] = pd.to_datetime(agrupado['mes_anio'] + '-01')\n",
    "            agrupado = agrupado.set_index('fecha')\n",
    "            agrupado = agrupado.drop('mes_anio', axis=1)\n",
    "        else:\n",
    "            # Si no hay columnas categóricas, agrupar solo por mes_anio\n",
    "            agrupado = df_copia.groupby('mes_anio')['cantidad'].sum().reset_index()\n",
    "            agrupado['fecha'] = pd.to_datetime(agrupado['mes_anio'] + '-01')\n",
    "            agrupado = agrupado.set_index('fecha')\n",
    "            agrupado = agrupado.drop('mes_anio', axis=1)\n",
    "        \n",
    "        dataframes_agrupados.append(agrupado)\n",
    "    \n",
    "    return dataframes_agrupados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81f46803",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = agrupar_por_mes(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a5bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_ultimo_registro(dataframes_agrupados):\n",
    "    \"\"\"\n",
    "    Elimina el último registro de cada dataframe en la lista.\n",
    "    \n",
    "    Args:\n",
    "        dataframes_agrupados: Lista de dataframes con datos agrupados por mes-año\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con el último registro eliminado en cada uno\n",
    "    \"\"\"\n",
    "    resultado = []\n",
    "    \n",
    "    for df in dataframes_agrupados:\n",
    "        # Si el dataframe tiene al menos un registro\n",
    "        if len(df) > 0:\n",
    "            # Eliminar el último registro\n",
    "            df_sin_ultimo = df.iloc[:-1].copy()\n",
    "            resultado.append(df_sin_ultimo)\n",
    "        else:\n",
    "            # Si el dataframe está vacío, agregarlo sin cambios\n",
    "            resultado.append(df.copy())\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eb5b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = eliminar_ultimo_registro(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2fea5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajustar_para_mantener_ratios(timeseries, resultados):\n",
    "    \"\"\"\n",
    "    Ajusta los valores de 2023-09 y 2023-10 sumando cantidades para que mantengan \n",
    "    los mismos ratios que 2022-09 y 2022-10, utilizando los valores de 'resultados'.\n",
    "    \n",
    "    Args:\n",
    "        timeseries: Lista de dataframes mensuales\n",
    "        resultados: Diccionario con las sumas de cantidades\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con las cantidades ajustadas\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    dataframes_ajustados = []\n",
    "    \n",
    "    for i, df in enumerate(timeseries):\n",
    "        df_ajustado = df.copy()\n",
    "        clave_resultado = f'dataframe_{i}'\n",
    "        \n",
    "        # Verificar que exista el valor en resultados\n",
    "        if clave_resultado in resultados:\n",
    "            valor_a_distribuir = resultados[clave_resultado]\n",
    "            \n",
    "            # 1. Calcular los ratios objetivo de 2022-09 y 2022-10\n",
    "            if '2022-09-01' in df_ajustado.index and '2022-10-01' in df_ajustado.index:\n",
    "                valor_sep_2022 = df_ajustado.loc['2022-09-01', 'cantidad']\n",
    "                valor_oct_2022 = df_ajustado.loc['2022-10-01', 'cantidad']\n",
    "                \n",
    "                # Ratio objetivo (proporción de sep respecto a la suma)\n",
    "                if valor_sep_2022 + valor_oct_2022 > 0:\n",
    "                    ratio_objetivo = valor_sep_2022 / (valor_sep_2022 + valor_oct_2022)\n",
    "                else:\n",
    "                    ratio_objetivo = 0.5\n",
    "                \n",
    "                # Valores actuales o cero si no existen\n",
    "                valor_sep_2023 = df_ajustado.loc['2023-09-01', 'cantidad'] if '2023-09-01' in df_ajustado.index else 0\n",
    "                valor_oct_2023 = df_ajustado.loc['2023-10-01', 'cantidad'] if '2023-10-01' in df_ajustado.index else 0\n",
    "                \n",
    "                # 2. Calcular cuánto agregar a cada mes para mantener el ratio objetivo\n",
    "                # Resolviendo el sistema de ecuaciones:\n",
    "                # (valor_sep_2023 + x) / (valor_sep_2023 + x + valor_oct_2023 + y) = ratio_objetivo\n",
    "                # x + y = valor_a_distribuir\n",
    "                \n",
    "                # Si ambos valores son cero, distribuimos según el ratio objetivo\n",
    "                if valor_sep_2023 == 0 and valor_oct_2023 == 0:\n",
    "                    incremento_sep = valor_a_distribuir * ratio_objetivo\n",
    "                    incremento_oct = valor_a_distribuir * (1 - ratio_objetivo)\n",
    "                else:\n",
    "                    # Para mantener el ratio: (a + x) / (a + b + x + y) = r, donde x + y = v\n",
    "                    # Resolviendo: x = (r*(a+b) - a) + r*v\n",
    "                    a = valor_sep_2023\n",
    "                    b = valor_oct_2023\n",
    "                    r = ratio_objetivo\n",
    "                    v = valor_a_distribuir\n",
    "                    \n",
    "                    # Calculamos los incrementos\n",
    "                    incremento_sep = max(0, (r*(a+b) - a) + r*v)\n",
    "                    incremento_oct = max(0, v - incremento_sep)\n",
    "                    \n",
    "                    # Si hay valores negativos, ajustamos la distribución\n",
    "                    if incremento_sep < 0 or incremento_oct < 0:\n",
    "                        incremento_sep = v * r\n",
    "                        incremento_oct = v * (1 - r)\n",
    "                \n",
    "                # Actualizar o crear los registros para 2023-09\n",
    "                if '2023-09-01' in df_ajustado.index:\n",
    "                    # Sumar el incremento calculado\n",
    "                    df_ajustado.loc['2023-09-01', 'cantidad'] += incremento_sep\n",
    "                else:\n",
    "                    # Crear nuevo registro\n",
    "                    nuevo_registro = pd.DataFrame(index=[pd.to_datetime('2023-09-01')])\n",
    "                    \n",
    "                    # Copiar valores categóricos\n",
    "                    if len(df_ajustado) > 0:\n",
    "                        for col in df_ajustado.columns:\n",
    "                            if col != 'cantidad':\n",
    "                                nuevo_registro[col] = df_ajustado[col].iloc[0]\n",
    "                    \n",
    "                    # Asignar el valor calculado\n",
    "                    nuevo_registro['cantidad'] = incremento_sep\n",
    "                    \n",
    "                    # Concatenar\n",
    "                    df_ajustado = pd.concat([df_ajustado, nuevo_registro])\n",
    "                \n",
    "                # Actualizar o crear los registros para 2023-10\n",
    "                if '2023-10-01' in df_ajustado.index:\n",
    "                    # Sumar el incremento calculado\n",
    "                    df_ajustado.loc['2023-10-01', 'cantidad'] += incremento_oct\n",
    "                else:\n",
    "                    # Crear nuevo registro\n",
    "                    nuevo_registro = pd.DataFrame(index=[pd.to_datetime('2023-10-01')])\n",
    "                    \n",
    "                    # Copiar valores categóricos\n",
    "                    if len(df_ajustado) > 0:\n",
    "                        for col in df_ajustado.columns:\n",
    "                            if col != 'cantidad':\n",
    "                                nuevo_registro[col] = df_ajustado[col].iloc[0]\n",
    "                    \n",
    "                    # Asignar el valor calculado\n",
    "                    nuevo_registro['cantidad'] = incremento_oct\n",
    "                    \n",
    "                    # Concatenar\n",
    "                    df_ajustado = pd.concat([df_ajustado, nuevo_registro])\n",
    "                \n",
    "                # Ordenar por fecha\n",
    "                df_ajustado = df_ajustado.sort_index()\n",
    "        \n",
    "        dataframes_ajustados.append(df_ajustado)\n",
    "    \n",
    "    return dataframes_ajustados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cfb4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = ajustar_para_mantener_ratios(timeseries,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c88d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_columnas_temporales(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Agrega las columnas 'month' y 'quarter' a cada dataframe, calculadas a partir del índice de fecha.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con las nuevas columnas 'month' y 'quarter'\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    resultado = []\n",
    "    \n",
    "    for df in lista_dataframes:\n",
    "        # Crear una copia del dataframe\n",
    "        df_nuevo = df.copy()\n",
    "        \n",
    "        # Asegurarse de que el índice es de tipo datetime\n",
    "        if not isinstance(df_nuevo.index, pd.DatetimeIndex):\n",
    "            df_nuevo.index = pd.to_datetime(df_nuevo.index)\n",
    "        \n",
    "        # Agregar columna de mes (valores 1-12)\n",
    "        df_nuevo['month'] = df_nuevo.index.month\n",
    "        \n",
    "        # Agregar columna de trimestre (valores 1-4)\n",
    "        df_nuevo['quarter'] = df_nuevo.index.quarter\n",
    "        \n",
    "        # Añadir a la lista de resultados\n",
    "        resultado.append(df_nuevo)\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "135b69cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = agregar_columnas_temporales(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5602e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificar_columnas_categoricas(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Codifica las columnas categóricas usando códigos numéricos únicos para cada valor.\n",
    "    Las columnas a codificar son: Tipo_Producto, segmento_producto, supergrupo_producto, \n",
    "    grupo_producto y subgrupo_producto.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con columnas categóricas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con columnas categóricas codificadas y diccionario de mapeos\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Columnas categóricas a codificar\n",
    "    columnas_categoricas = [\n",
    "        'Tipo_Producto', \n",
    "        'segmento_producto', \n",
    "        'supergrupo_producto', \n",
    "        'grupo_producto', \n",
    "        'subgrupo_producto'\n",
    "    ]\n",
    "    \n",
    "    # Diccionario para almacenar los mapeos para cada columna\n",
    "    mapeos = {col: {} for col in columnas_categoricas}\n",
    "    \n",
    "    # Lista para almacenar los dataframes codificados\n",
    "    dataframes_codificados = []\n",
    "    \n",
    "    # Crear mapeos para cada columna categórica\n",
    "    codigo_actual = {}\n",
    "    for col in columnas_categoricas:\n",
    "        codigo_actual[col] = 0\n",
    "    \n",
    "    # Iterar sobre cada dataframe para crear los mapeos\n",
    "    for df in lista_dataframes:\n",
    "        for col in columnas_categoricas:\n",
    "            if col in df.columns:\n",
    "                # Obtener el valor único en esta columna para este dataframe\n",
    "                # (asumiendo que cada dataframe tiene un solo valor para cada columna categórica)\n",
    "                if len(df) > 0:\n",
    "                    valor = df[col].iloc[0]\n",
    "                    \n",
    "                    # Si el valor no está en el mapeo, asignarle un código\n",
    "                    if valor not in mapeos[col]:\n",
    "                        mapeos[col][valor] = codigo_actual[col]\n",
    "                        codigo_actual[col] += 1\n",
    "    \n",
    "    # Aplicar los mapeos a cada dataframe\n",
    "    for df in lista_dataframes:\n",
    "        df_codificado = df.copy()\n",
    "        \n",
    "        for col in columnas_categoricas:\n",
    "            if col in df.columns:\n",
    "                if len(df) > 0:\n",
    "                    valor = df[col].iloc[0]\n",
    "                    codigo = mapeos[col][valor]\n",
    "                    \n",
    "                    # Reemplazar el valor categórico con su código\n",
    "                    df_codificado[col] = codigo\n",
    "        \n",
    "        dataframes_codificados.append(df_codificado)\n",
    "    \n",
    "    return dataframes_codificados, mapeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fc8d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries,mapeos = codificar_columnas_categoricas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76a7acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tipo_Producto': {'LILI PINK': 0, 'YOI': 1},\n",
       " 'segmento_producto': {'JUVENIL': 0, 'TEEN': 1, 'ADULTO': 2, 'GIRLS': 3},\n",
       " 'supergrupo_producto': {'INTERIOR JUVENIL': 0,\n",
       "  'INTERIOR TEEN': 1,\n",
       "  'LINEA SECRET': 2,\n",
       "  'INTERIOR MUJER': 3,\n",
       "  'BELLEZA Y BIENESTAR': 4},\n",
       " 'grupo_producto': {'PANTY PAQX3': 0,\n",
       "  'BRASIER PAQX2': 1,\n",
       "  'PANTY PAQX2': 2,\n",
       "  'PANTY': 3,\n",
       "  'BRASIER SILICONA': 4,\n",
       "  'FRAGANCIAS': 5},\n",
       " 'subgrupo_producto': {'ALGODON': 0,\n",
       "  'MICROFIBRA': 1,\n",
       "  'SEAMLESS': 2,\n",
       "  'ENCAJE': 3,\n",
       "  'SILICONA': 4,\n",
       "  'NO APLICA': 5}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "950521f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_registros_mensuales(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Verifica que existan registros para todos los meses desde la primera hasta la última fecha\n",
    "    en cada dataframe, e identifica los meses faltantes.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha en formato 'YYYY-MM-DD'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de tuplas (dataframe_id, completo, meses_faltantes) donde:\n",
    "        - dataframe_id: Índice del dataframe en la lista\n",
    "        - completo: Boolean indicando si tiene todos los meses\n",
    "        - meses_faltantes: Lista de fechas de meses faltantes en formato 'YYYY-MM-01'\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Asegurarse de que el índice es de tipo datetime\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df = df.copy()\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Verificar que hay registros en el dataframe\n",
    "        if len(df) == 0:\n",
    "            resultados.append((i, True, []))\n",
    "            continue\n",
    "        \n",
    "        # Obtener la primera y última fecha\n",
    "        primera_fecha = df.index.min()\n",
    "        ultima_fecha = df.index.max()\n",
    "        \n",
    "        # Crear un rango de todos los meses entre la primera y última fecha\n",
    "        todos_los_meses = pd.date_range(\n",
    "            start=pd.Timestamp(year=primera_fecha.year, month=primera_fecha.month, day=1),\n",
    "            end=pd.Timestamp(year=ultima_fecha.year, month=ultima_fecha.month, day=1),\n",
    "            freq='MS'  # Inicio de mes (Month Start)\n",
    "        )\n",
    "        \n",
    "        # Convertir los índices del dataframe a inicio de mes\n",
    "        meses_presentes = df.index.to_period('M').to_timestamp()\n",
    "        meses_presentes = meses_presentes.unique()  # Eliminar duplicados\n",
    "        \n",
    "        # Encontrar meses faltantes\n",
    "        meses_faltantes = [fecha for fecha in todos_los_meses if fecha not in meses_presentes]\n",
    "        \n",
    "        # Determinar si está completo\n",
    "        completo = len(meses_faltantes) == 0\n",
    "        \n",
    "        # Guardar resultados\n",
    "        resultados.append((i, completo, meses_faltantes))\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5323dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, True, []),\n",
       " (1, True, []),\n",
       " (2, True, []),\n",
       " (3, True, []),\n",
       " (4, True, []),\n",
       " (5, True, []),\n",
       " (6, True, []),\n",
       " (7, True, []),\n",
       " (8, True, []),\n",
       " (9, True, []),\n",
       " (10, True, []),\n",
       " (11, True, []),\n",
       " (12, True, []),\n",
       " (13, True, []),\n",
       " (14, True, [])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verificar_registros_mensuales(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "982031b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_vectores_categoricos(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae los valores categóricos del primer registro de cada dataframe y crea\n",
    "    un vector con estos valores.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes que contienen columnas categóricas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de vectores categóricos, uno por cada dataframe\n",
    "    \"\"\"\n",
    "    # Definir las columnas categóricas\n",
    "    columnas_categoricas = [\n",
    "        'Tipo_Producto', \n",
    "        'segmento_producto', \n",
    "        'supergrupo_producto', \n",
    "        'grupo_producto', \n",
    "        'subgrupo_producto'\n",
    "    ]\n",
    "    \n",
    "    vectores_categoricos = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío, se usará un vector de ceros.\")\n",
    "            vectores_categoricos.append([0] * len(columnas_categoricas))\n",
    "            continue\n",
    "        \n",
    "        # Crear el vector para este dataframe\n",
    "        vector = []\n",
    "        \n",
    "        for col in columnas_categoricas:\n",
    "            # Verificar si la columna existe en el dataframe\n",
    "            if col in df.columns:\n",
    "                # Obtener el valor del primer registro\n",
    "                valor = df[col].iloc[0]\n",
    "                \n",
    "                # Convertir a entero si es posible, de lo contrario usar un código hash\n",
    "                try:\n",
    "                    valor_numerico = int(valor)\n",
    "                except (ValueError, TypeError):\n",
    "                    # Si no se puede convertir a entero, usar un código hash simple\n",
    "                    if valor is None:\n",
    "                        valor_numerico = 0\n",
    "                    else:\n",
    "                        # Hash simple basado en la representación string del valor\n",
    "                        valor_numerico = hash(str(valor)) % 10000  # Limitar a 4 dígitos\n",
    "            else:\n",
    "                # Si la columna no existe, usar 0\n",
    "                valor_numerico = 0\n",
    "            \n",
    "            vector.append(valor_numerico)\n",
    "        \n",
    "        vectores_categoricos.append(vector)\n",
    "        \n",
    "    return vectores_categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d63ec96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_cat = extraer_vectores_categoricos(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a31cbf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_vectores_cantidad(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae los valores de la columna 'cantidad' de cada dataframe y crea \n",
    "    un vector con estos valores.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes que contienen la columna 'cantidad'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de vectores, donde cada vector contiene los valores de 'cantidad' de un dataframe\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    vectores_cantidad = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío.\")\n",
    "            vectores_cantidad.append([])\n",
    "            continue\n",
    "        \n",
    "        # Verificar que exista la columna 'cantidad'\n",
    "        if 'cantidad' not in df.columns:\n",
    "            print(f\"Advertencia: Dataframe {i} no tiene columna 'cantidad'.\")\n",
    "            vectores_cantidad.append([])\n",
    "            continue\n",
    "        \n",
    "        # Extraer los valores de 'cantidad' como una lista\n",
    "        valores = df['cantidad'].tolist()\n",
    "        \n",
    "        # Opcionalmente, puedes manejar valores NaN\n",
    "        # valores = [0 if pd.isna(x) else x for x in valores]  # Convierte NaN a 0\n",
    "        # O simplemente:\n",
    "        valores = df['cantidad'].fillna(0).tolist()  # Rellena NaN con 0\n",
    "        \n",
    "        vectores_cantidad.append(valores)\n",
    "    \n",
    "    return vectores_cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5db630e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_target = extraer_vectores_cantidad(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "327fa6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_vectores_temporales(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae los valores de las columnas 'month' y 'quarter' de cada dataframe\n",
    "    y crea un conjunto de vectores con estos valores.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes que contienen las columnas 'month' y 'quarter'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de conjuntos de vectores, donde cada conjunto contiene los vectores\n",
    "        de 'month' y 'quarter' para un dataframe\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    conjuntos_vectores = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío.\")\n",
    "            conjuntos_vectores.append(([], []))\n",
    "            continue\n",
    "        \n",
    "        # Verificar que existan las columnas necesarias\n",
    "        columnas_faltantes = []\n",
    "        if 'month' not in df.columns:\n",
    "            columnas_faltantes.append('month')\n",
    "        if 'quarter' not in df.columns:\n",
    "            columnas_faltantes.append('quarter')\n",
    "        \n",
    "        if columnas_faltantes:\n",
    "            print(f\"Advertencia: Dataframe {i} no tiene las columnas: {columnas_faltantes}\")\n",
    "            \n",
    "            # Si faltan las columnas, podemos crearlas a partir del índice si es de tipo fecha\n",
    "            df_temp = df.copy()\n",
    "            \n",
    "            if isinstance(df_temp.index, pd.DatetimeIndex):\n",
    "                if 'month' not in df_temp.columns:\n",
    "                    df_temp['month'] = df_temp.index.month\n",
    "                if 'quarter' not in df_temp.columns:\n",
    "                    df_temp['quarter'] = df_temp.index.quarter\n",
    "            else:\n",
    "                # Si el índice no es de tipo fecha, tratar de convertirlo\n",
    "                try:\n",
    "                    df_temp.index = pd.to_datetime(df_temp.index)\n",
    "                    if 'month' not in df_temp.columns:\n",
    "                        df_temp['month'] = df_temp.index.month\n",
    "                    if 'quarter' not in df_temp.columns:\n",
    "                        df_temp['quarter'] = df_temp.index.quarter\n",
    "                except:\n",
    "                    # Si no se puede convertir, usar valores vacíos\n",
    "                    month_vector = []\n",
    "                    quarter_vector = []\n",
    "                    conjuntos_vectores.append((month_vector, quarter_vector))\n",
    "                    continue\n",
    "            \n",
    "            # Usar el dataframe temporal con las columnas agregadas\n",
    "            df = df_temp\n",
    "        \n",
    "        # Extraer los vectores\n",
    "        month_vector = df['month'].tolist()\n",
    "        quarter_vector = df['quarter'].tolist()\n",
    "        \n",
    "        # Guardar el conjunto de vectores\n",
    "        conjuntos_vectores.append((month_vector, quarter_vector))\n",
    "    \n",
    "    return conjuntos_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ebcdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_dynamic = extraer_vectores_temporales(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf970b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_primeros_indices(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae el primer índice de cada dataframe y lo devuelve en formato \"YYYY-MM-DD 00:00:00\".\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índices de fecha\n",
    "    \n",
    "    Returns:\n",
    "        Lista de strings con los primeros índices en formato \"YYYY-MM-DD 00:00:00\"\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    primeros_indices = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío. Se usará fecha por defecto.\")\n",
    "            primeros_indices.append(\"2000-01-01 00:00:00\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener el primer índice\n",
    "        primer_indice = df.index[0]\n",
    "        \n",
    "        # Convertir a datetime si no lo es\n",
    "        if not isinstance(primer_indice, pd.Timestamp) and not isinstance(primer_indice, datetime):\n",
    "            try:\n",
    "                primer_indice = pd.to_datetime(primer_indice)\n",
    "            except:\n",
    "                print(f\"Advertencia: No se pudo convertir el índice del Dataframe {i} a fecha. Se usará fecha por defecto.\")\n",
    "                primeros_indices.append(\"2000-01-01 00:00:00\")\n",
    "                continue\n",
    "        \n",
    "        # Formatear a \"YYYY-MM-DD 00:00:00\"\n",
    "        indice_formateado = primer_indice.strftime(\"%Y-%m-%d 00:00:00\")\n",
    "        \n",
    "        primeros_indices.append(indice_formateado)\n",
    "    \n",
    "    return primeros_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4042f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = extraer_primeros_indices(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18af2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_test(start, vectores_target, vectores_cat, vectores_dynamic):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios con la estructura requerida para entrenamiento,\n",
    "    donde start son las fechas de inicio de cada serie (un valor por dataframe).\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else float(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic\n",
    "        if len(target_data) != len(month_vector) or len(target_data) != len(quarter_vector):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes - target: {len(target_data)}, \"\n",
    "                  f\"month: {len(month_vector)}, quarter: {len(quarter_vector)}\")\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector, quarter_vector]  # Usar valores originales sin normalizar\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e92b152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = crear_diccionarios_test(start,vectores_target,vectores_cat,vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "731b34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_entrenamiento(start, vectores_target, vectores_cat, vectores_dynamic, puntos_a_excluir=6):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios excluyendo los últimos 'puntos_a_excluir' valores de \n",
    "    target y dynamic_feat para cada serie.\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "        puntos_a_excluir: Número de puntos a excluir del final de las series (default=6)\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else float(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar que hay suficientes puntos para excluir\n",
    "        if len(target_data) <= puntos_a_excluir:\n",
    "            print(f\"Advertencia: Serie {i} tiene menos puntos ({len(target_data)}) que los requeridos a excluir ({puntos_a_excluir}). Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Excluir los últimos 'puntos_a_excluir' valores\n",
    "        target_data_recortado = target_data[:-puntos_a_excluir]\n",
    "        month_vector_recortado = month_vector[:-puntos_a_excluir]\n",
    "        quarter_vector_recortado = quarter_vector[:-puntos_a_excluir]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic después del recorte\n",
    "        if len(target_data_recortado) != len(month_vector_recortado) or len(target_data_recortado) != len(quarter_vector_recortado):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes después del recorte - target: {len(target_data_recortado)}, \"\n",
    "                  f\"month: {len(month_vector_recortado)}, quarter: {len(quarter_vector_recortado)}\")\n",
    "            # Ajustar a la longitud mínima\n",
    "            min_len = min(len(target_data_recortado), len(month_vector_recortado), len(quarter_vector_recortado))\n",
    "            target_data_recortado = target_data_recortado[:min_len]\n",
    "            month_vector_recortado = month_vector_recortado[:min_len]\n",
    "            quarter_vector_recortado = quarter_vector_recortado[:min_len]\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data_recortado),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector_recortado, quarter_vector_recortado]\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1abad3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = crear_diccionarios_entrenamiento(start,vectores_target, vectores_cat, vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14b00d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, \"wb\") as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef54ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"data_json/mensual_modificado_float/train.json\", train)\n",
    "write_dicts_to_file(\"data_json/mensual_modificado_float/test.json\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "110638ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/22/25 14:19:17] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/22/25 14:19:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=589464;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=262519;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\u001b\\\u001b[2m1352\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boto_session = boto3.Session(profile_name='lilipink', region_name='us-east-1')\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "s3_client = boto_session.client('s3')\n",
    "sm_client= boto_session.client('sagemaker')\n",
    "s3 = boto_session.resource(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7439c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region=None):\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration=location\n",
    "            )\n",
    "        print(f\"Bucket S3 '{bucket_name}' creado exitosamente en {region if region else 'la región por defecto'}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        print(f\"Error al crear el bucket S3: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd32a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket S3 'forecasting-mensual-15-v3' creado exitosamente en la región por defecto\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"forecasting-mensual-15-v3\"\n",
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b5a1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = bucket_name  # replace with an existing bucket if needed\n",
    "s3_bucket_prefix = (\n",
    "        \"lilipink\"  \n",
    "    )\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "if default_bucket_prefix:\n",
    "    s3_prefix = f\"{default_bucket_prefix}/{s3_bucket_prefix}\"\n",
    "else:\n",
    "    s3_prefix = s3_bucket_prefix\n",
    "\n",
    "role = \"arn:aws:iam::844598627082:role/service-role/AmazonSageMaker-ExecutionRole-20250513T105052\"  # IAM role to use by SageMaker\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea21564f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/22/25 14:19:18] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Same images used for training and inference. Defaulting to image     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         scope: inference.                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/22/25 14:19:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Same images used for training and inference. Defaulting to image     \u001b]8;id=379881;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=207173;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         scope: inference.                                                    \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#530\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=959484;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=867560;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#530\u001b\\\u001b[2m530\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_name = sagemaker.image_uris.retrieve(\"forecasting-deepar\", region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc300d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith(\"s3://\")\n",
    "    split = s3_path.split(\"/\")\n",
    "    bucket = split[2]\n",
    "    path = \"/\".join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "\n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print(\n",
    "                \"File s3://{}/{} already exists.\\nSet override to upload anyway.\\n\".format(\n",
    "                    s3_bucket, s3_path\n",
    "                )\n",
    "            )\n",
    "            return\n",
    "        else:\n",
    "            print(\"Overwriting existing file\")\n",
    "    with open(local_file, \"rb\") as data:\n",
    "        print(\"Uploading file to {}\".format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7061e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file\n",
      "Uploading file to s3://forecasting-mensual-15-v3/lilipink/data/train/train.json\n",
      "Overwriting existing file\n",
      "Uploading file to s3://forecasting-mensual-15-v3/lilipink/data/test/test.json\n"
     ]
    }
   ],
   "source": [
    "local_file = 'data_json/mensual_modificado_float/'\n",
    "copy_to_s3(local_file + 'train.json', s3_data_path + \"/train/train.json\",override=True)\n",
    "copy_to_s3(local_file + 'test.json', s3_data_path + \"/test/test.json\",override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35a4dcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/22/25 14:19:20] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/22/25 14:19:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=511139;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=633370;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\u001b\\\u001b[2m1352\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.2xlarge\",\n",
    "   # use_spot_instances=True,\n",
    "   # max_run=1800,  # max training time in seconds\n",
    "   # max_wait=1800,  # seconds to wait for spot instance\n",
    "    base_job_name=\"lilipink-forecasting\",\n",
    "    output_path=s3_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb5e23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###PRIMER ENTRENAMIENTO###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "067612dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 12\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    #\"learning_rate\": \"1E-3\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "8e98ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "91d8d854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 10:46:54] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 10:46:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=706920;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=688576;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-15-46-54-277                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=659238;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=827897;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-15-46-54-277                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 15:46:56 Starting - Starting the training job...\n",
      "2025-05-21 15:47:21 Starting - Preparing the instances for training...\n",
      "2025-05-21 15:47:59 Downloading - Downloading the training image...............\n",
      "2025-05-21 15:50:21 Training - Training image download completed. Training in progress.Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '12', 'early_stopping_patience': '40', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '12', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Detected entry point for worker worker\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Using early stopping with patience 40\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] random_seed is None\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] [cardinality=auto] Inferred value of cardinality=[2, 4, 5, 6, 6] from dataset.\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Training set statistics:\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Real time series\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] number of time series: 15\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] number of observations: 582\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] mean target length: 38.8\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] min/mean/max target: 1.0/30.99656357388316/350.0\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] mean abs(target): 30.99656357388316\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] contains missing values: no\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Small number of time series. Doing 86 passes over dataset with prob 0.9922480620155039 per epoch.\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Test set statistics:\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Real time series\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] number of time series: 15\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] number of observations: 672\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] mean target length: 44.8\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] min/mean/max target: 1.0/30.99702380952381/388.0\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] mean abs(target): 30.99702380952381\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] contains missing values: no\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] #memory_usage::<batchbuffer> = 1.875 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] nvidia-smi: took 0.030 seconds to run.\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] nvidia-smi identified 0 GPUs.\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Number of GPUs being used: 0\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Create Store: local\n",
      "#metrics {\"StartTime\": 1747842637.308393, \"EndTime\": 1747842637.3462539, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 37.012338638305664, \"count\": 1, \"min\": 37.012338638305664, \"max\": 37.012338638305664}}}\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Number of GPUs being used: 0\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] #memory_usage::<model> = 16 mb\n",
      "#metrics {\"StartTime\": 1747842637.34632, \"EndTime\": 1747842637.4075513, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 99.03502464294434, \"count\": 1, \"min\": 99.03502464294434, \"max\": 99.03502464294434}}}\n",
      "[15:50:37] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 20480 bytes with malloc directly\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Epoch[0] Batch[0] avg_epoch_loss=3.930136\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.9301364421844482\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Epoch[0] Batch[5] avg_epoch_loss=3.897061\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.8970611095428467\n",
      "[05/21/2025 15:50:37 INFO 140269512570688] Epoch[0] Batch [5]#011Speed: 2828.78 samples/sec#011loss=3.897061\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] Epoch[0] Batch[10] avg_epoch_loss=3.818715\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.7247003078460694\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] Epoch[0] Batch [10]#011Speed: 2598.33 samples/sec#011loss=3.724700\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747842637.4076068, \"EndTime\": 1747842638.2339876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 826.3039588928223, \"count\": 1, \"min\": 826.3039588928223, \"max\": 826.3039588928223}}}\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1632.3916921103553 records/second\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.818715290589766\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_984f63ff-73d0-4db3-9b1c-fbb2a4e86345-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842638.2340484, \"EndTime\": 1747842638.2438462, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.487152099609375, \"count\": 1, \"min\": 9.487152099609375, \"max\": 9.487152099609375}}}\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] Epoch[1] Batch[0] avg_epoch_loss=3.654456\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.6544556617736816\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] Epoch[1] Batch[5] avg_epoch_loss=3.753445\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.753444949785868\n",
      "[05/21/2025 15:50:38 INFO 140269512570688] Epoch[1] Batch [5]#011Speed: 2306.84 samples/sec#011loss=3.753445\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] Epoch[1] Batch[10] avg_epoch_loss=3.760570\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.7691197872161863\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] Epoch[1] Batch [10]#011Speed: 2325.91 samples/sec#011loss=3.769120\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747842638.2438953, \"EndTime\": 1747842639.107575, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 863.6331558227539, \"count\": 1, \"min\": 863.6331558227539, \"max\": 863.6331558227539}}}\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1562.9962834637322 records/second\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.7605698758905586\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_334bfe59-d24c-46bf-879a-a1fd5beb7626-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842639.1076381, \"EndTime\": 1747842639.116529, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.502960205078125, \"count\": 1, \"min\": 8.502960205078125, \"max\": 8.502960205078125}}}\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] Epoch[2] Batch[0] avg_epoch_loss=3.595540\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.5955398082733154\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] Epoch[2] Batch[5] avg_epoch_loss=3.729937\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.7299370765686035\n",
      "[05/21/2025 15:50:39 INFO 140269512570688] Epoch[2] Batch [5]#011Speed: 2083.77 samples/sec#011loss=3.729937\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] Epoch[2] Batch[10] avg_epoch_loss=3.739305\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.7505465507507325\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] Epoch[2] Batch [10]#011Speed: 2331.46 samples/sec#011loss=3.750547\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747842639.1165843, \"EndTime\": 1747842640.036151, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.5108413696289, \"count\": 1, \"min\": 919.5108413696289, \"max\": 919.5108413696289}}}\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1421.2678912174158 records/second\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.739305019378662\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_74dec229-2a22-4ce6-ad06-a2ed891722d5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842640.0362122, \"EndTime\": 1747842640.0464294, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.899616241455078, \"count\": 1, \"min\": 9.899616241455078, \"max\": 9.899616241455078}}}\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] Epoch[3] Batch[0] avg_epoch_loss=3.565123\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.5651228427886963\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] Epoch[3] Batch[5] avg_epoch_loss=3.654647\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.6546465953191123\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] Epoch[3] Batch [5]#011Speed: 2746.65 samples/sec#011loss=3.654647\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] processed a total of 1259 examples\n",
      "#metrics {\"StartTime\": 1747842640.0464869, \"EndTime\": 1747842640.8085139, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 761.970043182373, \"count\": 1, \"min\": 761.970043182373, \"max\": 761.970043182373}}}\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1652.0922558636034 records/second\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.6211477756500243\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:40 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_ac193003-cf72-4fa9-bc1b-2c6189f0e53a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842640.8085752, \"EndTime\": 1747842640.818154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.145259857177734, \"count\": 1, \"min\": 9.145259857177734, \"max\": 9.145259857177734}}}\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] Epoch[4] Batch[0] avg_epoch_loss=3.796616\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.7966158390045166\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] Epoch[4] Batch[5] avg_epoch_loss=3.661680\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.661679983139038\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] Epoch[4] Batch [5]#011Speed: 2700.69 samples/sec#011loss=3.661680\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] processed a total of 1257 examples\n",
      "#metrics {\"StartTime\": 1747842640.8182154, \"EndTime\": 1747842641.5601301, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 741.8594360351562, \"count\": 1, \"min\": 741.8594360351562, \"max\": 741.8594360351562}}}\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1694.191241443069 records/second\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.6460265159606933\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] Epoch[5] Batch[0] avg_epoch_loss=3.566949\n",
      "[05/21/2025 15:50:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.566948890686035\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] Epoch[5] Batch[5] avg_epoch_loss=3.599637\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.5996368726094565\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] Epoch[5] Batch [5]#011Speed: 2706.74 samples/sec#011loss=3.599637\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] Epoch[5] Batch[10] avg_epoch_loss=3.659482\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.7312958240509033\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] Epoch[5] Batch [10]#011Speed: 2565.19 samples/sec#011loss=3.731296\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747842641.5601869, \"EndTime\": 1747842642.3495674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.8619899749756, \"count\": 1, \"min\": 788.8619899749756, \"max\": 788.8619899749756}}}\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1730.14878392696 records/second\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.6594818505373867\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] Epoch[6] Batch[0] avg_epoch_loss=3.645688\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.64568829536438\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] Epoch[6] Batch[5] avg_epoch_loss=3.628077\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.628077268600464\n",
      "[05/21/2025 15:50:42 INFO 140269512570688] Epoch[6] Batch [5]#011Speed: 2824.71 samples/sec#011loss=3.628077\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] Epoch[6] Batch[10] avg_epoch_loss=3.617883\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.605650854110718\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] Epoch[6] Batch [10]#011Speed: 2534.28 samples/sec#011loss=3.605651\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747842642.3496253, \"EndTime\": 1747842643.1349065, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.0260734558105, \"count\": 1, \"min\": 785.0260734558105, \"max\": 785.0260734558105}}}\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1730.9639626152104 records/second\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.6178834438323975\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_b788fd2d-936b-4b00-bfbd-cb5763cfb830-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842643.1349647, \"EndTime\": 1747842643.1440835, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.819818496704102, \"count\": 1, \"min\": 8.819818496704102, \"max\": 8.819818496704102}}}\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] Epoch[7] Batch[0] avg_epoch_loss=3.608570\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.6085703372955322\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] Epoch[7] Batch[5] avg_epoch_loss=3.566366\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.5663658380508423\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] Epoch[7] Batch [5]#011Speed: 2520.99 samples/sec#011loss=3.566366\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] Epoch[7] Batch[10] avg_epoch_loss=3.436280\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.2801767110824587\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] Epoch[7] Batch [10]#011Speed: 2553.35 samples/sec#011loss=3.280177\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747842643.144135, \"EndTime\": 1747842643.9595485, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 815.3643608093262, \"count\": 1, \"min\": 815.3643608093262, \"max\": 815.3643608093262}}}\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1617.5071671556652 records/second\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.4362798712470313\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:43 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_9be29035-b2a8-4d22-9fa8-219e3286db9a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842643.959608, \"EndTime\": 1747842643.9692562, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.382963180541992, \"count\": 1, \"min\": 9.382963180541992, \"max\": 9.382963180541992}}}\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] Epoch[8] Batch[0] avg_epoch_loss=3.449322\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.4493215084075928\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] Epoch[8] Batch[5] avg_epoch_loss=3.525123\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.5251234769821167\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] Epoch[8] Batch [5]#011Speed: 2789.47 samples/sec#011loss=3.525123\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] Epoch[8] Batch[10] avg_epoch_loss=3.570429\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.6247955322265626\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] Epoch[8] Batch [10]#011Speed: 2765.92 samples/sec#011loss=3.624796\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747842643.9693084, \"EndTime\": 1747842644.7457862, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 776.430606842041, \"count\": 1, \"min\": 776.430606842041, \"max\": 776.430606842041}}}\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1724.3816415509132 records/second\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.570428956638683\n",
      "[05/21/2025 15:50:44 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] Epoch[9] Batch[0] avg_epoch_loss=3.649138\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.6491384506225586\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] Epoch[9] Batch[5] avg_epoch_loss=3.527868\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.527868072191874\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] Epoch[9] Batch [5]#011Speed: 2828.69 samples/sec#011loss=3.527868\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] Epoch[9] Batch[10] avg_epoch_loss=3.551075\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.5789223670959474\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] Epoch[9] Batch [10]#011Speed: 2517.32 samples/sec#011loss=3.578922\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747842644.74584, \"EndTime\": 1747842645.5342808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.193941116333, \"count\": 1, \"min\": 788.193941116333, \"max\": 788.193941116333}}}\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1724.0165830527299 records/second\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.551074569875544\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] Epoch[10] Batch[0] avg_epoch_loss=3.613336\n",
      "[05/21/2025 15:50:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.6133363246917725\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] Epoch[10] Batch[5] avg_epoch_loss=3.532454\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.5324536164601645\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] Epoch[10] Batch [5]#011Speed: 2611.55 samples/sec#011loss=3.532454\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] Epoch[10] Batch[10] avg_epoch_loss=3.610319\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.7037582874298094\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] Epoch[10] Batch [10]#011Speed: 2521.06 samples/sec#011loss=3.703758\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747842645.534335, \"EndTime\": 1747842646.3506427, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 816.0169124603271, \"count\": 1, \"min\": 816.0169124603271, \"max\": 816.0169124603271}}}\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1626.0221818415532 records/second\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.6103193759918213\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] Epoch[11] Batch[0] avg_epoch_loss=3.543556\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.543555974960327\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] Epoch[11] Batch[5] avg_epoch_loss=3.579456\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.5794562896092734\n",
      "[05/21/2025 15:50:46 INFO 140269512570688] Epoch[11] Batch [5]#011Speed: 2670.74 samples/sec#011loss=3.579456\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] Epoch[11] Batch[10] avg_epoch_loss=3.609040\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=3.6445412635803223\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] Epoch[11] Batch [10]#011Speed: 2746.21 samples/sec#011loss=3.644541\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747842646.3506994, \"EndTime\": 1747842647.1337612, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.6457023620605, \"count\": 1, \"min\": 782.6457023620605, \"max\": 782.6457023620605}}}\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1695.3393312569963 records/second\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.609040368687023\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] Epoch[12] Batch[0] avg_epoch_loss=3.488717\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.4887168407440186\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] Epoch[12] Batch[5] avg_epoch_loss=3.475434\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.475434422492981\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] Epoch[12] Batch [5]#011Speed: 2796.72 samples/sec#011loss=3.475434\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] Epoch[12] Batch[10] avg_epoch_loss=3.476035\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=3.4767558097839357\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] Epoch[12] Batch [10]#011Speed: 2385.24 samples/sec#011loss=3.476756\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747842647.1338193, \"EndTime\": 1747842647.9439423, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.8688125610352, \"count\": 1, \"min\": 809.8688125610352, \"max\": 809.8688125610352}}}\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1688.983465187172 records/second\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.4760350530797783\n",
      "[05/21/2025 15:50:47 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] Epoch[13] Batch[0] avg_epoch_loss=3.502913\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.5029125213623047\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] Epoch[13] Batch[5] avg_epoch_loss=3.469846\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.4698458115259805\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] Epoch[13] Batch [5]#011Speed: 2874.56 samples/sec#011loss=3.469846\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] Epoch[13] Batch[10] avg_epoch_loss=3.459350\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.4467548370361327\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] Epoch[13] Batch [10]#011Speed: 2696.12 samples/sec#011loss=3.446755\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747842647.9439995, \"EndTime\": 1747842648.7175307, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 773.2748985290527, \"count\": 1, \"min\": 773.2748985290527, \"max\": 773.2748985290527}}}\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1692.6145390488534 records/second\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.459349914030595\n",
      "[05/21/2025 15:50:48 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] Epoch[14] Batch[0] avg_epoch_loss=3.451914\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.451913595199585\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] Epoch[14] Batch[5] avg_epoch_loss=3.441899\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.4418988625208535\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] Epoch[14] Batch [5]#011Speed: 2888.36 samples/sec#011loss=3.441899\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] Epoch[14] Batch[10] avg_epoch_loss=3.460192\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=3.482142925262451\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] Epoch[14] Batch [10]#011Speed: 2626.51 samples/sec#011loss=3.482143\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747842648.7175863, \"EndTime\": 1747842649.486242, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 768.4001922607422, \"count\": 1, \"min\": 768.4001922607422, \"max\": 768.4001922607422}}}\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1777.518736884429 records/second\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.460191618312489\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] Epoch[15] Batch[0] avg_epoch_loss=3.363209\n",
      "[05/21/2025 15:50:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.3632094860076904\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] Epoch[15] Batch[5] avg_epoch_loss=3.391140\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=3.39113982518514\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] Epoch[15] Batch [5]#011Speed: 2707.47 samples/sec#011loss=3.391140\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] Epoch[15] Batch[10] avg_epoch_loss=3.408637\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=3.4296334743499757\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] Epoch[15] Batch [10]#011Speed: 2467.44 samples/sec#011loss=3.429633\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] processed a total of 1377 examples\n",
      "#metrics {\"StartTime\": 1747842649.4863007, \"EndTime\": 1747842650.2868934, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.3363609313965, \"count\": 1, \"min\": 800.3363609313965, \"max\": 800.3363609313965}}}\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1720.347231803608 records/second\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=15, train loss <loss>=3.4086369384418833\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_39eefb53-9dfd-4598-a506-cd38865d6454-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842650.2869484, \"EndTime\": 1747842650.2967827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.518861770629883, \"count\": 1, \"min\": 9.518861770629883, \"max\": 9.518861770629883}}}\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] Epoch[16] Batch[0] avg_epoch_loss=3.505870\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.5058698654174805\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] Epoch[16] Batch[5] avg_epoch_loss=3.487770\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=3.487770398457845\n",
      "[05/21/2025 15:50:50 INFO 140269512570688] Epoch[16] Batch [5]#011Speed: 2788.69 samples/sec#011loss=3.487770\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747842650.2968369, \"EndTime\": 1747842651.032008, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 735.1176738739014, \"count\": 1, \"min\": 735.1176738739014, \"max\": 735.1176738739014}}}\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1723.3128129760917 records/second\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.4520564794540407\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] Epoch[17] Batch[0] avg_epoch_loss=3.536126\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.536125898361206\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] Epoch[17] Batch[5] avg_epoch_loss=3.422279\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.422278801600138\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] Epoch[17] Batch [5]#011Speed: 2795.36 samples/sec#011loss=3.422279\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] Epoch[17] Batch[10] avg_epoch_loss=3.396760\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.366137075424194\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] Epoch[17] Batch [10]#011Speed: 2590.02 samples/sec#011loss=3.366137\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747842651.0320718, \"EndTime\": 1747842651.818016, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.5901718139648, \"count\": 1, \"min\": 785.5901718139648, \"max\": 785.5901718139648}}}\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1696.6281212029992 records/second\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.3967598351565274\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:51 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_e8d2bed6-0b9d-496b-9bcf-02924db582af-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842651.8180737, \"EndTime\": 1747842651.827578, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.228229522705078, \"count\": 1, \"min\": 9.228229522705078, \"max\": 9.228229522705078}}}\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] Epoch[18] Batch[0] avg_epoch_loss=3.429634\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.4296343326568604\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] Epoch[18] Batch[5] avg_epoch_loss=3.365540\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.3655401468276978\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] Epoch[18] Batch [5]#011Speed: 2883.32 samples/sec#011loss=3.365540\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] Epoch[18] Batch[10] avg_epoch_loss=3.343536\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.3171299934387206\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] Epoch[18] Batch [10]#011Speed: 2452.17 samples/sec#011loss=3.317130\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747842651.827634, \"EndTime\": 1747842652.6285038, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.7988929748535, \"count\": 1, \"min\": 800.7988929748535, \"max\": 800.7988929748535}}}\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1665.6073654404427 records/second\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.34353553165089\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_b3ee611e-6de5-4f9c-bc24-03f5229f8cb1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842652.6285653, \"EndTime\": 1747842652.6376698, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.824348449707031, \"count\": 1, \"min\": 8.824348449707031, \"max\": 8.824348449707031}}}\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] Epoch[19] Batch[0] avg_epoch_loss=3.390533\n",
      "[05/21/2025 15:50:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.390532970428467\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] Epoch[19] Batch[5] avg_epoch_loss=3.338454\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=3.3384539683659873\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] Epoch[19] Batch [5]#011Speed: 2730.33 samples/sec#011loss=3.338454\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] Epoch[19] Batch[10] avg_epoch_loss=3.375376\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=3.419682836532593\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] Epoch[19] Batch [10]#011Speed: 2702.09 samples/sec#011loss=3.419683\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747842652.6377254, \"EndTime\": 1747842653.4258597, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.0818843841553, \"count\": 1, \"min\": 788.0818843841553, \"max\": 788.0818843841553}}}\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1668.4266239943856 records/second\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=19, train loss <loss>=3.3753761811689897\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] Epoch[20] Batch[0] avg_epoch_loss=3.426910\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.426909923553467\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] Epoch[20] Batch[5] avg_epoch_loss=3.354073\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=3.354073405265808\n",
      "[05/21/2025 15:50:53 INFO 140269512570688] Epoch[20] Batch [5]#011Speed: 2814.93 samples/sec#011loss=3.354073\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] processed a total of 1260 examples\n",
      "#metrics {\"StartTime\": 1747842653.4259157, \"EndTime\": 1747842654.1466982, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 720.4766273498535, \"count\": 1, \"min\": 720.4766273498535, \"max\": 720.4766273498535}}}\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1748.6079456626287 records/second\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.315706467628479\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_06b8c786-1573-4433-83ce-f2fdc6ad4144-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842654.1467617, \"EndTime\": 1747842654.157293, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.128259658813477, \"count\": 1, \"min\": 10.128259658813477, \"max\": 10.128259658813477}}}\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] Epoch[21] Batch[0] avg_epoch_loss=3.341954\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.341953992843628\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] Epoch[21] Batch[5] avg_epoch_loss=3.328561\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.328561027844747\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] Epoch[21] Batch [5]#011Speed: 2810.23 samples/sec#011loss=3.328561\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] Epoch[21] Batch[10] avg_epoch_loss=3.307112\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=3.281373167037964\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] Epoch[21] Batch [10]#011Speed: 2706.37 samples/sec#011loss=3.281373\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747842654.1573546, \"EndTime\": 1747842654.9328208, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 775.4111289978027, \"count\": 1, \"min\": 775.4111289978027, \"max\": 775.4111289978027}}}\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1653.0653946564257 records/second\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=21, train loss <loss>=3.3071120002053003\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:54 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_2c85b375-62c6-45a6-930b-5ae0a5c08488-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842654.9329088, \"EndTime\": 1747842654.9426103, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.409189224243164, \"count\": 1, \"min\": 9.409189224243164, \"max\": 9.409189224243164}}}\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] Epoch[22] Batch[0] avg_epoch_loss=3.329231\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=3.329230546951294\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] Epoch[22] Batch[5] avg_epoch_loss=3.316089\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=3.3160887956619263\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] Epoch[22] Batch [5]#011Speed: 2713.67 samples/sec#011loss=3.316089\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] Epoch[22] Batch[10] avg_epoch_loss=3.292930\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=3.265139579772949\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] Epoch[22] Batch [10]#011Speed: 2529.70 samples/sec#011loss=3.265140\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] processed a total of 1397 examples\n",
      "#metrics {\"StartTime\": 1747842654.9426649, \"EndTime\": 1747842655.7419372, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.2196083068848, \"count\": 1, \"min\": 799.2196083068848, \"max\": 799.2196083068848}}}\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1747.7637645759019 records/second\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=22, train loss <loss>=3.2929300611669365\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:55 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_5ebf5a22-6b0e-4c8a-b5f2-82bf90eec06e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842655.741996, \"EndTime\": 1747842655.7516913, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.424209594726562, \"count\": 1, \"min\": 9.424209594726562, \"max\": 9.424209594726562}}}\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] Epoch[23] Batch[0] avg_epoch_loss=3.222693\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=3.22269344329834\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] Epoch[23] Batch[5] avg_epoch_loss=3.297432\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=3.2974315087000527\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] Epoch[23] Batch [5]#011Speed: 2836.60 samples/sec#011loss=3.297432\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] Epoch[23] Batch[10] avg_epoch_loss=3.373140\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=3.4639894008636474\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] Epoch[23] Batch [10]#011Speed: 2710.52 samples/sec#011loss=3.463989\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747842655.7517512, \"EndTime\": 1747842656.5226848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 770.8775997161865, \"count\": 1, \"min\": 770.8775997161865, \"max\": 770.8775997161865}}}\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1700.4629244560665 records/second\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=23, train loss <loss>=3.373139641501687\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] Epoch[24] Batch[0] avg_epoch_loss=3.424196\n",
      "[05/21/2025 15:50:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=3.4241955280303955\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] Epoch[24] Batch[5] avg_epoch_loss=3.300886\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=3.3008862336476645\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] Epoch[24] Batch [5]#011Speed: 2831.01 samples/sec#011loss=3.300886\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] Epoch[24] Batch[10] avg_epoch_loss=3.346687\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=3.40164794921875\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] Epoch[24] Batch [10]#011Speed: 2770.25 samples/sec#011loss=3.401648\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747842656.5227435, \"EndTime\": 1747842657.2939248, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 770.9143161773682, \"count\": 1, \"min\": 770.9143161773682, \"max\": 770.9143161773682}}}\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1684.8266658008135 records/second\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=24, train loss <loss>=3.346687013452703\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] Epoch[25] Batch[0] avg_epoch_loss=3.249509\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=3.24950909614563\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] Epoch[25] Batch[5] avg_epoch_loss=3.289517\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=3.289517402648926\n",
      "[05/21/2025 15:50:57 INFO 140269512570688] Epoch[25] Batch [5]#011Speed: 2757.88 samples/sec#011loss=3.289517\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] Epoch[25] Batch[10] avg_epoch_loss=3.297449\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=3.306967258453369\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] Epoch[25] Batch [10]#011Speed: 2473.06 samples/sec#011loss=3.306967\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] processed a total of 1389 examples\n",
      "#metrics {\"StartTime\": 1747842657.2939801, \"EndTime\": 1747842658.092249, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.0179786682129, \"count\": 1, \"min\": 798.0179786682129, \"max\": 798.0179786682129}}}\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1740.3808227026966 records/second\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=25, train loss <loss>=3.297449155287309\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] Epoch[26] Batch[0] avg_epoch_loss=3.194323\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=3.1943228244781494\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] Epoch[26] Batch[5] avg_epoch_loss=3.252950\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=3.2529503107070923\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] Epoch[26] Batch [5]#011Speed: 2736.68 samples/sec#011loss=3.252950\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] Epoch[26] Batch[10] avg_epoch_loss=3.207187\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=3.1522709369659423\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] Epoch[26] Batch [10]#011Speed: 2389.24 samples/sec#011loss=3.152271\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747842658.0923047, \"EndTime\": 1747842658.9333773, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 840.796709060669, \"count\": 1, \"min\": 840.796709060669, \"max\": 840.796709060669}}}\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1594.7498908397233 records/second\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=26, train loss <loss>=3.20718695900657\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:50:58 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_6f2be9d0-c3f5-4e53-8e55-8423fdcd1263-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842658.9334338, \"EndTime\": 1747842658.9431932, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.465456008911133, \"count\": 1, \"min\": 9.465456008911133, \"max\": 9.465456008911133}}}\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] Epoch[27] Batch[0] avg_epoch_loss=3.227951\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=3.2279510498046875\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] Epoch[27] Batch[5] avg_epoch_loss=3.235733\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=3.2357333103815713\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] Epoch[27] Batch [5]#011Speed: 2837.45 samples/sec#011loss=3.235733\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] Epoch[27] Batch[10] avg_epoch_loss=3.326847\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=3.436184310913086\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] Epoch[27] Batch [10]#011Speed: 2525.03 samples/sec#011loss=3.436184\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747842658.943246, \"EndTime\": 1747842659.731968, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.6707782745361, \"count\": 1, \"min\": 788.6707782745361, \"max\": 788.6707782745361}}}\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1659.4822546266128 records/second\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=27, train loss <loss>=3.3268474015322598\n",
      "[05/21/2025 15:50:59 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] Epoch[28] Batch[0] avg_epoch_loss=3.338089\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=3.3380889892578125\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] Epoch[28] Batch[5] avg_epoch_loss=3.288204\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=3.288203557332357\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] Epoch[28] Batch [5]#011Speed: 2867.28 samples/sec#011loss=3.288204\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] Epoch[28] Batch[10] avg_epoch_loss=3.254115\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=3.2132080078125\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] Epoch[28] Batch [10]#011Speed: 2784.45 samples/sec#011loss=3.213208\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747842659.732069, \"EndTime\": 1747842660.5000536, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 767.7149772644043, \"count\": 1, \"min\": 767.7149772644043, \"max\": 767.7149772644043}}}\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1698.259601468682 records/second\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=28, train loss <loss>=3.2541146711869673\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] Epoch[29] Batch[0] avg_epoch_loss=3.278195\n",
      "[05/21/2025 15:51:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=3.278195381164551\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] Epoch[29] Batch[5] avg_epoch_loss=3.294964\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=3.294963796933492\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] Epoch[29] Batch [5]#011Speed: 2803.92 samples/sec#011loss=3.294964\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] Epoch[29] Batch[10] avg_epoch_loss=3.223261\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=3.1372182369232178\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] Epoch[29] Batch [10]#011Speed: 2854.33 samples/sec#011loss=3.137218\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747842660.500152, \"EndTime\": 1747842661.2685564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 768.064022064209, \"count\": 1, \"min\": 768.064022064209, \"max\": 768.064022064209}}}\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1701.4898642273274 records/second\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=29, train loss <loss>=3.2232612696560947\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] Epoch[30] Batch[0] avg_epoch_loss=3.325585\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=3.32558536529541\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] Epoch[30] Batch[5] avg_epoch_loss=3.276523\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=3.276523470878601\n",
      "[05/21/2025 15:51:01 INFO 140269512570688] Epoch[30] Batch [5]#011Speed: 2339.07 samples/sec#011loss=3.276523\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] Epoch[30] Batch[10] avg_epoch_loss=3.240343\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=3.1969262599945067\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] Epoch[30] Batch [10]#011Speed: 2396.82 samples/sec#011loss=3.196926\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] processed a total of 1390 examples\n",
      "#metrics {\"StartTime\": 1747842661.2686143, \"EndTime\": 1747842662.116615, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 847.7377891540527, \"count\": 1, \"min\": 847.7377891540527, \"max\": 847.7377891540527}}}\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1639.4813463128924 records/second\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=30, train loss <loss>=3.24034292047674\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] Epoch[31] Batch[0] avg_epoch_loss=3.238839\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=3.2388386726379395\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] Epoch[31] Batch[5] avg_epoch_loss=3.224396\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=3.224395513534546\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] Epoch[31] Batch [5]#011Speed: 2594.88 samples/sec#011loss=3.224396\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] Epoch[31] Batch[10] avg_epoch_loss=3.242781\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=3.264843225479126\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] Epoch[31] Batch [10]#011Speed: 2341.51 samples/sec#011loss=3.264843\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747842662.1166756, \"EndTime\": 1747842662.9500725, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 833.1277370452881, \"count\": 1, \"min\": 833.1277370452881, \"max\": 833.1277370452881}}}\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1627.4366867968909 records/second\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=31, train loss <loss>=3.2427808371457187\n",
      "[05/21/2025 15:51:02 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] Epoch[32] Batch[0] avg_epoch_loss=3.117982\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=3.1179823875427246\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] Epoch[32] Batch[5] avg_epoch_loss=3.207600\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=3.2076003154118857\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] Epoch[32] Batch [5]#011Speed: 2784.76 samples/sec#011loss=3.207600\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] Epoch[32] Batch[10] avg_epoch_loss=3.239891\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=3.2786397457122805\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] Epoch[32] Batch [10]#011Speed: 2633.75 samples/sec#011loss=3.278640\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747842662.9501283, \"EndTime\": 1747842663.7391963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.8162136077881, \"count\": 1, \"min\": 788.8162136077881, \"max\": 788.8162136077881}}}\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1674.463937381476 records/second\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=32, train loss <loss>=3.2398909655484287\n",
      "[05/21/2025 15:51:03 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] Epoch[33] Batch[0] avg_epoch_loss=3.315513\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=3.3155128955841064\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] Epoch[33] Batch[5] avg_epoch_loss=3.246075\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=3.246074914932251\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] Epoch[33] Batch [5]#011Speed: 2819.12 samples/sec#011loss=3.246075\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747842663.7392576, \"EndTime\": 1747842664.479663, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 740.046501159668, \"count\": 1, \"min\": 740.046501159668, \"max\": 740.046501159668}}}\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1726.69933197482 records/second\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=33, train loss <loss>=3.239989399909973\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] Epoch[34] Batch[0] avg_epoch_loss=3.108865\n",
      "[05/21/2025 15:51:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=3.10886549949646\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] Epoch[34] Batch[5] avg_epoch_loss=3.172370\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=3.172370433807373\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] Epoch[34] Batch [5]#011Speed: 2764.27 samples/sec#011loss=3.172370\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] Epoch[34] Batch[10] avg_epoch_loss=3.182131\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=3.193843221664429\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] Epoch[34] Batch [10]#011Speed: 2681.62 samples/sec#011loss=3.193843\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747842664.4797251, \"EndTime\": 1747842665.252683, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 772.6583480834961, \"count\": 1, \"min\": 772.6583480834961, \"max\": 772.6583480834961}}}\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1723.7152932944089 records/second\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=34, train loss <loss>=3.1821307919242163\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_e260f4f1-9105-4b5c-8ef9-f7b6d8997087-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842665.252744, \"EndTime\": 1747842665.2628798, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.842872619628906, \"count\": 1, \"min\": 9.842872619628906, \"max\": 9.842872619628906}}}\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] Epoch[35] Batch[0] avg_epoch_loss=3.126564\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=3.126563787460327\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] Epoch[35] Batch[5] avg_epoch_loss=3.170841\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=3.1708410580952964\n",
      "[05/21/2025 15:51:05 INFO 140269512570688] Epoch[35] Batch [5]#011Speed: 2712.76 samples/sec#011loss=3.170841\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] Epoch[35] Batch[10] avg_epoch_loss=3.194201\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=3.2222336769104003\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] Epoch[35] Batch [10]#011Speed: 2532.61 samples/sec#011loss=3.222234\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747842665.2629335, \"EndTime\": 1747842666.0807188, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.7361488342285, \"count\": 1, \"min\": 817.7361488342285, \"max\": 817.7361488342285}}}\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1656.8320656752794 records/second\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=35, train loss <loss>=3.194201339374889\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] Epoch[36] Batch[0] avg_epoch_loss=3.207356\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=3.2073559761047363\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] Epoch[36] Batch[5] avg_epoch_loss=3.127833\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=3.127833127975464\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] Epoch[36] Batch [5]#011Speed: 2838.10 samples/sec#011loss=3.127833\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] Epoch[36] Batch[10] avg_epoch_loss=3.162085\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=3.2031864166259765\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] Epoch[36] Batch [10]#011Speed: 2821.00 samples/sec#011loss=3.203186\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747842666.0807793, \"EndTime\": 1747842666.8714163, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.3633117675781, \"count\": 1, \"min\": 790.3633117675781, \"max\": 790.3633117675781}}}\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1623.1258700339147 records/second\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=36, train loss <loss>=3.162084622816606\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:06 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_500958cf-99a0-479b-bde4-c731a8a9986b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842666.8714747, \"EndTime\": 1747842666.8816955, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.935140609741211, \"count\": 1, \"min\": 9.935140609741211, \"max\": 9.935140609741211}}}\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] Epoch[37] Batch[0] avg_epoch_loss=3.187308\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=3.1873080730438232\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] Epoch[37] Batch[5] avg_epoch_loss=3.171643\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=3.1716431776682534\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] Epoch[37] Batch [5]#011Speed: 3015.65 samples/sec#011loss=3.171643\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] Epoch[37] Batch[10] avg_epoch_loss=3.128584\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=3.076913261413574\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] Epoch[37] Batch [10]#011Speed: 2800.17 samples/sec#011loss=3.076913\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747842666.8818753, \"EndTime\": 1747842667.664754, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.822847366333, \"count\": 1, \"min\": 782.822847366333, \"max\": 782.822847366333}}}\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1692.4099299855561 records/second\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=37, train loss <loss>=3.1285841248252173\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:07 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_9020edc5-0aaa-4561-82ac-65925116f4fc-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842667.6648088, \"EndTime\": 1747842667.6763566, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.263132095336914, \"count\": 1, \"min\": 11.263132095336914, \"max\": 11.263132095336914}}}\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] Epoch[38] Batch[0] avg_epoch_loss=3.148983\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=3.1489832401275635\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] Epoch[38] Batch[5] avg_epoch_loss=3.142371\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=3.1423714558283486\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] Epoch[38] Batch [5]#011Speed: 2888.63 samples/sec#011loss=3.142371\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] Epoch[38] Batch[10] avg_epoch_loss=3.085557\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=3.017380475997925\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] Epoch[38] Batch [10]#011Speed: 2774.21 samples/sec#011loss=3.017380\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747842667.6764083, \"EndTime\": 1747842668.4657803, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.325475692749, \"count\": 1, \"min\": 789.325475692749, \"max\": 789.325475692749}}}\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1665.793253541711 records/second\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=38, train loss <loss>=3.085557374087247\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_eb79e61e-5a84-44a1-abf2-11494e757199-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842668.4658399, \"EndTime\": 1747842668.4760075, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.882926940917969, \"count\": 1, \"min\": 9.882926940917969, \"max\": 9.882926940917969}}}\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] Epoch[39] Batch[0] avg_epoch_loss=3.133486\n",
      "[05/21/2025 15:51:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=3.133485794067383\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] Epoch[39] Batch[5] avg_epoch_loss=3.185747\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=3.1857468684514365\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] Epoch[39] Batch [5]#011Speed: 2934.13 samples/sec#011loss=3.185747\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] Epoch[39] Batch[10] avg_epoch_loss=3.152069\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=3.1116547107696535\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] Epoch[39] Batch [10]#011Speed: 2748.06 samples/sec#011loss=3.111655\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747842668.4760613, \"EndTime\": 1747842669.2607667, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.6558094024658, \"count\": 1, \"min\": 784.6558094024658, \"max\": 784.6558094024658}}}\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1698.6518451813463 records/second\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=39, train loss <loss>=3.152068614959717\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] Epoch[40] Batch[0] avg_epoch_loss=3.083292\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=3.083292007446289\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] Epoch[40] Batch[5] avg_epoch_loss=3.108072\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=3.108071724573771\n",
      "[05/21/2025 15:51:09 INFO 140269512570688] Epoch[40] Batch [5]#011Speed: 2820.12 samples/sec#011loss=3.108072\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] Epoch[40] Batch[10] avg_epoch_loss=3.132289\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=3.1613495349884033\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] Epoch[40] Batch [10]#011Speed: 2564.95 samples/sec#011loss=3.161350\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] processed a total of 1376 examples\n",
      "#metrics {\"StartTime\": 1747842669.2608247, \"EndTime\": 1747842670.0690324, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.9047203063965, \"count\": 1, \"min\": 807.9047203063965, \"max\": 807.9047203063965}}}\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1702.9937299181959 records/second\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=40, train loss <loss>=3.1322889111258765\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] Epoch[41] Batch[0] avg_epoch_loss=3.142825\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=3.1428253650665283\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] Epoch[41] Batch[5] avg_epoch_loss=3.149984\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=3.1499836444854736\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] Epoch[41] Batch [5]#011Speed: 2516.10 samples/sec#011loss=3.149984\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747842670.069088, \"EndTime\": 1747842670.832054, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 762.6051902770996, \"count\": 1, \"min\": 762.6051902770996, \"max\": 762.6051902770996}}}\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1671.6752489583557 records/second\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=41, train loss <loss>=3.1437321662902833\n",
      "[05/21/2025 15:51:10 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] Epoch[42] Batch[0] avg_epoch_loss=3.209493\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=3.2094931602478027\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] Epoch[42] Batch[5] avg_epoch_loss=3.092134\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=3.09213395913442\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] Epoch[42] Batch [5]#011Speed: 2869.68 samples/sec#011loss=3.092134\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] processed a total of 1265 examples\n",
      "#metrics {\"StartTime\": 1747842670.832126, \"EndTime\": 1747842671.5427763, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 710.3583812713623, \"count\": 1, \"min\": 710.3583812713623, \"max\": 710.3583812713623}}}\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1780.5719394353898 records/second\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=42, train loss <loss>=3.089363217353821\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] Epoch[43] Batch[0] avg_epoch_loss=3.104205\n",
      "[05/21/2025 15:51:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=3.104205369949341\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] Epoch[43] Batch[5] avg_epoch_loss=3.088278\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=3.088277538617452\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] Epoch[43] Batch [5]#011Speed: 2592.97 samples/sec#011loss=3.088278\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] Epoch[43] Batch[10] avg_epoch_loss=3.033135\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.96696400642395\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] Epoch[43] Batch [10]#011Speed: 2895.35 samples/sec#011loss=2.966964\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747842671.5428345, \"EndTime\": 1747842672.3230412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 779.8740863800049, \"count\": 1, \"min\": 779.8740863800049, \"max\": 779.8740863800049}}}\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1657.7871264944044 records/second\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=43, train loss <loss>=3.033135023984042\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_43232826-7d46-4d0d-9469-c21a42ef0f33-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842672.3230953, \"EndTime\": 1747842672.3320684, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.708715438842773, \"count\": 1, \"min\": 8.708715438842773, \"max\": 8.708715438842773}}}\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] Epoch[44] Batch[0] avg_epoch_loss=3.126375\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=3.1263747215270996\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] Epoch[44] Batch[5] avg_epoch_loss=3.098824\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=3.098824222882589\n",
      "[05/21/2025 15:51:12 INFO 140269512570688] Epoch[44] Batch [5]#011Speed: 2201.25 samples/sec#011loss=3.098824\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] Epoch[44] Batch[10] avg_epoch_loss=3.075482\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=3.0474715709686278\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] Epoch[44] Batch [10]#011Speed: 2702.06 samples/sec#011loss=3.047472\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747842672.3321173, \"EndTime\": 1747842673.1788454, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 846.6830253601074, \"count\": 1, \"min\": 846.6830253601074, \"max\": 846.6830253601074}}}\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1594.3029460044656 records/second\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=44, train loss <loss>=3.0754821083762427\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] Epoch[45] Batch[0] avg_epoch_loss=3.223400\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=3.2233996391296387\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] Epoch[45] Batch[5] avg_epoch_loss=3.163778\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=3.1637783447901406\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] Epoch[45] Batch [5]#011Speed: 2945.25 samples/sec#011loss=3.163778\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] Epoch[45] Batch[10] avg_epoch_loss=3.174271\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=3.186862564086914\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] Epoch[45] Batch [10]#011Speed: 2414.92 samples/sec#011loss=3.186863\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747842673.1789, \"EndTime\": 1747842673.969169, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.9878025054932, \"count\": 1, \"min\": 789.9878025054932, \"max\": 789.9878025054932}}}\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1728.950165579601 records/second\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=45, train loss <loss>=3.1742711717432197\n",
      "[05/21/2025 15:51:13 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] Epoch[46] Batch[0] avg_epoch_loss=3.001856\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=3.0018563270568848\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] Epoch[46] Batch[5] avg_epoch_loss=3.102874\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=3.102874000867208\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] Epoch[46] Batch [5]#011Speed: 2699.75 samples/sec#011loss=3.102874\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] Epoch[46] Batch[10] avg_epoch_loss=3.104727\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=3.1069514751434326\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] Epoch[46] Batch [10]#011Speed: 2685.28 samples/sec#011loss=3.106951\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747842673.969227, \"EndTime\": 1747842674.7600698, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.5833721160889, \"count\": 1, \"min\": 790.5833721160889, \"max\": 790.5833721160889}}}\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1664.4093605129067 records/second\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=46, train loss <loss>=3.1047273982654917\n",
      "[05/21/2025 15:51:14 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] Epoch[47] Batch[0] avg_epoch_loss=2.971931\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.971930742263794\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] Epoch[47] Batch[5] avg_epoch_loss=3.085092\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=3.085092067718506\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] Epoch[47] Batch [5]#011Speed: 2797.92 samples/sec#011loss=3.085092\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] Epoch[47] Batch[10] avg_epoch_loss=3.070444\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=3.0528666019439696\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] Epoch[47] Batch [10]#011Speed: 2660.99 samples/sec#011loss=3.052867\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747842674.7601297, \"EndTime\": 1747842675.5443306, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 783.9460372924805, \"count\": 1, \"min\": 783.9460372924805, \"max\": 783.9460372924805}}}\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1674.6722425000996 records/second\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=47, train loss <loss>=3.0704441287300805\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] Epoch[48] Batch[0] avg_epoch_loss=3.172502\n",
      "[05/21/2025 15:51:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=3.172502040863037\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] Epoch[48] Batch[5] avg_epoch_loss=3.077660\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=3.0776596864064536\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] Epoch[48] Batch [5]#011Speed: 2780.51 samples/sec#011loss=3.077660\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] Epoch[48] Batch[10] avg_epoch_loss=3.262788\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=3.484941530227661\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] Epoch[48] Batch [10]#011Speed: 2714.38 samples/sec#011loss=3.484942\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747842675.5443895, \"EndTime\": 1747842676.3205197, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 775.8479118347168, \"count\": 1, \"min\": 775.8479118347168, \"max\": 775.8479118347168}}}\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1723.0783843368367 records/second\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=48, train loss <loss>=3.262787797234275\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] Epoch[49] Batch[0] avg_epoch_loss=2.967322\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.9673216342926025\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] Epoch[49] Batch[5] avg_epoch_loss=3.175549\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=3.175549030303955\n",
      "[05/21/2025 15:51:16 INFO 140269512570688] Epoch[49] Batch [5]#011Speed: 2842.96 samples/sec#011loss=3.175549\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] Epoch[49] Batch[10] avg_epoch_loss=3.262441\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=3.366712188720703\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] Epoch[49] Batch [10]#011Speed: 2908.08 samples/sec#011loss=3.366712\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747842676.3205795, \"EndTime\": 1747842677.0834482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 762.6054286956787, \"count\": 1, \"min\": 762.6054286956787, \"max\": 762.6054286956787}}}\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1679.5876336613792 records/second\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=49, train loss <loss>=3.2624413750388404\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] Epoch[50] Batch[0] avg_epoch_loss=3.192076\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=3.192075729370117\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] Epoch[50] Batch[5] avg_epoch_loss=3.242452\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=3.242451866467794\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] Epoch[50] Batch [5]#011Speed: 2804.28 samples/sec#011loss=3.242452\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] Epoch[50] Batch[10] avg_epoch_loss=3.233082\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=3.221837568283081\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] Epoch[50] Batch [10]#011Speed: 2606.33 samples/sec#011loss=3.221838\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747842677.0835028, \"EndTime\": 1747842677.8654172, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 781.6557884216309, \"count\": 1, \"min\": 781.6557884216309, \"max\": 781.6557884216309}}}\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1728.1703593639827 records/second\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=50, train loss <loss>=3.233081730929288\n",
      "[05/21/2025 15:51:17 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] Epoch[51] Batch[0] avg_epoch_loss=3.194673\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=3.1946728229522705\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] Epoch[51] Batch[5] avg_epoch_loss=3.125069\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=3.1250692208607993\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] Epoch[51] Batch [5]#011Speed: 2717.60 samples/sec#011loss=3.125069\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] Epoch[51] Batch[10] avg_epoch_loss=3.079694\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=3.025243139266968\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] Epoch[51] Batch [10]#011Speed: 2346.48 samples/sec#011loss=3.025243\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747842677.8654842, \"EndTime\": 1747842678.6920912, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 826.2550830841064, \"count\": 1, \"min\": 826.2550830841064, \"max\": 826.2550830841064}}}\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1608.2880880800014 records/second\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=51, train loss <loss>=3.0796937292272393\n",
      "[05/21/2025 15:51:18 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] Epoch[52] Batch[0] avg_epoch_loss=3.085317\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=3.0853168964385986\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] Epoch[52] Batch[5] avg_epoch_loss=3.089310\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=3.08931040763855\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] Epoch[52] Batch [5]#011Speed: 2779.29 samples/sec#011loss=3.089310\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] Epoch[52] Batch[10] avg_epoch_loss=3.052751\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=3.0088786602020265\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] Epoch[52] Batch [10]#011Speed: 2434.05 samples/sec#011loss=3.008879\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747842678.6921494, \"EndTime\": 1747842679.4959908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.5891056060791, \"count\": 1, \"min\": 803.5891056060791, \"max\": 803.5891056060791}}}\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1689.7373997955417 records/second\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=52, train loss <loss>=3.05275052244013\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] Epoch[53] Batch[0] avg_epoch_loss=3.098912\n",
      "[05/21/2025 15:51:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=3.098912477493286\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] Epoch[53] Batch[5] avg_epoch_loss=3.102546\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=3.1025464137395224\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] Epoch[53] Batch [5]#011Speed: 2724.60 samples/sec#011loss=3.102546\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747842679.4960496, \"EndTime\": 1747842680.2331269, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 736.8154525756836, \"count\": 1, \"min\": 736.8154525756836, \"max\": 736.8154525756836}}}\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1719.3413305509048 records/second\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=53, train loss <loss>=3.0534005880355837\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] Epoch[54] Batch[0] avg_epoch_loss=3.162652\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=3.162651538848877\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] Epoch[54] Batch[5] avg_epoch_loss=3.052362\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=3.052362004915873\n",
      "[05/21/2025 15:51:20 INFO 140269512570688] Epoch[54] Batch [5]#011Speed: 2760.09 samples/sec#011loss=3.052362\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] Epoch[54] Batch[10] avg_epoch_loss=3.056130\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=3.0606525421142576\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] Epoch[54] Batch [10]#011Speed: 2635.87 samples/sec#011loss=3.060653\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747842680.2331908, \"EndTime\": 1747842681.0189428, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.4058742523193, \"count\": 1, \"min\": 785.4058742523193, \"max\": 785.4058742523193}}}\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1700.8495897659886 records/second\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=54, train loss <loss>=3.056130430915139\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] Epoch[55] Batch[0] avg_epoch_loss=3.006800\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=3.0067996978759766\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] Epoch[55] Batch[5] avg_epoch_loss=3.025257\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=3.0252568324406943\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] Epoch[55] Batch [5]#011Speed: 2950.26 samples/sec#011loss=3.025257\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] processed a total of 1270 examples\n",
      "#metrics {\"StartTime\": 1747842681.0189996, \"EndTime\": 1747842681.729104, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 709.8391056060791, \"count\": 1, \"min\": 709.8391056060791, \"max\": 709.8391056060791}}}\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1788.9161184155291 records/second\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=55, train loss <loss>=3.0569772958755492\n",
      "[05/21/2025 15:51:21 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] Epoch[56] Batch[0] avg_epoch_loss=2.893527\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.893526554107666\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] Epoch[56] Batch[5] avg_epoch_loss=2.982420\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.9824200868606567\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] Epoch[56] Batch [5]#011Speed: 2825.48 samples/sec#011loss=2.982420\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] Epoch[56] Batch[10] avg_epoch_loss=2.987307\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=2.993172216415405\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] Epoch[56] Batch [10]#011Speed: 2605.67 samples/sec#011loss=2.993172\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747842681.7291627, \"EndTime\": 1747842682.5116131, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.1557521820068, \"count\": 1, \"min\": 782.1557521820068, \"max\": 782.1557521820068}}}\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1697.6795618368958 records/second\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.9873074184764516\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_2ec3d9cc-70bc-453e-98a3-eb7f70fd74f0-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842682.5116735, \"EndTime\": 1747842682.520936, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.986949920654297, \"count\": 1, \"min\": 8.986949920654297, \"max\": 8.986949920654297}}}\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] Epoch[57] Batch[0] avg_epoch_loss=3.049573\n",
      "[05/21/2025 15:51:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=3.0495734214782715\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] Epoch[57] Batch[5] avg_epoch_loss=2.968707\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.9687071243921914\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] Epoch[57] Batch [5]#011Speed: 2601.32 samples/sec#011loss=2.968707\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747842682.5209906, \"EndTime\": 1747842683.2715552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 750.514030456543, \"count\": 1, \"min\": 750.514030456543, \"max\": 750.514030456543}}}\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1686.65581317786 records/second\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.9684094429016112\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_7a6d3479-c66d-4a4b-ad67-340d72306639-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842683.2716112, \"EndTime\": 1747842683.2817838, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.795427322387695, \"count\": 1, \"min\": 9.795427322387695, \"max\": 9.795427322387695}}}\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] Epoch[58] Batch[0] avg_epoch_loss=3.010531\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=3.010530710220337\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] Epoch[58] Batch[5] avg_epoch_loss=3.007752\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=3.007752458254496\n",
      "[05/21/2025 15:51:23 INFO 140269512570688] Epoch[58] Batch [5]#011Speed: 2784.03 samples/sec#011loss=3.007752\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] Epoch[58] Batch[10] avg_epoch_loss=3.003769\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.9989883422851564\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] Epoch[58] Batch [10]#011Speed: 2329.88 samples/sec#011loss=2.998988\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747842683.2818422, \"EndTime\": 1747842684.1088302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 826.9360065460205, \"count\": 1, \"min\": 826.9360065460205, \"max\": 826.9360065460205}}}\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1634.7871559045875 records/second\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=58, train loss <loss>=3.0037687691775234\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] Epoch[59] Batch[0] avg_epoch_loss=2.993656\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.9936556816101074\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] Epoch[59] Batch[5] avg_epoch_loss=2.971601\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.971601406733195\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] Epoch[59] Batch [5]#011Speed: 2813.96 samples/sec#011loss=2.971601\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] Epoch[59] Batch[10] avg_epoch_loss=2.984173\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=2.999259090423584\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] Epoch[59] Batch [10]#011Speed: 2470.60 samples/sec#011loss=2.999259\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747842684.108885, \"EndTime\": 1747842684.9075127, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.3195781707764, \"count\": 1, \"min\": 798.3195781707764, \"max\": 798.3195781707764}}}\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1715.8182763931663 records/second\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.9841730811379175\n",
      "[05/21/2025 15:51:24 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] Epoch[60] Batch[0] avg_epoch_loss=3.062751\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=3.062750816345215\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] Epoch[60] Batch[5] avg_epoch_loss=2.997421\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.997421065966288\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] Epoch[60] Batch [5]#011Speed: 2842.42 samples/sec#011loss=2.997421\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] Epoch[60] Batch[10] avg_epoch_loss=2.972562\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.942731809616089\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] Epoch[60] Batch [10]#011Speed: 2553.03 samples/sec#011loss=2.942732\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] processed a total of 1381 examples\n",
      "#metrics {\"StartTime\": 1747842684.9076166, \"EndTime\": 1747842685.6969202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.0069484710693, \"count\": 1, \"min\": 789.0069484710693, \"max\": 789.0069484710693}}}\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1750.1121173474398 records/second\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.972562313079834\n",
      "[05/21/2025 15:51:25 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] Epoch[61] Batch[0] avg_epoch_loss=2.959857\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.9598567485809326\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] Epoch[61] Batch[5] avg_epoch_loss=2.946810\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.9468102057774863\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] Epoch[61] Batch [5]#011Speed: 2525.94 samples/sec#011loss=2.946810\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] Epoch[61] Batch[10] avg_epoch_loss=2.955621\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=2.9661941528320312\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] Epoch[61] Batch [10]#011Speed: 2730.79 samples/sec#011loss=2.966194\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747842685.6969783, \"EndTime\": 1747842686.5035608, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 806.3294887542725, \"count\": 1, \"min\": 806.3294887542725, \"max\": 806.3294887542725}}}\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1613.312128365114 records/second\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.9556210908022793\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_0059711a-c79b-4b05-bb22-97eef7b7b6b9-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842686.5036178, \"EndTime\": 1747842686.513674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.777307510375977, \"count\": 1, \"min\": 9.777307510375977, \"max\": 9.777307510375977}}}\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] Epoch[62] Batch[0] avg_epoch_loss=3.000596\n",
      "[05/21/2025 15:51:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=3.000596284866333\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] Epoch[62] Batch[5] avg_epoch_loss=3.082250\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=3.082249919573466\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] Epoch[62] Batch [5]#011Speed: 2434.22 samples/sec#011loss=3.082250\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] Epoch[62] Batch[10] avg_epoch_loss=3.045668\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=3.0017704010009765\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] Epoch[62] Batch [10]#011Speed: 2573.42 samples/sec#011loss=3.001770\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747842686.5137296, \"EndTime\": 1747842687.334462, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 820.6794261932373, \"count\": 1, \"min\": 820.6794261932373, \"max\": 820.6794261932373}}}\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1656.9810704714344 records/second\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=62, train loss <loss>=3.0456683202223345\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] Epoch[63] Batch[0] avg_epoch_loss=3.017917\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=3.017916679382324\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] Epoch[63] Batch[5] avg_epoch_loss=2.972343\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.9723430077234902\n",
      "[05/21/2025 15:51:27 INFO 140269512570688] Epoch[63] Batch [5]#011Speed: 2829.28 samples/sec#011loss=2.972343\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] Epoch[63] Batch[10] avg_epoch_loss=3.024436\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=3.0869471549987795\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] Epoch[63] Batch [10]#011Speed: 2655.59 samples/sec#011loss=3.086947\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747842687.3345225, \"EndTime\": 1747842688.1171305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.3424339294434, \"count\": 1, \"min\": 782.3424339294434, \"max\": 782.3424339294434}}}\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1652.541620121435 records/second\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=63, train loss <loss>=3.0244358019395308\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] Epoch[64] Batch[0] avg_epoch_loss=3.017259\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=3.017258644104004\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] Epoch[64] Batch[5] avg_epoch_loss=3.022452\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=3.022451559702555\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] Epoch[64] Batch [5]#011Speed: 2588.80 samples/sec#011loss=3.022452\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] Epoch[64] Batch[10] avg_epoch_loss=3.049364\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=3.0816596508026124\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] Epoch[64] Batch [10]#011Speed: 2540.78 samples/sec#011loss=3.081660\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747842688.1171896, \"EndTime\": 1747842688.9293332, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.7945194244385, \"count\": 1, \"min\": 811.7945194244385, \"max\": 811.7945194244385}}}\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1623.3800013978218 records/second\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=64, train loss <loss>=3.0493643283843994\n",
      "[05/21/2025 15:51:28 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] Epoch[65] Batch[0] avg_epoch_loss=3.001725\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=3.001725435256958\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] Epoch[65] Batch[5] avg_epoch_loss=3.005704\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=3.0057039658228555\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] Epoch[65] Batch [5]#011Speed: 2760.45 samples/sec#011loss=3.005704\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] Epoch[65] Batch[10] avg_epoch_loss=3.018244\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=3.033291482925415\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] Epoch[65] Batch [10]#011Speed: 2721.53 samples/sec#011loss=3.033291\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747842688.9293942, \"EndTime\": 1747842689.7130227, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 783.3552360534668, \"count\": 1, \"min\": 783.3552360534668, \"max\": 783.3552360534668}}}\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1681.0453981904996 records/second\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=65, train loss <loss>=3.018243746324019\n",
      "[05/21/2025 15:51:29 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] Epoch[66] Batch[0] avg_epoch_loss=2.955697\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.9556968212127686\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] Epoch[66] Batch[5] avg_epoch_loss=3.005148\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=3.005147933959961\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] Epoch[66] Batch [5]#011Speed: 2760.80 samples/sec#011loss=3.005148\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] Epoch[66] Batch[10] avg_epoch_loss=3.044473\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=3.091664028167725\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] Epoch[66] Batch [10]#011Speed: 2608.41 samples/sec#011loss=3.091664\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747842689.7130802, \"EndTime\": 1747842690.5052457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.9137477874756, \"count\": 1, \"min\": 791.9137477874756, \"max\": 791.9137477874756}}}\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1657.8211802090548 records/second\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=66, train loss <loss>=3.0444734313271264\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] Epoch[67] Batch[0] avg_epoch_loss=3.069862\n",
      "[05/21/2025 15:51:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=3.0698623657226562\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] Epoch[67] Batch[5] avg_epoch_loss=3.005004\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=3.0050042072931924\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] Epoch[67] Batch [5]#011Speed: 2717.69 samples/sec#011loss=3.005004\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] Epoch[67] Batch[10] avg_epoch_loss=2.972965\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.9345170974731447\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] Epoch[67] Batch [10]#011Speed: 2666.87 samples/sec#011loss=2.934517\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747842690.5053053, \"EndTime\": 1747842691.2903075, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.7363948822021, \"count\": 1, \"min\": 784.7363948822021, \"max\": 784.7363948822021}}}\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1694.6497494065532 records/second\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.9729646119204434\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] Epoch[68] Batch[0] avg_epoch_loss=2.984496\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.9844963550567627\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] Epoch[68] Batch[5] avg_epoch_loss=3.013637\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=3.0136368672053018\n",
      "[05/21/2025 15:51:31 INFO 140269512570688] Epoch[68] Batch [5]#011Speed: 2861.90 samples/sec#011loss=3.013637\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] Epoch[68] Batch[10] avg_epoch_loss=2.883475\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.7272799491882322\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] Epoch[68] Batch [10]#011Speed: 2702.35 samples/sec#011loss=2.727280\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747842691.290365, \"EndTime\": 1747842692.0679772, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 777.3573398590088, \"count\": 1, \"min\": 777.3573398590088, \"max\": 777.3573398590088}}}\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1673.4336994768823 records/second\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.8834746317429976\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_e69dc1e9-afb1-4ca4-b6be-e1ef3cd04eea-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842692.068034, \"EndTime\": 1747842692.0774238, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.110689163208008, \"count\": 1, \"min\": 9.110689163208008, \"max\": 9.110689163208008}}}\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] Epoch[69] Batch[0] avg_epoch_loss=3.022088\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=3.022088050842285\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] Epoch[69] Batch[5] avg_epoch_loss=2.971786\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.9717859029769897\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] Epoch[69] Batch [5]#011Speed: 2838.88 samples/sec#011loss=2.971786\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] Epoch[69] Batch[10] avg_epoch_loss=3.010377\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=3.056687259674072\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] Epoch[69] Batch [10]#011Speed: 2769.13 samples/sec#011loss=3.056687\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747842692.0774896, \"EndTime\": 1747842692.8493557, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 771.8117237091064, \"count\": 1, \"min\": 771.8117237091064, \"max\": 771.8117237091064}}}\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1668.6234565136615 records/second\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=69, train loss <loss>=3.010377428748391\n",
      "[05/21/2025 15:51:32 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] Epoch[70] Batch[0] avg_epoch_loss=3.010774\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=3.0107736587524414\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] Epoch[70] Batch[5] avg_epoch_loss=2.958371\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.9583710034688315\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] Epoch[70] Batch [5]#011Speed: 2762.08 samples/sec#011loss=2.958371\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] Epoch[70] Batch[10] avg_epoch_loss=3.002164\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=3.054716157913208\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] Epoch[70] Batch [10]#011Speed: 2598.03 samples/sec#011loss=3.054716\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747842692.8494086, \"EndTime\": 1747842693.640112, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.3878688812256, \"count\": 1, \"min\": 790.3878688812256, \"max\": 790.3878688812256}}}\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1698.8997836319077 records/second\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=70, train loss <loss>=3.0021642554890025\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] Epoch[71] Batch[0] avg_epoch_loss=2.989815\n",
      "[05/21/2025 15:51:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.9898154735565186\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] Epoch[71] Batch[5] avg_epoch_loss=2.980789\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.980788747469584\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] Epoch[71] Batch [5]#011Speed: 2895.33 samples/sec#011loss=2.980789\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] Epoch[71] Batch[10] avg_epoch_loss=2.902890\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.8094107151031493\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] Epoch[71] Batch [10]#011Speed: 2734.33 samples/sec#011loss=2.809411\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747842693.6402059, \"EndTime\": 1747842694.4060423, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 765.5668258666992, \"count\": 1, \"min\": 765.5668258666992, \"max\": 765.5668258666992}}}\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1724.0247246502272 records/second\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.9028896418484775\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] Epoch[72] Batch[0] avg_epoch_loss=2.811764\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.8117635250091553\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] Epoch[72] Batch[5] avg_epoch_loss=2.917258\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.917257865269979\n",
      "[05/21/2025 15:51:34 INFO 140269512570688] Epoch[72] Batch [5]#011Speed: 2859.64 samples/sec#011loss=2.917258\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] Epoch[72] Batch[10] avg_epoch_loss=2.924372\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.9329079151153565\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] Epoch[72] Batch [10]#011Speed: 2687.84 samples/sec#011loss=2.932908\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842694.4060981, \"EndTime\": 1747842695.1838338, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 777.4648666381836, \"count\": 1, \"min\": 777.4648666381836, \"max\": 777.4648666381836}}}\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1669.3532274419726 records/second\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.924371524290605\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] Epoch[73] Batch[0] avg_epoch_loss=2.862340\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.8623404502868652\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] Epoch[73] Batch[5] avg_epoch_loss=2.899510\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.89950954914093\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] Epoch[73] Batch [5]#011Speed: 2548.35 samples/sec#011loss=2.899510\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] Epoch[73] Batch[10] avg_epoch_loss=2.900473\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=2.9016290664672852\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] Epoch[73] Batch [10]#011Speed: 2669.41 samples/sec#011loss=2.901629\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747842695.183889, \"EndTime\": 1747842695.9909334, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 806.7924976348877, \"count\": 1, \"min\": 806.7924976348877, \"max\": 806.7924976348877}}}\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1609.8967372146285 records/second\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.900472966107455\n",
      "[05/21/2025 15:51:35 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] Epoch[74] Batch[0] avg_epoch_loss=3.030324\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=3.0303242206573486\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] Epoch[74] Batch[5] avg_epoch_loss=2.922398\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.9223981300989785\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] Epoch[74] Batch [5]#011Speed: 2546.60 samples/sec#011loss=2.922398\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] Epoch[74] Batch[10] avg_epoch_loss=2.968464\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=3.023743438720703\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] Epoch[74] Batch [10]#011Speed: 2648.56 samples/sec#011loss=3.023743\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747842695.9909945, \"EndTime\": 1747842696.801526, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.1465702056885, \"count\": 1, \"min\": 810.1465702056885, \"max\": 810.1465702056885}}}\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1639.059060186628 records/second\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.9684641794724898\n",
      "[05/21/2025 15:51:36 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] Epoch[75] Batch[0] avg_epoch_loss=2.832469\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.8324687480926514\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] Epoch[75] Batch[5] avg_epoch_loss=2.902211\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.902210831642151\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] Epoch[75] Batch [5]#011Speed: 2835.70 samples/sec#011loss=2.902211\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] processed a total of 1255 examples\n",
      "#metrics {\"StartTime\": 1747842696.8015726, \"EndTime\": 1747842697.5333297, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 731.5511703491211, \"count\": 1, \"min\": 731.5511703491211, \"max\": 731.5511703491211}}}\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1715.323681975754 records/second\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.8814151763916014\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_2ed694e8-8eaf-45ed-a371-cd3f298872ee-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842697.5333917, \"EndTime\": 1747842697.542751, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.951663970947266, \"count\": 1, \"min\": 8.951663970947266, \"max\": 8.951663970947266}}}\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] Epoch[76] Batch[0] avg_epoch_loss=2.838230\n",
      "[05/21/2025 15:51:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.8382296562194824\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] Epoch[76] Batch[5] avg_epoch_loss=2.912364\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.9123642444610596\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] Epoch[76] Batch [5]#011Speed: 2645.16 samples/sec#011loss=2.912364\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] Epoch[76] Batch[10] avg_epoch_loss=2.881680\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.8448588848114014\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] Epoch[76] Batch [10]#011Speed: 2520.25 samples/sec#011loss=2.844859\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] processed a total of 1377 examples\n",
      "#metrics {\"StartTime\": 1747842697.542818, \"EndTime\": 1747842698.3441505, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.2716770172119, \"count\": 1, \"min\": 801.2716770172119, \"max\": 801.2716770172119}}}\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1718.3132247087183 records/second\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.881679990074851\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] Epoch[77] Batch[0] avg_epoch_loss=2.944905\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.9449045658111572\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] Epoch[77] Batch[5] avg_epoch_loss=2.901803\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.9018025000890098\n",
      "[05/21/2025 15:51:38 INFO 140269512570688] Epoch[77] Batch [5]#011Speed: 2736.90 samples/sec#011loss=2.901803\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] Epoch[77] Batch[10] avg_epoch_loss=2.911555\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.9232583045959473\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] Epoch[77] Batch [10]#011Speed: 2514.32 samples/sec#011loss=2.923258\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747842698.3442123, \"EndTime\": 1747842699.1515996, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.0251941680908, \"count\": 1, \"min\": 807.0251941680908, \"max\": 807.0251941680908}}}\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1649.0837917634703 records/second\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.911555138501254\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] Epoch[78] Batch[0] avg_epoch_loss=2.983114\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.983114242553711\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] Epoch[78] Batch[5] avg_epoch_loss=2.930037\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.9300366640090942\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] Epoch[78] Batch [5]#011Speed: 2611.63 samples/sec#011loss=2.930037\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] Epoch[78] Batch[10] avg_epoch_loss=2.900873\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.8658758640289306\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] Epoch[78] Batch [10]#011Speed: 2350.31 samples/sec#011loss=2.865876\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] processed a total of 1376 examples\n",
      "#metrics {\"StartTime\": 1747842699.1516595, \"EndTime\": 1747842699.9909334, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 839.026689529419, \"count\": 1, \"min\": 839.026689529419, \"max\": 839.026689529419}}}\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1639.820765857046 records/second\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.900872664018111\n",
      "[05/21/2025 15:51:39 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] Epoch[79] Batch[0] avg_epoch_loss=3.071285\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=3.071284532546997\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] Epoch[79] Batch[5] avg_epoch_loss=2.953027\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.9530266920725503\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] Epoch[79] Batch [5]#011Speed: 2593.63 samples/sec#011loss=2.953027\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] Epoch[79] Batch[10] avg_epoch_loss=2.944739\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.9347928047180174\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] Epoch[79] Batch [10]#011Speed: 2567.84 samples/sec#011loss=2.934793\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747842699.9909937, \"EndTime\": 1747842700.8061137, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.8283958435059, \"count\": 1, \"min\": 814.8283958435059, \"max\": 814.8283958435059}}}\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1580.5016083642547 records/second\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.9447385614568535\n",
      "[05/21/2025 15:51:40 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] Epoch[80] Batch[0] avg_epoch_loss=2.976328\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.976328134536743\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] Epoch[80] Batch[5] avg_epoch_loss=3.012995\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=3.0129950046539307\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] Epoch[80] Batch [5]#011Speed: 2654.76 samples/sec#011loss=3.012995\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] Epoch[80] Batch[10] avg_epoch_loss=2.957181\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.890204429626465\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] Epoch[80] Batch [10]#011Speed: 2501.62 samples/sec#011loss=2.890204\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747842700.8061829, \"EndTime\": 1747842701.6484232, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 841.7353630065918, \"count\": 1, \"min\": 841.7353630065918, \"max\": 841.7353630065918}}}\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1562.0474155814768 records/second\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.9571811069141734\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] Epoch[81] Batch[0] avg_epoch_loss=2.992698\n",
      "[05/21/2025 15:51:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.9926977157592773\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] Epoch[81] Batch[5] avg_epoch_loss=2.947495\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.9474953015645347\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] Epoch[81] Batch [5]#011Speed: 2756.59 samples/sec#011loss=2.947495\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] Epoch[81] Batch[10] avg_epoch_loss=3.024050\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=3.1159164905548096\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] Epoch[81] Batch [10]#011Speed: 2819.24 samples/sec#011loss=3.115916\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747842701.6484995, \"EndTime\": 1747842702.4271646, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 778.3465385437012, \"count\": 1, \"min\": 778.3465385437012, \"max\": 778.3465385437012}}}\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1679.0000551299659 records/second\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=81, train loss <loss>=3.024050387469205\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] Epoch[82] Batch[0] avg_epoch_loss=2.889359\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.8893587589263916\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] Epoch[82] Batch[5] avg_epoch_loss=2.895475\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.8954749504725137\n",
      "[05/21/2025 15:51:42 INFO 140269512570688] Epoch[82] Batch [5]#011Speed: 2941.81 samples/sec#011loss=2.895475\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] processed a total of 1249 examples\n",
      "#metrics {\"StartTime\": 1747842702.427227, \"EndTime\": 1747842703.165743, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 738.2247447967529, \"count\": 1, \"min\": 738.2247447967529, \"max\": 738.2247447967529}}}\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1691.6847032366754 records/second\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.899806785583496\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] Epoch[83] Batch[0] avg_epoch_loss=2.881249\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.881249189376831\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] Epoch[83] Batch[5] avg_epoch_loss=2.875129\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.875128666559855\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] Epoch[83] Batch [5]#011Speed: 2823.68 samples/sec#011loss=2.875129\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] Epoch[83] Batch[10] avg_epoch_loss=2.928157\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.991789960861206\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] Epoch[83] Batch [10]#011Speed: 2942.74 samples/sec#011loss=2.991790\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747842703.1658063, \"EndTime\": 1747842703.9528515, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.7157459259033, \"count\": 1, \"min\": 786.7157459259033, \"max\": 786.7157459259033}}}\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1634.4649636403415 records/second\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.928156527605924\n",
      "[05/21/2025 15:51:43 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] Epoch[84] Batch[0] avg_epoch_loss=2.831458\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.8314576148986816\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] Epoch[84] Batch[5] avg_epoch_loss=2.856130\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.856129844983419\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] Epoch[84] Batch [5]#011Speed: 2831.84 samples/sec#011loss=2.856130\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] Epoch[84] Batch[10] avg_epoch_loss=2.874672\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.8969225883483887\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] Epoch[84] Batch [10]#011Speed: 2781.81 samples/sec#011loss=2.896923\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747842703.952909, \"EndTime\": 1747842704.7228942, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 769.705057144165, \"count\": 1, \"min\": 769.705057144165, \"max\": 769.705057144165}}}\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1719.958267014421 records/second\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.8746720010584053\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:44 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_6826a4e8-2a73-4a0a-8db6-93b7580465c5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842704.7229471, \"EndTime\": 1747842704.7318985, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.688926696777344, \"count\": 1, \"min\": 8.688926696777344, \"max\": 8.688926696777344}}}\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] Epoch[85] Batch[0] avg_epoch_loss=2.773127\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.7731266021728516\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] Epoch[85] Batch[5] avg_epoch_loss=2.852964\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.852964440981547\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] Epoch[85] Batch [5]#011Speed: 2734.79 samples/sec#011loss=2.852964\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] Epoch[85] Batch[10] avg_epoch_loss=2.853128\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=2.85332350730896\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] Epoch[85] Batch [10]#011Speed: 2774.97 samples/sec#011loss=2.853324\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747842704.7319486, \"EndTime\": 1747842705.5087836, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 776.7889499664307, \"count\": 1, \"min\": 776.7889499664307, \"max\": 776.7889499664307}}}\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1708.1286061690794 records/second\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.8531276529485528\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_4b6876dd-b853-41a4-b571-498feb0b0b86-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842705.50884, \"EndTime\": 1747842705.5182974, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.726119995117188, \"count\": 1, \"min\": 8.726119995117188, \"max\": 8.726119995117188}}}\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] Epoch[86] Batch[0] avg_epoch_loss=2.941299\n",
      "[05/21/2025 15:51:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.9412989616394043\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] Epoch[86] Batch[5] avg_epoch_loss=2.876974\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.876974105834961\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] Epoch[86] Batch [5]#011Speed: 2548.61 samples/sec#011loss=2.876974\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] Epoch[86] Batch[10] avg_epoch_loss=2.848504\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.814339113235474\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] Epoch[86] Batch [10]#011Speed: 2582.67 samples/sec#011loss=2.814339\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747842705.5183487, \"EndTime\": 1747842706.3267603, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 808.3646297454834, \"count\": 1, \"min\": 808.3646297454834, \"max\": 808.3646297454834}}}\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1651.3431557564513 records/second\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.848503654653376\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_3c56c60d-4369-4108-9695-0ff988249312-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842706.326804, \"EndTime\": 1747842706.336666, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.609699249267578, \"count\": 1, \"min\": 9.609699249267578, \"max\": 9.609699249267578}}}\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] Epoch[87] Batch[0] avg_epoch_loss=2.872177\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.8721766471862793\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] Epoch[87] Batch[5] avg_epoch_loss=2.852424\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.852423588434855\n",
      "[05/21/2025 15:51:46 INFO 140269512570688] Epoch[87] Batch [5]#011Speed: 2795.79 samples/sec#011loss=2.852424\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] Epoch[87] Batch[10] avg_epoch_loss=3.005477\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=3.189142179489136\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] Epoch[87] Batch [10]#011Speed: 2676.15 samples/sec#011loss=3.189142\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747842706.3367205, \"EndTime\": 1747842707.118929, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.1555137634277, \"count\": 1, \"min\": 782.1555137634277, \"max\": 782.1555137634277}}}\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1704.07714086034 records/second\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=87, train loss <loss>=3.0054774934595283\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] Epoch[88] Batch[0] avg_epoch_loss=2.833385\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.8333852291107178\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] Epoch[88] Batch[5] avg_epoch_loss=2.840414\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.84041420618693\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] Epoch[88] Batch [5]#011Speed: 2865.07 samples/sec#011loss=2.840414\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] Epoch[88] Batch[10] avg_epoch_loss=2.875310\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=2.9171839237213133\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] Epoch[88] Batch [10]#011Speed: 2688.64 samples/sec#011loss=2.917184\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747842707.1189866, \"EndTime\": 1747842707.8993979, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.1625728607178, \"count\": 1, \"min\": 780.1625728607178, \"max\": 780.1625728607178}}}\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1734.06155468951 records/second\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.875309532338923\n",
      "[05/21/2025 15:51:47 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] Epoch[89] Batch[0] avg_epoch_loss=2.748020\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.7480199337005615\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] Epoch[89] Batch[5] avg_epoch_loss=2.837349\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.8373494148254395\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] Epoch[89] Batch [5]#011Speed: 2818.23 samples/sec#011loss=2.837349\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] Epoch[89] Batch[10] avg_epoch_loss=2.877872\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=2.9264997005462647\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] Epoch[89] Batch [10]#011Speed: 2561.62 samples/sec#011loss=2.926500\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] processed a total of 1376 examples\n",
      "#metrics {\"StartTime\": 1747842707.8994558, \"EndTime\": 1747842708.6870005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 787.2943878173828, \"count\": 1, \"min\": 787.2943878173828, \"max\": 787.2943878173828}}}\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1747.5705733767024 records/second\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.877872271971269\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] Epoch[90] Batch[0] avg_epoch_loss=2.805255\n",
      "[05/21/2025 15:51:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.8052549362182617\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] Epoch[90] Batch[5] avg_epoch_loss=2.839660\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.8396596113840737\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] Epoch[90] Batch [5]#011Speed: 2804.51 samples/sec#011loss=2.839660\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] Epoch[90] Batch[10] avg_epoch_loss=2.871615\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.9099624156951904\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] Epoch[90] Batch [10]#011Speed: 2583.79 samples/sec#011loss=2.909962\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] processed a total of 1377 examples\n",
      "#metrics {\"StartTime\": 1747842708.6870573, \"EndTime\": 1747842709.4703054, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.9830646514893, \"count\": 1, \"min\": 782.9830646514893, \"max\": 782.9830646514893}}}\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1758.45953938585 records/second\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.8716154315254907\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] Epoch[91] Batch[0] avg_epoch_loss=2.842048\n",
      "[05/21/2025 15:51:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.842048168182373\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] Epoch[91] Batch[5] avg_epoch_loss=2.828656\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.8286559184392295\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] Epoch[91] Batch [5]#011Speed: 2894.64 samples/sec#011loss=2.828656\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747842709.4703653, \"EndTime\": 1747842710.1862073, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 715.5506610870361, \"count\": 1, \"min\": 715.5506610870361, \"max\": 715.5506610870361}}}\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1787.2065138158728 records/second\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.819092631340027\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_90412bf3-38aa-4af1-aefe-7e76a2b5f64e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842710.1862676, \"EndTime\": 1747842710.1954696, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.846044540405273, \"count\": 1, \"min\": 8.846044540405273, \"max\": 8.846044540405273}}}\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] Epoch[92] Batch[0] avg_epoch_loss=2.863125\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.8631248474121094\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] Epoch[92] Batch[5] avg_epoch_loss=2.808713\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.8087129990259805\n",
      "[05/21/2025 15:51:50 INFO 140269512570688] Epoch[92] Batch [5]#011Speed: 2696.22 samples/sec#011loss=2.808713\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] Epoch[92] Batch[10] avg_epoch_loss=2.835496\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.8676366806030273\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] Epoch[92] Batch [10]#011Speed: 2476.42 samples/sec#011loss=2.867637\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] processed a total of 1379 examples\n",
      "#metrics {\"StartTime\": 1747842710.1955209, \"EndTime\": 1747842711.0143604, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 818.7932968139648, \"count\": 1, \"min\": 818.7932968139648, \"max\": 818.7932968139648}}}\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1684.0214767179787 records/second\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.835496490651911\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] Epoch[93] Batch[0] avg_epoch_loss=2.827524\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.827524423599243\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] Epoch[93] Batch[5] avg_epoch_loss=2.821049\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.821049372355143\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] Epoch[93] Batch [5]#011Speed: 2693.51 samples/sec#011loss=2.821049\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] Epoch[93] Batch[10] avg_epoch_loss=2.762263\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.6917186737060548\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] Epoch[93] Batch [10]#011Speed: 2708.21 samples/sec#011loss=2.691719\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747842711.014414, \"EndTime\": 1747842711.8035731, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.8591289520264, \"count\": 1, \"min\": 788.8591289520264, \"max\": 788.8591289520264}}}\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1673.1144512066319 records/second\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.762262691151012\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:51:51 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_130d1401-b770-4228-91a3-357259c07743-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842711.803633, \"EndTime\": 1747842711.812792, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.854389190673828, \"count\": 1, \"min\": 8.854389190673828, \"max\": 8.854389190673828}}}\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] Epoch[94] Batch[0] avg_epoch_loss=2.947117\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.9471166133880615\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] Epoch[94] Batch[5] avg_epoch_loss=2.874141\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.8741411765416465\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] Epoch[94] Batch [5]#011Speed: 2734.47 samples/sec#011loss=2.874141\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] Epoch[94] Batch[10] avg_epoch_loss=2.934836\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=3.007670831680298\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] Epoch[94] Batch [10]#011Speed: 2673.54 samples/sec#011loss=3.007671\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747842711.8128455, \"EndTime\": 1747842712.5959134, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 783.0150127410889, \"count\": 1, \"min\": 783.0150127410889, \"max\": 783.0150127410889}}}\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1730.2965653657661 records/second\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.9348364743319424\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] Epoch[95] Batch[0] avg_epoch_loss=2.897782\n",
      "[05/21/2025 15:51:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.8977816104888916\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] Epoch[95] Batch[5] avg_epoch_loss=2.870479\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.8704788287480674\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] Epoch[95] Batch [5]#011Speed: 2736.05 samples/sec#011loss=2.870479\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] Epoch[95] Batch[10] avg_epoch_loss=2.845866\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.8163304328918457\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] Epoch[95] Batch [10]#011Speed: 2523.77 samples/sec#011loss=2.816330\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747842712.5959704, \"EndTime\": 1747842713.4198759, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 823.5929012298584, \"count\": 1, \"min\": 823.5929012298584, \"max\": 823.5929012298584}}}\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1664.4709061574292 records/second\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.845865921540694\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] Epoch[96] Batch[0] avg_epoch_loss=2.878634\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.878633975982666\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] Epoch[96] Batch[5] avg_epoch_loss=2.822308\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.822307507197062\n",
      "[05/21/2025 15:51:53 INFO 140269512570688] Epoch[96] Batch [5]#011Speed: 2861.21 samples/sec#011loss=2.822308\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] processed a total of 1251 examples\n",
      "#metrics {\"StartTime\": 1747842713.4199376, \"EndTime\": 1747842714.1392627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 719.0663814544678, \"count\": 1, \"min\": 719.0663814544678, \"max\": 719.0663814544678}}}\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1739.530411016671 records/second\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.8384983062744142\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] Epoch[97] Batch[0] avg_epoch_loss=2.757285\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.757284641265869\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] Epoch[97] Batch[5] avg_epoch_loss=2.788630\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.7886303663253784\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] Epoch[97] Batch [5]#011Speed: 2793.44 samples/sec#011loss=2.788630\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] Epoch[97] Batch[10] avg_epoch_loss=2.778123\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.7655141353607178\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] Epoch[97] Batch [10]#011Speed: 2801.27 samples/sec#011loss=2.765514\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747842714.1393259, \"EndTime\": 1747842714.912464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 772.8428840637207, \"count\": 1, \"min\": 772.8428840637207, \"max\": 772.8428840637207}}}\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1661.166343768382 records/second\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.778122988614169\n",
      "[05/21/2025 15:51:54 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] Epoch[98] Batch[0] avg_epoch_loss=3.124231\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=3.1242313385009766\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] Epoch[98] Batch[5] avg_epoch_loss=3.035854\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=3.03585422039032\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] Epoch[98] Batch [5]#011Speed: 2743.60 samples/sec#011loss=3.035854\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] Epoch[98] Batch[10] avg_epoch_loss=3.024172\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=3.0101528644561766\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] Epoch[98] Batch [10]#011Speed: 2563.36 samples/sec#011loss=3.010153\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747842714.9125443, \"EndTime\": 1747842715.70934, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.5066432952881, \"count\": 1, \"min\": 796.5066432952881, \"max\": 796.5066432952881}}}\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1668.3132672121133 records/second\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=98, train loss <loss>=3.0241717858748003\n",
      "[05/21/2025 15:51:55 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] Epoch[99] Batch[0] avg_epoch_loss=2.999549\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.9995486736297607\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] Epoch[99] Batch[5] avg_epoch_loss=2.971530\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.9715301593144736\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] Epoch[99] Batch [5]#011Speed: 2608.79 samples/sec#011loss=2.971530\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] Epoch[99] Batch[10] avg_epoch_loss=2.945124\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=2.913436937332153\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] Epoch[99] Batch [10]#011Speed: 2523.07 samples/sec#011loss=2.913437\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] processed a total of 1362 examples\n",
      "#metrics {\"StartTime\": 1747842715.7094147, \"EndTime\": 1747842716.51968, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.9093437194824, \"count\": 1, \"min\": 809.9093437194824, \"max\": 809.9093437194824}}}\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1681.481600265616 records/second\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.9451241493225098\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] Epoch[100] Batch[0] avg_epoch_loss=2.952206\n",
      "[05/21/2025 15:51:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.9522061347961426\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] Epoch[100] Batch[5] avg_epoch_loss=2.888101\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.88810141881307\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] Epoch[100] Batch [5]#011Speed: 2723.05 samples/sec#011loss=2.888101\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] Epoch[100] Batch[10] avg_epoch_loss=2.891820\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.896282768249512\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] Epoch[100] Batch [10]#011Speed: 2278.90 samples/sec#011loss=2.896283\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747842716.5197384, \"EndTime\": 1747842717.343483, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 823.3730792999268, \"count\": 1, \"min\": 823.3730792999268, \"max\": 823.3730792999268}}}\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1658.8567795344075 records/second\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.8918202140114526\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] Epoch[101] Batch[0] avg_epoch_loss=2.894325\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.894324541091919\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] Epoch[101] Batch[5] avg_epoch_loss=2.847789\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.8477891286214194\n",
      "[05/21/2025 15:51:57 INFO 140269512570688] Epoch[101] Batch [5]#011Speed: 2865.83 samples/sec#011loss=2.847789\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] Epoch[101] Batch[10] avg_epoch_loss=2.863591\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=2.8825523853302\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] Epoch[101] Batch [10]#011Speed: 2619.83 samples/sec#011loss=2.882552\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747842717.343539, \"EndTime\": 1747842718.123126, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 779.3335914611816, \"count\": 1, \"min\": 779.3335914611816, \"max\": 779.3335914611816}}}\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1728.193048168746 records/second\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.8635906089435923\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] Epoch[102] Batch[0] avg_epoch_loss=2.864674\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.8646738529205322\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] Epoch[102] Batch[5] avg_epoch_loss=2.817527\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.8175267378489175\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] Epoch[102] Batch [5]#011Speed: 2639.64 samples/sec#011loss=2.817527\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] Epoch[102] Batch[10] avg_epoch_loss=2.809082\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=2.79894814491272\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] Epoch[102] Batch [10]#011Speed: 2358.67 samples/sec#011loss=2.798948\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747842718.1231873, \"EndTime\": 1747842718.9469287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 823.3940601348877, \"count\": 1, \"min\": 823.3940601348877, \"max\": 823.3940601348877}}}\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1638.142427452596 records/second\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.8090819228779185\n",
      "[05/21/2025 15:51:58 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] Epoch[103] Batch[0] avg_epoch_loss=2.843768\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.8437676429748535\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] Epoch[103] Batch[5] avg_epoch_loss=2.812571\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.812571366628011\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] Epoch[103] Batch [5]#011Speed: 2986.63 samples/sec#011loss=2.812571\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] Epoch[103] Batch[10] avg_epoch_loss=2.815213\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.8183820247650146\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] Epoch[103] Batch [10]#011Speed: 2765.82 samples/sec#011loss=2.818382\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747842718.9469965, \"EndTime\": 1747842719.7191632, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 771.8524932861328, \"count\": 1, \"min\": 771.8524932861328, \"max\": 771.8524932861328}}}\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1709.9785313809068 records/second\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.8152125748721035\n",
      "[05/21/2025 15:51:59 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] Epoch[104] Batch[0] avg_epoch_loss=2.789568\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.789567708969116\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] Epoch[104] Batch[5] avg_epoch_loss=2.712041\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.712040583292643\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] Epoch[104] Batch [5]#011Speed: 2830.76 samples/sec#011loss=2.712041\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] Epoch[104] Batch[10] avg_epoch_loss=2.767923\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=2.8349821090698244\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] Epoch[104] Batch [10]#011Speed: 2695.01 samples/sec#011loss=2.834982\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842719.7192204, \"EndTime\": 1747842720.4963224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 776.8499851226807, \"count\": 1, \"min\": 776.8499851226807, \"max\": 776.8499851226807}}}\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1670.6667014453296 records/second\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.7679230950095435\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] Epoch[105] Batch[0] avg_epoch_loss=2.853195\n",
      "[05/21/2025 15:52:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.8531947135925293\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] Epoch[105] Batch[5] avg_epoch_loss=2.841841\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.841840982437134\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] Epoch[105] Batch [5]#011Speed: 2610.41 samples/sec#011loss=2.841841\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] Epoch[105] Batch[10] avg_epoch_loss=2.886877\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.9409206390380858\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] Epoch[105] Batch [10]#011Speed: 2623.68 samples/sec#011loss=2.940921\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747842720.4963791, \"EndTime\": 1747842721.2999806, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.28369140625, \"count\": 1, \"min\": 803.28369140625, \"max\": 803.28369140625}}}\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1644.316458491117 records/second\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.886877189983021\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] Epoch[106] Batch[0] avg_epoch_loss=2.798035\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.7980353832244873\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] Epoch[106] Batch[5] avg_epoch_loss=2.836372\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.836371660232544\n",
      "[05/21/2025 15:52:01 INFO 140269512570688] Epoch[106] Batch [5]#011Speed: 2691.22 samples/sec#011loss=2.836372\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] Epoch[106] Batch[10] avg_epoch_loss=2.898181\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=2.9723525524139403\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] Epoch[106] Batch [10]#011Speed: 2450.03 samples/sec#011loss=2.972353\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747842721.3000405, \"EndTime\": 1747842722.111407, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.1104965209961, \"count\": 1, \"min\": 811.1104965209961, \"max\": 811.1104965209961}}}\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1642.0086514739776 records/second\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.8981811566786333\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] Epoch[107] Batch[0] avg_epoch_loss=2.788092\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.7880918979644775\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] Epoch[107] Batch[5] avg_epoch_loss=2.814376\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.814375718434652\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] Epoch[107] Batch [5]#011Speed: 2834.09 samples/sec#011loss=2.814376\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] Epoch[107] Batch[10] avg_epoch_loss=2.881375\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.961773920059204\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] Epoch[107] Batch [10]#011Speed: 2734.23 samples/sec#011loss=2.961774\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747842722.1114683, \"EndTime\": 1747842722.9097984, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.0260848999023, \"count\": 1, \"min\": 798.0260848999023, \"max\": 798.0260848999023}}}\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1661.4171586709253 records/second\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.8813749009912666\n",
      "[05/21/2025 15:52:02 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] Epoch[108] Batch[0] avg_epoch_loss=2.730612\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.730612277984619\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] Epoch[108] Batch[5] avg_epoch_loss=2.788233\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.7882333596547446\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] Epoch[108] Batch [5]#011Speed: 2724.20 samples/sec#011loss=2.788233\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] Epoch[108] Batch[10] avg_epoch_loss=2.801007\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.8163360118865968\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] Epoch[108] Batch [10]#011Speed: 2563.34 samples/sec#011loss=2.816336\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747842722.909858, \"EndTime\": 1747842723.7247174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.5911693572998, \"count\": 1, \"min\": 814.5911693572998, \"max\": 814.5911693572998}}}\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1660.7726358054679 records/second\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.8010072924874048\n",
      "[05/21/2025 15:52:03 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] Epoch[109] Batch[0] avg_epoch_loss=2.931719\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.931718587875366\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] Epoch[109] Batch[5] avg_epoch_loss=2.800591\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.8005913496017456\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] Epoch[109] Batch [5]#011Speed: 2783.81 samples/sec#011loss=2.800591\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] Epoch[109] Batch[10] avg_epoch_loss=2.793837\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.7857316970825194\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] Epoch[109] Batch [10]#011Speed: 2674.56 samples/sec#011loss=2.785732\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842723.7247775, \"EndTime\": 1747842724.5343568, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.2899322509766, \"count\": 1, \"min\": 809.2899322509766, \"max\": 809.2899322509766}}}\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1603.6885180082616 records/second\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.7938369620930064\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] Epoch[110] Batch[0] avg_epoch_loss=2.867218\n",
      "[05/21/2025 15:52:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.867218494415283\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] Epoch[110] Batch[5] avg_epoch_loss=2.748995\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.748995224634806\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] Epoch[110] Batch [5]#011Speed: 2584.95 samples/sec#011loss=2.748995\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] Epoch[110] Batch[10] avg_epoch_loss=2.687317\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.613303542137146\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] Epoch[110] Batch [10]#011Speed: 2691.96 samples/sec#011loss=2.613304\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747842724.5344198, \"EndTime\": 1747842725.3761382, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 841.4123058319092, \"count\": 1, \"min\": 841.4123058319092, \"max\": 841.4123058319092}}}\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1531.794903062537 records/second\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.6873171871358696\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_40aab427-ef4d-4caf-befe-130626fd1b51-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842725.3761945, \"EndTime\": 1747842725.3860798, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.067058563232422, \"count\": 1, \"min\": 9.067058563232422, \"max\": 9.067058563232422}}}\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] Epoch[111] Batch[0] avg_epoch_loss=2.730275\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.7302746772766113\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] Epoch[111] Batch[5] avg_epoch_loss=2.786370\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.7863699197769165\n",
      "[05/21/2025 15:52:05 INFO 140269512570688] Epoch[111] Batch [5]#011Speed: 2750.56 samples/sec#011loss=2.786370\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] Epoch[111] Batch[10] avg_epoch_loss=2.830947\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=2.884440517425537\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] Epoch[111] Batch [10]#011Speed: 2622.58 samples/sec#011loss=2.884441\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747842725.386131, \"EndTime\": 1747842726.1757314, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.5514965057373, \"count\": 1, \"min\": 789.5514965057373, \"max\": 789.5514965057373}}}\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1645.0560301450641 records/second\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.8309474641626533\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] Epoch[112] Batch[0] avg_epoch_loss=2.859838\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.8598382472991943\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] Epoch[112] Batch[5] avg_epoch_loss=2.777962\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.7779618899027505\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] Epoch[112] Batch [5]#011Speed: 2808.78 samples/sec#011loss=2.777962\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] Epoch[112] Batch[10] avg_epoch_loss=2.690172\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.584825038909912\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] Epoch[112] Batch [10]#011Speed: 2874.88 samples/sec#011loss=2.584825\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747842726.1757908, \"EndTime\": 1747842726.9432125, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 767.1627998352051, \"count\": 1, \"min\": 767.1627998352051, \"max\": 767.1627998352051}}}\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1669.5710694458342 records/second\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.690172412178733\n",
      "[05/21/2025 15:52:06 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] Epoch[113] Batch[0] avg_epoch_loss=2.677310\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.6773104667663574\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] Epoch[113] Batch[5] avg_epoch_loss=2.768811\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.7688111464182534\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] Epoch[113] Batch [5]#011Speed: 2728.58 samples/sec#011loss=2.768811\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] Epoch[113] Batch[10] avg_epoch_loss=2.797290\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.831464910507202\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] Epoch[113] Batch [10]#011Speed: 2530.55 samples/sec#011loss=2.831465\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747842726.9432807, \"EndTime\": 1747842727.7658694, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 822.2594261169434, \"count\": 1, \"min\": 822.2594261169434, \"max\": 822.2594261169434}}}\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1620.962850107663 records/second\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.7972901300950483\n",
      "[05/21/2025 15:52:07 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] Epoch[114] Batch[0] avg_epoch_loss=2.646149\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.6461493968963623\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] Epoch[114] Batch[5] avg_epoch_loss=2.751650\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.751650094985962\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] Epoch[114] Batch [5]#011Speed: 2491.36 samples/sec#011loss=2.751650\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] Epoch[114] Batch[10] avg_epoch_loss=2.794266\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=2.845404052734375\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] Epoch[114] Batch [10]#011Speed: 2471.99 samples/sec#011loss=2.845404\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] processed a total of 1389 examples\n",
      "#metrics {\"StartTime\": 1747842727.7659302, \"EndTime\": 1747842728.6140893, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 847.8925228118896, \"count\": 1, \"min\": 847.8925228118896, \"max\": 847.8925228118896}}}\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1638.0070633029052 records/second\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.79426553032615\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] Epoch[115] Batch[0] avg_epoch_loss=2.778566\n",
      "[05/21/2025 15:52:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.7785658836364746\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] Epoch[115] Batch[5] avg_epoch_loss=2.786947\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.7869470516840615\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] Epoch[115] Batch [5]#011Speed: 2832.02 samples/sec#011loss=2.786947\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] Epoch[115] Batch[10] avg_epoch_loss=2.735338\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=2.6734070777893066\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] Epoch[115] Batch [10]#011Speed: 2550.05 samples/sec#011loss=2.673407\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] processed a total of 1384 examples\n",
      "#metrics {\"StartTime\": 1747842728.6141496, \"EndTime\": 1747842729.4522188, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 837.7995491027832, \"count\": 1, \"min\": 837.7995491027832, \"max\": 837.7995491027832}}}\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1651.7697197955133 records/second\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.735337972640991\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] Epoch[116] Batch[0] avg_epoch_loss=2.709815\n",
      "[05/21/2025 15:52:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.70981502532959\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] Epoch[116] Batch[5] avg_epoch_loss=2.710810\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.7108103036880493\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] Epoch[116] Batch [5]#011Speed: 2611.59 samples/sec#011loss=2.710810\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] processed a total of 1260 examples\n",
      "#metrics {\"StartTime\": 1747842729.4522796, \"EndTime\": 1747842730.2238493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 771.2767124176025, \"count\": 1, \"min\": 771.2767124176025, \"max\": 771.2767124176025}}}\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1633.4403290603864 records/second\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.7182406187057495\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] Epoch[117] Batch[0] avg_epoch_loss=2.725979\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.7259788513183594\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] Epoch[117] Batch[5] avg_epoch_loss=2.709997\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.7099968592325845\n",
      "[05/21/2025 15:52:10 INFO 140269512570688] Epoch[117] Batch [5]#011Speed: 2802.26 samples/sec#011loss=2.709997\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] Epoch[117] Batch[10] avg_epoch_loss=2.740274\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.77660551071167\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] Epoch[117] Batch [10]#011Speed: 2425.33 samples/sec#011loss=2.776606\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747842730.2239172, \"EndTime\": 1747842731.046324, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 822.0911026000977, \"count\": 1, \"min\": 822.0911026000977, \"max\": 822.0911026000977}}}\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1633.6571030962762 records/second\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.740273518995805\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] Epoch[118] Batch[0] avg_epoch_loss=2.675872\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.6758716106414795\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] Epoch[118] Batch[5] avg_epoch_loss=2.682049\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.682048519452413\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] Epoch[118] Batch [5]#011Speed: 2751.73 samples/sec#011loss=2.682049\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] Epoch[118] Batch[10] avg_epoch_loss=2.764853\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.8642194747924803\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] Epoch[118] Batch [10]#011Speed: 2701.38 samples/sec#011loss=2.864219\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747842731.0468976, \"EndTime\": 1747842731.8517747, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 804.588794708252, \"count\": 1, \"min\": 804.588794708252, \"max\": 804.588794708252}}}\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1656.5593954736373 records/second\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.764853499152444\n",
      "[05/21/2025 15:52:11 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] Epoch[119] Batch[0] avg_epoch_loss=2.723312\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.7233119010925293\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] Epoch[119] Batch[5] avg_epoch_loss=2.779251\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.779251297314962\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] Epoch[119] Batch [5]#011Speed: 2809.55 samples/sec#011loss=2.779251\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] processed a total of 1235 examples\n",
      "#metrics {\"StartTime\": 1747842731.8518364, \"EndTime\": 1747842732.5965922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 744.4820404052734, \"count\": 1, \"min\": 744.4820404052734, \"max\": 744.4820404052734}}}\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1658.6536637598408 records/second\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.7570210695266724\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] Epoch[120] Batch[0] avg_epoch_loss=2.755502\n",
      "[05/21/2025 15:52:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.755502462387085\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] Epoch[120] Batch[5] avg_epoch_loss=2.755019\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.7550187905629477\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] Epoch[120] Batch [5]#011Speed: 2713.60 samples/sec#011loss=2.755019\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] Epoch[120] Batch[10] avg_epoch_loss=2.788483\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=2.828639602661133\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] Epoch[120] Batch [10]#011Speed: 2683.58 samples/sec#011loss=2.828640\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747842732.596659, \"EndTime\": 1747842733.4087577, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.7833137512207, \"count\": 1, \"min\": 811.7833137512207, \"max\": 811.7833137512207}}}\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1638.1844494145507 records/second\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.7884827960621226\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] Epoch[121] Batch[0] avg_epoch_loss=2.862943\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.862942934036255\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] Epoch[121] Batch[5] avg_epoch_loss=2.757697\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.757696787516276\n",
      "[05/21/2025 15:52:13 INFO 140269512570688] Epoch[121] Batch [5]#011Speed: 2824.91 samples/sec#011loss=2.757697\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] processed a total of 1265 examples\n",
      "#metrics {\"StartTime\": 1747842733.4088202, \"EndTime\": 1747842734.1577363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 748.1729984283447, \"count\": 1, \"min\": 748.1729984283447, \"max\": 748.1729984283447}}}\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1690.560774285148 records/second\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.759255075454712\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] Epoch[122] Batch[0] avg_epoch_loss=2.675936\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.675936460494995\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] Epoch[122] Batch[5] avg_epoch_loss=2.681597\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.681596795717875\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] Epoch[122] Batch [5]#011Speed: 2970.50 samples/sec#011loss=2.681597\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] Epoch[122] Batch[10] avg_epoch_loss=2.627816\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=2.5632798194885256\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] Epoch[122] Batch [10]#011Speed: 2548.34 samples/sec#011loss=2.563280\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747842734.1578023, \"EndTime\": 1747842734.9637618, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 805.6001663208008, \"count\": 1, \"min\": 805.6001663208008, \"max\": 805.6001663208008}}}\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1644.5481471266844 records/second\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.6278163519772617\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:52:14 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_bedf9828-37ed-44ff-9784-4d6011b2e29d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842734.9638236, \"EndTime\": 1747842734.9744818, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.367631912231445, \"count\": 1, \"min\": 10.367631912231445, \"max\": 10.367631912231445}}}\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] Epoch[123] Batch[0] avg_epoch_loss=2.745709\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.745709180831909\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] Epoch[123] Batch[5] avg_epoch_loss=2.725343\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.7253433068593345\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] Epoch[123] Batch [5]#011Speed: 2873.66 samples/sec#011loss=2.725343\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] Epoch[123] Batch[10] avg_epoch_loss=2.716090\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=2.7049862861633303\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] Epoch[123] Batch [10]#011Speed: 2720.75 samples/sec#011loss=2.704986\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747842734.97454, \"EndTime\": 1747842735.7678306, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 793.2379245758057, \"count\": 1, \"min\": 793.2379245758057, \"max\": 793.2379245758057}}}\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1699.1776251214897 records/second\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] #progress_metric: host=algo-1, completed 31.0 % of epochs\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.716090115633878\n",
      "[05/21/2025 15:52:15 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] Epoch[124] Batch[0] avg_epoch_loss=2.659153\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.6591532230377197\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] Epoch[124] Batch[5] avg_epoch_loss=2.735942\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.7359416484832764\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] Epoch[124] Batch [5]#011Speed: 2914.63 samples/sec#011loss=2.735942\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] Epoch[124] Batch[10] avg_epoch_loss=2.769422\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=2.809597396850586\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] Epoch[124] Batch [10]#011Speed: 2596.17 samples/sec#011loss=2.809597\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747842735.767887, \"EndTime\": 1747842736.5782082, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.0543022155762, \"count\": 1, \"min\": 810.0543022155762, \"max\": 810.0543022155762}}}\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1588.6135854442718 records/second\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] #progress_metric: host=algo-1, completed 31.25 % of epochs\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.7694215341047808\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] Epoch[125] Batch[0] avg_epoch_loss=2.755876\n",
      "[05/21/2025 15:52:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.755875825881958\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] Epoch[125] Batch[5] avg_epoch_loss=2.725793\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.7257926861445108\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] Epoch[125] Batch [5]#011Speed: 2816.07 samples/sec#011loss=2.725793\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] Epoch[125] Batch[10] avg_epoch_loss=2.737867\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=2.7523562908172607\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] Epoch[125] Batch [10]#011Speed: 2582.55 samples/sec#011loss=2.752356\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747842736.5782657, \"EndTime\": 1747842737.3629384, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.3847274780273, \"count\": 1, \"min\": 784.3847274780273, \"max\": 784.3847274780273}}}\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1722.1931918338964 records/second\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] #progress_metric: host=algo-1, completed 31.5 % of epochs\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.7378670519048516\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] Epoch[126] Batch[0] avg_epoch_loss=2.810449\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.8104491233825684\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] Epoch[126] Batch[5] avg_epoch_loss=2.756213\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.756212751070658\n",
      "[05/21/2025 15:52:17 INFO 140269512570688] Epoch[126] Batch [5]#011Speed: 2950.62 samples/sec#011loss=2.756213\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] processed a total of 1270 examples\n",
      "#metrics {\"StartTime\": 1747842737.3629916, \"EndTime\": 1747842738.085464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 722.1879959106445, \"count\": 1, \"min\": 722.1879959106445, \"max\": 722.1879959106445}}}\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1758.3063007037165 records/second\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] #progress_metric: host=algo-1, completed 31.75 % of epochs\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.763869619369507\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] Epoch[127] Batch[0] avg_epoch_loss=2.747812\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.747811794281006\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] Epoch[127] Batch[5] avg_epoch_loss=2.735767\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.7357671658198037\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] Epoch[127] Batch [5]#011Speed: 2609.36 samples/sec#011loss=2.735767\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] Epoch[127] Batch[10] avg_epoch_loss=2.699342\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=2.6556326389312743\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] Epoch[127] Batch [10]#011Speed: 2439.71 samples/sec#011loss=2.655633\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747842738.085533, \"EndTime\": 1747842738.908629, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 822.8011131286621, \"count\": 1, \"min\": 822.8011131286621, \"max\": 822.8011131286621}}}\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1590.7363912189899 records/second\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] #progress_metric: host=algo-1, completed 32.0 % of epochs\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.699342380870472\n",
      "[05/21/2025 15:52:18 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] Epoch[128] Batch[0] avg_epoch_loss=2.683721\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.683720827102661\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] Epoch[128] Batch[5] avg_epoch_loss=2.758271\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.7582711776097617\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] Epoch[128] Batch [5]#011Speed: 2943.77 samples/sec#011loss=2.758271\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] Epoch[128] Batch[10] avg_epoch_loss=2.718219\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=2.6701573371887206\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] Epoch[128] Batch [10]#011Speed: 2494.76 samples/sec#011loss=2.670157\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747842738.9086888, \"EndTime\": 1747842739.696689, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 787.7447605133057, \"count\": 1, \"min\": 787.7447605133057, \"max\": 787.7447605133057}}}\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1703.4124101198402 records/second\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] #progress_metric: host=algo-1, completed 32.25 % of epochs\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.718219431963834\n",
      "[05/21/2025 15:52:19 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] Epoch[129] Batch[0] avg_epoch_loss=2.697219\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.697218894958496\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] Epoch[129] Batch[5] avg_epoch_loss=2.755270\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.7552700440088906\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] Epoch[129] Batch [5]#011Speed: 2810.15 samples/sec#011loss=2.755270\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] Epoch[129] Batch[10] avg_epoch_loss=2.740281\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=2.7222948551177977\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] Epoch[129] Batch [10]#011Speed: 2653.59 samples/sec#011loss=2.722295\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747842739.696747, \"EndTime\": 1747842740.4855874, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.5880470275879, \"count\": 1, \"min\": 788.5880470275879, \"max\": 788.5880470275879}}}\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1642.0027775712033 records/second\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] #progress_metric: host=algo-1, completed 32.5 % of epochs\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.7402813217856665\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] Epoch[130] Batch[0] avg_epoch_loss=2.778480\n",
      "[05/21/2025 15:52:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.778480052947998\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] Epoch[130] Batch[5] avg_epoch_loss=2.803182\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.803182045618693\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] Epoch[130] Batch [5]#011Speed: 2813.63 samples/sec#011loss=2.803182\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] Epoch[130] Batch[10] avg_epoch_loss=2.917196\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=3.054012489318848\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] Epoch[130] Batch [10]#011Speed: 2729.48 samples/sec#011loss=3.054012\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747842740.4856448, \"EndTime\": 1747842741.2655544, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 779.632568359375, \"count\": 1, \"min\": 779.632568359375, \"max\": 779.632568359375}}}\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1656.9912543075638 records/second\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] #progress_metric: host=algo-1, completed 32.75 % of epochs\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.917195883664218\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] Epoch[131] Batch[0] avg_epoch_loss=2.800011\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.800011396408081\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] Epoch[131] Batch[5] avg_epoch_loss=2.798143\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.798142989476522\n",
      "[05/21/2025 15:52:21 INFO 140269512570688] Epoch[131] Batch [5]#011Speed: 2839.97 samples/sec#011loss=2.798143\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] Epoch[131] Batch[10] avg_epoch_loss=2.741112\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=2.6726739406585693\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] Epoch[131] Batch [10]#011Speed: 2515.26 samples/sec#011loss=2.672674\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747842741.265617, \"EndTime\": 1747842742.0828745, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 816.9825077056885, \"count\": 1, \"min\": 816.9825077056885, \"max\": 816.9825077056885}}}\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1619.181872375863 records/second\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] #progress_metric: host=algo-1, completed 33.0 % of epochs\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.7411116036501797\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] Epoch[132] Batch[0] avg_epoch_loss=2.628088\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.6280877590179443\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] Epoch[132] Batch[5] avg_epoch_loss=2.762502\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.7625019550323486\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] Epoch[132] Batch [5]#011Speed: 2621.17 samples/sec#011loss=2.762502\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747842742.0829391, \"EndTime\": 1747842742.857555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 774.343729019165, \"count\": 1, \"min\": 774.343729019165, \"max\": 774.343729019165}}}\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1651.5209115619075 records/second\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] #progress_metric: host=algo-1, completed 33.25 % of epochs\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.7441957712173464\n",
      "[05/21/2025 15:52:22 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] Epoch[133] Batch[0] avg_epoch_loss=2.867135\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.8671345710754395\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] Epoch[133] Batch[5] avg_epoch_loss=2.740016\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.740015904108683\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] Epoch[133] Batch [5]#011Speed: 2844.99 samples/sec#011loss=2.740016\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] Epoch[133] Batch[10] avg_epoch_loss=2.673042\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=2.5926743507385255\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] Epoch[133] Batch [10]#011Speed: 2676.52 samples/sec#011loss=2.592674\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747842742.857619, \"EndTime\": 1747842743.6603627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.4294376373291, \"count\": 1, \"min\": 802.4294376373291, \"max\": 802.4294376373291}}}\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1629.8639109665817 records/second\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] #progress_metric: host=algo-1, completed 33.5 % of epochs\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.6730424707586113\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] Epoch[134] Batch[0] avg_epoch_loss=2.706759\n",
      "[05/21/2025 15:52:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.706758737564087\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] Epoch[134] Batch[5] avg_epoch_loss=2.669714\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.669713536898295\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] Epoch[134] Batch [5]#011Speed: 2762.80 samples/sec#011loss=2.669714\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] Epoch[134] Batch[10] avg_epoch_loss=2.712040\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.762831687927246\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] Epoch[134] Batch [10]#011Speed: 2580.71 samples/sec#011loss=2.762832\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747842743.660424, \"EndTime\": 1747842744.4786139, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.8937435150146, \"count\": 1, \"min\": 817.8937435150146, \"max\": 817.8937435150146}}}\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1611.277785404598 records/second\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] #progress_metric: host=algo-1, completed 33.75 % of epochs\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.712039969184182\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] Epoch[135] Batch[0] avg_epoch_loss=2.538887\n",
      "[05/21/2025 15:52:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.538886785507202\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] Epoch[135] Batch[5] avg_epoch_loss=2.672407\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.672407110532125\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] Epoch[135] Batch [5]#011Speed: 2581.49 samples/sec#011loss=2.672407\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] Epoch[135] Batch[10] avg_epoch_loss=2.747335\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=2.837247610092163\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] Epoch[135] Batch [10]#011Speed: 2767.32 samples/sec#011loss=2.837248\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747842744.4786744, \"EndTime\": 1747842745.3021173, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 822.6561546325684, \"count\": 1, \"min\": 822.6561546325684, \"max\": 822.6561546325684}}}\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1575.2053860150345 records/second\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] #progress_metric: host=algo-1, completed 34.0 % of epochs\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.747334610332142\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] Epoch[136] Batch[0] avg_epoch_loss=2.625708\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.6257083415985107\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] Epoch[136] Batch[5] avg_epoch_loss=2.686554\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.686553875605265\n",
      "[05/21/2025 15:52:25 INFO 140269512570688] Epoch[136] Batch [5]#011Speed: 2881.46 samples/sec#011loss=2.686554\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] Epoch[136] Batch[10] avg_epoch_loss=2.698625\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=2.7131109714508055\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] Epoch[136] Batch [10]#011Speed: 2695.81 samples/sec#011loss=2.713111\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747842745.302181, \"EndTime\": 1747842746.0974112, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.9612140655518, \"count\": 1, \"min\": 794.9612140655518, \"max\": 794.9612140655518}}}\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1701.7835362617154 records/second\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] #progress_metric: host=algo-1, completed 34.25 % of epochs\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.6986252828077837\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] Epoch[137] Batch[0] avg_epoch_loss=2.653446\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.6534459590911865\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] Epoch[137] Batch[5] avg_epoch_loss=2.647098\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.6470978260040283\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] Epoch[137] Batch [5]#011Speed: 2837.93 samples/sec#011loss=2.647098\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] Epoch[137] Batch[10] avg_epoch_loss=2.592570\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=2.527136754989624\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] Epoch[137] Batch [10]#011Speed: 2796.78 samples/sec#011loss=2.527137\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747842746.0974693, \"EndTime\": 1747842746.8924375, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.6867942810059, \"count\": 1, \"min\": 794.6867942810059, \"max\": 794.6867942810059}}}\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1626.8003582825236 records/second\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] #progress_metric: host=algo-1, completed 34.5 % of epochs\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.5925700664520264\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:52:26 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_242b71cb-e2ce-443e-a69d-fb205dd5e155-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842746.892528, \"EndTime\": 1747842746.9022048, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.30476188659668, \"count\": 1, \"min\": 9.30476188659668, \"max\": 9.30476188659668}}}\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] Epoch[138] Batch[0] avg_epoch_loss=2.686514\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.686514377593994\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] Epoch[138] Batch[5] avg_epoch_loss=2.656640\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.65664009253184\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] Epoch[138] Batch [5]#011Speed: 2895.92 samples/sec#011loss=2.656640\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] Epoch[138] Batch[10] avg_epoch_loss=2.563434\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.451586604118347\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] Epoch[138] Batch [10]#011Speed: 2707.91 samples/sec#011loss=2.451587\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747842746.902249, \"EndTime\": 1747842747.6727722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 770.470380783081, \"count\": 1, \"min\": 770.470380783081, \"max\": 770.470380783081}}}\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1685.7806437240388 records/second\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] #progress_metric: host=algo-1, completed 34.75 % of epochs\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.563433961434798\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_89a94806-61e0-4f03-8571-96e78cea1bfe-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842747.6728344, \"EndTime\": 1747842747.682092, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.865833282470703, \"count\": 1, \"min\": 8.865833282470703, \"max\": 8.865833282470703}}}\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] Epoch[139] Batch[0] avg_epoch_loss=2.645798\n",
      "[05/21/2025 15:52:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.6457977294921875\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] Epoch[139] Batch[5] avg_epoch_loss=2.651925\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.651925484339396\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] Epoch[139] Batch [5]#011Speed: 2845.07 samples/sec#011loss=2.651925\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] Epoch[139] Batch[10] avg_epoch_loss=2.553384\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=2.435133767127991\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] Epoch[139] Batch [10]#011Speed: 2766.80 samples/sec#011loss=2.435134\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747842747.6821475, \"EndTime\": 1747842748.4553065, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 773.1046676635742, \"count\": 1, \"min\": 773.1046676635742, \"max\": 773.1046676635742}}}\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1660.647454027192 records/second\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] #progress_metric: host=algo-1, completed 35.0 % of epochs\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.553383794697848\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_f80343f6-c7a7-4db5-8634-47aa9e64bb2a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842748.4553628, \"EndTime\": 1747842748.4645245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.789300918579102, \"count\": 1, \"min\": 8.789300918579102, \"max\": 8.789300918579102}}}\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] Epoch[140] Batch[0] avg_epoch_loss=2.701784\n",
      "[05/21/2025 15:52:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.701784133911133\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] Epoch[140] Batch[5] avg_epoch_loss=2.675359\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.67535928885142\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] Epoch[140] Batch [5]#011Speed: 2768.27 samples/sec#011loss=2.675359\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] Epoch[140] Batch[10] avg_epoch_loss=2.679719\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=2.6849497318267823\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] Epoch[140] Batch [10]#011Speed: 2656.76 samples/sec#011loss=2.684950\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747842748.4645734, \"EndTime\": 1747842749.2462173, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 781.5952301025391, \"count\": 1, \"min\": 781.5952301025391, \"max\": 781.5952301025391}}}\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1723.2092058580959 records/second\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] #progress_metric: host=algo-1, completed 35.25 % of epochs\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.6797185811129483\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] Epoch[141] Batch[0] avg_epoch_loss=2.601766\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.6017658710479736\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] Epoch[141] Batch[5] avg_epoch_loss=2.636510\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.636510173479716\n",
      "[05/21/2025 15:52:29 INFO 140269512570688] Epoch[141] Batch [5]#011Speed: 2761.39 samples/sec#011loss=2.636510\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] Epoch[141] Batch[10] avg_epoch_loss=2.674027\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=2.719046926498413\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] Epoch[141] Batch [10]#011Speed: 2665.01 samples/sec#011loss=2.719047\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747842749.246276, \"EndTime\": 1747842750.0224087, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 775.825023651123, \"count\": 1, \"min\": 775.825023651123, \"max\": 775.825023651123}}}\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1756.5630577178222 records/second\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] #progress_metric: host=algo-1, completed 35.5 % of epochs\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.6740268793973057\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] Epoch[142] Batch[0] avg_epoch_loss=2.770928\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.770927906036377\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] Epoch[142] Batch[5] avg_epoch_loss=2.766255\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.766255497932434\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] Epoch[142] Batch [5]#011Speed: 2813.22 samples/sec#011loss=2.766255\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] Epoch[142] Batch[10] avg_epoch_loss=2.841277\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=2.9313022613525392\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] Epoch[142] Batch [10]#011Speed: 2552.62 samples/sec#011loss=2.931302\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747842750.0225003, \"EndTime\": 1747842750.8141532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.3863658905029, \"count\": 1, \"min\": 791.3863658905029, \"max\": 791.3863658905029}}}\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1684.1935527792623 records/second\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] #progress_metric: host=algo-1, completed 35.75 % of epochs\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.841276754032482\n",
      "[05/21/2025 15:52:30 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] Epoch[143] Batch[0] avg_epoch_loss=2.766448\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.7664482593536377\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] Epoch[143] Batch[5] avg_epoch_loss=2.704393\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.7043930689493814\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] Epoch[143] Batch [5]#011Speed: 2948.86 samples/sec#011loss=2.704393\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] Epoch[143] Batch[10] avg_epoch_loss=2.705356\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=2.7065107345581056\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] Epoch[143] Batch [10]#011Speed: 2806.85 samples/sec#011loss=2.706511\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747842750.8142126, \"EndTime\": 1747842751.5744464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 759.9785327911377, \"count\": 1, \"min\": 759.9785327911377, \"max\": 759.9785327911377}}}\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1713.0101350524758 records/second\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] #progress_metric: host=algo-1, completed 36.0 % of epochs\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.705355644226074\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] Epoch[144] Batch[0] avg_epoch_loss=2.624952\n",
      "[05/21/2025 15:52:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.6249520778656006\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] Epoch[144] Batch[5] avg_epoch_loss=2.678933\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.678933262825012\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] Epoch[144] Batch [5]#011Speed: 2887.63 samples/sec#011loss=2.678933\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] Epoch[144] Batch[10] avg_epoch_loss=2.729787\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=2.790811014175415\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] Epoch[144] Batch [10]#011Speed: 2762.14 samples/sec#011loss=2.790811\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747842751.5745049, \"EndTime\": 1747842752.3435078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 768.7182426452637, \"count\": 1, \"min\": 768.7182426452637, \"max\": 768.7182426452637}}}\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1696.1440132581115 records/second\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] #progress_metric: host=algo-1, completed 36.25 % of epochs\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.7297867861661045\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] Epoch[145] Batch[0] avg_epoch_loss=2.620261\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.6202614307403564\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] Epoch[145] Batch[5] avg_epoch_loss=2.667458\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.6674582958221436\n",
      "[05/21/2025 15:52:32 INFO 140269512570688] Epoch[145] Batch [5]#011Speed: 2605.24 samples/sec#011loss=2.667458\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] Epoch[145] Batch[10] avg_epoch_loss=2.675625\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=2.685425615310669\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] Epoch[145] Batch [10]#011Speed: 2657.94 samples/sec#011loss=2.685426\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747842752.3435645, \"EndTime\": 1747842753.1419637, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.147439956665, \"count\": 1, \"min\": 798.147439956665, \"max\": 798.147439956665}}}\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1688.6285369028978 records/second\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] #progress_metric: host=algo-1, completed 36.5 % of epochs\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.6756252592260186\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] Epoch[146] Batch[0] avg_epoch_loss=2.603454\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.603454351425171\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] Epoch[146] Batch[5] avg_epoch_loss=2.666033\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.6660330295562744\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] Epoch[146] Batch [5]#011Speed: 2748.87 samples/sec#011loss=2.666033\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] Epoch[146] Batch[10] avg_epoch_loss=2.633764\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=2.5950406074523924\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] Epoch[146] Batch [10]#011Speed: 2568.16 samples/sec#011loss=2.595041\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747842753.1420639, \"EndTime\": 1747842753.9337115, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.3484573364258, \"count\": 1, \"min\": 791.3484573364258, \"max\": 791.3484573364258}}}\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1698.1785870504325 records/second\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] #progress_metric: host=algo-1, completed 36.75 % of epochs\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.6337637467817827\n",
      "[05/21/2025 15:52:33 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] Epoch[147] Batch[0] avg_epoch_loss=2.560740\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=2.560739517211914\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] Epoch[147] Batch[5] avg_epoch_loss=2.585912\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=2.5859124263127646\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] Epoch[147] Batch [5]#011Speed: 2885.48 samples/sec#011loss=2.585912\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747842753.9337692, \"EndTime\": 1747842754.6617887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 727.6878356933594, \"count\": 1, \"min\": 727.6878356933594, \"max\": 727.6878356933594}}}\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1739.5438336481554 records/second\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] #progress_metric: host=algo-1, completed 37.0 % of epochs\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.5882147312164308\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] Epoch[148] Batch[0] avg_epoch_loss=2.648002\n",
      "[05/21/2025 15:52:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.6480021476745605\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] Epoch[148] Batch[5] avg_epoch_loss=2.585852\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.5858517487843833\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] Epoch[148] Batch [5]#011Speed: 2729.97 samples/sec#011loss=2.585852\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] Epoch[148] Batch[10] avg_epoch_loss=2.702723\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=2.8429686069488525\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] Epoch[148] Batch [10]#011Speed: 2731.15 samples/sec#011loss=2.842969\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747842754.6618476, \"EndTime\": 1747842755.453947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.7656898498535, \"count\": 1, \"min\": 791.7656898498535, \"max\": 791.7656898498535}}}\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1687.1733065084068 records/second\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] #progress_metric: host=algo-1, completed 37.25 % of epochs\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.7027230479500512\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] Epoch[149] Batch[0] avg_epoch_loss=2.664254\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.6642544269561768\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] Epoch[149] Batch[5] avg_epoch_loss=2.686678\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.6866784493128457\n",
      "[05/21/2025 15:52:35 INFO 140269512570688] Epoch[149] Batch [5]#011Speed: 2769.91 samples/sec#011loss=2.686678\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] processed a total of 1217 examples\n",
      "#metrics {\"StartTime\": 1747842755.4540088, \"EndTime\": 1747842756.174498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 720.2367782592773, \"count\": 1, \"min\": 720.2367782592773, \"max\": 720.2367782592773}}}\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1689.5207576196888 records/second\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] #progress_metric: host=algo-1, completed 37.5 % of epochs\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.6921499967575073\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] Epoch[150] Batch[0] avg_epoch_loss=2.801087\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.801086664199829\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] Epoch[150] Batch[5] avg_epoch_loss=2.720472\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.720472057660421\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] Epoch[150] Batch [5]#011Speed: 2679.27 samples/sec#011loss=2.720472\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] Epoch[150] Batch[10] avg_epoch_loss=2.702247\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=2.6803768157958983\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] Epoch[150] Batch [10]#011Speed: 2381.85 samples/sec#011loss=2.680377\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] processed a total of 1389 examples\n",
      "#metrics {\"StartTime\": 1747842756.174555, \"EndTime\": 1747842756.9875069, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.4969005584717, \"count\": 1, \"min\": 812.4969005584717, \"max\": 812.4969005584717}}}\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1709.3403351321947 records/second\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] #progress_metric: host=algo-1, completed 37.75 % of epochs\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.7022469477220015\n",
      "[05/21/2025 15:52:36 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] Epoch[151] Batch[0] avg_epoch_loss=2.653442\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.6534416675567627\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] Epoch[151] Batch[5] avg_epoch_loss=2.620976\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.6209755341211953\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] Epoch[151] Batch [5]#011Speed: 2939.94 samples/sec#011loss=2.620976\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] Epoch[151] Batch[10] avg_epoch_loss=2.787486\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=2.9872992992401124\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] Epoch[151] Batch [10]#011Speed: 2792.86 samples/sec#011loss=2.987299\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747842756.987571, \"EndTime\": 1747842757.7492695, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 761.366605758667, \"count\": 1, \"min\": 761.366605758667, \"max\": 761.366605758667}}}\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1719.070162161722 records/second\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] #progress_metric: host=algo-1, completed 38.0 % of epochs\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.787486336447976\n",
      "[05/21/2025 15:52:37 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] Epoch[152] Batch[0] avg_epoch_loss=2.688074\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.6880743503570557\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] Epoch[152] Batch[5] avg_epoch_loss=2.840760\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.8407599925994873\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] Epoch[152] Batch [5]#011Speed: 2899.57 samples/sec#011loss=2.840760\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] Epoch[152] Batch[10] avg_epoch_loss=2.820899\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=2.797065782546997\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] Epoch[152] Batch [10]#011Speed: 2637.69 samples/sec#011loss=2.797066\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747842757.7493289, \"EndTime\": 1747842758.5288815, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 779.2067527770996, \"count\": 1, \"min\": 779.2067527770996, \"max\": 779.2067527770996}}}\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1684.8392438062028 records/second\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] #progress_metric: host=algo-1, completed 38.25 % of epochs\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.8208989880301734\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] Epoch[153] Batch[0] avg_epoch_loss=2.839295\n",
      "[05/21/2025 15:52:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.8392951488494873\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] Epoch[153] Batch[5] avg_epoch_loss=2.754408\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.754408121109009\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] Epoch[153] Batch [5]#011Speed: 2770.14 samples/sec#011loss=2.754408\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] Epoch[153] Batch[10] avg_epoch_loss=2.671462\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=2.571926999092102\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] Epoch[153] Batch [10]#011Speed: 2658.77 samples/sec#011loss=2.571927\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747842758.5289457, \"EndTime\": 1747842759.3138099, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.5585346221924, \"count\": 1, \"min\": 784.5585346221924, \"max\": 784.5585346221924}}}\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1674.6282531992654 records/second\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] #progress_metric: host=algo-1, completed 38.5 % of epochs\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.671462156555869\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] Epoch[154] Batch[0] avg_epoch_loss=2.731397\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.7313971519470215\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] Epoch[154] Batch[5] avg_epoch_loss=2.710339\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.7103386720021567\n",
      "[05/21/2025 15:52:39 INFO 140269512570688] Epoch[154] Batch [5]#011Speed: 2760.73 samples/sec#011loss=2.710339\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] processed a total of 1245 examples\n",
      "#metrics {\"StartTime\": 1747842759.313873, \"EndTime\": 1747842760.0391932, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 724.4548797607422, \"count\": 1, \"min\": 724.4548797607422, \"max\": 724.4548797607422}}}\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1718.2909319571847 records/second\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] #progress_metric: host=algo-1, completed 38.75 % of epochs\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.70206081867218\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] Epoch[155] Batch[0] avg_epoch_loss=2.764058\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.7640576362609863\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] Epoch[155] Batch[5] avg_epoch_loss=2.700206\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.70020592212677\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] Epoch[155] Batch [5]#011Speed: 2879.06 samples/sec#011loss=2.700206\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] Epoch[155] Batch[10] avg_epoch_loss=2.667986\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=2.6293217182159423\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] Epoch[155] Batch [10]#011Speed: 2689.41 samples/sec#011loss=2.629322\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747842760.039261, \"EndTime\": 1747842760.839142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.5049953460693, \"count\": 1, \"min\": 799.5049953460693, \"max\": 799.5049953460693}}}\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1639.5758852843367 records/second\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] #progress_metric: host=algo-1, completed 39.0 % of epochs\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.6679858294400303\n",
      "[05/21/2025 15:52:40 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] Epoch[156] Batch[0] avg_epoch_loss=2.611570\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.611569881439209\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] Epoch[156] Batch[5] avg_epoch_loss=2.699805\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.6998053391774497\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] Epoch[156] Batch [5]#011Speed: 2827.80 samples/sec#011loss=2.699805\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] Epoch[156] Batch[10] avg_epoch_loss=2.980144\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=3.31655011177063\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] Epoch[156] Batch [10]#011Speed: 2613.51 samples/sec#011loss=3.316550\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747842760.8392036, \"EndTime\": 1747842761.6504316, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.9064102172852, \"count\": 1, \"min\": 810.9064102172852, \"max\": 810.9064102172852}}}\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1625.1558239016786 records/second\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] #progress_metric: host=algo-1, completed 39.25 % of epochs\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.9801438721743496\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] Epoch[157] Batch[0] avg_epoch_loss=2.655682\n",
      "[05/21/2025 15:52:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.655682325363159\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] Epoch[157] Batch[5] avg_epoch_loss=2.797075\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.797075112660726\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] Epoch[157] Batch [5]#011Speed: 2799.11 samples/sec#011loss=2.797075\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] Epoch[157] Batch[10] avg_epoch_loss=2.836278\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=2.883321237564087\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] Epoch[157] Batch [10]#011Speed: 2622.81 samples/sec#011loss=2.883321\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747842761.6504939, \"EndTime\": 1747842762.4327624, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.0079326629639, \"count\": 1, \"min\": 782.0079326629639, \"max\": 782.0079326629639}}}\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1709.5136959930055 records/second\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] #progress_metric: host=algo-1, completed 39.5 % of epochs\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.836277896707708\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] Epoch[158] Batch[0] avg_epoch_loss=2.760369\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.760369300842285\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] Epoch[158] Batch[5] avg_epoch_loss=2.757229\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.7572291692097983\n",
      "[05/21/2025 15:52:42 INFO 140269512570688] Epoch[158] Batch [5]#011Speed: 2760.98 samples/sec#011loss=2.757229\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] Epoch[158] Batch[10] avg_epoch_loss=2.837861\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=2.934618377685547\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] Epoch[158] Batch [10]#011Speed: 2595.53 samples/sec#011loss=2.934618\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747842762.4328208, \"EndTime\": 1747842763.223516, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.3871536254883, \"count\": 1, \"min\": 790.3871536254883, \"max\": 790.3871536254883}}}\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1690.1237686967029 records/second\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] #progress_metric: host=algo-1, completed 39.75 % of epochs\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.8378606276078657\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] Epoch[159] Batch[0] avg_epoch_loss=2.666366\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.6663663387298584\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] Epoch[159] Batch[5] avg_epoch_loss=2.724545\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.7245445251464844\n",
      "[05/21/2025 15:52:43 INFO 140269512570688] Epoch[159] Batch [5]#011Speed: 2806.21 samples/sec#011loss=2.724545\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] Epoch[159] Batch[10] avg_epoch_loss=2.805794\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=2.9032922744750977\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] Epoch[159] Batch [10]#011Speed: 2682.48 samples/sec#011loss=2.903292\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747842763.223574, \"EndTime\": 1747842764.0088923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.0661277770996, \"count\": 1, \"min\": 785.0661277770996, \"max\": 785.0661277770996}}}\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1654.7676810470878 records/second\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] #progress_metric: host=algo-1, completed 40.0 % of epochs\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.8057935021140357\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] Epoch[160] Batch[0] avg_epoch_loss=2.803005\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.8030052185058594\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] Epoch[160] Batch[5] avg_epoch_loss=2.740026\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.7400259574254355\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] Epoch[160] Batch [5]#011Speed: 2709.98 samples/sec#011loss=2.740026\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] Epoch[160] Batch[10] avg_epoch_loss=2.709478\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=2.672819423675537\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] Epoch[160] Batch [10]#011Speed: 2418.87 samples/sec#011loss=2.672819\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747842764.0094054, \"EndTime\": 1747842764.823476, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.8024806976318, \"count\": 1, \"min\": 813.8024806976318, \"max\": 813.8024806976318}}}\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1659.9358359827154 records/second\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] #progress_metric: host=algo-1, completed 40.25 % of epochs\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.7094775329936636\n",
      "[05/21/2025 15:52:44 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] Epoch[161] Batch[0] avg_epoch_loss=2.696831\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.696830987930298\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] Epoch[161] Batch[5] avg_epoch_loss=2.679072\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.6790724198023477\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] Epoch[161] Batch [5]#011Speed: 2790.59 samples/sec#011loss=2.679072\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] Epoch[161] Batch[10] avg_epoch_loss=2.750116\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=2.8353678226470946\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] Epoch[161] Batch [10]#011Speed: 2487.55 samples/sec#011loss=2.835368\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747842764.8235326, \"EndTime\": 1747842765.627604, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.7757873535156, \"count\": 1, \"min\": 803.7757873535156, \"max\": 803.7757873535156}}}\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1656.9873638248594 records/second\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] #progress_metric: host=algo-1, completed 40.5 % of epochs\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.7501157847317783\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] Epoch[162] Batch[0] avg_epoch_loss=2.609108\n",
      "[05/21/2025 15:52:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.6091082096099854\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] Epoch[162] Batch[5] avg_epoch_loss=2.631806\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.6318055391311646\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] Epoch[162] Batch [5]#011Speed: 2791.67 samples/sec#011loss=2.631806\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] Epoch[162] Batch[10] avg_epoch_loss=2.552892\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=2.458195161819458\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] Epoch[162] Batch [10]#011Speed: 2740.81 samples/sec#011loss=2.458195\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747842765.627666, \"EndTime\": 1747842766.431361, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.429365158081, \"count\": 1, \"min\": 803.429365158081, \"max\": 803.429365158081}}}\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1600.721782821789 records/second\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] #progress_metric: host=algo-1, completed 40.75 % of epochs\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.552891731262207\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_c84c1cfa-9050-4959-9dd2-2e350c6bac0b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842766.4319143, \"EndTime\": 1747842766.4418483, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.633302688598633, \"count\": 1, \"min\": 9.633302688598633, \"max\": 9.633302688598633}}}\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] Epoch[163] Batch[0] avg_epoch_loss=2.707872\n",
      "[05/21/2025 15:52:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.7078723907470703\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] Epoch[163] Batch[5] avg_epoch_loss=2.652796\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.6527960697809854\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] Epoch[163] Batch [5]#011Speed: 2818.49 samples/sec#011loss=2.652796\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] Epoch[163] Batch[10] avg_epoch_loss=2.667411\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=2.6849486351013185\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] Epoch[163] Batch [10]#011Speed: 2677.95 samples/sec#011loss=2.684949\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747842766.4419012, \"EndTime\": 1747842767.2404237, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.4702587127686, \"count\": 1, \"min\": 798.4702587127686, \"max\": 798.4702587127686}}}\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1700.516028102172 records/second\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] #progress_metric: host=algo-1, completed 41.0 % of epochs\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.667410872199319\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] Epoch[164] Batch[0] avg_epoch_loss=2.664925\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.6649246215820312\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] Epoch[164] Batch[5] avg_epoch_loss=2.650697\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.650697350502014\n",
      "[05/21/2025 15:52:47 INFO 140269512570688] Epoch[164] Batch [5]#011Speed: 2926.66 samples/sec#011loss=2.650697\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] Epoch[164] Batch[10] avg_epoch_loss=2.652205\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=2.654013729095459\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] Epoch[164] Batch [10]#011Speed: 2768.74 samples/sec#011loss=2.654014\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747842767.240503, \"EndTime\": 1747842768.0268378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.9084606170654, \"count\": 1, \"min\": 785.9084606170654, \"max\": 785.9084606170654}}}\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1675.5099777180978 records/second\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] #progress_metric: host=algo-1, completed 41.25 % of epochs\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.6522047953172163\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] Epoch[165] Batch[0] avg_epoch_loss=2.582142\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.582141876220703\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] Epoch[165] Batch[5] avg_epoch_loss=2.599223\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.599223335584005\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] Epoch[165] Batch [5]#011Speed: 2669.17 samples/sec#011loss=2.599223\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] Epoch[165] Batch[10] avg_epoch_loss=2.620603\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=2.6462579727172852\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] Epoch[165] Batch [10]#011Speed: 2693.57 samples/sec#011loss=2.646258\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747842768.0269284, \"EndTime\": 1747842768.8408947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.6928081512451, \"count\": 1, \"min\": 813.6928081512451, \"max\": 813.6928081512451}}}\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1640.4914153489804 records/second\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] #progress_metric: host=algo-1, completed 41.5 % of epochs\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.6206027160991323\n",
      "[05/21/2025 15:52:48 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] Epoch[166] Batch[0] avg_epoch_loss=2.517916\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.517916440963745\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] Epoch[166] Batch[5] avg_epoch_loss=2.566036\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.566035588582357\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] Epoch[166] Batch [5]#011Speed: 2838.65 samples/sec#011loss=2.566036\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] Epoch[166] Batch[10] avg_epoch_loss=2.618076\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=2.6805245876312256\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] Epoch[166] Batch [10]#011Speed: 2743.63 samples/sec#011loss=2.680525\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747842768.840954, \"EndTime\": 1747842769.6387775, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.5475788116455, \"count\": 1, \"min\": 797.5475788116455, \"max\": 797.5475788116455}}}\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1673.697704754173 records/second\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] #progress_metric: host=algo-1, completed 41.75 % of epochs\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.618076042695479\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] Epoch[167] Batch[0] avg_epoch_loss=2.770128\n",
      "[05/21/2025 15:52:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=2.7701282501220703\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] Epoch[167] Batch[5] avg_epoch_loss=2.924389\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.9243894815444946\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] Epoch[167] Batch [5]#011Speed: 2589.03 samples/sec#011loss=2.924389\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] Epoch[167] Batch[10] avg_epoch_loss=2.930488\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=2.9378053188323974\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] Epoch[167] Batch [10]#011Speed: 2634.29 samples/sec#011loss=2.937805\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747842769.6388373, \"EndTime\": 1747842770.4666793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 827.5406360626221, \"count\": 1, \"min\": 827.5406360626221, \"max\": 827.5406360626221}}}\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1613.0632582035278 records/second\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] #progress_metric: host=algo-1, completed 42.0 % of epochs\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.9304875894026323\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] Epoch[168] Batch[0] avg_epoch_loss=2.815352\n",
      "[05/21/2025 15:52:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.815351963043213\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] Epoch[168] Batch[5] avg_epoch_loss=2.821126\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.821126421292623\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] Epoch[168] Batch [5]#011Speed: 2802.52 samples/sec#011loss=2.821126\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] Epoch[168] Batch[10] avg_epoch_loss=2.827922\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=2.8360757350921633\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] Epoch[168] Batch [10]#011Speed: 2543.44 samples/sec#011loss=2.836076\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747842770.4667296, \"EndTime\": 1747842771.279459, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.483549118042, \"count\": 1, \"min\": 812.483549118042, \"max\": 812.483549118042}}}\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1685.994541390543 records/second\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] #progress_metric: host=algo-1, completed 42.25 % of epochs\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.8279215639287774\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] Epoch[169] Batch[0] avg_epoch_loss=2.583335\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.5833349227905273\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] Epoch[169] Batch[5] avg_epoch_loss=2.631866\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.6318657398223877\n",
      "[05/21/2025 15:52:51 INFO 140269512570688] Epoch[169] Batch [5]#011Speed: 2871.75 samples/sec#011loss=2.631866\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] Epoch[169] Batch[10] avg_epoch_loss=2.572681\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.5016600131988525\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] Epoch[169] Batch [10]#011Speed: 2710.59 samples/sec#011loss=2.501660\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747842771.2795212, \"EndTime\": 1747842772.0779023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.1112003326416, \"count\": 1, \"min\": 798.1112003326416, \"max\": 798.1112003326416}}}\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1621.1540963236437 records/second\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] #progress_metric: host=algo-1, completed 42.5 % of epochs\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.5726813186298716\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] Epoch[170] Batch[0] avg_epoch_loss=2.643947\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.643946647644043\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] Epoch[170] Batch[5] avg_epoch_loss=2.632049\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.632049481074015\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] Epoch[170] Batch [5]#011Speed: 2783.86 samples/sec#011loss=2.632049\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] Epoch[170] Batch[10] avg_epoch_loss=2.611283\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=2.586364269256592\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] Epoch[170] Batch [10]#011Speed: 2550.25 samples/sec#011loss=2.586364\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] processed a total of 1372 examples\n",
      "#metrics {\"StartTime\": 1747842772.077959, \"EndTime\": 1747842772.8933215, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 815.0639533996582, \"count\": 1, \"min\": 815.0639533996582, \"max\": 815.0639533996582}}}\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1683.106067310963 records/second\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] #progress_metric: host=algo-1, completed 42.75 % of epochs\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.611283475702459\n",
      "[05/21/2025 15:52:52 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] Epoch[171] Batch[0] avg_epoch_loss=2.685653\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.6856532096862793\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] Epoch[171] Batch[5] avg_epoch_loss=2.546114\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.546113888422648\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] Epoch[171] Batch [5]#011Speed: 2707.18 samples/sec#011loss=2.546114\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] Epoch[171] Batch[10] avg_epoch_loss=2.542910\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=2.5390645027160645\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] Epoch[171] Batch [10]#011Speed: 2406.13 samples/sec#011loss=2.539065\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747842772.8933861, \"EndTime\": 1747842773.7131956, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 819.3953037261963, \"count\": 1, \"min\": 819.3953037261963, \"max\": 819.3953037261963}}}\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1631.473653800668 records/second\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] #progress_metric: host=algo-1, completed 43.0 % of epochs\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.542909622192383\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:52:53 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_305bc214-7ca2-44a5-abe5-1e200cf7748c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842773.7132702, \"EndTime\": 1747842773.7230043, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.412288665771484, \"count\": 1, \"min\": 9.412288665771484, \"max\": 9.412288665771484}}}\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] Epoch[172] Batch[0] avg_epoch_loss=2.572824\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.572824001312256\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] Epoch[172] Batch[5] avg_epoch_loss=2.593623\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.5936229626337686\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] Epoch[172] Batch [5]#011Speed: 2766.43 samples/sec#011loss=2.593623\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] Epoch[172] Batch[10] avg_epoch_loss=2.524430\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=2.441398048400879\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] Epoch[172] Batch [10]#011Speed: 2671.20 samples/sec#011loss=2.441398\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747842773.7230587, \"EndTime\": 1747842774.513481, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.3697490692139, \"count\": 1, \"min\": 790.3697490692139, \"max\": 790.3697490692139}}}\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1630.6692645779622 records/second\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] #progress_metric: host=algo-1, completed 43.25 % of epochs\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.524429819800637\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_27fb6936-2255-4640-9702-a73a822a243d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842774.5135527, \"EndTime\": 1747842774.5220277, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.098602294921875, \"count\": 1, \"min\": 8.098602294921875, \"max\": 8.098602294921875}}}\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] Epoch[173] Batch[0] avg_epoch_loss=2.458291\n",
      "[05/21/2025 15:52:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.4582912921905518\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] Epoch[173] Batch[5] avg_epoch_loss=2.517450\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.5174497763315835\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] Epoch[173] Batch [5]#011Speed: 2625.15 samples/sec#011loss=2.517450\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] Epoch[173] Batch[10] avg_epoch_loss=2.494258\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=2.4664275646209717\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] Epoch[173] Batch [10]#011Speed: 2448.33 samples/sec#011loss=2.466428\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747842774.5220873, \"EndTime\": 1747842775.3539104, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 831.7692279815674, \"count\": 1, \"min\": 831.7692279815674, \"max\": 831.7692279815674}}}\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1600.0346866965067 records/second\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] #progress_metric: host=algo-1, completed 43.5 % of epochs\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.494257861917669\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_cbb56ea1-ba03-4711-b7cb-37e61c8629eb-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842775.3539684, \"EndTime\": 1747842775.3619108, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 7.566690444946289, \"count\": 1, \"min\": 7.566690444946289, \"max\": 7.566690444946289}}}\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] Epoch[174] Batch[0] avg_epoch_loss=2.449552\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.449552297592163\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] Epoch[174] Batch[5] avg_epoch_loss=2.565004\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.565003991127014\n",
      "[05/21/2025 15:52:55 INFO 140269512570688] Epoch[174] Batch [5]#011Speed: 2828.15 samples/sec#011loss=2.565004\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] Epoch[174] Batch[10] avg_epoch_loss=2.505626\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=2.4343731880187987\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] Epoch[174] Batch [10]#011Speed: 2659.00 samples/sec#011loss=2.434373\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747842775.361961, \"EndTime\": 1747842776.1633444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.3293743133545, \"count\": 1, \"min\": 801.3293743133545, \"max\": 801.3293743133545}}}\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1615.9044574921043 records/second\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] #progress_metric: host=algo-1, completed 43.75 % of epochs\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.5056263533505527\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] Epoch[175] Batch[0] avg_epoch_loss=2.648905\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.6489052772521973\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] Epoch[175] Batch[5] avg_epoch_loss=2.587420\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.587419788042704\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] Epoch[175] Batch [5]#011Speed: 2752.60 samples/sec#011loss=2.587420\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] Epoch[175] Batch[10] avg_epoch_loss=2.561720\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=2.530880498886108\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] Epoch[175] Batch [10]#011Speed: 2537.93 samples/sec#011loss=2.530880\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747842776.1633954, \"EndTime\": 1747842776.9643672, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.6751537322998, \"count\": 1, \"min\": 800.6751537322998, \"max\": 800.6751537322998}}}\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1653.4277018573623 records/second\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] #progress_metric: host=algo-1, completed 44.0 % of epochs\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.5617201111533423\n",
      "[05/21/2025 15:52:56 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] Epoch[176] Batch[0] avg_epoch_loss=2.541865\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.541865348815918\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] Epoch[176] Batch[5] avg_epoch_loss=2.531919\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.5319193998972573\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] Epoch[176] Batch [5]#011Speed: 2846.90 samples/sec#011loss=2.531919\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] Epoch[176] Batch[10] avg_epoch_loss=2.464903\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.3844841718673706\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] Epoch[176] Batch [10]#011Speed: 2423.74 samples/sec#011loss=2.384484\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747842776.9644227, \"EndTime\": 1747842777.766638, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.9332885742188, \"count\": 1, \"min\": 801.9332885742188, \"max\": 801.9332885742188}}}\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1653.323237175676 records/second\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] #progress_metric: host=algo-1, completed 44.25 % of epochs\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.4649033871564\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:52:57 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_7a7f4a87-810c-4199-a7f7-9dd766b3f709-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842777.7666957, \"EndTime\": 1747842777.776376, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.418487548828125, \"count\": 1, \"min\": 9.418487548828125, \"max\": 9.418487548828125}}}\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] Epoch[177] Batch[0] avg_epoch_loss=2.620293\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.620292901992798\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] Epoch[177] Batch[5] avg_epoch_loss=2.559347\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.5593473513921103\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] Epoch[177] Batch [5]#011Speed: 3001.12 samples/sec#011loss=2.559347\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] Epoch[177] Batch[10] avg_epoch_loss=2.508294\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=2.4470299243927003\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] Epoch[177] Batch [10]#011Speed: 2558.10 samples/sec#011loss=2.447030\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747842777.7764316, \"EndTime\": 1747842778.5526538, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 776.1695384979248, \"count\": 1, \"min\": 776.1695384979248, \"max\": 776.1695384979248}}}\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1681.150373819892 records/second\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] #progress_metric: host=algo-1, completed 44.5 % of epochs\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.5082939754832876\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] Epoch[178] Batch[0] avg_epoch_loss=2.592478\n",
      "[05/21/2025 15:52:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.592477560043335\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] Epoch[178] Batch[5] avg_epoch_loss=2.528185\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.528185486793518\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] Epoch[178] Batch [5]#011Speed: 2530.18 samples/sec#011loss=2.528185\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] Epoch[178] Batch[10] avg_epoch_loss=2.597827\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=2.681397819519043\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] Epoch[178] Batch [10]#011Speed: 2892.57 samples/sec#011loss=2.681398\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842778.5527096, \"EndTime\": 1747842779.3417163, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.7628078460693, \"count\": 1, \"min\": 788.7628078460693, \"max\": 788.7628078460693}}}\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1645.455958068458 records/second\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] #progress_metric: host=algo-1, completed 44.75 % of epochs\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.5978274562142114\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] Epoch[179] Batch[0] avg_epoch_loss=2.598610\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.5986099243164062\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] Epoch[179] Batch[5] avg_epoch_loss=2.609055\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.6090546449025473\n",
      "[05/21/2025 15:52:59 INFO 140269512570688] Epoch[179] Batch [5]#011Speed: 2886.87 samples/sec#011loss=2.609055\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] Epoch[179] Batch[10] avg_epoch_loss=2.610311\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=2.6118183612823485\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] Epoch[179] Batch [10]#011Speed: 2281.29 samples/sec#011loss=2.611818\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747842779.3417654, \"EndTime\": 1747842780.1544557, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.4420642852783, \"count\": 1, \"min\": 812.4420642852783, \"max\": 812.4420642852783}}}\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1627.0096058905879 records/second\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] #progress_metric: host=algo-1, completed 45.0 % of epochs\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.6103108796206387\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] Epoch[180] Batch[0] avg_epoch_loss=2.488921\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.4889209270477295\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] Epoch[180] Batch[5] avg_epoch_loss=2.525250\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.5252495606740317\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] Epoch[180] Batch [5]#011Speed: 2757.60 samples/sec#011loss=2.525250\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] Epoch[180] Batch[10] avg_epoch_loss=2.541445\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=2.560879135131836\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] Epoch[180] Batch [10]#011Speed: 2667.42 samples/sec#011loss=2.560879\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842780.1545167, \"EndTime\": 1747842780.9428744, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.0463600158691, \"count\": 1, \"min\": 788.0463600158691, \"max\": 788.0463600158691}}}\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1646.924866290748 records/second\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] #progress_metric: host=algo-1, completed 45.25 % of epochs\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.5414448217912153\n",
      "[05/21/2025 15:53:00 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] Epoch[181] Batch[0] avg_epoch_loss=2.510652\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.5106518268585205\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] Epoch[181] Batch[5] avg_epoch_loss=2.528795\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.52879536151886\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] Epoch[181] Batch [5]#011Speed: 2666.74 samples/sec#011loss=2.528795\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] Epoch[181] Batch[10] avg_epoch_loss=2.528865\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=2.528949165344238\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] Epoch[181] Batch [10]#011Speed: 2407.82 samples/sec#011loss=2.528949\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747842780.9429336, \"EndTime\": 1747842781.7614703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 818.2494640350342, \"count\": 1, \"min\": 818.2494640350342, \"max\": 818.2494640350342}}}\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1633.808922081683 records/second\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] #progress_metric: host=algo-1, completed 45.5 % of epochs\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.528865272348577\n",
      "[05/21/2025 15:53:01 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] Epoch[182] Batch[0] avg_epoch_loss=2.568408\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.5684075355529785\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] Epoch[182] Batch[5] avg_epoch_loss=2.519508\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.519507726033529\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] Epoch[182] Batch [5]#011Speed: 2486.09 samples/sec#011loss=2.519508\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] Epoch[182] Batch[10] avg_epoch_loss=2.543183\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=2.571592378616333\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] Epoch[182] Batch [10]#011Speed: 2662.05 samples/sec#011loss=2.571592\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747842781.761527, \"EndTime\": 1747842782.6063104, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 844.5160388946533, \"count\": 1, \"min\": 844.5160388946533, \"max\": 844.5160388946533}}}\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1575.8530593764299 records/second\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] #progress_metric: host=algo-1, completed 45.75 % of epochs\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.5431825681166216\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] Epoch[183] Batch[0] avg_epoch_loss=2.566273\n",
      "[05/21/2025 15:53:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.5662729740142822\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] Epoch[183] Batch[5] avg_epoch_loss=2.506997\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.506997307141622\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] Epoch[183] Batch [5]#011Speed: 2462.93 samples/sec#011loss=2.506997\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] Epoch[183] Batch[10] avg_epoch_loss=2.492886\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=2.4759534358978272\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] Epoch[183] Batch [10]#011Speed: 2539.38 samples/sec#011loss=2.475953\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747842782.6063833, \"EndTime\": 1747842783.436816, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 830.1160335540771, \"count\": 1, \"min\": 830.1160335540771, \"max\": 830.1160335540771}}}\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1559.8288893892122 records/second\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] #progress_metric: host=algo-1, completed 46.0 % of epochs\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.4928864565762607\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] Epoch[184] Batch[0] avg_epoch_loss=2.522778\n",
      "[05/21/2025 15:53:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.522778272628784\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] Epoch[184] Batch[5] avg_epoch_loss=2.519081\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.5190812746683755\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] Epoch[184] Batch [5]#011Speed: 2622.79 samples/sec#011loss=2.519081\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] Epoch[184] Batch[10] avg_epoch_loss=2.530776\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=2.544809103012085\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] Epoch[184] Batch [10]#011Speed: 2541.80 samples/sec#011loss=2.544809\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747842783.4368887, \"EndTime\": 1747842784.2839088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 846.6687202453613, \"count\": 1, \"min\": 846.6687202453613, \"max\": 846.6687202453613}}}\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1578.9619581682887 records/second\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] #progress_metric: host=algo-1, completed 46.25 % of epochs\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.5307757420973345\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] Epoch[185] Batch[0] avg_epoch_loss=2.522172\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.522172451019287\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] Epoch[185] Batch[5] avg_epoch_loss=2.526669\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.5266693830490112\n",
      "[05/21/2025 15:53:04 INFO 140269512570688] Epoch[185] Batch [5]#011Speed: 2643.44 samples/sec#011loss=2.526669\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] Epoch[185] Batch[10] avg_epoch_loss=2.570237\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=2.6225175857543945\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] Epoch[185] Batch [10]#011Speed: 2197.08 samples/sec#011loss=2.622518\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747842784.2839677, \"EndTime\": 1747842785.1452234, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 861.0031604766846, \"count\": 1, \"min\": 861.0031604766846, \"max\": 861.0031604766846}}}\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1535.2622682654812 records/second\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] #progress_metric: host=algo-1, completed 46.5 % of epochs\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.5702367479150947\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] Epoch[186] Batch[0] avg_epoch_loss=2.534852\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.5348520278930664\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] Epoch[186] Batch[5] avg_epoch_loss=2.528466\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.5284661054611206\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] Epoch[186] Batch [5]#011Speed: 2774.87 samples/sec#011loss=2.528466\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] Epoch[186] Batch[10] avg_epoch_loss=2.511940\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=2.492109251022339\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] Epoch[186] Batch [10]#011Speed: 2906.05 samples/sec#011loss=2.492109\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842785.1452818, \"EndTime\": 1747842785.9090133, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 763.4382247924805, \"count\": 1, \"min\": 763.4382247924805, \"max\": 763.4382247924805}}}\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1700.0182960492625 records/second\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] #progress_metric: host=algo-1, completed 46.75 % of epochs\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.511940262534402\n",
      "[05/21/2025 15:53:05 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] Epoch[187] Batch[0] avg_epoch_loss=2.484927\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.484926700592041\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] Epoch[187] Batch[5] avg_epoch_loss=2.491602\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.491601745287577\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] Epoch[187] Batch [5]#011Speed: 2876.16 samples/sec#011loss=2.491602\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] Epoch[187] Batch[10] avg_epoch_loss=2.467387\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=2.438329792022705\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] Epoch[187] Batch [10]#011Speed: 2802.77 samples/sec#011loss=2.438330\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747842785.9090686, \"EndTime\": 1747842786.673398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 764.0829086303711, \"count\": 1, \"min\": 764.0829086303711, \"max\": 764.0829086303711}}}\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1701.094109653061 records/second\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] #progress_metric: host=algo-1, completed 47.0 % of epochs\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.467387221076272\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] Epoch[188] Batch[0] avg_epoch_loss=2.506236\n",
      "[05/21/2025 15:53:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.5062355995178223\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] Epoch[188] Batch[5] avg_epoch_loss=2.516120\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.516120354334513\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] Epoch[188] Batch [5]#011Speed: 2587.31 samples/sec#011loss=2.516120\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] processed a total of 1252 examples\n",
      "#metrics {\"StartTime\": 1747842786.6734834, \"EndTime\": 1747842787.4139736, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 740.1845455169678, \"count\": 1, \"min\": 740.1845455169678, \"max\": 740.1845455169678}}}\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1691.252157596928 records/second\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] #progress_metric: host=algo-1, completed 47.25 % of epochs\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.4999346017837523\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] Epoch[189] Batch[0] avg_epoch_loss=2.513030\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.5130302906036377\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] Epoch[189] Batch[5] avg_epoch_loss=2.464661\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.4646610418955484\n",
      "[05/21/2025 15:53:07 INFO 140269512570688] Epoch[189] Batch [5]#011Speed: 2887.66 samples/sec#011loss=2.464661\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] Epoch[189] Batch[10] avg_epoch_loss=2.518848\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=2.5838719844818114\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] Epoch[189] Batch [10]#011Speed: 2703.88 samples/sec#011loss=2.583872\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747842787.414037, \"EndTime\": 1747842788.1891208, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 774.7931480407715, \"count\": 1, \"min\": 774.7931480407715, \"max\": 774.7931480407715}}}\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1682.8672505378408 records/second\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] #progress_metric: host=algo-1, completed 47.5 % of epochs\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.5188478339802134\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] Epoch[190] Batch[0] avg_epoch_loss=2.513112\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.5131118297576904\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] Epoch[190] Batch[5] avg_epoch_loss=2.516130\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.5161298910776773\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] Epoch[190] Batch [5]#011Speed: 2771.19 samples/sec#011loss=2.516130\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] Epoch[190] Batch[10] avg_epoch_loss=2.512119\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=2.5073051929473875\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] Epoch[190] Batch [10]#011Speed: 2756.07 samples/sec#011loss=2.507305\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747842788.1891708, \"EndTime\": 1747842788.9739358, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.5427989959717, \"count\": 1, \"min\": 784.5427989959717, \"max\": 784.5427989959717}}}\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1642.8208960303377 records/second\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] #progress_metric: host=algo-1, completed 47.75 % of epochs\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.5121186646548184\n",
      "[05/21/2025 15:53:08 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:09 INFO 140269512570688] Epoch[191] Batch[0] avg_epoch_loss=2.514032\n",
      "[05/21/2025 15:53:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.5140323638916016\n",
      "[05/21/2025 15:53:09 INFO 140269512570688] Epoch[191] Batch[5] avg_epoch_loss=2.538014\n",
      "[05/21/2025 15:53:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.5380138556162515\n",
      "[05/21/2025 15:53:09 INFO 140269512570688] Epoch[191] Batch [5]#011Speed: 2639.04 samples/sec#011loss=2.538014\n",
      "[05/21/2025 15:53:09 INFO 140269512570688] processed a total of 1237 examples\n",
      "#metrics {\"StartTime\": 1747842788.9739919, \"EndTime\": 1747842789.709972, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 735.729455947876, \"count\": 1, \"min\": 735.729455947876, \"max\": 735.729455947876}}}\n",
      "[05/21/2025 15:53:09 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1681.1164495480768 records/second\n",
      "[05/21/2025 15:53:09 INFO 140269512570688] #progress_metric: host=algo-1, completed 48.0 % of epochs\n",
      "[05/21/2025 15:53:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.570986294746399\n",
      "[05/21/2025 15:53:09 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] Epoch[192] Batch[0] avg_epoch_loss=2.514854\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.5148541927337646\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] Epoch[192] Batch[5] avg_epoch_loss=2.489479\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.4894785483678183\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] Epoch[192] Batch [5]#011Speed: 2877.38 samples/sec#011loss=2.489479\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] processed a total of 1248 examples\n",
      "#metrics {\"StartTime\": 1747842789.7100327, \"EndTime\": 1747842790.426771, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 716.4463996887207, \"count\": 1, \"min\": 716.4463996887207, \"max\": 716.4463996887207}}}\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1741.7145366938546 records/second\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] #progress_metric: host=algo-1, completed 48.25 % of epochs\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.473927879333496\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] Epoch[193] Batch[0] avg_epoch_loss=2.502100\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.5021004676818848\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] Epoch[193] Batch[5] avg_epoch_loss=2.487778\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.487778425216675\n",
      "[05/21/2025 15:53:10 INFO 140269512570688] Epoch[193] Batch [5]#011Speed: 2865.42 samples/sec#011loss=2.487778\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] Epoch[193] Batch[10] avg_epoch_loss=2.457886\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=2.422013998031616\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] Epoch[193] Batch [10]#011Speed: 2710.01 samples/sec#011loss=2.422014\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747842790.426829, \"EndTime\": 1747842791.1934524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 766.3397789001465, \"count\": 1, \"min\": 766.3397789001465, \"max\": 766.3397789001465}}}\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1753.5817555027832 records/second\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] #progress_metric: host=algo-1, completed 48.5 % of epochs\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.457885503768921\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_1f77526a-c646-4616-afc5-c5201c4e05ba-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842791.1935158, \"EndTime\": 1747842791.2030642, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.27114486694336, \"count\": 1, \"min\": 9.27114486694336, \"max\": 9.27114486694336}}}\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] Epoch[194] Batch[0] avg_epoch_loss=2.526833\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.5268332958221436\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] Epoch[194] Batch[5] avg_epoch_loss=2.501231\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.5012309551239014\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] Epoch[194] Batch [5]#011Speed: 2676.86 samples/sec#011loss=2.501231\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] Epoch[194] Batch[10] avg_epoch_loss=2.523095\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=2.5493317604064942\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] Epoch[194] Batch [10]#011Speed: 2579.80 samples/sec#011loss=2.549332\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747842791.2031145, \"EndTime\": 1747842791.998986, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.8238124847412, \"count\": 1, \"min\": 795.8238124847412, \"max\": 795.8238124847412}}}\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1715.0249634916236 records/second\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] #progress_metric: host=algo-1, completed 48.75 % of epochs\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.52309495752508\n",
      "[05/21/2025 15:53:11 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] Epoch[195] Batch[0] avg_epoch_loss=2.553110\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.553109884262085\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] Epoch[195] Batch[5] avg_epoch_loss=2.512518\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.512518366177877\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] Epoch[195] Batch [5]#011Speed: 2880.62 samples/sec#011loss=2.512518\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] Epoch[195] Batch[10] avg_epoch_loss=2.516521\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=2.521324300765991\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] Epoch[195] Batch [10]#011Speed: 2611.18 samples/sec#011loss=2.521324\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] processed a total of 1390 examples\n",
      "#metrics {\"StartTime\": 1747842791.9990416, \"EndTime\": 1747842792.7727654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 773.4715938568115, \"count\": 1, \"min\": 773.4715938568115, \"max\": 773.4715938568115}}}\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1796.9014091452664 records/second\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] #progress_metric: host=algo-1, completed 49.0 % of epochs\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.5165210637179287\n",
      "[05/21/2025 15:53:12 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] Epoch[196] Batch[0] avg_epoch_loss=2.456893\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.456892728805542\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] Epoch[196] Batch[5] avg_epoch_loss=2.477228\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.477227807044983\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] Epoch[196] Batch [5]#011Speed: 2655.84 samples/sec#011loss=2.477228\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] Epoch[196] Batch[10] avg_epoch_loss=2.474285\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.470753002166748\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] Epoch[196] Batch [10]#011Speed: 2358.32 samples/sec#011loss=2.470753\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] processed a total of 1382 examples\n",
      "#metrics {\"StartTime\": 1747842792.772821, \"EndTime\": 1747842793.594104, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 821.0413455963135, \"count\": 1, \"min\": 821.0413455963135, \"max\": 821.0413455963135}}}\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1683.0479230072826 records/second\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] #progress_metric: host=algo-1, completed 49.25 % of epochs\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.4742847139185127\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] Epoch[197] Batch[0] avg_epoch_loss=2.464634\n",
      "[05/21/2025 15:53:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.4646339416503906\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] Epoch[197] Batch[5] avg_epoch_loss=2.497453\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.4974529345830283\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] Epoch[197] Batch [5]#011Speed: 2566.96 samples/sec#011loss=2.497453\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] Epoch[197] Batch[10] avg_epoch_loss=2.509107\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=2.523091268539429\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] Epoch[197] Batch [10]#011Speed: 2542.85 samples/sec#011loss=2.523091\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747842793.594163, \"EndTime\": 1747842794.4115398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.1243667602539, \"count\": 1, \"min\": 817.1243667602539, \"max\": 817.1243667602539}}}\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1617.6955504305447 records/second\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] #progress_metric: host=algo-1, completed 49.5 % of epochs\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.5091067227450283\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] Epoch[198] Batch[0] avg_epoch_loss=2.379200\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.379199743270874\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] Epoch[198] Batch[5] avg_epoch_loss=2.467629\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.467629154523214\n",
      "[05/21/2025 15:53:14 INFO 140269512570688] Epoch[198] Batch [5]#011Speed: 2576.15 samples/sec#011loss=2.467629\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] Epoch[198] Batch[10] avg_epoch_loss=2.585712\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.727410888671875\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] Epoch[198] Batch [10]#011Speed: 2351.58 samples/sec#011loss=2.727411\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842794.4115987, \"EndTime\": 1747842795.2529347, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 841.0868644714355, \"count\": 1, \"min\": 841.0868644714355, \"max\": 841.0868644714355}}}\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1542.9950687816952 records/second\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] #progress_metric: host=algo-1, completed 49.75 % of epochs\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.5857117609544233\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] Epoch[199] Batch[0] avg_epoch_loss=2.542814\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.542813539505005\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] Epoch[199] Batch[5] avg_epoch_loss=2.551725\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.551725228627523\n",
      "[05/21/2025 15:53:15 INFO 140269512570688] Epoch[199] Batch [5]#011Speed: 2798.65 samples/sec#011loss=2.551725\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] processed a total of 1260 examples\n",
      "#metrics {\"StartTime\": 1747842795.2530332, \"EndTime\": 1747842796.0145361, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 761.1539363861084, \"count\": 1, \"min\": 761.1539363861084, \"max\": 761.1539363861084}}}\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1655.1604494545304 records/second\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] #progress_metric: host=algo-1, completed 50.0 % of epochs\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.566812014579773\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] Epoch[200] Batch[0] avg_epoch_loss=2.578381\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.578380823135376\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] Epoch[200] Batch[5] avg_epoch_loss=2.547584\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.5475844542185464\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] Epoch[200] Batch [5]#011Speed: 2790.30 samples/sec#011loss=2.547584\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] processed a total of 1207 examples\n",
      "#metrics {\"StartTime\": 1747842796.0146046, \"EndTime\": 1747842796.7406518, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 725.6269454956055, \"count\": 1, \"min\": 725.6269454956055, \"max\": 725.6269454956055}}}\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1663.1689406659805 records/second\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] #progress_metric: host=algo-1, completed 50.25 % of epochs\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.540598225593567\n",
      "[05/21/2025 15:53:16 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] Epoch[201] Batch[0] avg_epoch_loss=2.589320\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.589320421218872\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] Epoch[201] Batch[5] avg_epoch_loss=2.582779\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.582778970400492\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] Epoch[201] Batch [5]#011Speed: 2855.27 samples/sec#011loss=2.582779\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] Epoch[201] Batch[10] avg_epoch_loss=2.538327\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=2.484984302520752\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] Epoch[201] Batch [10]#011Speed: 2675.30 samples/sec#011loss=2.484984\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747842796.740716, \"EndTime\": 1747842797.5426862, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.6221523284912, \"count\": 1, \"min\": 801.6221523284912, \"max\": 801.6221523284912}}}\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1641.4876315305046 records/second\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] #progress_metric: host=algo-1, completed 50.5 % of epochs\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.538326848636974\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] Epoch[202] Batch[0] avg_epoch_loss=2.550066\n",
      "[05/21/2025 15:53:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.5500662326812744\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] Epoch[202] Batch[5] avg_epoch_loss=2.536080\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.5360802014668784\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] Epoch[202] Batch [5]#011Speed: 2847.28 samples/sec#011loss=2.536080\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] Epoch[202] Batch[10] avg_epoch_loss=2.538416\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=2.541218948364258\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] Epoch[202] Batch [10]#011Speed: 2573.14 samples/sec#011loss=2.541219\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747842797.5427468, \"EndTime\": 1747842798.3597546, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 816.7426586151123, \"count\": 1, \"min\": 816.7426586151123, \"max\": 816.7426586151123}}}\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1653.9314307129835 records/second\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] #progress_metric: host=algo-1, completed 50.75 % of epochs\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.5384159955111416\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] Epoch[203] Batch[0] avg_epoch_loss=2.637038\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.637038469314575\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] Epoch[203] Batch[5] avg_epoch_loss=2.509125\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.509125312169393\n",
      "[05/21/2025 15:53:18 INFO 140269512570688] Epoch[203] Batch [5]#011Speed: 2783.55 samples/sec#011loss=2.509125\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] Epoch[203] Batch[10] avg_epoch_loss=2.520534\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=2.5342240810394285\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] Epoch[203] Batch [10]#011Speed: 2406.75 samples/sec#011loss=2.534224\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747842798.3598201, \"EndTime\": 1747842799.1960945, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 835.9885215759277, \"count\": 1, \"min\": 835.9885215759277, \"max\": 835.9885215759277}}}\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1591.9623149962372 records/second\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] #progress_metric: host=algo-1, completed 51.0 % of epochs\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.5205338434739546\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] Epoch[204] Batch[0] avg_epoch_loss=2.529058\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.529057741165161\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] Epoch[204] Batch[5] avg_epoch_loss=2.463908\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.4639081160227456\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] Epoch[204] Batch [5]#011Speed: 2712.69 samples/sec#011loss=2.463908\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] processed a total of 1244 examples\n",
      "#metrics {\"StartTime\": 1747842799.1961522, \"EndTime\": 1747842799.9448822, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 748.4443187713623, \"count\": 1, \"min\": 748.4443187713623, \"max\": 748.4443187713623}}}\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1661.9072962937246 records/second\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] #progress_metric: host=algo-1, completed 51.25 % of epochs\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.4440758228302\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:53:19 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_9e6352ce-e09e-4435-bca0-c9c91d43de26-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842799.9449456, \"EndTime\": 1747842799.954793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.536981582641602, \"count\": 1, \"min\": 9.536981582641602, \"max\": 9.536981582641602}}}\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] Epoch[205] Batch[0] avg_epoch_loss=2.459562\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.459562063217163\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] Epoch[205] Batch[5] avg_epoch_loss=2.470968\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.4709675709406533\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] Epoch[205] Batch [5]#011Speed: 2684.57 samples/sec#011loss=2.470968\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] Epoch[205] Batch[10] avg_epoch_loss=2.571521\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=2.692184400558472\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] Epoch[205] Batch [10]#011Speed: 2508.37 samples/sec#011loss=2.692184\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747842799.954844, \"EndTime\": 1747842800.7642488, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.3552589416504, \"count\": 1, \"min\": 809.3552589416504, \"max\": 809.3552589416504}}}\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1639.4076426967404 records/second\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] #progress_metric: host=algo-1, completed 51.5 % of epochs\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.571520675312389\n",
      "[05/21/2025 15:53:20 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] Epoch[206] Batch[0] avg_epoch_loss=2.431085\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.431084632873535\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] Epoch[206] Batch[5] avg_epoch_loss=2.477696\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.477696259816488\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] Epoch[206] Batch [5]#011Speed: 2467.27 samples/sec#011loss=2.477696\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] Epoch[206] Batch[10] avg_epoch_loss=2.484680\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=2.493059825897217\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] Epoch[206] Batch [10]#011Speed: 2592.96 samples/sec#011loss=2.493060\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747842800.764304, \"EndTime\": 1747842801.5862472, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 821.6722011566162, \"count\": 1, \"min\": 821.6722011566162, \"max\": 821.6722011566162}}}\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1566.1576327009982 records/second\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] #progress_metric: host=algo-1, completed 51.75 % of epochs\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.484679698944092\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] Epoch[207] Batch[0] avg_epoch_loss=2.641701\n",
      "[05/21/2025 15:53:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.6417012214660645\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] Epoch[207] Batch[5] avg_epoch_loss=2.545017\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.545017123222351\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] Epoch[207] Batch [5]#011Speed: 2594.78 samples/sec#011loss=2.545017\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] Epoch[207] Batch[10] avg_epoch_loss=2.504970\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=2.456914281845093\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] Epoch[207] Batch [10]#011Speed: 2462.36 samples/sec#011loss=2.456914\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] processed a total of 1392 examples\n",
      "#metrics {\"StartTime\": 1747842801.5863028, \"EndTime\": 1747842802.4010284, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.4769668579102, \"count\": 1, \"min\": 814.4769668579102, \"max\": 814.4769668579102}}}\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1708.8991889384197 records/second\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] #progress_metric: host=algo-1, completed 52.0 % of epochs\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.5049703771417793\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] Epoch[208] Batch[0] avg_epoch_loss=2.535296\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.5352959632873535\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] Epoch[208] Batch[5] avg_epoch_loss=2.469802\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.469802220662435\n",
      "[05/21/2025 15:53:22 INFO 140269512570688] Epoch[208] Batch [5]#011Speed: 2635.23 samples/sec#011loss=2.469802\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] Epoch[208] Batch[10] avg_epoch_loss=2.461456\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.451441192626953\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] Epoch[208] Batch [10]#011Speed: 2497.50 samples/sec#011loss=2.451441\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747842802.4010825, \"EndTime\": 1747842803.2188938, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 817.56591796875, \"count\": 1, \"min\": 817.56591796875, \"max\": 817.56591796875}}}\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1659.9418866666433 records/second\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] #progress_metric: host=algo-1, completed 52.25 % of epochs\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.461456298828125\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] Epoch[209] Batch[0] avg_epoch_loss=2.394986\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.3949856758117676\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] Epoch[209] Batch[5] avg_epoch_loss=2.451464\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.451463977495829\n",
      "[05/21/2025 15:53:23 INFO 140269512570688] Epoch[209] Batch [5]#011Speed: 2664.39 samples/sec#011loss=2.451464\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] Epoch[209] Batch[10] avg_epoch_loss=2.385962\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=2.3073586940765383\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] Epoch[209] Batch [10]#011Speed: 2473.33 samples/sec#011loss=2.307359\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747842803.2193985, \"EndTime\": 1747842804.0342398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.5589828491211, \"count\": 1, \"min\": 814.5589828491211, \"max\": 814.5589828491211}}}\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1652.2542972846177 records/second\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] #progress_metric: host=algo-1, completed 52.5 % of epochs\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.385961575941606\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_38321560-86a6-4373-9fba-12c6688dc58d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842804.0342968, \"EndTime\": 1747842804.0434046, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.843183517456055, \"count\": 1, \"min\": 8.843183517456055, \"max\": 8.843183517456055}}}\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] Epoch[210] Batch[0] avg_epoch_loss=2.358082\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.358081817626953\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] Epoch[210] Batch[5] avg_epoch_loss=2.440741\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.4407405058542886\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] Epoch[210] Batch [5]#011Speed: 2637.39 samples/sec#011loss=2.440741\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] Epoch[210] Batch[10] avg_epoch_loss=2.471571\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=2.508568286895752\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] Epoch[210] Batch [10]#011Speed: 2367.25 samples/sec#011loss=2.508568\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747842804.0434582, \"EndTime\": 1747842804.8695924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 826.0829448699951, \"count\": 1, \"min\": 826.0829448699951, \"max\": 826.0829448699951}}}\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1658.2486768516862 records/second\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] #progress_metric: host=algo-1, completed 52.75 % of epochs\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.4715713154185903\n",
      "[05/21/2025 15:53:24 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] Epoch[211] Batch[0] avg_epoch_loss=2.493736\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.4937355518341064\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] Epoch[211] Batch[5] avg_epoch_loss=2.491730\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.4917301734288535\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] Epoch[211] Batch [5]#011Speed: 2498.16 samples/sec#011loss=2.491730\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] Epoch[211] Batch[10] avg_epoch_loss=2.468293\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=2.440168619155884\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] Epoch[211] Batch [10]#011Speed: 2338.90 samples/sec#011loss=2.440169\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747842804.8696527, \"EndTime\": 1747842805.7127457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 842.8287506103516, \"count\": 1, \"min\": 842.8287506103516, \"max\": 842.8287506103516}}}\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1607.5148425403754 records/second\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] #progress_metric: host=algo-1, completed 53.0 % of epochs\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.4682931033047764\n",
      "[05/21/2025 15:53:25 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] Epoch[212] Batch[0] avg_epoch_loss=2.519990\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.5199904441833496\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] Epoch[212] Batch[5] avg_epoch_loss=2.442949\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.4429489771525064\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] Epoch[212] Batch [5]#011Speed: 2824.86 samples/sec#011loss=2.442949\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] Epoch[212] Batch[10] avg_epoch_loss=2.568803\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.719828414916992\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] Epoch[212] Batch [10]#011Speed: 2544.83 samples/sec#011loss=2.719828\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747842805.7128017, \"EndTime\": 1747842806.5044403, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.3069725036621, \"count\": 1, \"min\": 791.3069725036621, \"max\": 791.3069725036621}}}\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1726.0219097461136 records/second\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] #progress_metric: host=algo-1, completed 53.25 % of epochs\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.5688032670454546\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] Epoch[213] Batch[0] avg_epoch_loss=2.503808\n",
      "[05/21/2025 15:53:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.503807544708252\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] Epoch[213] Batch[5] avg_epoch_loss=2.530545\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.5305445988972983\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] Epoch[213] Batch [5]#011Speed: 2721.66 samples/sec#011loss=2.530545\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] processed a total of 1242 examples\n",
      "#metrics {\"StartTime\": 1747842806.5045187, \"EndTime\": 1747842807.2367902, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 731.935977935791, \"count\": 1, \"min\": 731.935977935791, \"max\": 731.935977935791}}}\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1696.6464480130383 records/second\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] #progress_metric: host=algo-1, completed 53.5 % of epochs\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.5101035594940186\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] Epoch[214] Batch[0] avg_epoch_loss=2.446208\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.4462084770202637\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] Epoch[214] Batch[5] avg_epoch_loss=2.417509\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.4175087213516235\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] Epoch[214] Batch [5]#011Speed: 2808.65 samples/sec#011loss=2.417509\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] processed a total of 1264 examples\n",
      "#metrics {\"StartTime\": 1747842807.2368536, \"EndTime\": 1747842807.9640253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 726.8369197845459, \"count\": 1, \"min\": 726.8369197845459, \"max\": 726.8369197845459}}}\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1738.8190803046016 records/second\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] #progress_metric: host=algo-1, completed 53.75 % of epochs\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.4097121000289916\n",
      "[05/21/2025 15:53:27 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] Epoch[215] Batch[0] avg_epoch_loss=2.456296\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.4562957286834717\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] Epoch[215] Batch[5] avg_epoch_loss=2.442694\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.4426939487457275\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] Epoch[215] Batch [5]#011Speed: 2765.72 samples/sec#011loss=2.442694\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] Epoch[215] Batch[10] avg_epoch_loss=2.464493\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=2.4906520366668703\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] Epoch[215] Batch [10]#011Speed: 2640.86 samples/sec#011loss=2.490652\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747842807.9640875, \"EndTime\": 1747842808.7506483, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.2775325775146, \"count\": 1, \"min\": 786.2775325775146, \"max\": 786.2775325775146}}}\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1691.2413579835195 records/second\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] #progress_metric: host=algo-1, completed 54.0 % of epochs\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.464493079618974\n",
      "[05/21/2025 15:53:28 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] Epoch[216] Batch[0] avg_epoch_loss=2.393878\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.3938777446746826\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] Epoch[216] Batch[5] avg_epoch_loss=2.411664\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.41166361172994\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] Epoch[216] Batch [5]#011Speed: 2910.91 samples/sec#011loss=2.411664\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] Epoch[216] Batch[10] avg_epoch_loss=2.423206\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=2.4370569705963137\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] Epoch[216] Batch [10]#011Speed: 2587.61 samples/sec#011loss=2.437057\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747842808.7507458, \"EndTime\": 1747842809.5358346, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.8296165466309, \"count\": 1, \"min\": 784.8296165466309, \"max\": 784.8296165466309}}}\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1635.8504533341757 records/second\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] #progress_metric: host=algo-1, completed 54.25 % of epochs\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.4232060475782915\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] Epoch[217] Batch[0] avg_epoch_loss=2.555771\n",
      "[05/21/2025 15:53:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.5557711124420166\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] Epoch[217] Batch[5] avg_epoch_loss=2.502952\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.5029520988464355\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] Epoch[217] Batch [5]#011Speed: 2597.96 samples/sec#011loss=2.502952\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] Epoch[217] Batch[10] avg_epoch_loss=2.506364\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=2.510459136962891\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] Epoch[217] Batch [10]#011Speed: 2701.20 samples/sec#011loss=2.510459\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747842809.5358915, \"EndTime\": 1747842810.327514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.3801670074463, \"count\": 1, \"min\": 791.3801670074463, \"max\": 791.3801670074463}}}\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1710.7561238641827 records/second\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] #progress_metric: host=algo-1, completed 54.5 % of epochs\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.5063643888993696\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] Epoch[218] Batch[0] avg_epoch_loss=2.385363\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=2.3853626251220703\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] Epoch[218] Batch[5] avg_epoch_loss=2.427196\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.4271957079569497\n",
      "[05/21/2025 15:53:30 INFO 140269512570688] Epoch[218] Batch [5]#011Speed: 2691.03 samples/sec#011loss=2.427196\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] Epoch[218] Batch[10] avg_epoch_loss=2.491949\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=2.5696523189544678\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] Epoch[218] Batch [10]#011Speed: 2685.05 samples/sec#011loss=2.569652\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747842810.3275702, \"EndTime\": 1747842811.1191835, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.3386821746826, \"count\": 1, \"min\": 791.3386821746826, \"max\": 791.3386821746826}}}\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1666.6100241453116 records/second\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] #progress_metric: host=algo-1, completed 54.75 % of epochs\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.4919487129558218\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] Epoch[219] Batch[0] avg_epoch_loss=2.641835\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.6418347358703613\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] Epoch[219] Batch[5] avg_epoch_loss=2.526737\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.5267367362976074\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] Epoch[219] Batch [5]#011Speed: 2706.73 samples/sec#011loss=2.526737\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747842811.119243, \"EndTime\": 1747842811.8546312, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 735.1377010345459, \"count\": 1, \"min\": 735.1377010345459, \"max\": 735.1377010345459}}}\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1738.066507547978 records/second\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] #progress_metric: host=algo-1, completed 55.0 % of epochs\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.510485219955444\n",
      "[05/21/2025 15:53:31 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] Epoch[220] Batch[0] avg_epoch_loss=2.518833\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.5188329219818115\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] Epoch[220] Batch[5] avg_epoch_loss=2.447947\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.4479465087254844\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] Epoch[220] Batch [5]#011Speed: 2792.75 samples/sec#011loss=2.447947\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] Epoch[220] Batch[10] avg_epoch_loss=2.467311\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=2.4905489921569823\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] Epoch[220] Batch [10]#011Speed: 2764.76 samples/sec#011loss=2.490549\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747842811.8547602, \"EndTime\": 1747842812.6541102, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.0293502807617, \"count\": 1, \"min\": 799.0293502807617, \"max\": 799.0293502807617}}}\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1633.05327564386 records/second\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] #progress_metric: host=algo-1, completed 55.25 % of epochs\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.4673112739216196\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] Epoch[221] Batch[0] avg_epoch_loss=2.476603\n",
      "[05/21/2025 15:53:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.476602792739868\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] Epoch[221] Batch[5] avg_epoch_loss=2.428170\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.428170124689738\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] Epoch[221] Batch [5]#011Speed: 2931.52 samples/sec#011loss=2.428170\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] Epoch[221] Batch[10] avg_epoch_loss=2.512046\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=2.6126966953277586\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] Epoch[221] Batch [10]#011Speed: 2767.10 samples/sec#011loss=2.612697\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747842812.6541681, \"EndTime\": 1747842813.4424305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 787.9688739776611, \"count\": 1, \"min\": 787.9688739776611, \"max\": 787.9688739776611}}}\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1652.0790991558972 records/second\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] #progress_metric: host=algo-1, completed 55.5 % of epochs\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.512045838616111\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] Epoch[222] Batch[0] avg_epoch_loss=3.001606\n",
      "[05/21/2025 15:53:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=3.001605749130249\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] Epoch[222] Batch[5] avg_epoch_loss=2.923398\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.9233982960383096\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] Epoch[222] Batch [5]#011Speed: 2785.41 samples/sec#011loss=2.923398\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] Epoch[222] Batch[10] avg_epoch_loss=2.898160\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=2.867873525619507\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] Epoch[222] Batch [10]#011Speed: 2525.10 samples/sec#011loss=2.867874\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747842813.442531, \"EndTime\": 1747842814.264723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 821.8913078308105, \"count\": 1, \"min\": 821.8913078308105, \"max\": 821.8913078308105}}}\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1586.4068535999036 records/second\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] #progress_metric: host=algo-1, completed 55.75 % of epochs\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.898159764029763\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] Epoch[223] Batch[0] avg_epoch_loss=2.642647\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.642646551132202\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] Epoch[223] Batch[5] avg_epoch_loss=2.715709\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.71570885181427\n",
      "[05/21/2025 15:53:34 INFO 140269512570688] Epoch[223] Batch [5]#011Speed: 2722.64 samples/sec#011loss=2.715709\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] Epoch[223] Batch[10] avg_epoch_loss=2.699273\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=2.679551029205322\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] Epoch[223] Batch [10]#011Speed: 2492.81 samples/sec#011loss=2.679551\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747842814.264784, \"EndTime\": 1747842815.0939357, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 828.8826942443848, \"count\": 1, \"min\": 828.8826942443848, \"max\": 828.8826942443848}}}\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1624.9038996986162 records/second\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] #progress_metric: host=algo-1, completed 56.0 % of epochs\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.699273477901112\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] Epoch[224] Batch[0] avg_epoch_loss=2.595428\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.595428228378296\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] Epoch[224] Batch[5] avg_epoch_loss=2.717868\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.717867890993754\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] Epoch[224] Batch [5]#011Speed: 2649.31 samples/sec#011loss=2.717868\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] processed a total of 1260 examples\n",
      "#metrics {\"StartTime\": 1747842815.093994, \"EndTime\": 1747842815.8387113, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 744.4095611572266, \"count\": 1, \"min\": 744.4095611572266, \"max\": 744.4095611572266}}}\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1692.3976425408398 records/second\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] #progress_metric: host=algo-1, completed 56.25 % of epochs\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.7237483501434325\n",
      "[05/21/2025 15:53:35 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] Epoch[225] Batch[0] avg_epoch_loss=2.711699\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.711698532104492\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] Epoch[225] Batch[5] avg_epoch_loss=2.660862\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.660861849784851\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] Epoch[225] Batch [5]#011Speed: 2719.14 samples/sec#011loss=2.660862\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] Epoch[225] Batch[10] avg_epoch_loss=2.693909\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=2.7335648059844972\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] Epoch[225] Batch [10]#011Speed: 2667.76 samples/sec#011loss=2.733565\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747842815.8387759, \"EndTime\": 1747842816.6276824, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.5310649871826, \"count\": 1, \"min\": 788.5310649871826, \"max\": 788.5310649871826}}}\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1662.4046524199005 records/second\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] #progress_metric: host=algo-1, completed 56.5 % of epochs\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.6939086480574175\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] Epoch[226] Batch[0] avg_epoch_loss=2.692102\n",
      "[05/21/2025 15:53:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=2.6921024322509766\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] Epoch[226] Batch[5] avg_epoch_loss=2.554406\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.554405848185221\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] Epoch[226] Batch [5]#011Speed: 2902.17 samples/sec#011loss=2.554406\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] Epoch[226] Batch[10] avg_epoch_loss=2.553086\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=2.551503133773804\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] Epoch[226] Batch [10]#011Speed: 2922.24 samples/sec#011loss=2.551503\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747842816.6277401, \"EndTime\": 1747842817.38501, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 757.0128440856934, \"count\": 1, \"min\": 757.0128440856934, \"max\": 757.0128440856934}}}\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1722.2534748955115 records/second\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] #progress_metric: host=algo-1, completed 56.75 % of epochs\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.553086432543668\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] Epoch[227] Batch[0] avg_epoch_loss=2.436930\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.436929702758789\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] Epoch[227] Batch[5] avg_epoch_loss=2.492517\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.492517034212748\n",
      "[05/21/2025 15:53:37 INFO 140269512570688] Epoch[227] Batch [5]#011Speed: 2861.17 samples/sec#011loss=2.492517\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] Epoch[227] Batch[10] avg_epoch_loss=2.514954\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=2.541877508163452\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] Epoch[227] Batch [10]#011Speed: 2590.03 samples/sec#011loss=2.541878\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747842817.3851142, \"EndTime\": 1747842818.169083, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 783.663272857666, \"count\": 1, \"min\": 783.663272857666, \"max\": 783.663272857666}}}\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1686.764289768873 records/second\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] #progress_metric: host=algo-1, completed 57.0 % of epochs\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.51495361328125\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] Epoch[228] Batch[0] avg_epoch_loss=2.475722\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.475722074508667\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] Epoch[228] Batch[5] avg_epoch_loss=2.474040\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.4740399519602456\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] Epoch[228] Batch [5]#011Speed: 2757.67 samples/sec#011loss=2.474040\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] processed a total of 1227 examples\n",
      "#metrics {\"StartTime\": 1747842818.1691382, \"EndTime\": 1747842818.9012923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 731.9080829620361, \"count\": 1, \"min\": 731.9080829620361, \"max\": 731.9080829620361}}}\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1676.2265206974316 records/second\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] #progress_metric: host=algo-1, completed 57.25 % of epochs\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.4621325969696044\n",
      "[05/21/2025 15:53:38 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] Epoch[229] Batch[0] avg_epoch_loss=2.494509\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.4945085048675537\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] Epoch[229] Batch[5] avg_epoch_loss=2.444894\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.4448939164479575\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] Epoch[229] Batch [5]#011Speed: 2814.53 samples/sec#011loss=2.444894\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] processed a total of 1270 examples\n",
      "#metrics {\"StartTime\": 1747842818.9013553, \"EndTime\": 1747842819.6366897, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 735.0063323974609, \"count\": 1, \"min\": 735.0063323974609, \"max\": 735.0063323974609}}}\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1727.676761386561 records/second\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] #progress_metric: host=algo-1, completed 57.5 % of epochs\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.4258339643478393\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] Epoch[230] Batch[0] avg_epoch_loss=2.428851\n",
      "[05/21/2025 15:53:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.4288506507873535\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] Epoch[230] Batch[5] avg_epoch_loss=2.355954\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.355953574180603\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] Epoch[230] Batch [5]#011Speed: 2878.48 samples/sec#011loss=2.355954\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] Epoch[230] Batch[10] avg_epoch_loss=2.390526\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=2.4320118904113768\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] Epoch[230] Batch [10]#011Speed: 2627.44 samples/sec#011loss=2.432012\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747842819.6367476, \"EndTime\": 1747842820.4173136, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.3158760070801, \"count\": 1, \"min\": 780.3158760070801, \"max\": 780.3158760070801}}}\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1673.4914850761613 records/second\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] #progress_metric: host=algo-1, completed 57.75 % of epochs\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.390525536103682\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] Epoch[231] Batch[0] avg_epoch_loss=2.438964\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.4389636516571045\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] Epoch[231] Batch[5] avg_epoch_loss=2.465850\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.4658497174580893\n",
      "[05/21/2025 15:53:40 INFO 140269512570688] Epoch[231] Batch [5]#011Speed: 2766.40 samples/sec#011loss=2.465850\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] Epoch[231] Batch[10] avg_epoch_loss=2.483383\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=2.50442214012146\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] Epoch[231] Batch [10]#011Speed: 2739.41 samples/sec#011loss=2.504422\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842820.4173717, \"EndTime\": 1747842821.200198, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.573938369751, \"count\": 1, \"min\": 782.573938369751, \"max\": 782.573938369751}}}\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1658.4442932824893 records/second\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] #progress_metric: host=algo-1, completed 58.0 % of epochs\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.4833826368505303\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] Epoch[232] Batch[0] avg_epoch_loss=2.517653\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.517652750015259\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] Epoch[232] Batch[5] avg_epoch_loss=2.448559\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.4485594431559243\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] Epoch[232] Batch [5]#011Speed: 2775.48 samples/sec#011loss=2.448559\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] Epoch[232] Batch[10] avg_epoch_loss=2.433962\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=2.4164459228515627\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] Epoch[232] Batch [10]#011Speed: 2689.40 samples/sec#011loss=2.416446\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747842821.200257, \"EndTime\": 1747842821.986189, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.6650352478027, \"count\": 1, \"min\": 785.6650352478027, \"max\": 785.6650352478027}}}\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1664.6563385538275 records/second\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] #progress_metric: host=algo-1, completed 58.25 % of epochs\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.4339623884721235\n",
      "[05/21/2025 15:53:41 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] Epoch[233] Batch[0] avg_epoch_loss=2.338345\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.3383452892303467\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] Epoch[233] Batch[5] avg_epoch_loss=2.385467\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.3854668140411377\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] Epoch[233] Batch [5]#011Speed: 2665.10 samples/sec#011loss=2.385467\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] Epoch[233] Batch[10] avg_epoch_loss=2.361127\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=2.3319184303283693\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] Epoch[233] Batch [10]#011Speed: 2442.46 samples/sec#011loss=2.331918\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747842821.9862444, \"EndTime\": 1747842822.7958848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.3981742858887, \"count\": 1, \"min\": 809.3981742858887, \"max\": 809.3981742858887}}}\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1676.3725956709854 records/second\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] #progress_metric: host=algo-1, completed 58.5 % of epochs\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.3611266396262427\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:53:42 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_cfcb53e7-5edb-4bed-bd6c-db04a77de90d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842822.7959437, \"EndTime\": 1747842822.805864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.654045104980469, \"count\": 1, \"min\": 9.654045104980469, \"max\": 9.654045104980469}}}\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] Epoch[234] Batch[0] avg_epoch_loss=2.364830\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.364830255508423\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] Epoch[234] Batch[5] avg_epoch_loss=2.392289\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.39228888352712\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] Epoch[234] Batch [5]#011Speed: 2661.16 samples/sec#011loss=2.392289\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] Epoch[234] Batch[10] avg_epoch_loss=2.397278\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=2.403265047073364\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] Epoch[234] Batch [10]#011Speed: 2645.93 samples/sec#011loss=2.403265\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747842822.8059173, \"EndTime\": 1747842823.603922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.9421615600586, \"count\": 1, \"min\": 797.9421615600586, \"max\": 797.9421615600586}}}\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1611.4588145315488 records/second\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] #progress_metric: host=algo-1, completed 58.75 % of epochs\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.3972780487754126\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] Epoch[235] Batch[0] avg_epoch_loss=2.454400\n",
      "[05/21/2025 15:53:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.454400062561035\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] Epoch[235] Batch[5] avg_epoch_loss=2.380571\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.380571166674296\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] Epoch[235] Batch [5]#011Speed: 2588.88 samples/sec#011loss=2.380571\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] Epoch[235] Batch[10] avg_epoch_loss=2.379923\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=2.3791443347930907\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] Epoch[235] Batch [10]#011Speed: 2572.48 samples/sec#011loss=2.379144\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747842823.6039736, \"EndTime\": 1747842824.4137468, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.5188140869141, \"count\": 1, \"min\": 809.5188140869141, \"max\": 809.5188140869141}}}\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1672.4168025969032 records/second\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] #progress_metric: host=algo-1, completed 59.0 % of epochs\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.3799226067282935\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] Epoch[236] Batch[0] avg_epoch_loss=2.351378\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.3513777256011963\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] Epoch[236] Batch[5] avg_epoch_loss=2.413970\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.4139696756998696\n",
      "[05/21/2025 15:53:44 INFO 140269512570688] Epoch[236] Batch [5]#011Speed: 2797.96 samples/sec#011loss=2.413970\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] processed a total of 1270 examples\n",
      "#metrics {\"StartTime\": 1747842824.413807, \"EndTime\": 1747842825.143547, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 729.032039642334, \"count\": 1, \"min\": 729.032039642334, \"max\": 729.032039642334}}}\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1741.8149023762578 records/second\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] #progress_metric: host=algo-1, completed 59.25 % of epochs\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.3833233594894407\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] Epoch[237] Batch[0] avg_epoch_loss=2.400802\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.4008023738861084\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] Epoch[237] Batch[5] avg_epoch_loss=2.392534\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.3925344149271646\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] Epoch[237] Batch [5]#011Speed: 2790.63 samples/sec#011loss=2.392534\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747842825.143609, \"EndTime\": 1747842825.869825, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 725.7897853851318, \"count\": 1, \"min\": 725.7897853851318, \"max\": 725.7897853851318}}}\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1761.9728313046642 records/second\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] #progress_metric: host=algo-1, completed 59.5 % of epochs\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.382142519950867\n",
      "[05/21/2025 15:53:45 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] Epoch[238] Batch[0] avg_epoch_loss=2.285208\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.285208225250244\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] Epoch[238] Batch[5] avg_epoch_loss=2.354405\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.354405482610067\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] Epoch[238] Batch [5]#011Speed: 2883.43 samples/sec#011loss=2.354405\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] Epoch[238] Batch[10] avg_epoch_loss=2.387472\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=2.4271512985229493\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] Epoch[238] Batch [10]#011Speed: 2505.88 samples/sec#011loss=2.427151\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747842825.8698916, \"EndTime\": 1747842826.6838667, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.6322498321533, \"count\": 1, \"min\": 813.6322498321533, \"max\": 813.6322498321533}}}\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1636.9214556108996 records/second\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] #progress_metric: host=algo-1, completed 59.75 % of epochs\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.387471762570468\n",
      "[05/21/2025 15:53:46 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] Epoch[239] Batch[0] avg_epoch_loss=2.526833\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.5268332958221436\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] Epoch[239] Batch[5] avg_epoch_loss=2.516395\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.5163952112197876\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] Epoch[239] Batch [5]#011Speed: 2757.11 samples/sec#011loss=2.516395\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] Epoch[239] Batch[10] avg_epoch_loss=2.482166\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=2.4410908699035643\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] Epoch[239] Batch [10]#011Speed: 2527.39 samples/sec#011loss=2.441091\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747842826.6839273, \"EndTime\": 1747842827.5068367, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 822.645902633667, \"count\": 1, \"min\": 822.645902633667, \"max\": 822.645902633667}}}\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1632.3554874491822 records/second\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] #progress_metric: host=algo-1, completed 60.0 % of epochs\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.482165965166959\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] Epoch[240] Batch[0] avg_epoch_loss=2.532226\n",
      "[05/21/2025 15:53:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.532226085662842\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] Epoch[240] Batch[5] avg_epoch_loss=2.463941\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.4639407793680825\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] Epoch[240] Batch [5]#011Speed: 2705.48 samples/sec#011loss=2.463941\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] Epoch[240] Batch[10] avg_epoch_loss=2.355548\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=2.2254756689071655\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] Epoch[240] Batch [10]#011Speed: 2637.54 samples/sec#011loss=2.225476\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747842827.5068989, \"EndTime\": 1747842828.3287067, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 821.5339183807373, \"count\": 1, \"min\": 821.5339183807373, \"max\": 821.5339183807373}}}\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1573.7120153493386 records/second\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] #progress_metric: host=algo-1, completed 60.25 % of epochs\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.355547547340393\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_6ff24f44-9f69-4aed-bb8c-f9b1c2c3b732-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842828.3287675, \"EndTime\": 1747842828.3394327, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.349512100219727, \"count\": 1, \"min\": 10.349512100219727, \"max\": 10.349512100219727}}}\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] Epoch[241] Batch[0] avg_epoch_loss=2.542962\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.542962074279785\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] Epoch[241] Batch[5] avg_epoch_loss=2.419994\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.4199943939844766\n",
      "[05/21/2025 15:53:48 INFO 140269512570688] Epoch[241] Batch [5]#011Speed: 2737.72 samples/sec#011loss=2.419994\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] Epoch[241] Batch[10] avg_epoch_loss=2.323153\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.2069440364837645\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] Epoch[241] Batch [10]#011Speed: 2737.77 samples/sec#011loss=2.206944\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747842828.3394868, \"EndTime\": 1747842829.1454039, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 805.8657646179199, \"count\": 1, \"min\": 805.8657646179199, \"max\": 805.8657646179199}}}\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1625.402979988262 records/second\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] #progress_metric: host=algo-1, completed 60.5 % of epochs\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.323153322393244\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_499d9615-db18-4701-b2f1-fe60bd7e88a2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842829.1454635, \"EndTime\": 1747842829.155179, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.421586990356445, \"count\": 1, \"min\": 9.421586990356445, \"max\": 9.421586990356445}}}\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] Epoch[242] Batch[0] avg_epoch_loss=2.361928\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.3619282245635986\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] Epoch[242] Batch[5] avg_epoch_loss=2.386964\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.386964122454325\n",
      "[05/21/2025 15:53:49 INFO 140269512570688] Epoch[242] Batch [5]#011Speed: 2794.60 samples/sec#011loss=2.386964\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] Epoch[242] Batch[10] avg_epoch_loss=2.538526\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=2.720399284362793\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] Epoch[242] Batch [10]#011Speed: 2584.86 samples/sec#011loss=2.720399\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747842829.1552312, \"EndTime\": 1747842830.0666466, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.3662242889404, \"count\": 1, \"min\": 911.3662242889404, \"max\": 911.3662242889404}}}\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1459.2058527020458 records/second\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] #progress_metric: host=algo-1, completed 60.75 % of epochs\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.538525559685447\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] Epoch[243] Batch[0] avg_epoch_loss=2.316252\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=2.3162519931793213\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] Epoch[243] Batch[5] avg_epoch_loss=2.423876\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.4238758087158203\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] Epoch[243] Batch [5]#011Speed: 2782.54 samples/sec#011loss=2.423876\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] processed a total of 1270 examples\n",
      "#metrics {\"StartTime\": 1747842830.0667055, \"EndTime\": 1747842830.8017414, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 734.7855567932129, \"count\": 1, \"min\": 734.7855567932129, \"max\": 734.7855567932129}}}\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1728.1834686655254 records/second\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] #progress_metric: host=algo-1, completed 61.0 % of epochs\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.445090484619141\n",
      "[05/21/2025 15:53:50 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] Epoch[244] Batch[0] avg_epoch_loss=2.434134\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.434134006500244\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] Epoch[244] Batch[5] avg_epoch_loss=2.413563\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.413562814394633\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] Epoch[244] Batch [5]#011Speed: 2702.63 samples/sec#011loss=2.413563\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] Epoch[244] Batch[10] avg_epoch_loss=2.339451\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=2.2505161285400392\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] Epoch[244] Batch [10]#011Speed: 2712.55 samples/sec#011loss=2.250516\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747842830.8018017, \"EndTime\": 1747842831.591101, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.0095710754395, \"count\": 1, \"min\": 789.0095710754395, \"max\": 789.0095710754395}}}\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1639.8410190079007 records/second\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] #progress_metric: host=algo-1, completed 61.25 % of epochs\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.3394506844607266\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] Epoch[245] Batch[0] avg_epoch_loss=2.390414\n",
      "[05/21/2025 15:53:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.390413999557495\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] Epoch[245] Batch[5] avg_epoch_loss=2.390184\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.3901836474736533\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] Epoch[245] Batch [5]#011Speed: 2876.67 samples/sec#011loss=2.390184\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] Epoch[245] Batch[10] avg_epoch_loss=2.463871\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=2.552296686172485\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] Epoch[245] Batch [10]#011Speed: 2791.14 samples/sec#011loss=2.552297\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747842831.5911613, \"EndTime\": 1747842832.359425, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 768.0044174194336, \"count\": 1, \"min\": 768.0044174194336, \"max\": 768.0044174194336}}}\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1684.694725928961 records/second\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] #progress_metric: host=algo-1, completed 61.5 % of epochs\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.463871392336759\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] Epoch[246] Batch[0] avg_epoch_loss=2.601040\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.6010401248931885\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] Epoch[246] Batch[5] avg_epoch_loss=2.458974\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.4589739243189492\n",
      "[05/21/2025 15:53:52 INFO 140269512570688] Epoch[246] Batch [5]#011Speed: 2782.90 samples/sec#011loss=2.458974\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] Epoch[246] Batch[10] avg_epoch_loss=2.405295\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=2.3408806800842283\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] Epoch[246] Batch [10]#011Speed: 2456.84 samples/sec#011loss=2.340881\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747842832.3594835, \"EndTime\": 1747842833.1582289, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.4914779663086, \"count\": 1, \"min\": 798.4914779663086, \"max\": 798.4914779663086}}}\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1675.3595683932608 records/second\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] #progress_metric: host=algo-1, completed 61.75 % of epochs\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=246, train loss <loss>=2.4052951769395308\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] Epoch[247] Batch[0] avg_epoch_loss=2.598761\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.5987606048583984\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] Epoch[247] Batch[5] avg_epoch_loss=2.458802\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.4588021437327066\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] Epoch[247] Batch [5]#011Speed: 2773.10 samples/sec#011loss=2.458802\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] Epoch[247] Batch[10] avg_epoch_loss=2.458921\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=2.459062671661377\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] Epoch[247] Batch [10]#011Speed: 2815.41 samples/sec#011loss=2.459063\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747842833.1583364, \"EndTime\": 1747842833.9288445, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 770.1470851898193, \"count\": 1, \"min\": 770.1470851898193, \"max\": 770.1470851898193}}}\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1696.877752921814 records/second\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] #progress_metric: host=algo-1, completed 62.0 % of epochs\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=247, train loss <loss>=2.458920565518466\n",
      "[05/21/2025 15:53:53 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] Epoch[248] Batch[0] avg_epoch_loss=2.347157\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.3471570014953613\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] Epoch[248] Batch[5] avg_epoch_loss=2.492686\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.492686152458191\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] Epoch[248] Batch [5]#011Speed: 2774.91 samples/sec#011loss=2.492686\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] Epoch[248] Batch[10] avg_epoch_loss=2.469056\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=2.4406989574432374\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] Epoch[248] Batch [10]#011Speed: 2400.00 samples/sec#011loss=2.440699\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] processed a total of 1385 examples\n",
      "#metrics {\"StartTime\": 1747842833.9289033, \"EndTime\": 1747842834.743689, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.4609928131104, \"count\": 1, \"min\": 814.4609928131104, \"max\": 814.4609928131104}}}\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1700.3324614746978 records/second\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] #progress_metric: host=algo-1, completed 62.25 % of epochs\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.4690556092695757\n",
      "[05/21/2025 15:53:54 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] Epoch[249] Batch[0] avg_epoch_loss=2.398963\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.398963212966919\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] Epoch[249] Batch[5] avg_epoch_loss=2.375073\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.375072956085205\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] Epoch[249] Batch [5]#011Speed: 2783.64 samples/sec#011loss=2.375073\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] Epoch[249] Batch[10] avg_epoch_loss=2.370182\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=2.36431303024292\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] Epoch[249] Batch [10]#011Speed: 2745.98 samples/sec#011loss=2.364313\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842834.743746, \"EndTime\": 1747842835.526958, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.9656600952148, \"count\": 1, \"min\": 782.9656600952148, \"max\": 782.9656600952148}}}\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1657.6186951832842 records/second\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] #progress_metric: host=algo-1, completed 62.5 % of epochs\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.370182080702348\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] Epoch[250] Batch[0] avg_epoch_loss=2.298694\n",
      "[05/21/2025 15:53:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.298694133758545\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] Epoch[250] Batch[5] avg_epoch_loss=2.329566\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.3295658429463706\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] Epoch[250] Batch [5]#011Speed: 2811.83 samples/sec#011loss=2.329566\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] Epoch[250] Batch[10] avg_epoch_loss=2.275252\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=2.210075330734253\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] Epoch[250] Batch [10]#011Speed: 2416.30 samples/sec#011loss=2.210075\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747842835.5270154, \"EndTime\": 1747842836.3353338, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 808.0639839172363, \"count\": 1, \"min\": 808.0639839172363, \"max\": 808.0639839172363}}}\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1635.8295157181976 records/second\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] #progress_metric: host=algo-1, completed 62.75 % of epochs\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.2752519737590444\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_3a877752-4fa1-4745-8b04-f26119ecdab6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842836.3353927, \"EndTime\": 1747842836.344521, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.853912353515625, \"count\": 1, \"min\": 8.853912353515625, \"max\": 8.853912353515625}}}\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] Epoch[251] Batch[0] avg_epoch_loss=2.307520\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.3075196743011475\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] Epoch[251] Batch[5] avg_epoch_loss=2.389970\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.3899700244267783\n",
      "[05/21/2025 15:53:56 INFO 140269512570688] Epoch[251] Batch [5]#011Speed: 2852.29 samples/sec#011loss=2.389970\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] Epoch[251] Batch[10] avg_epoch_loss=2.374701\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=2.3563791275024415\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] Epoch[251] Batch [10]#011Speed: 2686.94 samples/sec#011loss=2.356379\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747842836.3445756, \"EndTime\": 1747842837.1241944, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 779.5679569244385, \"count\": 1, \"min\": 779.5679569244385, \"max\": 779.5679569244385}}}\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1716.147921991424 records/second\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] #progress_metric: host=algo-1, completed 63.0 % of epochs\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.374701434915716\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] Epoch[252] Batch[0] avg_epoch_loss=2.325367\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=2.3253672122955322\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] Epoch[252] Batch[5] avg_epoch_loss=2.419916\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.4199160734812417\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] Epoch[252] Batch [5]#011Speed: 2827.89 samples/sec#011loss=2.419916\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] Epoch[252] Batch[10] avg_epoch_loss=2.487409\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=2.568399524688721\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] Epoch[252] Batch [10]#011Speed: 2720.07 samples/sec#011loss=2.568400\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747842837.1242511, \"EndTime\": 1747842837.900155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 775.5911350250244, \"count\": 1, \"min\": 775.5911350250244, \"max\": 775.5911350250244}}}\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1670.7919388659013 records/second\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] #progress_metric: host=algo-1, completed 63.25 % of epochs\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.4874085513028232\n",
      "[05/21/2025 15:53:57 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] Epoch[253] Batch[0] avg_epoch_loss=2.316958\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=2.316958427429199\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] Epoch[253] Batch[5] avg_epoch_loss=2.395719\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.3957186539967856\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] Epoch[253] Batch [5]#011Speed: 2811.18 samples/sec#011loss=2.395719\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] Epoch[253] Batch[10] avg_epoch_loss=2.369609\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=2.33827805519104\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] Epoch[253] Batch [10]#011Speed: 2672.82 samples/sec#011loss=2.338278\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842837.9002142, \"EndTime\": 1747842838.6835976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 783.1311225891113, \"count\": 1, \"min\": 783.1311225891113, \"max\": 783.1311225891113}}}\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1657.2664883234725 records/second\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] #progress_metric: host=algo-1, completed 63.5 % of epochs\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.3696092909032647\n",
      "[05/21/2025 15:53:58 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] Epoch[254] Batch[0] avg_epoch_loss=2.504673\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.5046727657318115\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] Epoch[254] Batch[5] avg_epoch_loss=2.458997\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.4589970111846924\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] Epoch[254] Batch [5]#011Speed: 2759.66 samples/sec#011loss=2.458997\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] Epoch[254] Batch[10] avg_epoch_loss=2.459972\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=254, batch=10 train loss <loss>=2.4611412525177\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] Epoch[254] Batch [10]#011Speed: 2672.02 samples/sec#011loss=2.461141\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747842838.683655, \"EndTime\": 1747842839.482659, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.7556457519531, \"count\": 1, \"min\": 798.7556457519531, \"max\": 798.7556457519531}}}\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1687.4537516668836 records/second\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] #progress_metric: host=algo-1, completed 63.75 % of epochs\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.4599716663360596\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] Epoch[255] Batch[0] avg_epoch_loss=2.466455\n",
      "[05/21/2025 15:53:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=2.46645450592041\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] Epoch[255] Batch[5] avg_epoch_loss=2.375252\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.3752524852752686\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] Epoch[255] Batch [5]#011Speed: 2834.67 samples/sec#011loss=2.375252\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] Epoch[255] Batch[10] avg_epoch_loss=2.388378\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=2.404128360748291\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] Epoch[255] Batch [10]#011Speed: 2686.32 samples/sec#011loss=2.404128\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842839.4827125, \"EndTime\": 1747842840.2653518, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.3593616485596, \"count\": 1, \"min\": 782.3593616485596, \"max\": 782.3593616485596}}}\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1658.80508774362 records/second\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] #progress_metric: host=algo-1, completed 64.0 % of epochs\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.3883778832175513\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] Epoch[256] Batch[0] avg_epoch_loss=2.445220\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.4452197551727295\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] Epoch[256] Batch[5] avg_epoch_loss=2.387640\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.3876402775446572\n",
      "[05/21/2025 15:54:00 INFO 140269512570688] Epoch[256] Batch [5]#011Speed: 2658.84 samples/sec#011loss=2.387640\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] processed a total of 1277 examples\n",
      "#metrics {\"StartTime\": 1747842840.2654548, \"EndTime\": 1747842841.0081246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 742.3617839813232, \"count\": 1, \"min\": 742.3617839813232, \"max\": 742.3617839813232}}}\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1719.9667857705967 records/second\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] #progress_metric: host=algo-1, completed 64.25 % of epochs\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.358833074569702\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] Epoch[257] Batch[0] avg_epoch_loss=2.290685\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.290684938430786\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] Epoch[257] Batch[5] avg_epoch_loss=2.351106\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.3511062463124595\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] Epoch[257] Batch [5]#011Speed: 2761.91 samples/sec#011loss=2.351106\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] Epoch[257] Batch[10] avg_epoch_loss=2.348407\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=2.345167064666748\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] Epoch[257] Batch [10]#011Speed: 2545.38 samples/sec#011loss=2.345167\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747842841.0081882, \"EndTime\": 1747842841.811602, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.114652633667, \"count\": 1, \"min\": 803.114652633667, \"max\": 803.114652633667}}}\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1634.7062897851656 records/second\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] #progress_metric: host=algo-1, completed 64.5 % of epochs\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.3484066182916816\n",
      "[05/21/2025 15:54:01 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] Epoch[258] Batch[0] avg_epoch_loss=2.359223\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.3592233657836914\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] Epoch[258] Batch[5] avg_epoch_loss=2.404548\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.404547611872355\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] Epoch[258] Batch [5]#011Speed: 2877.54 samples/sec#011loss=2.404548\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] Epoch[258] Batch[10] avg_epoch_loss=2.610662\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=2.8579984664916993\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] Epoch[258] Batch [10]#011Speed: 2768.67 samples/sec#011loss=2.857998\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747842841.8116596, \"EndTime\": 1747842842.5788383, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 766.9286727905273, \"count\": 1, \"min\": 766.9286727905273, \"max\": 766.9286727905273}}}\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1714.403845131683 records/second\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] #progress_metric: host=algo-1, completed 64.75 % of epochs\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.6106616366993296\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] Epoch[259] Batch[0] avg_epoch_loss=2.878994\n",
      "[05/21/2025 15:54:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.8789937496185303\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] Epoch[259] Batch[5] avg_epoch_loss=2.844195\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.8441949685414634\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] Epoch[259] Batch [5]#011Speed: 2776.05 samples/sec#011loss=2.844195\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] Epoch[259] Batch[10] avg_epoch_loss=2.796938\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=2.7402287483215333\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] Epoch[259] Batch [10]#011Speed: 2583.96 samples/sec#011loss=2.740229\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747842842.5788949, \"EndTime\": 1747842843.3702548, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.126012802124, \"count\": 1, \"min\": 791.126012802124, \"max\": 791.126012802124}}}\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1656.9549370106524 records/second\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] #progress_metric: host=algo-1, completed 65.0 % of epochs\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.796937595714222\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] Epoch[260] Batch[0] avg_epoch_loss=3.018229\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=3.018228769302368\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] Epoch[260] Batch[5] avg_epoch_loss=2.801202\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.801201820373535\n",
      "[05/21/2025 15:54:03 INFO 140269512570688] Epoch[260] Batch [5]#011Speed: 2743.39 samples/sec#011loss=2.801202\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] processed a total of 1252 examples\n",
      "#metrics {\"StartTime\": 1747842843.3703125, \"EndTime\": 1747842844.0976055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 727.0376682281494, \"count\": 1, \"min\": 727.0376682281494, \"max\": 727.0376682281494}}}\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1721.832416009632 records/second\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] #progress_metric: host=algo-1, completed 65.25 % of epochs\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.7852782249450683\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] Epoch[261] Batch[0] avg_epoch_loss=2.636023\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.6360225677490234\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] Epoch[261] Batch[5] avg_epoch_loss=2.665894\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.665894110997518\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] Epoch[261] Batch [5]#011Speed: 2856.70 samples/sec#011loss=2.665894\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] Epoch[261] Batch[10] avg_epoch_loss=2.594547\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=2.5089298725128173\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] Epoch[261] Batch [10]#011Speed: 2564.41 samples/sec#011loss=2.508930\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747842844.097668, \"EndTime\": 1747842844.8866277, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 788.6621952056885, \"count\": 1, \"min\": 788.6621952056885, \"max\": 788.6621952056885}}}\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1639.2924270572182 records/second\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] #progress_metric: host=algo-1, completed 65.5 % of epochs\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=261, train loss <loss>=2.5945467298681084\n",
      "[05/21/2025 15:54:04 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] Epoch[262] Batch[0] avg_epoch_loss=2.391448\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.3914477825164795\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] Epoch[262] Batch[5] avg_epoch_loss=2.488901\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.4889010985692344\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] Epoch[262] Batch [5]#011Speed: 2617.74 samples/sec#011loss=2.488901\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] Epoch[262] Batch[10] avg_epoch_loss=2.519648\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=2.556543779373169\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] Epoch[262] Batch [10]#011Speed: 2636.62 samples/sec#011loss=2.556544\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747842844.88669, \"EndTime\": 1747842845.7122288, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 825.2644538879395, \"count\": 1, \"min\": 825.2644538879395, \"max\": 825.2644538879395}}}\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1633.2303692613357 records/second\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] #progress_metric: host=algo-1, completed 65.75 % of epochs\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.5196477716619317\n",
      "[05/21/2025 15:54:05 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] Epoch[263] Batch[0] avg_epoch_loss=2.428304\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.428304433822632\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] Epoch[263] Batch[5] avg_epoch_loss=2.469078\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.469078024228414\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] Epoch[263] Batch [5]#011Speed: 2813.30 samples/sec#011loss=2.469078\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] Epoch[263] Batch[10] avg_epoch_loss=2.349700\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=263, batch=10 train loss <loss>=2.206446647644043\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] Epoch[263] Batch [10]#011Speed: 2756.80 samples/sec#011loss=2.206447\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747842845.712292, \"EndTime\": 1747842846.5157242, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.0989170074463, \"count\": 1, \"min\": 803.0989170074463, \"max\": 803.0989170074463}}}\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1611.0672412262852 records/second\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] #progress_metric: host=algo-1, completed 66.0 % of epochs\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=263, train loss <loss>=2.3497001257809726\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] Epoch[264] Batch[0] avg_epoch_loss=2.373041\n",
      "[05/21/2025 15:54:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.3730411529541016\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] Epoch[264] Batch[5] avg_epoch_loss=2.394772\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.3947721322377524\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] Epoch[264] Batch [5]#011Speed: 2737.36 samples/sec#011loss=2.394772\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] Epoch[264] Batch[10] avg_epoch_loss=2.361931\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=2.3225220680236816\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] Epoch[264] Batch [10]#011Speed: 2724.88 samples/sec#011loss=2.322522\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747842846.5157878, \"EndTime\": 1747842847.3251898, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.1287612915039, \"count\": 1, \"min\": 809.1287612915039, \"max\": 809.1287612915039}}}\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1626.257231708413 records/second\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] #progress_metric: host=algo-1, completed 66.25 % of epochs\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.3619311939586294\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] Epoch[265] Batch[0] avg_epoch_loss=2.283624\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.2836239337921143\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] Epoch[265] Batch[5] avg_epoch_loss=2.382725\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.382725159327189\n",
      "[05/21/2025 15:54:07 INFO 140269512570688] Epoch[265] Batch [5]#011Speed: 2730.14 samples/sec#011loss=2.382725\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] Epoch[265] Batch[10] avg_epoch_loss=2.418653\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=2.461767053604126\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] Epoch[265] Batch [10]#011Speed: 2469.50 samples/sec#011loss=2.461767\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747842847.3252506, \"EndTime\": 1747842848.1534462, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 827.9225826263428, \"count\": 1, \"min\": 827.9225826263428, \"max\": 827.9225826263428}}}\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1650.9056746437025 records/second\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] #progress_metric: host=algo-1, completed 66.5 % of epochs\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.418653293089433\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] Epoch[266] Batch[0] avg_epoch_loss=2.348319\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.3483190536499023\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] Epoch[266] Batch[5] avg_epoch_loss=2.379871\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.379870851834615\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] Epoch[266] Batch [5]#011Speed: 2821.89 samples/sec#011loss=2.379871\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] Epoch[266] Batch[10] avg_epoch_loss=2.384909\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=2.3909558773040773\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] Epoch[266] Batch [10]#011Speed: 2398.48 samples/sec#011loss=2.390956\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747842848.1535184, \"EndTime\": 1747842848.9840412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 830.2476406097412, \"count\": 1, \"min\": 830.2476406097412, \"max\": 830.2476406097412}}}\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1572.8561718490682 records/second\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] #progress_metric: host=algo-1, completed 66.75 % of epochs\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.3849094997752798\n",
      "[05/21/2025 15:54:08 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] Epoch[267] Batch[0] avg_epoch_loss=2.376444\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.3764443397521973\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] Epoch[267] Batch[5] avg_epoch_loss=2.371724\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.3717238903045654\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] Epoch[267] Batch [5]#011Speed: 2862.17 samples/sec#011loss=2.371724\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] Epoch[267] Batch[10] avg_epoch_loss=2.348354\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=2.3203108310699463\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] Epoch[267] Batch [10]#011Speed: 2657.90 samples/sec#011loss=2.320311\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747842848.9841003, \"EndTime\": 1747842849.7610059, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 776.641845703125, \"count\": 1, \"min\": 776.641845703125, \"max\": 776.641845703125}}}\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1694.2479849031956 records/second\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] #progress_metric: host=algo-1, completed 67.0 % of epochs\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.348354317925193\n",
      "[05/21/2025 15:54:09 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] Epoch[268] Batch[0] avg_epoch_loss=2.521986\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.5219860076904297\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] Epoch[268] Batch[5] avg_epoch_loss=2.402112\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.402112046877543\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] Epoch[268] Batch [5]#011Speed: 2787.27 samples/sec#011loss=2.402112\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] Epoch[268] Batch[10] avg_epoch_loss=2.386821\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=268, batch=10 train loss <loss>=2.3684722423553466\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] Epoch[268] Batch [10]#011Speed: 2626.19 samples/sec#011loss=2.368472\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747842849.7610774, \"EndTime\": 1747842850.588748, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 827.2926807403564, \"count\": 1, \"min\": 827.2926807403564, \"max\": 827.2926807403564}}}\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1608.6912214151803 records/second\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] #progress_metric: host=algo-1, completed 67.25 % of epochs\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.386821226640181\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] Epoch[269] Batch[0] avg_epoch_loss=2.289237\n",
      "[05/21/2025 15:54:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=2.2892372608184814\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] Epoch[269] Batch[5] avg_epoch_loss=2.313456\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=2.3134562174479165\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] Epoch[269] Batch [5]#011Speed: 2615.60 samples/sec#011loss=2.313456\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] Epoch[269] Batch[10] avg_epoch_loss=2.374693\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=269, batch=10 train loss <loss>=2.4481778144836426\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] Epoch[269] Batch [10]#011Speed: 2630.44 samples/sec#011loss=2.448178\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747842850.5888054, \"EndTime\": 1747842851.4059944, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 816.8377876281738, \"count\": 1, \"min\": 816.8377876281738, \"max\": 816.8377876281738}}}\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1652.4940143422314 records/second\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] #progress_metric: host=algo-1, completed 67.5 % of epochs\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=269, train loss <loss>=2.3746933070096103\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] Epoch[270] Batch[0] avg_epoch_loss=2.294824\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=2.2948241233825684\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] Epoch[270] Batch[5] avg_epoch_loss=2.331775\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=2.3317748308181763\n",
      "[05/21/2025 15:54:11 INFO 140269512570688] Epoch[270] Batch [5]#011Speed: 2646.91 samples/sec#011loss=2.331775\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] Epoch[270] Batch[10] avg_epoch_loss=2.338529\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=2.3466344356536863\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] Epoch[270] Batch [10]#011Speed: 2755.63 samples/sec#011loss=2.346634\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747842851.4060693, \"EndTime\": 1747842852.2001595, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 793.759822845459, \"count\": 1, \"min\": 793.759822845459, \"max\": 793.759822845459}}}\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1624.986871027934 records/second\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] #progress_metric: host=algo-1, completed 67.75 % of epochs\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=270, train loss <loss>=2.338529196652499\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] Epoch[271] Batch[0] avg_epoch_loss=2.730538\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=2.7305376529693604\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] Epoch[271] Batch[5] avg_epoch_loss=2.604081\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=2.6040807565053306\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] Epoch[271] Batch [5]#011Speed: 2766.26 samples/sec#011loss=2.604081\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] Epoch[271] Batch[10] avg_epoch_loss=2.563664\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=271, batch=10 train loss <loss>=2.5151639938354493\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] Epoch[271] Batch [10]#011Speed: 2573.32 samples/sec#011loss=2.515164\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747842852.2002215, \"EndTime\": 1747842852.9974892, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.9670295715332, \"count\": 1, \"min\": 796.9670295715332, \"max\": 796.9670295715332}}}\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1634.7508625161001 records/second\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] #progress_metric: host=algo-1, completed 68.0 % of epochs\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] #quality_metric: host=algo-1, epoch=271, train loss <loss>=2.563664046200839\n",
      "[05/21/2025 15:54:12 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] Epoch[272] Batch[0] avg_epoch_loss=2.535107\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=2.535106658935547\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] Epoch[272] Batch[5] avg_epoch_loss=2.625344\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=2.6253443161646524\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] Epoch[272] Batch [5]#011Speed: 2784.92 samples/sec#011loss=2.625344\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] Epoch[272] Batch[10] avg_epoch_loss=2.710992\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=2.813768815994263\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] Epoch[272] Batch [10]#011Speed: 2688.55 samples/sec#011loss=2.813769\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747842852.9975557, \"EndTime\": 1747842853.7786155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 780.6963920593262, \"count\": 1, \"min\": 780.6963920593262, \"max\": 780.6963920593262}}}\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1673.9495142239539 records/second\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] #progress_metric: host=algo-1, completed 68.25 % of epochs\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] #quality_metric: host=algo-1, epoch=272, train loss <loss>=2.7109918160872026\n",
      "[05/21/2025 15:54:13 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] Epoch[273] Batch[0] avg_epoch_loss=2.573525\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=2.5735254287719727\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] Epoch[273] Batch[5] avg_epoch_loss=2.516020\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=2.5160202980041504\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] Epoch[273] Batch [5]#011Speed: 2603.77 samples/sec#011loss=2.516020\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] Epoch[273] Batch[10] avg_epoch_loss=2.467753\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=273, batch=10 train loss <loss>=2.4098315715789793\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] Epoch[273] Batch [10]#011Speed: 2396.89 samples/sec#011loss=2.409832\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] processed a total of 1364 examples\n",
      "#metrics {\"StartTime\": 1747842853.7786756, \"EndTime\": 1747842854.6064038, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 827.4199962615967, \"count\": 1, \"min\": 827.4199962615967, \"max\": 827.4199962615967}}}\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1648.3253369382514 records/second\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] #progress_metric: host=algo-1, completed 68.5 % of epochs\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=273, train loss <loss>=2.467752695083618\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] Epoch[274] Batch[0] avg_epoch_loss=2.573760\n",
      "[05/21/2025 15:54:14 INFO 140269512570688] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=2.5737595558166504\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] Epoch[274] Batch[5] avg_epoch_loss=2.455008\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=2.4550075133641562\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] Epoch[274] Batch [5]#011Speed: 2455.95 samples/sec#011loss=2.455008\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] Epoch[274] Batch[10] avg_epoch_loss=2.470118\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=274, batch=10 train loss <loss>=2.4882503509521485\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] Epoch[274] Batch [10]#011Speed: 2601.99 samples/sec#011loss=2.488250\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747842854.6064618, \"EndTime\": 1747842855.433548, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 826.8301486968994, \"count\": 1, \"min\": 826.8301486968994, \"max\": 826.8301486968994}}}\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1605.9635682148114 records/second\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] #progress_metric: host=algo-1, completed 68.75 % of epochs\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=274, train loss <loss>=2.4701178940859707\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] Epoch[275] Batch[0] avg_epoch_loss=2.520051\n",
      "[05/21/2025 15:54:15 INFO 140269512570688] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=2.5200507640838623\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] Epoch[275] Batch[5] avg_epoch_loss=2.567397\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=2.567397435506185\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] Epoch[275] Batch [5]#011Speed: 2530.97 samples/sec#011loss=2.567397\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] Epoch[275] Batch[10] avg_epoch_loss=2.507185\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=275, batch=10 train loss <loss>=2.4349304676055907\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] Epoch[275] Batch [10]#011Speed: 2751.29 samples/sec#011loss=2.434930\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747842855.433606, \"EndTime\": 1747842856.2438006, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.941291809082, \"count\": 1, \"min\": 809.941291809082, \"max\": 809.941291809082}}}\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1596.2475450994705 records/second\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] #progress_metric: host=algo-1, completed 69.0 % of epochs\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=275, train loss <loss>=2.5071851773695513\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] Epoch[276] Batch[0] avg_epoch_loss=2.496011\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=2.4960107803344727\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] Epoch[276] Batch[5] avg_epoch_loss=2.397569\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=2.397569020589193\n",
      "[05/21/2025 15:54:16 INFO 140269512570688] Epoch[276] Batch [5]#011Speed: 2647.76 samples/sec#011loss=2.397569\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] Epoch[276] Batch[10] avg_epoch_loss=2.511109\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=2.64735803604126\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] Epoch[276] Batch [10]#011Speed: 2574.36 samples/sec#011loss=2.647358\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747842856.2438557, \"EndTime\": 1747842857.0457134, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 801.5363216400146, \"count\": 1, \"min\": 801.5363216400146, \"max\": 801.5363216400146}}}\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1647.9016899639855 records/second\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] #progress_metric: host=algo-1, completed 69.25 % of epochs\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=276, train loss <loss>=2.511109482158314\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] Epoch[277] Batch[0] avg_epoch_loss=2.402905\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=2.402904510498047\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] Epoch[277] Batch[5] avg_epoch_loss=2.386084\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=2.3860839207967124\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] Epoch[277] Batch [5]#011Speed: 2876.96 samples/sec#011loss=2.386084\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] Epoch[277] Batch[10] avg_epoch_loss=2.387276\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=277, batch=10 train loss <loss>=2.3887075901031496\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] Epoch[277] Batch [10]#011Speed: 2667.58 samples/sec#011loss=2.388708\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747842857.0457737, \"EndTime\": 1747842857.815892, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 769.8228359222412, \"count\": 1, \"min\": 769.8228359222412, \"max\": 769.8228359222412}}}\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1756.0350482447543 records/second\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] #progress_metric: host=algo-1, completed 69.5 % of epochs\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] #quality_metric: host=algo-1, epoch=277, train loss <loss>=2.3872764977541836\n",
      "[05/21/2025 15:54:17 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] Epoch[278] Batch[0] avg_epoch_loss=2.387619\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=2.3876187801361084\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] Epoch[278] Batch[5] avg_epoch_loss=2.351781\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=2.3517809311548867\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] Epoch[278] Batch [5]#011Speed: 2854.81 samples/sec#011loss=2.351781\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] Epoch[278] Batch[10] avg_epoch_loss=2.322800\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=2.288023900985718\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] Epoch[278] Batch [10]#011Speed: 2693.05 samples/sec#011loss=2.288024\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747842857.815954, \"EndTime\": 1747842858.5902402, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 774.0347385406494, \"count\": 1, \"min\": 774.0347385406494, \"max\": 774.0347385406494}}}\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1711.6186244167127 records/second\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] #progress_metric: host=algo-1, completed 69.75 % of epochs\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=278, train loss <loss>=2.322800462896174\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] Epoch[279] Batch[0] avg_epoch_loss=2.345539\n",
      "[05/21/2025 15:54:18 INFO 140269512570688] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=2.345539093017578\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] Epoch[279] Batch[5] avg_epoch_loss=2.370374\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=2.3703740437825522\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] Epoch[279] Batch [5]#011Speed: 2875.52 samples/sec#011loss=2.370374\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] Epoch[279] Batch[10] avg_epoch_loss=2.367343\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=2.363706636428833\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] Epoch[279] Batch [10]#011Speed: 2733.86 samples/sec#011loss=2.363707\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747842858.590298, \"EndTime\": 1747842859.3629518, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 772.4049091339111, \"count\": 1, \"min\": 772.4049091339111, \"max\": 772.4049091339111}}}\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1713.940105936506 records/second\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] #progress_metric: host=algo-1, completed 70.0 % of epochs\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=279, train loss <loss>=2.367343404076316\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] Epoch[280] Batch[0] avg_epoch_loss=2.388748\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=2.3887484073638916\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] Epoch[280] Batch[5] avg_epoch_loss=2.299302\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=2.2993016640345254\n",
      "[05/21/2025 15:54:19 INFO 140269512570688] Epoch[280] Batch [5]#011Speed: 2712.55 samples/sec#011loss=2.299302\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747842859.3630064, \"EndTime\": 1747842860.1086292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 745.3603744506836, \"count\": 1, \"min\": 745.3603744506836, \"max\": 745.3603744506836}}}\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1698.2894140697335 records/second\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] #progress_metric: host=algo-1, completed 70.25 % of epochs\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=280, train loss <loss>=2.3114323377609254\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] Epoch[281] Batch[0] avg_epoch_loss=2.327715\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=2.3277149200439453\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] Epoch[281] Batch[5] avg_epoch_loss=2.279195\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=2.2791951497395835\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] Epoch[281] Batch [5]#011Speed: 2639.97 samples/sec#011loss=2.279195\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] Epoch[281] Batch[10] avg_epoch_loss=2.296895\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=281, batch=10 train loss <loss>=2.3181342124938964\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] Epoch[281] Batch [10]#011Speed: 2616.59 samples/sec#011loss=2.318134\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747842860.1086946, \"EndTime\": 1747842860.9151103, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 806.0643672943115, \"count\": 1, \"min\": 806.0643672943115, \"max\": 806.0643672943115}}}\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1605.1575621280215 records/second\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] #progress_metric: host=algo-1, completed 70.5 % of epochs\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] #quality_metric: host=algo-1, epoch=281, train loss <loss>=2.2968947237188164\n",
      "[05/21/2025 15:54:20 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] Epoch[282] Batch[0] avg_epoch_loss=2.273831\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=2.2738311290740967\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] Epoch[282] Batch[5] avg_epoch_loss=2.293339\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=2.2933390935262046\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] Epoch[282] Batch [5]#011Speed: 2847.09 samples/sec#011loss=2.293339\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] Epoch[282] Batch[10] avg_epoch_loss=2.326418\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=282, batch=10 train loss <loss>=2.366111993789673\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] Epoch[282] Batch [10]#011Speed: 2428.83 samples/sec#011loss=2.366112\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] processed a total of 1384 examples\n",
      "#metrics {\"StartTime\": 1747842860.9151673, \"EndTime\": 1747842861.711088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.6418991088867, \"count\": 1, \"min\": 795.6418991088867, \"max\": 795.6418991088867}}}\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1739.2842183985053 records/second\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] #progress_metric: host=algo-1, completed 70.75 % of epochs\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] #quality_metric: host=algo-1, epoch=282, train loss <loss>=2.3264176845550537\n",
      "[05/21/2025 15:54:21 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] Epoch[283] Batch[0] avg_epoch_loss=2.316222\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=2.3162219524383545\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] Epoch[283] Batch[5] avg_epoch_loss=2.297030\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=2.2970300912857056\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] Epoch[283] Batch [5]#011Speed: 2755.22 samples/sec#011loss=2.297030\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] Epoch[283] Batch[10] avg_epoch_loss=2.373976\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=283, batch=10 train loss <loss>=2.4663115978240966\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] Epoch[283] Batch [10]#011Speed: 2642.77 samples/sec#011loss=2.466312\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747842861.7111466, \"EndTime\": 1747842862.5004687, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 789.074182510376, \"count\": 1, \"min\": 789.074182510376, \"max\": 789.074182510376}}}\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1685.3001285781959 records/second\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] #progress_metric: host=algo-1, completed 71.0 % of epochs\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=283, train loss <loss>=2.373976230621338\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] Epoch[284] Batch[0] avg_epoch_loss=2.449412\n",
      "[05/21/2025 15:54:22 INFO 140269512570688] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=2.449411630630493\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] Epoch[284] Batch[5] avg_epoch_loss=2.414675\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=2.414675235748291\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] Epoch[284] Batch [5]#011Speed: 2591.02 samples/sec#011loss=2.414675\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] Epoch[284] Batch[10] avg_epoch_loss=2.423328\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=284, batch=10 train loss <loss>=2.433711624145508\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] Epoch[284] Batch [10]#011Speed: 2532.68 samples/sec#011loss=2.433712\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] processed a total of 1390 examples\n",
      "#metrics {\"StartTime\": 1747842862.500542, \"EndTime\": 1747842863.3083968, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 807.5969219207764, \"count\": 1, \"min\": 807.5969219207764, \"max\": 807.5969219207764}}}\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1720.8934941406326 records/second\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] #progress_metric: host=algo-1, completed 71.25 % of epochs\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=284, train loss <loss>=2.4233281395652075\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] Epoch[285] Batch[0] avg_epoch_loss=2.332362\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=2.3323616981506348\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] Epoch[285] Batch[5] avg_epoch_loss=2.300478\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=2.3004777828852334\n",
      "[05/21/2025 15:54:23 INFO 140269512570688] Epoch[285] Batch [5]#011Speed: 2792.39 samples/sec#011loss=2.300478\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] Epoch[285] Batch[10] avg_epoch_loss=2.254649\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=2.199654388427734\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] Epoch[285] Batch [10]#011Speed: 2379.73 samples/sec#011loss=2.199654\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747842863.3084702, \"EndTime\": 1747842864.120652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.8240833282471, \"count\": 1, \"min\": 811.8240833282471, \"max\": 811.8240833282471}}}\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1613.468600055206 records/second\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] #progress_metric: host=algo-1, completed 71.5 % of epochs\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=285, train loss <loss>=2.254648967222734\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_e186010e-a35e-4cce-a669-81e57ae6314e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842864.120712, \"EndTime\": 1747842864.1298268, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.793115615844727, \"count\": 1, \"min\": 8.793115615844727, \"max\": 8.793115615844727}}}\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] Epoch[286] Batch[0] avg_epoch_loss=2.217944\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=2.217944383621216\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] Epoch[286] Batch[5] avg_epoch_loss=2.260993\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=2.2609928448994956\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] Epoch[286] Batch [5]#011Speed: 2764.62 samples/sec#011loss=2.260993\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] Epoch[286] Batch[10] avg_epoch_loss=2.459466\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=286, batch=10 train loss <loss>=2.69763445854187\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] Epoch[286] Batch [10]#011Speed: 2627.38 samples/sec#011loss=2.697634\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747842864.1298838, \"EndTime\": 1747842864.9206123, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.6758785247803, \"count\": 1, \"min\": 790.6758785247803, \"max\": 790.6758785247803}}}\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1662.9510537582537 records/second\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] #progress_metric: host=algo-1, completed 71.75 % of epochs\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] #quality_metric: host=algo-1, epoch=286, train loss <loss>=2.4594663056460293\n",
      "[05/21/2025 15:54:24 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] Epoch[287] Batch[0] avg_epoch_loss=2.301292\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=2.3012924194335938\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] Epoch[287] Batch[5] avg_epoch_loss=2.335056\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=2.3350563049316406\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] Epoch[287] Batch [5]#011Speed: 2627.29 samples/sec#011loss=2.335056\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] Epoch[287] Batch[10] avg_epoch_loss=2.482142\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=2.658645820617676\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] Epoch[287] Batch [10]#011Speed: 2534.28 samples/sec#011loss=2.658646\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747842864.920668, \"EndTime\": 1747842865.7339482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 812.9141330718994, \"count\": 1, \"min\": 812.9141330718994, \"max\": 812.9141330718994}}}\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1676.5097896956654 records/second\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] #progress_metric: host=algo-1, completed 72.0 % of epochs\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] #quality_metric: host=algo-1, epoch=287, train loss <loss>=2.482142448425293\n",
      "[05/21/2025 15:54:25 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] Epoch[288] Batch[0] avg_epoch_loss=2.323566\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=2.323565721511841\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] Epoch[288] Batch[5] avg_epoch_loss=2.338146\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=2.338145613670349\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] Epoch[288] Batch [5]#011Speed: 2746.35 samples/sec#011loss=2.338146\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] Epoch[288] Batch[10] avg_epoch_loss=2.411647\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=288, batch=10 train loss <loss>=2.499848985671997\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] Epoch[288] Batch [10]#011Speed: 2501.77 samples/sec#011loss=2.499849\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] processed a total of 1402 examples\n",
      "#metrics {\"StartTime\": 1747842865.7340045, \"EndTime\": 1747842866.5317879, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 797.5308895111084, \"count\": 1, \"min\": 797.5308895111084, \"max\": 797.5308895111084}}}\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1757.7207100811036 records/second\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] #progress_metric: host=algo-1, completed 72.25 % of epochs\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=288, train loss <loss>=2.411647146398371\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] Epoch[289] Batch[0] avg_epoch_loss=2.343884\n",
      "[05/21/2025 15:54:26 INFO 140269512570688] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=2.343883752822876\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] Epoch[289] Batch[5] avg_epoch_loss=2.319509\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=2.3195090691248574\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] Epoch[289] Batch [5]#011Speed: 2891.59 samples/sec#011loss=2.319509\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] Epoch[289] Batch[10] avg_epoch_loss=2.318605\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=289, batch=10 train loss <loss>=2.317519283294678\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] Epoch[289] Batch [10]#011Speed: 2840.05 samples/sec#011loss=2.317519\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747842866.5318494, \"EndTime\": 1747842867.3270574, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.9397563934326, \"count\": 1, \"min\": 794.9397563934326, \"max\": 794.9397563934326}}}\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1617.5633377397012 records/second\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] #progress_metric: host=algo-1, completed 72.5 % of epochs\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=289, train loss <loss>=2.3186046210202305\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] Epoch[290] Batch[0] avg_epoch_loss=2.352537\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=2.352537155151367\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] Epoch[290] Batch[5] avg_epoch_loss=2.295627\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=2.2956270376841226\n",
      "[05/21/2025 15:54:27 INFO 140269512570688] Epoch[290] Batch [5]#011Speed: 2909.07 samples/sec#011loss=2.295627\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] Epoch[290] Batch[10] avg_epoch_loss=2.332668\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=290, batch=10 train loss <loss>=2.3771167278289793\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] Epoch[290] Batch [10]#011Speed: 2582.14 samples/sec#011loss=2.377117\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747842867.327113, \"EndTime\": 1747842868.1192396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.8820381164551, \"count\": 1, \"min\": 791.8820381164551, \"max\": 791.8820381164551}}}\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1623.7851640876863 records/second\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] #progress_metric: host=algo-1, completed 72.75 % of epochs\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=290, train loss <loss>=2.3326678059317847\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] Epoch[291] Batch[0] avg_epoch_loss=2.274226\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=2.274225950241089\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] Epoch[291] Batch[5] avg_epoch_loss=2.313109\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=2.3131094773610434\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] Epoch[291] Batch [5]#011Speed: 2774.73 samples/sec#011loss=2.313109\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] Epoch[291] Batch[10] avg_epoch_loss=2.235725\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=291, batch=10 train loss <loss>=2.1428632497787476\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] Epoch[291] Batch [10]#011Speed: 2646.14 samples/sec#011loss=2.142863\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747842868.1193032, \"EndTime\": 1747842868.9301314, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 810.5602264404297, \"count\": 1, \"min\": 810.5602264404297, \"max\": 810.5602264404297}}}\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1627.0853231399706 records/second\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] #progress_metric: host=algo-1, completed 73.0 % of epochs\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] #quality_metric: host=algo-1, epoch=291, train loss <loss>=2.23572482846\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:54:28 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_c8e5f94e-3a1e-4f03-94b9-32d6cd52efe8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842868.9301934, \"EndTime\": 1747842868.9400876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.603261947631836, \"count\": 1, \"min\": 9.603261947631836, \"max\": 9.603261947631836}}}\n",
      "[05/21/2025 15:54:29 INFO 140269512570688] Epoch[292] Batch[0] avg_epoch_loss=2.220142\n",
      "[05/21/2025 15:54:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=2.220142364501953\n",
      "[05/21/2025 15:54:29 INFO 140269512570688] Epoch[292] Batch[5] avg_epoch_loss=2.246835\n",
      "[05/21/2025 15:54:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=2.2468348344167075\n",
      "[05/21/2025 15:54:29 INFO 140269512570688] Epoch[292] Batch [5]#011Speed: 2875.34 samples/sec#011loss=2.246835\n",
      "[05/21/2025 15:54:29 INFO 140269512570688] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747842868.9401503, \"EndTime\": 1747842869.6848824, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 744.6768283843994, \"count\": 1, \"min\": 744.6768283843994, \"max\": 744.6768283843994}}}\n",
      "[05/21/2025 15:54:29 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1715.9532533136564 records/second\n",
      "[05/21/2025 15:54:29 INFO 140269512570688] #progress_metric: host=algo-1, completed 73.25 % of epochs\n",
      "[05/21/2025 15:54:29 INFO 140269512570688] #quality_metric: host=algo-1, epoch=292, train loss <loss>=2.2510253190994263\n",
      "[05/21/2025 15:54:29 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] Epoch[293] Batch[0] avg_epoch_loss=2.192140\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=2.1921401023864746\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] Epoch[293] Batch[5] avg_epoch_loss=2.269033\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=2.2690332730611167\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] Epoch[293] Batch [5]#011Speed: 2709.56 samples/sec#011loss=2.269033\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] Epoch[293] Batch[10] avg_epoch_loss=2.367896\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=293, batch=10 train loss <loss>=2.4865322589874266\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] Epoch[293] Batch [10]#011Speed: 2542.62 samples/sec#011loss=2.486532\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747842869.6849499, \"EndTime\": 1747842870.5127609, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 827.4307250976562, \"count\": 1, \"min\": 827.4307250976562, \"max\": 827.4307250976562}}}\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1643.4631277309404 records/second\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] #progress_metric: host=algo-1, completed 73.5 % of epochs\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=293, train loss <loss>=2.3678964484821665\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] Epoch[294] Batch[0] avg_epoch_loss=2.306882\n",
      "[05/21/2025 15:54:30 INFO 140269512570688] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=2.30688214302063\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] Epoch[294] Batch[5] avg_epoch_loss=2.271520\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=2.271519581476847\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] Epoch[294] Batch [5]#011Speed: 2822.87 samples/sec#011loss=2.271520\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] Epoch[294] Batch[10] avg_epoch_loss=2.219678\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=294, batch=10 train loss <loss>=2.157467412948608\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] Epoch[294] Batch [10]#011Speed: 2735.79 samples/sec#011loss=2.157467\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747842870.512822, \"EndTime\": 1747842871.3134015, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 800.3132343292236, \"count\": 1, \"min\": 800.3132343292236, \"max\": 800.3132343292236}}}\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1616.6853560209393 records/second\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] #progress_metric: host=algo-1, completed 73.75 % of epochs\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=294, train loss <loss>=2.219677686691284\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_e00e9798-97b7-4e8a-8fab-cb5bea717170-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842871.313461, \"EndTime\": 1747842871.3230414, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.276628494262695, \"count\": 1, \"min\": 9.276628494262695, \"max\": 9.276628494262695}}}\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] Epoch[295] Batch[0] avg_epoch_loss=2.309776\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=295, batch=0 train loss <loss>=2.3097758293151855\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] Epoch[295] Batch[5] avg_epoch_loss=2.273225\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] #quality_metric: host=algo-1, epoch=295, batch=5 train loss <loss>=2.273225426673889\n",
      "[05/21/2025 15:54:31 INFO 140269512570688] Epoch[295] Batch [5]#011Speed: 2754.70 samples/sec#011loss=2.273225\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] Epoch[295] Batch[10] avg_epoch_loss=2.340067\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=295, batch=10 train loss <loss>=2.420276737213135\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] Epoch[295] Batch [10]#011Speed: 2441.41 samples/sec#011loss=2.420277\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747842871.323097, \"EndTime\": 1747842872.150209, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 827.0599842071533, \"count\": 1, \"min\": 827.0599842071533, \"max\": 827.0599842071533}}}\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1640.5737867136384 records/second\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] #progress_metric: host=algo-1, completed 74.0 % of epochs\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=295, train loss <loss>=2.3400669314644555\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] Epoch[296] Batch[0] avg_epoch_loss=2.292784\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=296, batch=0 train loss <loss>=2.2927842140197754\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] Epoch[296] Batch[5] avg_epoch_loss=2.262819\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=296, batch=5 train loss <loss>=2.262819250424703\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] Epoch[296] Batch [5]#011Speed: 2902.57 samples/sec#011loss=2.262819\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747842872.1502695, \"EndTime\": 1747842872.901814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 751.2738704681396, \"count\": 1, \"min\": 751.2738704681396, \"max\": 751.2738704681396}}}\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1698.2324145669072 records/second\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] #progress_metric: host=algo-1, completed 74.25 % of epochs\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] #quality_metric: host=algo-1, epoch=296, train loss <loss>=2.269541549682617\n",
      "[05/21/2025 15:54:32 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] Epoch[297] Batch[0] avg_epoch_loss=2.247973\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=297, batch=0 train loss <loss>=2.2479732036590576\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] Epoch[297] Batch[5] avg_epoch_loss=2.264954\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=297, batch=5 train loss <loss>=2.2649537722269693\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] Epoch[297] Batch [5]#011Speed: 2826.80 samples/sec#011loss=2.264954\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747842872.9018788, \"EndTime\": 1747842873.6264558, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 724.22194480896, \"count\": 1, \"min\": 724.22194480896, \"max\": 724.22194480896}}}\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1757.531477145026 records/second\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] #progress_metric: host=algo-1, completed 74.5 % of epochs\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=297, train loss <loss>=2.272858715057373\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] Epoch[298] Batch[0] avg_epoch_loss=2.343614\n",
      "[05/21/2025 15:54:33 INFO 140269512570688] #quality_metric: host=algo-1, epoch=298, batch=0 train loss <loss>=2.343613624572754\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] Epoch[298] Batch[5] avg_epoch_loss=2.318746\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=298, batch=5 train loss <loss>=2.3187460899353027\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] Epoch[298] Batch [5]#011Speed: 2942.20 samples/sec#011loss=2.318746\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] Epoch[298] Batch[10] avg_epoch_loss=2.288340\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=298, batch=10 train loss <loss>=2.251853609085083\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] Epoch[298] Batch [10]#011Speed: 2926.93 samples/sec#011loss=2.251854\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747842873.626515, \"EndTime\": 1747842874.3782332, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 751.4157295227051, \"count\": 1, \"min\": 751.4157295227051, \"max\": 751.4157295227051}}}\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1727.2179717760957 records/second\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] #progress_metric: host=algo-1, completed 74.75 % of epochs\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=298, train loss <loss>=2.2883404168215664\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] Epoch[299] Batch[0] avg_epoch_loss=2.333961\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=299, batch=0 train loss <loss>=2.33396053314209\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] Epoch[299] Batch[5] avg_epoch_loss=2.320504\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] #quality_metric: host=algo-1, epoch=299, batch=5 train loss <loss>=2.320504387219747\n",
      "[05/21/2025 15:54:34 INFO 140269512570688] Epoch[299] Batch [5]#011Speed: 2965.55 samples/sec#011loss=2.320504\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] processed a total of 1256 examples\n",
      "#metrics {\"StartTime\": 1747842874.3782873, \"EndTime\": 1747842875.0949864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 716.4492607116699, \"count\": 1, \"min\": 716.4492607116699, \"max\": 716.4492607116699}}}\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1752.8642091067625 records/second\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] #progress_metric: host=algo-1, completed 75.0 % of epochs\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=299, train loss <loss>=2.325003457069397\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] Epoch[300] Batch[0] avg_epoch_loss=2.358623\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=300, batch=0 train loss <loss>=2.3586227893829346\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] Epoch[300] Batch[5] avg_epoch_loss=2.250700\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=300, batch=5 train loss <loss>=2.250699599583944\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] Epoch[300] Batch [5]#011Speed: 2971.29 samples/sec#011loss=2.250700\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747842875.0950475, \"EndTime\": 1747842875.799578, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 704.1945457458496, \"count\": 1, \"min\": 704.1945457458496, \"max\": 704.1945457458496}}}\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1797.559465659941 records/second\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] #progress_metric: host=algo-1, completed 75.25 % of epochs\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] #quality_metric: host=algo-1, epoch=300, train loss <loss>=2.247072672843933\n",
      "[05/21/2025 15:54:35 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] Epoch[301] Batch[0] avg_epoch_loss=2.221908\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=301, batch=0 train loss <loss>=2.2219080924987793\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] Epoch[301] Batch[5] avg_epoch_loss=2.229663\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=301, batch=5 train loss <loss>=2.229663054148356\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] Epoch[301] Batch [5]#011Speed: 2900.84 samples/sec#011loss=2.229663\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] Epoch[301] Batch[10] avg_epoch_loss=2.237858\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=301, batch=10 train loss <loss>=2.2476916790008543\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] Epoch[301] Batch [10]#011Speed: 2615.59 samples/sec#011loss=2.247692\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] processed a total of 1387 examples\n",
      "#metrics {\"StartTime\": 1747842875.7996397, \"EndTime\": 1747842876.573482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 773.5555171966553, \"count\": 1, \"min\": 773.5555171966553, \"max\": 773.5555171966553}}}\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1792.8032843973253 records/second\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] #progress_metric: host=algo-1, completed 75.5 % of epochs\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=301, train loss <loss>=2.2378578836267646\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] Epoch[302] Batch[0] avg_epoch_loss=2.255950\n",
      "[05/21/2025 15:54:36 INFO 140269512570688] #quality_metric: host=algo-1, epoch=302, batch=0 train loss <loss>=2.2559499740600586\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] Epoch[302] Batch[5] avg_epoch_loss=2.249576\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=302, batch=5 train loss <loss>=2.249575893084208\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] Epoch[302] Batch [5]#011Speed: 2819.41 samples/sec#011loss=2.249576\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] Epoch[302] Batch[10] avg_epoch_loss=2.230955\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=302, batch=10 train loss <loss>=2.2086103916168214\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] Epoch[302] Batch [10]#011Speed: 2560.20 samples/sec#011loss=2.208610\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] processed a total of 1394 examples\n",
      "#metrics {\"StartTime\": 1747842876.573548, \"EndTime\": 1747842877.3585174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.7111225128174, \"count\": 1, \"min\": 784.7111225128174, \"max\": 784.7111225128174}}}\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1776.2502254922779 records/second\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] #progress_metric: host=algo-1, completed 75.75 % of epochs\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=302, train loss <loss>=2.2309552105990322\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] Epoch[303] Batch[0] avg_epoch_loss=2.341825\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=303, batch=0 train loss <loss>=2.341825246810913\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] Epoch[303] Batch[5] avg_epoch_loss=2.268480\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] #quality_metric: host=algo-1, epoch=303, batch=5 train loss <loss>=2.268479585647583\n",
      "[05/21/2025 15:54:37 INFO 140269512570688] Epoch[303] Batch [5]#011Speed: 2969.36 samples/sec#011loss=2.268480\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] Epoch[303] Batch[10] avg_epoch_loss=2.358480\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=303, batch=10 train loss <loss>=2.4664815425872804\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] Epoch[303] Batch [10]#011Speed: 2713.60 samples/sec#011loss=2.466482\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747842877.3585773, \"EndTime\": 1747842878.123123, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 764.2664909362793, \"count\": 1, \"min\": 764.2664909362793, \"max\": 764.2664909362793}}}\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1703.3944494317116 records/second\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] #progress_metric: host=algo-1, completed 76.0 % of epochs\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=303, train loss <loss>=2.3584804751656274\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] Epoch[304] Batch[0] avg_epoch_loss=2.397533\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=304, batch=0 train loss <loss>=2.3975331783294678\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] Epoch[304] Batch[5] avg_epoch_loss=2.269337\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=304, batch=5 train loss <loss>=2.269336740175883\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] Epoch[304] Batch [5]#011Speed: 2997.47 samples/sec#011loss=2.269337\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] Epoch[304] Batch[10] avg_epoch_loss=2.331073\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=304, batch=10 train loss <loss>=2.405155897140503\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] Epoch[304] Batch [10]#011Speed: 2553.59 samples/sec#011loss=2.405156\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747842878.1231828, \"EndTime\": 1747842878.9188068, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 795.276403427124, \"count\": 1, \"min\": 795.276403427124, \"max\": 795.276403427124}}}\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1732.5345681021843 records/second\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] #progress_metric: host=algo-1, completed 76.25 % of epochs\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] #quality_metric: host=algo-1, epoch=304, train loss <loss>=2.3310727206143467\n",
      "[05/21/2025 15:54:38 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] Epoch[305] Batch[0] avg_epoch_loss=2.232990\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=305, batch=0 train loss <loss>=2.232990264892578\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] Epoch[305] Batch[5] avg_epoch_loss=2.229072\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=305, batch=5 train loss <loss>=2.229071537653605\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] Epoch[305] Batch [5]#011Speed: 3001.83 samples/sec#011loss=2.229072\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] Epoch[305] Batch[10] avg_epoch_loss=2.129017\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=305, batch=10 train loss <loss>=2.0089511632919312\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] Epoch[305] Batch [10]#011Speed: 2675.66 samples/sec#011loss=2.008951\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747842878.9188654, \"EndTime\": 1747842879.7104988, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.3715839385986, \"count\": 1, \"min\": 791.3715839385986, \"max\": 791.3715839385986}}}\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1627.1873267508051 records/second\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] #progress_metric: host=algo-1, completed 76.5 % of epochs\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] #quality_metric: host=algo-1, epoch=305, train loss <loss>=2.1290168220346626\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] best epoch loss so far\n",
      "[05/21/2025 15:54:39 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/state_01537c2f-ce8d-4c34-a849-06bdecd0c791-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842879.7106483, \"EndTime\": 1747842879.7204516, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.496450424194336, \"count\": 1, \"min\": 9.496450424194336, \"max\": 9.496450424194336}}}\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] Epoch[306] Batch[0] avg_epoch_loss=2.333641\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=306, batch=0 train loss <loss>=2.3336410522460938\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] Epoch[306] Batch[5] avg_epoch_loss=2.267592\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=306, batch=5 train loss <loss>=2.2675917545954385\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] Epoch[306] Batch [5]#011Speed: 2689.27 samples/sec#011loss=2.267592\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] Epoch[306] Batch[10] avg_epoch_loss=2.301074\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=306, batch=10 train loss <loss>=2.341251993179321\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] Epoch[306] Batch [10]#011Speed: 2797.10 samples/sec#011loss=2.341252\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747842879.7205186, \"EndTime\": 1747842880.5361848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 815.6194686889648, \"count\": 1, \"min\": 815.6194686889648, \"max\": 815.6194686889648}}}\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1582.6724932489724 records/second\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] #progress_metric: host=algo-1, completed 76.75 % of epochs\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=306, train loss <loss>=2.301073681224476\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] Epoch[307] Batch[0] avg_epoch_loss=2.283890\n",
      "[05/21/2025 15:54:40 INFO 140269512570688] #quality_metric: host=algo-1, epoch=307, batch=0 train loss <loss>=2.2838897705078125\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] Epoch[307] Batch[5] avg_epoch_loss=2.219303\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=307, batch=5 train loss <loss>=2.219302694002787\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] Epoch[307] Batch [5]#011Speed: 2918.53 samples/sec#011loss=2.219303\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] Epoch[307] Batch[10] avg_epoch_loss=2.213851\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=307, batch=10 train loss <loss>=2.2073097229003906\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] Epoch[307] Batch [10]#011Speed: 2612.31 samples/sec#011loss=2.207310\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747842880.5362463, \"EndTime\": 1747842881.3356774, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 798.6187934875488, \"count\": 1, \"min\": 798.6187934875488, \"max\": 798.6187934875488}}}\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1652.6809791044775 records/second\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] #progress_metric: host=algo-1, completed 77.0 % of epochs\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=307, train loss <loss>=2.2138513435016978\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] Epoch[308] Batch[0] avg_epoch_loss=2.218814\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=308, batch=0 train loss <loss>=2.2188143730163574\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] Epoch[308] Batch[5] avg_epoch_loss=2.286531\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] #quality_metric: host=algo-1, epoch=308, batch=5 train loss <loss>=2.28653077284495\n",
      "[05/21/2025 15:54:41 INFO 140269512570688] Epoch[308] Batch [5]#011Speed: 2870.30 samples/sec#011loss=2.286531\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] Epoch[308] Batch[10] avg_epoch_loss=2.302257\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=308, batch=10 train loss <loss>=2.3211287021636964\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] Epoch[308] Batch [10]#011Speed: 2580.88 samples/sec#011loss=2.321129\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] processed a total of 1376 examples\n",
      "#metrics {\"StartTime\": 1747842881.335732, \"EndTime\": 1747842882.1148434, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 778.874397277832, \"count\": 1, \"min\": 778.874397277832, \"max\": 778.874397277832}}}\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1766.4621902572458 records/second\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] #progress_metric: host=algo-1, completed 77.25 % of epochs\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=308, train loss <loss>=2.302257104353471\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] Epoch[309] Batch[0] avg_epoch_loss=2.319828\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=309, batch=0 train loss <loss>=2.3198280334472656\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] Epoch[309] Batch[5] avg_epoch_loss=2.278731\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=309, batch=5 train loss <loss>=2.278730630874634\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] Epoch[309] Batch [5]#011Speed: 2862.17 samples/sec#011loss=2.278731\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] Epoch[309] Batch[10] avg_epoch_loss=2.259789\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=309, batch=10 train loss <loss>=2.2370582103729246\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] Epoch[309] Batch [10]#011Speed: 2715.97 samples/sec#011loss=2.237058\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747842882.1148996, \"EndTime\": 1747842882.892616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 777.4677276611328, \"count\": 1, \"min\": 777.4677276611328, \"max\": 777.4677276611328}}}\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1693.6779236181355 records/second\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] #progress_metric: host=algo-1, completed 77.5 % of epochs\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] #quality_metric: host=algo-1, epoch=309, train loss <loss>=2.2597886215556753\n",
      "[05/21/2025 15:54:42 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] Epoch[310] Batch[0] avg_epoch_loss=2.449386\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=310, batch=0 train loss <loss>=2.4493863582611084\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] Epoch[310] Batch[5] avg_epoch_loss=2.308610\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=310, batch=5 train loss <loss>=2.308609922726949\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] Epoch[310] Batch [5]#011Speed: 2805.59 samples/sec#011loss=2.308610\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] Epoch[310] Batch[10] avg_epoch_loss=2.372211\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=310, batch=10 train loss <loss>=2.4485331058502195\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] Epoch[310] Batch [10]#011Speed: 2670.28 samples/sec#011loss=2.448533\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747842882.892716, \"EndTime\": 1747842883.6929245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.8964786529541, \"count\": 1, \"min\": 799.8964786529541, \"max\": 799.8964786529541}}}\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1691.2969770664758 records/second\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] #progress_metric: host=algo-1, completed 77.75 % of epochs\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] #quality_metric: host=algo-1, epoch=310, train loss <loss>=2.372211369601163\n",
      "[05/21/2025 15:54:43 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] Epoch[311] Batch[0] avg_epoch_loss=2.324314\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=311, batch=0 train loss <loss>=2.3243141174316406\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] Epoch[311] Batch[5] avg_epoch_loss=2.272569\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=311, batch=5 train loss <loss>=2.272569020589193\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] Epoch[311] Batch [5]#011Speed: 2607.07 samples/sec#011loss=2.272569\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] processed a total of 1259 examples\n",
      "#metrics {\"StartTime\": 1747842883.6929786, \"EndTime\": 1747842884.4397793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 746.5548515319824, \"count\": 1, \"min\": 746.5548515319824, \"max\": 746.5548515319824}}}\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1686.1973197125249 records/second\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] #progress_metric: host=algo-1, completed 78.0 % of epochs\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=311, train loss <loss>=2.282926106452942\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] Epoch[312] Batch[0] avg_epoch_loss=2.240318\n",
      "[05/21/2025 15:54:44 INFO 140269512570688] #quality_metric: host=algo-1, epoch=312, batch=0 train loss <loss>=2.2403182983398438\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] Epoch[312] Batch[5] avg_epoch_loss=2.284416\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=312, batch=5 train loss <loss>=2.2844162782033286\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] Epoch[312] Batch [5]#011Speed: 2567.17 samples/sec#011loss=2.284416\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] Epoch[312] Batch[10] avg_epoch_loss=2.268657\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=312, batch=10 train loss <loss>=2.2497462749481203\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] Epoch[312] Batch [10]#011Speed: 2593.82 samples/sec#011loss=2.249746\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747842884.4398432, \"EndTime\": 1747842885.251165, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.0232353210449, \"count\": 1, \"min\": 811.0232353210449, \"max\": 811.0232353210449}}}\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1594.1023626259603 records/second\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] #progress_metric: host=algo-1, completed 78.25 % of epochs\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=312, train loss <loss>=2.268657185814597\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] Epoch[313] Batch[0] avg_epoch_loss=2.297000\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=313, batch=0 train loss <loss>=2.2970004081726074\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] Epoch[313] Batch[5] avg_epoch_loss=2.249608\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=313, batch=5 train loss <loss>=2.2496079206466675\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] Epoch[313] Batch [5]#011Speed: 2786.40 samples/sec#011loss=2.249608\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] processed a total of 1277 examples\n",
      "#metrics {\"StartTime\": 1747842885.2512248, \"EndTime\": 1747842885.9892237, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 737.7500534057617, \"count\": 1, \"min\": 737.7500534057617, \"max\": 737.7500534057617}}}\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1730.7528429433737 records/second\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] #progress_metric: host=algo-1, completed 78.5 % of epochs\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] #quality_metric: host=algo-1, epoch=313, train loss <loss>=2.256643772125244\n",
      "[05/21/2025 15:54:45 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] Epoch[314] Batch[0] avg_epoch_loss=2.247720\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=314, batch=0 train loss <loss>=2.2477200031280518\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] Epoch[314] Batch[5] avg_epoch_loss=2.255325\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=314, batch=5 train loss <loss>=2.2553248008092246\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] Epoch[314] Batch [5]#011Speed: 2827.62 samples/sec#011loss=2.255325\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] Epoch[314] Batch[10] avg_epoch_loss=2.178207\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=314, batch=10 train loss <loss>=2.0856667041778563\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] Epoch[314] Batch [10]#011Speed: 2671.91 samples/sec#011loss=2.085667\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747842885.9892752, \"EndTime\": 1747842886.7675202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 777.9624462127686, \"count\": 1, \"min\": 777.9624462127686, \"max\": 777.9624462127686}}}\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1695.267035446771 records/second\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] #progress_metric: host=algo-1, completed 78.75 % of epochs\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] #quality_metric: host=algo-1, epoch=314, train loss <loss>=2.1782074841586025\n",
      "[05/21/2025 15:54:46 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] Epoch[315] Batch[0] avg_epoch_loss=2.202909\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=315, batch=0 train loss <loss>=2.202908754348755\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] Epoch[315] Batch[5] avg_epoch_loss=2.237933\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=315, batch=5 train loss <loss>=2.2379334370295205\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] Epoch[315] Batch [5]#011Speed: 2556.29 samples/sec#011loss=2.237933\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] Epoch[315] Batch[10] avg_epoch_loss=2.246813\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=315, batch=10 train loss <loss>=2.2574695110321046\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] Epoch[315] Batch [10]#011Speed: 2486.82 samples/sec#011loss=2.257470\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747842886.767578, \"EndTime\": 1747842887.5839274, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 816.0982131958008, \"count\": 1, \"min\": 816.0982131958008, \"max\": 816.0982131958008}}}\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1673.639194585389 records/second\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] #progress_metric: host=algo-1, completed 79.0 % of epochs\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=315, train loss <loss>=2.2468134706670586\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] Epoch[316] Batch[0] avg_epoch_loss=2.201608\n",
      "[05/21/2025 15:54:47 INFO 140269512570688] #quality_metric: host=algo-1, epoch=316, batch=0 train loss <loss>=2.201608180999756\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] Epoch[316] Batch[5] avg_epoch_loss=2.272944\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=316, batch=5 train loss <loss>=2.2729443311691284\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] Epoch[316] Batch [5]#011Speed: 2791.18 samples/sec#011loss=2.272944\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] Epoch[316] Batch[10] avg_epoch_loss=2.324178\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=316, batch=10 train loss <loss>=2.385657548904419\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] Epoch[316] Batch [10]#011Speed: 2717.86 samples/sec#011loss=2.385658\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747842887.5839863, \"EndTime\": 1747842888.366355, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 782.071590423584, \"count\": 1, \"min\": 782.071590423584, \"max\": 782.071590423584}}}\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1673.5450248379368 records/second\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] #progress_metric: host=algo-1, completed 79.25 % of epochs\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=316, train loss <loss>=2.324177611957897\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] Epoch[317] Batch[0] avg_epoch_loss=2.277118\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=317, batch=0 train loss <loss>=2.27711820602417\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] Epoch[317] Batch[5] avg_epoch_loss=2.264643\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] #quality_metric: host=algo-1, epoch=317, batch=5 train loss <loss>=2.2646434704462686\n",
      "[05/21/2025 15:54:48 INFO 140269512570688] Epoch[317] Batch [5]#011Speed: 2917.84 samples/sec#011loss=2.264643\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747842888.3664134, \"EndTime\": 1747842889.0790553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 712.3658657073975, \"count\": 1, \"min\": 712.3658657073975, \"max\": 712.3658657073975}}}\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1796.5859737561757 records/second\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] #progress_metric: host=algo-1, completed 79.5 % of epochs\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=317, train loss <loss>=2.2626570224761964\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] Epoch[318] Batch[0] avg_epoch_loss=2.135486\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=318, batch=0 train loss <loss>=2.135485887527466\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] Epoch[318] Batch[5] avg_epoch_loss=2.222179\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=318, batch=5 train loss <loss>=2.2221792141596475\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] Epoch[318] Batch [5]#011Speed: 2921.30 samples/sec#011loss=2.222179\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] Epoch[318] Batch[10] avg_epoch_loss=2.142906\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=318, batch=10 train loss <loss>=2.0477788925170897\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] Epoch[318] Batch [10]#011Speed: 2659.63 samples/sec#011loss=2.047779\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747842889.0791209, \"EndTime\": 1747842889.850565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 771.1539268493652, \"count\": 1, \"min\": 771.1539268493652, \"max\": 771.1539268493652}}}\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1710.2482130193466 records/second\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] #progress_metric: host=algo-1, completed 79.75 % of epochs\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] #quality_metric: host=algo-1, epoch=318, train loss <loss>=2.142906340685758\n",
      "[05/21/2025 15:54:49 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] Epoch[319] Batch[0] avg_epoch_loss=2.177178\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=319, batch=0 train loss <loss>=2.177178382873535\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] Epoch[319] Batch[5] avg_epoch_loss=2.300233\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=319, batch=5 train loss <loss>=2.3002328475316367\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] Epoch[319] Batch [5]#011Speed: 2746.63 samples/sec#011loss=2.300233\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] Epoch[319] Batch[10] avg_epoch_loss=2.305545\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=319, batch=10 train loss <loss>=2.311918544769287\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] Epoch[319] Batch [10]#011Speed: 2627.52 samples/sec#011loss=2.311919\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747842889.8506176, \"EndTime\": 1747842890.6424687, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 791.6014194488525, \"count\": 1, \"min\": 791.6014194488525, \"max\": 791.6014194488525}}}\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1652.1521456311616 records/second\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] #progress_metric: host=algo-1, completed 80.0 % of epochs\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=319, train loss <loss>=2.305544528094205\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] Epoch[320] Batch[0] avg_epoch_loss=2.290073\n",
      "[05/21/2025 15:54:50 INFO 140269512570688] #quality_metric: host=algo-1, epoch=320, batch=0 train loss <loss>=2.2900726795196533\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] Epoch[320] Batch[5] avg_epoch_loss=2.232834\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=320, batch=5 train loss <loss>=2.232833504676819\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] Epoch[320] Batch [5]#011Speed: 2733.87 samples/sec#011loss=2.232834\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747842890.6425333, \"EndTime\": 1747842891.384722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 741.9347763061523, \"count\": 1, \"min\": 741.9347763061523, \"max\": 741.9347763061523}}}\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1699.3853264068641 records/second\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] #progress_metric: host=algo-1, completed 80.25 % of epochs\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=320, train loss <loss>=2.2423925399780273\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] Epoch[321] Batch[0] avg_epoch_loss=2.298638\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=321, batch=0 train loss <loss>=2.298638105392456\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] Epoch[321] Batch[5] avg_epoch_loss=2.255655\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] #quality_metric: host=algo-1, epoch=321, batch=5 train loss <loss>=2.2556550105412803\n",
      "[05/21/2025 15:54:51 INFO 140269512570688] Epoch[321] Batch [5]#011Speed: 2566.31 samples/sec#011loss=2.255655\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] Epoch[321] Batch[10] avg_epoch_loss=2.282857\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=321, batch=10 train loss <loss>=2.315500259399414\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] Epoch[321] Batch [10]#011Speed: 2518.60 samples/sec#011loss=2.315500\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747842891.3847876, \"EndTime\": 1747842892.1962433, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 811.1615180969238, \"count\": 1, \"min\": 811.1615180969238, \"max\": 811.1615180969238}}}\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1687.5267591328313 records/second\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] #progress_metric: host=algo-1, completed 80.5 % of epochs\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=321, train loss <loss>=2.2828573963858863\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] Epoch[322] Batch[0] avg_epoch_loss=2.269201\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=322, batch=0 train loss <loss>=2.2692010402679443\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] Epoch[322] Batch[5] avg_epoch_loss=2.265185\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=322, batch=5 train loss <loss>=2.265184680620829\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] Epoch[322] Batch [5]#011Speed: 2590.25 samples/sec#011loss=2.265185\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] Epoch[322] Batch[10] avg_epoch_loss=2.332938\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=322, batch=10 train loss <loss>=2.414242887496948\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] Epoch[322] Batch [10]#011Speed: 2651.04 samples/sec#011loss=2.414243\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747842892.1962998, \"EndTime\": 1747842892.999322, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 802.748441696167, \"count\": 1, \"min\": 802.748441696167, \"max\": 802.748441696167}}}\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1624.2243337911577 records/second\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] #progress_metric: host=algo-1, completed 80.75 % of epochs\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] #quality_metric: host=algo-1, epoch=322, train loss <loss>=2.332938411019065\n",
      "[05/21/2025 15:54:52 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] Epoch[323] Batch[0] avg_epoch_loss=2.353244\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=323, batch=0 train loss <loss>=2.353243589401245\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] Epoch[323] Batch[5] avg_epoch_loss=2.333146\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=323, batch=5 train loss <loss>=2.3331463734308877\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] Epoch[323] Batch [5]#011Speed: 2745.93 samples/sec#011loss=2.333146\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] Epoch[323] Batch[10] avg_epoch_loss=2.315003\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=323, batch=10 train loss <loss>=2.2932306289672852\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] Epoch[323] Batch [10]#011Speed: 2653.06 samples/sec#011loss=2.293231\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747842892.999387, \"EndTime\": 1747842893.7957742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 796.0190773010254, \"count\": 1, \"min\": 796.0190773010254, \"max\": 796.0190773010254}}}\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1632.923230439254 records/second\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] #progress_metric: host=algo-1, completed 81.0 % of epochs\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] #quality_metric: host=algo-1, epoch=323, train loss <loss>=2.315002853220159\n",
      "[05/21/2025 15:54:53 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] Epoch[324] Batch[0] avg_epoch_loss=2.376435\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=324, batch=0 train loss <loss>=2.3764350414276123\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] Epoch[324] Batch[5] avg_epoch_loss=2.411218\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=324, batch=5 train loss <loss>=2.4112181663513184\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] Epoch[324] Batch [5]#011Speed: 2721.80 samples/sec#011loss=2.411218\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] Epoch[324] Batch[10] avg_epoch_loss=2.378350\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=324, batch=10 train loss <loss>=2.3389081954956055\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] Epoch[324] Batch [10]#011Speed: 2591.20 samples/sec#011loss=2.338908\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747842893.7958367, \"EndTime\": 1747842894.5887616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 792.5543785095215, \"count\": 1, \"min\": 792.5543785095215, \"max\": 792.5543785095215}}}\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1686.7617345437898 records/second\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] #progress_metric: host=algo-1, completed 81.25 % of epochs\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=324, train loss <loss>=2.3783499977805396\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] Epoch[325] Batch[0] avg_epoch_loss=2.372542\n",
      "[05/21/2025 15:54:54 INFO 140269512570688] #quality_metric: host=algo-1, epoch=325, batch=0 train loss <loss>=2.372542381286621\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] Epoch[325] Batch[5] avg_epoch_loss=2.346525\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=325, batch=5 train loss <loss>=2.3465246756871543\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] Epoch[325] Batch [5]#011Speed: 2752.36 samples/sec#011loss=2.346525\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] Epoch[325] Batch[10] avg_epoch_loss=2.331666\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=325, batch=10 train loss <loss>=2.3138365268707277\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] Epoch[325] Batch [10]#011Speed: 2696.60 samples/sec#011loss=2.313837\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747842894.5888197, \"EndTime\": 1747842895.3731217, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.0142250061035, \"count\": 1, \"min\": 784.0142250061035, \"max\": 784.0142250061035}}}\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1706.4070939612968 records/second\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] #progress_metric: host=algo-1, completed 81.5 % of epochs\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=325, train loss <loss>=2.331666426225142\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] Epoch[326] Batch[0] avg_epoch_loss=2.189816\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=326, batch=0 train loss <loss>=2.1898157596588135\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] Epoch[326] Batch[5] avg_epoch_loss=2.287283\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] #quality_metric: host=algo-1, epoch=326, batch=5 train loss <loss>=2.287282864252726\n",
      "[05/21/2025 15:54:55 INFO 140269512570688] Epoch[326] Batch [5]#011Speed: 2750.12 samples/sec#011loss=2.287283\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] Epoch[326] Batch[10] avg_epoch_loss=2.333768\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=326, batch=10 train loss <loss>=2.389549493789673\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] Epoch[326] Batch [10]#011Speed: 2577.37 samples/sec#011loss=2.389549\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] processed a total of 1399 examples\n",
      "#metrics {\"StartTime\": 1747842895.3731802, \"EndTime\": 1747842896.15843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 784.9140167236328, \"count\": 1, \"min\": 784.9140167236328, \"max\": 784.9140167236328}}}\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1782.160538769788 records/second\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] #progress_metric: host=algo-1, completed 81.75 % of epochs\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=326, train loss <loss>=2.333767695860429\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] Epoch[327] Batch[0] avg_epoch_loss=2.272861\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=327, batch=0 train loss <loss>=2.2728612422943115\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] Epoch[327] Batch[5] avg_epoch_loss=2.213737\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=327, batch=5 train loss <loss>=2.2137373288472495\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] Epoch[327] Batch [5]#011Speed: 2979.54 samples/sec#011loss=2.213737\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] Epoch[327] Batch[10] avg_epoch_loss=2.258997\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=327, batch=10 train loss <loss>=2.313309097290039\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] Epoch[327] Batch [10]#011Speed: 2598.98 samples/sec#011loss=2.313309\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747842896.1584892, \"EndTime\": 1747842896.953405, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 794.6417331695557, \"count\": 1, \"min\": 794.6417331695557, \"max\": 794.6417331695557}}}\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1679.8113608300123 records/second\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] #progress_metric: host=algo-1, completed 82.0 % of epochs\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] #quality_metric: host=algo-1, epoch=327, train loss <loss>=2.258997223593972\n",
      "[05/21/2025 15:54:56 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] Epoch[328] Batch[0] avg_epoch_loss=2.174572\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=328, batch=0 train loss <loss>=2.1745717525482178\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] Epoch[328] Batch[5] avg_epoch_loss=2.202406\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=328, batch=5 train loss <loss>=2.2024057308832803\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] Epoch[328] Batch [5]#011Speed: 2742.87 samples/sec#011loss=2.202406\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] Epoch[328] Batch[10] avg_epoch_loss=2.205086\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=328, batch=10 train loss <loss>=2.208302354812622\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] Epoch[328] Batch [10]#011Speed: 2784.88 samples/sec#011loss=2.208302\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747842896.9534647, \"EndTime\": 1747842897.7570357, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 803.2946586608887, \"count\": 1, \"min\": 803.2946586608887, \"max\": 803.2946586608887}}}\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1610.6288273519938 records/second\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] #progress_metric: host=algo-1, completed 82.25 % of epochs\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] #quality_metric: host=algo-1, epoch=328, train loss <loss>=2.205086014487527\n",
      "[05/21/2025 15:54:57 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] Epoch[329] Batch[0] avg_epoch_loss=2.453112\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=329, batch=0 train loss <loss>=2.4531116485595703\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] Epoch[329] Batch[5] avg_epoch_loss=2.388006\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=329, batch=5 train loss <loss>=2.38800581296285\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] Epoch[329] Batch [5]#011Speed: 2796.33 samples/sec#011loss=2.388006\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] Epoch[329] Batch[10] avg_epoch_loss=2.333902\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=329, batch=10 train loss <loss>=2.268976831436157\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] Epoch[329] Batch [10]#011Speed: 2678.14 samples/sec#011loss=2.268977\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747842897.757123, \"EndTime\": 1747842898.571383, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 813.971996307373, \"count\": 1, \"min\": 813.971996307373, \"max\": 813.971996307373}}}\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1584.6456561926698 records/second\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] #progress_metric: host=algo-1, completed 82.5 % of epochs\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=329, train loss <loss>=2.333901730450717\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] Epoch[330] Batch[0] avg_epoch_loss=2.332367\n",
      "[05/21/2025 15:54:58 INFO 140269512570688] #quality_metric: host=algo-1, epoch=330, batch=0 train loss <loss>=2.332366943359375\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] Epoch[330] Batch[5] avg_epoch_loss=2.320364\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=330, batch=5 train loss <loss>=2.320364157358805\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] Epoch[330] Batch [5]#011Speed: 2727.47 samples/sec#011loss=2.320364\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747842898.5714436, \"EndTime\": 1747842899.3337882, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 762.0723247528076, \"count\": 1, \"min\": 762.0723247528076, \"max\": 762.0723247528076}}}\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1671.534037581449 records/second\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] #progress_metric: host=algo-1, completed 82.75 % of epochs\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=330, train loss <loss>=2.2944705724716186\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] Epoch[331] Batch[0] avg_epoch_loss=2.301962\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=331, batch=0 train loss <loss>=2.301961898803711\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] Epoch[331] Batch[5] avg_epoch_loss=2.240536\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] #quality_metric: host=algo-1, epoch=331, batch=5 train loss <loss>=2.2405358950297036\n",
      "[05/21/2025 15:54:59 INFO 140269512570688] Epoch[331] Batch [5]#011Speed: 2780.22 samples/sec#011loss=2.240536\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] Epoch[331] Batch[10] avg_epoch_loss=2.239282\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=331, batch=10 train loss <loss>=2.237777280807495\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] Epoch[331] Batch [10]#011Speed: 2441.18 samples/sec#011loss=2.237777\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] processed a total of 1381 examples\n",
      "#metrics {\"StartTime\": 1747842899.3338563, \"EndTime\": 1747842900.159074, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 824.8603343963623, \"count\": 1, \"min\": 824.8603343963623, \"max\": 824.8603343963623}}}\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1673.9992850076744 records/second\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] #progress_metric: host=algo-1, completed 83.0 % of epochs\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=331, train loss <loss>=2.2392819794741543\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] Epoch[332] Batch[0] avg_epoch_loss=2.232653\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=332, batch=0 train loss <loss>=2.2326529026031494\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] Epoch[332] Batch[5] avg_epoch_loss=2.223816\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=332, batch=5 train loss <loss>=2.2238155206044516\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] Epoch[332] Batch [5]#011Speed: 2831.85 samples/sec#011loss=2.223816\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] Epoch[332] Batch[10] avg_epoch_loss=2.270366\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=332, batch=10 train loss <loss>=2.326225996017456\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] Epoch[332] Batch [10]#011Speed: 2628.27 samples/sec#011loss=2.326226\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747842900.159155, \"EndTime\": 1747842900.945448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 786.0357761383057, \"count\": 1, \"min\": 786.0357761383057, \"max\": 786.0357761383057}}}\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1684.204515326215 records/second\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] #progress_metric: host=algo-1, completed 83.25 % of epochs\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] #quality_metric: host=algo-1, epoch=332, train loss <loss>=2.270365736701272\n",
      "[05/21/2025 15:55:00 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] Epoch[333] Batch[0] avg_epoch_loss=2.371485\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=333, batch=0 train loss <loss>=2.3714849948883057\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] Epoch[333] Batch[5] avg_epoch_loss=2.245244\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=333, batch=5 train loss <loss>=2.2452441453933716\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] Epoch[333] Batch [5]#011Speed: 2451.77 samples/sec#011loss=2.245244\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] Epoch[333] Batch[10] avg_epoch_loss=2.250210\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=333, batch=10 train loss <loss>=2.256168985366821\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] Epoch[333] Batch [10]#011Speed: 2674.71 samples/sec#011loss=2.256169\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747842900.945511, \"EndTime\": 1747842901.786959, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 841.1557674407959, \"count\": 1, \"min\": 841.1557674407959, \"max\": 841.1557674407959}}}\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1529.87894839318 records/second\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] #progress_metric: host=algo-1, completed 83.5 % of epochs\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] #quality_metric: host=algo-1, epoch=333, train loss <loss>=2.2502099817449395\n",
      "[05/21/2025 15:55:01 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] Epoch[334] Batch[0] avg_epoch_loss=2.340138\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=334, batch=0 train loss <loss>=2.3401377201080322\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] Epoch[334] Batch[5] avg_epoch_loss=2.367236\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=334, batch=5 train loss <loss>=2.367235541343689\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] Epoch[334] Batch [5]#011Speed: 2671.73 samples/sec#011loss=2.367236\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] Epoch[334] Batch[10] avg_epoch_loss=2.331175\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=334, batch=10 train loss <loss>=2.2879024028778074\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] Epoch[334] Batch [10]#011Speed: 2556.53 samples/sec#011loss=2.287902\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747842901.7870169, \"EndTime\": 1747842902.591555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 804.2604923248291, \"count\": 1, \"min\": 804.2604923248291, \"max\": 804.2604923248291}}}\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1689.5727280892108 records/second\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] #progress_metric: host=algo-1, completed 83.75 % of epochs\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=334, train loss <loss>=2.3311750238591973\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] Epoch[335] Batch[0] avg_epoch_loss=2.466443\n",
      "[05/21/2025 15:55:02 INFO 140269512570688] #quality_metric: host=algo-1, epoch=335, batch=0 train loss <loss>=2.4664430618286133\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] Epoch[335] Batch[5] avg_epoch_loss=2.492677\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=335, batch=5 train loss <loss>=2.4926770528157554\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] Epoch[335] Batch [5]#011Speed: 2535.23 samples/sec#011loss=2.492677\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] Epoch[335] Batch[10] avg_epoch_loss=2.627031\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=335, batch=10 train loss <loss>=2.7882554054260256\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] Epoch[335] Batch [10]#011Speed: 2385.17 samples/sec#011loss=2.788255\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747842902.591611, \"EndTime\": 1747842903.4316514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 839.789628982544, \"count\": 1, \"min\": 839.789628982544, \"max\": 839.789628982544}}}\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1565.7038813660988 records/second\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] #progress_metric: host=algo-1, completed 84.0 % of epochs\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=335, train loss <loss>=2.627030849456787\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] Epoch[336] Batch[0] avg_epoch_loss=2.756597\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=336, batch=0 train loss <loss>=2.756596803665161\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] Epoch[336] Batch[5] avg_epoch_loss=2.649275\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] #quality_metric: host=algo-1, epoch=336, batch=5 train loss <loss>=2.649274786313375\n",
      "[05/21/2025 15:55:03 INFO 140269512570688] Epoch[336] Batch [5]#011Speed: 2707.01 samples/sec#011loss=2.649275\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] Epoch[336] Batch[10] avg_epoch_loss=2.632567\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=336, batch=10 train loss <loss>=2.612517976760864\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] Epoch[336] Batch [10]#011Speed: 2622.35 samples/sec#011loss=2.612518\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747842903.43171, \"EndTime\": 1747842904.231737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 799.7410297393799, \"count\": 1, \"min\": 799.7410297393799, \"max\": 799.7410297393799}}}\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1609.0972889234538 records/second\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] #progress_metric: host=algo-1, completed 84.25 % of epochs\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=336, train loss <loss>=2.632567145607688\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] Epoch[337] Batch[0] avg_epoch_loss=2.584782\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=337, batch=0 train loss <loss>=2.5847818851470947\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] Epoch[337] Batch[5] avg_epoch_loss=2.521114\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] #quality_metric: host=algo-1, epoch=337, batch=5 train loss <loss>=2.521114150683085\n",
      "[05/21/2025 15:55:04 INFO 140269512570688] Epoch[337] Batch [5]#011Speed: 2696.11 samples/sec#011loss=2.521114\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] Epoch[337] Batch[10] avg_epoch_loss=2.454890\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=337, batch=10 train loss <loss>=2.3754216194152833\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] Epoch[337] Batch [10]#011Speed: 2407.15 samples/sec#011loss=2.375422\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] processed a total of 1375 examples\n",
      "#metrics {\"StartTime\": 1747842904.2317939, \"EndTime\": 1747842905.046939, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 814.8560523986816, \"count\": 1, \"min\": 814.8560523986816, \"max\": 814.8560523986816}}}\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1687.2171353309418 records/second\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] #progress_metric: host=algo-1, completed 84.5 % of epochs\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=337, train loss <loss>=2.4548902728340845\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] Epoch[338] Batch[0] avg_epoch_loss=2.299658\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=338, batch=0 train loss <loss>=2.2996580600738525\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] Epoch[338] Batch[5] avg_epoch_loss=2.324755\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=338, batch=5 train loss <loss>=2.32475483417511\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] Epoch[338] Batch [5]#011Speed: 2560.82 samples/sec#011loss=2.324755\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] Epoch[338] Batch[10] avg_epoch_loss=2.357287\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=338, batch=10 train loss <loss>=2.396326684951782\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] Epoch[338] Batch [10]#011Speed: 2411.03 samples/sec#011loss=2.396327\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747842905.047002, \"EndTime\": 1747842905.8830614, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 835.7551097869873, \"count\": 1, \"min\": 835.7551097869873, \"max\": 835.7551097869873}}}\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1605.486205597283 records/second\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] #progress_metric: host=algo-1, completed 84.75 % of epochs\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] #quality_metric: host=algo-1, epoch=338, train loss <loss>=2.3572874936190518\n",
      "[05/21/2025 15:55:05 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] Epoch[339] Batch[0] avg_epoch_loss=2.282540\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=339, batch=0 train loss <loss>=2.2825400829315186\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] Epoch[339] Batch[5] avg_epoch_loss=2.258828\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=339, batch=5 train loss <loss>=2.2588284810384116\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] Epoch[339] Batch [5]#011Speed: 2557.21 samples/sec#011loss=2.258828\n",
      "\n",
      "2025-05-21 15:55:17 Uploading - Uploading generated training model[05/21/2025 15:55:06 INFO 140269512570688] Epoch[339] Batch[10] avg_epoch_loss=2.308649\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=339, batch=10 train loss <loss>=2.3684335231781004\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] Epoch[339] Batch [10]#011Speed: 2627.50 samples/sec#011loss=2.368434\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747842905.8831568, \"EndTime\": 1747842906.7214227, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 837.9025459289551, \"count\": 1, \"min\": 837.9025459289551, \"max\": 837.9025459289551}}}\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1542.937369358871 records/second\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] #progress_metric: host=algo-1, completed 85.0 % of epochs\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] #quality_metric: host=algo-1, epoch=339, train loss <loss>=2.30864895473827\n",
      "[05/21/2025 15:55:06 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] Epoch[340] Batch[0] avg_epoch_loss=2.279753\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=340, batch=0 train loss <loss>=2.2797529697418213\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] Epoch[340] Batch[5] avg_epoch_loss=2.241872\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=340, batch=5 train loss <loss>=2.2418715159098306\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] Epoch[340] Batch [5]#011Speed: 2571.93 samples/sec#011loss=2.241872\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] Epoch[340] Batch[10] avg_epoch_loss=2.251470\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=340, batch=10 train loss <loss>=2.2629887580871584\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] Epoch[340] Batch [10]#011Speed: 2527.58 samples/sec#011loss=2.262989\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747842906.7214887, \"EndTime\": 1747842907.5696163, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 847.759485244751, \"count\": 1, \"min\": 847.759485244751, \"max\": 847.759485244751}}}\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1529.7511426709057 records/second\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] #progress_metric: host=algo-1, completed 85.25 % of epochs\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=340, train loss <loss>=2.2514702623540703\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] Epoch[341] Batch[0] avg_epoch_loss=2.200009\n",
      "[05/21/2025 15:55:07 INFO 140269512570688] #quality_metric: host=algo-1, epoch=341, batch=0 train loss <loss>=2.2000088691711426\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] Epoch[341] Batch[5] avg_epoch_loss=2.229377\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=341, batch=5 train loss <loss>=2.229376951853434\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] Epoch[341] Batch [5]#011Speed: 2577.03 samples/sec#011loss=2.229377\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] Epoch[341] Batch[10] avg_epoch_loss=2.158085\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=341, batch=10 train loss <loss>=2.0725342988967896\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] Epoch[341] Batch [10]#011Speed: 2435.26 samples/sec#011loss=2.072534\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747842907.5696719, \"EndTime\": 1747842908.4200404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 849.9677181243896, \"count\": 1, \"min\": 849.9677181243896, \"max\": 849.9677181243896}}}\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1575.1789778424359 records/second\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] #progress_metric: host=algo-1, completed 85.5 % of epochs\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=341, train loss <loss>=2.158084836873141\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] Epoch[342] Batch[0] avg_epoch_loss=2.140128\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=342, batch=0 train loss <loss>=2.1401281356811523\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] Epoch[342] Batch[5] avg_epoch_loss=2.211573\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] #quality_metric: host=algo-1, epoch=342, batch=5 train loss <loss>=2.211572607358297\n",
      "[05/21/2025 15:55:08 INFO 140269512570688] Epoch[342] Batch [5]#011Speed: 2615.32 samples/sec#011loss=2.211573\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] Epoch[342] Batch[10] avg_epoch_loss=2.257882\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=342, batch=10 train loss <loss>=2.3134531497955324\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] Epoch[342] Batch [10]#011Speed: 2337.37 samples/sec#011loss=2.313453\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747842908.4201038, \"EndTime\": 1747842909.2728274, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 852.3988723754883, \"count\": 1, \"min\": 852.3988723754883, \"max\": 852.3988723754883}}}\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1589.4437754115204 records/second\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] #progress_metric: host=algo-1, completed 85.75 % of epochs\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=342, train loss <loss>=2.2578819448297676\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] Epoch[343] Batch[0] avg_epoch_loss=2.224389\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=343, batch=0 train loss <loss>=2.22438907623291\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] Epoch[343] Batch[5] avg_epoch_loss=2.241749\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] #quality_metric: host=algo-1, epoch=343, batch=5 train loss <loss>=2.2417489687601724\n",
      "[05/21/2025 15:55:09 INFO 140269512570688] Epoch[343] Batch [5]#011Speed: 2636.05 samples/sec#011loss=2.241749\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] Epoch[343] Batch[10] avg_epoch_loss=2.230099\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=343, batch=10 train loss <loss>=2.216118860244751\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] Epoch[343] Batch [10]#011Speed: 2309.99 samples/sec#011loss=2.216119\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] processed a total of 1430 examples\n",
      "#metrics {\"StartTime\": 1747842909.272894, \"EndTime\": 1747842910.1761038, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 902.8134346008301, \"count\": 1, \"min\": 902.8134346008301, \"max\": 902.8134346008301}}}\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1583.772231242684 records/second\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] #progress_metric: host=algo-1, completed 86.0 % of epochs\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=343, train loss <loss>=2.2119221488634744\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] Epoch[344] Batch[0] avg_epoch_loss=2.184716\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=344, batch=0 train loss <loss>=2.184715747833252\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] Epoch[344] Batch[5] avg_epoch_loss=2.205889\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=344, batch=5 train loss <loss>=2.2058890660603843\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] Epoch[344] Batch [5]#011Speed: 2541.56 samples/sec#011loss=2.205889\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] processed a total of 1259 examples\n",
      "#metrics {\"StartTime\": 1747842910.176166, \"EndTime\": 1747842910.9514103, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 774.3878364562988, \"count\": 1, \"min\": 774.3878364562988, \"max\": 774.3878364562988}}}\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1625.5946292808 records/second\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] #progress_metric: host=algo-1, completed 86.25 % of epochs\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] #quality_metric: host=algo-1, epoch=344, train loss <loss>=2.183794903755188\n",
      "[05/21/2025 15:55:10 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Epoch[345] Batch[0] avg_epoch_loss=2.166134\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=345, batch=0 train loss <loss>=2.1661338806152344\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Epoch[345] Batch[5] avg_epoch_loss=2.196143\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=345, batch=5 train loss <loss>=2.1961425145467124\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Epoch[345] Batch [5]#011Speed: 2576.07 samples/sec#011loss=2.196143\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Epoch[345] Batch[10] avg_epoch_loss=2.143661\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=345, batch=10 train loss <loss>=2.0806828498840333\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Epoch[345] Batch [10]#011Speed: 2443.30 samples/sec#011loss=2.080683\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747842910.951474, \"EndTime\": 1747842911.7791657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 827.390193939209, \"count\": 1, \"min\": 827.390193939209, \"max\": 827.390193939209}}}\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] #throughput_metric: host=algo-1, train throughput=1625.4223957131303 records/second\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] #progress_metric: host=algo-1, completed 86.5 % of epochs\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] #quality_metric: host=algo-1, epoch=345, train loss <loss>=2.143660848790949\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] loss did not improve\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Loading parameters from best epoch (305)\n",
      "#metrics {\"StartTime\": 1747842911.7792242, \"EndTime\": 1747842911.784315, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 4.810810089111328, \"count\": 1, \"min\": 4.810810089111328, \"max\": 4.810810089111328}}}\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] stopping training now\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Final loss: 2.1290168220346626 (occurred at epoch 305)\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] #quality_metric: host=algo-1, train final_loss <loss>=2.1290168220346626\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Worker algo-1 finished training.\n",
      "[05/21/2025 15:55:11 WARNING 140269512570688] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747842911.7843645, \"EndTime\": 1747842911.8277879, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 42.96398162841797, \"count\": 1, \"min\": 42.96398162841797, \"max\": 42.96398162841797}}}\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747842911.827837, \"EndTime\": 1747842911.8470068, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 62.212467193603516, \"count\": 1, \"min\": 62.212467193603516, \"max\": 62.212467193603516}}}\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747842911.8470604, \"EndTime\": 1747842911.8504364, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 3.3469200134277344, \"count\": 1, \"min\": 3.3469200134277344, \"max\": 3.3469200134277344}}}\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Successfully serialized the model for prediction.\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] #memory_usage::<batchbuffer> = 1.875 mb\n",
      "[05/21/2025 15:55:11 INFO 140269512570688] Evaluating model accuracy on testset using 100 samples\n",
      "#metrics {\"StartTime\": 1747842911.8504717, \"EndTime\": 1747842911.8521295, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}}}\n",
      "#metrics {\"StartTime\": 1747842911.8521676, \"EndTime\": 1747842912.0363662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 184.25559997558594, \"count\": 1, \"min\": 184.25559997558594, \"max\": 184.25559997558594}}}\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, RMSE): 29.74464861043271\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, mean_absolute_QuantileLoss): 1402.123945228259\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, mean_wQuantileLoss): 0.5025533853864727\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, wQuantileLoss[0.1]): 0.21290137329409206\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, wQuantileLoss[0.2]): 0.35561053583698893\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, wQuantileLoss[0.3]): 0.4542025388868051\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, wQuantileLoss[0.4]): 0.5237114789067203\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, wQuantileLoss[0.5]): 0.5794388940257411\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, wQuantileLoss[0.6]): 0.6157915306091309\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, wQuantileLoss[0.7]): 0.6256250864630533\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, wQuantileLoss[0.8]): 0.6051407310185039\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #test_score (algo-1, wQuantileLoss[0.9]): 0.5505582994372186\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #quality_metric: host=algo-1, test RMSE <loss>=29.74464861043271\n",
      "[05/21/2025 15:55:12 INFO 140269512570688] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.5025533853864727\n",
      "#metrics {\"StartTime\": 1747842912.0369055, \"EndTime\": 1747842912.0457158, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 4.135847091674805, \"count\": 1, \"min\": 4.135847091674805, \"max\": 4.135847091674805}, \"totaltime\": {\"sum\": 274885.49065589905, \"count\": 1, \"min\": 274885.49065589905, \"max\": 274885.49065589905}}}\n",
      "\n",
      "2025-05-21 15:55:30 Completed - Training job completed\n",
      "Training seconds: 466\n",
      "Billable seconds: 466\n",
      "CPU times: total: 15 s\n",
      "Wall time: 9min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "bade9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-21 15:55:30 Starting - Preparing the instances for training\n",
      "2025-05-21 15:55:30 Downloading - Downloading the training image\n",
      "2025-05-21 15:55:30 Training - Training image download completed. Training in progress.\n",
      "2025-05-21 15:55:30 Uploading - Uploading generated training model\n",
      "2025-05-21 15:55:30 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-21-15-46-54-277',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec135f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62e6bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.Predictor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            # serializer=JSONSerializer(),\n",
    "            serializer=IdentitySerializer(content_type=\"application/json\"),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        ts,\n",
    "        cat=None,\n",
    "        dynamic_feat=None,\n",
    "        num_samples=100,\n",
    "        return_samples=False,\n",
    "        quantiles=[\"0.1\", \"0.5\", \"0.9\"],\n",
    "    ):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "\n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "\n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + ts.index.freq\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "\n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(\n",
    "            ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None\n",
    "        )\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles,\n",
    "        }\n",
    "\n",
    "        http_request_data = {\"instances\": [instance], \"configuration\": configuration}\n",
    "\n",
    "        return json.dumps(http_request_data).encode(\"utf-8\")\n",
    "\n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode(\"utf-8\"))[\"predictions\"][0]\n",
    "        prediction_length = len(next(iter(predictions[\"quantiles\"].values())))\n",
    "        prediction_index = pd.date_range(\n",
    "            start=prediction_time, freq=freq, periods=prediction_length\n",
    "        )\n",
    "        if return_samples:\n",
    "            dict_of_samples = {\"sample_\" + str(i): s for i, s in enumerate(predictions[\"samples\"])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(\n",
    "            data={**predictions[\"quantiles\"], **dict_of_samples}, index=prediction_index\n",
    "        )\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "\n",
    "\n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]\n",
    "\n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "04c071b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 10:56:44] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-15-56-44-579 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 10:56:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-15-56-44-579 \u001b]8;id=962564;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=345416;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 10:56:45] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-15-56-44-579                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 10:56:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=862905;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=803381;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-15-56-44-579                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 10:56:46] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-15-56-44-579                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 10:56:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=551908;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=428340;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-15-56-44-579                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "49cd1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_a_series(timeseries):\n",
    "    series_list = []\n",
    "    \n",
    "    for ts in timeseries:\n",
    "        # Verificar que la columna 'cantidad' existe\n",
    "        if 'cantidad' in ts.columns:\n",
    "            # Extraer la columna 'cantidad' como una serie\n",
    "            serie = ts['cantidad']\n",
    "\n",
    "            # Asegurarse de que el índice esté ordenado\n",
    "            serie = serie.sort_index()\n",
    "\n",
    "            # Intentar inferir la frecuencia del índice\n",
    "            try:\n",
    "                freq = pd.infer_freq(serie.index)\n",
    "                if freq is not None:\n",
    "                    serie.index.freq = freq\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo inferir frecuencia para una serie: {e}\")\n",
    "\n",
    "            series_list.append(serie)\n",
    "        else:\n",
    "            print(f\"Advertencia: Un dataframe no contiene la columna 'cantidad'\")\n",
    "    \n",
    "    return series_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6fce0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_list = convertir_a_series(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "2ef79e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_lista_features_dinamicas(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Crea una lista de listas con los vectores de 'month' y 'quarter' para cada dataframe.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con columnas 'month' y 'quarter'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de listas donde cada elemento es [month_vector, quarter_vector] para un dataframe\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    lista_features = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío. Se añadirá una lista vacía.\")\n",
    "            lista_features.append([[], []])\n",
    "            continue\n",
    "        \n",
    "        # Verificar que existan las columnas necesarias\n",
    "        columnas_faltantes = []\n",
    "        if 'month' not in df.columns:\n",
    "            columnas_faltantes.append('month')\n",
    "        if 'quarter' not in df.columns:\n",
    "            columnas_faltantes.append('quarter')\n",
    "        \n",
    "        if columnas_faltantes:\n",
    "            # Si faltan columnas, intentar generarlas a partir del índice si es posible\n",
    "            df_temp = df.copy()\n",
    "                \n",
    "            # Generar columnas de fechas si el índice es de tipo datetime\n",
    "            if ('month' in columnas_faltantes or 'quarter' in columnas_faltantes) and isinstance(df_temp.index, pd.DatetimeIndex):\n",
    "                if 'month' not in df_temp.columns:\n",
    "                    df_temp['month'] = df_temp.index.month\n",
    "                if 'quarter' not in df_temp.columns:\n",
    "                    df_temp['quarter'] = df_temp.index.quarter\n",
    "                df = df_temp\n",
    "            elif 'month' in columnas_faltantes or 'quarter' in columnas_faltantes:\n",
    "                # Intentar convertir el índice a datetime si no lo es\n",
    "                try:\n",
    "                    df_temp.index = pd.to_datetime(df_temp.index)\n",
    "                    if 'month' not in df_temp.columns:\n",
    "                        df_temp['month'] = df_temp.index.month\n",
    "                    if 'quarter' not in df_temp.columns:\n",
    "                        df_temp['quarter'] = df_temp.index.quarter\n",
    "                    df = df_temp\n",
    "                except:\n",
    "                    print(f\"Error: No se pueden generar las columnas {columnas_faltantes} para el Dataframe {i}. Se añadirá una lista vacía.\")\n",
    "                    lista_features.append([[], []])\n",
    "                    continue\n",
    "        \n",
    "        # Crear los vectores de características dinámicas\n",
    "        month_vector = df['month'].tolist()\n",
    "        quarter_vector = df['quarter'].tolist()\n",
    "        \n",
    "        # Añadir los vectores a la lista\n",
    "        lista_features.append([month_vector, quarter_vector])\n",
    "        \n",
    "    return lista_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "bf2f1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_list = crear_lista_features_dinamicas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f1877063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>8.005324</td>\n",
       "      <td>10.983337</td>\n",
       "      <td>13.424570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>0.119590</td>\n",
       "      <td>2.713603</td>\n",
       "      <td>4.847787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>-4.027497</td>\n",
       "      <td>-1.945598</td>\n",
       "      <td>0.712716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>-9.014154</td>\n",
       "      <td>-6.940654</td>\n",
       "      <td>-4.373694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>-5.861849</td>\n",
       "      <td>2.172155</td>\n",
       "      <td>7.716484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>-13.019146</td>\n",
       "      <td>1.216626</td>\n",
       "      <td>18.418119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01   8.005324  10.983337  13.424570\n",
       "2024-12-01   0.119590   2.713603   4.847787\n",
       "2025-01-01  -4.027497  -1.945598   0.712716\n",
       "2025-02-01  -9.014154  -6.940654  -4.373694\n",
       "2025-03-01  -5.861849   2.172155   7.716484\n",
       "2025-04-01 -13.019146   1.216626  18.418119"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=6\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "75e29775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    14.0\n",
       "2024-12-01    73.0\n",
       "2025-01-01    26.0\n",
       "2025-02-01    12.0\n",
       "2025-03-01    23.0\n",
       "2025-04-01    29.0\n",
       "Freq: MS, Name: cantidad, dtype: float64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[6].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03a9e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2DO ENTRENAMIENTO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "5649ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    #\"learning_rate\": \"1E-3\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "35de1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "df473ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 11:14:41] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 11:14:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=955046;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=565503;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-16-14-41-449                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=616357;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=837267;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-16-14-41-449                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 16:14:43 Starting - Starting the training job...\n",
      "2025-05-21 16:15:07 Starting - Preparing the instances for training...\n",
      "2025-05-21 16:15:42 Downloading - Downloading the training image.........\n",
      "2025-05-21 16:17:14 Training - Training image download completed. Training in progress..Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '18', 'early_stopping_patience': '40', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '18', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] Detected entry point for worker worker\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] Using early stopping with patience 40\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] random_seed is None\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] [cardinality=auto] Inferred value of cardinality=[2, 4, 5, 6, 6] from dataset.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Training set statistics:\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Real time series\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] number of time series: 15\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] number of observations: 582\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] mean target length: 38.8\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] min/mean/max target: 1.0/30.99656357388316/350.0\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] mean abs(target): 30.99656357388316\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] contains missing values: no\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Small number of time series. Doing 86 passes over dataset with prob 0.9922480620155039 per epoch.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Test set statistics:\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Real time series\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] number of time series: 15\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] number of observations: 672\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] mean target length: 44.8\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] min/mean/max target: 1.0/30.99702380952381/388.0\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] mean abs(target): 30.99702380952381\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] contains missing values: no\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] nvidia-smi: took 0.030 seconds to run.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] nvidia-smi identified 0 GPUs.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Number of GPUs being used: 0\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Create Store: local\n",
      "#metrics {\"StartTime\": 1747844253.0371804, \"EndTime\": 1747844253.0848963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 46.84758186340332, \"count\": 1, \"min\": 46.84758186340332, \"max\": 46.84758186340332}}}\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Number of GPUs being used: 0\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] #memory_usage::<model> = 21 mb\n",
      "#metrics {\"StartTime\": 1747844253.0849526, \"EndTime\": 1747844253.1619067, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 124.61495399475098, \"count\": 1, \"min\": 124.61495399475098, \"max\": 124.61495399475098}}}\n",
      "[16:17:33] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 20480 bytes with malloc directly\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Epoch[0] Batch[0] avg_epoch_loss=3.753399\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.7533986568450928\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Epoch[0] Batch[5] avg_epoch_loss=3.480704\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.4807043075561523\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Epoch[0] Batch [5]#011Speed: 2142.82 samples/sec#011loss=3.480704\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Epoch[0] Batch[10] avg_epoch_loss=3.531558\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.592581605911255\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Epoch[0] Batch [10]#011Speed: 1646.05 samples/sec#011loss=3.592582\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747844253.1619542, \"EndTime\": 1747844254.2148647, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 1052.8380870819092, \"count\": 1, \"min\": 1052.8380870819092, \"max\": 1052.8380870819092}}}\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1284.0146092434939 records/second\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.53155762499029\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_32489641-7d98-4e34-b76f-b67d263fa726-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844254.2149394, \"EndTime\": 1747844254.2264044, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.989189147949219, \"count\": 1, \"min\": 10.989189147949219, \"max\": 10.989189147949219}}}\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Epoch[1] Batch[0] avg_epoch_loss=3.453705\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.453705310821533\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Epoch[1] Batch[5] avg_epoch_loss=3.405561\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.4055606524149575\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Epoch[1] Batch [5]#011Speed: 1620.66 samples/sec#011loss=3.405561\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Epoch[1] Batch[10] avg_epoch_loss=3.469333\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.5458587646484374\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Epoch[1] Batch [10]#011Speed: 2099.79 samples/sec#011loss=3.545859\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747844254.2264605, \"EndTime\": 1747844255.2667363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1040.226936340332, \"count\": 1, \"min\": 1040.226936340332, \"max\": 1040.226936340332}}}\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1254.4353253482227 records/second\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.469332521611994\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_d957fa88-a937-4bd9-8c90-9985fbaab718-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844255.2667916, \"EndTime\": 1747844255.2766502, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.553909301757812, \"count\": 1, \"min\": 9.553909301757812, \"max\": 9.553909301757812}}}\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Epoch[2] Batch[0] avg_epoch_loss=3.228668\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.228667736053467\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Epoch[2] Batch[5] avg_epoch_loss=3.315588\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.3155884742736816\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Epoch[2] Batch [5]#011Speed: 1917.09 samples/sec#011loss=3.315588\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Epoch[2] Batch[10] avg_epoch_loss=3.259377\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.191923427581787\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Epoch[2] Batch [10]#011Speed: 2040.38 samples/sec#011loss=3.191923\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747844255.2766993, \"EndTime\": 1747844256.2376146, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.8674049377441, \"count\": 1, \"min\": 960.8674049377441, \"max\": 960.8674049377441}}}\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1396.4686512812764 records/second\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.2593770894137295\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_e749dd0a-a603-49c2-a8b9-0a92a258295a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844256.2377155, \"EndTime\": 1747844256.2486606, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.623931884765625, \"count\": 1, \"min\": 10.623931884765625, \"max\": 10.623931884765625}}}\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Epoch[3] Batch[0] avg_epoch_loss=3.345333\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.3453330993652344\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Epoch[3] Batch[5] avg_epoch_loss=3.349148\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.349148074785868\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Epoch[3] Batch [5]#011Speed: 2197.29 samples/sec#011loss=3.349148\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] Epoch[3] Batch[10] avg_epoch_loss=3.345339\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=3.3407680988311768\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] Epoch[3] Batch [10]#011Speed: 2115.52 samples/sec#011loss=3.340768\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844256.2487144, \"EndTime\": 1747844257.1680331, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.2698001861572, \"count\": 1, \"min\": 919.2698001861572, \"max\": 919.2698001861572}}}\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1420.5671790578826 records/second\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.345338994806463\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] Epoch[4] Batch[0] avg_epoch_loss=3.389310\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.389310359954834\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] Epoch[4] Batch[5] avg_epoch_loss=3.340915\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.3409146467844644\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] Epoch[4] Batch [5]#011Speed: 2204.75 samples/sec#011loss=3.340915\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] Epoch[4] Batch[10] avg_epoch_loss=3.358957\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.3806087493896486\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] Epoch[4] Batch [10]#011Speed: 2007.03 samples/sec#011loss=3.380609\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844257.168089, \"EndTime\": 1747844258.0983407, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.9900531768799, \"count\": 1, \"min\": 929.9900531768799, \"max\": 929.9900531768799}}}\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1432.1489177134067 records/second\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.3589574206959116\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] Epoch[5] Batch[0] avg_epoch_loss=3.347919\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.347919464111328\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] Epoch[5] Batch[5] avg_epoch_loss=3.294286\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.294285774230957\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] Epoch[5] Batch [5]#011Speed: 2120.79 samples/sec#011loss=3.294286\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] Epoch[5] Batch[10] avg_epoch_loss=3.375697\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.4733904361724854\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] Epoch[5] Batch [10]#011Speed: 2140.90 samples/sec#011loss=3.473390\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747844258.0983953, \"EndTime\": 1747844259.0163932, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.7467823028564, \"count\": 1, \"min\": 917.7467823028564, \"max\": 917.7467823028564}}}\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1410.919454867321 records/second\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.375696984204379\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] Epoch[6] Batch[0] avg_epoch_loss=3.199827\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.199826717376709\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] Epoch[6] Batch[5] avg_epoch_loss=3.307880\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.30787984530131\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] Epoch[6] Batch [5]#011Speed: 2172.12 samples/sec#011loss=3.307880\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] processed a total of 1260 examples\n",
      "#metrics {\"StartTime\": 1747844259.0164587, \"EndTime\": 1747844259.8690226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 852.2608280181885, \"count\": 1, \"min\": 852.2608280181885, \"max\": 852.2608280181885}}}\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1478.2655630072704 records/second\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.2958977699279783\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] Epoch[7] Batch[0] avg_epoch_loss=3.167600\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.16759991645813\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] Epoch[7] Batch[5] avg_epoch_loss=3.267885\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.2678849697113037\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] Epoch[7] Batch [5]#011Speed: 2170.09 samples/sec#011loss=3.267885\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] Epoch[7] Batch[10] avg_epoch_loss=3.329810\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.404119873046875\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] Epoch[7] Batch [10]#011Speed: 1947.30 samples/sec#011loss=3.404120\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747844259.86908, \"EndTime\": 1747844260.8129969, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.4936046600342, \"count\": 1, \"min\": 943.4936046600342, \"max\": 943.4936046600342}}}\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1444.5016660126596 records/second\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.3298099257729272\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] Epoch[8] Batch[0] avg_epoch_loss=3.164814\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.164813756942749\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] Epoch[8] Batch[5] avg_epoch_loss=3.314466\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.314465800921122\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] Epoch[8] Batch [5]#011Speed: 2220.42 samples/sec#011loss=3.314466\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] Epoch[8] Batch[10] avg_epoch_loss=3.272942\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.2231131076812742\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] Epoch[8] Batch [10]#011Speed: 2134.84 samples/sec#011loss=3.223113\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747844260.813053, \"EndTime\": 1747844261.71966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.360387802124, \"count\": 1, \"min\": 906.360387802124, \"max\": 906.360387802124}}}\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1487.1341108937631 records/second\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.2729418494484643\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[9] Batch[0] avg_epoch_loss=3.373947\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.3739466667175293\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[9] Batch[5] avg_epoch_loss=3.263353\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.2633527517318726\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[9] Batch [5]#011Speed: 2128.92 samples/sec#011loss=3.263353\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[9] Batch[10] avg_epoch_loss=3.230842\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.1918297290802\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[9] Batch [10]#011Speed: 2171.15 samples/sec#011loss=3.191830\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747844261.7197149, \"EndTime\": 1747844262.6345532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.588212966919, \"count\": 1, \"min\": 914.588212966919, \"max\": 914.588212966919}}}\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1439.8616956638357 records/second\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.230842286890203\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_ecfb3c07-894c-4587-88b2-31c6a6c8e4a5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844262.6346083, \"EndTime\": 1747844262.6457222, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.839223861694336, \"count\": 1, \"min\": 10.839223861694336, \"max\": 10.839223861694336}}}\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[10] Batch[0] avg_epoch_loss=3.329922\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.3299219608306885\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] Epoch[10] Batch[5] avg_epoch_loss=3.250695\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.250694910685221\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] Epoch[10] Batch [5]#011Speed: 2206.27 samples/sec#011loss=3.250695\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] Epoch[10] Batch[10] avg_epoch_loss=3.276585\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.3076525688171388\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] Epoch[10] Batch [10]#011Speed: 2103.78 samples/sec#011loss=3.307653\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844262.6457717, \"EndTime\": 1747844263.554626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.8096618652344, \"count\": 1, \"min\": 908.8096618652344, \"max\": 908.8096618652344}}}\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1465.520790919815 records/second\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.276584755290638\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] Epoch[11] Batch[0] avg_epoch_loss=3.217952\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.2179524898529053\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] Epoch[11] Batch[5] avg_epoch_loss=3.203618\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.2036184867223105\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] Epoch[11] Batch [5]#011Speed: 2188.44 samples/sec#011loss=3.203618\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] Epoch[11] Batch[10] avg_epoch_loss=3.252336\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=3.3107959747314455\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] Epoch[11] Batch [10]#011Speed: 2119.72 samples/sec#011loss=3.310796\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747844263.5546827, \"EndTime\": 1747844264.4799447, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0068664550781, \"count\": 1, \"min\": 925.0068664550781, \"max\": 925.0068664550781}}}\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1403.10805815822 records/second\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.2523355267264624\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] Epoch[12] Batch[0] avg_epoch_loss=3.270044\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.2700438499450684\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Epoch[12] Batch[5] avg_epoch_loss=3.190872\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.1908716758092246\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Epoch[12] Batch [5]#011Speed: 2144.94 samples/sec#011loss=3.190872\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Epoch[12] Batch[10] avg_epoch_loss=3.196439\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=3.203120708465576\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Epoch[12] Batch [10]#011Speed: 2101.90 samples/sec#011loss=3.203121\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747844264.4799998, \"EndTime\": 1747844265.409565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.316520690918, \"count\": 1, \"min\": 929.316520690918, \"max\": 929.316520690918}}}\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1474.0704784767672 records/second\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.196439417925748\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_5c4bace2-86df-4f13-8242-162d7386c8b4-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844265.4096203, \"EndTime\": 1747844265.4200537, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.080575942993164, \"count\": 1, \"min\": 10.080575942993164, \"max\": 10.080575942993164}}}\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Epoch[13] Batch[0] avg_epoch_loss=3.073098\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.0730981826782227\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[13] Batch[5] avg_epoch_loss=3.160310\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.160310427347819\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[13] Batch [5]#011Speed: 2144.62 samples/sec#011loss=3.160310\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[13] Batch[10] avg_epoch_loss=3.163378\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.16705904006958\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[13] Batch [10]#011Speed: 2057.72 samples/sec#011loss=3.167059\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747844265.4201076, \"EndTime\": 1747844266.351987, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.833028793335, \"count\": 1, \"min\": 931.833028793335, \"max\": 931.833028793335}}}\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.4543630666865 records/second\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.163377978584983\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_8605e18c-d459-408d-bf82-76d286e50f60-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844266.352045, \"EndTime\": 1747844266.362412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.054349899291992, \"count\": 1, \"min\": 10.054349899291992, \"max\": 10.054349899291992}}}\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[14] Batch[0] avg_epoch_loss=3.139221\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.139221429824829\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[14] Batch[5] avg_epoch_loss=3.162249\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.1622488101323447\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[14] Batch [5]#011Speed: 2160.95 samples/sec#011loss=3.162249\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Epoch[14] Batch[10] avg_epoch_loss=3.142185\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=3.1181085109710693\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Epoch[14] Batch [10]#011Speed: 2036.34 samples/sec#011loss=3.118109\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747844266.3624659, \"EndTime\": 1747844267.2898984, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.3824691772461, \"count\": 1, \"min\": 927.3824691772461, \"max\": 927.3824691772461}}}\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1464.2088912184713 records/second\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.1421850377863105\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_abc21b79-a4e7-4ea9-91d6-18b999f8b01a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844267.289952, \"EndTime\": 1747844267.3002884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.00070571899414, \"count\": 1, \"min\": 10.00070571899414, \"max\": 10.00070571899414}}}\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Epoch[15] Batch[0] avg_epoch_loss=3.169248\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.169248104095459\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Epoch[15] Batch[5] avg_epoch_loss=3.116711\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=3.116711378097534\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Epoch[15] Batch [5]#011Speed: 2217.56 samples/sec#011loss=3.116711\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] processed a total of 1259 examples\n",
      "#metrics {\"StartTime\": 1747844267.300335, \"EndTime\": 1747844268.1467736, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 846.3881015777588, \"count\": 1, \"min\": 846.3881015777588, \"max\": 846.3881015777588}}}\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1487.3389115045768 records/second\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=15, train loss <loss>=3.1053293466567995\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_d5ceac36-4ee2-406d-ad81-49bb35e6e8d6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844268.1468332, \"EndTime\": 1747844268.1579049, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.759353637695312, \"count\": 1, \"min\": 10.759353637695312, \"max\": 10.759353637695312}}}\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] Epoch[16] Batch[0] avg_epoch_loss=3.217985\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.217984676361084\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] Epoch[16] Batch[5] avg_epoch_loss=3.117103\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=3.11710254351298\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] Epoch[16] Batch [5]#011Speed: 2237.47 samples/sec#011loss=3.117103\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[16] Batch[10] avg_epoch_loss=3.153348\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=3.196842002868652\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[16] Batch [10]#011Speed: 2210.40 samples/sec#011loss=3.196842\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844268.157954, \"EndTime\": 1747844269.0491135, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 891.1130428314209, \"count\": 1, \"min\": 891.1130428314209, \"max\": 891.1130428314209}}}\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1468.821713871122 records/second\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.153347752311013\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[17] Batch[0] avg_epoch_loss=3.112368\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.112367630004883\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[17] Batch[5] avg_epoch_loss=3.113505\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.1135048866271973\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[17] Batch [5]#011Speed: 2242.53 samples/sec#011loss=3.113505\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[17] Batch[10] avg_epoch_loss=3.097730\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.0788010120391847\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[17] Batch [10]#011Speed: 2062.55 samples/sec#011loss=3.078801\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747844269.0491657, \"EndTime\": 1747844269.9520032, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 902.5955200195312, \"count\": 1, \"min\": 902.5955200195312, \"max\": 902.5955200195312}}}\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1499.9858999802964 records/second\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.0977303981781006\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_ea097a88-b8e7-4e04-9866-7cd88b4b926e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844269.9520574, \"EndTime\": 1747844269.9624069, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.07390022277832, \"count\": 1, \"min\": 10.07390022277832, \"max\": 10.07390022277832}}}\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Epoch[18] Batch[0] avg_epoch_loss=3.184320\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.1843199729919434\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Epoch[18] Batch[5] avg_epoch_loss=3.148649\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.1486487785975137\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Epoch[18] Batch [5]#011Speed: 2036.66 samples/sec#011loss=3.148649\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Epoch[18] Batch[10] avg_epoch_loss=3.090709\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.0211817264556884\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Epoch[18] Batch [10]#011Speed: 2124.10 samples/sec#011loss=3.021182\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844269.9624584, \"EndTime\": 1747844270.8969254, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.4191551208496, \"count\": 1, \"min\": 934.4191551208496, \"max\": 934.4191551208496}}}\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.8698273462533 records/second\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.0907092094421387\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_8452d9a9-66d4-4e61-97e4-df1b23365845-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844270.8969786, \"EndTime\": 1747844270.9069178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.594202041625977, \"count\": 1, \"min\": 9.594202041625977, \"max\": 9.594202041625977}}}\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Epoch[19] Batch[0] avg_epoch_loss=3.114054\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.1140542030334473\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Epoch[19] Batch[5] avg_epoch_loss=3.061827\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=3.061826785405477\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Epoch[19] Batch [5]#011Speed: 2014.87 samples/sec#011loss=3.061827\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Epoch[19] Batch[10] avg_epoch_loss=2.947856\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=2.811090612411499\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Epoch[19] Batch [10]#011Speed: 2205.20 samples/sec#011loss=2.811091\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747844270.906967, \"EndTime\": 1747844271.8365998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.5847415924072, \"count\": 1, \"min\": 929.5847415924072, \"max\": 929.5847415924072}}}\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1384.3656011872872 records/second\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.9478557976809414\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_35c9deb2-fcfd-42bd-89e7-d2f3f0591133-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844271.8366563, \"EndTime\": 1747844271.8474627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.543346405029297, \"count\": 1, \"min\": 10.543346405029297, \"max\": 10.543346405029297}}}\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] Epoch[20] Batch[0] avg_epoch_loss=3.163296\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.1632955074310303\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] Epoch[20] Batch[5] avg_epoch_loss=3.118913\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=3.118913014729818\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] Epoch[20] Batch [5]#011Speed: 2166.64 samples/sec#011loss=3.118913\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747844271.847512, \"EndTime\": 1747844272.700904, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 853.3427715301514, \"count\": 1, \"min\": 853.3427715301514, \"max\": 853.3427715301514}}}\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1484.600708974373 records/second\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.100708508491516\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[21] Batch[0] avg_epoch_loss=2.935093\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=2.9350931644439697\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[21] Batch[5] avg_epoch_loss=3.021580\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.0215804179509482\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[21] Batch [5]#011Speed: 2193.26 samples/sec#011loss=3.021580\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[21] Batch[10] avg_epoch_loss=2.987009\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=2.945522499084473\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[21] Batch [10]#011Speed: 1986.14 samples/sec#011loss=2.945522\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747844272.7009604, \"EndTime\": 1747844273.6295998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.3497333526611, \"count\": 1, \"min\": 928.3497333526611, \"max\": 928.3497333526611}}}\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1471.297863500051 records/second\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=21, train loss <loss>=2.987008636648005\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[22] Batch[0] avg_epoch_loss=2.996017\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.99601674079895\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] Epoch[22] Batch[5] avg_epoch_loss=2.980684\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.980684280395508\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] Epoch[22] Batch [5]#011Speed: 2179.83 samples/sec#011loss=2.980684\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] Epoch[22] Batch[10] avg_epoch_loss=2.983089\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=2.985973596572876\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] Epoch[22] Batch [10]#011Speed: 2107.98 samples/sec#011loss=2.985974\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844273.6296537, \"EndTime\": 1747844274.5464482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.5475368499756, \"count\": 1, \"min\": 916.5475368499756, \"max\": 916.5475368499756}}}\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.7857003330107 records/second\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.9830885150215845\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] Epoch[23] Batch[0] avg_epoch_loss=2.899899\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.8998990058898926\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] Epoch[23] Batch[5] avg_epoch_loss=2.992970\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.992969512939453\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] Epoch[23] Batch [5]#011Speed: 2118.09 samples/sec#011loss=2.992970\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] Epoch[23] Batch[10] avg_epoch_loss=3.105073\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=3.2395971775054933\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] Epoch[23] Batch [10]#011Speed: 2162.33 samples/sec#011loss=3.239597\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844274.546503, \"EndTime\": 1747844275.4611733, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.4232273101807, \"count\": 1, \"min\": 914.4232273101807, \"max\": 914.4232273101807}}}\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1448.8066502549739 records/second\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=23, train loss <loss>=3.105072996833108\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] Epoch[24] Batch[0] avg_epoch_loss=2.964596\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.9645955562591553\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Epoch[24] Batch[5] avg_epoch_loss=2.960554\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.9605544010798135\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Epoch[24] Batch [5]#011Speed: 2036.40 samples/sec#011loss=2.960554\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Epoch[24] Batch[10] avg_epoch_loss=2.880204\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.7837835788726806\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Epoch[24] Batch [10]#011Speed: 2159.45 samples/sec#011loss=2.783784\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844275.461268, \"EndTime\": 1747844276.3956757, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.0171813964844, \"count\": 1, \"min\": 934.0171813964844, \"max\": 934.0171813964844}}}\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1388.5010139352607 records/second\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.880204027349299\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_dee121b8-9412-4977-9fb5-6e2e8d35b655-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844276.3957314, \"EndTime\": 1747844276.4063368, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.312080383300781, \"count\": 1, \"min\": 10.312080383300781, \"max\": 10.312080383300781}}}\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Epoch[25] Batch[0] avg_epoch_loss=3.030883\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=3.030883312225342\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[25] Batch[5] avg_epoch_loss=3.008580\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=3.008580048878988\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[25] Batch [5]#011Speed: 2171.95 samples/sec#011loss=3.008580\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[25] Batch[10] avg_epoch_loss=2.971188\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=2.9263179302215576\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[25] Batch [10]#011Speed: 2112.26 samples/sec#011loss=2.926318\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844276.4063852, \"EndTime\": 1747844277.3182383, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.8070602416992, \"count\": 1, \"min\": 911.8070602416992, \"max\": 911.8070602416992}}}\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1470.5201560624532 records/second\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.971188176761974\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[26] Batch[0] avg_epoch_loss=3.111129\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=3.111128807067871\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[26] Batch[5] avg_epoch_loss=2.981121\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.981120983759562\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[26] Batch [5]#011Speed: 2199.01 samples/sec#011loss=2.981121\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] Epoch[26] Batch[10] avg_epoch_loss=3.003871\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=3.0311717987060547\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] Epoch[26] Batch [10]#011Speed: 1942.88 samples/sec#011loss=3.031172\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] processed a total of 1362 examples\n",
      "#metrics {\"StartTime\": 1747844277.318327, \"EndTime\": 1747844278.255448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.859130859375, \"count\": 1, \"min\": 936.859130859375, \"max\": 936.859130859375}}}\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1453.6036637280642 records/second\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=26, train loss <loss>=3.003871354189786\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] Epoch[27] Batch[0] avg_epoch_loss=2.948818\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.9488184452056885\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] Epoch[27] Batch[5] avg_epoch_loss=2.965740\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.9657403230667114\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] Epoch[27] Batch [5]#011Speed: 2086.11 samples/sec#011loss=2.965740\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] Epoch[27] Batch[10] avg_epoch_loss=2.962515\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.958644247055054\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] Epoch[27] Batch [10]#011Speed: 2006.96 samples/sec#011loss=2.958644\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] processed a total of 1414 examples\n",
      "#metrics {\"StartTime\": 1747844278.2555425, \"EndTime\": 1747844279.2467356, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 990.9274578094482, \"count\": 1, \"min\": 990.9274578094482, \"max\": 990.9274578094482}}}\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1426.8176359426218 records/second\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=27, train loss <loss>=3.021000564098358\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] Epoch[28] Batch[0] avg_epoch_loss=2.988422\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.988421678543091\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] Epoch[28] Batch[5] avg_epoch_loss=2.986384\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.98638379573822\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] Epoch[28] Batch [5]#011Speed: 2186.66 samples/sec#011loss=2.986384\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] Epoch[28] Batch[10] avg_epoch_loss=3.041811\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=3.108324432373047\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] Epoch[28] Batch [10]#011Speed: 2004.06 samples/sec#011loss=3.108324\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844279.246796, \"EndTime\": 1747844280.1759396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.8535118103027, \"count\": 1, \"min\": 928.8535118103027, \"max\": 928.8535118103027}}}\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.9066062014258 records/second\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=28, train loss <loss>=3.0418113578449595\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] Epoch[29] Batch[0] avg_epoch_loss=2.941563\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.941563129425049\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] Epoch[29] Batch[5] avg_epoch_loss=2.964945\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.9649451971054077\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] Epoch[29] Batch [5]#011Speed: 2060.59 samples/sec#011loss=2.964945\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] Epoch[29] Batch[10] avg_epoch_loss=3.016815\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=3.0790579319000244\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] Epoch[29] Batch [10]#011Speed: 2033.88 samples/sec#011loss=3.079058\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844280.1759942, \"EndTime\": 1747844281.1197906, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.5365200042725, \"count\": 1, \"min\": 943.5365200042725, \"max\": 943.5365200042725}}}\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.5809422359312 records/second\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=29, train loss <loss>=3.0168146220120517\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] Epoch[30] Batch[0] avg_epoch_loss=2.934904\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.934903860092163\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] Epoch[30] Batch[5] avg_epoch_loss=2.976976\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.97697647412618\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] Epoch[30] Batch [5]#011Speed: 2182.44 samples/sec#011loss=2.976976\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] Epoch[30] Batch[10] avg_epoch_loss=3.016997\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=3.0650208950042725\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] Epoch[30] Batch [10]#011Speed: 1740.07 samples/sec#011loss=3.065021\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844281.1198483, \"EndTime\": 1747844282.1040366, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 983.9351177215576, \"count\": 1, \"min\": 983.9351177215576, \"max\": 983.9351177215576}}}\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1346.5189856549384 records/second\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=30, train loss <loss>=3.016996665434404\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] Epoch[31] Batch[0] avg_epoch_loss=2.910988\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.910987615585327\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] Epoch[31] Batch[5] avg_epoch_loss=2.948782\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.9487820068995156\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] Epoch[31] Batch [5]#011Speed: 2024.63 samples/sec#011loss=2.948782\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Epoch[31] Batch[10] avg_epoch_loss=2.858777\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=2.7507699489593507\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Epoch[31] Batch [10]#011Speed: 2024.51 samples/sec#011loss=2.750770\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747844282.104092, \"EndTime\": 1747844283.0586572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.277515411377, \"count\": 1, \"min\": 954.277515411377, \"max\": 954.277515411377}}}\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.4188261375398 records/second\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.8587765260176226\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_85b62897-3f8d-4e7b-b1e3-380f4bb1a5d2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844283.058712, \"EndTime\": 1747844283.0696557, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.644197463989258, \"count\": 1, \"min\": 10.644197463989258, \"max\": 10.644197463989258}}}\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Epoch[32] Batch[0] avg_epoch_loss=2.839033\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.8390326499938965\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Epoch[32] Batch[5] avg_epoch_loss=2.938138\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.9381381273269653\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Epoch[32] Batch [5]#011Speed: 2121.92 samples/sec#011loss=2.938138\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747844283.0697029, \"EndTime\": 1747844283.9271212, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 857.367992401123, \"count\": 1, \"min\": 857.367992401123, \"max\": 857.367992401123}}}\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1491.5964823500233 records/second\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.91433470249176\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] Epoch[33] Batch[0] avg_epoch_loss=3.030623\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=3.030623197555542\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] Epoch[33] Batch[5] avg_epoch_loss=2.898388\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.8983875513076782\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] Epoch[33] Batch [5]#011Speed: 2192.53 samples/sec#011loss=2.898388\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] processed a total of 1238 examples\n",
      "#metrics {\"StartTime\": 1747844283.9271946, \"EndTime\": 1747844284.7919815, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.4335269927979, \"count\": 1, \"min\": 864.4335269927979, \"max\": 864.4335269927979}}}\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.9491568331673 records/second\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.867684030532837\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] Epoch[34] Batch[0] avg_epoch_loss=2.841973\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.841973066329956\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] Epoch[34] Batch[5] avg_epoch_loss=2.856923\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.8569226264953613\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] Epoch[34] Batch [5]#011Speed: 2144.03 samples/sec#011loss=2.856923\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] Epoch[34] Batch[10] avg_epoch_loss=2.895933\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=2.942746114730835\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] Epoch[34] Batch [10]#011Speed: 1978.23 samples/sec#011loss=2.942746\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747844284.79206, \"EndTime\": 1747844285.7327156, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.3445720672607, \"count\": 1, \"min\": 940.3445720672607, \"max\": 940.3445720672607}}}\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1445.089973917664 records/second\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.8959333029660312\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[35] Batch[0] avg_epoch_loss=2.833843\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.8338427543640137\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[35] Batch[5] avg_epoch_loss=2.860663\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.860662857691447\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[35] Batch [5]#011Speed: 2165.84 samples/sec#011loss=2.860663\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[35] Batch[10] avg_epoch_loss=2.873239\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=2.8883305549621583\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[35] Batch [10]#011Speed: 1926.19 samples/sec#011loss=2.888331\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] processed a total of 1394 examples\n",
      "#metrics {\"StartTime\": 1747844285.7327695, \"EndTime\": 1747844286.6718035, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.788890838623, \"count\": 1, \"min\": 938.788890838623, \"max\": 938.788890838623}}}\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1484.763672875889 records/second\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.8732390837235884\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[36] Batch[0] avg_epoch_loss=2.771353\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.771352767944336\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Epoch[36] Batch[5] avg_epoch_loss=2.798503\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.7985031604766846\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Epoch[36] Batch [5]#011Speed: 2181.99 samples/sec#011loss=2.798503\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Epoch[36] Batch[10] avg_epoch_loss=2.839319\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.888297986984253\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Epoch[36] Batch [10]#011Speed: 2064.69 samples/sec#011loss=2.888298\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844286.671858, \"EndTime\": 1747844287.59631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.2115020751953, \"count\": 1, \"min\": 924.2115020751953, \"max\": 924.2115020751953}}}\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1441.1017763521907 records/second\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.8393189907073975\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_f27338cd-e0b5-4936-9bd7-958f1f0c97a7-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844287.5963647, \"EndTime\": 1747844287.607496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.868549346923828, \"count\": 1, \"min\": 10.868549346923828, \"max\": 10.868549346923828}}}\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Epoch[37] Batch[0] avg_epoch_loss=2.820853\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.8208532333374023\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] Epoch[37] Batch[5] avg_epoch_loss=2.853956\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.8539563020070395\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] Epoch[37] Batch [5]#011Speed: 2125.59 samples/sec#011loss=2.853956\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747844287.607544, \"EndTime\": 1747844288.4722607, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.6693229675293, \"count\": 1, \"min\": 864.6693229675293, \"max\": 864.6693229675293}}}\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.0881199032383 records/second\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.864393162727356\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] Epoch[38] Batch[0] avg_epoch_loss=2.743274\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.743273973464966\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Epoch[38] Batch[5] avg_epoch_loss=2.801143\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.801142772038778\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Epoch[38] Batch [5]#011Speed: 2161.15 samples/sec#011loss=2.801143\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Epoch[38] Batch[10] avg_epoch_loss=2.832631\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=2.870417070388794\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Epoch[38] Batch [10]#011Speed: 1936.94 samples/sec#011loss=2.870417\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747844288.47232, \"EndTime\": 1747844289.415446, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.7917003631592, \"count\": 1, \"min\": 942.7917003631592, \"max\": 942.7917003631592}}}\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.6729235319226 records/second\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.832631089470603\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_312f3c90-ab97-4e50-9685-1a38bc752735-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844289.4155016, \"EndTime\": 1747844289.4263535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.589361190795898, \"count\": 1, \"min\": 10.589361190795898, \"max\": 10.589361190795898}}}\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Epoch[39] Batch[0] avg_epoch_loss=2.722493\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.7224926948547363\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[39] Batch[5] avg_epoch_loss=2.769656\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.7696563005447388\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[39] Batch [5]#011Speed: 2114.36 samples/sec#011loss=2.769656\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[39] Batch[10] avg_epoch_loss=2.848568\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=2.9432626247406004\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[39] Batch [10]#011Speed: 1969.16 samples/sec#011loss=2.943263\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747844289.4264016, \"EndTime\": 1747844290.3708978, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.4520473480225, \"count\": 1, \"min\": 944.4520473480225, \"max\": 944.4520473480225}}}\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1401.752524576856 records/second\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.8485682660883125\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[40] Batch[0] avg_epoch_loss=2.939894\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.939893960952759\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[40] Batch[5] avg_epoch_loss=2.848230\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.848229924837748\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[40] Batch [5]#011Speed: 2142.29 samples/sec#011loss=2.848230\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] Epoch[40] Batch[10] avg_epoch_loss=2.862678\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=2.8800151348114014\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] Epoch[40] Batch [10]#011Speed: 2106.50 samples/sec#011loss=2.880015\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844290.3709524, \"EndTime\": 1747844291.2942414, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.0482578277588, \"count\": 1, \"min\": 923.0482578277588, \"max\": 923.0482578277588}}}\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.7482329070822 records/second\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.862677747553045\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] Epoch[41] Batch[0] avg_epoch_loss=2.792788\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.792787551879883\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] Epoch[41] Batch[5] avg_epoch_loss=2.884656\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.884656389554342\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] Epoch[41] Batch [5]#011Speed: 1993.05 samples/sec#011loss=2.884656\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747844291.2942986, \"EndTime\": 1747844292.1884685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 893.9125537872314, \"count\": 1, \"min\": 893.9125537872314, \"max\": 893.9125537872314}}}\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.292598972347 records/second\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.877144384384155\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] Epoch[42] Batch[0] avg_epoch_loss=2.643600\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.6435999870300293\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] Epoch[42] Batch[5] avg_epoch_loss=2.825771\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.825770934422811\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] Epoch[42] Batch [5]#011Speed: 2214.89 samples/sec#011loss=2.825771\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Epoch[42] Batch[10] avg_epoch_loss=2.801968\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.7734045028686523\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Epoch[42] Batch [10]#011Speed: 2088.14 samples/sec#011loss=2.773405\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747844292.1885285, \"EndTime\": 1747844293.0989609, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.1457595825195, \"count\": 1, \"min\": 910.1457595825195, \"max\": 910.1457595825195}}}\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.3829561414584 records/second\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.8019680109891025\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_220d0423-291b-4ab7-8a25-e1128972764a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844293.099017, \"EndTime\": 1747844293.1100094, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.73002815246582, \"count\": 1, \"min\": 10.73002815246582, \"max\": 10.73002815246582}}}\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Epoch[43] Batch[0] avg_epoch_loss=2.818613\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.818612813949585\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Epoch[43] Batch[5] avg_epoch_loss=2.813760\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.813759724299113\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Epoch[43] Batch [5]#011Speed: 2176.38 samples/sec#011loss=2.813760\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[43] Batch[10] avg_epoch_loss=2.745500\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.663588523864746\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[43] Batch [10]#011Speed: 2162.13 samples/sec#011loss=2.663589\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747844293.1100607, \"EndTime\": 1747844294.0208051, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.698652267456, \"count\": 1, \"min\": 910.698652267456, \"max\": 910.698652267456}}}\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.0311518430824 records/second\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.745500087738037\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_80482ca4-146c-441a-bd71-be04ce65fa0d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844294.0208619, \"EndTime\": 1747844294.0318751, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.746479034423828, \"count\": 1, \"min\": 10.746479034423828, \"max\": 10.746479034423828}}}\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[44] Batch[0] avg_epoch_loss=2.871888\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.8718881607055664\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[44] Batch[5] avg_epoch_loss=2.798786\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.7987858057022095\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[44] Batch [5]#011Speed: 2163.97 samples/sec#011loss=2.798786\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[44] Batch[10] avg_epoch_loss=2.790603\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=2.780783987045288\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[44] Batch [10]#011Speed: 1997.45 samples/sec#011loss=2.780784\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747844294.0319307, \"EndTime\": 1747844294.9648702, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.8882694244385, \"count\": 1, \"min\": 932.8882694244385, \"max\": 932.8882694244385}}}\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1477.0087576594383 records/second\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.7906031608581543\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] Epoch[45] Batch[0] avg_epoch_loss=2.881600\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.8815999031066895\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] Epoch[45] Batch[5] avg_epoch_loss=2.765190\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.7651896874109902\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] Epoch[45] Batch [5]#011Speed: 2157.05 samples/sec#011loss=2.765190\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] Epoch[45] Batch[10] avg_epoch_loss=2.778004\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=2.793380546569824\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] Epoch[45] Batch [10]#011Speed: 2052.61 samples/sec#011loss=2.793381\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] processed a total of 1362 examples\n",
      "#metrics {\"StartTime\": 1747844294.964921, \"EndTime\": 1747844295.8931549, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.9413223266602, \"count\": 1, \"min\": 927.9413223266602, \"max\": 927.9413223266602}}}\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1467.6366353073379 records/second\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.7780037143013696\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] Epoch[46] Batch[0] avg_epoch_loss=2.587780\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.5877797603607178\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] Epoch[46] Batch[5] avg_epoch_loss=2.798245\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.798245429992676\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] Epoch[46] Batch [5]#011Speed: 2155.61 samples/sec#011loss=2.798245\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] Epoch[46] Batch[10] avg_epoch_loss=2.762800\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.720265817642212\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] Epoch[46] Batch [10]#011Speed: 2143.42 samples/sec#011loss=2.720266\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747844295.8932104, \"EndTime\": 1747844296.8124318, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.9565181732178, \"count\": 1, \"min\": 918.9565181732178, \"max\": 918.9565181732178}}}\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1393.846528849873 records/second\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.7628001516515557\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] Epoch[47] Batch[0] avg_epoch_loss=2.715326\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.7153263092041016\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] Epoch[47] Batch[5] avg_epoch_loss=2.726246\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.726246198018392\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] Epoch[47] Batch [5]#011Speed: 2174.15 samples/sec#011loss=2.726246\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] Epoch[47] Batch[10] avg_epoch_loss=2.786092\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=2.857906150817871\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] Epoch[47] Batch [10]#011Speed: 1988.93 samples/sec#011loss=2.857906\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844296.8124866, \"EndTime\": 1747844297.7466738, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.8908195495605, \"count\": 1, \"min\": 933.8908195495605, \"max\": 933.8908195495605}}}\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.1727041705224 records/second\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.7860916311090644\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[48] Batch[0] avg_epoch_loss=2.542259\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.5422587394714355\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[48] Batch[5] avg_epoch_loss=2.726263\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.7262625296910605\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[48] Batch [5]#011Speed: 2247.62 samples/sec#011loss=2.726263\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[48] Batch[10] avg_epoch_loss=2.804776\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=2.89899263381958\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[48] Batch [10]#011Speed: 2110.20 samples/sec#011loss=2.898993\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747844297.7467308, \"EndTime\": 1747844298.655018, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.0173969268799, \"count\": 1, \"min\": 908.0173969268799, \"max\": 908.0173969268799}}}\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1461.2761058271292 records/second\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.8047762133858423\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[49] Batch[0] avg_epoch_loss=3.000951\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=3.000950813293457\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] Epoch[49] Batch[5] avg_epoch_loss=2.981481\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.9814807176589966\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] Epoch[49] Batch [5]#011Speed: 2222.96 samples/sec#011loss=2.981481\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] Epoch[49] Batch[10] avg_epoch_loss=3.067530\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=3.1707894802093506\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] Epoch[49] Batch [10]#011Speed: 2202.17 samples/sec#011loss=3.170789\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747844298.6550713, \"EndTime\": 1747844299.552472, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.1579074859619, \"count\": 1, \"min\": 897.1579074859619, \"max\": 897.1579074859619}}}\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1446.6518460453085 records/second\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=49, train loss <loss>=3.0675301551818848\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] Epoch[50] Batch[0] avg_epoch_loss=2.960189\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.9601891040802\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] Epoch[50] Batch[5] avg_epoch_loss=2.935006\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.935006260871887\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] Epoch[50] Batch [5]#011Speed: 2183.80 samples/sec#011loss=2.935006\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] Epoch[50] Batch[10] avg_epoch_loss=2.964458\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.9998002529144285\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] Epoch[50] Batch [10]#011Speed: 2055.74 samples/sec#011loss=2.999800\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844299.5525298, \"EndTime\": 1747844300.473726, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.9356307983398, \"count\": 1, \"min\": 920.9356307983398, \"max\": 920.9356307983398}}}\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1464.686480170188 records/second\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.9644580754366787\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] Epoch[51] Batch[0] avg_epoch_loss=2.762835\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.7628345489501953\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] Epoch[51] Batch[5] avg_epoch_loss=2.862908\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.8629081646601358\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] Epoch[51] Batch [5]#011Speed: 2142.93 samples/sec#011loss=2.862908\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] Epoch[51] Batch[10] avg_epoch_loss=2.883451\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.9081027030944826\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] Epoch[51] Batch [10]#011Speed: 2009.75 samples/sec#011loss=2.908103\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747844300.4737813, \"EndTime\": 1747844301.4066741, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.647705078125, \"count\": 1, \"min\": 932.647705078125, \"max\": 932.647705078125}}}\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1398.0441536133492 records/second\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.883451136675748\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] Epoch[52] Batch[0] avg_epoch_loss=2.789102\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.7891016006469727\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[52] Batch[5] avg_epoch_loss=2.781222\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.781221866607666\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[52] Batch [5]#011Speed: 2148.34 samples/sec#011loss=2.781222\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[52] Batch[10] avg_epoch_loss=2.831510\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=2.891856813430786\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[52] Batch [10]#011Speed: 1992.98 samples/sec#011loss=2.891857\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747844301.406731, \"EndTime\": 1747844302.3457391, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.762903213501, \"count\": 1, \"min\": 938.762903213501, \"max\": 938.762903213501}}}\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.2825149004143 records/second\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.831510478799993\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[53] Batch[0] avg_epoch_loss=2.740258\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.74025821685791\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[53] Batch[5] avg_epoch_loss=2.762394\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.762393832206726\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[53] Batch [5]#011Speed: 2141.44 samples/sec#011loss=2.762394\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Epoch[53] Batch[10] avg_epoch_loss=2.713519\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.654868459701538\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Epoch[53] Batch [10]#011Speed: 2089.86 samples/sec#011loss=2.654868\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844302.3457956, \"EndTime\": 1747844303.2718155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.7667064666748, \"count\": 1, \"min\": 925.7667064666748, \"max\": 925.7667064666748}}}\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1421.3992479055769 records/second\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.713518662886186\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_7e6014f5-eed0-4edb-b89a-f9502d0a1421-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844303.2718701, \"EndTime\": 1747844303.2828476, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.702133178710938, \"count\": 1, \"min\": 10.702133178710938, \"max\": 10.702133178710938}}}\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Epoch[54] Batch[0] avg_epoch_loss=2.703054\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.703054428100586\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Epoch[54] Batch[5] avg_epoch_loss=2.749809\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.7498091061909995\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Epoch[54] Batch [5]#011Speed: 2146.14 samples/sec#011loss=2.749809\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] Epoch[54] Batch[10] avg_epoch_loss=2.778501\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=2.812930965423584\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] Epoch[54] Batch [10]#011Speed: 1963.42 samples/sec#011loss=2.812931\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844303.2828963, \"EndTime\": 1747844304.2224438, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.5003318786621, \"count\": 1, \"min\": 939.5003318786621, \"max\": 939.5003318786621}}}\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.740656458518 records/second\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.778500860387629\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] Epoch[55] Batch[0] avg_epoch_loss=2.656221\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.6562211513519287\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] Epoch[55] Batch[5] avg_epoch_loss=2.739138\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.7391379674275718\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] Epoch[55] Batch [5]#011Speed: 2126.49 samples/sec#011loss=2.739138\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Epoch[55] Batch[10] avg_epoch_loss=2.673060\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.5937660694122315\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Epoch[55] Batch [10]#011Speed: 1988.34 samples/sec#011loss=2.593766\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747844304.222502, \"EndTime\": 1747844305.1608891, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.1406307220459, \"count\": 1, \"min\": 938.1406307220459, \"max\": 938.1406307220459}}}\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.7446407384434 records/second\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.6730598319660532\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_d616934f-9625-4e6c-b0c4-641f920266f0-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844305.1609454, \"EndTime\": 1747844305.1715205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.169506072998047, \"count\": 1, \"min\": 10.169506072998047, \"max\": 10.169506072998047}}}\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Epoch[56] Batch[0] avg_epoch_loss=2.649429\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.6494293212890625\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Epoch[56] Batch[5] avg_epoch_loss=2.693852\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.6938523054122925\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Epoch[56] Batch [5]#011Speed: 2146.51 samples/sec#011loss=2.693852\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747844305.171568, \"EndTime\": 1747844306.0295868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 857.9707145690918, \"count\": 1, \"min\": 857.9707145690918, \"max\": 857.9707145690918}}}\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1484.7469215403676 records/second\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.719949984550476\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] Epoch[57] Batch[0] avg_epoch_loss=2.632661\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.6326608657836914\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] Epoch[57] Batch[5] avg_epoch_loss=2.665387\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.6653868754704795\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] Epoch[57] Batch [5]#011Speed: 2157.19 samples/sec#011loss=2.665387\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] Epoch[57] Batch[10] avg_epoch_loss=2.677641\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=2.69234676361084\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] Epoch[57] Batch [10]#011Speed: 1918.60 samples/sec#011loss=2.692347\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747844306.0296462, \"EndTime\": 1747844306.9783173, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.3165740966797, \"count\": 1, \"min\": 948.3165740966797, \"max\": 948.3165740966797}}}\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.8290434887099 records/second\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.677641370079734\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] Epoch[58] Batch[0] avg_epoch_loss=2.789186\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.7891860008239746\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] Epoch[58] Batch[5] avg_epoch_loss=2.714509\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.714509129524231\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] Epoch[58] Batch [5]#011Speed: 2256.23 samples/sec#011loss=2.714509\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] Epoch[58] Batch[10] avg_epoch_loss=2.740179\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.770983362197876\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] Epoch[58] Batch [10]#011Speed: 2080.31 samples/sec#011loss=2.770983\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747844306.978374, \"EndTime\": 1747844307.8877199, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.0604782104492, \"count\": 1, \"min\": 909.0604782104492, \"max\": 909.0604782104492}}}\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.4166669944732 records/second\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.7401792352849785\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] Epoch[59] Batch[0] avg_epoch_loss=2.738549\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.738548517227173\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] Epoch[59] Batch[5] avg_epoch_loss=2.681741\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.681740959485372\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] Epoch[59] Batch [5]#011Speed: 2225.02 samples/sec#011loss=2.681741\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] Epoch[59] Batch[10] avg_epoch_loss=2.718385\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=2.762358570098877\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] Epoch[59] Batch [10]#011Speed: 2241.26 samples/sec#011loss=2.762359\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747844307.8877769, \"EndTime\": 1747844308.783738, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 895.6897258758545, \"count\": 1, \"min\": 895.6897258758545, \"max\": 895.6897258758545}}}\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1438.985336687665 records/second\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.718385327946056\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Epoch[60] Batch[0] avg_epoch_loss=2.636716\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.636716365814209\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Epoch[60] Batch[5] avg_epoch_loss=2.640205\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.640204668045044\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Epoch[60] Batch [5]#011Speed: 2179.99 samples/sec#011loss=2.640205\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Epoch[60] Batch[10] avg_epoch_loss=2.665488\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.695828151702881\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Epoch[60] Batch [10]#011Speed: 2079.68 samples/sec#011loss=2.695828\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747844308.783792, \"EndTime\": 1747844309.7036903, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.6581840515137, \"count\": 1, \"min\": 919.6581840515137, \"max\": 919.6581840515137}}}\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1446.057529944179 records/second\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.6654880697076972\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_d780b17a-c384-49bc-b803-2fd8af05b712-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844309.7037504, \"EndTime\": 1747844309.713369, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.301424026489258, \"count\": 1, \"min\": 9.301424026489258, \"max\": 9.301424026489258}}}\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] Epoch[61] Batch[0] avg_epoch_loss=2.587524\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.5875244140625\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] Epoch[61] Batch[5] avg_epoch_loss=2.688253\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.6882527271906533\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] Epoch[61] Batch [5]#011Speed: 2040.54 samples/sec#011loss=2.688253\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] processed a total of 1245 examples\n",
      "#metrics {\"StartTime\": 1747844309.7134233, \"EndTime\": 1747844310.6006336, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 887.1428966522217, \"count\": 1, \"min\": 887.1428966522217, \"max\": 887.1428966522217}}}\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1403.2329958474647 records/second\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.6469605445861815\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_a30b099d-892c-47b7-83fe-0e7429670e2c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844310.6006973, \"EndTime\": 1747844310.6102302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.11569595336914, \"count\": 1, \"min\": 9.11569595336914, \"max\": 9.11569595336914}}}\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] Epoch[62] Batch[0] avg_epoch_loss=2.639351\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.639350652694702\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] Epoch[62] Batch[5] avg_epoch_loss=2.715307\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.7153072357177734\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] Epoch[62] Batch [5]#011Speed: 2196.10 samples/sec#011loss=2.715307\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] Epoch[62] Batch[10] avg_epoch_loss=2.759767\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.8131179809570312\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] Epoch[62] Batch [10]#011Speed: 1929.85 samples/sec#011loss=2.813118\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747844310.6102738, \"EndTime\": 1747844311.5577018, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.3822116851807, \"count\": 1, \"min\": 947.3822116851807, \"max\": 947.3822116851807}}}\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.9104432579988 records/second\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.7597666653719815\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] Epoch[63] Batch[0] avg_epoch_loss=2.767029\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.767029285430908\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] Epoch[63] Batch[5] avg_epoch_loss=2.673155\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.673155148824056\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] Epoch[63] Batch [5]#011Speed: 2111.77 samples/sec#011loss=2.673155\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] Epoch[63] Batch[10] avg_epoch_loss=2.696899\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.725390625\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] Epoch[63] Batch [10]#011Speed: 2022.46 samples/sec#011loss=2.725391\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747844311.557758, \"EndTime\": 1747844312.4985, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.49072265625, \"count\": 1, \"min\": 940.49072265625, \"max\": 940.49072265625}}}\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1455.496150110214 records/second\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.6968985470858486\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] Epoch[64] Batch[0] avg_epoch_loss=2.802317\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.802316665649414\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] Epoch[64] Batch[5] avg_epoch_loss=2.699165\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.6991650660832724\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] Epoch[64] Batch [5]#011Speed: 2130.54 samples/sec#011loss=2.699165\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747844312.4985561, \"EndTime\": 1747844313.3660083, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 867.1646118164062, \"count\": 1, \"min\": 867.1646118164062, \"max\": 867.1646118164062}}}\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1475.9110567644868 records/second\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.6842265367507934\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] Epoch[65] Batch[0] avg_epoch_loss=2.747829\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.7478294372558594\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] Epoch[65] Batch[5] avg_epoch_loss=2.692172\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.6921721696853638\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] Epoch[65] Batch [5]#011Speed: 2152.82 samples/sec#011loss=2.692172\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Epoch[65] Batch[10] avg_epoch_loss=2.597779\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.4845073938369753\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Epoch[65] Batch [10]#011Speed: 2126.77 samples/sec#011loss=2.484507\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747844313.3660707, \"EndTime\": 1747844314.2837496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.259693145752, \"count\": 1, \"min\": 917.259693145752, \"max\": 917.259693145752}}}\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1443.2988997080008 records/second\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.597779089754278\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_26ff6204-3425-43cd-92e8-c18351622c9a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844314.2838042, \"EndTime\": 1747844314.2942386, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.16998291015625, \"count\": 1, \"min\": 10.16998291015625, \"max\": 10.16998291015625}}}\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Epoch[66] Batch[0] avg_epoch_loss=2.742064\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.7420644760131836\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Epoch[66] Batch[5] avg_epoch_loss=2.680289\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.6802891890207925\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Epoch[66] Batch [5]#011Speed: 2195.00 samples/sec#011loss=2.680289\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] Epoch[66] Batch[10] avg_epoch_loss=2.734270\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.7990467071533205\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] Epoch[66] Batch [10]#011Speed: 2073.28 samples/sec#011loss=2.799047\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844314.2942877, \"EndTime\": 1747844315.2128654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.5318946838379, \"count\": 1, \"min\": 918.5318946838379, \"max\": 918.5318946838379}}}\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1428.2439575886624 records/second\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.7342698790810327\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] Epoch[67] Batch[0] avg_epoch_loss=2.653497\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.6534972190856934\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] Epoch[67] Batch[5] avg_epoch_loss=2.704259\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.704259475072225\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] Epoch[67] Batch [5]#011Speed: 2125.32 samples/sec#011loss=2.704259\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] Epoch[67] Batch[10] avg_epoch_loss=2.703344\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.7022465229034425\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] Epoch[67] Batch [10]#011Speed: 1978.59 samples/sec#011loss=2.702247\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747844315.2129185, \"EndTime\": 1747844316.1542091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.0426616668701, \"count\": 1, \"min\": 941.0426616668701, \"max\": 941.0426616668701}}}\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1454.6447600255058 records/second\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.7033444968136875\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] Epoch[68] Batch[0] avg_epoch_loss=2.595007\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.5950074195861816\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] Epoch[68] Batch[5] avg_epoch_loss=2.645993\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.6459934314092\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] Epoch[68] Batch [5]#011Speed: 2159.51 samples/sec#011loss=2.645993\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Epoch[68] Batch[10] avg_epoch_loss=2.583158\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.5077563524246216\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Epoch[68] Batch [10]#011Speed: 2002.12 samples/sec#011loss=2.507756\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747844316.1542637, \"EndTime\": 1747844317.0920267, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.4833106994629, \"count\": 1, \"min\": 937.4833106994629, \"max\": 937.4833106994629}}}\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1410.0336452856982 records/second\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.583158395507119\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_8f649221-177b-4135-9dc8-e4145cc7e915-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844317.0920823, \"EndTime\": 1747844317.102839, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.469436645507812, \"count\": 1, \"min\": 10.469436645507812, \"max\": 10.469436645507812}}}\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Epoch[69] Batch[0] avg_epoch_loss=2.637610\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.63761043548584\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Epoch[69] Batch[5] avg_epoch_loss=2.672314\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.672313849131266\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Epoch[69] Batch [5]#011Speed: 2182.69 samples/sec#011loss=2.672314\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[69] Batch[10] avg_epoch_loss=2.698810\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.730605459213257\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[69] Batch [10]#011Speed: 2073.61 samples/sec#011loss=2.730605\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844317.1028888, \"EndTime\": 1747844318.0293224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.3887405395508, \"count\": 1, \"min\": 926.3887405395508, \"max\": 926.3887405395508}}}\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1437.7166144307114 records/second\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.698810035532171\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[70] Batch[0] avg_epoch_loss=2.708440\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.708439826965332\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[70] Batch[5] avg_epoch_loss=2.711126\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.7111255725224814\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[70] Batch [5]#011Speed: 2134.60 samples/sec#011loss=2.711126\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[70] Batch[10] avg_epoch_loss=2.689081\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.6626279830932615\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[70] Batch [10]#011Speed: 2125.25 samples/sec#011loss=2.662628\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747844318.0293763, \"EndTime\": 1747844318.9463341, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.6877269744873, \"count\": 1, \"min\": 916.6877269744873, \"max\": 916.6877269744873}}}\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1433.2944943420487 records/second\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.689081213691018\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] Epoch[71] Batch[0] avg_epoch_loss=2.640226\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.640226364135742\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] Epoch[71] Batch[5] avg_epoch_loss=2.697364\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.6973640521367392\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] Epoch[71] Batch [5]#011Speed: 2194.95 samples/sec#011loss=2.697364\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] Epoch[71] Batch[10] avg_epoch_loss=2.701304\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.7060321807861327\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] Epoch[71] Batch [10]#011Speed: 2033.88 samples/sec#011loss=2.706032\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747844318.94639, \"EndTime\": 1747844319.8691812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.529935836792, \"count\": 1, \"min\": 922.529935836792, \"max\": 922.529935836792}}}\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1485.9996774953795 records/second\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.7013041106137363\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Epoch[72] Batch[0] avg_epoch_loss=2.785212\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.7852115631103516\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Epoch[72] Batch[5] avg_epoch_loss=2.638068\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.638068159421285\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Epoch[72] Batch [5]#011Speed: 2136.09 samples/sec#011loss=2.638068\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Epoch[72] Batch[10] avg_epoch_loss=2.555631\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.4567064523696898\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Epoch[72] Batch [10]#011Speed: 2161.40 samples/sec#011loss=2.456706\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747844319.8692358, \"EndTime\": 1747844320.7891335, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.0182685852051, \"count\": 1, \"min\": 919.0182685852051, \"max\": 919.0182685852051}}}\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1423.118701101084 records/second\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.555631019852378\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_791974c1-f20b-4315-908a-45f7903f1a5c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844320.7891927, \"EndTime\": 1747844320.7996707, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.125875473022461, \"count\": 1, \"min\": 10.125875473022461, \"max\": 10.125875473022461}}}\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] Epoch[73] Batch[0] avg_epoch_loss=2.587415\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.5874152183532715\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] Epoch[73] Batch[5] avg_epoch_loss=2.663499\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.663499196370443\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] Epoch[73] Batch [5]#011Speed: 2135.34 samples/sec#011loss=2.663499\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] Epoch[73] Batch[10] avg_epoch_loss=2.662399\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=2.661077785491943\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] Epoch[73] Batch [10]#011Speed: 2165.25 samples/sec#011loss=2.661078\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844320.799707, \"EndTime\": 1747844321.7170436, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.2964096069336, \"count\": 1, \"min\": 917.2964096069336, \"max\": 917.2964096069336}}}\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1413.8175633689013 records/second\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.6623985550620337\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[74] Batch[0] avg_epoch_loss=2.677128\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.6771275997161865\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[74] Batch[5] avg_epoch_loss=2.648040\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.648040016492208\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[74] Batch [5]#011Speed: 2106.96 samples/sec#011loss=2.648040\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[74] Batch[10] avg_epoch_loss=2.620211\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.5868155479431154\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[74] Batch [10]#011Speed: 2037.65 samples/sec#011loss=2.586816\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747844321.7170982, \"EndTime\": 1747844322.6508062, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.4621429443359, \"count\": 1, \"min\": 933.4621429443359, \"max\": 933.4621429443359}}}\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.5245874174452 records/second\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.620210712606257\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[75] Batch[0] avg_epoch_loss=2.576171\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.576171398162842\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] Epoch[75] Batch[5] avg_epoch_loss=2.565156\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.565155506134033\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] Epoch[75] Batch [5]#011Speed: 2172.26 samples/sec#011loss=2.565156\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] Epoch[75] Batch[10] avg_epoch_loss=2.598329\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=2.6381362438201905\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] Epoch[75] Batch [10]#011Speed: 2109.52 samples/sec#011loss=2.638136\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747844322.650863, \"EndTime\": 1747844323.5644343, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 913.3241176605225, \"count\": 1, \"min\": 913.3241176605225, \"max\": 913.3241176605225}}}\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1473.6086308506135 records/second\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.59832856871865\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] Epoch[76] Batch[0] avg_epoch_loss=2.667192\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.667191505432129\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] Epoch[76] Batch[5] avg_epoch_loss=2.648342\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.648342251777649\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] Epoch[76] Batch [5]#011Speed: 2138.92 samples/sec#011loss=2.648342\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] Epoch[76] Batch[10] avg_epoch_loss=2.653079\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.658762741088867\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] Epoch[76] Batch [10]#011Speed: 2095.11 samples/sec#011loss=2.658763\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747844323.5644875, \"EndTime\": 1747844324.4853055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.5539226531982, \"count\": 1, \"min\": 920.5539226531982, \"max\": 920.5539226531982}}}\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1453.3409622800655 records/second\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.6530788378282026\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] Epoch[77] Batch[0] avg_epoch_loss=2.482671\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.4826714992523193\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] Epoch[77] Batch[5] avg_epoch_loss=2.617149\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.617148995399475\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] Epoch[77] Batch [5]#011Speed: 2138.31 samples/sec#011loss=2.617149\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] Epoch[77] Batch[10] avg_epoch_loss=2.634044\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.6543182849884035\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] Epoch[77] Batch [10]#011Speed: 2053.55 samples/sec#011loss=2.654318\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747844324.4853623, \"EndTime\": 1747844325.4153063, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.6698570251465, \"count\": 1, \"min\": 929.6698570251465, \"max\": 929.6698570251465}}}\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.0017909262813 records/second\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.634044127030806\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] Epoch[78] Batch[0] avg_epoch_loss=2.507796\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.507796049118042\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[78] Batch[5] avg_epoch_loss=2.581424\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.581424276034037\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[78] Batch [5]#011Speed: 2135.96 samples/sec#011loss=2.581424\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[78] Batch[10] avg_epoch_loss=2.596632\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.6148819446563722\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[78] Batch [10]#011Speed: 2076.17 samples/sec#011loss=2.614882\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844325.4153607, \"EndTime\": 1747844326.3466473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.0281276702881, \"count\": 1, \"min\": 931.0281276702881, \"max\": 931.0281276702881}}}\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1450.95207470739 records/second\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.596632307226008\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[79] Batch[0] avg_epoch_loss=2.659168\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.659168243408203\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[79] Batch[5] avg_epoch_loss=2.565337\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.5653370221455893\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[79] Batch [5]#011Speed: 2195.61 samples/sec#011loss=2.565337\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] Epoch[79] Batch[10] avg_epoch_loss=2.604857\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.652281379699707\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] Epoch[79] Batch [10]#011Speed: 2052.05 samples/sec#011loss=2.652281\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844326.3467045, \"EndTime\": 1747844327.266499, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.5408821105957, \"count\": 1, \"min\": 919.5408821105957, \"max\": 919.5408821105957}}}\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1458.21018529657 records/second\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.604857184670188\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] Epoch[80] Batch[0] avg_epoch_loss=2.539536\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.539536237716675\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] Epoch[80] Batch[5] avg_epoch_loss=2.519401\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.5194009145100913\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] Epoch[80] Batch [5]#011Speed: 2184.44 samples/sec#011loss=2.519401\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Epoch[80] Batch[10] avg_epoch_loss=2.542533\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.57029128074646\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Epoch[80] Batch [10]#011Speed: 1948.75 samples/sec#011loss=2.570291\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] processed a total of 1380 examples\n",
      "#metrics {\"StartTime\": 1747844327.2665532, \"EndTime\": 1747844328.20755, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.709114074707, \"count\": 1, \"min\": 940.709114074707, \"max\": 940.709114074707}}}\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1466.8435013531482 records/second\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.542532899162986\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_625c93f5-58de-4bfb-9098-4de2e08c0733-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844328.2076077, \"EndTime\": 1747844328.2182775, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.394096374511719, \"count\": 1, \"min\": 10.394096374511719, \"max\": 10.394096374511719}}}\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Epoch[81] Batch[0] avg_epoch_loss=2.599761\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.5997612476348877\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Epoch[81] Batch[5] avg_epoch_loss=2.617402\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.6174017985661826\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Epoch[81] Batch [5]#011Speed: 2195.30 samples/sec#011loss=2.617402\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Epoch[81] Batch[10] avg_epoch_loss=2.524622\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.413285565376282\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Epoch[81] Batch [10]#011Speed: 2114.87 samples/sec#011loss=2.413286\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844328.218328, \"EndTime\": 1747844329.1334972, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.12131690979, \"count\": 1, \"min\": 915.12131690979, \"max\": 915.12131690979}}}\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.2836254506803 records/second\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.524621692570773\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_827f84db-51f5-4ce8-bc61-2ef2192583d5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844329.1335526, \"EndTime\": 1747844329.1443543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.52093505859375, \"count\": 1, \"min\": 10.52093505859375, \"max\": 10.52093505859375}}}\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Epoch[82] Batch[0] avg_epoch_loss=2.544739\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.5447394847869873\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Epoch[82] Batch[5] avg_epoch_loss=2.559262\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.5592620372772217\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Epoch[82] Batch [5]#011Speed: 2063.30 samples/sec#011loss=2.559262\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747844329.1444013, \"EndTime\": 1747844330.008599, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.152193069458, \"count\": 1, \"min\": 864.152193069458, \"max\": 864.152193069458}}}\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1478.7596905383798 records/second\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.544045925140381\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Epoch[83] Batch[0] avg_epoch_loss=2.516079\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.5160794258117676\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Epoch[83] Batch[5] avg_epoch_loss=2.562589\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.5625888109207153\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Epoch[83] Batch [5]#011Speed: 2251.95 samples/sec#011loss=2.562589\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Epoch[83] Batch[10] avg_epoch_loss=2.521766\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.472777843475342\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Epoch[83] Batch [10]#011Speed: 1956.67 samples/sec#011loss=2.472778\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] processed a total of 1397 examples\n",
      "#metrics {\"StartTime\": 1747844330.0086575, \"EndTime\": 1747844330.9262424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.2530174255371, \"count\": 1, \"min\": 917.2530174255371, \"max\": 917.2530174255371}}}\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1522.8915985307117 records/second\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.521765643900091\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_3af60ff6-d845-4fc9-a85a-036313d67334-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844330.9262962, \"EndTime\": 1747844330.9367306, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.13326644897461, \"count\": 1, \"min\": 10.13326644897461, \"max\": 10.13326644897461}}}\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] Epoch[84] Batch[0] avg_epoch_loss=2.593500\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.5934996604919434\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] Epoch[84] Batch[5] avg_epoch_loss=2.568795\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.568795402844747\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] Epoch[84] Batch [5]#011Speed: 2151.02 samples/sec#011loss=2.568795\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] Epoch[84] Batch[10] avg_epoch_loss=2.581604\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.596974420547485\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] Epoch[84] Batch [10]#011Speed: 2109.20 samples/sec#011loss=2.596974\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844330.9367797, \"EndTime\": 1747844331.8757305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.9054775238037, \"count\": 1, \"min\": 938.9054775238037, \"max\": 938.9054775238037}}}\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1394.0540681357738 records/second\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.5816040472550825\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] Epoch[85] Batch[0] avg_epoch_loss=2.574815\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.574815273284912\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] Epoch[85] Batch[5] avg_epoch_loss=2.582688\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.5826878945032754\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] Epoch[85] Batch [5]#011Speed: 2204.28 samples/sec#011loss=2.582688\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] Epoch[85] Batch[10] avg_epoch_loss=2.593978\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=2.6075253009796144\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] Epoch[85] Batch [10]#011Speed: 2087.10 samples/sec#011loss=2.607525\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747844331.8757877, \"EndTime\": 1747844332.7881424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.1079444885254, \"count\": 1, \"min\": 912.1079444885254, \"max\": 912.1079444885254}}}\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1498.5874503268678 records/second\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.593977624719793\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] Epoch[86] Batch[0] avg_epoch_loss=2.564471\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.564471483230591\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] Epoch[86] Batch[5] avg_epoch_loss=2.505260\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.505259911219279\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] Epoch[86] Batch [5]#011Speed: 2095.10 samples/sec#011loss=2.505260\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] Epoch[86] Batch[10] avg_epoch_loss=2.559611\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.6248323917388916\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] Epoch[86] Batch [10]#011Speed: 2012.56 samples/sec#011loss=2.624832\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747844332.7881992, \"EndTime\": 1747844333.7352378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.786642074585, \"count\": 1, \"min\": 946.786642074585, \"max\": 946.786642074585}}}\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1425.7517645921293 records/second\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.559611038728194\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[87] Batch[0] avg_epoch_loss=2.576954\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.576953887939453\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[87] Batch[5] avg_epoch_loss=2.546942\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.546941558519999\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[87] Batch [5]#011Speed: 2147.80 samples/sec#011loss=2.546942\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[87] Batch[10] avg_epoch_loss=2.526176\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.501256513595581\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[87] Batch [10]#011Speed: 2067.62 samples/sec#011loss=2.501257\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844333.7352922, \"EndTime\": 1747844334.6643832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.8334846496582, \"count\": 1, \"min\": 928.8334846496582, \"max\": 928.8334846496582}}}\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.9350323588255 records/second\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.5261756290089\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[88] Batch[0] avg_epoch_loss=2.521134\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.521134376525879\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] Epoch[88] Batch[5] avg_epoch_loss=2.524491\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.52449099222819\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] Epoch[88] Batch [5]#011Speed: 2009.92 samples/sec#011loss=2.524491\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] Epoch[88] Batch[10] avg_epoch_loss=2.548667\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=2.5776791095733644\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] Epoch[88] Batch [10]#011Speed: 2080.61 samples/sec#011loss=2.577679\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844334.664438, \"EndTime\": 1747844335.6101573, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.4381465911865, \"count\": 1, \"min\": 945.4381465911865, \"max\": 945.4381465911865}}}\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1412.9795710673038 records/second\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.548667409203269\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] Epoch[89] Batch[0] avg_epoch_loss=2.496668\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.4966676235198975\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] Epoch[89] Batch[5] avg_epoch_loss=2.523211\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.5232107639312744\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] Epoch[89] Batch [5]#011Speed: 2139.86 samples/sec#011loss=2.523211\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] Epoch[89] Batch[10] avg_epoch_loss=2.580910\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=2.6501489639282227\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] Epoch[89] Batch [10]#011Speed: 2081.06 samples/sec#011loss=2.650149\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844335.6102111, \"EndTime\": 1747844336.5389662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.5123348236084, \"count\": 1, \"min\": 928.5123348236084, \"max\": 928.5123348236084}}}\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1412.883483190494 records/second\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.580909945748069\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] Epoch[90] Batch[0] avg_epoch_loss=2.678149\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.6781492233276367\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] Epoch[90] Batch[5] avg_epoch_loss=2.540747\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.5407474438349404\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] Epoch[90] Batch [5]#011Speed: 2015.56 samples/sec#011loss=2.540747\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] Epoch[90] Batch[10] avg_epoch_loss=2.548369\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.5575154781341554\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] Epoch[90] Batch [10]#011Speed: 1968.46 samples/sec#011loss=2.557515\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844336.539024, \"EndTime\": 1747844337.5055056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 966.2370681762695, \"count\": 1, \"min\": 966.2370681762695, \"max\": 966.2370681762695}}}\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1364.9627827611084 records/second\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.548369277607311\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] Epoch[91] Batch[0] avg_epoch_loss=2.544415\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.544414520263672\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] Epoch[91] Batch[5] avg_epoch_loss=2.495894\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.4958940744400024\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] Epoch[91] Batch [5]#011Speed: 2216.38 samples/sec#011loss=2.495894\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] Epoch[91] Batch[10] avg_epoch_loss=2.521802\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=2.552891254425049\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] Epoch[91] Batch [10]#011Speed: 2000.24 samples/sec#011loss=2.552891\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747844337.5055654, \"EndTime\": 1747844338.4303374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.518346786499, \"count\": 1, \"min\": 924.518346786499, \"max\": 924.518346786499}}}\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1478.476599223064 records/second\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.5218018835241143\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] Epoch[92] Batch[0] avg_epoch_loss=2.581659\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.5816593170166016\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[92] Batch[5] avg_epoch_loss=2.512166\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.5121663014094033\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[92] Batch [5]#011Speed: 2267.61 samples/sec#011loss=2.512166\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[92] Batch[10] avg_epoch_loss=2.505539\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.4975860118865967\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[92] Batch [10]#011Speed: 2107.61 samples/sec#011loss=2.497586\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844338.4303923, \"EndTime\": 1747844339.3350036, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.3686389923096, \"count\": 1, \"min\": 904.3686389923096, \"max\": 904.3686389923096}}}\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1482.6706875435939 records/second\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.505538897080855\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_e45a1a04-2c04-43d9-b97b-53284d69f460-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844339.3350575, \"EndTime\": 1747844339.345525, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.207176208496094, \"count\": 1, \"min\": 10.207176208496094, \"max\": 10.207176208496094}}}\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[93] Batch[0] avg_epoch_loss=2.486224\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.4862236976623535\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[93] Batch[5] avg_epoch_loss=2.548997\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.548997243245443\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[93] Batch [5]#011Speed: 2227.42 samples/sec#011loss=2.548997\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Epoch[93] Batch[10] avg_epoch_loss=2.502475\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.446647882461548\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Epoch[93] Batch [10]#011Speed: 1958.03 samples/sec#011loss=2.446648\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747844339.3455737, \"EndTime\": 1747844340.2710476, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.426721572876, \"count\": 1, \"min\": 925.426721572876, \"max\": 925.426721572876}}}\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1478.10331510158 records/second\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.5024748065254907\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_0a2abff6-f741-4722-b207-e69860709141-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844340.2711043, \"EndTime\": 1747844340.2815213, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.152816772460938, \"count\": 1, \"min\": 10.152816772460938, \"max\": 10.152816772460938}}}\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Epoch[94] Batch[0] avg_epoch_loss=2.568638\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.5686376094818115\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Epoch[94] Batch[5] avg_epoch_loss=2.550819\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.5508190790812173\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Epoch[94] Batch [5]#011Speed: 2128.34 samples/sec#011loss=2.550819\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Epoch[94] Batch[10] avg_epoch_loss=2.488851\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=2.4144886255264284\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Epoch[94] Batch [10]#011Speed: 2040.25 samples/sec#011loss=2.414489\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844340.2815726, \"EndTime\": 1747844341.232095, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.4749774932861, \"count\": 1, \"min\": 950.4749774932861, \"max\": 950.4749774932861}}}\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.1647255760943 records/second\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.4888506911017676\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_45724cd0-2b12-4272-b652-14118951d852-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844341.2321517, \"EndTime\": 1747844341.242488, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.069608688354492, \"count\": 1, \"min\": 10.069608688354492, \"max\": 10.069608688354492}}}\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Epoch[95] Batch[0] avg_epoch_loss=2.615051\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.615050792694092\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Epoch[95] Batch[5] avg_epoch_loss=2.479632\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.4796317418416343\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Epoch[95] Batch [5]#011Speed: 2098.60 samples/sec#011loss=2.479632\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] Epoch[95] Batch[10] avg_epoch_loss=2.525263\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.580020618438721\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] Epoch[95] Batch [10]#011Speed: 1873.79 samples/sec#011loss=2.580021\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844341.2425356, \"EndTime\": 1747844342.205766, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.1829261779785, \"count\": 1, \"min\": 963.1829261779785, \"max\": 963.1829261779785}}}\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1392.1358771102402 records/second\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.525263049385764\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] Epoch[96] Batch[0] avg_epoch_loss=2.540325\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.5403249263763428\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] Epoch[96] Batch[5] avg_epoch_loss=2.515888\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.515888492266337\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] Epoch[96] Batch [5]#011Speed: 2195.18 samples/sec#011loss=2.515888\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] Epoch[96] Batch[10] avg_epoch_loss=2.545796\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.581685018539429\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] Epoch[96] Batch [10]#011Speed: 2113.40 samples/sec#011loss=2.581685\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747844342.205823, \"EndTime\": 1747844343.1179688, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.8402004241943, \"count\": 1, \"min\": 911.8402004241943, \"max\": 911.8402004241943}}}\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1448.5918695275918 records/second\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.5457960042086514\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] Epoch[97] Batch[0] avg_epoch_loss=2.425649\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.425649404525757\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] Epoch[97] Batch[5] avg_epoch_loss=2.498859\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.4988587697347007\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] Epoch[97] Batch [5]#011Speed: 2203.32 samples/sec#011loss=2.498859\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[97] Batch[10] avg_epoch_loss=2.482701\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.463312101364136\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[97] Batch [10]#011Speed: 2054.44 samples/sec#011loss=2.463312\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747844343.1180232, \"EndTime\": 1747844344.0347826, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.3815975189209, \"count\": 1, \"min\": 916.3815975189209, \"max\": 916.3815975189209}}}\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1480.7178223758988 records/second\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.4827011932026255\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_c097895e-48a0-4481-85c7-279eabca7c8c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844344.0348241, \"EndTime\": 1747844344.0456467, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.603666305541992, \"count\": 1, \"min\": 10.603666305541992, \"max\": 10.603666305541992}}}\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[98] Batch[0] avg_epoch_loss=2.416579\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.416578769683838\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[98] Batch[5] avg_epoch_loss=2.438522\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.43852162361145\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[98] Batch [5]#011Speed: 2185.18 samples/sec#011loss=2.438522\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[98] Batch[10] avg_epoch_loss=2.465466\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=2.497799205780029\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[98] Batch [10]#011Speed: 2115.02 samples/sec#011loss=2.497799\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747844344.0456958, \"EndTime\": 1747844344.9603317, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.5913124084473, \"count\": 1, \"min\": 914.5913124084473, \"max\": 914.5913124084473}}}\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1443.139305836308 records/second\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.4654659791426226\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_38048547-ce28-4ca4-b3c4-5b870dc3f122-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844344.9603875, \"EndTime\": 1747844344.971202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.554313659667969, \"count\": 1, \"min\": 10.554313659667969, \"max\": 10.554313659667969}}}\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] Epoch[99] Batch[0] avg_epoch_loss=2.473066\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.4730658531188965\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] Epoch[99] Batch[5] avg_epoch_loss=2.469876\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.469875693321228\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] Epoch[99] Batch [5]#011Speed: 2156.93 samples/sec#011loss=2.469876\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] processed a total of 1269 examples\n",
      "#metrics {\"StartTime\": 1747844344.9712505, \"EndTime\": 1747844345.825837, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 854.5260429382324, \"count\": 1, \"min\": 854.5260429382324, \"max\": 854.5260429382324}}}\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1484.8816883986062 records/second\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.471322846412659\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Epoch[100] Batch[0] avg_epoch_loss=2.366273\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.3662731647491455\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Epoch[100] Batch[5] avg_epoch_loss=2.445511\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.4455111026763916\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Epoch[100] Batch [5]#011Speed: 2145.06 samples/sec#011loss=2.445511\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Epoch[100] Batch[10] avg_epoch_loss=2.332029\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.195850133895874\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Epoch[100] Batch [10]#011Speed: 2035.57 samples/sec#011loss=2.195850\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844345.8258963, \"EndTime\": 1747844346.7571185, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.9351444244385, \"count\": 1, \"min\": 930.9351444244385, \"max\": 930.9351444244385}}}\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1385.5799156613887 records/second\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.3320288441397925\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_29617f75-22dd-4e81-b640-fb20f128afd8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844346.7571747, \"EndTime\": 1747844346.7681153, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.617733001708984, \"count\": 1, \"min\": 10.617733001708984, \"max\": 10.617733001708984}}}\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[101] Batch[0] avg_epoch_loss=2.514674\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.514674425125122\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[101] Batch[5] avg_epoch_loss=2.484517\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.484517296155294\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[101] Batch [5]#011Speed: 2178.92 samples/sec#011loss=2.484517\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[101] Batch[10] avg_epoch_loss=2.504199\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=2.527817153930664\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[101] Batch [10]#011Speed: 2142.91 samples/sec#011loss=2.527817\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747844346.768165, \"EndTime\": 1747844347.6741576, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 905.9481620788574, \"count\": 1, \"min\": 905.9481620788574, \"max\": 905.9481620788574}}}\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.3602376532765 records/second\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.504199049689553\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[102] Batch[0] avg_epoch_loss=2.569388\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.5693881511688232\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] Epoch[102] Batch[5] avg_epoch_loss=2.572202\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.5722023248672485\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] Epoch[102] Batch [5]#011Speed: 2130.81 samples/sec#011loss=2.572202\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] Epoch[102] Batch[10] avg_epoch_loss=2.454001\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=2.312159562110901\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] Epoch[102] Batch [10]#011Speed: 2141.76 samples/sec#011loss=2.312160\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844347.6742132, \"EndTime\": 1747844348.595684, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.2260246276855, \"count\": 1, \"min\": 921.2260246276855, \"max\": 921.2260246276855}}}\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.0427171913975 records/second\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.4540010690689087\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] Epoch[103] Batch[0] avg_epoch_loss=2.595697\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.5956969261169434\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] Epoch[103] Batch[5] avg_epoch_loss=2.464097\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.4640973011652627\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] Epoch[103] Batch [5]#011Speed: 2223.46 samples/sec#011loss=2.464097\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] Epoch[103] Batch[10] avg_epoch_loss=2.531548\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.6124877452850344\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] Epoch[103] Batch [10]#011Speed: 2087.91 samples/sec#011loss=2.612488\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747844348.5957534, \"EndTime\": 1747844349.510564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.5660400390625, \"count\": 1, \"min\": 914.5660400390625, \"max\": 914.5660400390625}}}\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1439.8996034729223 records/second\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.5315475030378862\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] Epoch[104] Batch[0] avg_epoch_loss=2.487704\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.487703561782837\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] Epoch[104] Batch[5] avg_epoch_loss=2.455972\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.455971678098043\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] Epoch[104] Batch [5]#011Speed: 2138.44 samples/sec#011loss=2.455972\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] Epoch[104] Batch[10] avg_epoch_loss=2.484526\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=2.518790531158447\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] Epoch[104] Batch [10]#011Speed: 1945.91 samples/sec#011loss=2.518791\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747844349.5106187, \"EndTime\": 1747844350.4584174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.5491046905518, \"count\": 1, \"min\": 947.5491046905518, \"max\": 947.5491046905518}}}\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1382.374275764955 records/second\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.4845257022164087\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] Epoch[105] Batch[0] avg_epoch_loss=2.488034\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.4880340099334717\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] Epoch[105] Batch[5] avg_epoch_loss=2.586483\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.5864830017089844\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] Epoch[105] Batch [5]#011Speed: 2137.98 samples/sec#011loss=2.586483\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] Epoch[105] Batch[10] avg_epoch_loss=2.520594\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.44152774810791\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] Epoch[105] Batch [10]#011Speed: 2006.70 samples/sec#011loss=2.441528\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747844350.4584813, \"EndTime\": 1747844351.3958073, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.9912147521973, \"count\": 1, \"min\": 936.9912147521973, \"max\": 936.9912147521973}}}\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.2419539995929 records/second\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.5205942500721323\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] Epoch[106] Batch[0] avg_epoch_loss=2.679627\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.679626703262329\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[106] Batch[5] avg_epoch_loss=2.552969\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.5529689391454062\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[106] Batch [5]#011Speed: 2137.83 samples/sec#011loss=2.552969\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[106] Batch[10] avg_epoch_loss=2.601831\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=2.6604661464691164\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[106] Batch [10]#011Speed: 2089.74 samples/sec#011loss=2.660466\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844351.3958657, \"EndTime\": 1747844352.3523421, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.1793804168701, \"count\": 1, \"min\": 956.1793804168701, \"max\": 956.1793804168701}}}\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1385.6147656552112 records/second\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.601831306110729\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[107] Batch[0] avg_epoch_loss=2.481964\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.481964349746704\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[107] Batch[5] avg_epoch_loss=2.499590\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.499589681625366\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[107] Batch [5]#011Speed: 2204.46 samples/sec#011loss=2.499590\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] Epoch[107] Batch[10] avg_epoch_loss=2.509140\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.520600986480713\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] Epoch[107] Batch [10]#011Speed: 2103.16 samples/sec#011loss=2.520601\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844352.3523917, \"EndTime\": 1747844353.2666519, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.0136241912842, \"count\": 1, \"min\": 914.0136241912842, \"max\": 914.0136241912842}}}\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.1095289077832 records/second\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.509140274741433\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] Epoch[108] Batch[0] avg_epoch_loss=2.499492\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.4994921684265137\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] Epoch[108] Batch[5] avg_epoch_loss=2.469515\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.4695154428482056\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] Epoch[108] Batch [5]#011Speed: 2243.37 samples/sec#011loss=2.469515\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] Epoch[108] Batch[10] avg_epoch_loss=2.501070\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.538936233520508\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] Epoch[108] Batch [10]#011Speed: 2042.43 samples/sec#011loss=2.538936\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747844353.2667491, \"EndTime\": 1747844354.1831021, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.0678386688232, \"count\": 1, \"min\": 916.0678386688232, \"max\": 916.0678386688232}}}\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1496.4785137204742 records/second\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.501070347699252\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] Epoch[109] Batch[0] avg_epoch_loss=2.484426\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.484426259994507\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] Epoch[109] Batch[5] avg_epoch_loss=2.479495\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.4794954856236777\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] Epoch[109] Batch [5]#011Speed: 2136.85 samples/sec#011loss=2.479495\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] Epoch[109] Batch[10] avg_epoch_loss=2.447394\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.408871793746948\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] Epoch[109] Batch [10]#011Speed: 2134.47 samples/sec#011loss=2.408872\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747844354.1831574, \"EndTime\": 1747844355.1055264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.1246242523193, \"count\": 1, \"min\": 922.1246242523193, \"max\": 922.1246242523193}}}\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1418.3339172662838 records/second\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.4473938074978916\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] Epoch[110] Batch[0] avg_epoch_loss=2.515764\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.515763759613037\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] Epoch[110] Batch[5] avg_epoch_loss=2.444915\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.444915493329366\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] Epoch[110] Batch [5]#011Speed: 2130.40 samples/sec#011loss=2.444915\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[110] Batch[10] avg_epoch_loss=2.473953\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.508798599243164\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[110] Batch [10]#011Speed: 2094.63 samples/sec#011loss=2.508799\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844355.1055825, \"EndTime\": 1747844356.0369165, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.0657978057861, \"count\": 1, \"min\": 931.0657978057861, \"max\": 931.0657978057861}}}\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1402.567138604925 records/second\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.473953268744729\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[111] Batch[0] avg_epoch_loss=2.477202\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.4772024154663086\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[111] Batch[5] avg_epoch_loss=2.517113\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.5171127319335938\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[111] Batch [5]#011Speed: 2163.01 samples/sec#011loss=2.517113\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[111] Batch[10] avg_epoch_loss=2.532923\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=2.5518945693969726\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[111] Batch [10]#011Speed: 2036.30 samples/sec#011loss=2.551895\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844356.036973, \"EndTime\": 1747844356.9655929, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.3826351165771, \"count\": 1, \"min\": 928.3826351165771, \"max\": 928.3826351165771}}}\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1438.938759998069 records/second\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.5329226580533115\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] Epoch[112] Batch[0] avg_epoch_loss=2.579566\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.579566478729248\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] Epoch[112] Batch[5] avg_epoch_loss=2.501805\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.501805067062378\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] Epoch[112] Batch [5]#011Speed: 2160.23 samples/sec#011loss=2.501805\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] Epoch[112] Batch[10] avg_epoch_loss=2.484142\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.4629465103149415\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] Epoch[112] Batch [10]#011Speed: 2006.72 samples/sec#011loss=2.462947\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] processed a total of 1388 examples\n",
      "#metrics {\"StartTime\": 1747844356.9656465, \"EndTime\": 1747844357.8937457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.8521537780762, \"count\": 1, \"min\": 927.8521537780762, \"max\": 927.8521537780762}}}\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1495.7915360263964 records/second\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.4841420867226343\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] Epoch[113] Batch[0] avg_epoch_loss=2.420855\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.4208552837371826\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] Epoch[113] Batch[5] avg_epoch_loss=2.489880\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.489880363146464\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] Epoch[113] Batch [5]#011Speed: 2097.24 samples/sec#011loss=2.489880\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] Epoch[113] Batch[10] avg_epoch_loss=2.467430\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.4404892444610597\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] Epoch[113] Batch [10]#011Speed: 2155.80 samples/sec#011loss=2.440489\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747844357.8938024, \"EndTime\": 1747844358.8173594, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.2959747314453, \"count\": 1, \"min\": 923.2959747314453, \"max\": 923.2959747314453}}}\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1439.2958059452806 records/second\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.467429854653098\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] Epoch[114] Batch[0] avg_epoch_loss=2.502264\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.5022644996643066\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] Epoch[114] Batch[5] avg_epoch_loss=2.578713\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.5787134567896524\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] Epoch[114] Batch [5]#011Speed: 2137.48 samples/sec#011loss=2.578713\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] Epoch[114] Batch[10] avg_epoch_loss=2.618420\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=2.6660674571990968\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] Epoch[114] Batch [10]#011Speed: 2205.12 samples/sec#011loss=2.666067\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747844358.817406, \"EndTime\": 1747844359.7289417, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.2064838409424, \"count\": 1, \"min\": 911.2064838409424, \"max\": 911.2064838409424}}}\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.774972888757 records/second\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.618419820612127\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[115] Batch[0] avg_epoch_loss=2.581695\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.581695318222046\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[115] Batch[5] avg_epoch_loss=2.511013\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.5110127131144204\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[115] Batch [5]#011Speed: 2057.87 samples/sec#011loss=2.511013\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[115] Batch[10] avg_epoch_loss=2.360514\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=2.1799148082733155\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[115] Batch [10]#011Speed: 2104.54 samples/sec#011loss=2.179915\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747844359.7289958, \"EndTime\": 1747844360.6715782, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.3387050628662, \"count\": 1, \"min\": 942.3387050628662, \"max\": 942.3387050628662}}}\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1359.2658729335524 records/second\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.3605136654593726\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[116] Batch[0] avg_epoch_loss=2.427891\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.4278910160064697\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] Epoch[116] Batch[5] avg_epoch_loss=2.431253\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.4312525590260825\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] Epoch[116] Batch [5]#011Speed: 2192.01 samples/sec#011loss=2.431253\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] Epoch[116] Batch[10] avg_epoch_loss=2.516590\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=2.6189942359924316\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] Epoch[116] Batch [10]#011Speed: 1960.26 samples/sec#011loss=2.618994\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747844360.6716332, \"EndTime\": 1747844361.6060398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.1399669647217, \"count\": 1, \"min\": 934.1399669647217, \"max\": 934.1399669647217}}}\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.136648433945 records/second\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.5165896849198774\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] Epoch[117] Batch[0] avg_epoch_loss=2.460442\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.460441827774048\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] Epoch[117] Batch[5] avg_epoch_loss=2.453490\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.4534895022710166\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] Epoch[117] Batch [5]#011Speed: 2189.03 samples/sec#011loss=2.453490\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] Epoch[117] Batch[10] avg_epoch_loss=2.442530\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.429378843307495\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] Epoch[117] Batch [10]#011Speed: 2037.66 samples/sec#011loss=2.429379\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844361.6060941, \"EndTime\": 1747844362.5311887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.8487949371338, \"count\": 1, \"min\": 924.8487949371338, \"max\": 924.8487949371338}}}\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1440.1099459070715 records/second\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.4425301118330522\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] Epoch[118] Batch[0] avg_epoch_loss=2.521953\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.5219528675079346\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] Epoch[118] Batch[5] avg_epoch_loss=2.487997\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.4879966576894126\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] Epoch[118] Batch [5]#011Speed: 2144.68 samples/sec#011loss=2.487997\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] Epoch[118] Batch[10] avg_epoch_loss=2.484834\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.4810391426086427\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] Epoch[118] Batch [10]#011Speed: 2055.71 samples/sec#011loss=2.481039\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844362.531238, \"EndTime\": 1747844363.4621613, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.6051731109619, \"count\": 1, \"min\": 930.6051731109619, \"max\": 930.6051731109619}}}\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.188066253392 records/second\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.484834150834517\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] Epoch[119] Batch[0] avg_epoch_loss=2.501423\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.5014233589172363\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] Epoch[119] Batch[5] avg_epoch_loss=2.359029\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.3590290546417236\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] Epoch[119] Batch [5]#011Speed: 2114.87 samples/sec#011loss=2.359029\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747844363.4622195, \"EndTime\": 1747844364.3291228, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 866.5966987609863, \"count\": 1, \"min\": 866.5966987609863, \"max\": 866.5966987609863}}}\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1454.931343915868 records/second\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.359263563156128\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] Epoch[120] Batch[0] avg_epoch_loss=2.391076\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.39107608795166\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] Epoch[120] Batch[5] avg_epoch_loss=2.422777\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.422776738802592\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] Epoch[120] Batch [5]#011Speed: 2198.38 samples/sec#011loss=2.422777\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] Epoch[120] Batch[10] avg_epoch_loss=2.408092\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=2.3904700756072996\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] Epoch[120] Batch [10]#011Speed: 2022.39 samples/sec#011loss=2.390470\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747844364.329191, \"EndTime\": 1747844365.2576568, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.0266761779785, \"count\": 1, \"min\": 928.0266761779785, \"max\": 928.0266761779785}}}\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1416.8540885627929 records/second\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.408091891895641\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] Epoch[121] Batch[0] avg_epoch_loss=2.414685\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.414684772491455\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] Epoch[121] Batch[5] avg_epoch_loss=2.488867\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.488867481549581\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] Epoch[121] Batch [5]#011Speed: 2149.32 samples/sec#011loss=2.488867\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] Epoch[121] Batch[10] avg_epoch_loss=2.510795\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=2.5371081829071045\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] Epoch[121] Batch [10]#011Speed: 2063.11 samples/sec#011loss=2.537108\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747844365.2577128, \"EndTime\": 1747844366.1901793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.2206974029541, \"count\": 1, \"min\": 932.2206974029541, \"max\": 932.2206974029541}}}\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1465.1803502724156 records/second\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.510795073075728\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] Epoch[122] Batch[0] avg_epoch_loss=2.438099\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.4380991458892822\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] Epoch[122] Batch[5] avg_epoch_loss=2.390530\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.39052951335907\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] Epoch[122] Batch [5]#011Speed: 2140.83 samples/sec#011loss=2.390530\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] Epoch[122] Batch[10] avg_epoch_loss=2.378257\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=2.3635307788848876\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] Epoch[122] Batch [10]#011Speed: 1964.00 samples/sec#011loss=2.363531\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] processed a total of 1409 examples\n",
      "#metrics {\"StartTime\": 1747844366.1902387, \"EndTime\": 1747844367.1933372, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1002.8350353240967, \"count\": 1, \"min\": 1002.8350353240967, \"max\": 1002.8350353240967}}}\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1404.8938137857438 records/second\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.4166356523831687\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] Epoch[123] Batch[0] avg_epoch_loss=2.465710\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.465710401535034\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] Epoch[123] Batch[5] avg_epoch_loss=2.415783\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.415782928466797\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] Epoch[123] Batch [5]#011Speed: 2167.97 samples/sec#011loss=2.415783\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] Epoch[123] Batch[10] avg_epoch_loss=2.387924\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=2.3544943809509276\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] Epoch[123] Batch [10]#011Speed: 2073.64 samples/sec#011loss=2.354494\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747844367.193395, \"EndTime\": 1747844368.1176212, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.9192008972168, \"count\": 1, \"min\": 923.9192008972168, \"max\": 923.9192008972168}}}\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1468.6101318806702 records/second\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 31.0 % of epochs\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.3879244977777656\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] Epoch[124] Batch[0] avg_epoch_loss=2.412093\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.412093162536621\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] Epoch[124] Batch[5] avg_epoch_loss=2.385314\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.385314146677653\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] Epoch[124] Batch [5]#011Speed: 2161.77 samples/sec#011loss=2.385314\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[124] Batch[10] avg_epoch_loss=2.409338\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=2.4381657600402833\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[124] Batch [10]#011Speed: 2191.12 samples/sec#011loss=2.438166\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747844368.1176796, \"EndTime\": 1747844369.023939, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.012773513794, \"count\": 1, \"min\": 906.012773513794, \"max\": 906.012773513794}}}\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.904095816299 records/second\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 31.25 % of epochs\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.4093376072970303\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[125] Batch[0] avg_epoch_loss=2.421747\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.4217472076416016\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[125] Batch[5] avg_epoch_loss=2.365662\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.3656618197758994\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[125] Batch [5]#011Speed: 2254.09 samples/sec#011loss=2.365662\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[125] Batch[10] avg_epoch_loss=2.243230\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=2.096311259269714\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[125] Batch [10]#011Speed: 2177.57 samples/sec#011loss=2.096311\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747844369.0239944, \"EndTime\": 1747844369.9255493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 901.3078212738037, \"count\": 1, \"min\": 901.3078212738037, \"max\": 901.3078212738037}}}\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1421.1334580186774 records/second\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 31.5 % of epochs\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.2432297468185425\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_19b92750-1c29-430d-bb51-434f2547cfca-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844369.9256067, \"EndTime\": 1747844369.9359908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.117769241333008, \"count\": 1, \"min\": 10.117769241333008, \"max\": 10.117769241333008}}}\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] Epoch[126] Batch[0] avg_epoch_loss=2.417030\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.4170303344726562\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] Epoch[126] Batch[5] avg_epoch_loss=2.414675\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.4146751165390015\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] Epoch[126] Batch [5]#011Speed: 2133.83 samples/sec#011loss=2.414675\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] Epoch[126] Batch[10] avg_epoch_loss=2.431236\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=2.451109790802002\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] Epoch[126] Batch [10]#011Speed: 2073.56 samples/sec#011loss=2.451110\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747844369.9360435, \"EndTime\": 1747844370.8768215, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.7308101654053, \"count\": 1, \"min\": 940.7308101654053, \"max\": 940.7308101654053}}}\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1421.1119381539127 records/second\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 31.75 % of epochs\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.4312363321130928\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] Epoch[127] Batch[0] avg_epoch_loss=2.418379\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.418379306793213\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] Epoch[127] Batch[5] avg_epoch_loss=2.377191\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.377190947532654\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] Epoch[127] Batch [5]#011Speed: 2134.78 samples/sec#011loss=2.377191\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] Epoch[127] Batch[10] avg_epoch_loss=2.402442\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=2.4327428340911865\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] Epoch[127] Batch [10]#011Speed: 2090.41 samples/sec#011loss=2.432743\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747844370.8768773, \"EndTime\": 1747844371.804797, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.1972179412842, \"count\": 1, \"min\": 927.1972179412842, \"max\": 927.1972179412842}}}\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.2599416245168 records/second\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 32.0 % of epochs\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.4024418050592597\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] Epoch[128] Batch[0] avg_epoch_loss=2.349715\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.349715232849121\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] Epoch[128] Batch[5] avg_epoch_loss=2.406762\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.40676216284434\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] Epoch[128] Batch [5]#011Speed: 2156.42 samples/sec#011loss=2.406762\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] Epoch[128] Batch[10] avg_epoch_loss=2.455539\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=2.5140711307525634\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] Epoch[128] Batch [10]#011Speed: 2124.96 samples/sec#011loss=2.514071\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844371.8048542, \"EndTime\": 1747844372.725425, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.3290939331055, \"count\": 1, \"min\": 920.3290939331055, \"max\": 920.3290939331055}}}\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.9331996746603 records/second\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 32.25 % of epochs\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.455538966438987\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[129] Batch[0] avg_epoch_loss=2.328143\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.328143358230591\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[129] Batch[5] avg_epoch_loss=2.427358\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.4273579518000283\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[129] Batch [5]#011Speed: 2212.77 samples/sec#011loss=2.427358\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[129] Batch[10] avg_epoch_loss=2.429665\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=2.4324339866638183\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[129] Batch [10]#011Speed: 2086.24 samples/sec#011loss=2.432434\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844372.725503, \"EndTime\": 1747844373.6418812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.118860244751, \"count\": 1, \"min\": 916.118860244751, \"max\": 916.118860244751}}}\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1436.3669791713019 records/second\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 32.5 % of epochs\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.4296652403744785\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[130] Batch[0] avg_epoch_loss=2.547657\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.547656774520874\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] Epoch[130] Batch[5] avg_epoch_loss=2.461944\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.4619439442952475\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] Epoch[130] Batch [5]#011Speed: 2193.13 samples/sec#011loss=2.461944\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] Epoch[130] Batch[10] avg_epoch_loss=2.477146\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=2.495387601852417\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] Epoch[130] Batch [10]#011Speed: 2100.79 samples/sec#011loss=2.495388\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844373.6419353, \"EndTime\": 1747844374.5580904, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.9159660339355, \"count\": 1, \"min\": 915.9159660339355, \"max\": 915.9159660339355}}}\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1474.8894722677283 records/second\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 32.75 % of epochs\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.4771456068212334\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] Epoch[131] Batch[0] avg_epoch_loss=2.453865\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.4538650512695312\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] Epoch[131] Batch[5] avg_epoch_loss=2.459543\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.459542989730835\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] Epoch[131] Batch [5]#011Speed: 2181.17 samples/sec#011loss=2.459543\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] Epoch[131] Batch[10] avg_epoch_loss=2.429714\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=2.393918180465698\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] Epoch[131] Batch [10]#011Speed: 2182.44 samples/sec#011loss=2.393918\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747844374.5581474, \"EndTime\": 1747844375.4691663, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.771369934082, \"count\": 1, \"min\": 910.771369934082, \"max\": 910.771369934082}}}\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1408.5688037133314 records/second\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 33.0 % of epochs\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.4297135309739546\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] Epoch[132] Batch[0] avg_epoch_loss=2.365893\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.3658928871154785\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] Epoch[132] Batch[5] avg_epoch_loss=2.381746\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.381745934486389\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] Epoch[132] Batch [5]#011Speed: 2215.01 samples/sec#011loss=2.381746\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] Epoch[132] Batch[10] avg_epoch_loss=2.411666\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=2.447569465637207\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] Epoch[132] Batch [10]#011Speed: 1995.39 samples/sec#011loss=2.447569\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747844375.4692218, \"EndTime\": 1747844376.4269218, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.4384689331055, \"count\": 1, \"min\": 957.4384689331055, \"max\": 957.4384689331055}}}\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.981642019378 records/second\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 33.25 % of epochs\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.4116657213731245\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] Epoch[133] Batch[0] avg_epoch_loss=2.469029\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.4690287113189697\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[133] Batch[5] avg_epoch_loss=2.397215\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.397215207417806\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[133] Batch [5]#011Speed: 2234.74 samples/sec#011loss=2.397215\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[133] Batch[10] avg_epoch_loss=2.508304\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=2.641610527038574\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[133] Batch [10]#011Speed: 2154.76 samples/sec#011loss=2.641611\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747844376.4269767, \"EndTime\": 1747844377.3364787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.8075160980225, \"count\": 1, \"min\": 908.8075160980225, \"max\": 908.8075160980225}}}\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.0209838451226 records/second\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 33.5 % of epochs\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.50830398906361\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[134] Batch[0] avg_epoch_loss=2.650060\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.650059700012207\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[134] Batch[5] avg_epoch_loss=2.730564\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.7305637200673423\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[134] Batch [5]#011Speed: 2197.51 samples/sec#011loss=2.730564\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] Epoch[134] Batch[10] avg_epoch_loss=2.793463\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.868942928314209\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] Epoch[134] Batch [10]#011Speed: 2066.22 samples/sec#011loss=2.868943\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747844377.336592, \"EndTime\": 1747844378.275621, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.7617111206055, \"count\": 1, \"min\": 938.7617111206055, \"max\": 938.7617111206055}}}\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.4073423780894 records/second\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 33.75 % of epochs\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.793463360179554\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] Epoch[135] Batch[0] avg_epoch_loss=2.774531\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.774531126022339\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] Epoch[135] Batch[5] avg_epoch_loss=2.711623\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.711622953414917\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] Epoch[135] Batch [5]#011Speed: 2069.68 samples/sec#011loss=2.711623\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] Epoch[135] Batch[10] avg_epoch_loss=2.593354\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=2.451430559158325\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] Epoch[135] Batch [10]#011Speed: 2169.49 samples/sec#011loss=2.451431\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747844378.2756808, \"EndTime\": 1747844379.2010014, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0121116638184, \"count\": 1, \"min\": 925.0121116638184, \"max\": 925.0121116638184}}}\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1421.4707447637884 records/second\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 34.0 % of epochs\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.593353683298284\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] Epoch[136] Batch[0] avg_epoch_loss=2.554748\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.554748058319092\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] Epoch[136] Batch[5] avg_epoch_loss=2.508444\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.508443911870321\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] Epoch[136] Batch [5]#011Speed: 2201.54 samples/sec#011loss=2.508444\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] Epoch[136] Batch[10] avg_epoch_loss=2.484134\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=2.4549629211425783\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] Epoch[136] Batch [10]#011Speed: 2053.47 samples/sec#011loss=2.454963\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747844379.2010598, \"EndTime\": 1747844380.1239307, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.6226806640625, \"count\": 1, \"min\": 922.6226806640625, \"max\": 922.6226806640625}}}\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1468.494796442817 records/second\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 34.25 % of epochs\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.4841343706304375\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] Epoch[137] Batch[0] avg_epoch_loss=2.371437\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.3714370727539062\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] Epoch[137] Batch[5] avg_epoch_loss=2.483833\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.4838332335154214\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] Epoch[137] Batch [5]#011Speed: 2180.20 samples/sec#011loss=2.483833\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[137] Batch[10] avg_epoch_loss=2.466566\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=2.44584584236145\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[137] Batch [10]#011Speed: 2181.58 samples/sec#011loss=2.445846\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747844380.123993, \"EndTime\": 1747844381.0340328, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.7566604614258, \"count\": 1, \"min\": 909.7566604614258, \"max\": 909.7566604614258}}}\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1420.0278678700083 records/second\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 34.5 % of epochs\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.4665662375363437\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[138] Batch[0] avg_epoch_loss=2.572862\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.572862148284912\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[138] Batch[5] avg_epoch_loss=2.456529\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.4565288623174033\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[138] Batch [5]#011Speed: 2124.23 samples/sec#011loss=2.456529\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[138] Batch[10] avg_epoch_loss=2.384054\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.2970836877822878\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[138] Batch [10]#011Speed: 2150.05 samples/sec#011loss=2.297084\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747844381.0340903, \"EndTime\": 1747844381.9606528, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.3174533843994, \"count\": 1, \"min\": 926.3174533843994, \"max\": 926.3174533843994}}}\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1384.9281443767788 records/second\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 34.75 % of epochs\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.3840537829832598\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] Epoch[139] Batch[0] avg_epoch_loss=2.294175\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.294175386428833\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] Epoch[139] Batch[5] avg_epoch_loss=2.425527\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.4255266586939492\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] Epoch[139] Batch [5]#011Speed: 2169.39 samples/sec#011loss=2.425527\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] Epoch[139] Batch[10] avg_epoch_loss=2.443351\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=2.4647404670715334\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] Epoch[139] Batch [10]#011Speed: 2022.68 samples/sec#011loss=2.464740\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747844381.9607098, \"EndTime\": 1747844382.892108, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.1282634735107, \"count\": 1, \"min\": 931.1282634735107, \"max\": 931.1282634735107}}}\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1442.2158119762064 records/second\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 35.0 % of epochs\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.4433511170473965\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] Epoch[140] Batch[0] avg_epoch_loss=2.347186\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.3471856117248535\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] Epoch[140] Batch[5] avg_epoch_loss=2.360451\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.3604511817296348\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] Epoch[140] Batch [5]#011Speed: 2189.74 samples/sec#011loss=2.360451\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747844382.8921585, \"EndTime\": 1747844383.743627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 851.2370586395264, \"count\": 1, \"min\": 851.2370586395264, \"max\": 851.2370586395264}}}\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1495.3102004352052 records/second\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 35.25 % of epochs\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.4053548336029054\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] Epoch[141] Batch[0] avg_epoch_loss=2.371131\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.3711307048797607\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] Epoch[141] Batch[5] avg_epoch_loss=2.421040\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.421039859453837\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] Epoch[141] Batch [5]#011Speed: 2110.52 samples/sec#011loss=2.421040\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] Epoch[141] Batch[10] avg_epoch_loss=2.392971\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=2.3592894077301025\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] Epoch[141] Batch [10]#011Speed: 1970.81 samples/sec#011loss=2.359289\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747844383.7436879, \"EndTime\": 1747844384.689682, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.6679821014404, \"count\": 1, \"min\": 945.6679821014404, \"max\": 945.6679821014404}}}\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1441.184974844716 records/second\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 35.5 % of epochs\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.392971472306685\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[142] Batch[0] avg_epoch_loss=2.446964\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.4469635486602783\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[142] Batch[5] avg_epoch_loss=2.346366\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.3463656504948935\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[142] Batch [5]#011Speed: 2154.14 samples/sec#011loss=2.346366\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[142] Batch[10] avg_epoch_loss=2.423116\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=2.515215349197388\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[142] Batch [10]#011Speed: 2133.13 samples/sec#011loss=2.515215\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747844384.689736, \"EndTime\": 1747844385.6100914, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.1090335845947, \"count\": 1, \"min\": 920.1090335845947, \"max\": 920.1090335845947}}}\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.217852517075 records/second\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 35.75 % of epochs\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.423115513541482\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[143] Batch[0] avg_epoch_loss=2.285443\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.28544282913208\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] Epoch[143] Batch[5] avg_epoch_loss=2.349302\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.3493016560872397\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] Epoch[143] Batch [5]#011Speed: 2199.19 samples/sec#011loss=2.349302\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] Epoch[143] Batch[10] avg_epoch_loss=2.358295\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=2.369087505340576\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] Epoch[143] Batch [10]#011Speed: 2025.78 samples/sec#011loss=2.369088\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747844385.6101494, \"EndTime\": 1747844386.5410168, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.5815696716309, \"count\": 1, \"min\": 930.5815696716309, \"max\": 930.5815696716309}}}\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1420.4888973827037 records/second\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 36.0 % of epochs\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.3582952239296655\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] Epoch[144] Batch[0] avg_epoch_loss=2.358984\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.3589842319488525\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] Epoch[144] Batch[5] avg_epoch_loss=2.312392\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.312392274538676\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] Epoch[144] Batch [5]#011Speed: 2252.80 samples/sec#011loss=2.312392\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] Epoch[144] Batch[10] avg_epoch_loss=2.324947\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=2.3400121212005613\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] Epoch[144] Batch [10]#011Speed: 2011.85 samples/sec#011loss=2.340012\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747844386.541074, \"EndTime\": 1747844387.4583712, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.0527458190918, \"count\": 1, \"min\": 917.0527458190918, \"max\": 917.0527458190918}}}\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1477.4181533267165 records/second\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 36.25 % of epochs\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.3249467502940786\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] Epoch[145] Batch[0] avg_epoch_loss=2.254450\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.2544500827789307\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Epoch[145] Batch[5] avg_epoch_loss=2.325000\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.3250003258387246\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Epoch[145] Batch [5]#011Speed: 2166.85 samples/sec#011loss=2.325000\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Epoch[145] Batch[10] avg_epoch_loss=2.219018\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=2.0918401002883913\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Epoch[145] Batch [10]#011Speed: 2096.99 samples/sec#011loss=2.091840\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747844387.4584293, \"EndTime\": 1747844388.385219, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.5437126159668, \"count\": 1, \"min\": 926.5437126159668, \"max\": 926.5437126159668}}}\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1391.0475316657785 records/second\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 36.5 % of epochs\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.219018405134028\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_58058a4e-ff5f-4df2-915b-edd635c6a423-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844388.3852844, \"EndTime\": 1747844388.3954344, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.791135787963867, \"count\": 1, \"min\": 9.791135787963867, \"max\": 9.791135787963867}}}\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Epoch[146] Batch[0] avg_epoch_loss=2.407546\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.407546043395996\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] Epoch[146] Batch[5] avg_epoch_loss=2.369877\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.3698767820994058\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] Epoch[146] Batch [5]#011Speed: 1999.56 samples/sec#011loss=2.369877\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747844388.3954928, \"EndTime\": 1747844389.279679, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 884.0987682342529, \"count\": 1, \"min\": 884.0987682342529, \"max\": 884.0987682342529}}}\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1441.9960707184393 records/second\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 36.75 % of epochs\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.343180537223816\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] Epoch[147] Batch[0] avg_epoch_loss=2.315478\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=2.3154780864715576\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] Epoch[147] Batch[5] avg_epoch_loss=2.337687\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=2.337686816851298\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] Epoch[147] Batch [5]#011Speed: 2150.44 samples/sec#011loss=2.337687\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747844389.2797408, \"EndTime\": 1747844390.138001, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 857.9027652740479, \"count\": 1, \"min\": 857.9027652740479, \"max\": 857.9027652740479}}}\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1491.854273314508 records/second\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 37.0 % of epochs\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.355016088485718\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] Epoch[148] Batch[0] avg_epoch_loss=2.266876\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.266876459121704\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] Epoch[148] Batch[5] avg_epoch_loss=2.318702\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.31870174407959\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] Epoch[148] Batch [5]#011Speed: 2155.68 samples/sec#011loss=2.318702\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[148] Batch[10] avg_epoch_loss=2.435118\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=2.5748181343078613\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[148] Batch [10]#011Speed: 2077.20 samples/sec#011loss=2.574818\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747844390.1380603, \"EndTime\": 1747844391.066178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.8314113616943, \"count\": 1, \"min\": 927.8314113616943, \"max\": 927.8314113616943}}}\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1447.3325530909547 records/second\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 37.25 % of epochs\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.4351182850924404\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[149] Batch[0] avg_epoch_loss=2.403487\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.403486967086792\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[149] Batch[5] avg_epoch_loss=2.398267\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.398266832033793\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[149] Batch [5]#011Speed: 2213.14 samples/sec#011loss=2.398267\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[149] Batch[10] avg_epoch_loss=2.329826\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=2.247696280479431\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[149] Batch [10]#011Speed: 2200.67 samples/sec#011loss=2.247696\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747844391.0662334, \"EndTime\": 1747844391.9726436, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.1710834503174, \"count\": 1, \"min\": 906.1710834503174, \"max\": 906.1710834503174}}}\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1416.8201313932675 records/second\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 37.5 % of epochs\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.329825672236356\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] Epoch[150] Batch[0] avg_epoch_loss=2.217197\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.2171974182128906\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] Epoch[150] Batch[5] avg_epoch_loss=2.317984\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.317983786265055\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] Epoch[150] Batch [5]#011Speed: 2168.89 samples/sec#011loss=2.317984\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] Epoch[150] Batch[10] avg_epoch_loss=2.377537\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=2.448999834060669\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] Epoch[150] Batch [10]#011Speed: 2046.51 samples/sec#011loss=2.449000\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747844391.9726996, \"EndTime\": 1747844392.9014053, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.4634590148926, \"count\": 1, \"min\": 928.4634590148926, \"max\": 928.4634590148926}}}\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1450.62203567778 records/second\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 37.75 % of epochs\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.3775365352630615\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] Epoch[151] Batch[0] avg_epoch_loss=2.441972\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.44197154045105\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] Epoch[151] Batch[5] avg_epoch_loss=2.314077\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.314076542854309\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] Epoch[151] Batch [5]#011Speed: 2141.88 samples/sec#011loss=2.314077\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] Epoch[151] Batch[10] avg_epoch_loss=2.333195\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=2.3561376571655273\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] Epoch[151] Batch [10]#011Speed: 1978.83 samples/sec#011loss=2.356138\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747844392.9014828, \"EndTime\": 1747844393.843166, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.4339065551758, \"count\": 1, \"min\": 941.4339065551758, \"max\": 941.4339065551758}}}\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1439.1706250547606 records/second\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 38.0 % of epochs\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.3331952311775903\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] Epoch[152] Batch[0] avg_epoch_loss=2.293791\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.2937912940979004\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] Epoch[152] Batch[5] avg_epoch_loss=2.350782\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.350781520207723\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] Epoch[152] Batch [5]#011Speed: 2168.28 samples/sec#011loss=2.350782\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] Epoch[152] Batch[10] avg_epoch_loss=2.325568\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=2.2953118801116945\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] Epoch[152] Batch [10]#011Speed: 2053.05 samples/sec#011loss=2.295312\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747844393.843221, \"EndTime\": 1747844394.7661674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.6915836334229, \"count\": 1, \"min\": 922.6915836334229, \"max\": 922.6915836334229}}}\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.7392681698614 records/second\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 38.25 % of epochs\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.325568047436801\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] Epoch[153] Batch[0] avg_epoch_loss=2.324811\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.324810743331909\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] Epoch[153] Batch[5] avg_epoch_loss=2.302463\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.302462895711263\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] Epoch[153] Batch [5]#011Speed: 2127.35 samples/sec#011loss=2.302463\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] Epoch[153] Batch[10] avg_epoch_loss=2.375377\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=2.4628739833831785\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] Epoch[153] Batch [10]#011Speed: 2121.47 samples/sec#011loss=2.462874\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844394.7662199, \"EndTime\": 1747844395.6919198, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.4100322723389, \"count\": 1, \"min\": 925.4100322723389, \"max\": 925.4100322723389}}}\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1401.413076648621 records/second\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 38.5 % of epochs\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.3753770264712246\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[154] Batch[0] avg_epoch_loss=2.229473\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.229473352432251\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[154] Batch[5] avg_epoch_loss=2.354401\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.3544007539749146\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[154] Batch [5]#011Speed: 2189.82 samples/sec#011loss=2.354401\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[154] Batch[10] avg_epoch_loss=2.326115\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=2.292171812057495\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[154] Batch [10]#011Speed: 1955.53 samples/sec#011loss=2.292172\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747844395.6919768, \"EndTime\": 1747844396.6313827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.1193389892578, \"count\": 1, \"min\": 939.1193389892578, \"max\": 939.1193389892578}}}\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1445.8873054377416 records/second\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 38.75 % of epochs\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.3261148712851782\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[155] Batch[0] avg_epoch_loss=2.332606\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.332606077194214\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] Epoch[155] Batch[5] avg_epoch_loss=2.313935\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.3139353593190513\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] Epoch[155] Batch [5]#011Speed: 2183.25 samples/sec#011loss=2.313935\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] Epoch[155] Batch[10] avg_epoch_loss=2.366865\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=2.430380344390869\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] Epoch[155] Batch [10]#011Speed: 1946.59 samples/sec#011loss=2.430380\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844396.631449, \"EndTime\": 1747844397.573259, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.5557384490967, \"count\": 1, \"min\": 941.5557384490967, \"max\": 941.5557384490967}}}\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.7277776891597 records/second\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 39.0 % of epochs\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.366864897988059\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] Epoch[156] Batch[0] avg_epoch_loss=2.257180\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.2571797370910645\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] Epoch[156] Batch[5] avg_epoch_loss=2.301977\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.3019769191741943\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] Epoch[156] Batch [5]#011Speed: 2219.14 samples/sec#011loss=2.301977\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] Epoch[156] Batch[10] avg_epoch_loss=2.288552\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=2.2724430084228517\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] Epoch[156] Batch [10]#011Speed: 2092.72 samples/sec#011loss=2.272443\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844397.5733168, \"EndTime\": 1747844398.4893532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.7545566558838, \"count\": 1, \"min\": 915.7545566558838, \"max\": 915.7545566558838}}}\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1436.9375926933012 records/second\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 39.25 % of epochs\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.2885524142872202\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] Epoch[157] Batch[0] avg_epoch_loss=2.256745\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.256744861602783\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] Epoch[157] Batch[5] avg_epoch_loss=2.297895\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.297894597053528\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] Epoch[157] Batch [5]#011Speed: 2165.05 samples/sec#011loss=2.297895\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] Epoch[157] Batch[10] avg_epoch_loss=2.368222\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=2.452614974975586\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] Epoch[157] Batch [10]#011Speed: 2140.56 samples/sec#011loss=2.452615\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747844398.489408, \"EndTime\": 1747844399.4057562, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.0046577453613, \"count\": 1, \"min\": 916.0046577453613, \"max\": 916.0046577453613}}}\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.0723111749376 records/second\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 39.5 % of epochs\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.368222041563554\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] Epoch[158] Batch[0] avg_epoch_loss=2.303841\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.3038413524627686\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] Epoch[158] Batch[5] avg_epoch_loss=2.329891\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.3298914432525635\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] Epoch[158] Batch [5]#011Speed: 1943.29 samples/sec#011loss=2.329891\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] Epoch[158] Batch[10] avg_epoch_loss=2.315077\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=2.2972986698150635\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] Epoch[158] Batch [10]#011Speed: 2022.37 samples/sec#011loss=2.297299\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747844399.405815, \"EndTime\": 1747844400.3730314, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 966.963529586792, \"count\": 1, \"min\": 966.963529586792, \"max\": 966.963529586792}}}\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1393.9326337111518 records/second\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 39.75 % of epochs\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.315076546235518\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] Epoch[159] Batch[0] avg_epoch_loss=2.270633\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.2706334590911865\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] Epoch[159] Batch[5] avg_epoch_loss=2.261721\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.26172137260437\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] Epoch[159] Batch [5]#011Speed: 2126.55 samples/sec#011loss=2.261721\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747844400.373087, \"EndTime\": 1747844401.3119347, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.5759830474854, \"count\": 1, \"min\": 938.5759830474854, \"max\": 938.5759830474854}}}\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1348.668958477418 records/second\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 40.0 % of epochs\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.2646661043167113\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] Epoch[160] Batch[0] avg_epoch_loss=2.348164\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.3481638431549072\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] Epoch[160] Batch[5] avg_epoch_loss=2.294722\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.2947216828664145\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] Epoch[160] Batch [5]#011Speed: 2083.61 samples/sec#011loss=2.294722\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] Epoch[160] Batch[10] avg_epoch_loss=2.336715\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=2.387107276916504\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] Epoch[160] Batch [10]#011Speed: 1928.41 samples/sec#011loss=2.387107\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747844401.3120098, \"EndTime\": 1747844402.275074, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 962.7559185028076, \"count\": 1, \"min\": 962.7559185028076, \"max\": 962.7559185028076}}}\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1398.9751302223908 records/second\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 40.25 % of epochs\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.3367151347073642\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] Epoch[161] Batch[0] avg_epoch_loss=2.268247\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.268247365951538\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] Epoch[161] Batch[5] avg_epoch_loss=2.298446\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.2984460592269897\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] Epoch[161] Batch [5]#011Speed: 2100.87 samples/sec#011loss=2.298446\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] Epoch[161] Batch[10] avg_epoch_loss=2.327358\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=2.3620516777038576\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] Epoch[161] Batch [10]#011Speed: 2046.85 samples/sec#011loss=2.362052\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747844402.2751353, \"EndTime\": 1747844403.213976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.4911060333252, \"count\": 1, \"min\": 938.4911060333252, \"max\": 938.4911060333252}}}\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.1368771533746 records/second\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 40.5 % of epochs\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.327357703989202\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] Epoch[162] Batch[0] avg_epoch_loss=2.417369\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.4173688888549805\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] Epoch[162] Batch[5] avg_epoch_loss=2.295865\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.295864741007487\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] Epoch[162] Batch [5]#011Speed: 2180.73 samples/sec#011loss=2.295865\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] Epoch[162] Batch[10] avg_epoch_loss=2.248915\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=2.1925751209259032\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] Epoch[162] Batch [10]#011Speed: 2114.07 samples/sec#011loss=2.192575\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747844403.2140713, \"EndTime\": 1747844404.1330788, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.7510013580322, \"count\": 1, \"min\": 918.7510013580322, \"max\": 918.7510013580322}}}\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.071521798585 records/second\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 40.75 % of epochs\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.2489149136976763\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] Epoch[163] Batch[0] avg_epoch_loss=2.490334\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.4903335571289062\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] Epoch[163] Batch[5] avg_epoch_loss=2.364074\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.364073872566223\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] Epoch[163] Batch [5]#011Speed: 2198.75 samples/sec#011loss=2.364074\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[163] Batch[10] avg_epoch_loss=2.368072\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=2.372869110107422\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[163] Batch [10]#011Speed: 2126.06 samples/sec#011loss=2.372869\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844404.1331353, \"EndTime\": 1747844405.0415404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.1623554229736, \"count\": 1, \"min\": 908.1623554229736, \"max\": 908.1623554229736}}}\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1476.472555289347 records/second\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 41.0 % of epochs\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.3680717078122226\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[164] Batch[0] avg_epoch_loss=2.546010\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.5460095405578613\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[164] Batch[5] avg_epoch_loss=2.472324\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.4723244508107505\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[164] Batch [5]#011Speed: 2164.59 samples/sec#011loss=2.472324\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[164] Batch[10] avg_epoch_loss=2.455597\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=2.4355239868164062\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[164] Batch [10]#011Speed: 2062.03 samples/sec#011loss=2.435524\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747844405.0415957, \"EndTime\": 1747844405.9799225, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.0800724029541, \"count\": 1, \"min\": 938.0800724029541, \"max\": 938.0800724029541}}}\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1388.8893267905605 records/second\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 41.25 % of epochs\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.4555969671769575\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] Epoch[165] Batch[0] avg_epoch_loss=2.422015\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.4220149517059326\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] Epoch[165] Batch[5] avg_epoch_loss=2.470610\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.4706103404363\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] Epoch[165] Batch [5]#011Speed: 2063.80 samples/sec#011loss=2.470610\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] processed a total of 1243 examples\n",
      "#metrics {\"StartTime\": 1747844405.9799762, \"EndTime\": 1747844406.8497722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 869.5247173309326, \"count\": 1, \"min\": 869.5247173309326, \"max\": 869.5247173309326}}}\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.3637298039914 records/second\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 41.5 % of epochs\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.471579337120056\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] Epoch[166] Batch[0] avg_epoch_loss=2.445377\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.4453771114349365\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] Epoch[166] Batch[5] avg_epoch_loss=2.368198\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.3681981960932412\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] Epoch[166] Batch [5]#011Speed: 2152.76 samples/sec#011loss=2.368198\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] Epoch[166] Batch[10] avg_epoch_loss=2.393544\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=2.423958921432495\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] Epoch[166] Batch [10]#011Speed: 2101.31 samples/sec#011loss=2.423959\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747844406.8498352, \"EndTime\": 1747844407.7766635, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.511287689209, \"count\": 1, \"min\": 926.511287689209, \"max\": 926.511287689209}}}\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1387.8764467995377 records/second\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 41.75 % of epochs\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.393543980338357\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] Epoch[167] Batch[0] avg_epoch_loss=2.402444\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=2.4024436473846436\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] Epoch[167] Batch[5] avg_epoch_loss=2.433686\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.4336864153544107\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] Epoch[167] Batch [5]#011Speed: 2198.49 samples/sec#011loss=2.433686\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] Epoch[167] Batch[10] avg_epoch_loss=2.402691\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=2.365496015548706\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] Epoch[167] Batch [10]#011Speed: 2038.39 samples/sec#011loss=2.365496\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747844407.77672, \"EndTime\": 1747844408.7033606, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.393985748291, \"count\": 1, \"min\": 926.393985748291, \"max\": 926.393985748291}}}\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1476.541902332412 records/second\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 42.0 % of epochs\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.4026907790790903\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[168] Batch[0] avg_epoch_loss=2.250059\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.250058889389038\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[168] Batch[5] avg_epoch_loss=2.301390\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.301389733950297\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[168] Batch [5]#011Speed: 2162.45 samples/sec#011loss=2.301390\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[168] Batch[10] avg_epoch_loss=2.328149\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=2.3602608680725097\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[168] Batch [10]#011Speed: 2164.56 samples/sec#011loss=2.360261\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844408.7034278, \"EndTime\": 1747844409.619222, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.5449867248535, \"count\": 1, \"min\": 915.5449867248535, \"max\": 915.5449867248535}}}\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.6177238578616 records/second\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 42.25 % of epochs\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.328149340369485\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[169] Batch[0] avg_epoch_loss=2.277385\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.2773852348327637\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] Epoch[169] Batch[5] avg_epoch_loss=2.311664\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.311663786570231\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] Epoch[169] Batch [5]#011Speed: 2043.26 samples/sec#011loss=2.311664\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] Epoch[169] Batch[10] avg_epoch_loss=2.322823\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.336214208602905\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] Epoch[169] Batch [10]#011Speed: 2060.90 samples/sec#011loss=2.336214\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844409.6192791, \"EndTime\": 1747844410.5623326, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.795991897583, \"count\": 1, \"min\": 942.795991897583, \"max\": 942.795991897583}}}\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.724105512347 records/second\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 42.5 % of epochs\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.322823069312356\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] Epoch[170] Batch[0] avg_epoch_loss=2.279757\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.279756784439087\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] Epoch[170] Batch[5] avg_epoch_loss=2.341592\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.341592232386271\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] Epoch[170] Batch [5]#011Speed: 2140.87 samples/sec#011loss=2.341592\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] Epoch[170] Batch[10] avg_epoch_loss=2.362781\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=2.38820858001709\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] Epoch[170] Batch [10]#011Speed: 2138.32 samples/sec#011loss=2.388209\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844410.562388, \"EndTime\": 1747844411.4839475, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.3221073150635, \"count\": 1, \"min\": 921.3221073150635, \"max\": 921.3221073150635}}}\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.418887836908 records/second\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 42.75 % of epochs\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.3627814813093706\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] Epoch[171] Batch[0] avg_epoch_loss=2.455422\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.4554216861724854\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Epoch[171] Batch[5] avg_epoch_loss=2.319022\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.319022297859192\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Epoch[171] Batch [5]#011Speed: 2234.25 samples/sec#011loss=2.319022\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Epoch[171] Batch[10] avg_epoch_loss=2.208417\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=2.0756905555725096\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Epoch[171] Batch [10]#011Speed: 1956.61 samples/sec#011loss=2.075691\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844411.484006, \"EndTime\": 1747844412.4186308, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.3786239624023, \"count\": 1, \"min\": 934.3786239624023, \"max\": 934.3786239624023}}}\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1380.4768883464033 records/second\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 43.0 % of epochs\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.2084169604561548\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_c377c09f-74f6-427d-a3d8-1176f9e2b2f7-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844412.418684, \"EndTime\": 1747844412.4296396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.692596435546875, \"count\": 1, \"min\": 10.692596435546875, \"max\": 10.692596435546875}}}\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Epoch[172] Batch[0] avg_epoch_loss=2.423239\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.423238515853882\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[172] Batch[5] avg_epoch_loss=2.288428\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.28842830657959\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[172] Batch [5]#011Speed: 2173.64 samples/sec#011loss=2.288428\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[172] Batch[10] avg_epoch_loss=2.252656\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=2.2097291469573976\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[172] Batch [10]#011Speed: 2157.01 samples/sec#011loss=2.209729\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844412.429689, \"EndTime\": 1747844413.3483365, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.6022281646729, \"count\": 1, \"min\": 918.6022281646729, \"max\": 918.6022281646729}}}\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1442.2815933720142 records/second\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 43.25 % of epochs\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.252655961296775\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[173] Batch[0] avg_epoch_loss=2.274303\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.274303436279297\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[173] Batch[5] avg_epoch_loss=2.435970\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.4359697898228965\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[173] Batch [5]#011Speed: 2131.28 samples/sec#011loss=2.435970\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] Epoch[173] Batch[10] avg_epoch_loss=2.412766\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=2.3849222660064697\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] Epoch[173] Batch [10]#011Speed: 1968.69 samples/sec#011loss=2.384922\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747844413.3483922, \"EndTime\": 1747844414.2910674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.4035549163818, \"count\": 1, \"min\": 942.4035549163818, \"max\": 942.4035549163818}}}\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1451.4781698013119 records/second\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 43.5 % of epochs\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.412766369906339\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] Epoch[174] Batch[0] avg_epoch_loss=2.412391\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.412391424179077\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] Epoch[174] Batch[5] avg_epoch_loss=2.328897\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.3288971980412803\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] Epoch[174] Batch [5]#011Speed: 2208.13 samples/sec#011loss=2.328897\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] Epoch[174] Batch[10] avg_epoch_loss=2.325103\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=2.320550060272217\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] Epoch[174] Batch [10]#011Speed: 2099.86 samples/sec#011loss=2.320550\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844414.2911232, \"EndTime\": 1747844415.207856, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.4464473724365, \"count\": 1, \"min\": 916.4464473724365, \"max\": 916.4464473724365}}}\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.8543372539634 records/second\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 43.75 % of epochs\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.3251030445098877\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] Epoch[175] Batch[0] avg_epoch_loss=2.355162\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.3551623821258545\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] Epoch[175] Batch[5] avg_epoch_loss=2.288846\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.288846492767334\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] Epoch[175] Batch [5]#011Speed: 2135.10 samples/sec#011loss=2.288846\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] Epoch[175] Batch[10] avg_epoch_loss=2.267757\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=2.242449426651001\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] Epoch[175] Batch [10]#011Speed: 2037.06 samples/sec#011loss=2.242449\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844415.2079103, \"EndTime\": 1747844416.145288, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.1261596679688, \"count\": 1, \"min\": 937.1261596679688, \"max\": 937.1261596679688}}}\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1383.8974452903838 records/second\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 44.0 % of epochs\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.2677569172599097\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] Epoch[176] Batch[0] avg_epoch_loss=2.343240\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.3432400226593018\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] Epoch[176] Batch[5] avg_epoch_loss=2.339534\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.3395336469014487\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] Epoch[176] Batch [5]#011Speed: 2152.74 samples/sec#011loss=2.339534\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] Epoch[176] Batch[10] avg_epoch_loss=2.473007\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.6331750392913817\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] Epoch[176] Batch [10]#011Speed: 2017.31 samples/sec#011loss=2.633175\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844416.145343, \"EndTime\": 1747844417.0779521, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.3413372039795, \"count\": 1, \"min\": 932.3413372039795, \"max\": 932.3413372039795}}}\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1414.5905905967334 records/second\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 44.25 % of epochs\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.473007007078691\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] Epoch[177] Batch[0] avg_epoch_loss=2.520688\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.520688056945801\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] Epoch[177] Batch[5] avg_epoch_loss=2.420799\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.420799136161804\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] Epoch[177] Batch [5]#011Speed: 2152.58 samples/sec#011loss=2.420799\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[177] Batch[10] avg_epoch_loss=2.454213\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=2.494310140609741\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[177] Batch [10]#011Speed: 2097.58 samples/sec#011loss=2.494310\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747844417.0780098, \"EndTime\": 1747844418.0019827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.7310886383057, \"count\": 1, \"min\": 923.7310886383057, \"max\": 923.7310886383057}}}\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1458.084121317418 records/second\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 44.5 % of epochs\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.4542132290926846\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[178] Batch[0] avg_epoch_loss=2.285871\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.2858712673187256\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[178] Batch[5] avg_epoch_loss=2.399009\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.3990089098612466\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[178] Batch [5]#011Speed: 2196.35 samples/sec#011loss=2.399009\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[178] Batch[10] avg_epoch_loss=2.385001\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=2.368190574645996\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[178] Batch [10]#011Speed: 2059.27 samples/sec#011loss=2.368191\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747844418.002038, \"EndTime\": 1747844418.920888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.6029434204102, \"count\": 1, \"min\": 918.6029434204102, \"max\": 918.6029434204102}}}\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1469.4933095265283 records/second\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 44.75 % of epochs\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.3850005756724966\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] Epoch[179] Batch[0] avg_epoch_loss=2.387969\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.3879690170288086\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] Epoch[179] Batch[5] avg_epoch_loss=2.327167\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.3271666367848716\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] Epoch[179] Batch [5]#011Speed: 2110.40 samples/sec#011loss=2.327167\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] Epoch[179] Batch[10] avg_epoch_loss=2.285501\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=2.235502338409424\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] Epoch[179] Batch [10]#011Speed: 2098.74 samples/sec#011loss=2.235502\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747844418.9209416, \"EndTime\": 1747844419.8644176, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.2005882263184, \"count\": 1, \"min\": 943.2005882263184, \"max\": 943.2005882263184}}}\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1405.7303712885239 records/second\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 45.0 % of epochs\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.2855010466142134\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] Epoch[180] Batch[0] avg_epoch_loss=2.285327\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.285327196121216\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] Epoch[180] Batch[5] avg_epoch_loss=2.257989\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.2579893271128335\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] Epoch[180] Batch [5]#011Speed: 2180.65 samples/sec#011loss=2.257989\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] Epoch[180] Batch[10] avg_epoch_loss=2.232889\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=2.202767753601074\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] Epoch[180] Batch [10]#011Speed: 2046.98 samples/sec#011loss=2.202768\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747844419.8644726, \"EndTime\": 1747844420.7927008, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.912712097168, \"count\": 1, \"min\": 927.912712097168, \"max\": 927.912712097168}}}\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.9591419795145 records/second\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 45.25 % of epochs\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.232888611880216\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Epoch[181] Batch[0] avg_epoch_loss=2.269516\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.2695159912109375\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Epoch[181] Batch[5] avg_epoch_loss=2.252482\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.252481738726298\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Epoch[181] Batch [5]#011Speed: 2136.08 samples/sec#011loss=2.252482\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Epoch[181] Batch[10] avg_epoch_loss=2.162564\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=2.0546637535095216\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Epoch[181] Batch [10]#011Speed: 2048.83 samples/sec#011loss=2.054664\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747844420.7927585, \"EndTime\": 1747844421.7297697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.6779327392578, \"count\": 1, \"min\": 936.6779327392578, \"max\": 936.6779327392578}}}\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1389.8950456877494 records/second\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 45.5 % of epochs\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.1625644727186724\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_69947841-16bd-485e-b2cb-db9d973de1c1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844421.729826, \"EndTime\": 1747844421.7406147, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.52403450012207, \"count\": 1, \"min\": 10.52403450012207, \"max\": 10.52403450012207}}}\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] Epoch[182] Batch[0] avg_epoch_loss=2.342083\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.3420827388763428\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] Epoch[182] Batch[5] avg_epoch_loss=2.263306\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.263305902481079\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] Epoch[182] Batch [5]#011Speed: 2153.57 samples/sec#011loss=2.263306\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] processed a total of 1269 examples\n",
      "#metrics {\"StartTime\": 1747844421.740667, \"EndTime\": 1747844422.6060226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 865.3059005737305, \"count\": 1, \"min\": 865.3059005737305, \"max\": 865.3059005737305}}}\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1466.3855182297707 records/second\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 45.75 % of epochs\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.2542507886886596\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] Epoch[183] Batch[0] avg_epoch_loss=2.207478\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.2074780464172363\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] Epoch[183] Batch[5] avg_epoch_loss=2.225078\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.225078026453654\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] Epoch[183] Batch [5]#011Speed: 2141.97 samples/sec#011loss=2.225078\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] Epoch[183] Batch[10] avg_epoch_loss=2.203507\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=2.177621006965637\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] Epoch[183] Batch [10]#011Speed: 2105.50 samples/sec#011loss=2.177621\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747844422.6060817, \"EndTime\": 1747844423.5309718, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.5550632476807, \"count\": 1, \"min\": 924.5550632476807, \"max\": 924.5550632476807}}}\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1448.1308847198536 records/second\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 46.0 % of epochs\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.203506653959101\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] Epoch[184] Batch[0] avg_epoch_loss=2.186476\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.186475992202759\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] Epoch[184] Batch[5] avg_epoch_loss=2.207302\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.2073023319244385\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] Epoch[184] Batch [5]#011Speed: 2026.23 samples/sec#011loss=2.207302\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] Epoch[184] Batch[10] avg_epoch_loss=2.219013\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=2.2330652713775634\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] Epoch[184] Batch [10]#011Speed: 2034.63 samples/sec#011loss=2.233065\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844423.5310276, \"EndTime\": 1747844424.4793487, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.0772018432617, \"count\": 1, \"min\": 948.0772018432617, \"max\": 948.0772018432617}}}\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1395.332815841584 records/second\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 46.25 % of epochs\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.2190127589485864\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] Epoch[185] Batch[0] avg_epoch_loss=2.237939\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.23793888092041\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] Epoch[185] Batch[5] avg_epoch_loss=2.235370\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.2353699604670205\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] Epoch[185] Batch [5]#011Speed: 2079.39 samples/sec#011loss=2.235370\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] Epoch[185] Batch[10] avg_epoch_loss=2.243000\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=2.2521552562713625\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] Epoch[185] Batch [10]#011Speed: 2066.28 samples/sec#011loss=2.252155\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747844424.4794044, \"EndTime\": 1747844425.4211507, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.4966106414795, \"count\": 1, \"min\": 941.4966106414795, \"max\": 941.4966106414795}}}\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1456.0616497652609 records/second\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 46.5 % of epochs\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.242999640378085\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] Epoch[186] Batch[0] avg_epoch_loss=2.120279\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.12027907371521\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[186] Batch[5] avg_epoch_loss=2.220194\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.2201935847600303\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[186] Batch [5]#011Speed: 2151.71 samples/sec#011loss=2.220194\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[186] Batch[10] avg_epoch_loss=2.201114\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=2.178218698501587\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[186] Batch [10]#011Speed: 1977.49 samples/sec#011loss=2.178219\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] processed a total of 1396 examples\n",
      "#metrics {\"StartTime\": 1747844425.4212084, \"EndTime\": 1747844426.3611608, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.6605491638184, \"count\": 1, \"min\": 939.6605491638184, \"max\": 939.6605491638184}}}\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1485.5139695816179 records/second\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 46.75 % of epochs\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.2011140910061924\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[187] Batch[0] avg_epoch_loss=2.181596\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.18159556388855\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[187] Batch[5] avg_epoch_loss=2.202896\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.2028964360555015\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[187] Batch [5]#011Speed: 2093.34 samples/sec#011loss=2.202896\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] Epoch[187] Batch[10] avg_epoch_loss=2.198268\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=2.192714214324951\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] Epoch[187] Batch [10]#011Speed: 1876.23 samples/sec#011loss=2.192714\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747844426.361216, \"EndTime\": 1747844427.3292959, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 967.808723449707, \"count\": 1, \"min\": 967.808723449707, \"max\": 967.808723449707}}}\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1412.3018371753044 records/second\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 47.0 % of epochs\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.1982681534507056\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] Epoch[188] Batch[0] avg_epoch_loss=2.134347\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.134347438812256\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] Epoch[188] Batch[5] avg_epoch_loss=2.201319\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.2013185818990073\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] Epoch[188] Batch [5]#011Speed: 2173.74 samples/sec#011loss=2.201319\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] Epoch[188] Batch[10] avg_epoch_loss=2.239240\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=2.2847452640533445\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] Epoch[188] Batch [10]#011Speed: 1993.00 samples/sec#011loss=2.284745\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747844427.32935, \"EndTime\": 1747844428.2648692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.7455501556396, \"count\": 1, \"min\": 934.7455501556396, \"max\": 934.7455501556396}}}\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1444.1103319384397 records/second\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 47.25 % of epochs\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.23923980106007\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] Epoch[189] Batch[0] avg_epoch_loss=2.231008\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.2310078144073486\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] Epoch[189] Batch[5] avg_epoch_loss=2.198471\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.1984713474909463\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] Epoch[189] Batch [5]#011Speed: 2206.14 samples/sec#011loss=2.198471\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] Epoch[189] Batch[10] avg_epoch_loss=2.192304\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=2.1849036693572996\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] Epoch[189] Batch [10]#011Speed: 2153.05 samples/sec#011loss=2.184904\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844428.2649262, \"EndTime\": 1747844429.1908998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.6927967071533, \"count\": 1, \"min\": 925.6927967071533, \"max\": 925.6927967071533}}}\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1400.984675734588 records/second\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 47.5 % of epochs\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.1923042210665615\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] Epoch[190] Batch[0] avg_epoch_loss=2.222224\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.222224235534668\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] Epoch[190] Batch[5] avg_epoch_loss=2.192694\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.1926939884821572\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] Epoch[190] Batch [5]#011Speed: 2186.13 samples/sec#011loss=2.192694\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Epoch[190] Batch[10] avg_epoch_loss=2.120107\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=2.0330026865005495\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Epoch[190] Batch [10]#011Speed: 2121.16 samples/sec#011loss=2.033003\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747844429.1909564, \"EndTime\": 1747844430.1104863, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.2402362823486, \"count\": 1, \"min\": 919.2402362823486, \"max\": 919.2402362823486}}}\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1409.7297911865078 records/second\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 47.75 % of epochs\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.1201070330359717\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_f10aef95-1b23-4b6b-ae15-f314e8bd0b9a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844430.1105444, \"EndTime\": 1747844430.1209936, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.189056396484375, \"count\": 1, \"min\": 10.189056396484375, \"max\": 10.189056396484375}}}\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Epoch[191] Batch[0] avg_epoch_loss=2.220549\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.2205488681793213\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Epoch[191] Batch[5] avg_epoch_loss=2.166945\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.166945219039917\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Epoch[191] Batch [5]#011Speed: 2116.54 samples/sec#011loss=2.166945\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] Epoch[191] Batch[10] avg_epoch_loss=2.239659\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=2.326914930343628\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] Epoch[191] Batch [10]#011Speed: 2005.91 samples/sec#011loss=2.326915\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747844430.1210454, \"EndTime\": 1747844431.0632734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.1792030334473, \"count\": 1, \"min\": 942.1792030334473, \"max\": 942.1792030334473}}}\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1379.6560395998017 records/second\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 48.0 % of epochs\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.2396587241779673\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] Epoch[192] Batch[0] avg_epoch_loss=2.204095\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.204094886779785\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] Epoch[192] Batch[5] avg_epoch_loss=2.289934\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.289934237798055\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] Epoch[192] Batch [5]#011Speed: 2114.91 samples/sec#011loss=2.289934\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[192] Batch[10] avg_epoch_loss=2.290091\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=2.2902793407440187\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[192] Batch [10]#011Speed: 2029.04 samples/sec#011loss=2.290279\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747844431.0633307, \"EndTime\": 1747844432.0119772, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.3954906463623, \"count\": 1, \"min\": 948.3954906463623, \"max\": 948.3954906463623}}}\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1375.8888986085178 records/second\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 48.25 % of epochs\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.290091102773493\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[193] Batch[0] avg_epoch_loss=2.268916\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.268916130065918\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[193] Batch[5] avg_epoch_loss=2.276996\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.2769957780838013\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[193] Batch [5]#011Speed: 2207.21 samples/sec#011loss=2.276996\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[193] Batch[10] avg_epoch_loss=2.300075\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=2.3277692794799805\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[193] Batch [10]#011Speed: 2077.67 samples/sec#011loss=2.327769\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747844432.012033, \"EndTime\": 1747844432.9281142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.8389568328857, \"count\": 1, \"min\": 915.8389568328857, \"max\": 915.8389568328857}}}\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.5413621985426 records/second\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 48.5 % of epochs\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.300074642354792\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] Epoch[194] Batch[0] avg_epoch_loss=2.224495\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.2244949340820312\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] Epoch[194] Batch[5] avg_epoch_loss=2.224732\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.2247315645217896\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] Epoch[194] Batch [5]#011Speed: 2222.23 samples/sec#011loss=2.224732\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] Epoch[194] Batch[10] avg_epoch_loss=2.236438\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=2.250484800338745\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] Epoch[194] Batch [10]#011Speed: 1968.68 samples/sec#011loss=2.250485\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] processed a total of 1375 examples\n",
      "#metrics {\"StartTime\": 1747844432.9281726, \"EndTime\": 1747844433.8730626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.6396827697754, \"count\": 1, \"min\": 944.6396827697754, \"max\": 944.6396827697754}}}\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1455.443330720493 records/second\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 48.75 % of epochs\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.236437580802224\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] Epoch[195] Batch[0] avg_epoch_loss=2.223054\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.2230544090270996\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] Epoch[195] Batch[5] avg_epoch_loss=2.230622\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.2306220531463623\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] Epoch[195] Batch [5]#011Speed: 2103.79 samples/sec#011loss=2.230622\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] Epoch[195] Batch[10] avg_epoch_loss=2.266708\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=2.3100100994110107\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] Epoch[195] Batch [10]#011Speed: 1969.83 samples/sec#011loss=2.310010\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844433.873123, \"EndTime\": 1747844434.8271701, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.7491798400879, \"count\": 1, \"min\": 953.7491798400879, \"max\": 953.7491798400879}}}\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1387.034066552369 records/second\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 49.0 % of epochs\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.2667075287212026\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] Epoch[196] Batch[0] avg_epoch_loss=2.114752\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.1147522926330566\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] Epoch[196] Batch[5] avg_epoch_loss=2.188905\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.1889049212137857\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] Epoch[196] Batch [5]#011Speed: 2096.74 samples/sec#011loss=2.188905\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] Epoch[196] Batch[10] avg_epoch_loss=2.151026\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.105570578575134\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] Epoch[196] Batch [10]#011Speed: 2044.90 samples/sec#011loss=2.105571\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747844434.8272238, \"EndTime\": 1747844435.7681081, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.5581951141357, \"count\": 1, \"min\": 940.5581951141357, \"max\": 940.5581951141357}}}\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1412.8324235463367 records/second\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 49.25 % of epochs\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.1510256745598535\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] Epoch[197] Batch[0] avg_epoch_loss=2.218790\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.218790292739868\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] Epoch[197] Batch[5] avg_epoch_loss=2.181632\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.181632320086161\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] Epoch[197] Batch [5]#011Speed: 2021.55 samples/sec#011loss=2.181632\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747844435.7681856, \"EndTime\": 1747844436.6559618, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 887.4204158782959, \"count\": 1, \"min\": 887.4204158782959, \"max\": 887.4204158782959}}}\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.4759130248606 records/second\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 49.5 % of epochs\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.1750035524368285\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] Epoch[198] Batch[0] avg_epoch_loss=2.191280\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.1912803649902344\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] Epoch[198] Batch[5] avg_epoch_loss=2.165895\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.1658952236175537\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] Epoch[198] Batch [5]#011Speed: 2190.92 samples/sec#011loss=2.165895\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] Epoch[198] Batch[10] avg_epoch_loss=2.164875\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.1636516094207763\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] Epoch[198] Batch [10]#011Speed: 2049.32 samples/sec#011loss=2.163652\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747844436.656024, \"EndTime\": 1747844437.588201, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.8387508392334, \"count\": 1, \"min\": 931.8387508392334, \"max\": 931.8387508392334}}}\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.2039368976834 records/second\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 49.75 % of epochs\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.164875398982655\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] Epoch[199] Batch[0] avg_epoch_loss=2.202812\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.202812433242798\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] Epoch[199] Batch[5] avg_epoch_loss=2.171891\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.1718913316726685\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] Epoch[199] Batch [5]#011Speed: 2188.51 samples/sec#011loss=2.171891\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] Epoch[199] Batch[10] avg_epoch_loss=2.191814\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=2.2157201290130617\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] Epoch[199] Batch [10]#011Speed: 2089.56 samples/sec#011loss=2.215720\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844437.588256, \"EndTime\": 1747844438.507479, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.9832210540771, \"count\": 1, \"min\": 918.9832210540771, \"max\": 918.9832210540771}}}\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.1530908797536 records/second\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 50.0 % of epochs\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.191813512281938\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] Epoch[200] Batch[0] avg_epoch_loss=2.205767\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.2057671546936035\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] Epoch[200] Batch[5] avg_epoch_loss=2.163594\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.163594365119934\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] Epoch[200] Batch [5]#011Speed: 2232.93 samples/sec#011loss=2.163594\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] Epoch[200] Batch[10] avg_epoch_loss=2.172927\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=2.1841251850128174\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] Epoch[200] Batch [10]#011Speed: 1989.03 samples/sec#011loss=2.184125\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] processed a total of 1392 examples\n",
      "#metrics {\"StartTime\": 1747844438.5075336, \"EndTime\": 1747844439.4294884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.7102527618408, \"count\": 1, \"min\": 921.7102527618408, \"max\": 921.7102527618408}}}\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1510.0969348126848 records/second\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 50.25 % of epochs\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.1729265559803355\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] Epoch[201] Batch[0] avg_epoch_loss=2.219630\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.219630241394043\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[201] Batch[5] avg_epoch_loss=2.212164\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.212164044380188\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[201] Batch [5]#011Speed: 2145.07 samples/sec#011loss=2.212164\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[201] Batch[10] avg_epoch_loss=2.208648\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=2.204428195953369\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[201] Batch [10]#011Speed: 1953.88 samples/sec#011loss=2.204428\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] processed a total of 1396 examples\n",
      "#metrics {\"StartTime\": 1747844439.4295444, \"EndTime\": 1747844440.3708005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.9737586975098, \"count\": 1, \"min\": 940.9737586975098, \"max\": 940.9737586975098}}}\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1483.4285847475555 records/second\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 50.5 % of epochs\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.208647749640725\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[202] Batch[0] avg_epoch_loss=2.123602\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.1236023902893066\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[202] Batch[5] avg_epoch_loss=2.190491\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.1904907623926797\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[202] Batch [5]#011Speed: 2095.86 samples/sec#011loss=2.190491\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Epoch[202] Batch[10] avg_epoch_loss=2.099372\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=1.9900302648544312\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Epoch[202] Batch [10]#011Speed: 2118.50 samples/sec#011loss=1.990030\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747844440.3708591, \"EndTime\": 1747844441.299555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.4489154815674, \"count\": 1, \"min\": 928.4489154815674, \"max\": 928.4489154815674}}}\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1401.1329931147461 records/second\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 50.75 % of epochs\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.0993723544207485\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_66f623dc-d5d4-4eb5-af66-873445dab848-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844441.2996116, \"EndTime\": 1747844441.3105419, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.640144348144531, \"count\": 1, \"min\": 10.640144348144531, \"max\": 10.640144348144531}}}\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Epoch[203] Batch[0] avg_epoch_loss=2.162575\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.1625752449035645\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Epoch[203] Batch[5] avg_epoch_loss=2.153125\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.1531251668930054\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Epoch[203] Batch [5]#011Speed: 2141.36 samples/sec#011loss=2.153125\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] Epoch[203] Batch[10] avg_epoch_loss=2.323638\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=2.5282530307769777\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] Epoch[203] Batch [10]#011Speed: 2051.45 samples/sec#011loss=2.528253\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747844441.310592, \"EndTime\": 1747844442.2553658, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.7240829467773, \"count\": 1, \"min\": 944.7240829467773, \"max\": 944.7240829467773}}}\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1418.2657560414298 records/second\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 51.0 % of epochs\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.323637832294811\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] Epoch[204] Batch[0] avg_epoch_loss=2.236738\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.2367379665374756\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] Epoch[204] Batch[5] avg_epoch_loss=2.274503\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.2745028336842856\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] Epoch[204] Batch [5]#011Speed: 2179.95 samples/sec#011loss=2.274503\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] processed a total of 1227 examples\n",
      "#metrics {\"StartTime\": 1747844442.2554297, \"EndTime\": 1747844443.097475, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 841.799259185791, \"count\": 1, \"min\": 841.799259185791, \"max\": 841.799259185791}}}\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.4311748687114 records/second\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 51.25 % of epochs\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.250216019153595\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] Epoch[205] Batch[0] avg_epoch_loss=2.268302\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.2683019638061523\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] Epoch[205] Batch[5] avg_epoch_loss=2.275498\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.275498112042745\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] Epoch[205] Batch [5]#011Speed: 2183.50 samples/sec#011loss=2.275498\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[205] Batch[10] avg_epoch_loss=2.302355\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=2.3345824241638184\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[205] Batch [10]#011Speed: 2067.94 samples/sec#011loss=2.334582\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747844443.0975375, \"EndTime\": 1747844444.0247908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.9585609436035, \"count\": 1, \"min\": 926.9585609436035, \"max\": 926.9585609436035}}}\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1443.3240485650033 records/second\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 51.5 % of epochs\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.3023546175523237\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[206] Batch[0] avg_epoch_loss=2.207852\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.207852363586426\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[206] Batch[5] avg_epoch_loss=2.168553\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.168552796045939\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[206] Batch [5]#011Speed: 1948.61 samples/sec#011loss=2.168553\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[206] Batch[10] avg_epoch_loss=2.198014\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=2.233367586135864\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[206] Batch [10]#011Speed: 2130.41 samples/sec#011loss=2.233368\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747844444.0248358, \"EndTime\": 1747844444.9728792, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.8485584259033, \"count\": 1, \"min\": 947.8485584259033, \"max\": 947.8485584259033}}}\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1389.339108100318 records/second\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 51.75 % of epochs\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.1980140642686323\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] Epoch[207] Batch[0] avg_epoch_loss=2.198467\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.1984667778015137\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] Epoch[207] Batch[5] avg_epoch_loss=2.197401\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.197401444117228\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] Epoch[207] Batch [5]#011Speed: 2143.90 samples/sec#011loss=2.197401\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] Epoch[207] Batch[10] avg_epoch_loss=2.162070\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=2.119672250747681\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] Epoch[207] Batch [10]#011Speed: 2066.03 samples/sec#011loss=2.119672\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747844444.9729347, \"EndTime\": 1747844445.904755, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.5760135650635, \"count\": 1, \"min\": 931.5760135650635, \"max\": 931.5760135650635}}}\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.4574055639293 records/second\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 52.0 % of epochs\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.1620699925856157\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] Epoch[208] Batch[0] avg_epoch_loss=2.266285\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.2662854194641113\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] Epoch[208] Batch[5] avg_epoch_loss=2.342024\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.3420235315958657\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] Epoch[208] Batch [5]#011Speed: 2160.93 samples/sec#011loss=2.342024\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] Epoch[208] Batch[10] avg_epoch_loss=2.364377\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.391201877593994\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] Epoch[208] Batch [10]#011Speed: 1977.63 samples/sec#011loss=2.391202\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] processed a total of 1413 examples\n",
      "#metrics {\"StartTime\": 1747844445.9048107, \"EndTime\": 1747844446.9070728, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1002.0110607147217, \"count\": 1, \"min\": 1002.0110607147217, \"max\": 1002.0110607147217}}}\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1410.034234519736 records/second\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 52.25 % of epochs\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.3148432870705924\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] Epoch[209] Batch[0] avg_epoch_loss=2.381964\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.3819644451141357\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] Epoch[209] Batch[5] avg_epoch_loss=2.314153\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.3141531944274902\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] Epoch[209] Batch [5]#011Speed: 2166.86 samples/sec#011loss=2.314153\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] Epoch[209] Batch[10] avg_epoch_loss=2.426307\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=2.560890769958496\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] Epoch[209] Batch [10]#011Speed: 2109.81 samples/sec#011loss=2.560891\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747844446.907135, \"EndTime\": 1747844447.8301382, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.7101802825928, \"count\": 1, \"min\": 922.7101802825928, \"max\": 922.7101802825928}}}\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1398.999322570594 records/second\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 52.5 % of epochs\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.426306637850675\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] Epoch[210] Batch[0] avg_epoch_loss=2.178801\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.1788012981414795\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] Epoch[210] Batch[5] avg_epoch_loss=2.283313\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.283312519391378\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] Epoch[210] Batch [5]#011Speed: 2130.17 samples/sec#011loss=2.283313\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747844447.8301947, \"EndTime\": 1747844448.6934836, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 863.039493560791, \"count\": 1, \"min\": 863.039493560791, \"max\": 863.039493560791}}}\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1467.9078636434074 records/second\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 52.75 % of epochs\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.2861845970153807\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[211] Batch[0] avg_epoch_loss=2.290043\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.2900431156158447\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[211] Batch[5] avg_epoch_loss=2.203702\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.203702211380005\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[211] Batch [5]#011Speed: 2244.81 samples/sec#011loss=2.203702\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[211] Batch[10] avg_epoch_loss=2.198770\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=2.1928505897521973\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[211] Batch [10]#011Speed: 2072.20 samples/sec#011loss=2.192851\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] processed a total of 1383 examples\n",
      "#metrics {\"StartTime\": 1747844448.6935458, \"EndTime\": 1747844449.600697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.8546295166016, \"count\": 1, \"min\": 906.8546295166016, \"max\": 906.8546295166016}}}\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1524.9123697315254 records/second\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 53.0 % of epochs\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.1987696560946377\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[212] Batch[0] avg_epoch_loss=2.145395\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.145394802093506\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] Epoch[212] Batch[5] avg_epoch_loss=2.177683\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.1776832739512124\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] Epoch[212] Batch [5]#011Speed: 2132.52 samples/sec#011loss=2.177683\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] Epoch[212] Batch[10] avg_epoch_loss=2.185011\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.19380521774292\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] Epoch[212] Batch [10]#011Speed: 2122.56 samples/sec#011loss=2.193805\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844449.600752, \"EndTime\": 1747844450.5245595, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.5687255859375, \"count\": 1, \"min\": 923.5687255859375, \"max\": 923.5687255859375}}}\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1404.1549698326762 records/second\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 53.25 % of epochs\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.1850114302201704\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] Epoch[213] Batch[0] avg_epoch_loss=2.319232\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.319232225418091\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] Epoch[213] Batch[5] avg_epoch_loss=2.362285\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.3622852166493735\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] Epoch[213] Batch [5]#011Speed: 2130.41 samples/sec#011loss=2.362285\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] Epoch[213] Batch[10] avg_epoch_loss=2.378485\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=2.3979246616363525\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] Epoch[213] Batch [10]#011Speed: 2001.42 samples/sec#011loss=2.397925\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747844450.5246496, \"EndTime\": 1747844451.4655364, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.6254291534424, \"count\": 1, \"min\": 940.6254291534424, \"max\": 940.6254291534424}}}\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1437.197644807059 records/second\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 53.5 % of epochs\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.3784849643707275\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] Epoch[214] Batch[0] avg_epoch_loss=2.207564\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.207563638687134\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] Epoch[214] Batch[5] avg_epoch_loss=2.261972\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.261971910794576\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] Epoch[214] Batch [5]#011Speed: 2110.87 samples/sec#011loss=2.261972\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] Epoch[214] Batch[10] avg_epoch_loss=2.369025\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=2.497488260269165\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] Epoch[214] Batch [10]#011Speed: 2140.17 samples/sec#011loss=2.497488\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747844451.4655974, \"EndTime\": 1747844452.415094, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 949.1779804229736, \"count\": 1, \"min\": 949.1779804229736, \"max\": 949.1779804229736}}}\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1354.7173698685185 records/second\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 53.75 % of epochs\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.369024796919389\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] Epoch[215] Batch[0] avg_epoch_loss=2.233238\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.2332379817962646\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[215] Batch[5] avg_epoch_loss=2.310457\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.3104573090871177\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[215] Batch [5]#011Speed: 2067.96 samples/sec#011loss=2.310457\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[215] Batch[10] avg_epoch_loss=2.424845\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=2.5621108531951906\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[215] Batch [10]#011Speed: 2073.62 samples/sec#011loss=2.562111\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844452.4151592, \"EndTime\": 1747844453.3490922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.6338043212891, \"count\": 1, \"min\": 933.6338043212891, \"max\": 933.6338043212891}}}\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1446.9077855907358 records/second\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 54.0 % of epochs\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.4248452836816963\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[216] Batch[0] avg_epoch_loss=2.276415\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.2764153480529785\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[216] Batch[5] avg_epoch_loss=2.332436\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.3324364026387534\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[216] Batch [5]#011Speed: 2231.26 samples/sec#011loss=2.332436\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] Epoch[216] Batch[10] avg_epoch_loss=2.317406\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=2.2993701934814452\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] Epoch[216] Batch [10]#011Speed: 2047.32 samples/sec#011loss=2.299370\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747844453.3491461, \"EndTime\": 1747844454.2671657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.7813529968262, \"count\": 1, \"min\": 917.7813529968262, \"max\": 917.7813529968262}}}\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1466.4385309881538 records/second\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 54.25 % of epochs\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.3174063075672495\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] Epoch[217] Batch[0] avg_epoch_loss=2.252441\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.252440929412842\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] Epoch[217] Batch[5] avg_epoch_loss=2.250445\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.250444849332174\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] Epoch[217] Batch [5]#011Speed: 2190.83 samples/sec#011loss=2.250445\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] Epoch[217] Batch[10] avg_epoch_loss=2.360031\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=2.49153413772583\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] Epoch[217] Batch [10]#011Speed: 2172.79 samples/sec#011loss=2.491534\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747844454.2672248, \"EndTime\": 1747844455.1754255, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.9287052154541, \"count\": 1, \"min\": 907.9287052154541, \"max\": 907.9287052154541}}}\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1414.0623974503487 records/second\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 54.5 % of epochs\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.3600308895111084\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] Epoch[218] Batch[0] avg_epoch_loss=2.160618\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=2.160618305206299\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] Epoch[218] Batch[5] avg_epoch_loss=2.197252\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.197251637776693\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] Epoch[218] Batch [5]#011Speed: 2120.74 samples/sec#011loss=2.197252\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747844455.1754842, \"EndTime\": 1747844456.0429168, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 867.1820163726807, \"count\": 1, \"min\": 867.1820163726807, \"max\": 867.1820163726807}}}\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1471.280229117974 records/second\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 54.75 % of epochs\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.1921730756759645\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] Epoch[219] Batch[0] avg_epoch_loss=2.148972\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.1489717960357666\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] Epoch[219] Batch[5] avg_epoch_loss=2.206292\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.2062920729319253\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] Epoch[219] Batch [5]#011Speed: 2113.06 samples/sec#011loss=2.206292\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] Epoch[219] Batch[10] avg_epoch_loss=2.208831\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=2.211878776550293\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] Epoch[219] Batch [10]#011Speed: 2081.01 samples/sec#011loss=2.211879\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747844456.042977, \"EndTime\": 1747844456.9769843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.6154460906982, \"count\": 1, \"min\": 933.6154460906982, \"max\": 933.6154460906982}}}\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.8652953118653 records/second\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 55.0 % of epochs\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.208831483667547\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] Epoch[220] Batch[0] avg_epoch_loss=2.114685\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.11468505859375\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] Epoch[220] Batch[5] avg_epoch_loss=2.170950\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.170950253804525\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] Epoch[220] Batch [5]#011Speed: 2093.23 samples/sec#011loss=2.170950\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] Epoch[220] Batch[10] avg_epoch_loss=2.118172\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=2.054839086532593\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] Epoch[220] Batch [10]#011Speed: 2087.84 samples/sec#011loss=2.054839\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747844456.9770854, \"EndTime\": 1747844457.9101918, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.8317642211914, \"count\": 1, \"min\": 932.8317642211914, \"max\": 932.8317642211914}}}\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.218338334716 records/second\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 55.25 % of epochs\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.118172450499101\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] Epoch[221] Batch[0] avg_epoch_loss=2.186387\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.186386823654175\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] Epoch[221] Batch[5] avg_epoch_loss=2.131918\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.131918430328369\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] Epoch[221] Batch [5]#011Speed: 2189.56 samples/sec#011loss=2.131918\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] Epoch[221] Batch[10] avg_epoch_loss=2.191399\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=2.2627758026123046\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] Epoch[221] Batch [10]#011Speed: 2091.18 samples/sec#011loss=2.262776\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747844457.9102457, \"EndTime\": 1747844458.828832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.3139801025391, \"count\": 1, \"min\": 918.3139801025391, \"max\": 918.3139801025391}}}\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1459.0633218052367 records/second\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 55.5 % of epochs\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.1913990540937944\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] Epoch[222] Batch[0] avg_epoch_loss=2.418191\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=2.418191432952881\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] Epoch[222] Batch[5] avg_epoch_loss=2.225063\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.2250633239746094\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] Epoch[222] Batch [5]#011Speed: 2206.48 samples/sec#011loss=2.225063\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] processed a total of 1262 examples\n",
      "#metrics {\"StartTime\": 1747844458.8288877, \"EndTime\": 1747844459.682305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 853.1687259674072, \"count\": 1, \"min\": 853.1687259674072, \"max\": 853.1687259674072}}}\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1479.035350968348 records/second\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 55.75 % of epochs\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.2138325452804564\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[223] Batch[0] avg_epoch_loss=2.189793\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.189793109893799\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[223] Batch[5] avg_epoch_loss=2.205834\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.2058343092600503\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[223] Batch [5]#011Speed: 2132.65 samples/sec#011loss=2.205834\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[223] Batch[10] avg_epoch_loss=2.254772\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=2.3134968757629393\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[223] Batch [10]#011Speed: 2106.22 samples/sec#011loss=2.313497\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844459.6823657, \"EndTime\": 1747844460.6087496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.0504245758057, \"count\": 1, \"min\": 926.0504245758057, \"max\": 926.0504245758057}}}\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1423.1185627361313 records/second\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 56.0 % of epochs\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.2547718394886362\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[224] Batch[0] avg_epoch_loss=2.044531\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.0445306301116943\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] Epoch[224] Batch[5] avg_epoch_loss=2.183264\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.183264136314392\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] Epoch[224] Batch [5]#011Speed: 2108.31 samples/sec#011loss=2.183264\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] Epoch[224] Batch[10] avg_epoch_loss=2.148940\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=2.1077516317367553\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] Epoch[224] Batch [10]#011Speed: 1767.97 samples/sec#011loss=2.107752\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844460.6088068, \"EndTime\": 1747844461.5949411, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 985.8365058898926, \"count\": 1, \"min\": 985.8365058898926, \"max\": 985.8365058898926}}}\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1368.269210269982 records/second\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 56.25 % of epochs\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.1489402705972847\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] Epoch[225] Batch[0] avg_epoch_loss=2.169954\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.1699540615081787\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Epoch[225] Batch[5] avg_epoch_loss=2.141982\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.141981840133667\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Epoch[225] Batch [5]#011Speed: 2122.66 samples/sec#011loss=2.141982\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Epoch[225] Batch[10] avg_epoch_loss=2.098197\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=2.0456557750701903\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Epoch[225] Batch [10]#011Speed: 2169.47 samples/sec#011loss=2.045656\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747844461.5949917, \"EndTime\": 1747844462.5309029, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.6434345245361, \"count\": 1, \"min\": 935.6434345245361, \"max\": 935.6434345245361}}}\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1404.258411564047 records/second\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 56.5 % of epochs\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.098197265104814\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_09a95c9d-8e4c-4b62-818d-fea88424c140-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844462.5309565, \"EndTime\": 1747844462.5412636, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.048389434814453, \"count\": 1, \"min\": 10.048389434814453, \"max\": 10.048389434814453}}}\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Epoch[226] Batch[0] avg_epoch_loss=2.265798\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=2.2657980918884277\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] Epoch[226] Batch[5] avg_epoch_loss=2.173375\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.173375368118286\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] Epoch[226] Batch [5]#011Speed: 2195.65 samples/sec#011loss=2.173375\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] Epoch[226] Batch[10] avg_epoch_loss=2.137421\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=2.0942755222320555\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] Epoch[226] Batch [10]#011Speed: 1956.09 samples/sec#011loss=2.094276\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844462.5413113, \"EndTime\": 1747844463.477142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.786247253418, \"count\": 1, \"min\": 935.786247253418, \"max\": 935.786247253418}}}\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.479706219289 records/second\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 56.75 % of epochs\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.137420892715454\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] Epoch[227] Batch[0] avg_epoch_loss=2.098751\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.0987510681152344\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[227] Batch[5] avg_epoch_loss=2.136324\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.136324087778727\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[227] Batch [5]#011Speed: 2214.62 samples/sec#011loss=2.136324\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[227] Batch[10] avg_epoch_loss=2.154931\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=2.177258586883545\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[227] Batch [10]#011Speed: 2200.96 samples/sec#011loss=2.177259\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747844463.4772446, \"EndTime\": 1747844464.3816047, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.0439128875732, \"count\": 1, \"min\": 904.0439128875732, \"max\": 904.0439128875732}}}\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1422.3637322065265 records/second\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 57.0 % of epochs\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.154930678280917\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[228] Batch[0] avg_epoch_loss=2.085278\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.085278272628784\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[228] Batch[5] avg_epoch_loss=2.106476\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.106476346651713\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[228] Batch [5]#011Speed: 2181.96 samples/sec#011loss=2.106476\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] Epoch[228] Batch[10] avg_epoch_loss=2.189946\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=2.290109968185425\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] Epoch[228] Batch [10]#011Speed: 2124.50 samples/sec#011loss=2.290110\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747844464.3816605, \"EndTime\": 1747844465.2940657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.1639728546143, \"count\": 1, \"min\": 912.1639728546143, \"max\": 912.1639728546143}}}\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1441.5043157499128 records/second\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 57.25 % of epochs\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.189946174621582\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] Epoch[229] Batch[0] avg_epoch_loss=2.103817\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.1038174629211426\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] Epoch[229] Batch[5] avg_epoch_loss=2.172805\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.172805349032084\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] Epoch[229] Batch [5]#011Speed: 2077.63 samples/sec#011loss=2.172805\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] processed a total of 1262 examples\n",
      "#metrics {\"StartTime\": 1747844465.294117, \"EndTime\": 1747844466.1914606, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 896.9743251800537, \"count\": 1, \"min\": 896.9743251800537, \"max\": 896.9743251800537}}}\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.7929056673177 records/second\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 57.5 % of epochs\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.171135401725769\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] Epoch[230] Batch[0] avg_epoch_loss=2.082486\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.0824859142303467\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] Epoch[230] Batch[5] avg_epoch_loss=2.126018\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.126018206278483\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] Epoch[230] Batch [5]#011Speed: 2106.85 samples/sec#011loss=2.126018\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747844466.1915288, \"EndTime\": 1747844467.055914, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 863.9934062957764, \"count\": 1, \"min\": 863.9934062957764, \"max\": 863.9934062957764}}}\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1481.3321398890362 records/second\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 57.75 % of epochs\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.1157091856002808\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] Epoch[231] Batch[0] avg_epoch_loss=2.044520\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.044520378112793\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] Epoch[231] Batch[5] avg_epoch_loss=2.102587\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.1025867064793906\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] Epoch[231] Batch [5]#011Speed: 2226.60 samples/sec#011loss=2.102587\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] Epoch[231] Batch[10] avg_epoch_loss=2.130683\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=2.164398717880249\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] Epoch[231] Batch [10]#011Speed: 2122.58 samples/sec#011loss=2.164399\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844467.0559762, \"EndTime\": 1747844467.9650147, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.7293148040771, \"count\": 1, \"min\": 908.7293148040771, \"max\": 908.7293148040771}}}\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1437.0381723686796 records/second\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 58.0 % of epochs\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.1306830752979624\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] Epoch[232] Batch[0] avg_epoch_loss=2.166233\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.1662330627441406\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] Epoch[232] Batch[5] avg_epoch_loss=2.150295\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.1502949396769204\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] Epoch[232] Batch [5]#011Speed: 2222.41 samples/sec#011loss=2.150295\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] Epoch[232] Batch[10] avg_epoch_loss=2.147755\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=2.144706916809082\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] Epoch[232] Batch [10]#011Speed: 1954.23 samples/sec#011loss=2.144707\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844467.9650722, \"EndTime\": 1747844468.9008226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.4674816131592, \"count\": 1, \"min\": 935.4674816131592, \"max\": 935.4674816131592}}}\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1414.0866764709556 records/second\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 58.25 % of epochs\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.1477549292824487\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] Epoch[233] Batch[0] avg_epoch_loss=2.144544\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.1445443630218506\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] Epoch[233] Batch[5] avg_epoch_loss=2.103925\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.103924552599589\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] Epoch[233] Batch [5]#011Speed: 2204.68 samples/sec#011loss=2.103925\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] Epoch[233] Batch[10] avg_epoch_loss=2.183500\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=2.2789910793304444\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] Epoch[233] Batch [10]#011Speed: 2101.52 samples/sec#011loss=2.278991\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844468.9009125, \"EndTime\": 1747844469.8167875, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.6019687652588, \"count\": 1, \"min\": 915.6019687652588, \"max\": 915.6019687652588}}}\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.5265272518645 records/second\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 58.5 % of epochs\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.1835002465681597\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] Epoch[234] Batch[0] avg_epoch_loss=2.084017\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.084017038345337\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] Epoch[234] Batch[5] avg_epoch_loss=2.102297\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.1022969484329224\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] Epoch[234] Batch [5]#011Speed: 2203.14 samples/sec#011loss=2.102297\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] Epoch[234] Batch[10] avg_epoch_loss=2.141853\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=2.189320755004883\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] Epoch[234] Batch [10]#011Speed: 1952.78 samples/sec#011loss=2.189321\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] processed a total of 1381 examples\n",
      "#metrics {\"StartTime\": 1747844469.8168447, \"EndTime\": 1747844470.7503269, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.211088180542, \"count\": 1, \"min\": 933.211088180542, \"max\": 933.211088180542}}}\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1479.6975643875307 records/second\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 58.75 % of epochs\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.1418532241474497\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Epoch[235] Batch[0] avg_epoch_loss=2.213713\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.2137134075164795\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Epoch[235] Batch[5] avg_epoch_loss=2.103458\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.103458285331726\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Epoch[235] Batch [5]#011Speed: 2186.33 samples/sec#011loss=2.103458\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Epoch[235] Batch[10] avg_epoch_loss=2.025390\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=1.9317082643508912\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Epoch[235] Batch [10]#011Speed: 2141.58 samples/sec#011loss=1.931708\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747844470.7503862, \"EndTime\": 1747844471.6665583, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.9243106842041, \"count\": 1, \"min\": 915.9243106842041, \"max\": 915.9243106842041}}}\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1421.3794235392686 records/second\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 59.0 % of epochs\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.0253900939768013\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_abb907f2-359c-4c6a-835a-688fabbb27fb-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844471.6666174, \"EndTime\": 1747844471.6774325, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.513782501220703, \"count\": 1, \"min\": 10.513782501220703, \"max\": 10.513782501220703}}}\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[236] Batch[0] avg_epoch_loss=2.208539\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.2085392475128174\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[236] Batch[5] avg_epoch_loss=2.106447\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.1064474980036416\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[236] Batch [5]#011Speed: 2203.89 samples/sec#011loss=2.106447\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[236] Batch[10] avg_epoch_loss=2.112650\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=2.1200929641723634\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[236] Batch [10]#011Speed: 2169.01 samples/sec#011loss=2.120093\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844471.6774986, \"EndTime\": 1747844472.5872593, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.710168838501, \"count\": 1, \"min\": 909.710168838501, \"max\": 909.710168838501}}}\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.9025067119503 records/second\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 59.25 % of epochs\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.112649982625788\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[237] Batch[0] avg_epoch_loss=2.101073\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.1010725498199463\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] Epoch[237] Batch[5] avg_epoch_loss=2.115961\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.115960677464803\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] Epoch[237] Batch [5]#011Speed: 2194.22 samples/sec#011loss=2.115961\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] Epoch[237] Batch[10] avg_epoch_loss=2.073710\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=2.023009729385376\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] Epoch[237] Batch [10]#011Speed: 1964.36 samples/sec#011loss=2.023010\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747844472.5873165, \"EndTime\": 1747844473.5306098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.0415630340576, \"count\": 1, \"min\": 943.0415630340576, \"max\": 943.0415630340576}}}\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1414.4469966772438 records/second\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 59.5 % of epochs\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.073710246519609\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] Epoch[238] Batch[0] avg_epoch_loss=2.228057\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.2280569076538086\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] Epoch[238] Batch[5] avg_epoch_loss=2.225373\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.225372592608134\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] Epoch[238] Batch [5]#011Speed: 2097.72 samples/sec#011loss=2.225373\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] Epoch[238] Batch[10] avg_epoch_loss=2.182702\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=2.131497287750244\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] Epoch[238] Batch [10]#011Speed: 2025.74 samples/sec#011loss=2.131497\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844473.5306642, \"EndTime\": 1747844474.4792476, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.251485824585, \"count\": 1, \"min\": 948.251485824585, \"max\": 948.251485824585}}}\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.6053907938362 records/second\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 59.75 % of epochs\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.182701999490911\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] Epoch[239] Batch[0] avg_epoch_loss=2.250238\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.2502377033233643\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] Epoch[239] Batch[5] avg_epoch_loss=2.156253\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.156252900759379\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] Epoch[239] Batch [5]#011Speed: 2161.59 samples/sec#011loss=2.156253\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] Epoch[239] Batch[10] avg_epoch_loss=2.205487\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=2.2645677089691163\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] Epoch[239] Batch [10]#011Speed: 2120.90 samples/sec#011loss=2.264568\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747844474.4793, \"EndTime\": 1747844475.4018378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.290563583374, \"count\": 1, \"min\": 922.290563583374, \"max\": 922.290563583374}}}\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1402.9027154759954 records/second\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 60.0 % of epochs\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.2054869044910776\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] Epoch[240] Batch[0] avg_epoch_loss=2.111235\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.111234664916992\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[240] Batch[5] avg_epoch_loss=2.135606\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.1356064875920615\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[240] Batch [5]#011Speed: 2050.54 samples/sec#011loss=2.135606\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[240] Batch[10] avg_epoch_loss=2.105627\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=2.0696524143218995\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[240] Batch [10]#011Speed: 2154.33 samples/sec#011loss=2.069652\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747844475.401893, \"EndTime\": 1747844476.341685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.549446105957, \"count\": 1, \"min\": 939.549446105957, \"max\": 939.549446105957}}}\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1382.4526925395676 records/second\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 60.25 % of epochs\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.1056273633783515\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[241] Batch[0] avg_epoch_loss=2.112519\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.1125192642211914\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[241] Batch[5] avg_epoch_loss=2.163996\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.163995623588562\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[241] Batch [5]#011Speed: 2069.89 samples/sec#011loss=2.163996\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] Epoch[241] Batch[10] avg_epoch_loss=2.197976\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.2387518882751465\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] Epoch[241] Batch [10]#011Speed: 2027.85 samples/sec#011loss=2.238752\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747844476.3417408, \"EndTime\": 1747844477.2863777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.8629150390625, \"count\": 1, \"min\": 943.8629150390625, \"max\": 943.8629150390625}}}\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.858177986372 records/second\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 60.5 % of epochs\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.197975743900646\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] Epoch[242] Batch[0] avg_epoch_loss=2.273446\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.2734458446502686\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] Epoch[242] Batch[5] avg_epoch_loss=2.164304\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.164304176966349\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] Epoch[242] Batch [5]#011Speed: 2216.79 samples/sec#011loss=2.164304\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] Epoch[242] Batch[10] avg_epoch_loss=2.147145\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=2.1265542984008787\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] Epoch[242] Batch [10]#011Speed: 2048.28 samples/sec#011loss=2.126554\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844477.2864327, \"EndTime\": 1747844478.2032852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.6061878204346, \"count\": 1, \"min\": 916.6061878204346, \"max\": 916.6061878204346}}}\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1473.7801053765554 records/second\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 60.75 % of epochs\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.147145141254772\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] Epoch[243] Batch[0] avg_epoch_loss=2.202285\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=2.202284574508667\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] Epoch[243] Batch[5] avg_epoch_loss=2.195996\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.195995807647705\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] Epoch[243] Batch [5]#011Speed: 2046.45 samples/sec#011loss=2.195996\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] Epoch[243] Batch[10] avg_epoch_loss=2.176829\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=2.1538279056549072\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] Epoch[243] Batch [10]#011Speed: 2100.16 samples/sec#011loss=2.153828\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747844478.2033424, \"EndTime\": 1747844479.140913, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.3178482055664, \"count\": 1, \"min\": 937.3178482055664, \"max\": 937.3178482055664}}}\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.1484936733007 records/second\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 61.0 % of epochs\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.1768285794691606\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] Epoch[244] Batch[0] avg_epoch_loss=2.095212\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.0952117443084717\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] Epoch[244] Batch[5] avg_epoch_loss=2.106763\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.1067630449930825\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] Epoch[244] Batch [5]#011Speed: 2203.99 samples/sec#011loss=2.106763\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] Epoch[244] Batch[10] avg_epoch_loss=2.078181\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=2.043881869316101\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] Epoch[244] Batch [10]#011Speed: 2021.96 samples/sec#011loss=2.043882\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] processed a total of 1372 examples\n",
      "#metrics {\"StartTime\": 1747844479.140969, \"EndTime\": 1747844480.0646374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.274040222168, \"count\": 1, \"min\": 923.274040222168, \"max\": 923.274040222168}}}\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1485.8797902421654 records/second\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 61.25 % of epochs\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.0781806924126367\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] Epoch[245] Batch[0] avg_epoch_loss=2.081185\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.0811853408813477\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] Epoch[245] Batch[5] avg_epoch_loss=2.075188\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.075188239415487\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] Epoch[245] Batch [5]#011Speed: 2235.23 samples/sec#011loss=2.075188\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] processed a total of 1254 examples\n",
      "#metrics {\"StartTime\": 1747844480.0646927, \"EndTime\": 1747844480.9215238, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 856.5425872802734, \"count\": 1, \"min\": 856.5425872802734, \"max\": 856.5425872802734}}}\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1463.864736762711 records/second\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 61.5 % of epochs\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.056214988231659\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Epoch[246] Batch[0] avg_epoch_loss=2.074374\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.074374198913574\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Epoch[246] Batch[5] avg_epoch_loss=2.028003\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.028002997239431\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Epoch[246] Batch [5]#011Speed: 2152.30 samples/sec#011loss=2.028003\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Epoch[246] Batch[10] avg_epoch_loss=1.987982\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=1.939957046508789\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Epoch[246] Batch [10]#011Speed: 2073.40 samples/sec#011loss=1.939957\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747844480.9215868, \"EndTime\": 1747844481.8533163, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.4291477203369, \"count\": 1, \"min\": 931.4291477203369, \"max\": 931.4291477203369}}}\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1394.5021793891976 records/second\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 61.75 % of epochs\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=246, train loss <loss>=1.9879821105436846\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_668d5524-9324-4d89-9d9e-93fbb8a6c4fd-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844481.8533747, \"EndTime\": 1747844481.8646479, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.983705520629883, \"count\": 1, \"min\": 10.983705520629883, \"max\": 10.983705520629883}}}\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] Epoch[247] Batch[0] avg_epoch_loss=2.075244\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.0752439498901367\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] Epoch[247] Batch[5] avg_epoch_loss=2.054706\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.054705778757731\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] Epoch[247] Batch [5]#011Speed: 2228.90 samples/sec#011loss=2.054706\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] Epoch[247] Batch[10] avg_epoch_loss=2.119027\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=2.1962114334106446\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] Epoch[247] Batch [10]#011Speed: 1966.76 samples/sec#011loss=2.196211\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747844481.8646975, \"EndTime\": 1747844482.794408, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.6655654907227, \"count\": 1, \"min\": 929.6655654907227, \"max\": 929.6655654907227}}}\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1416.5124094565483 records/second\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 62.0 % of epochs\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=247, train loss <loss>=2.119026530872692\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] Epoch[248] Batch[0] avg_epoch_loss=2.074578\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.074578046798706\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] Epoch[248] Batch[5] avg_epoch_loss=2.124177\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.1241767406463623\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] Epoch[248] Batch [5]#011Speed: 2146.38 samples/sec#011loss=2.124177\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] Epoch[248] Batch[10] avg_epoch_loss=2.093256\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=2.056151032447815\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] Epoch[248] Batch [10]#011Speed: 2080.58 samples/sec#011loss=2.056151\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747844482.7944655, \"EndTime\": 1747844483.719626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.8561859130859, \"count\": 1, \"min\": 924.8561859130859, \"max\": 924.8561859130859}}}\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1445.49489817092 records/second\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 62.25 % of epochs\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.093255964192477\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[249] Batch[0] avg_epoch_loss=2.094382\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.094381809234619\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[249] Batch[5] avg_epoch_loss=2.125469\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.125468691190084\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[249] Batch [5]#011Speed: 2145.19 samples/sec#011loss=2.125469\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[249] Batch[10] avg_epoch_loss=2.126042\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=2.1267292499542236\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[249] Batch [10]#011Speed: 2144.66 samples/sec#011loss=2.126729\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844483.7196834, \"EndTime\": 1747844484.6393871, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.4116592407227, \"count\": 1, \"min\": 919.4116592407227, \"max\": 919.4116592407227}}}\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1410.5424555466216 records/second\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 62.5 % of epochs\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.126041672446511\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[250] Batch[0] avg_epoch_loss=2.372456\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.3724563121795654\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] Epoch[250] Batch[5] avg_epoch_loss=2.379787\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.379786570866903\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] Epoch[250] Batch [5]#011Speed: 2183.25 samples/sec#011loss=2.379787\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] Epoch[250] Batch[10] avg_epoch_loss=2.323853\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=2.256733274459839\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] Epoch[250] Batch [10]#011Speed: 2196.12 samples/sec#011loss=2.256733\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747844484.6394434, \"EndTime\": 1747844485.5505795, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.8943939208984, \"count\": 1, \"min\": 910.8943939208984, \"max\": 910.8943939208984}}}\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.1548021841813 records/second\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 62.75 % of epochs\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.3238532543182373\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] Epoch[251] Batch[0] avg_epoch_loss=2.296105\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.296104669570923\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] Epoch[251] Batch[5] avg_epoch_loss=2.409397\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.4093971252441406\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] Epoch[251] Batch [5]#011Speed: 2129.88 samples/sec#011loss=2.409397\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] Epoch[251] Batch[10] avg_epoch_loss=2.381258\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=2.3474917888641356\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] Epoch[251] Batch [10]#011Speed: 2071.69 samples/sec#011loss=2.347492\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747844485.5506375, \"EndTime\": 1747844486.4904478, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.5720958709717, \"count\": 1, \"min\": 939.5720958709717, \"max\": 939.5720958709717}}}\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1398.3851253425353 records/second\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 63.0 % of epochs\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.381258335980502\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] Epoch[252] Batch[0] avg_epoch_loss=2.316093\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=2.3160932064056396\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] Epoch[252] Batch[5] avg_epoch_loss=2.290615\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.2906148036321006\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] Epoch[252] Batch [5]#011Speed: 2105.96 samples/sec#011loss=2.290615\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] processed a total of 1221 examples\n",
      "#metrics {\"StartTime\": 1747844486.4905045, \"EndTime\": 1747844487.3534336, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 862.689733505249, \"count\": 1, \"min\": 862.689733505249, \"max\": 862.689733505249}}}\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1415.161700666042 records/second\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 63.25 % of epochs\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.217351162433624\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] Epoch[253] Batch[0] avg_epoch_loss=2.228507\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=2.2285070419311523\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] Epoch[253] Batch[5] avg_epoch_loss=2.166979\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.166979352633158\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] Epoch[253] Batch [5]#011Speed: 2074.42 samples/sec#011loss=2.166979\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] Epoch[253] Batch[10] avg_epoch_loss=2.205465\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=2.2516479015350344\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] Epoch[253] Batch [10]#011Speed: 2024.07 samples/sec#011loss=2.251648\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] processed a total of 1396 examples\n",
      "#metrics {\"StartTime\": 1747844487.3535128, \"EndTime\": 1747844488.2928777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.0690326690674, \"count\": 1, \"min\": 939.0690326690674, \"max\": 939.0690326690674}}}\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1486.448099267673 records/second\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 63.5 % of epochs\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.2054650566794654\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] Epoch[254] Batch[0] avg_epoch_loss=2.081606\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.081605911254883\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] Epoch[254] Batch[5] avg_epoch_loss=2.093350\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.0933500130971274\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] Epoch[254] Batch [5]#011Speed: 2190.14 samples/sec#011loss=2.093350\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747844488.292932, \"EndTime\": 1747844489.1420693, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 848.8447666168213, \"count\": 1, \"min\": 848.8447666168213, \"max\": 848.8447666168213}}}\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1505.4136921545676 records/second\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 63.75 % of epochs\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.0905584692955017\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] Epoch[255] Batch[0] avg_epoch_loss=2.142189\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=2.142188549041748\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] Epoch[255] Batch[5] avg_epoch_loss=2.085126\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.0851258039474487\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] Epoch[255] Batch [5]#011Speed: 2210.57 samples/sec#011loss=2.085126\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[255] Batch[10] avg_epoch_loss=2.189808\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=2.315425682067871\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[255] Batch [10]#011Speed: 2111.71 samples/sec#011loss=2.315426\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747844489.1421306, \"EndTime\": 1747844490.0518398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.4223976135254, \"count\": 1, \"min\": 909.4223976135254, \"max\": 909.4223976135254}}}\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1482.1207968750778 records/second\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 64.0 % of epochs\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.189807566729459\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[256] Batch[0] avg_epoch_loss=2.146406\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.1464059352874756\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[256] Batch[5] avg_epoch_loss=2.163758\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.163757880528768\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[256] Batch [5]#011Speed: 2186.03 samples/sec#011loss=2.163758\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[256] Batch[10] avg_epoch_loss=2.152655\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=2.139331007003784\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[256] Batch [10]#011Speed: 2069.08 samples/sec#011loss=2.139331\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844490.0518959, \"EndTime\": 1747844490.972747, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.5772876739502, \"count\": 1, \"min\": 920.5772876739502, \"max\": 920.5772876739502}}}\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1451.1328531089248 records/second\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 64.25 % of epochs\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.15265475619923\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] Epoch[257] Batch[0] avg_epoch_loss=2.096661\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.09666109085083\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] Epoch[257] Batch[5] avg_epoch_loss=2.094128\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.094128211339315\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] Epoch[257] Batch [5]#011Speed: 2181.00 samples/sec#011loss=2.094128\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] Epoch[257] Batch[10] avg_epoch_loss=2.056489\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=2.011322855949402\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] Epoch[257] Batch [10]#011Speed: 2133.00 samples/sec#011loss=2.011323\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747844490.9728017, \"EndTime\": 1747844491.8909464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.8953170776367, \"count\": 1, \"min\": 917.8953170776367, \"max\": 917.8953170776367}}}\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1409.6204963954542 records/second\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 64.5 % of epochs\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.056489413434809\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] Epoch[258] Batch[0] avg_epoch_loss=2.142484\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.142483711242676\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] Epoch[258] Batch[5] avg_epoch_loss=2.125413\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.1254132191340127\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] Epoch[258] Batch [5]#011Speed: 2229.09 samples/sec#011loss=2.125413\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] Epoch[258] Batch[10] avg_epoch_loss=2.031918\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=1.9197229862213134\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] Epoch[258] Batch [10]#011Speed: 2056.81 samples/sec#011loss=1.919723\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844491.891001, \"EndTime\": 1747844492.809504, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.255090713501, \"count\": 1, \"min\": 918.255090713501, \"max\": 918.255090713501}}}\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.1923813539236 records/second\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 64.75 % of epochs\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.0319176587191494\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] Epoch[259] Batch[0] avg_epoch_loss=2.065534\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.0655341148376465\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] Epoch[259] Batch[5] avg_epoch_loss=2.056187\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.056187470753988\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] Epoch[259] Batch [5]#011Speed: 2175.58 samples/sec#011loss=2.056187\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] Epoch[259] Batch[10] avg_epoch_loss=2.056605\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=2.057106637954712\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] Epoch[259] Batch [10]#011Speed: 2160.29 samples/sec#011loss=2.057107\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747844492.809563, \"EndTime\": 1747844493.7247088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.8881435394287, \"count\": 1, \"min\": 914.8881435394287, \"max\": 914.8881435394287}}}\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1402.2351765519186 records/second\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 65.0 % of epochs\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.056605274027044\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[260] Batch[0] avg_epoch_loss=2.146675\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=2.146674633026123\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[260] Batch[5] avg_epoch_loss=2.227282\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.227282484372457\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[260] Batch [5]#011Speed: 2148.48 samples/sec#011loss=2.227282\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[260] Batch[10] avg_epoch_loss=2.242275\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=260, batch=10 train loss <loss>=2.260265064239502\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[260] Batch [10]#011Speed: 2109.64 samples/sec#011loss=2.260265\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844493.7247622, \"EndTime\": 1747844494.6476424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.6412773132324, \"count\": 1, \"min\": 922.6412773132324, \"max\": 922.6412773132324}}}\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1433.7944708212376 records/second\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 65.25 % of epochs\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.2422745661302046\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[261] Batch[0] avg_epoch_loss=2.091267\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.091266632080078\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] Epoch[261] Batch[5] avg_epoch_loss=2.150998\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.150997757911682\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] Epoch[261] Batch [5]#011Speed: 2211.41 samples/sec#011loss=2.150998\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] Epoch[261] Batch[10] avg_epoch_loss=2.092135\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=2.021500062942505\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] Epoch[261] Batch [10]#011Speed: 2094.69 samples/sec#011loss=2.021500\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747844494.6476994, \"EndTime\": 1747844495.5666869, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.7374114990234, \"count\": 1, \"min\": 918.7374114990234, \"max\": 918.7374114990234}}}\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1448.592753894705 records/second\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 65.5 % of epochs\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=261, train loss <loss>=2.0921351692893286\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] Epoch[262] Batch[0] avg_epoch_loss=2.094076\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.094076156616211\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] Epoch[262] Batch[5] avg_epoch_loss=2.173132\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.1731321016947427\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] Epoch[262] Batch [5]#011Speed: 2134.19 samples/sec#011loss=2.173132\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] Epoch[262] Batch[10] avg_epoch_loss=2.203665\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=2.240303468704224\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] Epoch[262] Batch [10]#011Speed: 2022.95 samples/sec#011loss=2.240303\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844495.5667436, \"EndTime\": 1747844496.5047197, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.7350807189941, \"count\": 1, \"min\": 937.7350807189941, \"max\": 937.7350807189941}}}\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.460478527676 records/second\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 65.75 % of epochs\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.203664541244507\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] Epoch[263] Batch[0] avg_epoch_loss=2.182294\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.1822938919067383\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] Epoch[263] Batch[5] avg_epoch_loss=2.225466\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.2254664500554404\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] Epoch[263] Batch [5]#011Speed: 1983.36 samples/sec#011loss=2.225466\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] Epoch[263] Batch[10] avg_epoch_loss=2.191238\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=263, batch=10 train loss <loss>=2.1501638412475588\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] Epoch[263] Batch [10]#011Speed: 2034.28 samples/sec#011loss=2.150164\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747844496.5047731, \"EndTime\": 1747844497.46129, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.2332630157471, \"count\": 1, \"min\": 956.2332630157471, \"max\": 956.2332630157471}}}\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.486302348315 records/second\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 66.0 % of epochs\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=263, train loss <loss>=2.1912379915064033\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] Epoch[264] Batch[0] avg_epoch_loss=2.172250\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.1722500324249268\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[264] Batch[5] avg_epoch_loss=2.117030\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.1170299450556436\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[264] Batch [5]#011Speed: 2138.26 samples/sec#011loss=2.117030\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[264] Batch[10] avg_epoch_loss=2.169096\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=2.2315754652023316\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[264] Batch [10]#011Speed: 2140.87 samples/sec#011loss=2.231575\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747844497.461346, \"EndTime\": 1747844498.3798273, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.1814193725586, \"count\": 1, \"min\": 918.1814193725586, \"max\": 918.1814193725586}}}\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1448.382343853775 records/second\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 66.25 % of epochs\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.1690960905768653\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[265] Batch[0] avg_epoch_loss=2.111740\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.1117403507232666\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[265] Batch[5] avg_epoch_loss=2.069481\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.069481094678243\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[265] Batch [5]#011Speed: 2166.23 samples/sec#011loss=2.069481\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] Epoch[265] Batch[10] avg_epoch_loss=2.090607\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=2.1159587860107423\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] Epoch[265] Batch [10]#011Speed: 2049.65 samples/sec#011loss=2.115959\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747844498.3798835, \"EndTime\": 1747844499.3068752, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.7237186431885, \"count\": 1, \"min\": 926.7237186431885, \"max\": 926.7237186431885}}}\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1463.086770733409 records/second\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 66.5 % of epochs\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.0906073180111973\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] Epoch[266] Batch[0] avg_epoch_loss=2.046064\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.0460641384124756\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] Epoch[266] Batch[5] avg_epoch_loss=2.055419\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.055418531099955\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] Epoch[266] Batch [5]#011Speed: 2204.83 samples/sec#011loss=2.055419\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] Epoch[266] Batch[10] avg_epoch_loss=2.050448\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=2.044483518600464\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] Epoch[266] Batch [10]#011Speed: 2052.39 samples/sec#011loss=2.044484\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747844499.3069305, \"EndTime\": 1747844500.2312229, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.0367412567139, \"count\": 1, \"min\": 924.0367412567139, \"max\": 924.0367412567139}}}\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1440.2892188935098 records/second\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 66.75 % of epochs\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.0504480708729136\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] Epoch[267] Batch[0] avg_epoch_loss=2.075765\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.0757651329040527\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] Epoch[267] Batch[5] avg_epoch_loss=2.011019\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.0110191305478415\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] Epoch[267] Batch [5]#011Speed: 2145.20 samples/sec#011loss=2.011019\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] Epoch[267] Batch[10] avg_epoch_loss=2.057787\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=2.113909292221069\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] Epoch[267] Batch [10]#011Speed: 1966.30 samples/sec#011loss=2.113909\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747844500.231279, \"EndTime\": 1747844501.17951, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.9801654815674, \"count\": 1, \"min\": 947.9801654815674, \"max\": 947.9801654815674}}}\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1401.8000885205006 records/second\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 67.0 % of epochs\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.057787385853854\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] Epoch[268] Batch[0] avg_epoch_loss=2.007273\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.0072731971740723\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] Epoch[268] Batch[5] avg_epoch_loss=2.023583\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.023582677046458\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] Epoch[268] Batch [5]#011Speed: 2160.88 samples/sec#011loss=2.023583\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] processed a total of 1250 examples\n",
      "#metrics {\"StartTime\": 1747844501.179569, \"EndTime\": 1747844502.040682, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 860.8617782592773, \"count\": 1, \"min\": 860.8617782592773, \"max\": 860.8617782592773}}}\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1451.8769185609392 records/second\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 67.25 % of epochs\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.042870056629181\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] Epoch[269] Batch[0] avg_epoch_loss=1.988962\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=1.9889622926712036\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] Epoch[269] Batch[5] avg_epoch_loss=2.039282\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=2.0392818450927734\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] Epoch[269] Batch [5]#011Speed: 2145.87 samples/sec#011loss=2.039282\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] Epoch[269] Batch[10] avg_epoch_loss=2.028661\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=269, batch=10 train loss <loss>=2.0159154891967774\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] Epoch[269] Batch [10]#011Speed: 2219.38 samples/sec#011loss=2.015915\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747844502.0407443, \"EndTime\": 1747844502.9539, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.8751754760742, \"count\": 1, \"min\": 912.8751754760742, \"max\": 912.8751754760742}}}\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1407.5143364743567 records/second\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 67.5 % of epochs\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=269, train loss <loss>=2.028660774230957\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] Epoch[270] Batch[0] avg_epoch_loss=2.063635\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=2.0636346340179443\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] Epoch[270] Batch[5] avg_epoch_loss=2.068144\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=2.0681439638137817\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] Epoch[270] Batch [5]#011Speed: 2236.00 samples/sec#011loss=2.068144\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] Epoch[270] Batch[10] avg_epoch_loss=2.095536\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=2.128405809402466\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] Epoch[270] Batch [10]#011Speed: 2040.54 samples/sec#011loss=2.128406\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747844502.953955, \"EndTime\": 1747844503.8727028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.5035228729248, \"count\": 1, \"min\": 918.5035228729248, \"max\": 918.5035228729248}}}\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1453.3194907019044 records/second\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 67.75 % of epochs\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=270, train loss <loss>=2.095535711808638\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] Epoch[271] Batch[0] avg_epoch_loss=2.081211\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=2.0812106132507324\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] Epoch[271] Batch[5] avg_epoch_loss=2.050624\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=2.050623973210653\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] Epoch[271] Batch [5]#011Speed: 2203.10 samples/sec#011loss=2.050624\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] Epoch[271] Batch[10] avg_epoch_loss=2.047355\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=271, batch=10 train loss <loss>=2.0434326410293577\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] Epoch[271] Batch [10]#011Speed: 2057.72 samples/sec#011loss=2.043433\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747844503.8727589, \"EndTime\": 1747844504.7900245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.0253276824951, \"count\": 1, \"min\": 917.0253276824951, \"max\": 917.0253276824951}}}\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1482.9153694333352 records/second\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 68.0 % of epochs\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=271, train loss <loss>=2.0473551858555186\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] Epoch[272] Batch[0] avg_epoch_loss=2.062631\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=2.062631368637085\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] Epoch[272] Batch[5] avg_epoch_loss=2.049751\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=2.0497512022654214\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] Epoch[272] Batch [5]#011Speed: 2175.81 samples/sec#011loss=2.049751\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] Epoch[272] Batch[10] avg_epoch_loss=2.061618\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=2.075857639312744\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] Epoch[272] Batch [10]#011Speed: 2016.70 samples/sec#011loss=2.075858\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747844504.7900841, \"EndTime\": 1747844505.725321, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.9985122680664, \"count\": 1, \"min\": 934.9985122680664, \"max\": 934.9985122680664}}}\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1459.7643459237843 records/second\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 68.25 % of epochs\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=272, train loss <loss>=2.061617764559659\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[273] Batch[0] avg_epoch_loss=2.013784\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=2.013784408569336\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[273] Batch[5] avg_epoch_loss=2.027751\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=2.0277512470881143\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[273] Batch [5]#011Speed: 2226.49 samples/sec#011loss=2.027751\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[273] Batch[10] avg_epoch_loss=1.997438\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=273, batch=10 train loss <loss>=1.9610623359680175\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[273] Batch [10]#011Speed: 2124.11 samples/sec#011loss=1.961062\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747844505.725378, \"EndTime\": 1747844506.635154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.5268249511719, \"count\": 1, \"min\": 909.5268249511719, \"max\": 909.5268249511719}}}\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1432.4729895248092 records/second\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 68.5 % of epochs\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=273, train loss <loss>=1.9974381056698887\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[274] Batch[0] avg_epoch_loss=1.934196\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=1.9341957569122314\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] Epoch[274] Batch[5] avg_epoch_loss=2.043501\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=2.0435009002685547\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] Epoch[274] Batch [5]#011Speed: 2154.11 samples/sec#011loss=2.043501\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] Epoch[274] Batch[10] avg_epoch_loss=2.043374\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=274, batch=10 train loss <loss>=2.0432215452194216\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] Epoch[274] Batch [10]#011Speed: 2101.18 samples/sec#011loss=2.043222\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747844506.635214, \"EndTime\": 1747844507.559697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.2210388183594, \"count\": 1, \"min\": 924.2210388183594, \"max\": 924.2210388183594}}}\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.5944147865976 records/second\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 68.75 % of epochs\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=274, train loss <loss>=2.0433739207007666\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] Epoch[275] Batch[0] avg_epoch_loss=2.001681\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=2.001681089401245\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] Epoch[275] Batch[5] avg_epoch_loss=2.102991\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=2.102990984916687\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] Epoch[275] Batch [5]#011Speed: 2112.42 samples/sec#011loss=2.102991\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] processed a total of 1272 examples\n",
      "#metrics {\"StartTime\": 1747844507.5597517, \"EndTime\": 1747844508.4212089, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 861.2117767333984, \"count\": 1, \"min\": 861.2117767333984, \"max\": 861.2117767333984}}}\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1476.8173220251435 records/second\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 69.0 % of epochs\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=275, train loss <loss>=2.091800808906555\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] Epoch[276] Batch[0] avg_epoch_loss=2.097358\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=2.097357749938965\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[276] Batch[5] avg_epoch_loss=2.061634\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=2.0616343021392822\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[276] Batch [5]#011Speed: 2242.67 samples/sec#011loss=2.061634\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[276] Batch[10] avg_epoch_loss=2.119225\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=2.1883330583572387\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[276] Batch [10]#011Speed: 2028.87 samples/sec#011loss=2.188333\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] processed a total of 1382 examples\n",
      "#metrics {\"StartTime\": 1747844508.4212794, \"EndTime\": 1747844509.338387, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.8002605438232, \"count\": 1, \"min\": 916.8002605438232, \"max\": 916.8002605438232}}}\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1507.2853622017883 records/second\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 69.25 % of epochs\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=276, train loss <loss>=2.119224645874717\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[277] Batch[0] avg_epoch_loss=2.048753\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=2.048752784729004\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[277] Batch[5] avg_epoch_loss=2.033185\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=2.0331848859786987\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[277] Batch [5]#011Speed: 2155.88 samples/sec#011loss=2.033185\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747844509.33844, \"EndTime\": 1747844510.1943762, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 855.663537979126, \"count\": 1, \"min\": 855.663537979126, \"max\": 855.663537979126}}}\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1489.912258584341 records/second\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 69.5 % of epochs\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=277, train loss <loss>=2.0188499689102173\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] Epoch[278] Batch[0] avg_epoch_loss=1.969388\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=1.9693877696990967\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] Epoch[278] Batch[5] avg_epoch_loss=2.031577\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=2.031576673189799\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] Epoch[278] Batch [5]#011Speed: 2142.57 samples/sec#011loss=2.031577\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Epoch[278] Batch[10] avg_epoch_loss=1.956911\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=1.8673123836517334\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Epoch[278] Batch [10]#011Speed: 2121.15 samples/sec#011loss=1.867312\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844510.1944368, \"EndTime\": 1747844511.1165407, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.771764755249, \"count\": 1, \"min\": 921.771764755249, \"max\": 921.771764755249}}}\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1399.3499005701988 records/second\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 69.75 % of epochs\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=278, train loss <loss>=1.9569110870361328\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_65dd1f25-8463-4a5b-bbd3-1f348e9e4723-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844511.1165977, \"EndTime\": 1747844511.1273384, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.480403900146484, \"count\": 1, \"min\": 10.480403900146484, \"max\": 10.480403900146484}}}\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Epoch[279] Batch[0] avg_epoch_loss=2.061907\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=2.0619072914123535\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Epoch[279] Batch[5] avg_epoch_loss=2.049469\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=2.049468755722046\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Epoch[279] Batch [5]#011Speed: 2161.30 samples/sec#011loss=2.049469\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[279] Batch[10] avg_epoch_loss=2.038807\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=2.026011848449707\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[279] Batch [10]#011Speed: 2030.85 samples/sec#011loss=2.026012\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747844511.1273825, \"EndTime\": 1747844512.0636399, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.2053871154785, \"count\": 1, \"min\": 936.2053871154785, \"max\": 936.2053871154785}}}\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1380.974965279776 records/second\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 70.0 % of epochs\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=279, train loss <loss>=2.03880652514371\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[280] Batch[0] avg_epoch_loss=2.087935\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=2.087934732437134\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[280] Batch[5] avg_epoch_loss=2.069880\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=2.0698802868525186\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[280] Batch [5]#011Speed: 2179.53 samples/sec#011loss=2.069880\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[280] Batch[10] avg_epoch_loss=2.072417\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=2.075461220741272\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[280] Batch [10]#011Speed: 2181.11 samples/sec#011loss=2.075461\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844512.0636952, \"EndTime\": 1747844512.9912941, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.3598194122314, \"count\": 1, \"min\": 927.3598194122314, \"max\": 927.3598194122314}}}\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1390.869888108879 records/second\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 70.25 % of epochs\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=280, train loss <loss>=2.07241707498377\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] Epoch[281] Batch[0] avg_epoch_loss=2.209831\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=2.2098305225372314\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] Epoch[281] Batch[5] avg_epoch_loss=2.065507\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=2.0655071139335632\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] Epoch[281] Batch [5]#011Speed: 2201.85 samples/sec#011loss=2.065507\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] Epoch[281] Batch[10] avg_epoch_loss=1.974826\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=281, batch=10 train loss <loss>=1.8660086512565612\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] Epoch[281] Batch [10]#011Speed: 2166.90 samples/sec#011loss=1.866009\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844512.991385, \"EndTime\": 1747844513.9006913, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.0206623077393, \"count\": 1, \"min\": 909.0206623077393, \"max\": 909.0206623077393}}}\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1426.6774142789106 records/second\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 70.5 % of epochs\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=281, train loss <loss>=1.974825994534926\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] Epoch[282] Batch[0] avg_epoch_loss=2.123526\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=2.123525857925415\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] Epoch[282] Batch[5] avg_epoch_loss=2.077568\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=2.077568451563517\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] Epoch[282] Batch [5]#011Speed: 2204.18 samples/sec#011loss=2.077568\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] Epoch[282] Batch[10] avg_epoch_loss=2.054749\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=282, batch=10 train loss <loss>=2.027366304397583\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] Epoch[282] Batch [10]#011Speed: 2033.97 samples/sec#011loss=2.027366\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844513.9007478, \"EndTime\": 1747844514.833737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.7487945556641, \"count\": 1, \"min\": 932.7487945556641, \"max\": 932.7487945556641}}}\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1418.2596302650907 records/second\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 70.75 % of epochs\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=282, train loss <loss>=2.05474929376082\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] Epoch[283] Batch[0] avg_epoch_loss=2.091890\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=2.0918898582458496\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] Epoch[283] Batch[5] avg_epoch_loss=2.097097\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=2.097096562385559\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] Epoch[283] Batch [5]#011Speed: 2161.13 samples/sec#011loss=2.097097\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] Epoch[283] Batch[10] avg_epoch_loss=2.130858\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=283, batch=10 train loss <loss>=2.171372413635254\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] Epoch[283] Batch [10]#011Speed: 1945.73 samples/sec#011loss=2.171372\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747844514.833795, \"EndTime\": 1747844515.7835844, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 949.5463371276855, \"count\": 1, \"min\": 949.5463371276855, \"max\": 949.5463371276855}}}\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.295098039462 records/second\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 71.0 % of epochs\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=283, train loss <loss>=2.130858312953602\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] Epoch[284] Batch[0] avg_epoch_loss=2.001824\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=2.001824140548706\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] Epoch[284] Batch[5] avg_epoch_loss=2.029810\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=2.0298101902008057\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] Epoch[284] Batch [5]#011Speed: 2190.98 samples/sec#011loss=2.029810\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] Epoch[284] Batch[10] avg_epoch_loss=2.029354\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=284, batch=10 train loss <loss>=2.02880597114563\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] Epoch[284] Batch [10]#011Speed: 2032.96 samples/sec#011loss=2.028806\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747844515.7836401, \"EndTime\": 1747844516.7045734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.6669330596924, \"count\": 1, \"min\": 920.6669330596924, \"max\": 920.6669330596924}}}\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.7095675122666 records/second\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 71.25 % of epochs\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=284, train loss <loss>=2.0293537269939077\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[285] Batch[0] avg_epoch_loss=2.079565\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=2.0795648097991943\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[285] Batch[5] avg_epoch_loss=2.094036\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=2.094035506248474\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[285] Batch [5]#011Speed: 2108.82 samples/sec#011loss=2.094036\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[285] Batch[10] avg_epoch_loss=2.096006\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=2.098370981216431\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[285] Batch [10]#011Speed: 2050.70 samples/sec#011loss=2.098371\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747844516.7046316, \"EndTime\": 1747844517.6455595, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.6795501708984, \"count\": 1, \"min\": 940.6795501708984, \"max\": 940.6795501708984}}}\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1361.6531075038497 records/second\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 71.5 % of epochs\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=285, train loss <loss>=2.0960061766884546\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[286] Batch[0] avg_epoch_loss=2.030232\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=2.0302324295043945\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] Epoch[286] Batch[5] avg_epoch_loss=2.023871\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=2.023870607217153\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] Epoch[286] Batch [5]#011Speed: 2211.70 samples/sec#011loss=2.023871\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] Epoch[286] Batch[10] avg_epoch_loss=2.054100\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=286, batch=10 train loss <loss>=2.0903759479522703\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] Epoch[286] Batch [10]#011Speed: 2142.79 samples/sec#011loss=2.090376\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747844517.645618, \"EndTime\": 1747844518.5569959, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.0972881317139, \"count\": 1, \"min\": 911.0972881317139, \"max\": 911.0972881317139}}}\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.1127736368721 records/second\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 71.75 % of epochs\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=286, train loss <loss>=2.0541003075512974\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] Epoch[287] Batch[0] avg_epoch_loss=2.272309\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=2.2723093032836914\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] Epoch[287] Batch[5] avg_epoch_loss=2.287042\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=2.2870421012242637\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] Epoch[287] Batch [5]#011Speed: 2162.70 samples/sec#011loss=2.287042\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] Epoch[287] Batch[10] avg_epoch_loss=2.326892\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=2.3747119903564453\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] Epoch[287] Batch [10]#011Speed: 2088.24 samples/sec#011loss=2.374712\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747844518.5570514, \"EndTime\": 1747844519.4828715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.574541091919, \"count\": 1, \"min\": 925.574541091919, \"max\": 925.574541091919}}}\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.5271182158099 records/second\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 72.0 % of epochs\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=287, train loss <loss>=2.3268920508298008\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] Epoch[288] Batch[0] avg_epoch_loss=2.255603\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=2.255603313446045\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] Epoch[288] Batch[5] avg_epoch_loss=2.209161\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=2.2091609636942544\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] Epoch[288] Batch [5]#011Speed: 2168.05 samples/sec#011loss=2.209161\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] processed a total of 1271 examples\n",
      "#metrics {\"StartTime\": 1747844519.4829292, \"EndTime\": 1747844520.3461144, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 862.940788269043, \"count\": 1, \"min\": 862.940788269043, \"max\": 862.940788269043}}}\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.7125915514125 records/second\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 72.25 % of epochs\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=288, train loss <loss>=2.1523969173431396\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] Epoch[289] Batch[0] avg_epoch_loss=2.105288\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=2.10528826713562\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] Epoch[289] Batch[5] avg_epoch_loss=2.049546\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=2.0495463609695435\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] Epoch[289] Batch [5]#011Speed: 2121.58 samples/sec#011loss=2.049546\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] Epoch[289] Batch[10] avg_epoch_loss=2.002361\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=289, batch=10 train loss <loss>=1.9457375526428222\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] Epoch[289] Batch [10]#011Speed: 2071.42 samples/sec#011loss=1.945738\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747844520.3461761, \"EndTime\": 1747844521.287912, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.4143562316895, \"count\": 1, \"min\": 941.4143562316895, \"max\": 941.4143562316895}}}\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1378.6480220291694 records/second\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 72.5 % of epochs\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=289, train loss <loss>=2.002360539002852\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] Epoch[290] Batch[0] avg_epoch_loss=2.005005\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=2.005004644393921\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] Epoch[290] Batch[5] avg_epoch_loss=2.052449\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=2.052448829015096\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] Epoch[290] Batch [5]#011Speed: 2085.88 samples/sec#011loss=2.052449\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] Epoch[290] Batch[10] avg_epoch_loss=2.076067\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=290, batch=10 train loss <loss>=2.1044090747833253\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] Epoch[290] Batch [10]#011Speed: 2037.08 samples/sec#011loss=2.104409\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844521.2879705, \"EndTime\": 1747844522.2581716, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 969.9516296386719, \"count\": 1, \"min\": 969.9516296386719, \"max\": 969.9516296386719}}}\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1358.7114165484245 records/second\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 72.75 % of epochs\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=290, train loss <loss>=2.0760671225461094\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] Epoch[291] Batch[0] avg_epoch_loss=2.174697\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=2.174697160720825\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] Epoch[291] Batch[5] avg_epoch_loss=2.043999\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=2.043999433517456\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] Epoch[291] Batch [5]#011Speed: 2211.62 samples/sec#011loss=2.043999\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] Epoch[291] Batch[10] avg_epoch_loss=2.030773\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=291, batch=10 train loss <loss>=2.014902353286743\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] Epoch[291] Batch [10]#011Speed: 2147.93 samples/sec#011loss=2.014902\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747844522.2582288, \"EndTime\": 1747844523.165221, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.7420959472656, \"count\": 1, \"min\": 906.7420959472656, \"max\": 906.7420959472656}}}\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1474.3681829212278 records/second\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 73.0 % of epochs\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=291, train loss <loss>=2.030773487958041\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] Epoch[292] Batch[0] avg_epoch_loss=1.956750\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=1.9567500352859497\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] Epoch[292] Batch[5] avg_epoch_loss=1.971801\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=1.9718005855878193\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] Epoch[292] Batch [5]#011Speed: 2139.09 samples/sec#011loss=1.971801\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] processed a total of 1269 examples\n",
      "#metrics {\"StartTime\": 1747844523.1652792, \"EndTime\": 1747844524.0216346, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 856.069803237915, \"count\": 1, \"min\": 856.069803237915, \"max\": 856.069803237915}}}\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1482.1852716351575 records/second\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 73.25 % of epochs\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=292, train loss <loss>=1.9699634552001952\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] Epoch[293] Batch[0] avg_epoch_loss=2.018970\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=2.018970489501953\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] Epoch[293] Batch[5] avg_epoch_loss=1.989670\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=1.9896697004636128\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] Epoch[293] Batch [5]#011Speed: 2194.38 samples/sec#011loss=1.989670\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] Epoch[293] Batch[10] avg_epoch_loss=2.028575\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=293, batch=10 train loss <loss>=2.0752606868743895\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] Epoch[293] Batch [10]#011Speed: 2097.82 samples/sec#011loss=2.075261\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747844524.0216937, \"EndTime\": 1747844524.9609344, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.9538764953613, \"count\": 1, \"min\": 938.9538764953613, \"max\": 938.9538764953613}}}\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.8595134487493 records/second\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 73.5 % of epochs\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=293, train loss <loss>=2.0285746942866933\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] Epoch[294] Batch[0] avg_epoch_loss=2.025587\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=2.0255866050720215\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] Epoch[294] Batch[5] avg_epoch_loss=2.026751\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=2.0267507632573447\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] Epoch[294] Batch [5]#011Speed: 2166.26 samples/sec#011loss=2.026751\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] Epoch[294] Batch[10] avg_epoch_loss=2.043778\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=294, batch=10 train loss <loss>=2.0642106533050537\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] Epoch[294] Batch [10]#011Speed: 2101.87 samples/sec#011loss=2.064211\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747844524.960993, \"EndTime\": 1747844525.887616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.3420104980469, \"count\": 1, \"min\": 926.3420104980469, \"max\": 926.3420104980469}}}\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1404.318401655703 records/second\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 73.75 % of epochs\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=294, train loss <loss>=2.0437779860063032\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] Epoch[295] Batch[0] avg_epoch_loss=1.979458\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=295, batch=0 train loss <loss>=1.979457974433899\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] Epoch[295] Batch[5] avg_epoch_loss=2.060963\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=295, batch=5 train loss <loss>=2.060962696870168\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] Epoch[295] Batch [5]#011Speed: 2169.36 samples/sec#011loss=2.060963\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] Epoch[295] Batch[10] avg_epoch_loss=2.109374\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=295, batch=10 train loss <loss>=2.1674670696258547\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] Epoch[295] Batch [10]#011Speed: 2174.13 samples/sec#011loss=2.167467\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747844525.8876739, \"EndTime\": 1747844526.8001351, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.168025970459, \"count\": 1, \"min\": 912.168025970459, \"max\": 912.168025970459}}}\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1415.1762588630702 records/second\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 74.0 % of epochs\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=295, train loss <loss>=2.10937377539548\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] Epoch[296] Batch[0] avg_epoch_loss=2.145722\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=296, batch=0 train loss <loss>=2.1457221508026123\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] Epoch[296] Batch[5] avg_epoch_loss=2.133498\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=296, batch=5 train loss <loss>=2.133498469988505\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] Epoch[296] Batch [5]#011Speed: 2137.30 samples/sec#011loss=2.133498\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] Epoch[296] Batch[10] avg_epoch_loss=2.123422\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=296, batch=10 train loss <loss>=2.111329364776611\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] Epoch[296] Batch [10]#011Speed: 1976.66 samples/sec#011loss=2.111329\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747844526.8001943, \"EndTime\": 1747844527.7443001, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.8066482543945, \"count\": 1, \"min\": 943.8066482543945, \"max\": 943.8066482543945}}}\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1441.9029767353513 records/second\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 74.25 % of epochs\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=296, train loss <loss>=2.1234216039830986\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[297] Batch[0] avg_epoch_loss=2.233529\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=297, batch=0 train loss <loss>=2.2335288524627686\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[297] Batch[5] avg_epoch_loss=2.200092\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=297, batch=5 train loss <loss>=2.2000917196273804\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[297] Batch [5]#011Speed: 2167.71 samples/sec#011loss=2.200092\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[297] Batch[10] avg_epoch_loss=2.163770\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=297, batch=10 train loss <loss>=2.1201844692230223\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[297] Batch [10]#011Speed: 2148.91 samples/sec#011loss=2.120184\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844527.7443562, \"EndTime\": 1747844528.6606796, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.0811901092529, \"count\": 1, \"min\": 916.0811901092529, \"max\": 916.0811901092529}}}\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1444.06472374677 records/second\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 74.5 % of epochs\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=297, train loss <loss>=2.163770242170854\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[298] Batch[0] avg_epoch_loss=2.063551\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=298, batch=0 train loss <loss>=2.0635509490966797\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] Epoch[298] Batch[5] avg_epoch_loss=2.046894\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=298, batch=5 train loss <loss>=2.046894371509552\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] Epoch[298] Batch [5]#011Speed: 2193.75 samples/sec#011loss=2.046894\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] Epoch[298] Batch[10] avg_epoch_loss=2.025295\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=298, batch=10 train loss <loss>=1.9993764877319335\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] Epoch[298] Batch [10]#011Speed: 2017.14 samples/sec#011loss=1.999376\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747844528.660735, \"EndTime\": 1747844529.5834246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.4421977996826, \"count\": 1, \"min\": 922.4421977996826, \"max\": 922.4421977996826}}}\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1469.8014871998168 records/second\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 74.75 % of epochs\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=298, train loss <loss>=2.0252953334288164\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] Epoch[299] Batch[0] avg_epoch_loss=2.083143\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=299, batch=0 train loss <loss>=2.0831429958343506\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] Epoch[299] Batch[5] avg_epoch_loss=2.059275\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=299, batch=5 train loss <loss>=2.0592748721440635\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] Epoch[299] Batch [5]#011Speed: 2201.29 samples/sec#011loss=2.059275\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] Epoch[299] Batch[10] avg_epoch_loss=2.024920\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=299, batch=10 train loss <loss>=1.983694863319397\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] Epoch[299] Batch [10]#011Speed: 2003.55 samples/sec#011loss=1.983695\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844529.5835195, \"EndTime\": 1747844530.5163586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.5780868530273, \"count\": 1, \"min\": 932.5780868530273, \"max\": 932.5780868530273}}}\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.7293447948916 records/second\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 75.0 % of epochs\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=299, train loss <loss>=2.0249203226783057\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] Epoch[300] Batch[0] avg_epoch_loss=2.047976\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=300, batch=0 train loss <loss>=2.047976493835449\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] Epoch[300] Batch[5] avg_epoch_loss=2.041773\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=300, batch=5 train loss <loss>=2.0417732993761697\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] Epoch[300] Batch [5]#011Speed: 2150.86 samples/sec#011loss=2.041773\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] Epoch[300] Batch[10] avg_epoch_loss=2.055168\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=300, batch=10 train loss <loss>=2.0712414741516114\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] Epoch[300] Batch [10]#011Speed: 2038.49 samples/sec#011loss=2.071241\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747844530.516414, \"EndTime\": 1747844531.4482005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.541919708252, \"count\": 1, \"min\": 931.541919708252, \"max\": 931.541919708252}}}\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1443.7082006196235 records/second\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 75.25 % of epochs\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=300, train loss <loss>=2.0551679242740977\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] Epoch[301] Batch[0] avg_epoch_loss=1.944075\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=301, batch=0 train loss <loss>=1.9440745115280151\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[301] Batch[5] avg_epoch_loss=1.928944\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=301, batch=5 train loss <loss>=1.9289435942967732\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[301] Batch [5]#011Speed: 2126.38 samples/sec#011loss=1.928944\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[301] Batch[10] avg_epoch_loss=1.971324\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=301, batch=10 train loss <loss>=2.0221798419952393\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[301] Batch [10]#011Speed: 2069.68 samples/sec#011loss=2.022180\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747844531.4482589, \"EndTime\": 1747844532.3792346, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.7222366333008, \"count\": 1, \"min\": 930.7222366333008, \"max\": 930.7222366333008}}}\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1458.9544898366398 records/second\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 75.5 % of epochs\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=301, train loss <loss>=1.971323706886985\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[302] Batch[0] avg_epoch_loss=1.976236\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=302, batch=0 train loss <loss>=1.9762358665466309\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[302] Batch[5] avg_epoch_loss=1.983432\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=302, batch=5 train loss <loss>=1.9834323525428772\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[302] Batch [5]#011Speed: 2245.66 samples/sec#011loss=1.983432\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] processed a total of 1256 examples\n",
      "#metrics {\"StartTime\": 1747844532.379289, \"EndTime\": 1747844533.2214305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 841.893196105957, \"count\": 1, \"min\": 841.893196105957, \"max\": 841.893196105957}}}\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1491.6856025275754 records/second\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 75.75 % of epochs\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=302, train loss <loss>=2.00654559135437\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] Epoch[303] Batch[0] avg_epoch_loss=1.954631\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=303, batch=0 train loss <loss>=1.954630970954895\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] Epoch[303] Batch[5] avg_epoch_loss=1.975633\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=303, batch=5 train loss <loss>=1.9756327867507935\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] Epoch[303] Batch [5]#011Speed: 2229.87 samples/sec#011loss=1.975633\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Epoch[303] Batch[10] avg_epoch_loss=1.954375\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=303, batch=10 train loss <loss>=1.9288663864135742\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Epoch[303] Batch [10]#011Speed: 2128.71 samples/sec#011loss=1.928866\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844533.221508, \"EndTime\": 1747844534.1283586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.5582752227783, \"count\": 1, \"min\": 906.5582752227783, \"max\": 906.5582752227783}}}\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1473.5695663012802 records/second\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 76.0 % of epochs\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=303, train loss <loss>=1.9543753320520574\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_e9b93e35-329d-4a77-9316-6b9f78f24356-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844534.1284142, \"EndTime\": 1747844534.1393514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.672330856323242, \"count\": 1, \"min\": 10.672330856323242, \"max\": 10.672330856323242}}}\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Epoch[304] Batch[0] avg_epoch_loss=1.897976\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=304, batch=0 train loss <loss>=1.8979763984680176\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Epoch[304] Batch[5] avg_epoch_loss=2.024638\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=304, batch=5 train loss <loss>=2.0246376593907676\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Epoch[304] Batch [5]#011Speed: 2186.74 samples/sec#011loss=2.024638\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[304] Batch[10] avg_epoch_loss=2.074674\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=304, batch=10 train loss <loss>=2.1347182273864744\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[304] Batch [10]#011Speed: 2107.12 samples/sec#011loss=2.134718\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747844534.1394017, \"EndTime\": 1747844535.0618217, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.36328125, \"count\": 1, \"min\": 922.36328125, \"max\": 922.36328125}}}\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1399.540261637449 records/second\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 76.25 % of epochs\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=304, train loss <loss>=2.074674281206998\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[305] Batch[0] avg_epoch_loss=2.171135\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=305, batch=0 train loss <loss>=2.171135425567627\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[305] Batch[5] avg_epoch_loss=2.119835\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=305, batch=5 train loss <loss>=2.119835158189138\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[305] Batch [5]#011Speed: 2164.84 samples/sec#011loss=2.119835\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[305] Batch[10] avg_epoch_loss=2.142076\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=305, batch=10 train loss <loss>=2.1687654495239257\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[305] Batch [10]#011Speed: 2017.76 samples/sec#011loss=2.168765\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747844535.061877, \"EndTime\": 1747844535.9936774, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.5555095672607, \"count\": 1, \"min\": 931.5555095672607, \"max\": 931.5555095672607}}}\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1428.662839407378 records/second\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 76.5 % of epochs\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=305, train loss <loss>=2.1420761997049507\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] Epoch[306] Batch[0] avg_epoch_loss=2.242744\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=306, batch=0 train loss <loss>=2.242743730545044\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] Epoch[306] Batch[5] avg_epoch_loss=2.232954\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=306, batch=5 train loss <loss>=2.2329540650049844\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] Epoch[306] Batch [5]#011Speed: 2166.67 samples/sec#011loss=2.232954\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] Epoch[306] Batch[10] avg_epoch_loss=2.106814\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=306, batch=10 train loss <loss>=1.955445647239685\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] Epoch[306] Batch [10]#011Speed: 2054.74 samples/sec#011loss=1.955446\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844535.9937336, \"EndTime\": 1747844536.9229136, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.9026260375977, \"count\": 1, \"min\": 928.9026260375977, \"max\": 928.9026260375977}}}\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1416.5989290759173 records/second\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 76.75 % of epochs\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=306, train loss <loss>=2.1068138751116665\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] Epoch[307] Batch[0] avg_epoch_loss=2.151961\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=307, batch=0 train loss <loss>=2.151960849761963\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] Epoch[307] Batch[5] avg_epoch_loss=2.075274\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=307, batch=5 train loss <loss>=2.075273950894674\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] Epoch[307] Batch [5]#011Speed: 2024.54 samples/sec#011loss=2.075274\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] Epoch[307] Batch[10] avg_epoch_loss=2.038361\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=307, batch=10 train loss <loss>=1.9940653324127198\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] Epoch[307] Batch [10]#011Speed: 2105.99 samples/sec#011loss=1.994065\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844536.9229693, \"EndTime\": 1747844537.866043, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.8248405456543, \"count\": 1, \"min\": 942.8248405456543, \"max\": 942.8248405456543}}}\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1405.2250288190523 records/second\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 77.0 % of epochs\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=307, train loss <loss>=2.0383609424937856\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] Epoch[308] Batch[0] avg_epoch_loss=1.949635\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=308, batch=0 train loss <loss>=1.9496345520019531\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] Epoch[308] Batch[5] avg_epoch_loss=1.973885\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=308, batch=5 train loss <loss>=1.9738854765892029\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] Epoch[308] Batch [5]#011Speed: 2130.10 samples/sec#011loss=1.973885\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] Epoch[308] Batch[10] avg_epoch_loss=2.003941\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=308, batch=10 train loss <loss>=2.0400076627731325\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] Epoch[308] Batch [10]#011Speed: 2190.94 samples/sec#011loss=2.040008\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747844537.866099, \"EndTime\": 1747844538.7836885, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.341947555542, \"count\": 1, \"min\": 917.341947555542, \"max\": 917.341947555542}}}\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1396.2984624068533 records/second\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 77.25 % of epochs\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=308, train loss <loss>=2.0039410157637163\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] Epoch[309] Batch[0] avg_epoch_loss=2.095531\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=309, batch=0 train loss <loss>=2.095531463623047\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] Epoch[309] Batch[5] avg_epoch_loss=2.018467\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=309, batch=5 train loss <loss>=2.018466889858246\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] Epoch[309] Batch [5]#011Speed: 2178.33 samples/sec#011loss=2.018467\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] Epoch[309] Batch[10] avg_epoch_loss=2.004142\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=309, batch=10 train loss <loss>=1.9869529485702515\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] Epoch[309] Batch [10]#011Speed: 2132.95 samples/sec#011loss=1.986953\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747844538.783744, \"EndTime\": 1747844539.703094, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.1067218780518, \"count\": 1, \"min\": 919.1067218780518, \"max\": 919.1067218780518}}}\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1400.1433450338995 records/second\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 77.5 % of epochs\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=309, train loss <loss>=2.0041423710909756\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[310] Batch[0] avg_epoch_loss=2.020170\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=310, batch=0 train loss <loss>=2.020169973373413\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[310] Batch[5] avg_epoch_loss=2.008619\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=310, batch=5 train loss <loss>=2.0086193482081094\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[310] Batch [5]#011Speed: 2178.75 samples/sec#011loss=2.008619\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[310] Batch[10] avg_epoch_loss=2.003822\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=310, batch=10 train loss <loss>=1.9980658054351808\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[310] Batch [10]#011Speed: 2172.18 samples/sec#011loss=1.998066\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747844539.7031498, \"EndTime\": 1747844540.6168122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 913.4204387664795, \"count\": 1, \"min\": 913.4204387664795, \"max\": 913.4204387664795}}}\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1415.4280112623828 records/second\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 77.75 % of epochs\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=310, train loss <loss>=2.0038222833113237\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[311] Batch[0] avg_epoch_loss=1.999156\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=311, batch=0 train loss <loss>=1.9991559982299805\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] Epoch[311] Batch[5] avg_epoch_loss=2.016928\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=311, batch=5 train loss <loss>=2.016928215821584\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] Epoch[311] Batch [5]#011Speed: 2189.49 samples/sec#011loss=2.016928\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] processed a total of 1272 examples\n",
      "#metrics {\"StartTime\": 1747844540.6168685, \"EndTime\": 1747844541.475684, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 857.9583168029785, \"count\": 1, \"min\": 857.9583168029785, \"max\": 857.9583168029785}}}\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1482.435438265787 records/second\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 78.0 % of epochs\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=311, train loss <loss>=2.0079071640968325\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] Epoch[312] Batch[0] avg_epoch_loss=1.948977\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=312, batch=0 train loss <loss>=1.9489766359329224\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Epoch[312] Batch[5] avg_epoch_loss=1.974265\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=312, batch=5 train loss <loss>=1.9742645819981892\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Epoch[312] Batch [5]#011Speed: 2155.26 samples/sec#011loss=1.974265\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Epoch[312] Batch[10] avg_epoch_loss=1.931766\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=312, batch=10 train loss <loss>=1.8807667732238769\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Epoch[312] Batch [10]#011Speed: 2034.13 samples/sec#011loss=1.880767\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844541.475743, \"EndTime\": 1747844542.411455, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.4171752929688, \"count\": 1, \"min\": 935.4171752929688, \"max\": 935.4171752929688}}}\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1428.1130871008816 records/second\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 78.25 % of epochs\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=312, train loss <loss>=1.9317655780098655\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_f02184d7-5102-4f09-a7a3-36227fae0c4a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844542.4115117, \"EndTime\": 1747844542.422408, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.606527328491211, \"count\": 1, \"min\": 10.606527328491211, \"max\": 10.606527328491211}}}\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Epoch[313] Batch[0] avg_epoch_loss=1.989179\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=313, batch=0 train loss <loss>=1.989179015159607\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[313] Batch[5] avg_epoch_loss=1.938090\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=313, batch=5 train loss <loss>=1.938089907169342\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[313] Batch [5]#011Speed: 2134.85 samples/sec#011loss=1.938090\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[313] Batch[10] avg_epoch_loss=1.985537\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=313, batch=10 train loss <loss>=2.0424734115600587\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[313] Batch [10]#011Speed: 1959.54 samples/sec#011loss=2.042473\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747844542.4224563, \"EndTime\": 1747844543.374657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.1543979644775, \"count\": 1, \"min\": 952.1543979644775, \"max\": 952.1543979644775}}}\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1409.3096506968861 records/second\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 78.5 % of epochs\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=313, train loss <loss>=1.9855369546196677\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[314] Batch[0] avg_epoch_loss=1.951363\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=314, batch=0 train loss <loss>=1.9513630867004395\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[314] Batch[5] avg_epoch_loss=1.971190\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=314, batch=5 train loss <loss>=1.971190094947815\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[314] Batch [5]#011Speed: 2255.12 samples/sec#011loss=1.971190\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Epoch[314] Batch[10] avg_epoch_loss=1.873032\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=314, batch=10 train loss <loss>=1.7552432775497437\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Epoch[314] Batch [10]#011Speed: 2120.32 samples/sec#011loss=1.755243\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844543.374714, \"EndTime\": 1747844544.2794363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.350757598877, \"count\": 1, \"min\": 904.350757598877, \"max\": 904.350757598877}}}\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1450.6203502360222 records/second\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 78.75 % of epochs\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=314, train loss <loss>=1.8730324506759644\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_9df92fe5-5c10-46fa-a112-0e1e474613c7-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844544.2794962, \"EndTime\": 1747844544.2903469, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.56528091430664, \"count\": 1, \"min\": 10.56528091430664, \"max\": 10.56528091430664}}}\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Epoch[315] Batch[0] avg_epoch_loss=1.946999\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=315, batch=0 train loss <loss>=1.946998953819275\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Epoch[315] Batch[5] avg_epoch_loss=1.974433\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=315, batch=5 train loss <loss>=1.974432607491811\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Epoch[315] Batch [5]#011Speed: 2249.34 samples/sec#011loss=1.974433\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] Epoch[315] Batch[10] avg_epoch_loss=1.966270\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=315, batch=10 train loss <loss>=1.9564749956130982\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] Epoch[315] Batch [10]#011Speed: 2052.10 samples/sec#011loss=1.956475\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747844544.2903965, \"EndTime\": 1747844545.2030013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.5573635101318, \"count\": 1, \"min\": 912.5573635101318, \"max\": 912.5573635101318}}}\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1486.896949098523 records/second\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 79.0 % of epochs\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=315, train loss <loss>=1.9662700566378506\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] Epoch[316] Batch[0] avg_epoch_loss=1.991629\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=316, batch=0 train loss <loss>=1.991628646850586\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] Epoch[316] Batch[5] avg_epoch_loss=1.980418\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=316, batch=5 train loss <loss>=1.9804184238115947\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] Epoch[316] Batch [5]#011Speed: 2064.68 samples/sec#011loss=1.980418\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] Epoch[316] Batch[10] avg_epoch_loss=2.034246\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=316, batch=10 train loss <loss>=2.0988384246826173\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] Epoch[316] Batch [10]#011Speed: 1961.23 samples/sec#011loss=2.098838\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844545.203057, \"EndTime\": 1747844546.1582046, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.9038410186768, \"count\": 1, \"min\": 954.9038410186768, \"max\": 954.9038410186768}}}\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1398.974296086455 records/second\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 79.25 % of epochs\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=316, train loss <loss>=2.0342456969347866\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] Epoch[317] Batch[0] avg_epoch_loss=1.891972\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=317, batch=0 train loss <loss>=1.8919724225997925\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] Epoch[317] Batch[5] avg_epoch_loss=1.940321\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=317, batch=5 train loss <loss>=1.9403212865193684\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] Epoch[317] Batch [5]#011Speed: 2156.09 samples/sec#011loss=1.940321\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] Epoch[317] Batch[10] avg_epoch_loss=1.949080\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=317, batch=10 train loss <loss>=1.9595906496047975\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] Epoch[317] Batch [10]#011Speed: 1947.26 samples/sec#011loss=1.959591\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] processed a total of 1383 examples\n",
      "#metrics {\"StartTime\": 1747844546.1582592, \"EndTime\": 1747844547.1016502, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.1524276733398, \"count\": 1, \"min\": 943.1524276733398, \"max\": 943.1524276733398}}}\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1466.2281080859739 records/second\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 79.5 % of epochs\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=317, train loss <loss>=1.9490800879218362\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] Epoch[318] Batch[0] avg_epoch_loss=2.026574\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=318, batch=0 train loss <loss>=2.0265743732452393\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] Epoch[318] Batch[5] avg_epoch_loss=2.023883\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=318, batch=5 train loss <loss>=2.02388334274292\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] Epoch[318] Batch [5]#011Speed: 2163.53 samples/sec#011loss=2.023883\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[318] Batch[10] avg_epoch_loss=1.996456\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=318, batch=10 train loss <loss>=1.9635438203811646\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[318] Batch [10]#011Speed: 2180.88 samples/sec#011loss=1.963544\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844547.1017065, \"EndTime\": 1747844548.0189257, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.9256687164307, \"count\": 1, \"min\": 916.9256687164307, \"max\": 916.9256687164307}}}\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.745365579712 records/second\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 79.75 % of epochs\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=318, train loss <loss>=1.9964562871239402\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[319] Batch[0] avg_epoch_loss=2.347011\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=319, batch=0 train loss <loss>=2.347011089324951\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[319] Batch[5] avg_epoch_loss=2.366764\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=319, batch=5 train loss <loss>=2.366764227549235\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[319] Batch [5]#011Speed: 2085.16 samples/sec#011loss=2.366764\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[319] Batch[10] avg_epoch_loss=2.370226\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=319, batch=10 train loss <loss>=2.3743792533874513\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[319] Batch [10]#011Speed: 2133.99 samples/sec#011loss=2.374379\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844548.018982, \"EndTime\": 1747844548.947572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.3418655395508, \"count\": 1, \"min\": 928.3418655395508, \"max\": 928.3418655395508}}}\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.1505794678603 records/second\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 80.0 % of epochs\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=319, train loss <loss>=2.370225602930242\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] Epoch[320] Batch[0] avg_epoch_loss=2.181647\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=320, batch=0 train loss <loss>=2.181647300720215\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] Epoch[320] Batch[5] avg_epoch_loss=2.224921\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=320, batch=5 train loss <loss>=2.224920948346456\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] Epoch[320] Batch [5]#011Speed: 2277.04 samples/sec#011loss=2.224921\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] Epoch[320] Batch[10] avg_epoch_loss=2.280628\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=320, batch=10 train loss <loss>=2.3474770069122313\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] Epoch[320] Batch [10]#011Speed: 2082.69 samples/sec#011loss=2.347477\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747844548.947627, \"EndTime\": 1747844549.855101, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.1717262268066, \"count\": 1, \"min\": 907.1717262268066, \"max\": 907.1717262268066}}}\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1475.875993446009 records/second\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 80.25 % of epochs\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=320, train loss <loss>=2.2806282476945356\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] Epoch[321] Batch[0] avg_epoch_loss=2.167392\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=321, batch=0 train loss <loss>=2.1673924922943115\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] Epoch[321] Batch[5] avg_epoch_loss=2.095479\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=321, batch=5 train loss <loss>=2.0954786936442056\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] Epoch[321] Batch [5]#011Speed: 2202.23 samples/sec#011loss=2.095479\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] Epoch[321] Batch[10] avg_epoch_loss=2.119892\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=321, batch=10 train loss <loss>=2.1491881370544434\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] Epoch[321] Batch [10]#011Speed: 1923.19 samples/sec#011loss=2.149188\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844549.8551586, \"EndTime\": 1747844550.7983115, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.8999423980713, \"count\": 1, \"min\": 942.8999423980713, \"max\": 942.8999423980713}}}\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1422.0819547123251 records/second\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 80.5 % of epochs\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=321, train loss <loss>=2.1198920770124956\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] Epoch[322] Batch[0] avg_epoch_loss=2.159278\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=322, batch=0 train loss <loss>=2.1592776775360107\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] Epoch[322] Batch[5] avg_epoch_loss=2.120059\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=322, batch=5 train loss <loss>=2.1200589338938394\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] Epoch[322] Batch [5]#011Speed: 2160.72 samples/sec#011loss=2.120059\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] Epoch[322] Batch[10] avg_epoch_loss=2.044299\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=322, batch=10 train loss <loss>=1.9533878803253173\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] Epoch[322] Batch [10]#011Speed: 2076.19 samples/sec#011loss=1.953388\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747844550.7983673, \"EndTime\": 1747844551.724291, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.6727695465088, \"count\": 1, \"min\": 925.6727695465088, \"max\": 925.6727695465088}}}\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1439.891677843776 records/second\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 80.75 % of epochs\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=322, train loss <loss>=2.044299364089966\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[323] Batch[0] avg_epoch_loss=2.091526\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=323, batch=0 train loss <loss>=2.0915257930755615\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[323] Batch[5] avg_epoch_loss=2.026023\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=323, batch=5 train loss <loss>=2.0260226130485535\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[323] Batch [5]#011Speed: 2051.66 samples/sec#011loss=2.026023\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[323] Batch[10] avg_epoch_loss=1.957690\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=323, batch=10 train loss <loss>=1.875690793991089\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[323] Batch [10]#011Speed: 2089.09 samples/sec#011loss=1.875691\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844551.7243493, \"EndTime\": 1747844552.6682699, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.0503845214844, \"count\": 1, \"min\": 943.0503845214844, \"max\": 943.0503845214844}}}\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1391.1041079448446 records/second\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 81.0 % of epochs\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=323, train loss <loss>=1.9576899680224331\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[324] Batch[0] avg_epoch_loss=1.897087\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=324, batch=0 train loss <loss>=1.8970872163772583\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] Epoch[324] Batch[5] avg_epoch_loss=1.982966\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=324, batch=5 train loss <loss>=1.9829662442207336\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] Epoch[324] Batch [5]#011Speed: 2166.63 samples/sec#011loss=1.982966\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] Epoch[324] Batch[10] avg_epoch_loss=2.032220\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=324, batch=10 train loss <loss>=2.0913240909576416\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] Epoch[324] Batch [10]#011Speed: 2077.79 samples/sec#011loss=2.091324\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747844552.668325, \"EndTime\": 1747844553.5907888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.1782684326172, \"count\": 1, \"min\": 922.1782684326172, \"max\": 922.1782684326172}}}\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1465.9560132979686 records/second\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 81.25 % of epochs\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=324, train loss <loss>=2.032219810919328\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] Epoch[325] Batch[0] avg_epoch_loss=1.987223\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=325, batch=0 train loss <loss>=1.9872232675552368\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] Epoch[325] Batch[5] avg_epoch_loss=1.959030\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=325, batch=5 train loss <loss>=1.9590296546618144\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] Epoch[325] Batch [5]#011Speed: 2211.56 samples/sec#011loss=1.959030\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] processed a total of 1237 examples\n",
      "#metrics {\"StartTime\": 1747844553.5908473, \"EndTime\": 1747844554.439337, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 848.2027053833008, \"count\": 1, \"min\": 848.2027053833008, \"max\": 848.2027053833008}}}\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1458.2212286558579 records/second\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 81.5 % of epochs\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=325, train loss <loss>=1.9542640686035155\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] Epoch[326] Batch[0] avg_epoch_loss=1.902865\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=326, batch=0 train loss <loss>=1.9028648138046265\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[326] Batch[5] avg_epoch_loss=1.951081\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=326, batch=5 train loss <loss>=1.951081116994222\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[326] Batch [5]#011Speed: 2229.40 samples/sec#011loss=1.951081\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[326] Batch[10] avg_epoch_loss=1.886111\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=326, batch=10 train loss <loss>=1.8081474304199219\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[326] Batch [10]#011Speed: 2047.07 samples/sec#011loss=1.808147\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747844554.4393966, \"EndTime\": 1747844555.3630896, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.8725433349609, \"count\": 1, \"min\": 922.8725433349609, \"max\": 922.8725433349609}}}\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.7652092868025 records/second\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 81.75 % of epochs\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=326, train loss <loss>=1.8861112594604492\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[327] Batch[0] avg_epoch_loss=2.087726\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=327, batch=0 train loss <loss>=2.08772611618042\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[327] Batch[5] avg_epoch_loss=1.981912\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=327, batch=5 train loss <loss>=1.9819121956825256\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[327] Batch [5]#011Speed: 2159.59 samples/sec#011loss=1.981912\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] Epoch[327] Batch[10] avg_epoch_loss=1.980093\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=327, batch=10 train loss <loss>=1.977909517288208\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] Epoch[327] Batch [10]#011Speed: 2060.34 samples/sec#011loss=1.977910\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747844555.3631475, \"EndTime\": 1747844556.294245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.8521747589111, \"count\": 1, \"min\": 930.8521747589111, \"max\": 930.8521747589111}}}\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1453.3739428586648 records/second\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 82.0 % of epochs\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=327, train loss <loss>=1.9800927964123813\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] Epoch[328] Batch[0] avg_epoch_loss=2.135504\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=328, batch=0 train loss <loss>=2.1355042457580566\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] Epoch[328] Batch[5] avg_epoch_loss=2.115267\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=328, batch=5 train loss <loss>=2.115267197291056\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] Epoch[328] Batch [5]#011Speed: 2117.49 samples/sec#011loss=2.115267\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] Epoch[328] Batch[10] avg_epoch_loss=2.101479\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=328, batch=10 train loss <loss>=2.0849330186843873\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] Epoch[328] Batch [10]#011Speed: 2123.21 samples/sec#011loss=2.084933\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747844556.2943027, \"EndTime\": 1747844557.217654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.1090545654297, \"count\": 1, \"min\": 923.1090545654297, \"max\": 923.1090545654297}}}\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.8180187895225 records/second\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 82.25 % of epochs\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=328, train loss <loss>=2.101478934288025\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] Epoch[329] Batch[0] avg_epoch_loss=2.181826\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=329, batch=0 train loss <loss>=2.181825876235962\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] Epoch[329] Batch[5] avg_epoch_loss=2.160175\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=329, batch=5 train loss <loss>=2.1601752440134683\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] Epoch[329] Batch [5]#011Speed: 2176.89 samples/sec#011loss=2.160175\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] Epoch[329] Batch[10] avg_epoch_loss=2.195544\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=329, batch=10 train loss <loss>=2.2379855155944823\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] Epoch[329] Batch [10]#011Speed: 2121.96 samples/sec#011loss=2.237986\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844557.2177124, \"EndTime\": 1747844558.135081, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.1204566955566, \"count\": 1, \"min\": 917.1204566955566, \"max\": 917.1204566955566}}}\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.7950911780586 records/second\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 82.5 % of epochs\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=329, train loss <loss>=2.195543549277566\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] Epoch[330] Batch[0] avg_epoch_loss=2.020260\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=330, batch=0 train loss <loss>=2.0202596187591553\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] Epoch[330] Batch[5] avg_epoch_loss=2.100488\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=330, batch=5 train loss <loss>=2.100488265355428\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] Epoch[330] Batch [5]#011Speed: 2133.19 samples/sec#011loss=2.100488\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] Epoch[330] Batch[10] avg_epoch_loss=2.037305\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=330, batch=10 train loss <loss>=1.9614856004714967\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] Epoch[330] Batch [10]#011Speed: 2023.49 samples/sec#011loss=1.961486\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747844558.1351368, \"EndTime\": 1747844559.1037602, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 968.3494567871094, \"count\": 1, \"min\": 968.3494567871094, \"max\": 968.3494567871094}}}\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.5584660687368 records/second\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 82.75 % of epochs\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=330, train loss <loss>=2.037305235862732\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] Epoch[331] Batch[0] avg_epoch_loss=2.068285\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=331, batch=0 train loss <loss>=2.0682852268218994\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] Epoch[331] Batch[5] avg_epoch_loss=2.012760\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=331, batch=5 train loss <loss>=2.012760043144226\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] Epoch[331] Batch [5]#011Speed: 2113.59 samples/sec#011loss=2.012760\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[331] Batch[10] avg_epoch_loss=1.999939\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=331, batch=10 train loss <loss>=1.9845544338226317\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[331] Batch [10]#011Speed: 2118.85 samples/sec#011loss=1.984554\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747844559.103815, \"EndTime\": 1747844560.0303965, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.2869358062744, \"count\": 1, \"min\": 926.2869358062744, \"max\": 926.2869358062744}}}\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1393.6142767799006 records/second\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 83.0 % of epochs\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=331, train loss <loss>=1.9999393116344104\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[332] Batch[0] avg_epoch_loss=1.925253\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=332, batch=0 train loss <loss>=1.9252533912658691\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[332] Batch[5] avg_epoch_loss=1.997668\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=332, batch=5 train loss <loss>=1.997667908668518\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[332] Batch [5]#011Speed: 2130.50 samples/sec#011loss=1.997668\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[332] Batch[10] avg_epoch_loss=1.966203\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=332, batch=10 train loss <loss>=1.9284443616867066\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[332] Batch [10]#011Speed: 2125.11 samples/sec#011loss=1.928444\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844560.0304494, \"EndTime\": 1747844560.956516, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.8229732513428, \"count\": 1, \"min\": 925.8229732513428, \"max\": 925.8229732513428}}}\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1393.229350696904 records/second\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 83.25 % of epochs\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=332, train loss <loss>=1.9662026600404219\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] Epoch[333] Batch[0] avg_epoch_loss=1.883147\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=333, batch=0 train loss <loss>=1.8831466436386108\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] Epoch[333] Batch[5] avg_epoch_loss=1.934529\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=333, batch=5 train loss <loss>=1.9345289468765259\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] Epoch[333] Batch [5]#011Speed: 2196.75 samples/sec#011loss=1.934529\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] Epoch[333] Batch[10] avg_epoch_loss=1.892304\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=333, batch=10 train loss <loss>=1.8416346073150636\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] Epoch[333] Batch [10]#011Speed: 2139.35 samples/sec#011loss=1.841635\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747844560.9565718, \"EndTime\": 1747844561.8730876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.2371158599854, \"count\": 1, \"min\": 916.2371158599854, \"max\": 916.2371158599854}}}\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1402.3436502332088 records/second\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 83.5 % of epochs\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=333, train loss <loss>=1.892304247075861\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] Epoch[334] Batch[0] avg_epoch_loss=1.939021\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=334, batch=0 train loss <loss>=1.9390212297439575\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] Epoch[334] Batch[5] avg_epoch_loss=1.984599\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=334, batch=5 train loss <loss>=1.9845987558364868\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] Epoch[334] Batch [5]#011Speed: 2116.73 samples/sec#011loss=1.984599\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] Epoch[334] Batch[10] avg_epoch_loss=1.969920\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=334, batch=10 train loss <loss>=1.9523045778274537\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] Epoch[334] Batch [10]#011Speed: 2155.68 samples/sec#011loss=1.952305\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747844561.873146, \"EndTime\": 1747844562.7984486, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0564575195312, \"count\": 1, \"min\": 925.0564575195312, \"max\": 925.0564575195312}}}\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1386.8208482419436 records/second\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 83.75 % of epochs\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=334, train loss <loss>=1.969919584014199\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] Epoch[335] Batch[0] avg_epoch_loss=1.901392\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=335, batch=0 train loss <loss>=1.9013919830322266\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] Epoch[335] Batch[5] avg_epoch_loss=1.957714\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=335, batch=5 train loss <loss>=1.9577135642369587\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] Epoch[335] Batch [5]#011Speed: 2178.01 samples/sec#011loss=1.957714\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] Epoch[335] Batch[10] avg_epoch_loss=1.916576\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=335, batch=10 train loss <loss>=1.867211675643921\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] Epoch[335] Batch [10]#011Speed: 2187.86 samples/sec#011loss=1.867212\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844562.7985, \"EndTime\": 1747844563.7062461, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.5021743774414, \"count\": 1, \"min\": 907.5021743774414, \"max\": 907.5021743774414}}}\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1442.2915752593926 records/second\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 84.0 % of epochs\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=335, train loss <loss>=1.9165763421492144\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[336] Batch[0] avg_epoch_loss=1.946753\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=336, batch=0 train loss <loss>=1.9467525482177734\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[336] Batch[5] avg_epoch_loss=1.934292\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=336, batch=5 train loss <loss>=1.9342920184135437\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[336] Batch [5]#011Speed: 2175.28 samples/sec#011loss=1.934292\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[336] Batch[10] avg_epoch_loss=1.923450\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=336, batch=10 train loss <loss>=1.9104394674301148\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[336] Batch [10]#011Speed: 2172.54 samples/sec#011loss=1.910439\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747844563.706301, \"EndTime\": 1747844564.6212766, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.689302444458, \"count\": 1, \"min\": 914.689302444458, \"max\": 914.689302444458}}}\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1401.443882666589 records/second\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 84.25 % of epochs\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=336, train loss <loss>=1.9234499497847124\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[337] Batch[0] avg_epoch_loss=1.890816\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=337, batch=0 train loss <loss>=1.8908156156539917\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] Epoch[337] Batch[5] avg_epoch_loss=1.950219\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=337, batch=5 train loss <loss>=1.9502187768618267\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] Epoch[337] Batch [5]#011Speed: 2131.19 samples/sec#011loss=1.950219\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] Epoch[337] Batch[10] avg_epoch_loss=1.966249\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=337, batch=10 train loss <loss>=1.9854860782623291\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] Epoch[337] Batch [10]#011Speed: 1970.77 samples/sec#011loss=1.985486\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747844564.6213305, \"EndTime\": 1747844565.5676954, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.1073875427246, \"count\": 1, \"min\": 946.1073875427246, \"max\": 946.1073875427246}}}\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1414.099968578237 records/second\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 84.5 % of epochs\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=337, train loss <loss>=1.9662493684075095\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] Epoch[338] Batch[0] avg_epoch_loss=1.830634\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=338, batch=0 train loss <loss>=1.8306337594985962\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Epoch[338] Batch[5] avg_epoch_loss=1.918262\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=338, batch=5 train loss <loss>=1.9182615677515666\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Epoch[338] Batch [5]#011Speed: 2206.55 samples/sec#011loss=1.918262\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Epoch[338] Batch[10] avg_epoch_loss=1.857293\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=338, batch=10 train loss <loss>=1.7841316223144532\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Epoch[338] Batch [10]#011Speed: 2093.32 samples/sec#011loss=1.784132\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747844565.5677466, \"EndTime\": 1747844566.4874063, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.3406105041504, \"count\": 1, \"min\": 919.3406105041504, \"max\": 919.3406105041504}}}\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1422.5991136354974 records/second\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 84.75 % of epochs\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=338, train loss <loss>=1.8572934107346968\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_2da286c3-01cb-474e-a953-ef3afd2f7c89-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844566.4874752, \"EndTime\": 1747844566.49809, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.282278060913086, \"count\": 1, \"min\": 10.282278060913086, \"max\": 10.282278060913086}}}\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Epoch[339] Batch[0] avg_epoch_loss=2.045336\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=339, batch=0 train loss <loss>=2.0453362464904785\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] Epoch[339] Batch[5] avg_epoch_loss=2.040904\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=339, batch=5 train loss <loss>=2.040903707345327\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] Epoch[339] Batch [5]#011Speed: 2098.18 samples/sec#011loss=2.040904\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747844566.4981372, \"EndTime\": 1747844567.3773854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 879.1966438293457, \"count\": 1, \"min\": 879.1966438293457, \"max\": 879.1966438293457}}}\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1451.1505921404228 records/second\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 85.0 % of epochs\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=339, train loss <loss>=2.017747735977173\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] Epoch[340] Batch[0] avg_epoch_loss=1.942451\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=340, batch=0 train loss <loss>=1.9424514770507812\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] Epoch[340] Batch[5] avg_epoch_loss=1.943193\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=340, batch=5 train loss <loss>=1.9431930979092915\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] Epoch[340] Batch [5]#011Speed: 2017.46 samples/sec#011loss=1.943193\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] processed a total of 1238 examples\n",
      "#metrics {\"StartTime\": 1747844567.3774617, \"EndTime\": 1747844568.2650363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 887.1505260467529, \"count\": 1, \"min\": 887.1505260467529, \"max\": 887.1505260467529}}}\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1395.3403327664241 records/second\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 85.25 % of epochs\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=340, train loss <loss>=1.9766751885414124\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] Epoch[341] Batch[0] avg_epoch_loss=1.898194\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=341, batch=0 train loss <loss>=1.8981939554214478\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] Epoch[341] Batch[5] avg_epoch_loss=1.937606\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=341, batch=5 train loss <loss>=1.9376058181126912\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] Epoch[341] Batch [5]#011Speed: 2110.53 samples/sec#011loss=1.937606\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] Epoch[341] Batch[10] avg_epoch_loss=1.953986\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=341, batch=10 train loss <loss>=1.9736428260803223\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] Epoch[341] Batch [10]#011Speed: 1984.65 samples/sec#011loss=1.973643\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747844568.2650907, \"EndTime\": 1747844569.20618, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.7081604003906, \"count\": 1, \"min\": 940.7081604003906, \"max\": 940.7081604003906}}}\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1464.6875752648716 records/second\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 85.5 % of epochs\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=341, train loss <loss>=1.9539862762797962\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] Epoch[342] Batch[0] avg_epoch_loss=1.960180\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=342, batch=0 train loss <loss>=1.9601795673370361\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] Epoch[342] Batch[5] avg_epoch_loss=1.911338\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=342, batch=5 train loss <loss>=1.9113381505012512\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] Epoch[342] Batch [5]#011Speed: 2086.22 samples/sec#011loss=1.911338\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] Epoch[342] Batch[10] avg_epoch_loss=1.906371\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=342, batch=10 train loss <loss>=1.9004103660583496\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] Epoch[342] Batch [10]#011Speed: 1982.55 samples/sec#011loss=1.900410\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747844569.206239, \"EndTime\": 1747844570.151264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.7231292724609, \"count\": 1, \"min\": 944.7231292724609, \"max\": 944.7231292724609}}}\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1451.0804096260404 records/second\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 85.75 % of epochs\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=342, train loss <loss>=1.9063709757544778\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] Epoch[343] Batch[0] avg_epoch_loss=1.867126\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=343, batch=0 train loss <loss>=1.867126226425171\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] Epoch[343] Batch[5] avg_epoch_loss=1.952001\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=343, batch=5 train loss <loss>=1.9520011742909749\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] Epoch[343] Batch [5]#011Speed: 2110.37 samples/sec#011loss=1.952001\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747844570.1513247, \"EndTime\": 1747844571.020203, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 868.5636520385742, \"count\": 1, \"min\": 868.5636520385742, \"max\": 868.5636520385742}}}\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.4064160599387 records/second\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 86.0 % of epochs\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=343, train loss <loss>=1.9415612936019897\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] Epoch[344] Batch[0] avg_epoch_loss=1.878242\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=344, batch=0 train loss <loss>=1.8782421350479126\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] Epoch[344] Batch[5] avg_epoch_loss=1.928460\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=344, batch=5 train loss <loss>=1.9284604787826538\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] Epoch[344] Batch [5]#011Speed: 2111.31 samples/sec#011loss=1.928460\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] Epoch[344] Batch[10] avg_epoch_loss=1.950319\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=344, batch=10 train loss <loss>=1.9765501976013184\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] Epoch[344] Batch [10]#011Speed: 2037.53 samples/sec#011loss=1.976550\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747844571.0202715, \"EndTime\": 1747844571.96086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.2077198028564, \"count\": 1, \"min\": 940.2077198028564, \"max\": 940.2077198028564}}}\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.2127874073249 records/second\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 86.25 % of epochs\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=344, train loss <loss>=1.9503194418820469\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] Epoch[345] Batch[0] avg_epoch_loss=1.881248\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=345, batch=0 train loss <loss>=1.8812483549118042\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] Epoch[345] Batch[5] avg_epoch_loss=1.928709\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=345, batch=5 train loss <loss>=1.9287087122599285\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] Epoch[345] Batch [5]#011Speed: 2146.66 samples/sec#011loss=1.928709\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] Epoch[345] Batch[10] avg_epoch_loss=1.887068\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=345, batch=10 train loss <loss>=1.837098240852356\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] Epoch[345] Batch [10]#011Speed: 2085.24 samples/sec#011loss=1.837098\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844571.9609158, \"EndTime\": 1747844572.9036353, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.4736499786377, \"count\": 1, \"min\": 942.4736499786377, \"max\": 942.4736499786377}}}\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1385.5917526628527 records/second\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 86.5 % of epochs\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=345, train loss <loss>=1.88706758889285\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] Epoch[346] Batch[0] avg_epoch_loss=1.964410\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=346, batch=0 train loss <loss>=1.964409589767456\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] Epoch[346] Batch[5] avg_epoch_loss=2.004757\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=346, batch=5 train loss <loss>=2.004756987094879\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] Epoch[346] Batch [5]#011Speed: 2157.31 samples/sec#011loss=2.004757\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] Epoch[346] Batch[10] avg_epoch_loss=1.977614\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=346, batch=10 train loss <loss>=1.9450418949127197\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] Epoch[346] Batch [10]#011Speed: 2111.34 samples/sec#011loss=1.945042\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747844572.9036922, \"EndTime\": 1747844573.8238196, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.8799133300781, \"count\": 1, \"min\": 919.8799133300781, \"max\": 919.8799133300781}}}\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1444.6220025459959 records/second\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 86.75 % of epochs\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=346, train loss <loss>=1.9776137633757158\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] Epoch[347] Batch[0] avg_epoch_loss=1.958619\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=347, batch=0 train loss <loss>=1.9586193561553955\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] Epoch[347] Batch[5] avg_epoch_loss=1.987577\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=347, batch=5 train loss <loss>=1.9875773191452026\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] Epoch[347] Batch [5]#011Speed: 2143.78 samples/sec#011loss=1.987577\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] Epoch[347] Batch[10] avg_epoch_loss=1.964913\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=347, batch=10 train loss <loss>=1.9377164125442505\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] Epoch[347] Batch [10]#011Speed: 2137.32 samples/sec#011loss=1.937716\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747844573.8238757, \"EndTime\": 1747844574.7438056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.666051864624, \"count\": 1, \"min\": 919.666051864624, \"max\": 919.666051864624}}}\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1449.3061645591572 records/second\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 87.0 % of epochs\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=347, train loss <loss>=1.9649132706902244\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[348] Batch[0] avg_epoch_loss=1.981183\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=348, batch=0 train loss <loss>=1.9811831712722778\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[348] Batch[5] avg_epoch_loss=1.988753\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=348, batch=5 train loss <loss>=1.988753080368042\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[348] Batch [5]#011Speed: 2203.55 samples/sec#011loss=1.988753\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[348] Batch[10] avg_epoch_loss=2.008597\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=348, batch=10 train loss <loss>=2.032410192489624\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[348] Batch [10]#011Speed: 2093.91 samples/sec#011loss=2.032410\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844574.743862, \"EndTime\": 1747844575.6606205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.5079593658447, \"count\": 1, \"min\": 916.5079593658447, \"max\": 916.5079593658447}}}\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.753869460086 records/second\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 87.25 % of epochs\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=348, train loss <loss>=2.0085972222414883\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[349] Batch[0] avg_epoch_loss=1.892482\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=349, batch=0 train loss <loss>=1.8924821615219116\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Epoch[349] Batch[5] avg_epoch_loss=1.957979\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=349, batch=5 train loss <loss>=1.957979142665863\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Epoch[349] Batch [5]#011Speed: 2207.48 samples/sec#011loss=1.957979\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Epoch[349] Batch[10] avg_epoch_loss=1.855209\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=349, batch=10 train loss <loss>=1.7318843126296997\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Epoch[349] Batch [10]#011Speed: 2111.63 samples/sec#011loss=1.731884\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747844575.6606772, \"EndTime\": 1747844576.581631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.7141399383545, \"count\": 1, \"min\": 920.7141399383545, \"max\": 920.7141399383545}}}\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.3912586416716 records/second\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 87.5 % of epochs\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=349, train loss <loss>=1.855208765376698\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_486bfebe-1e6d-48df-89bb-542d9321fd20-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844576.581686, \"EndTime\": 1747844576.5925927, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.646343231201172, \"count\": 1, \"min\": 10.646343231201172, \"max\": 10.646343231201172}}}\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Epoch[350] Batch[0] avg_epoch_loss=2.013490\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=350, batch=0 train loss <loss>=2.0134904384613037\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] Epoch[350] Batch[5] avg_epoch_loss=1.937004\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=350, batch=5 train loss <loss>=1.937003533045451\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] Epoch[350] Batch [5]#011Speed: 2104.56 samples/sec#011loss=1.937004\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] Epoch[350] Batch[10] avg_epoch_loss=1.952326\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=350, batch=10 train loss <loss>=1.9707127571105958\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] Epoch[350] Batch [10]#011Speed: 2064.14 samples/sec#011loss=1.970713\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747844576.5926404, \"EndTime\": 1747844577.5282218, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.5344772338867, \"count\": 1, \"min\": 935.5344772338867, \"max\": 935.5344772338867}}}\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.3813657062333 records/second\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 87.75 % of epochs\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=350, train loss <loss>=1.9523259076205166\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] Epoch[351] Batch[0] avg_epoch_loss=1.905909\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=351, batch=0 train loss <loss>=1.9059085845947266\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] Epoch[351] Batch[5] avg_epoch_loss=1.883299\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=351, batch=5 train loss <loss>=1.8832994898160298\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] Epoch[351] Batch [5]#011Speed: 2190.22 samples/sec#011loss=1.883299\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] Epoch[351] Batch[10] avg_epoch_loss=1.961825\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=351, batch=10 train loss <loss>=2.0560564279556273\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] Epoch[351] Batch [10]#011Speed: 2070.40 samples/sec#011loss=2.056056\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844577.528278, \"EndTime\": 1747844578.4460626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.4978733062744, \"count\": 1, \"min\": 917.4978733062744, \"max\": 917.4978733062744}}}\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1423.307461855099 records/second\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 88.0 % of epochs\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=351, train loss <loss>=1.9618253707885742\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] Epoch[352] Batch[0] avg_epoch_loss=1.902905\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=352, batch=0 train loss <loss>=1.902904987335205\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] Epoch[352] Batch[5] avg_epoch_loss=1.909955\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=352, batch=5 train loss <loss>=1.9099551439285278\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] Epoch[352] Batch [5]#011Speed: 2074.71 samples/sec#011loss=1.909955\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] Epoch[352] Batch[10] avg_epoch_loss=1.922973\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=352, batch=10 train loss <loss>=1.9385939359664917\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] Epoch[352] Batch [10]#011Speed: 2044.01 samples/sec#011loss=1.938594\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747844578.4461184, \"EndTime\": 1747844579.3873055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.9317970275879, \"count\": 1, \"min\": 940.9317970275879, \"max\": 940.9317970275879}}}\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1392.1148850996985 records/second\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 88.25 % of epochs\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=352, train loss <loss>=1.9229727766730569\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] Epoch[353] Batch[0] avg_epoch_loss=1.955073\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=353, batch=0 train loss <loss>=1.9550726413726807\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[353] Batch[5] avg_epoch_loss=1.926557\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=353, batch=5 train loss <loss>=1.9265571633974712\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[353] Batch [5]#011Speed: 2150.30 samples/sec#011loss=1.926557\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[353] Batch[10] avg_epoch_loss=1.987137\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=353, batch=10 train loss <loss>=2.0598335027694703\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[353] Batch [10]#011Speed: 2113.49 samples/sec#011loss=2.059834\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747844579.387361, \"EndTime\": 1747844580.3122797, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.6659278869629, \"count\": 1, \"min\": 924.6659278869629, \"max\": 924.6659278869629}}}\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1391.7273590030431 records/second\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 88.5 % of epochs\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=353, train loss <loss>=1.9871373176574707\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[354] Batch[0] avg_epoch_loss=1.997734\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=354, batch=0 train loss <loss>=1.9977338314056396\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[354] Batch[5] avg_epoch_loss=1.935116\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=354, batch=5 train loss <loss>=1.9351160724957783\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[354] Batch [5]#011Speed: 2076.65 samples/sec#011loss=1.935116\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] Epoch[354] Batch[10] avg_epoch_loss=1.978463\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=354, batch=10 train loss <loss>=2.030479907989502\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] Epoch[354] Batch [10]#011Speed: 2058.25 samples/sec#011loss=2.030480\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747844580.3123374, \"EndTime\": 1747844581.2531357, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.5124187469482, \"count\": 1, \"min\": 940.5124187469482, \"max\": 940.5124187469482}}}\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1392.7362863513808 records/second\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 88.75 % of epochs\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=354, train loss <loss>=1.978463270447471\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] Epoch[355] Batch[0] avg_epoch_loss=1.894016\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=355, batch=0 train loss <loss>=1.8940162658691406\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] Epoch[355] Batch[5] avg_epoch_loss=1.957568\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=355, batch=5 train loss <loss>=1.9575678706169128\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] Epoch[355] Batch [5]#011Speed: 1786.76 samples/sec#011loss=1.957568\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] Epoch[355] Batch[10] avg_epoch_loss=1.998796\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=355, batch=10 train loss <loss>=2.0482698917388915\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] Epoch[355] Batch [10]#011Speed: 1953.32 samples/sec#011loss=2.048270\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747844581.253189, \"EndTime\": 1747844582.266266, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1012.8347873687744, \"count\": 1, \"min\": 1012.8347873687744, \"max\": 1012.8347873687744}}}\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1285.3889161533687 records/second\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 89.0 % of epochs\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=355, train loss <loss>=1.9987960620359941\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] Epoch[356] Batch[0] avg_epoch_loss=1.942045\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=356, batch=0 train loss <loss>=1.9420450925827026\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] Epoch[356] Batch[5] avg_epoch_loss=1.959397\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=356, batch=5 train loss <loss>=1.9593968987464905\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] Epoch[356] Batch [5]#011Speed: 2206.91 samples/sec#011loss=1.959397\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] Epoch[356] Batch[10] avg_epoch_loss=2.074807\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=356, batch=10 train loss <loss>=2.213299512863159\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] Epoch[356] Batch [10]#011Speed: 2013.22 samples/sec#011loss=2.213300\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844582.2663257, \"EndTime\": 1747844583.2044992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.9241466522217, \"count\": 1, \"min\": 937.9241466522217, \"max\": 937.9241466522217}}}\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.6306776647089 records/second\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 89.25 % of epochs\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=356, train loss <loss>=2.0748071778904307\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] Epoch[357] Batch[0] avg_epoch_loss=1.874987\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=357, batch=0 train loss <loss>=1.8749868869781494\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] Epoch[357] Batch[5] avg_epoch_loss=1.923519\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=357, batch=5 train loss <loss>=1.9235188563664753\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] Epoch[357] Batch [5]#011Speed: 2007.30 samples/sec#011loss=1.923519\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] processed a total of 1228 examples\n",
      "#metrics {\"StartTime\": 1747844583.204552, \"EndTime\": 1747844584.0819535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 877.1514892578125, \"count\": 1, \"min\": 877.1514892578125, \"max\": 877.1514892578125}}}\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1399.7967440477582 records/second\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 89.5 % of epochs\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=357, train loss <loss>=1.9079267859458924\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] Epoch[358] Batch[0] avg_epoch_loss=1.922627\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=358, batch=0 train loss <loss>=1.9226268529891968\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] Epoch[358] Batch[5] avg_epoch_loss=1.940480\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=358, batch=5 train loss <loss>=1.940480371316274\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] Epoch[358] Batch [5]#011Speed: 2134.65 samples/sec#011loss=1.940480\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747844584.0820324, \"EndTime\": 1747844584.951548, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 869.1158294677734, \"count\": 1, \"min\": 869.1158294677734, \"max\": 869.1158294677734}}}\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.6043770729764 records/second\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 89.75 % of epochs\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=358, train loss <loss>=1.9196133971214295\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] Epoch[359] Batch[0] avg_epoch_loss=1.867336\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=359, batch=0 train loss <loss>=1.8673360347747803\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] Epoch[359] Batch[5] avg_epoch_loss=1.919697\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=359, batch=5 train loss <loss>=1.9196965893109639\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] Epoch[359] Batch [5]#011Speed: 2097.69 samples/sec#011loss=1.919697\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] processed a total of 1253 examples\n",
      "#metrics {\"StartTime\": 1747844584.9516065, \"EndTime\": 1747844585.835968, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 884.0134143829346, \"count\": 1, \"min\": 884.0134143829346, \"max\": 884.0134143829346}}}\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.2502352212427 records/second\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 90.0 % of epochs\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=359, train loss <loss>=1.9233336806297303\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] Epoch[360] Batch[0] avg_epoch_loss=1.924537\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=360, batch=0 train loss <loss>=1.9245374202728271\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] Epoch[360] Batch[5] avg_epoch_loss=1.921983\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=360, batch=5 train loss <loss>=1.9219831625620525\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] Epoch[360] Batch [5]#011Speed: 2181.51 samples/sec#011loss=1.921983\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] Epoch[360] Batch[10] avg_epoch_loss=1.910325\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=360, batch=10 train loss <loss>=1.896335482597351\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] Epoch[360] Batch [10]#011Speed: 1956.76 samples/sec#011loss=1.896335\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844585.8360302, \"EndTime\": 1747844586.7746053, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.2884502410889, \"count\": 1, \"min\": 938.2884502410889, \"max\": 938.2884502410889}}}\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1409.891278288332 records/second\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 90.25 % of epochs\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=360, train loss <loss>=1.910325126214461\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] Epoch[361] Batch[0] avg_epoch_loss=2.007339\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=361, batch=0 train loss <loss>=2.0073392391204834\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] Epoch[361] Batch[5] avg_epoch_loss=2.037901\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=361, batch=5 train loss <loss>=2.0379007856051126\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] Epoch[361] Batch [5]#011Speed: 2139.08 samples/sec#011loss=2.037901\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] Epoch[361] Batch[10] avg_epoch_loss=1.994515\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=361, batch=10 train loss <loss>=1.9424513339996339\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] Epoch[361] Batch [10]#011Speed: 2090.70 samples/sec#011loss=1.942451\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844586.7746596, \"EndTime\": 1747844587.6999543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.053596496582, \"count\": 1, \"min\": 925.053596496582, \"max\": 925.053596496582}}}\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1425.7328796583572 records/second\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 90.5 % of epochs\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=361, train loss <loss>=1.9945146712389858\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[362] Batch[0] avg_epoch_loss=1.944668\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=362, batch=0 train loss <loss>=1.944668173789978\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[362] Batch[5] avg_epoch_loss=1.972118\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=362, batch=5 train loss <loss>=1.9721180200576782\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[362] Batch [5]#011Speed: 2134.07 samples/sec#011loss=1.972118\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[362] Batch[10] avg_epoch_loss=1.918621\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=362, batch=10 train loss <loss>=1.8544236660003661\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[362] Batch [10]#011Speed: 2132.58 samples/sec#011loss=1.854424\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747844587.7000115, \"EndTime\": 1747844588.6209083, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.6557273864746, \"count\": 1, \"min\": 920.6557273864746, \"max\": 920.6557273864746}}}\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1412.9962616430387 records/second\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 90.75 % of epochs\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=362, train loss <loss>=1.9186205863952637\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[363] Batch[0] avg_epoch_loss=1.920631\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=363, batch=0 train loss <loss>=1.920630693435669\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] Epoch[363] Batch[5] avg_epoch_loss=1.992560\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=363, batch=5 train loss <loss>=1.992559512456258\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] Epoch[363] Batch [5]#011Speed: 2130.50 samples/sec#011loss=1.992560\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] Epoch[363] Batch[10] avg_epoch_loss=1.951916\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=363, batch=10 train loss <loss>=1.9031442880630494\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] Epoch[363] Batch [10]#011Speed: 2068.88 samples/sec#011loss=1.903144\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747844588.6209645, \"EndTime\": 1747844589.5520096, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.7975769042969, \"count\": 1, \"min\": 930.7975769042969, \"max\": 930.7975769042969}}}\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.4540921205428 records/second\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 91.0 % of epochs\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=363, train loss <loss>=1.9519162286411633\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] Epoch[364] Batch[0] avg_epoch_loss=2.008521\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=364, batch=0 train loss <loss>=2.008521318435669\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] Epoch[364] Batch[5] avg_epoch_loss=1.907350\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=364, batch=5 train loss <loss>=1.907349705696106\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] Epoch[364] Batch [5]#011Speed: 2143.43 samples/sec#011loss=1.907350\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] Epoch[364] Batch[10] avg_epoch_loss=1.910223\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=364, batch=10 train loss <loss>=1.9136698961257934\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] Epoch[364] Batch [10]#011Speed: 2160.74 samples/sec#011loss=1.913670\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747844589.552066, \"EndTime\": 1747844590.4681785, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.825605392456, \"count\": 1, \"min\": 915.825605392456, \"max\": 915.825605392456}}}\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.8098766871824 records/second\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 91.25 % of epochs\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=364, train loss <loss>=1.910222519527782\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] Epoch[365] Batch[0] avg_epoch_loss=1.839038\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=365, batch=0 train loss <loss>=1.8390377759933472\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] Epoch[365] Batch[5] avg_epoch_loss=1.855465\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=365, batch=5 train loss <loss>=1.8554645776748657\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] Epoch[365] Batch [5]#011Speed: 2131.68 samples/sec#011loss=1.855465\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] processed a total of 1265 examples\n",
      "#metrics {\"StartTime\": 1747844590.468234, \"EndTime\": 1747844591.35762, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 889.1313076019287, \"count\": 1, \"min\": 889.1313076019287, \"max\": 889.1313076019287}}}\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1422.5908887381456 records/second\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 91.5 % of epochs\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=365, train loss <loss>=1.8646503806114196\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] Epoch[366] Batch[0] avg_epoch_loss=1.907968\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=366, batch=0 train loss <loss>=1.9079681634902954\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] Epoch[366] Batch[5] avg_epoch_loss=1.883509\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=366, batch=5 train loss <loss>=1.8835090001424153\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] Epoch[366] Batch [5]#011Speed: 2154.85 samples/sec#011loss=1.883509\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] Epoch[366] Batch[10] avg_epoch_loss=1.914761\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=366, batch=10 train loss <loss>=1.952262854576111\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] Epoch[366] Batch [10]#011Speed: 2017.10 samples/sec#011loss=1.952263\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747844591.3576825, \"EndTime\": 1747844592.2911985, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.2253932952881, \"count\": 1, \"min\": 933.2253932952881, \"max\": 933.2253932952881}}}\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1423.9633943597642 records/second\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 91.75 % of epochs\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=366, train loss <loss>=1.9147607521577314\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] Epoch[367] Batch[0] avg_epoch_loss=1.893311\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=367, batch=0 train loss <loss>=1.8933113813400269\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] Epoch[367] Batch[5] avg_epoch_loss=1.958928\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=367, batch=5 train loss <loss>=1.9589282274246216\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] Epoch[367] Batch [5]#011Speed: 2270.07 samples/sec#011loss=1.958928\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] Epoch[367] Batch[10] avg_epoch_loss=1.929331\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=367, batch=10 train loss <loss>=1.8938146591186524\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] Epoch[367] Batch [10]#011Speed: 2010.22 samples/sec#011loss=1.893815\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] processed a total of 1387 examples\n",
      "#metrics {\"StartTime\": 1747844592.2912555, \"EndTime\": 1747844593.2042212, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.7039909362793, \"count\": 1, \"min\": 912.7039909362793, \"max\": 912.7039909362793}}}\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1519.4931717485783 records/second\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 92.0 % of epochs\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=367, train loss <loss>=1.9293311509219082\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] Epoch[368] Batch[0] avg_epoch_loss=1.835091\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=368, batch=0 train loss <loss>=1.8350906372070312\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] Epoch[368] Batch[5] avg_epoch_loss=1.859682\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=368, batch=5 train loss <loss>=1.8596824208895366\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] Epoch[368] Batch [5]#011Speed: 2174.05 samples/sec#011loss=1.859682\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] Epoch[368] Batch[10] avg_epoch_loss=1.859569\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=368, batch=10 train loss <loss>=1.8594321250915526\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] Epoch[368] Batch [10]#011Speed: 2018.89 samples/sec#011loss=1.859432\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] processed a total of 1362 examples\n",
      "#metrics {\"StartTime\": 1747844593.2042866, \"EndTime\": 1747844594.130634, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.978422164917, \"count\": 1, \"min\": 925.978422164917, \"max\": 925.978422164917}}}\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1470.7406602244894 records/second\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 92.25 % of epochs\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=368, train loss <loss>=1.8595686500722712\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] Epoch[369] Batch[0] avg_epoch_loss=1.902289\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=369, batch=0 train loss <loss>=1.902288556098938\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] Epoch[369] Batch[5] avg_epoch_loss=1.890440\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=369, batch=5 train loss <loss>=1.890439788500468\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] Epoch[369] Batch [5]#011Speed: 2213.47 samples/sec#011loss=1.890440\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] processed a total of 1271 examples\n",
      "#metrics {\"StartTime\": 1747844594.130692, \"EndTime\": 1747844594.9748816, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 843.8458442687988, \"count\": 1, \"min\": 843.8458442687988, \"max\": 843.8458442687988}}}\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1506.0175847434284 records/second\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 92.5 % of epochs\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=369, train loss <loss>=1.8732738256454469\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] Epoch[370] Batch[0] avg_epoch_loss=1.903133\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=370, batch=0 train loss <loss>=1.9031330347061157\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] Epoch[370] Batch[5] avg_epoch_loss=1.897915\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=370, batch=5 train loss <loss>=1.8979148467381795\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] Epoch[370] Batch [5]#011Speed: 2173.26 samples/sec#011loss=1.897915\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] Epoch[370] Batch[10] avg_epoch_loss=1.877309\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=370, batch=10 train loss <loss>=1.8525811433792114\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] Epoch[370] Batch [10]#011Speed: 2091.30 samples/sec#011loss=1.852581\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844594.9749484, \"EndTime\": 1747844595.8953245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.9841022491455, \"count\": 1, \"min\": 919.9841022491455, \"max\": 919.9841022491455}}}\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1433.5848219954196 records/second\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 92.75 % of epochs\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=370, train loss <loss>=1.8773086179386487\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] Epoch[371] Batch[0] avg_epoch_loss=1.916072\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=371, batch=0 train loss <loss>=1.9160717725753784\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] Epoch[371] Batch[5] avg_epoch_loss=1.950581\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=371, batch=5 train loss <loss>=1.9505807757377625\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] Epoch[371] Batch [5]#011Speed: 2174.32 samples/sec#011loss=1.950581\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] Epoch[371] Batch[10] avg_epoch_loss=1.995080\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=371, batch=10 train loss <loss>=2.048479962348938\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] Epoch[371] Batch [10]#011Speed: 2061.74 samples/sec#011loss=2.048480\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747844595.89538, \"EndTime\": 1747844596.8176947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.9658374786377, \"count\": 1, \"min\": 921.9658374786377, \"max\": 921.9658374786377}}}\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1469.549644033932 records/second\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 93.0 % of epochs\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=371, train loss <loss>=1.9950804060155696\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] Epoch[372] Batch[0] avg_epoch_loss=1.963281\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=372, batch=0 train loss <loss>=1.9632809162139893\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] Epoch[372] Batch[5] avg_epoch_loss=1.943607\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=372, batch=5 train loss <loss>=1.9436069528261821\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] Epoch[372] Batch [5]#011Speed: 2146.20 samples/sec#011loss=1.943607\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] Epoch[372] Batch[10] avg_epoch_loss=1.940135\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=372, batch=10 train loss <loss>=1.9359686136245728\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] Epoch[372] Batch [10]#011Speed: 2126.77 samples/sec#011loss=1.935969\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747844596.8177514, \"EndTime\": 1747844597.7363105, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.3087348937988, \"count\": 1, \"min\": 918.3087348937988, \"max\": 918.3087348937988}}}\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.9820385055314 records/second\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 93.25 % of epochs\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=372, train loss <loss>=1.9401349804618142\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] Epoch[373] Batch[0] avg_epoch_loss=1.951711\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=373, batch=0 train loss <loss>=1.9517111778259277\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] Epoch[373] Batch[5] avg_epoch_loss=1.911455\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=373, batch=5 train loss <loss>=1.9114554127057393\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] Epoch[373] Batch [5]#011Speed: 2110.19 samples/sec#011loss=1.911455\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] Epoch[373] Batch[10] avg_epoch_loss=1.895978\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=373, batch=10 train loss <loss>=1.8774057626724243\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] Epoch[373] Batch [10]#011Speed: 1939.56 samples/sec#011loss=1.877406\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747844597.7363665, \"EndTime\": 1747844598.6854649, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.8351345062256, \"count\": 1, \"min\": 948.8351345062256, \"max\": 948.8351345062256}}}\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1444.7760658833413 records/second\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 93.5 % of epochs\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=373, train loss <loss>=1.8959782990542324\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] Epoch[374] Batch[0] avg_epoch_loss=2.003289\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=374, batch=0 train loss <loss>=2.003288745880127\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] Epoch[374] Batch[5] avg_epoch_loss=1.889786\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=374, batch=5 train loss <loss>=1.8897858063379924\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] Epoch[374] Batch [5]#011Speed: 2145.50 samples/sec#011loss=1.889786\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] processed a total of 1223 examples\n",
      "#metrics {\"StartTime\": 1747844598.6855204, \"EndTime\": 1747844599.5379586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 852.1826267242432, \"count\": 1, \"min\": 852.1826267242432, \"max\": 852.1826267242432}}}\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.9802073288804 records/second\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 93.75 % of epochs\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=374, train loss <loss>=1.9514550805091857\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] Epoch[375] Batch[0] avg_epoch_loss=1.924773\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=375, batch=0 train loss <loss>=1.9247729778289795\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] Epoch[375] Batch[5] avg_epoch_loss=1.881832\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=375, batch=5 train loss <loss>=1.881832202275594\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] Epoch[375] Batch [5]#011Speed: 2215.47 samples/sec#011loss=1.881832\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] Epoch[375] Batch[10] avg_epoch_loss=2.010984\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=375, batch=10 train loss <loss>=2.165965962409973\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] Epoch[375] Batch [10]#011Speed: 2038.47 samples/sec#011loss=2.165966\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747844599.538022, \"EndTime\": 1747844600.465318, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.0005226135254, \"count\": 1, \"min\": 927.0005226135254, \"max\": 927.0005226135254}}}\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1428.1360557093724 records/second\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 94.0 % of epochs\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=375, train loss <loss>=2.0109839114275845\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] Epoch[376] Batch[0] avg_epoch_loss=1.854953\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=376, batch=0 train loss <loss>=1.854953408241272\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] Epoch[376] Batch[5] avg_epoch_loss=1.898125\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=376, batch=5 train loss <loss>=1.8981253504753113\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] Epoch[376] Batch [5]#011Speed: 2096.11 samples/sec#011loss=1.898125\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] Epoch[376] Batch[10] avg_epoch_loss=1.945986\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=376, batch=10 train loss <loss>=2.003418970108032\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] Epoch[376] Batch [10]#011Speed: 2015.18 samples/sec#011loss=2.003419\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747844600.4653733, \"EndTime\": 1747844601.4256256, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 959.9812030792236, \"count\": 1, \"min\": 959.9812030792236, \"max\": 959.9812030792236}}}\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1385.3237184246952 records/second\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 94.25 % of epochs\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=376, train loss <loss>=1.9459860866720027\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] Epoch[377] Batch[0] avg_epoch_loss=1.836383\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=377, batch=0 train loss <loss>=1.8363831043243408\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[377] Batch[5] avg_epoch_loss=1.877891\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=377, batch=5 train loss <loss>=1.877890944480896\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[377] Batch [5]#011Speed: 2149.22 samples/sec#011loss=1.877891\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[377] Batch[10] avg_epoch_loss=1.887889\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=377, batch=10 train loss <loss>=1.8998858451843261\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[377] Batch [10]#011Speed: 2066.69 samples/sec#011loss=1.899886\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844601.425681, \"EndTime\": 1747844602.3498924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.9637851715088, \"count\": 1, \"min\": 923.9637851715088, \"max\": 923.9637851715088}}}\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1433.9230765658212 records/second\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 94.5 % of epochs\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=377, train loss <loss>=1.8878886266188188\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[378] Batch[0] avg_epoch_loss=1.884837\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=378, batch=0 train loss <loss>=1.8848369121551514\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[378] Batch[5] avg_epoch_loss=1.884732\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=378, batch=5 train loss <loss>=1.884732445081075\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[378] Batch [5]#011Speed: 2171.27 samples/sec#011loss=1.884732\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] Epoch[378] Batch[10] avg_epoch_loss=1.964028\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=378, batch=10 train loss <loss>=2.059181976318359\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] Epoch[378] Batch [10]#011Speed: 2059.20 samples/sec#011loss=2.059182\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747844602.3499405, \"EndTime\": 1747844603.2742178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.0500926971436, \"count\": 1, \"min\": 924.0500926971436, \"max\": 924.0500926971436}}}\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1437.022866834499 records/second\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 94.75 % of epochs\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=378, train loss <loss>=1.9640276865525679\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] Epoch[379] Batch[0] avg_epoch_loss=1.893410\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=379, batch=0 train loss <loss>=1.8934097290039062\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] Epoch[379] Batch[5] avg_epoch_loss=1.872226\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=379, batch=5 train loss <loss>=1.8722260197003682\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] Epoch[379] Batch [5]#011Speed: 2187.85 samples/sec#011loss=1.872226\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] Epoch[379] Batch[10] avg_epoch_loss=1.872603\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=379, batch=10 train loss <loss>=1.8730555295944213\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] Epoch[379] Batch [10]#011Speed: 2037.06 samples/sec#011loss=1.873056\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747844603.274273, \"EndTime\": 1747844604.1984198, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.839807510376, \"count\": 1, \"min\": 923.839807510376, \"max\": 923.839807510376}}}\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1471.9533454872467 records/second\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 95.0 % of epochs\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=379, train loss <loss>=1.8726030696522107\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] Epoch[380] Batch[0] avg_epoch_loss=1.785311\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=380, batch=0 train loss <loss>=1.7853105068206787\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] Epoch[380] Batch[5] avg_epoch_loss=1.864872\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=380, batch=5 train loss <loss>=1.8648719390233357\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] Epoch[380] Batch [5]#011Speed: 2182.84 samples/sec#011loss=1.864872\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] Epoch[380] Batch[10] avg_epoch_loss=1.911317\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=380, batch=10 train loss <loss>=1.96705162525177\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] Epoch[380] Batch [10]#011Speed: 2038.79 samples/sec#011loss=1.967052\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747844604.1984937, \"EndTime\": 1747844605.12228, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.4843254089355, \"count\": 1, \"min\": 923.4843254089355, \"max\": 923.4843254089355}}}\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1469.2603059398002 records/second\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 95.25 % of epochs\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=380, train loss <loss>=1.9113172509453513\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] Epoch[381] Batch[0] avg_epoch_loss=1.769135\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=381, batch=0 train loss <loss>=1.7691346406936646\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] Epoch[381] Batch[5] avg_epoch_loss=1.848879\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=381, batch=5 train loss <loss>=1.8488789598147075\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] Epoch[381] Batch [5]#011Speed: 2149.88 samples/sec#011loss=1.848879\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] Epoch[381] Batch[10] avg_epoch_loss=1.861372\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=381, batch=10 train loss <loss>=1.8763646841049195\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] Epoch[381] Batch [10]#011Speed: 1970.28 samples/sec#011loss=1.876365\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747844605.1223617, \"EndTime\": 1747844606.0735276, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.9167671203613, \"count\": 1, \"min\": 950.9167671203613, \"max\": 950.9167671203613}}}\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1349.1055627214803 records/second\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 95.5 % of epochs\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=381, train loss <loss>=1.861372470855713\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] Epoch[382] Batch[0] avg_epoch_loss=1.868259\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=382, batch=0 train loss <loss>=1.8682594299316406\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] Epoch[382] Batch[5] avg_epoch_loss=1.885089\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=382, batch=5 train loss <loss>=1.8850894570350647\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] Epoch[382] Batch [5]#011Speed: 2131.39 samples/sec#011loss=1.885089\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[382] Batch[10] avg_epoch_loss=2.109103\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=382, batch=10 train loss <loss>=2.3779193639755247\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[382] Batch [10]#011Speed: 2061.57 samples/sec#011loss=2.377919\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747844606.073584, \"EndTime\": 1747844607.0093565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.5216026306152, \"count\": 1, \"min\": 935.5216026306152, \"max\": 935.5216026306152}}}\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.43401863405 records/second\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 95.75 % of epochs\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=382, train loss <loss>=2.10910305109891\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[383] Batch[0] avg_epoch_loss=1.888615\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=383, batch=0 train loss <loss>=1.8886146545410156\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[383] Batch[5] avg_epoch_loss=1.926276\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=383, batch=5 train loss <loss>=1.9262755115826924\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[383] Batch [5]#011Speed: 2195.54 samples/sec#011loss=1.926276\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[383] Batch[10] avg_epoch_loss=1.939533\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=383, batch=10 train loss <loss>=1.9554420232772827\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[383] Batch [10]#011Speed: 2151.50 samples/sec#011loss=1.955442\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747844607.0094128, \"EndTime\": 1747844607.9166248, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.933069229126, \"count\": 1, \"min\": 906.933069229126, \"max\": 906.933069229126}}}\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1476.265881592194 records/second\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 96.0 % of epochs\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=383, train loss <loss>=1.9395330168984153\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] Epoch[384] Batch[0] avg_epoch_loss=1.878735\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=384, batch=0 train loss <loss>=1.8787345886230469\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] Epoch[384] Batch[5] avg_epoch_loss=1.938076\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=384, batch=5 train loss <loss>=1.9380757212638855\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] Epoch[384] Batch [5]#011Speed: 2166.20 samples/sec#011loss=1.938076\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] processed a total of 1244 examples\n",
      "#metrics {\"StartTime\": 1747844607.9166822, \"EndTime\": 1747844608.7731326, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 856.2033176422119, \"count\": 1, \"min\": 856.2033176422119, \"max\": 856.2033176422119}}}\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.7742257386221 records/second\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 96.25 % of epochs\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=384, train loss <loss>=1.9202686548233032\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] Epoch[385] Batch[0] avg_epoch_loss=1.877258\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=385, batch=0 train loss <loss>=1.87725830078125\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] Epoch[385] Batch[5] avg_epoch_loss=1.914976\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=385, batch=5 train loss <loss>=1.9149755835533142\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] Epoch[385] Batch [5]#011Speed: 2093.34 samples/sec#011loss=1.914976\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] Epoch[385] Batch[10] avg_epoch_loss=1.978058\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=385, batch=10 train loss <loss>=2.053757667541504\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] Epoch[385] Batch [10]#011Speed: 2148.41 samples/sec#011loss=2.053758\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844608.7731926, \"EndTime\": 1747844609.6942565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.720100402832, \"count\": 1, \"min\": 920.720100402832, \"max\": 920.720100402832}}}\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1465.0243857600894 records/second\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 96.5 % of epochs\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=385, train loss <loss>=1.9780583490024914\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] Epoch[386] Batch[0] avg_epoch_loss=1.879024\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=386, batch=0 train loss <loss>=1.8790241479873657\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] Epoch[386] Batch[5] avg_epoch_loss=1.923937\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=386, batch=5 train loss <loss>=1.9239368438720703\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] Epoch[386] Batch [5]#011Speed: 2158.50 samples/sec#011loss=1.923937\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747844609.694312, \"EndTime\": 1747844610.5415418, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 846.9538688659668, \"count\": 1, \"min\": 846.9538688659668, \"max\": 846.9538688659668}}}\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1509.9578457074758 records/second\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 96.75 % of epochs\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=386, train loss <loss>=1.9054224967956543\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] Epoch[387] Batch[0] avg_epoch_loss=1.898412\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=387, batch=0 train loss <loss>=1.8984123468399048\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] Epoch[387] Batch[5] avg_epoch_loss=1.870563\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=387, batch=5 train loss <loss>=1.8705626328786213\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] Epoch[387] Batch [5]#011Speed: 2171.51 samples/sec#011loss=1.870563\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] Epoch[387] Batch[10] avg_epoch_loss=1.885858\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=387, batch=10 train loss <loss>=1.9042129039764404\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] Epoch[387] Batch [10]#011Speed: 2050.43 samples/sec#011loss=1.904213\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747844610.5416026, \"EndTime\": 1747844611.475029, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.1073760986328, \"count\": 1, \"min\": 933.1073760986328, \"max\": 933.1073760986328}}}\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1400.5724274555312 records/second\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 97.0 % of epochs\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=387, train loss <loss>=1.8858582106503574\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] Epoch[388] Batch[0] avg_epoch_loss=2.079593\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=388, batch=0 train loss <loss>=2.079592704772949\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] Epoch[388] Batch[5] avg_epoch_loss=1.954362\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=388, batch=5 train loss <loss>=1.9543617566426594\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] Epoch[388] Batch [5]#011Speed: 2126.54 samples/sec#011loss=1.954362\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] Epoch[388] Batch[10] avg_epoch_loss=1.934951\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=388, batch=10 train loss <loss>=1.9116574287414552\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] Epoch[388] Batch [10]#011Speed: 2173.43 samples/sec#011loss=1.911657\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747844611.4750843, \"EndTime\": 1747844612.3908424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.5206680297852, \"count\": 1, \"min\": 915.5206680297852, \"max\": 915.5206680297852}}}\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1418.7372802818102 records/second\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 97.25 % of epochs\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=388, train loss <loss>=1.9349506985057483\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] Epoch[389] Batch[0] avg_epoch_loss=1.900690\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=389, batch=0 train loss <loss>=1.9006900787353516\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Epoch[389] Batch[5] avg_epoch_loss=1.916535\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=389, batch=5 train loss <loss>=1.9165347814559937\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Epoch[389] Batch [5]#011Speed: 2146.97 samples/sec#011loss=1.916535\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Epoch[389] Batch[10] avg_epoch_loss=1.855850\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=389, batch=10 train loss <loss>=1.7830280542373658\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Epoch[389] Batch [10]#011Speed: 2117.18 samples/sec#011loss=1.783028\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844612.3908968, \"EndTime\": 1747844613.3109858, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.8422431945801, \"count\": 1, \"min\": 919.8422431945801, \"max\": 919.8422431945801}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1422.9384393494288 records/second\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 97.5 % of epochs\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=389, train loss <loss>=1.8558499054475264\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Loading parameters from best epoch (349)\n",
      "#metrics {\"StartTime\": 1747844613.3110428, \"EndTime\": 1747844613.3164725, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 5.159139633178711, \"count\": 1, \"min\": 5.159139633178711, \"max\": 5.159139633178711}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] stopping training now\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Final loss: 1.855208765376698 (occurred at epoch 349)\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, train final_loss <loss>=1.855208765376698\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Worker algo-1 finished training.\n",
      "[05/21/2025 16:23:33 WARNING 140328105305920] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747844613.3165226, \"EndTime\": 1747844613.369023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 52.09207534790039, \"count\": 1, \"min\": 52.09207534790039, \"max\": 52.09207534790039}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747844613.3690696, \"EndTime\": 1747844613.391722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 74.81861114501953, \"count\": 1, \"min\": 74.81861114501953, \"max\": 74.81861114501953}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844613.391761, \"EndTime\": 1747844613.3955586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 3.7746429443359375, \"count\": 1, \"min\": 3.7746429443359375, \"max\": 3.7746429443359375}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Successfully serialized the model for prediction.\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Evaluating model accuracy on testset using 100 samples\n",
      "#metrics {\"StartTime\": 1747844613.3955932, \"EndTime\": 1747844613.397247, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}}}\n",
      "#metrics {\"StartTime\": 1747844613.3972874, \"EndTime\": 1747844613.5749, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 177.66714096069336, \"count\": 1, \"min\": 177.66714096069336, \"max\": 177.66714096069336}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, RMSE): 30.268762624880054\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, mean_absolute_QuantileLoss): 1398.5490469826593\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, mean_wQuantileLoss): 0.5012720598504156\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.1]): 0.21033582273777243\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.2]): 0.3290987657389761\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.3]): 0.4287174626832367\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.4]): 0.5116063667625511\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.5]): 0.5733221108768148\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.6]): 0.6165097236633301\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.7]): 0.6345287654220417\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.8]): 0.6268949049946229\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.9]): 0.580434615774394\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, test RMSE <loss>=30.268762624880054\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.5012720598504156\n",
      "#metrics {\"StartTime\": 1747844613.5749729, \"EndTime\": 1747844613.5850916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 3.976583480834961, \"count\": 1, \"min\": 3.976583480834961, \"max\": 3.976583480834961}, \"totaltime\": {\"sum\": 360693.0537223816, \"count\": 1, \"min\": 360693.0537223816, \"max\": 360693.0537223816}}}\n",
      "\n",
      "2025-05-21 16:23:49 Uploading - Uploading generated training model\n",
      "2025-05-21 16:23:49 Completed - Training job completed\n",
      "Training seconds: 501\n",
      "Billable seconds: 501\n",
      "CPU times: total: 15.5 s\n",
      "Wall time: 9min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "30028f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-21 16:23:49 Starting - Preparing the instances for training\n",
      "2025-05-21 16:23:49 Downloading - Downloading the training image\n",
      "2025-05-21 16:23:49 Training - Training image download completed. Training in progress.\n",
      "2025-05-21 16:23:49 Uploading - Uploading generated training model\n",
      "2025-05-21 16:23:49 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-21-16-14-41-449',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "0a66a95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 11:27:16] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-16-27-15-927 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 11:27:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-16-27-15-927 \u001b]8;id=890145;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=635645;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-16-27-15-927                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=975649;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=110072;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-16-27-15-927                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 11:27:17] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-16-27-15-927                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 11:27:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=559989;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=975198;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-16-27-15-927                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "9b524d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>Tipo_Producto</th>\n",
       "      <th>segmento_producto</th>\n",
       "      <th>supergrupo_producto</th>\n",
       "      <th>grupo_producto</th>\n",
       "      <th>subgrupo_producto</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-01</th>\n",
       "      <td>20001016001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               material  Tipo_Producto  segmento_producto  \\\n",
       "2021-08-01  20001016001              0                  0   \n",
       "\n",
       "            supergrupo_producto  grupo_producto  subgrupo_producto  cantidad  \\\n",
       "2021-08-01                    0               0                  0      25.0   \n",
       "\n",
       "            month  quarter  \n",
       "2021-08-01      8        3  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[6].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "c6ad49f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>-0.145210</td>\n",
       "      <td>5.119237</td>\n",
       "      <td>9.403378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>-7.877854</td>\n",
       "      <td>-1.599877</td>\n",
       "      <td>3.847554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>-1.344202</td>\n",
       "      <td>3.692548</td>\n",
       "      <td>9.995129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>-4.450853</td>\n",
       "      <td>0.291701</td>\n",
       "      <td>4.337483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>-0.706475</td>\n",
       "      <td>6.791806</td>\n",
       "      <td>12.815763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>-3.520440</td>\n",
       "      <td>3.702541</td>\n",
       "      <td>13.981384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0.1       0.5        0.9\n",
       "2024-11-01 -0.145210  5.119237   9.403378\n",
       "2024-12-01 -7.877854 -1.599877   3.847554\n",
       "2025-01-01 -1.344202  3.692548   9.995129\n",
       "2025-02-01 -4.450853  0.291701   4.337483\n",
       "2025-03-01 -0.706475  6.791806  12.815763\n",
       "2025-04-01 -3.520440  3.702541  13.981384"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=6\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "4d2af07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    14.0\n",
       "2024-12-01    73.0\n",
       "2025-01-01    26.0\n",
       "2025-02-01    12.0\n",
       "2025-03-01    23.0\n",
       "2025-04-01    29.0\n",
       "Freq: MS, Name: cantidad, dtype: float64"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[6].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d0707",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3ER ENTRENAMIENTO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06c4235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_cantidad_a_entero(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Convierte los valores de la columna 'cantidad' de cada dataframe a enteros,\n",
    "    redondeando al entero más cercano.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con una columna 'cantidad'\n",
    "    \n",
    "    Returns:\n",
    "        Una nueva lista de dataframes con los valores de 'cantidad' convertidos a enteros\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Lista que almacenará los dataframes modificados\n",
    "    lista_modificada = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Crear una copia para no modificar el original\n",
    "        df_modificado = df.copy()\n",
    "        \n",
    "        # Verificar que exista la columna 'cantidad'\n",
    "        if 'cantidad' not in df_modificado.columns:\n",
    "            print(f\"Advertencia: Dataframe {i} no tiene la columna 'cantidad'. Se añadirá sin cambios.\")\n",
    "            lista_modificada.append(df_modificado)\n",
    "            continue\n",
    "        \n",
    "        # Convertir a entero redondeando al entero más cercano\n",
    "        try:\n",
    "            # Primero verificar si hay valores nulos y manejarlos\n",
    "            if df_modificado['cantidad'].isna().any():\n",
    "                # Mantener los valores nulos como son\n",
    "                mask = df_modificado['cantidad'].notna()\n",
    "                df_modificado.loc[mask, 'cantidad'] = np.round(df_modificado.loc[mask, 'cantidad']).astype(int)\n",
    "            else:\n",
    "                # Si no hay valores nulos, convertir directamente\n",
    "                df_modificado['cantidad'] = np.round(df_modificado['cantidad']).astype(int)\n",
    "                \n",
    "            lista_modificada.append(df_modificado)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al convertir valores en Dataframe {i}: {e}. Se añadirá sin cambios.\")\n",
    "            lista_modificada.append(df_modificado)\n",
    "    \n",
    "    return lista_modificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79c82cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = convertir_cantidad_a_entero(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24e0c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(timeseries, keys=range(len(timeseries)))\n",
    "\n",
    "# Guardar con el índice (que ahora será MultiIndex)\n",
    "combined_df.to_csv('timeseries_combined.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ee08550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_target = extraer_vectores_cantidad(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "742a13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_test(start, vectores_target, vectores_cat, vectores_dynamic):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios con la estructura requerida para entrenamiento,\n",
    "    donde start son las fechas de inicio de cada serie (un valor por dataframe).\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie (como enteros)\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string, mantiene enteros como enteros\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else int(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic\n",
    "        if len(target_data) != len(month_vector) or len(target_data) != len(quarter_vector):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes - target: {len(target_data)}, \"\n",
    "                  f\"month: {len(month_vector)}, quarter: {len(quarter_vector)}\")\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector, quarter_vector]  # Usar valores originales sin normalizar\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "b2a5428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = crear_diccionarios_test(start,vectores_target,vectores_cat,vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "923ba370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_entrenamiento(start, vectores_target, vectores_cat, vectores_dynamic, puntos_a_excluir=6):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios excluyendo los últimos 'puntos_a_excluir' valores de \n",
    "    target y dynamic_feat para cada serie.\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "        puntos_a_excluir: Número de puntos a excluir del final de las series (default=6)\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string, mantiene enteros como enteros\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else int(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar que hay suficientes puntos para excluir\n",
    "        if len(target_data) <= puntos_a_excluir:\n",
    "            print(f\"Advertencia: Serie {i} tiene menos puntos ({len(target_data)}) que los requeridos a excluir ({puntos_a_excluir}). Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Excluir los últimos 'puntos_a_excluir' valores\n",
    "        target_data_recortado = target_data[:-puntos_a_excluir]\n",
    "        month_vector_recortado = month_vector[:-puntos_a_excluir]\n",
    "        quarter_vector_recortado = quarter_vector[:-puntos_a_excluir]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic después del recorte\n",
    "        if len(target_data_recortado) != len(month_vector_recortado) or len(target_data_recortado) != len(quarter_vector_recortado):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes después del recorte - target: {len(target_data_recortado)}, \"\n",
    "                  f\"month: {len(month_vector_recortado)}, quarter: {len(quarter_vector_recortado)}\")\n",
    "            # Ajustar a la longitud mínima\n",
    "            min_len = min(len(target_data_recortado), len(month_vector_recortado), len(quarter_vector_recortado))\n",
    "            target_data_recortado = target_data_recortado[:min_len]\n",
    "            month_vector_recortado = month_vector_recortado[:min_len]\n",
    "            quarter_vector_recortado = quarter_vector_recortado[:min_len]\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data_recortado),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector_recortado, quarter_vector_recortado]\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a1a7be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = crear_diccionarios_entrenamiento(start,vectores_target, vectores_cat, vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb2cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"data_json/mensual_modificado_int/train.json\", train)\n",
    "write_dicts_to_file(\"data_json/mensual_modificado_int/test.json\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "fbab8abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket S3 'forecasting-mensual-15-v4' creado exitosamente en la región por defecto\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"forecasting-mensual-15-v4\"\n",
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "af4e7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = bucket_name  # replace with an existing bucket if needed\n",
    "s3_bucket_prefix = (\n",
    "        \"lilipink\"  \n",
    "    )\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "if default_bucket_prefix:\n",
    "    s3_prefix = f\"{default_bucket_prefix}/{s3_bucket_prefix}\"\n",
    "else:\n",
    "    s3_prefix = s3_bucket_prefix\n",
    "\n",
    "role = \"arn:aws:iam::844598627082:role/service-role/AmazonSageMaker-ExecutionRole-20250513T105052\"  # IAM role to use by SageMaker\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file to s3://forecasting-mensual-15-v4/lilipink/data/train/train.json\n",
      "Uploading file to s3://forecasting-mensual-15-v4/lilipink/data/test/test.json\n"
     ]
    }
   ],
   "source": [
    "local_file = 'data_json/mensual_modificado_int/'\n",
    "copy_to_s3(local_file + 'train.json', s3_data_path + \"/train/train.json\",override=True)\n",
    "copy_to_s3(local_file + 'test.json', s3_data_path + \"/test/test.json\",override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "0e84683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"learning_rate\": \"1E-1\",\n",
    "    \"likelihood\":\"negative-binomial\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "42976f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "42949922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 17:50:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 17:50:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=946621;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=358654;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-50-26-760                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=190197;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=393617;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-50-26-760                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 22:50:28 Starting - Starting the training job...\n",
      "2025-05-21 22:50:44 Starting - Preparing the instances for training...\n",
      "2025-05-21 22:51:22 Downloading - Downloading the training image.........\n",
      "2025-05-21 22:53:08 Training - Training image download completed. Training in progress...Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/21/2025 22:53:25 INFO 140039678244672] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/21/2025 22:53:25 INFO 140039678244672] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '18', 'early_stopping_patience': '40', 'epochs': '400', 'learning_rate': '1E-1', 'likelihood': 'negative-binomial', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/21/2025 22:53:25 INFO 140039678244672] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '1E-1', 'likelihood': 'negative-binomial', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '18', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/21/2025 22:53:25 INFO 140039678244672] Detected entry point for worker worker\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Using early stopping with patience 40\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] random_seed is None\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] [cardinality=auto] Inferred value of cardinality=[2, 4, 5, 6, 6] from dataset.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Training set statistics:\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Integer time series\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] number of time series: 15\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] number of observations: 582\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] mean target length: 38.8\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] min/mean/max target: 1.0/30.99656357388316/350.0\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] mean abs(target): 30.99656357388316\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] contains missing values: no\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Small number of time series. Doing 86 passes over dataset with prob 0.9922480620155039 per epoch.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Test set statistics:\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Integer time series\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] number of time series: 15\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] number of observations: 672\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] mean target length: 44.8\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] min/mean/max target: 1.0/30.99702380952381/388.0\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] mean abs(target): 30.99702380952381\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] contains missing values: no\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] nvidia-smi: took 0.032 seconds to run.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] nvidia-smi identified 0 GPUs.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Number of GPUs being used: 0\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Create Store: local\n",
      "#metrics {\"StartTime\": 1747868006.096881, \"EndTime\": 1747868006.1429086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 45.05038261413574, \"count\": 1, \"min\": 45.05038261413574, \"max\": 45.05038261413574}}}\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Number of GPUs being used: 0\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] #memory_usage::<model> = 21 mb\n",
      "#metrics {\"StartTime\": 1747868006.1429837, \"EndTime\": 1747868006.2202697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 123.26431274414062, \"count\": 1, \"min\": 123.26431274414062, \"max\": 123.26431274414062}}}\n",
      "[22:53:26] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 20480 bytes with malloc directly\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Epoch[0] Batch[0] avg_epoch_loss=3.779001\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.779000997543335\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Epoch[0] Batch[5] avg_epoch_loss=5.264504\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=5.264503558476766\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Epoch[0] Batch [5]#011Speed: 1909.94 samples/sec#011loss=5.264504\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Epoch[0] Batch[10] avg_epoch_loss=4.471682\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.52029709815979\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Epoch[0] Batch [10]#011Speed: 2139.90 samples/sec#011loss=3.520297\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747868006.2203236, \"EndTime\": 1747868007.2365031, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 1016.1144733428955, \"count\": 1, \"min\": 1016.1144733428955, \"max\": 1016.1144733428955}}}\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1272.3412720421284 records/second\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=0, train loss <loss>=4.471682440150868\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_74c6775b-aedf-425c-a4da-f4df50251b26-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868007.2365966, \"EndTime\": 1747868007.2476692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.730266571044922, \"count\": 1, \"min\": 10.730266571044922, \"max\": 10.730266571044922}}}\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Epoch[1] Batch[0] avg_epoch_loss=3.569272\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.569272041320801\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Epoch[1] Batch[5] avg_epoch_loss=3.422921\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.4229212601979575\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Epoch[1] Batch [5]#011Speed: 2256.27 samples/sec#011loss=3.422921\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Epoch[1] Batch[10] avg_epoch_loss=3.350217\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.262971019744873\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Epoch[1] Batch [10]#011Speed: 1984.93 samples/sec#011loss=3.262971\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747868007.247718, \"EndTime\": 1747868008.1904504, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.6822662353516, \"count\": 1, \"min\": 942.6822662353516, \"max\": 942.6822662353516}}}\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1423.4706492865394 records/second\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.350216605446555\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_570a2efb-7f2c-4a7b-b523-405090c021a7-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868008.1905065, \"EndTime\": 1747868008.201092, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.301828384399414, \"count\": 1, \"min\": 10.301828384399414, \"max\": 10.301828384399414}}}\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Epoch[2] Batch[0] avg_epoch_loss=3.332011\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.3320109844207764\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Epoch[2] Batch[5] avg_epoch_loss=3.262753\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.2627533674240112\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Epoch[2] Batch [5]#011Speed: 2155.45 samples/sec#011loss=3.262753\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Epoch[2] Batch[10] avg_epoch_loss=3.349782\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.454216241836548\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Epoch[2] Batch [10]#011Speed: 2145.74 samples/sec#011loss=3.454216\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747868008.201145, \"EndTime\": 1747868009.1295812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.363561630249, \"count\": 1, \"min\": 928.363561630249, \"max\": 928.363561630249}}}\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1404.4875872191858 records/second\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.349781946702437\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_07f39d6d-21d7-45a3-b653-b06cc42f095b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868009.1296413, \"EndTime\": 1747868009.140705, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.78033447265625, \"count\": 1, \"min\": 10.78033447265625, \"max\": 10.78033447265625}}}\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Epoch[3] Batch[0] avg_epoch_loss=3.283588\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.283587694168091\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Epoch[3] Batch[5] avg_epoch_loss=3.228552\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.228552063306173\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Epoch[3] Batch [5]#011Speed: 2189.57 samples/sec#011loss=3.228552\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] processed a total of 1263 examples\n",
      "#metrics {\"StartTime\": 1747868009.1407561, \"EndTime\": 1747868010.0060468, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 865.2379512786865, \"count\": 1, \"min\": 865.2379512786865, \"max\": 865.2379512786865}}}\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1459.5608240582876 records/second\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.2851897716522216\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_cf1c6d30-667c-4ead-95fa-0d0182c7845c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868010.006107, \"EndTime\": 1747868010.0165246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.102033615112305, \"count\": 1, \"min\": 10.102033615112305, \"max\": 10.102033615112305}}}\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Epoch[4] Batch[0] avg_epoch_loss=3.385940\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.3859400749206543\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Epoch[4] Batch[5] avg_epoch_loss=3.255168\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.2551676432291665\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Epoch[4] Batch [5]#011Speed: 2103.05 samples/sec#011loss=3.255168\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Epoch[4] Batch[10] avg_epoch_loss=3.252001\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.2482015609741213\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Epoch[4] Batch [10]#011Speed: 1894.34 samples/sec#011loss=3.248202\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747868010.0166, \"EndTime\": 1747868010.9749227, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.2741260528564, \"count\": 1, \"min\": 958.2741260528564, \"max\": 958.2741260528564}}}\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1373.179584700367 records/second\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.252001242204146\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_96101552-9336-4237-9380-394fdbe6da7f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868010.97498, \"EndTime\": 1747868010.9860091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.747909545898438, \"count\": 1, \"min\": 10.747909545898438, \"max\": 10.747909545898438}}}\n",
      "[05/21/2025 22:53:31 INFO 140039678244672] Epoch[5] Batch[0] avg_epoch_loss=3.321702\n",
      "[05/21/2025 22:53:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.321702003479004\n",
      "[05/21/2025 22:53:31 INFO 140039678244672] Epoch[5] Batch[5] avg_epoch_loss=3.220100\n",
      "[05/21/2025 22:53:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.2201004028320312\n",
      "[05/21/2025 22:53:31 INFO 140039678244672] Epoch[5] Batch [5]#011Speed: 1717.77 samples/sec#011loss=3.220100\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Epoch[5] Batch[10] avg_epoch_loss=3.215730\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.2104866027832033\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Epoch[5] Batch [10]#011Speed: 1582.12 samples/sec#011loss=3.210487\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747868010.9860685, \"EndTime\": 1747868012.1244254, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1138.303518295288, \"count\": 1, \"min\": 1138.303518295288, \"max\": 1138.303518295288}}}\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1186.7659328403925 records/second\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.2157304937189277\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_a11992b5-e6e0-4911-a5ca-11cbaffed477-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868012.124481, \"EndTime\": 1747868012.1358838, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.926961898803711, \"count\": 1, \"min\": 10.926961898803711, \"max\": 10.926961898803711}}}\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Epoch[6] Batch[0] avg_epoch_loss=3.216772\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.2167723178863525\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Epoch[6] Batch[5] avg_epoch_loss=3.177713\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.177712599436442\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Epoch[6] Batch [5]#011Speed: 2001.09 samples/sec#011loss=3.177713\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] Epoch[6] Batch[10] avg_epoch_loss=3.226506\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.2850578308105467\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] Epoch[6] Batch [10]#011Speed: 1804.29 samples/sec#011loss=3.285058\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747868012.1359446, \"EndTime\": 1747868013.1517174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1015.7225131988525, \"count\": 1, \"min\": 1015.7225131988525, \"max\": 1015.7225131988525}}}\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1299.4595553727959 records/second\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.2265058864246714\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] Epoch[7] Batch[0] avg_epoch_loss=3.302910\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.302910327911377\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] Epoch[7] Batch[5] avg_epoch_loss=3.181818\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.1818178494771323\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] Epoch[7] Batch [5]#011Speed: 1907.73 samples/sec#011loss=3.181818\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Epoch[7] Batch[10] avg_epoch_loss=3.213976\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.252566337585449\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Epoch[7] Batch [10]#011Speed: 1902.80 samples/sec#011loss=3.252566\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747868013.151774, \"EndTime\": 1747868014.1544473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1002.4209022521973, \"count\": 1, \"min\": 1002.4209022521973, \"max\": 1002.4209022521973}}}\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1300.741868479194 records/second\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.213976253162731\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_57fc8cbf-fb66-4d00-b710-b133433fbbfb-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868014.1545033, \"EndTime\": 1747868014.1649113, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.143041610717773, \"count\": 1, \"min\": 10.143041610717773, \"max\": 10.143041610717773}}}\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Epoch[8] Batch[0] avg_epoch_loss=3.185846\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.1858460903167725\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Epoch[8] Batch[5] avg_epoch_loss=3.168270\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.168270150820414\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Epoch[8] Batch [5]#011Speed: 2062.20 samples/sec#011loss=3.168270\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Epoch[8] Batch[10] avg_epoch_loss=3.119979\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.06202917098999\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Epoch[8] Batch [10]#011Speed: 2055.94 samples/sec#011loss=3.062029\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747868014.1649594, \"EndTime\": 1747868015.1067848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.7765140533447, \"count\": 1, \"min\": 941.7765140533447, \"max\": 941.7765140533447}}}\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1434.395830142766 records/second\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.1199787963520396\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_ee59c9c8-1de6-4494-9de0-f038017eca53-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868015.1068408, \"EndTime\": 1747868015.1169887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.88149642944336, \"count\": 1, \"min\": 9.88149642944336, \"max\": 9.88149642944336}}}\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Epoch[9] Batch[0] avg_epoch_loss=2.961764\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.961763620376587\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Epoch[9] Batch[5] avg_epoch_loss=3.052943\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.0529428720474243\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Epoch[9] Batch [5]#011Speed: 1967.29 samples/sec#011loss=3.052943\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Epoch[9] Batch[10] avg_epoch_loss=3.093267\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.1416563987731934\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Epoch[9] Batch [10]#011Speed: 1758.01 samples/sec#011loss=3.141656\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747868015.117038, \"EndTime\": 1747868016.118444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1001.3566017150879, \"count\": 1, \"min\": 1001.3566017150879, \"max\": 1001.3566017150879}}}\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1358.0388542794299 records/second\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.0932672023773193\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_ad64e5f1-1b1c-4d5b-97e0-59a37c36a4cd-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868016.1185024, \"EndTime\": 1747868016.1291142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.330438613891602, \"count\": 1, \"min\": 10.330438613891602, \"max\": 10.330438613891602}}}\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Epoch[10] Batch[0] avg_epoch_loss=2.949334\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.949333667755127\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Epoch[10] Batch[5] avg_epoch_loss=3.025159\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.0251588026682534\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Epoch[10] Batch [5]#011Speed: 2049.61 samples/sec#011loss=3.025159\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747868016.1291978, \"EndTime\": 1747868017.0187862, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 889.5320892333984, \"count\": 1, \"min\": 889.5320892333984, \"max\": 889.5320892333984}}}\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1423.05004590753 records/second\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.0312586069107055\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_de96c00c-2335-49ed-8883-5221a813ac9f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868017.018862, \"EndTime\": 1747868017.0293543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.179519653320312, \"count\": 1, \"min\": 10.179519653320312, \"max\": 10.179519653320312}}}\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Epoch[11] Batch[0] avg_epoch_loss=2.934703\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.9347033500671387\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Epoch[11] Batch[5] avg_epoch_loss=3.015705\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.015704870223999\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Epoch[11] Batch [5]#011Speed: 2150.27 samples/sec#011loss=3.015705\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Epoch[11] Batch[10] avg_epoch_loss=3.098903\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=3.1987398624420167\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Epoch[11] Batch [10]#011Speed: 2085.55 samples/sec#011loss=3.198740\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747868017.0294023, \"EndTime\": 1747868017.9524827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.0301380157471, \"count\": 1, \"min\": 923.0301380157471, \"max\": 923.0301380157471}}}\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1433.1771617893407 records/second\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.0989025939594614\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] Epoch[12] Batch[0] avg_epoch_loss=3.088809\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.08880877494812\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] Epoch[12] Batch[5] avg_epoch_loss=2.964589\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.9645885626475015\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] Epoch[12] Batch [5]#011Speed: 2108.02 samples/sec#011loss=2.964589\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] Epoch[12] Batch[10] avg_epoch_loss=2.968965\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=2.9742156982421877\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] Epoch[12] Batch [10]#011Speed: 1976.67 samples/sec#011loss=2.974216\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] processed a total of 1410 examples\n",
      "#metrics {\"StartTime\": 1747868017.9525464, \"EndTime\": 1747868018.9512777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 997.7879524230957, \"count\": 1, \"min\": 997.7879524230957, \"max\": 997.7879524230957}}}\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1412.9972640653584 records/second\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.0685986280441284\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] Epoch[13] Batch[0] avg_epoch_loss=3.053341\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.0533409118652344\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] Epoch[13] Batch[5] avg_epoch_loss=2.995858\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.99585751692454\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] Epoch[13] Batch [5]#011Speed: 2112.58 samples/sec#011loss=2.995858\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] Epoch[13] Batch[10] avg_epoch_loss=3.045060\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.1041040420532227\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] Epoch[13] Batch [10]#011Speed: 2045.01 samples/sec#011loss=3.104104\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747868018.9513392, \"EndTime\": 1747868019.878963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.2928237915039, \"count\": 1, \"min\": 927.2928237915039, \"max\": 927.2928237915039}}}\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1462.1911708221778 records/second\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.045060482892123\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Epoch[14] Batch[0] avg_epoch_loss=2.993405\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=2.993405342102051\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Epoch[14] Batch[5] avg_epoch_loss=2.984151\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.984151323636373\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Epoch[14] Batch [5]#011Speed: 2179.12 samples/sec#011loss=2.984151\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Epoch[14] Batch[10] avg_epoch_loss=2.960331\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=2.9317463874816894\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Epoch[14] Batch [10]#011Speed: 1964.21 samples/sec#011loss=2.931746\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] processed a total of 1393 examples\n",
      "#metrics {\"StartTime\": 1747868019.8790188, \"EndTime\": 1747868020.8193023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.0391578674316, \"count\": 1, \"min\": 940.0391578674316, \"max\": 940.0391578674316}}}\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1481.7122382033813 records/second\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.9603308981115166\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_22677cf5-d72d-45a0-a746-f6db127a96d5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868020.8193638, \"EndTime\": 1747868020.8300414, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.349512100219727, \"count\": 1, \"min\": 10.349512100219727, \"max\": 10.349512100219727}}}\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Epoch[15] Batch[0] avg_epoch_loss=3.071212\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.07121205329895\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Epoch[15] Batch[5] avg_epoch_loss=2.924342\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.924341837565104\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Epoch[15] Batch [5]#011Speed: 2115.20 samples/sec#011loss=2.924342\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Epoch[15] Batch[10] avg_epoch_loss=2.955516\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=2.9929253101348876\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Epoch[15] Batch [10]#011Speed: 1996.59 samples/sec#011loss=2.992925\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747868020.830094, \"EndTime\": 1747868021.7888644, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.7209224700928, \"count\": 1, \"min\": 958.7209224700928, \"max\": 958.7209224700928}}}\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1417.3853529911867 records/second\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.955516143278642\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_4d54c1a5-c0a3-44e7-9ff8-1905aeb25df8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868021.7889237, \"EndTime\": 1747868021.799998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.765552520751953, \"count\": 1, \"min\": 10.765552520751953, \"max\": 10.765552520751953}}}\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] Epoch[16] Batch[0] avg_epoch_loss=3.018320\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.018320322036743\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] Epoch[16] Batch[5] avg_epoch_loss=2.998804\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.9988038142522178\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] Epoch[16] Batch [5]#011Speed: 2199.16 samples/sec#011loss=2.998804\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] Epoch[16] Batch[10] avg_epoch_loss=3.023663\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=3.0534934997558594\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] Epoch[16] Batch [10]#011Speed: 2034.98 samples/sec#011loss=3.053493\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747868021.8000505, \"EndTime\": 1747868022.7423878, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.284345626831, \"count\": 1, \"min\": 942.284345626831, \"max\": 942.284345626831}}}\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1385.873248038618 records/second\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.0236627622084185\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Epoch[17] Batch[0] avg_epoch_loss=2.846042\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=2.8460421562194824\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Epoch[17] Batch[5] avg_epoch_loss=2.887623\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=2.887623111406962\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Epoch[17] Batch [5]#011Speed: 2183.57 samples/sec#011loss=2.887623\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Epoch[17] Batch[10] avg_epoch_loss=2.942488\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.008326005935669\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Epoch[17] Batch [10]#011Speed: 2105.11 samples/sec#011loss=3.008326\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747868022.742441, \"EndTime\": 1747868023.6619241, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.2352294921875, \"count\": 1, \"min\": 919.2352294921875, \"max\": 919.2352294921875}}}\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1415.174802744461 records/second\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=17, train loss <loss>=2.9424880634654653\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_4ba5886e-00f8-4b36-9ce5-0d9984633e34-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868023.661983, \"EndTime\": 1747868023.6728594, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.542869567871094, \"count\": 1, \"min\": 10.542869567871094, \"max\": 10.542869567871094}}}\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[18] Batch[0] avg_epoch_loss=3.106320\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.1063196659088135\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[18] Batch[5] avg_epoch_loss=3.039408\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.0394084453582764\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[18] Batch [5]#011Speed: 2181.38 samples/sec#011loss=3.039408\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[18] Batch[10] avg_epoch_loss=3.038717\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.0378865718841555\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[18] Batch [10]#011Speed: 1966.46 samples/sec#011loss=3.037887\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] processed a total of 1379 examples\n",
      "#metrics {\"StartTime\": 1747868023.6729088, \"EndTime\": 1747868024.621821, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.8644599914551, \"count\": 1, \"min\": 948.8644599914551, \"max\": 948.8644599914551}}}\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1453.1868448160635 records/second\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.038716684688221\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[19] Batch[0] avg_epoch_loss=3.115020\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.115020275115967\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] Epoch[19] Batch[5] avg_epoch_loss=2.990650\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=2.9906504154205322\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] Epoch[19] Batch [5]#011Speed: 2157.45 samples/sec#011loss=2.990650\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] processed a total of 1200 examples\n",
      "#metrics {\"StartTime\": 1747868024.621877, \"EndTime\": 1747868025.463793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 841.6633605957031, \"count\": 1, \"min\": 841.6633605957031, \"max\": 841.6633605957031}}}\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1425.5906816496545 records/second\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.867463302612305\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_53d667d9-5e33-40c2-911b-cced8c583015-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868025.463857, \"EndTime\": 1747868025.474305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.091304779052734, \"count\": 1, \"min\": 10.091304779052734, \"max\": 10.091304779052734}}}\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] Epoch[20] Batch[0] avg_epoch_loss=3.145285\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.145284652709961\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] Epoch[20] Batch[5] avg_epoch_loss=2.968836\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=2.9688358306884766\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] Epoch[20] Batch [5]#011Speed: 2111.86 samples/sec#011loss=2.968836\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] Epoch[20] Batch[10] avg_epoch_loss=3.030304\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=3.1040658950805664\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] Epoch[20] Batch [10]#011Speed: 2018.36 samples/sec#011loss=3.104066\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747868025.4743543, \"EndTime\": 1747868026.40973, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.3268146514893, \"count\": 1, \"min\": 935.3268146514893, \"max\": 935.3268146514893}}}\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1387.6193550771459 records/second\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.03030404177579\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] Epoch[21] Batch[0] avg_epoch_loss=3.070351\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.0703511238098145\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[21] Batch[5] avg_epoch_loss=3.077614\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.0776140292485556\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[21] Batch [5]#011Speed: 2235.40 samples/sec#011loss=3.077614\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[21] Batch[10] avg_epoch_loss=3.056501\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=3.031165361404419\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[21] Batch [10]#011Speed: 2078.73 samples/sec#011loss=3.031165\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747868026.4097893, \"EndTime\": 1747868027.3185596, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.5204601287842, \"count\": 1, \"min\": 908.5204601287842, \"max\": 908.5204601287842}}}\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1482.477448987196 records/second\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=21, train loss <loss>=3.0565009984103115\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[22] Batch[0] avg_epoch_loss=2.863285\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.8632845878601074\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[22] Batch[5] avg_epoch_loss=2.942289\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.9422885179519653\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[22] Batch [5]#011Speed: 2149.55 samples/sec#011loss=2.942289\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] Epoch[22] Batch[10] avg_epoch_loss=2.940520\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=2.938397026062012\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] Epoch[22] Batch [10]#011Speed: 1904.23 samples/sec#011loss=2.938397\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] processed a total of 1391 examples\n",
      "#metrics {\"StartTime\": 1747868027.3186235, \"EndTime\": 1747868028.282409, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.4485244750977, \"count\": 1, \"min\": 963.4485244750977, \"max\": 963.4485244750977}}}\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1443.5940926795884 records/second\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.9405196580019863\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] Epoch[23] Batch[0] avg_epoch_loss=2.807034\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.8070342540740967\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] Epoch[23] Batch[5] avg_epoch_loss=2.845057\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.8450570901234946\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] Epoch[23] Batch [5]#011Speed: 2143.77 samples/sec#011loss=2.845057\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] processed a total of 1257 examples\n",
      "#metrics {\"StartTime\": 1747868028.2824953, \"EndTime\": 1747868029.1607444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 877.9096603393555, \"count\": 1, \"min\": 877.9096603393555, \"max\": 877.9096603393555}}}\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1431.6616696564006 records/second\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.8797963142395018\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] Epoch[24] Batch[0] avg_epoch_loss=2.908964\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.908964157104492\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] Epoch[24] Batch[5] avg_epoch_loss=2.880745\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.8807448546091714\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] Epoch[24] Batch [5]#011Speed: 2184.26 samples/sec#011loss=2.880745\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Epoch[24] Batch[10] avg_epoch_loss=2.844024\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.7999584674835205\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Epoch[24] Batch [10]#011Speed: 2129.90 samples/sec#011loss=2.799958\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747868029.1608036, \"EndTime\": 1747868030.0825734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.400785446167, \"count\": 1, \"min\": 921.400785446167, \"max\": 921.400785446167}}}\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1404.2337327333923 records/second\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.8440237695520576\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_8f113bc4-2d11-422d-9803-f9dc7c4c3e6f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868030.0826392, \"EndTime\": 1747868030.092664, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.677886962890625, \"count\": 1, \"min\": 9.677886962890625, \"max\": 9.677886962890625}}}\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Epoch[25] Batch[0] avg_epoch_loss=2.908136\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.9081361293792725\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Epoch[25] Batch[5] avg_epoch_loss=2.868694\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.868693550427755\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Epoch[25] Batch [5]#011Speed: 2132.32 samples/sec#011loss=2.868694\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[25] Batch[10] avg_epoch_loss=2.899229\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=2.935872268676758\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[25] Batch [10]#011Speed: 2033.66 samples/sec#011loss=2.935872\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747868030.0927207, \"EndTime\": 1747868031.0198338, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.06298828125, \"count\": 1, \"min\": 927.06298828125, \"max\": 927.06298828125}}}\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1392.4377464961133 records/second\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.899229331450029\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[26] Batch[0] avg_epoch_loss=2.954578\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.954577922821045\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[26] Batch[5] avg_epoch_loss=2.953744\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.9537444512049356\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[26] Batch [5]#011Speed: 2122.78 samples/sec#011loss=2.953744\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[26] Batch[10] avg_epoch_loss=2.983640\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=3.019514036178589\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[26] Batch [10]#011Speed: 2057.14 samples/sec#011loss=3.019514\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747868031.0198936, \"EndTime\": 1747868031.9571366, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.9893074035645, \"count\": 1, \"min\": 936.9893074035645, \"max\": 936.9893074035645}}}\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1387.2699563663193 records/second\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.983639717102051\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] Epoch[27] Batch[0] avg_epoch_loss=3.124765\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=3.124764919281006\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] Epoch[27] Batch[5] avg_epoch_loss=3.007196\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=3.007195750872294\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] Epoch[27] Batch [5]#011Speed: 2169.66 samples/sec#011loss=3.007196\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] Epoch[27] Batch[10] avg_epoch_loss=2.962127\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.908044767379761\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] Epoch[27] Batch [10]#011Speed: 2121.29 samples/sec#011loss=2.908045\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747868031.957213, \"EndTime\": 1747868032.8668697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.3954563140869, \"count\": 1, \"min\": 909.3954563140869, \"max\": 909.3954563140869}}}\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1495.3582618543296 records/second\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.9621271220120517\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] Epoch[28] Batch[0] avg_epoch_loss=2.849691\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.849691390991211\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] Epoch[28] Batch[5] avg_epoch_loss=2.861701\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.8617008129755654\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] Epoch[28] Batch [5]#011Speed: 2131.63 samples/sec#011loss=2.861701\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] Epoch[28] Batch[10] avg_epoch_loss=2.863094\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=2.8647647380828856\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] Epoch[28] Batch [10]#011Speed: 1759.54 samples/sec#011loss=2.864765\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747868032.8669264, \"EndTime\": 1747868033.8524303, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 985.2585792541504, \"count\": 1, \"min\": 985.2585792541504, \"max\": 985.2585792541504}}}\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1335.5726499738557 records/second\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.8630935062061655\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] Epoch[29] Batch[0] avg_epoch_loss=2.853114\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.853114128112793\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] Epoch[29] Batch[5] avg_epoch_loss=2.804688\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.8046875\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] Epoch[29] Batch [5]#011Speed: 2047.60 samples/sec#011loss=2.804688\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] Epoch[29] Batch[10] avg_epoch_loss=2.885855\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=2.98325572013855\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] Epoch[29] Batch [10]#011Speed: 2119.05 samples/sec#011loss=2.983256\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747868033.8524897, \"EndTime\": 1747868034.8048515, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.0378112792969, \"count\": 1, \"min\": 952.0378112792969, \"max\": 952.0378112792969}}}\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1374.8210994023534 records/second\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.88585487279025\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] Epoch[30] Batch[0] avg_epoch_loss=3.112880\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=3.1128804683685303\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] Epoch[30] Batch[5] avg_epoch_loss=2.986420\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.986419677734375\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] Epoch[30] Batch [5]#011Speed: 2147.34 samples/sec#011loss=2.986420\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] Epoch[30] Batch[10] avg_epoch_loss=2.950110\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=2.906538486480713\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] Epoch[30] Batch [10]#011Speed: 2040.73 samples/sec#011loss=2.906538\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747868034.804911, \"EndTime\": 1747868035.7423317, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.1659755706787, \"count\": 1, \"min\": 937.1659755706787, \"max\": 937.1659755706787}}}\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1449.9879260503653 records/second\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.9501100453463467\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] Epoch[31] Batch[0] avg_epoch_loss=2.980428\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.9804279804229736\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] Epoch[31] Batch[5] avg_epoch_loss=2.991928\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.9919283787409463\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] Epoch[31] Batch [5]#011Speed: 2078.54 samples/sec#011loss=2.991928\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] Epoch[31] Batch[10] avg_epoch_loss=2.937093\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=2.8712912082672117\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] Epoch[31] Batch [10]#011Speed: 2022.03 samples/sec#011loss=2.871291\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747868035.742387, \"EndTime\": 1747868036.686113, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.4278011322021, \"count\": 1, \"min\": 943.4278011322021, \"max\": 943.4278011322021}}}\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1393.7254945562552 records/second\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.9370933012528853\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[32] Batch[0] avg_epoch_loss=2.950505\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.950505256652832\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[32] Batch[5] avg_epoch_loss=2.875283\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.875282963116964\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[32] Batch [5]#011Speed: 2176.80 samples/sec#011loss=2.875283\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[32] Batch[10] avg_epoch_loss=2.872476\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=2.8691084384918213\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[32] Batch [10]#011Speed: 2040.16 samples/sec#011loss=2.869108\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747868036.6861691, \"EndTime\": 1747868037.6114874, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0693321228027, \"count\": 1, \"min\": 925.0693321228027, \"max\": 925.0693321228027}}}\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1423.547928112084 records/second\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.8724763610146264\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[33] Batch[0] avg_epoch_loss=2.786280\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.786280393600464\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Epoch[33] Batch[5] avg_epoch_loss=2.836293\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.83629310131073\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Epoch[33] Batch [5]#011Speed: 2153.83 samples/sec#011loss=2.836293\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Epoch[33] Batch[10] avg_epoch_loss=2.763503\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=2.6761550426483156\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Epoch[33] Batch [10]#011Speed: 2101.85 samples/sec#011loss=2.676155\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747868037.6115432, \"EndTime\": 1747868038.5297117, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.8721904754639, \"count\": 1, \"min\": 917.8721904754639, \"max\": 917.8721904754639}}}\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1416.1919140944283 records/second\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.763503074645996\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_ef94eb6d-0c4d-46be-a492-b4c1805ff196-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868038.5297666, \"EndTime\": 1747868038.539642, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.61160659790039, \"count\": 1, \"min\": 9.61160659790039, \"max\": 9.61160659790039}}}\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Epoch[34] Batch[0] avg_epoch_loss=3.011615\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=3.011615037918091\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] Epoch[34] Batch[5] avg_epoch_loss=2.879901\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.8799006938934326\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] Epoch[34] Batch [5]#011Speed: 2215.31 samples/sec#011loss=2.879901\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747868038.5396912, \"EndTime\": 1747868039.4234111, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 883.6703300476074, \"count\": 1, \"min\": 883.6703300476074, \"max\": 883.6703300476074}}}\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1447.2204557551572 records/second\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.893144679069519\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] Epoch[35] Batch[0] avg_epoch_loss=2.980130\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.980130195617676\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] Epoch[35] Batch[5] avg_epoch_loss=2.836271\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.8362707694371543\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] Epoch[35] Batch [5]#011Speed: 2153.97 samples/sec#011loss=2.836271\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] processed a total of 1264 examples\n",
      "#metrics {\"StartTime\": 1747868039.4234748, \"EndTime\": 1747868040.295035, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 871.2091445922852, \"count\": 1, \"min\": 871.2091445922852, \"max\": 871.2091445922852}}}\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1450.691978069969 records/second\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.8173850059509276\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] Epoch[36] Batch[0] avg_epoch_loss=2.751853\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.7518534660339355\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] Epoch[36] Batch[5] avg_epoch_loss=2.759395\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.759395440419515\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] Epoch[36] Batch [5]#011Speed: 2075.84 samples/sec#011loss=2.759395\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] Epoch[36] Batch[10] avg_epoch_loss=2.871870\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=3.0068397521972656\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] Epoch[36] Batch [10]#011Speed: 2023.17 samples/sec#011loss=3.006840\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747868040.2951035, \"EndTime\": 1747868041.2600992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 964.6739959716797, \"count\": 1, \"min\": 964.6739959716797, \"max\": 964.6739959716797}}}\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1345.398607896429 records/second\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.8718701275912197\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] Epoch[37] Batch[0] avg_epoch_loss=2.987023\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.987023115158081\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] Epoch[37] Batch[5] avg_epoch_loss=2.894200\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.8942000468571982\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] Epoch[37] Batch [5]#011Speed: 1981.27 samples/sec#011loss=2.894200\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] Epoch[37] Batch[10] avg_epoch_loss=2.877102\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=2.8565841197967528\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] Epoch[37] Batch [10]#011Speed: 2094.52 samples/sec#011loss=2.856584\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747868041.2601624, \"EndTime\": 1747868042.2113814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.9263038635254, \"count\": 1, \"min\": 950.9263038635254, \"max\": 950.9263038635254}}}\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1354.345867315678 records/second\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.8771018981933594\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] Epoch[38] Batch[0] avg_epoch_loss=2.799570\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.799570322036743\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] Epoch[38] Batch[5] avg_epoch_loss=2.851625\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.8516250054041543\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] Epoch[38] Batch [5]#011Speed: 2161.41 samples/sec#011loss=2.851625\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] Epoch[38] Batch[10] avg_epoch_loss=2.833903\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=2.8126355171203614\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] Epoch[38] Batch [10]#011Speed: 1980.87 samples/sec#011loss=2.812636\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747868042.211437, \"EndTime\": 1747868043.1451406, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.3789348602295, \"count\": 1, \"min\": 933.3789348602295, \"max\": 933.3789348602295}}}\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1451.5531256648578 records/second\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.833902510729703\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] Epoch[39] Batch[0] avg_epoch_loss=2.782075\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.7820751667022705\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] Epoch[39] Batch[5] avg_epoch_loss=2.756799\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.756799300511678\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] Epoch[39] Batch [5]#011Speed: 2132.30 samples/sec#011loss=2.756799\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Epoch[39] Batch[10] avg_epoch_loss=2.707347\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=2.6480039596557616\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Epoch[39] Batch [10]#011Speed: 2093.35 samples/sec#011loss=2.648004\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747868043.145215, \"EndTime\": 1747868044.0641434, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.6022281646729, \"count\": 1, \"min\": 918.6022281646729, \"max\": 918.6022281646729}}}\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1462.9527364455857 records/second\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.707346872849898\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_5e941c5f-f69a-434e-a30d-e3bbd154c09e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868044.064202, \"EndTime\": 1747868044.0752387, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.760068893432617, \"count\": 1, \"min\": 10.760068893432617, \"max\": 10.760068893432617}}}\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Epoch[40] Batch[0] avg_epoch_loss=2.823097\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.823096990585327\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Epoch[40] Batch[5] avg_epoch_loss=2.759601\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.7596009969711304\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Epoch[40] Batch [5]#011Speed: 2176.31 samples/sec#011loss=2.759601\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[40] Batch[10] avg_epoch_loss=2.804478\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=2.858330249786377\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[40] Batch [10]#011Speed: 2166.30 samples/sec#011loss=2.858330\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747868044.075292, \"EndTime\": 1747868045.0059552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.5994510650635, \"count\": 1, \"min\": 930.5994510650635, \"max\": 930.5994510650635}}}\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1395.741073217218 records/second\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.8044779300689697\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[41] Batch[0] avg_epoch_loss=2.794183\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.7941832542419434\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[41] Batch[5] avg_epoch_loss=2.871680\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.871680418650309\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[41] Batch [5]#011Speed: 2064.08 samples/sec#011loss=2.871680\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[41] Batch[10] avg_epoch_loss=2.775428\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=2.6599258899688722\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[41] Batch [10]#011Speed: 2046.30 samples/sec#011loss=2.659926\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747868045.006015, \"EndTime\": 1747868045.965257, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.9815139770508, \"count\": 1, \"min\": 958.9815139770508, \"max\": 958.9815139770508}}}\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1374.2422086148229 records/second\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.775428360158747\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] Epoch[42] Batch[0] avg_epoch_loss=2.724887\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.7248873710632324\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] Epoch[42] Batch[5] avg_epoch_loss=2.733680\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.7336795330047607\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] Epoch[42] Batch [5]#011Speed: 2132.31 samples/sec#011loss=2.733680\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] Epoch[42] Batch[10] avg_epoch_loss=2.768361\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.8099795818328857\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] Epoch[42] Batch [10]#011Speed: 2077.20 samples/sec#011loss=2.809980\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747868045.9653215, \"EndTime\": 1747868046.9160864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.465202331543, \"count\": 1, \"min\": 950.465202331543, \"max\": 950.465202331543}}}\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1393.9167776333336 records/second\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.768361373381181\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] Epoch[43] Batch[0] avg_epoch_loss=2.900434\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.9004335403442383\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] Epoch[43] Batch[5] avg_epoch_loss=2.837516\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.837515950202942\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] Epoch[43] Batch [5]#011Speed: 2100.42 samples/sec#011loss=2.837516\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] Epoch[43] Batch[10] avg_epoch_loss=2.775376\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.700806999206543\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] Epoch[43] Batch [10]#011Speed: 2111.19 samples/sec#011loss=2.700807\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747868046.9161499, \"EndTime\": 1747868047.8612869, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.8320865631104, \"count\": 1, \"min\": 944.8320865631104, \"max\": 944.8320865631104}}}\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1424.4652285426284 records/second\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.7753755179318516\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] Epoch[44] Batch[0] avg_epoch_loss=3.101784\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=3.1017837524414062\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] Epoch[44] Batch[5] avg_epoch_loss=2.849811\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.8498111168543496\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] Epoch[44] Batch [5]#011Speed: 1967.42 samples/sec#011loss=2.849811\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] Epoch[44] Batch[10] avg_epoch_loss=2.844781\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=2.8387439250946045\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] Epoch[44] Batch [10]#011Speed: 2041.50 samples/sec#011loss=2.838744\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747868047.8613443, \"EndTime\": 1747868048.8423269, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 980.7147979736328, \"count\": 1, \"min\": 980.7147979736328, \"max\": 980.7147979736328}}}\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1338.6993126767684 records/second\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.8447805751453745\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Epoch[45] Batch[0] avg_epoch_loss=2.803029\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.8030290603637695\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Epoch[45] Batch[5] avg_epoch_loss=2.758190\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.758190075556437\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Epoch[45] Batch [5]#011Speed: 2099.34 samples/sec#011loss=2.758190\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Epoch[45] Batch[10] avg_epoch_loss=2.662842\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=2.5484238386154177\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Epoch[45] Batch [10]#011Speed: 2146.93 samples/sec#011loss=2.548424\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747868048.842386, \"EndTime\": 1747868049.7842681, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.6167736053467, \"count\": 1, \"min\": 941.6167736053467, \"max\": 941.6167736053467}}}\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1368.794893100754 records/second\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.662841786037792\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_039d76d8-54db-4e82-a027-6d479b569763-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868049.784327, \"EndTime\": 1747868049.795143, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.514974594116211, \"count\": 1, \"min\": 10.514974594116211, \"max\": 10.514974594116211}}}\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] Epoch[46] Batch[0] avg_epoch_loss=2.868196\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.8681955337524414\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] Epoch[46] Batch[5] avg_epoch_loss=2.832919\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.832919160525004\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] Epoch[46] Batch [5]#011Speed: 2145.95 samples/sec#011loss=2.832919\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] Epoch[46] Batch[10] avg_epoch_loss=2.815736\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.795116138458252\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] Epoch[46] Batch [10]#011Speed: 2083.56 samples/sec#011loss=2.795116\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747868049.7952003, \"EndTime\": 1747868050.7359757, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.7215118408203, \"count\": 1, \"min\": 940.7215118408203, \"max\": 940.7215118408203}}}\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1409.4192033767388 records/second\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.8157359686764805\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] Epoch[47] Batch[0] avg_epoch_loss=2.761642\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.7616419792175293\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] Epoch[47] Batch[5] avg_epoch_loss=2.733175\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.733175357182821\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] Epoch[47] Batch [5]#011Speed: 2091.96 samples/sec#011loss=2.733175\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] Epoch[47] Batch[10] avg_epoch_loss=2.767752\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=2.809243011474609\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] Epoch[47] Batch [10]#011Speed: 2006.49 samples/sec#011loss=2.809243\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747868050.7360377, \"EndTime\": 1747868051.7020588, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 965.742826461792, \"count\": 1, \"min\": 965.742826461792, \"max\": 965.742826461792}}}\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1398.7594715796454 records/second\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.7677515636790884\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[48] Batch[0] avg_epoch_loss=2.710209\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.710209369659424\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[48] Batch[5] avg_epoch_loss=2.710558\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.7105578184127808\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[48] Batch [5]#011Speed: 2125.94 samples/sec#011loss=2.710558\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[48] Batch[10] avg_epoch_loss=2.614180\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=2.4985273838043214\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[48] Batch [10]#011Speed: 2007.02 samples/sec#011loss=2.498527\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747868051.7021356, \"EndTime\": 1747868052.6429226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.4549598693848, \"count\": 1, \"min\": 940.4549598693848, \"max\": 940.4549598693848}}}\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1390.67624211302 records/second\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.6141803481362085\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_e499476b-b91c-42c8-a53b-dc7532ce5051-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868052.6429858, \"EndTime\": 1747868052.6529496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.622335433959961, \"count\": 1, \"min\": 9.622335433959961, \"max\": 9.622335433959961}}}\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[49] Batch[0] avg_epoch_loss=3.172111\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=3.1721107959747314\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] Epoch[49] Batch[5] avg_epoch_loss=3.146817\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=3.1468174854914346\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] Epoch[49] Batch [5]#011Speed: 2106.01 samples/sec#011loss=3.146817\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] Epoch[49] Batch[10] avg_epoch_loss=3.058615\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=2.952771520614624\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] Epoch[49] Batch [10]#011Speed: 1941.44 samples/sec#011loss=2.952772\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747868052.653008, \"EndTime\": 1747868053.6075034, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.442024230957, \"count\": 1, \"min\": 954.442024230957, \"max\": 954.442024230957}}}\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1432.1159197881104 records/second\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=49, train loss <loss>=3.0586147741837935\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] Epoch[50] Batch[0] avg_epoch_loss=2.884904\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.884903907775879\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] Epoch[50] Batch[5] avg_epoch_loss=2.852137\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.8521373669306436\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] Epoch[50] Batch [5]#011Speed: 2069.33 samples/sec#011loss=2.852137\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] Epoch[50] Batch[10] avg_epoch_loss=2.849579\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.846509885787964\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] Epoch[50] Batch [10]#011Speed: 2041.65 samples/sec#011loss=2.846510\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747868053.6075609, \"EndTime\": 1747868054.5485847, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.6495094299316, \"count\": 1, \"min\": 940.6495094299316, \"max\": 940.6495094299316}}}\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1405.2865072602683 records/second\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.8495794209566983\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] Epoch[51] Batch[0] avg_epoch_loss=2.891051\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.8910510540008545\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] Epoch[51] Batch[5] avg_epoch_loss=2.839245\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.839244802792867\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] Epoch[51] Batch [5]#011Speed: 1972.75 samples/sec#011loss=2.839245\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] Epoch[51] Batch[10] avg_epoch_loss=2.871868\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.9110167980194093\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] Epoch[51] Batch [10]#011Speed: 1675.00 samples/sec#011loss=2.911017\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] processed a total of 1402 examples\n",
      "#metrics {\"StartTime\": 1747868054.5486424, \"EndTime\": 1747868055.5874686, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1038.573980331421, \"count\": 1, \"min\": 1038.573980331421, \"max\": 1038.573980331421}}}\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1349.755008718849 records/second\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.87186843698675\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] Epoch[52] Batch[0] avg_epoch_loss=2.772520\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.7725203037261963\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] Epoch[52] Batch[5] avg_epoch_loss=2.865179\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.865179419517517\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] Epoch[52] Batch [5]#011Speed: 2121.00 samples/sec#011loss=2.865179\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747868055.5875697, \"EndTime\": 1747868056.4559233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 867.4368858337402, \"count\": 1, \"min\": 867.4368858337402, \"max\": 867.4368858337402}}}\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1453.5258932325662 records/second\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.8412468671798705\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] Epoch[53] Batch[0] avg_epoch_loss=2.777425\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.7774252891540527\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] Epoch[53] Batch[5] avg_epoch_loss=2.773443\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.773443023363749\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] Epoch[53] Batch [5]#011Speed: 2111.76 samples/sec#011loss=2.773443\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] Epoch[53] Batch[10] avg_epoch_loss=2.709117\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.6319268226623533\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] Epoch[53] Batch [10]#011Speed: 2010.30 samples/sec#011loss=2.631927\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747868056.4559968, \"EndTime\": 1747868057.3996894, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.2554244995117, \"count\": 1, \"min\": 943.2554244995117, \"max\": 943.2554244995117}}}\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1386.5600933311969 records/second\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.7091174775903877\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] Epoch[54] Batch[0] avg_epoch_loss=2.797012\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.797011613845825\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[54] Batch[5] avg_epoch_loss=2.757059\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.75705885887146\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[54] Batch [5]#011Speed: 2143.84 samples/sec#011loss=2.757059\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[54] Batch[10] avg_epoch_loss=2.849418\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=2.9602492332458494\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[54] Batch [10]#011Speed: 2025.21 samples/sec#011loss=2.960249\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747868057.399748, \"EndTime\": 1747868058.3421905, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.1372413635254, \"count\": 1, \"min\": 942.1372413635254, \"max\": 942.1372413635254}}}\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1360.592011999915 records/second\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.849418119950728\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[55] Batch[0] avg_epoch_loss=2.898941\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.8989412784576416\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[55] Batch[5] avg_epoch_loss=2.896953\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.8969526290893555\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[55] Batch [5]#011Speed: 2184.13 samples/sec#011loss=2.896953\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] Epoch[55] Batch[10] avg_epoch_loss=2.820202\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.7281020641326905\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] Epoch[55] Batch [10]#011Speed: 2012.60 samples/sec#011loss=2.728102\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747868058.3422587, \"EndTime\": 1747868059.2730694, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.4728507995605, \"count\": 1, \"min\": 930.4728507995605, \"max\": 930.4728507995605}}}\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1464.7111223615807 records/second\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.8202023722908716\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] Epoch[56] Batch[0] avg_epoch_loss=2.816246\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.8162460327148438\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] Epoch[56] Batch[5] avg_epoch_loss=2.851778\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.8517781496047974\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] Epoch[56] Batch [5]#011Speed: 2137.36 samples/sec#011loss=2.851778\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] Epoch[56] Batch[10] avg_epoch_loss=2.771863\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=2.67596492767334\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] Epoch[56] Batch [10]#011Speed: 2077.14 samples/sec#011loss=2.675965\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747868059.2731285, \"EndTime\": 1747868060.2046514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.1025142669678, \"count\": 1, \"min\": 931.1025142669678, \"max\": 931.1025142669678}}}\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1411.0958002652021 records/second\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.7718630487268623\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] Epoch[57] Batch[0] avg_epoch_loss=2.708515\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.7085154056549072\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] Epoch[57] Batch[5] avg_epoch_loss=2.799202\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.799202005068461\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] Epoch[57] Batch [5]#011Speed: 2113.82 samples/sec#011loss=2.799202\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] Epoch[57] Batch[10] avg_epoch_loss=2.637991\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=2.4445388078689576\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] Epoch[57] Batch [10]#011Speed: 2021.61 samples/sec#011loss=2.444539\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747868060.2047117, \"EndTime\": 1747868061.1694884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 964.5133018493652, \"count\": 1, \"min\": 964.5133018493652, \"max\": 964.5133018493652}}}\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1329.042278446722 records/second\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.6379914608868686\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] Epoch[58] Batch[0] avg_epoch_loss=2.815988\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.8159875869750977\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] Epoch[58] Batch[5] avg_epoch_loss=2.831392\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.83139177163442\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] Epoch[58] Batch [5]#011Speed: 2117.03 samples/sec#011loss=2.831392\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] Epoch[58] Batch[10] avg_epoch_loss=2.757602\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.669053626060486\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] Epoch[58] Batch [10]#011Speed: 2052.13 samples/sec#011loss=2.669054\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747868061.169551, \"EndTime\": 1747868062.1041443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.3376159667969, \"count\": 1, \"min\": 934.3376159667969, \"max\": 934.3376159667969}}}\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1438.3204399815781 records/second\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.7576017054644497\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] Epoch[59] Batch[0] avg_epoch_loss=2.769587\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.769587278366089\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] Epoch[59] Batch[5] avg_epoch_loss=2.749524\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.7495243549346924\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] Epoch[59] Batch [5]#011Speed: 2099.44 samples/sec#011loss=2.749524\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] Epoch[59] Batch[10] avg_epoch_loss=2.668847\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=2.5720332145690916\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] Epoch[59] Batch [10]#011Speed: 2108.80 samples/sec#011loss=2.572033\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747868062.1042023, \"EndTime\": 1747868063.0424862, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.9897117614746, \"count\": 1, \"min\": 937.9897117614746, \"max\": 937.9897117614746}}}\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1395.4131996802696 records/second\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.6688465638594194\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] Epoch[60] Batch[0] avg_epoch_loss=2.959544\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.9595444202423096\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] Epoch[60] Batch[5] avg_epoch_loss=2.811174\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.8111735582351685\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] Epoch[60] Batch [5]#011Speed: 2000.38 samples/sec#011loss=2.811174\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] Epoch[60] Batch[10] avg_epoch_loss=2.668546\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.497391963005066\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] Epoch[60] Batch [10]#011Speed: 1858.55 samples/sec#011loss=2.497392\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747868063.0425436, \"EndTime\": 1747868064.0239594, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 981.1632633209229, \"count\": 1, \"min\": 981.1632633209229, \"max\": 981.1632633209229}}}\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1339.1046361323254 records/second\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.6685455604033037\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] Epoch[61] Batch[0] avg_epoch_loss=2.799644\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.7996444702148438\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] Epoch[61] Batch[5] avg_epoch_loss=2.868217\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.8682172695795694\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] Epoch[61] Batch [5]#011Speed: 1821.07 samples/sec#011loss=2.868217\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] processed a total of 1248 examples\n",
      "#metrics {\"StartTime\": 1747868064.0240204, \"EndTime\": 1747868064.9456122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.339750289917, \"count\": 1, \"min\": 921.339750289917, \"max\": 921.339750289917}}}\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1354.4142390065733 records/second\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.8896899938583376\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] Epoch[62] Batch[0] avg_epoch_loss=2.830926\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.8309261798858643\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] Epoch[62] Batch[5] avg_epoch_loss=2.835928\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.8359278440475464\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] Epoch[62] Batch [5]#011Speed: 1852.21 samples/sec#011loss=2.835928\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] Epoch[62] Batch[10] avg_epoch_loss=2.857639\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.883692407608032\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] Epoch[62] Batch [10]#011Speed: 1946.31 samples/sec#011loss=2.883692\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747868064.9456742, \"EndTime\": 1747868065.9416502, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 995.6896305084229, \"count\": 1, \"min\": 995.6896305084229, \"max\": 995.6896305084229}}}\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1338.6061639489956 records/second\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.8576390093023125\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] Epoch[63] Batch[0] avg_epoch_loss=2.655268\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.6552681922912598\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] Epoch[63] Batch[5] avg_epoch_loss=2.785733\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.785733461380005\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] Epoch[63] Batch [5]#011Speed: 2059.08 samples/sec#011loss=2.785733\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] Epoch[63] Batch[10] avg_epoch_loss=2.854958\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.938027572631836\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] Epoch[63] Batch [10]#011Speed: 2104.24 samples/sec#011loss=2.938028\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747868065.9417436, \"EndTime\": 1747868066.8812675, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.2566680908203, \"count\": 1, \"min\": 939.2566680908203, \"max\": 939.2566680908203}}}\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1366.9097446406622 records/second\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.8549580574035645\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] Epoch[64] Batch[0] avg_epoch_loss=2.933094\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.933093786239624\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] Epoch[64] Batch[5] avg_epoch_loss=2.911959\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.9119585752487183\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] Epoch[64] Batch [5]#011Speed: 2074.33 samples/sec#011loss=2.911959\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] Epoch[64] Batch[10] avg_epoch_loss=2.944036\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=2.982528638839722\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] Epoch[64] Batch [10]#011Speed: 1998.34 samples/sec#011loss=2.982529\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747868066.8813267, \"EndTime\": 1747868067.8258197, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.2322254180908, \"count\": 1, \"min\": 944.2322254180908, \"max\": 944.2322254180908}}}\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1412.6599911734022 records/second\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.9440358768809927\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] Epoch[65] Batch[0] avg_epoch_loss=2.745537\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.7455368041992188\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] Epoch[65] Batch[5] avg_epoch_loss=2.786935\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.7869345347086587\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] Epoch[65] Batch [5]#011Speed: 1858.94 samples/sec#011loss=2.786935\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] Epoch[65] Batch[10] avg_epoch_loss=2.799670\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.8149528026580812\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] Epoch[65] Batch [10]#011Speed: 1915.69 samples/sec#011loss=2.814953\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747868067.825878, \"EndTime\": 1747868068.8297899, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1003.6561489105225, \"count\": 1, \"min\": 1003.6561489105225, \"max\": 1003.6561489105225}}}\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1316.0733975375326 records/second\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.799670111049305\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] Epoch[66] Batch[0] avg_epoch_loss=2.897692\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.8976919651031494\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] Epoch[66] Batch[5] avg_epoch_loss=2.682137\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.682137211163839\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] Epoch[66] Batch [5]#011Speed: 2139.00 samples/sec#011loss=2.682137\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] Epoch[66] Batch[10] avg_epoch_loss=2.671645\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.659054231643677\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] Epoch[66] Batch [10]#011Speed: 1988.05 samples/sec#011loss=2.659054\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] processed a total of 1392 examples\n",
      "#metrics {\"StartTime\": 1747868068.8298488, \"EndTime\": 1747868069.7648025, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.6797466278076, \"count\": 1, \"min\": 934.6797466278076, \"max\": 934.6797466278076}}}\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1489.1229008772568 records/second\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.6716449477455835\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] Epoch[67] Batch[0] avg_epoch_loss=2.698026\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.698026180267334\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] Epoch[67] Batch[5] avg_epoch_loss=2.708687\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.7086872657140098\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] Epoch[67] Batch [5]#011Speed: 2154.38 samples/sec#011loss=2.708687\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] Epoch[67] Batch[10] avg_epoch_loss=2.743172\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.7845537662506104\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] Epoch[67] Batch [10]#011Speed: 2045.97 samples/sec#011loss=2.784554\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747868069.764868, \"EndTime\": 1747868070.6902134, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0130653381348, \"count\": 1, \"min\": 925.0130653381348, \"max\": 925.0130653381348}}}\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1437.6578217146102 records/second\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.743172038685192\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] Epoch[68] Batch[0] avg_epoch_loss=2.956230\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.9562296867370605\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] Epoch[68] Batch[5] avg_epoch_loss=2.859456\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.8594560623168945\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] Epoch[68] Batch [5]#011Speed: 2015.89 samples/sec#011loss=2.859456\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] processed a total of 1237 examples\n",
      "#metrics {\"StartTime\": 1747868070.6902707, \"EndTime\": 1747868071.5741842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 883.6619853973389, \"count\": 1, \"min\": 883.6619853973389, \"max\": 883.6619853973389}}}\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1399.7073570267366 records/second\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.8462641954422\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] Epoch[69] Batch[0] avg_epoch_loss=2.767323\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.7673230171203613\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Epoch[69] Batch[5] avg_epoch_loss=2.702632\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.7026323080062866\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Epoch[69] Batch [5]#011Speed: 2082.18 samples/sec#011loss=2.702632\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Epoch[69] Batch[10] avg_epoch_loss=2.612857\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.5051260948181153\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Epoch[69] Batch [10]#011Speed: 2166.61 samples/sec#011loss=2.505126\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747868071.5742471, \"EndTime\": 1747868072.4969347, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.3544597625732, \"count\": 1, \"min\": 922.3544597625732, \"max\": 922.3544597625732}}}\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1389.791133981236 records/second\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.6128567565571177\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_29cac851-26ca-4a74-bd1d-05dd602d928e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868072.4969926, \"EndTime\": 1747868072.5070033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.718894958496094, \"count\": 1, \"min\": 9.718894958496094, \"max\": 9.718894958496094}}}\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Epoch[70] Batch[0] avg_epoch_loss=2.805671\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.805671453475952\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] Epoch[70] Batch[5] avg_epoch_loss=2.789068\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.78906778494517\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] Epoch[70] Batch [5]#011Speed: 1981.75 samples/sec#011loss=2.789068\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] Epoch[70] Batch[10] avg_epoch_loss=2.708494\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.6118055820465087\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] Epoch[70] Batch [10]#011Speed: 1984.50 samples/sec#011loss=2.611806\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747868072.5070555, \"EndTime\": 1747868073.4677398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.6325626373291, \"count\": 1, \"min\": 960.6325626373291, \"max\": 960.6325626373291}}}\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1384.3793238399633 records/second\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.7084940563548696\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] Epoch[71] Batch[0] avg_epoch_loss=2.772291\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.772291421890259\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] Epoch[71] Batch[5] avg_epoch_loss=2.754039\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.7540394067764282\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] Epoch[71] Batch [5]#011Speed: 2159.21 samples/sec#011loss=2.754039\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] Epoch[71] Batch[10] avg_epoch_loss=2.729872\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.7008718967437746\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] Epoch[71] Batch [10]#011Speed: 2155.54 samples/sec#011loss=2.700872\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747868073.4677982, \"EndTime\": 1747868074.393007, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.9234199523926, \"count\": 1, \"min\": 924.9234199523926, \"max\": 924.9234199523926}}}\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1391.2807784061972 records/second\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.7298723567615855\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] Epoch[72] Batch[0] avg_epoch_loss=2.686310\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.686309814453125\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[72] Batch[5] avg_epoch_loss=2.826659\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.8266592820485434\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[72] Batch [5]#011Speed: 2159.62 samples/sec#011loss=2.826659\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[72] Batch[10] avg_epoch_loss=2.683611\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.5119534015655516\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[72] Batch [10]#011Speed: 2129.60 samples/sec#011loss=2.511953\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747868074.3931012, \"EndTime\": 1747868075.3485284, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.1308155059814, \"count\": 1, \"min\": 955.1308155059814, \"max\": 955.1308155059814}}}\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1358.849971333946 records/second\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.6836111545562744\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[73] Batch[0] avg_epoch_loss=2.810009\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.8100087642669678\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[73] Batch[5] avg_epoch_loss=2.786824\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.786824027697245\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[73] Batch [5]#011Speed: 2126.59 samples/sec#011loss=2.786824\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] processed a total of 1245 examples\n",
      "#metrics {\"StartTime\": 1747868075.348589, \"EndTime\": 1747868076.2372653, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 888.4060382843018, \"count\": 1, \"min\": 888.4060382843018, \"max\": 888.4060382843018}}}\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1401.2316886774631 records/second\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.7368746757507325\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] Epoch[74] Batch[0] avg_epoch_loss=2.705509\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.7055094242095947\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] Epoch[74] Batch[5] avg_epoch_loss=2.703939\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.7039392789204917\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] Epoch[74] Batch [5]#011Speed: 1997.28 samples/sec#011loss=2.703939\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] Epoch[74] Batch[10] avg_epoch_loss=2.616593\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.5117779970169067\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] Epoch[74] Batch [10]#011Speed: 1957.18 samples/sec#011loss=2.511778\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747868076.2373316, \"EndTime\": 1747868077.2255068, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 987.858772277832, \"count\": 1, \"min\": 987.858772277832, \"max\": 987.858772277832}}}\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1328.0176961977356 records/second\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.6165932416915894\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] Epoch[75] Batch[0] avg_epoch_loss=2.742567\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.742567300796509\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] Epoch[75] Batch[5] avg_epoch_loss=2.754796\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.7547960678736367\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] Epoch[75] Batch [5]#011Speed: 2046.06 samples/sec#011loss=2.754796\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] Epoch[75] Batch[10] avg_epoch_loss=2.764327\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=2.775764560699463\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] Epoch[75] Batch [10]#011Speed: 1993.86 samples/sec#011loss=2.775765\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747868077.2255597, \"EndTime\": 1747868078.198915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.1101989746094, \"count\": 1, \"min\": 973.1101989746094, \"max\": 973.1101989746094}}}\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1371.737934508125 records/second\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.764327200976285\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] Epoch[76] Batch[0] avg_epoch_loss=2.830038\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.830037832260132\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] Epoch[76] Batch[5] avg_epoch_loss=2.738950\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.738949775695801\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] Epoch[76] Batch [5]#011Speed: 2025.09 samples/sec#011loss=2.738950\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] Epoch[76] Batch[10] avg_epoch_loss=2.690033\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.631333017349243\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] Epoch[76] Batch [10]#011Speed: 2085.71 samples/sec#011loss=2.631333\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747868078.1989884, \"EndTime\": 1747868079.1607916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.4124298095703, \"count\": 1, \"min\": 961.4124298095703, \"max\": 961.4124298095703}}}\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1379.090819463028 records/second\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.6900330673564565\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] Epoch[77] Batch[0] avg_epoch_loss=2.960603\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.9606025218963623\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] Epoch[77] Batch[5] avg_epoch_loss=2.828712\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.8287116289138794\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] Epoch[77] Batch [5]#011Speed: 1866.49 samples/sec#011loss=2.828712\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] Epoch[77] Batch[10] avg_epoch_loss=2.728350\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.60791494846344\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] Epoch[77] Batch [10]#011Speed: 1833.56 samples/sec#011loss=2.607915\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747868079.160851, \"EndTime\": 1747868080.173708, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1012.5844478607178, \"count\": 1, \"min\": 1012.5844478607178, \"max\": 1012.5844478607178}}}\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1287.6852827994242 records/second\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.7283495014364068\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] Epoch[78] Batch[0] avg_epoch_loss=2.657533\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.6575334072113037\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] Epoch[78] Batch[5] avg_epoch_loss=2.730625\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.7306245962778726\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] Epoch[78] Batch [5]#011Speed: 1866.04 samples/sec#011loss=2.730625\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] Epoch[78] Batch[10] avg_epoch_loss=2.630934\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.511305332183838\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] Epoch[78] Batch [10]#011Speed: 1740.39 samples/sec#011loss=2.511305\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747868080.173766, \"EndTime\": 1747868081.2188659, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1044.7311401367188, \"count\": 1, \"min\": 1044.7311401367188, \"max\": 1044.7311401367188}}}\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1244.2339406488525 records/second\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.6309340216896753\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] Epoch[79] Batch[0] avg_epoch_loss=2.793998\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.7939984798431396\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] Epoch[79] Batch[5] avg_epoch_loss=2.759306\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.7593063910802207\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] Epoch[79] Batch [5]#011Speed: 1810.35 samples/sec#011loss=2.759306\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] Epoch[79] Batch[10] avg_epoch_loss=2.827669\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.9097039222717287\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] Epoch[79] Batch [10]#011Speed: 1817.42 samples/sec#011loss=2.909704\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747868081.2189245, \"EndTime\": 1747868082.2559922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1036.8094444274902, \"count\": 1, \"min\": 1036.8094444274902, \"max\": 1036.8094444274902}}}\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1267.2446596432235 records/second\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.8276689052581787\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] Epoch[80] Batch[0] avg_epoch_loss=2.773407\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.773406744003296\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] Epoch[80] Batch[5] avg_epoch_loss=2.733800\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.7338000535964966\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] Epoch[80] Batch [5]#011Speed: 1844.89 samples/sec#011loss=2.733800\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] Epoch[80] Batch[10] avg_epoch_loss=2.657774\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.5665430068969726\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] Epoch[80] Batch [10]#011Speed: 1720.86 samples/sec#011loss=2.566543\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747868082.2560494, \"EndTime\": 1747868083.2999132, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1043.6105728149414, \"count\": 1, \"min\": 1043.6105728149414, \"max\": 1043.6105728149414}}}\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1304.01846133322 records/second\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.6577741232785312\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] Epoch[81] Batch[0] avg_epoch_loss=2.692976\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.6929757595062256\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] Epoch[81] Batch[5] avg_epoch_loss=2.634967\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.63496732711792\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] Epoch[81] Batch [5]#011Speed: 1983.67 samples/sec#011loss=2.634967\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] Epoch[81] Batch[10] avg_epoch_loss=2.654137\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.677140951156616\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] Epoch[81] Batch [10]#011Speed: 1989.24 samples/sec#011loss=2.677141\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747868083.299972, \"EndTime\": 1747868084.2732759, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 972.9986190795898, \"count\": 1, \"min\": 972.9986190795898, \"max\": 972.9986190795898}}}\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1416.114487745059 records/second\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.6541371562264184\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] Epoch[82] Batch[0] avg_epoch_loss=2.537997\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.5379974842071533\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] Epoch[82] Batch[5] avg_epoch_loss=2.619919\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.619919180870056\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] Epoch[82] Batch [5]#011Speed: 2090.42 samples/sec#011loss=2.619919\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Epoch[82] Batch[10] avg_epoch_loss=2.515828\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=2.3909193754196165\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Epoch[82] Batch [10]#011Speed: 2121.49 samples/sec#011loss=2.390919\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747868084.2733338, \"EndTime\": 1747868085.201013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.4308681488037, \"count\": 1, \"min\": 927.4308681488037, \"max\": 927.4308681488037}}}\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1389.737035489017 records/second\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.5158283602107656\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_9988aea7-4a55-481c-bfb8-bb3000f40940-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868085.2010689, \"EndTime\": 1747868085.2109895, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.57942008972168, \"count\": 1, \"min\": 9.57942008972168, \"max\": 9.57942008972168}}}\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Epoch[83] Batch[0] avg_epoch_loss=2.776438\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.7764382362365723\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Epoch[83] Batch[5] avg_epoch_loss=2.704990\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.7049895524978638\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Epoch[83] Batch [5]#011Speed: 2028.01 samples/sec#011loss=2.704990\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] processed a total of 1258 examples\n",
      "#metrics {\"StartTime\": 1747868085.2110431, \"EndTime\": 1747868086.106716, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 895.6217765808105, \"count\": 1, \"min\": 895.6217765808105, \"max\": 895.6217765808105}}}\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1404.462723315409 records/second\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.6733351707458497\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] Epoch[84] Batch[0] avg_epoch_loss=2.745158\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.7451584339141846\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] Epoch[84] Batch[5] avg_epoch_loss=2.684010\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.6840099096298218\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] Epoch[84] Batch [5]#011Speed: 2110.88 samples/sec#011loss=2.684010\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] Epoch[84] Batch[10] avg_epoch_loss=2.781234\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.8979032039642334\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] Epoch[84] Batch [10]#011Speed: 2009.59 samples/sec#011loss=2.897903\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747868086.1067805, \"EndTime\": 1747868087.046054, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.9801025390625, \"count\": 1, \"min\": 938.9801025390625, \"max\": 938.9801025390625}}}\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1402.4567228522899 records/second\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.7812341343272817\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] Epoch[85] Batch[0] avg_epoch_loss=2.769842\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.7698419094085693\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] Epoch[85] Batch[5] avg_epoch_loss=2.683764\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.6837642192840576\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] Epoch[85] Batch [5]#011Speed: 2023.01 samples/sec#011loss=2.683764\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[85] Batch[10] avg_epoch_loss=2.694137\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=2.7065850734710692\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[85] Batch [10]#011Speed: 1992.74 samples/sec#011loss=2.706585\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747868087.0461118, \"EndTime\": 1747868088.0009742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.620361328125, \"count\": 1, \"min\": 954.620361328125, \"max\": 954.620361328125}}}\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1410.8548889478784 records/second\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.6941373348236084\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[86] Batch[0] avg_epoch_loss=2.655053\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.6550533771514893\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[86] Batch[5] avg_epoch_loss=2.642568\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.642568031946818\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[86] Batch [5]#011Speed: 2066.41 samples/sec#011loss=2.642568\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[86] Batch[10] avg_epoch_loss=2.618320\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.589222621917725\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[86] Batch [10]#011Speed: 1900.53 samples/sec#011loss=2.589223\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] processed a total of 1376 examples\n",
      "#metrics {\"StartTime\": 1747868088.001066, \"EndTime\": 1747868088.9602587, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.8954448699951, \"count\": 1, \"min\": 958.8954448699951, \"max\": 958.8954448699951}}}\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1434.8374116272958 records/second\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.61832011829723\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] Epoch[87] Batch[0] avg_epoch_loss=2.766579\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.7665786743164062\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] Epoch[87] Batch[5] avg_epoch_loss=2.666480\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.666479547818502\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] Epoch[87] Batch [5]#011Speed: 2120.71 samples/sec#011loss=2.666480\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] Epoch[87] Batch[10] avg_epoch_loss=2.664140\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.66133337020874\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] Epoch[87] Batch [10]#011Speed: 2054.49 samples/sec#011loss=2.661333\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747868088.960329, \"EndTime\": 1747868089.888624, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.009033203125, \"count\": 1, \"min\": 928.009033203125, \"max\": 928.009033203125}}}\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1443.8205206919097 records/second\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.664140376177701\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] Epoch[88] Batch[0] avg_epoch_loss=2.738768\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.738767623901367\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] Epoch[88] Batch[5] avg_epoch_loss=2.653844\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.653844396273295\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] Epoch[88] Batch [5]#011Speed: 2178.75 samples/sec#011loss=2.653844\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] processed a total of 1230 examples\n",
      "#metrics {\"StartTime\": 1747868089.8886814, \"EndTime\": 1747868090.7526479, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 863.7175559997559, \"count\": 1, \"min\": 863.7175559997559, \"max\": 863.7175559997559}}}\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1423.9213886272184 records/second\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.673880457878113\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] Epoch[89] Batch[0] avg_epoch_loss=2.685548\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.6855475902557373\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] Epoch[89] Batch[5] avg_epoch_loss=2.621079\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.6210792462031045\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] Epoch[89] Batch [5]#011Speed: 2040.75 samples/sec#011loss=2.621079\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] Epoch[89] Batch[10] avg_epoch_loss=2.532300\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=2.4257658958435058\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] Epoch[89] Batch [10]#011Speed: 1949.75 samples/sec#011loss=2.425766\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747868090.7527115, \"EndTime\": 1747868091.7325234, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 979.5064926147461, \"count\": 1, \"min\": 979.5064926147461, \"max\": 979.5064926147461}}}\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1373.0051137169842 records/second\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.532300450585105\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] Epoch[90] Batch[0] avg_epoch_loss=2.511914\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.5119142532348633\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] Epoch[90] Batch[5] avg_epoch_loss=2.552367\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.5523672898610434\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] Epoch[90] Batch [5]#011Speed: 1997.47 samples/sec#011loss=2.552367\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] Epoch[90] Batch[10] avg_epoch_loss=2.634405\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.7328495025634765\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] Epoch[90] Batch [10]#011Speed: 1847.70 samples/sec#011loss=2.732850\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] processed a total of 1374 examples\n",
      "#metrics {\"StartTime\": 1747868091.7325926, \"EndTime\": 1747868092.7115884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 978.7130355834961, \"count\": 1, \"min\": 978.7130355834961, \"max\": 978.7130355834961}}}\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1403.755518893788 records/second\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.6344046592712402\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] Epoch[91] Batch[0] avg_epoch_loss=2.660592\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.6605916023254395\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] Epoch[91] Batch[5] avg_epoch_loss=2.696772\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.696772495905558\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] Epoch[91] Batch [5]#011Speed: 2069.67 samples/sec#011loss=2.696772\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] processed a total of 1240 examples\n",
      "#metrics {\"StartTime\": 1747868092.711648, \"EndTime\": 1747868093.6031268, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 891.0551071166992, \"count\": 1, \"min\": 891.0551071166992, \"max\": 891.0551071166992}}}\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1391.4187828028078 records/second\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.637514042854309\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] Epoch[92] Batch[0] avg_epoch_loss=2.746128\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.7461283206939697\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] Epoch[92] Batch[5] avg_epoch_loss=2.701899\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.7018993695576987\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] Epoch[92] Batch [5]#011Speed: 2175.06 samples/sec#011loss=2.701899\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] Epoch[92] Batch[10] avg_epoch_loss=2.686649\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.668349266052246\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] Epoch[92] Batch [10]#011Speed: 1916.04 samples/sec#011loss=2.668349\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747868093.6032138, \"EndTime\": 1747868094.5678968, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 964.3692970275879, \"count\": 1, \"min\": 964.3692970275879, \"max\": 964.3692970275879}}}\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1391.4564892048058 records/second\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.6866493225097656\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] Epoch[93] Batch[0] avg_epoch_loss=2.699401\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.6994011402130127\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] Epoch[93] Batch[5] avg_epoch_loss=2.599568\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.599567691485087\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] Epoch[93] Batch [5]#011Speed: 2085.31 samples/sec#011loss=2.599568\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] Epoch[93] Batch[10] avg_epoch_loss=2.594279\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.5879316329956055\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] Epoch[93] Batch [10]#011Speed: 2059.90 samples/sec#011loss=2.587932\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747868094.5679564, \"EndTime\": 1747868095.540287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 972.0666408538818, \"count\": 1, \"min\": 972.0666408538818, \"max\": 972.0666408538818}}}\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1372.2066755756746 records/second\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.594278573989868\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] Epoch[94] Batch[0] avg_epoch_loss=2.523899\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.5238993167877197\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] Epoch[94] Batch[5] avg_epoch_loss=2.728736\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.72873584429423\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] Epoch[94] Batch [5]#011Speed: 2044.46 samples/sec#011loss=2.728736\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] processed a total of 1244 examples\n",
      "#metrics {\"StartTime\": 1747868095.540348, \"EndTime\": 1747868096.4461486, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 905.5004119873047, \"count\": 1, \"min\": 905.5004119873047, \"max\": 905.5004119873047}}}\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1373.6805904464734 records/second\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.7114044427871704\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] Epoch[95] Batch[0] avg_epoch_loss=2.640889\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.6408886909484863\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] Epoch[95] Batch[5] avg_epoch_loss=2.743198\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.7431979179382324\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] Epoch[95] Batch [5]#011Speed: 2095.43 samples/sec#011loss=2.743198\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] Epoch[95] Batch[10] avg_epoch_loss=2.779997\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.824154996871948\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] Epoch[95] Batch [10]#011Speed: 2021.89 samples/sec#011loss=2.824155\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747868096.446213, \"EndTime\": 1747868097.4061382, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 959.6130847930908, \"count\": 1, \"min\": 959.6130847930908, \"max\": 959.6130847930908}}}\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1399.3864487118972 records/second\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.7799965901808306\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] Epoch[96] Batch[0] avg_epoch_loss=2.770406\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.7704055309295654\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] Epoch[96] Batch[5] avg_epoch_loss=2.719531\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.7195308208465576\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] Epoch[96] Batch [5]#011Speed: 1895.15 samples/sec#011loss=2.719531\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] Epoch[96] Batch[10] avg_epoch_loss=2.728376\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.7389899253845216\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] Epoch[96] Batch [10]#011Speed: 1996.90 samples/sec#011loss=2.738990\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] processed a total of 1379 examples\n",
      "#metrics {\"StartTime\": 1747868097.4061992, \"EndTime\": 1747868098.3827183, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 976.207971572876, \"count\": 1, \"min\": 976.207971572876, \"max\": 976.207971572876}}}\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1412.4818806700366 records/second\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.728375868363814\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] Epoch[97] Batch[0] avg_epoch_loss=2.632780\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.632780075073242\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[97] Batch[5] avg_epoch_loss=2.638247\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.6382468938827515\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[97] Batch [5]#011Speed: 2001.07 samples/sec#011loss=2.638247\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[97] Batch[10] avg_epoch_loss=2.652910\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.670504856109619\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[97] Batch [10]#011Speed: 2026.65 samples/sec#011loss=2.670505\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747868098.3827782, \"EndTime\": 1747868099.3407185, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.1113586425781, \"count\": 1, \"min\": 957.1113586425781, \"max\": 957.1113586425781}}}\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1375.8934176087707 records/second\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.652909603985873\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[98] Batch[0] avg_epoch_loss=2.516323\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.5163233280181885\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[98] Batch[5] avg_epoch_loss=2.633808\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.6338077783584595\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[98] Batch [5]#011Speed: 2022.45 samples/sec#011loss=2.633808\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] Epoch[98] Batch[10] avg_epoch_loss=2.712326\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=2.806547927856445\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] Epoch[98] Batch [10]#011Speed: 2074.09 samples/sec#011loss=2.806548\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747868099.3407729, \"EndTime\": 1747868100.28715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.0678100585938, \"count\": 1, \"min\": 946.0678100585938, \"max\": 946.0678100585938}}}\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1367.635680800388 records/second\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.712326028130271\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] Epoch[99] Batch[0] avg_epoch_loss=2.733343\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.7333426475524902\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] Epoch[99] Batch[5] avg_epoch_loss=2.710128\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.7101282278696694\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] Epoch[99] Batch [5]#011Speed: 2025.33 samples/sec#011loss=2.710128\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] processed a total of 1251 examples\n",
      "#metrics {\"StartTime\": 1747868100.2872062, \"EndTime\": 1747868101.1849966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.451639175415, \"count\": 1, \"min\": 897.451639175415, \"max\": 897.451639175415}}}\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1393.7970148143622 records/second\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.646059823036194\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] Epoch[100] Batch[0] avg_epoch_loss=2.655790\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.655789852142334\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] Epoch[100] Batch[5] avg_epoch_loss=2.629428\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.6294278701146445\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] Epoch[100] Batch [5]#011Speed: 2006.76 samples/sec#011loss=2.629428\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] Epoch[100] Batch[10] avg_epoch_loss=2.766549\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.9310939788818358\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] Epoch[100] Batch [10]#011Speed: 1799.16 samples/sec#011loss=2.931094\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747868101.185061, \"EndTime\": 1747868102.1789312, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 993.5402870178223, \"count\": 1, \"min\": 993.5402870178223, \"max\": 993.5402870178223}}}\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1305.3205821716647 records/second\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.766548828645186\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] Epoch[101] Batch[0] avg_epoch_loss=3.951824\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=3.951824188232422\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] Epoch[101] Batch[5] avg_epoch_loss=3.365800\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=3.3658004999160767\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] Epoch[101] Batch [5]#011Speed: 2095.29 samples/sec#011loss=3.365800\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] Epoch[101] Batch[10] avg_epoch_loss=3.355721\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=3.3436246871948243\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] Epoch[101] Batch [10]#011Speed: 1943.21 samples/sec#011loss=3.343625\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] processed a total of 1364 examples\n",
      "#metrics {\"StartTime\": 1747868102.1789882, \"EndTime\": 1747868103.1309986, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.7612457275391, \"count\": 1, \"min\": 951.7612457275391, \"max\": 951.7612457275391}}}\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1433.0047340752221 records/second\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=101, train loss <loss>=3.3557205850427803\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] Epoch[102] Batch[0] avg_epoch_loss=3.288331\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=3.288330554962158\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] Epoch[102] Batch[5] avg_epoch_loss=3.013932\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=3.0139323075612388\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] Epoch[102] Batch [5]#011Speed: 1996.02 samples/sec#011loss=3.013932\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] Epoch[102] Batch[10] avg_epoch_loss=3.066422\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=3.1294085502624513\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] Epoch[102] Batch [10]#011Speed: 1990.62 samples/sec#011loss=3.129409\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747868103.1310563, \"EndTime\": 1747868104.0968542, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 965.5489921569824, \"count\": 1, \"min\": 965.5489921569824, \"max\": 965.5489921569824}}}\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1342.1196185645358 records/second\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=102, train loss <loss>=3.0664215087890625\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] Epoch[103] Batch[0] avg_epoch_loss=3.001844\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=3.0018436908721924\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] Epoch[103] Batch[5] avg_epoch_loss=2.933886\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.933886090914408\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] Epoch[103] Batch [5]#011Speed: 1995.92 samples/sec#011loss=2.933886\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] Epoch[103] Batch[10] avg_epoch_loss=2.798127\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.6352166652679445\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] Epoch[103] Batch [10]#011Speed: 1984.37 samples/sec#011loss=2.635217\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747868104.0969136, \"EndTime\": 1747868105.0831618, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 985.9631061553955, \"count\": 1, \"min\": 985.9631061553955, \"max\": 985.9631061553955}}}\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1319.3867151467907 records/second\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.7981272610751065\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] Epoch[104] Batch[0] avg_epoch_loss=2.926480\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.926480293273926\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] Epoch[104] Batch[5] avg_epoch_loss=2.855701\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.855700929959615\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] Epoch[104] Batch [5]#011Speed: 1951.87 samples/sec#011loss=2.855701\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747868105.083218, \"EndTime\": 1747868106.0000443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.5623188018799, \"count\": 1, \"min\": 916.5623188018799, \"max\": 916.5623188018799}}}\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1382.1942808155757 records/second\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.882403254508972\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] Epoch[105] Batch[0] avg_epoch_loss=2.678195\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.6781952381134033\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] Epoch[105] Batch[5] avg_epoch_loss=2.798267\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.798267443974813\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] Epoch[105] Batch [5]#011Speed: 1927.69 samples/sec#011loss=2.798267\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] Epoch[105] Batch[10] avg_epoch_loss=2.798478\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.79873104095459\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] Epoch[105] Batch [10]#011Speed: 1998.23 samples/sec#011loss=2.798731\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747868106.0001101, \"EndTime\": 1747868106.9737744, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.2863903045654, \"count\": 1, \"min\": 973.2863903045654, \"max\": 973.2863903045654}}}\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1391.0389511840795 records/second\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.7984781698747114\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] Epoch[106] Batch[0] avg_epoch_loss=2.817352\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.817352294921875\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] Epoch[106] Batch[5] avg_epoch_loss=2.793050\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.7930497328440347\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] Epoch[106] Batch [5]#011Speed: 2120.13 samples/sec#011loss=2.793050\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] Epoch[106] Batch[10] avg_epoch_loss=2.784385\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=2.7739876747131347\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] Epoch[106] Batch [10]#011Speed: 1921.12 samples/sec#011loss=2.773988\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] processed a total of 1414 examples\n",
      "#metrics {\"StartTime\": 1747868106.973832, \"EndTime\": 1747868107.9892282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1015.1159763336182, \"count\": 1, \"min\": 1015.1159763336182, \"max\": 1015.1159763336182}}}\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1392.814417315508 records/second\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.675286680459976\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] Epoch[107] Batch[0] avg_epoch_loss=2.787293\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.7872931957244873\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] Epoch[107] Batch[5] avg_epoch_loss=2.786016\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.786016265551249\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] Epoch[107] Batch [5]#011Speed: 1994.11 samples/sec#011loss=2.786016\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] Epoch[107] Batch[10] avg_epoch_loss=2.751252\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.709535551071167\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] Epoch[107] Batch [10]#011Speed: 1721.41 samples/sec#011loss=2.709536\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] processed a total of 1364 examples\n",
      "#metrics {\"StartTime\": 1747868107.9892924, \"EndTime\": 1747868108.997727, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1008.1026554107666, \"count\": 1, \"min\": 1008.1026554107666, \"max\": 1008.1026554107666}}}\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1352.9216201202796 records/second\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.751252304423939\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] Epoch[108] Batch[0] avg_epoch_loss=2.717089\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.7170891761779785\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] Epoch[108] Batch[5] avg_epoch_loss=2.764505\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.7645047108332315\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] Epoch[108] Batch [5]#011Speed: 1894.25 samples/sec#011loss=2.764505\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] Epoch[108] Batch[10] avg_epoch_loss=2.727584\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.68327956199646\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] Epoch[108] Batch [10]#011Speed: 1914.41 samples/sec#011loss=2.683280\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747868108.9977841, \"EndTime\": 1747868110.000153, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1002.1054744720459, \"count\": 1, \"min\": 1002.1054744720459, \"max\": 1002.1054744720459}}}\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1348.0489060746247 records/second\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.727584188634699\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] Epoch[109] Batch[0] avg_epoch_loss=2.709381\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.709380865097046\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] Epoch[109] Batch[5] avg_epoch_loss=2.665857\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.665856957435608\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] Epoch[109] Batch [5]#011Speed: 2074.24 samples/sec#011loss=2.665857\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] Epoch[109] Batch[10] avg_epoch_loss=2.683119\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.7038345336914062\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] Epoch[109] Batch [10]#011Speed: 1938.86 samples/sec#011loss=2.703835\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747868110.0002103, \"EndTime\": 1747868110.9562175, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.7368755340576, \"count\": 1, \"min\": 955.7368755340576, \"max\": 955.7368755340576}}}\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1441.6878032694797 records/second\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.6831194920973345\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] Epoch[110] Batch[0] avg_epoch_loss=2.644939\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.6449389457702637\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] Epoch[110] Batch[5] avg_epoch_loss=2.718509\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.718508799870809\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] Epoch[110] Batch [5]#011Speed: 2032.88 samples/sec#011loss=2.718509\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] Epoch[110] Batch[10] avg_epoch_loss=2.766152\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.8233241558074953\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] Epoch[110] Batch [10]#011Speed: 2054.18 samples/sec#011loss=2.823324\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747868110.956275, \"EndTime\": 1747868111.9071922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.5953788757324, \"count\": 1, \"min\": 950.5953788757324, \"max\": 950.5953788757324}}}\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1347.453491329045 records/second\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.7661521434783936\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] Epoch[111] Batch[0] avg_epoch_loss=3.144874\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=3.144874095916748\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] Epoch[111] Batch[5] avg_epoch_loss=2.871602\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.8716015021006265\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] Epoch[111] Batch [5]#011Speed: 2108.83 samples/sec#011loss=2.871602\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] Epoch[111] Batch[10] avg_epoch_loss=2.871455\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=2.871278190612793\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] Epoch[111] Batch [10]#011Speed: 1817.31 samples/sec#011loss=2.871278\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] processed a total of 1364 examples\n",
      "#metrics {\"StartTime\": 1747868111.9072504, \"EndTime\": 1747868112.8778353, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 970.3290462493896, \"count\": 1, \"min\": 970.3290462493896, \"max\": 970.3290462493896}}}\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1405.5906031083998 records/second\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.8714545423334297\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] Epoch[112] Batch[0] avg_epoch_loss=2.719615\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.7196147441864014\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] Epoch[112] Batch[5] avg_epoch_loss=2.750521\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.7505205074946084\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] Epoch[112] Batch [5]#011Speed: 2138.24 samples/sec#011loss=2.750521\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] Epoch[112] Batch[10] avg_epoch_loss=2.786705\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.8301273345947267\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] Epoch[112] Batch [10]#011Speed: 2013.03 samples/sec#011loss=2.830127\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747868112.877891, \"EndTime\": 1747868113.8166494, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.4865760803223, \"count\": 1, \"min\": 938.4865760803223, \"max\": 938.4865760803223}}}\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1398.9352251608727 records/second\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.786705428903753\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] Epoch[113] Batch[0] avg_epoch_loss=3.176594\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=3.1765942573547363\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] Epoch[113] Batch[5] avg_epoch_loss=3.020604\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=3.020604411760966\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] Epoch[113] Batch [5]#011Speed: 2122.97 samples/sec#011loss=3.020604\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] Epoch[113] Batch[10] avg_epoch_loss=2.884847\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.7219380378723144\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] Epoch[113] Batch [10]#011Speed: 1997.74 samples/sec#011loss=2.721938\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747868113.8167067, \"EndTime\": 1747868114.7603123, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.3615207672119, \"count\": 1, \"min\": 943.3615207672119, \"max\": 943.3615207672119}}}\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1385.3491257344722 records/second\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.884846969084306\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] Epoch[114] Batch[0] avg_epoch_loss=3.017334\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=3.017334222793579\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] Epoch[114] Batch[5] avg_epoch_loss=3.035681\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=3.0356813271840415\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] Epoch[114] Batch [5]#011Speed: 2160.25 samples/sec#011loss=3.035681\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747868114.7603693, \"EndTime\": 1747868115.6205723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 859.9410057067871, \"count\": 1, \"min\": 859.9410057067871, \"max\": 859.9410057067871}}}\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1485.9877823623797 records/second\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.941991376876831\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] Epoch[115] Batch[0] avg_epoch_loss=2.881479\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.8814785480499268\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] Epoch[115] Batch[5] avg_epoch_loss=2.808885\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.8088845014572144\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] Epoch[115] Batch [5]#011Speed: 2026.80 samples/sec#011loss=2.808885\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] Epoch[115] Batch[10] avg_epoch_loss=2.796095\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=2.780747079849243\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] Epoch[115] Batch [10]#011Speed: 1940.88 samples/sec#011loss=2.780747\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747868115.6206362, \"EndTime\": 1747868116.5820916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.1544609069824, \"count\": 1, \"min\": 961.1544609069824, \"max\": 961.1544609069824}}}\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1387.7917261324544 records/second\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.796094764362682\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] Epoch[116] Batch[0] avg_epoch_loss=2.803929\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.803929328918457\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] Epoch[116] Batch[5] avg_epoch_loss=2.794242\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.7942424615224204\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] Epoch[116] Batch [5]#011Speed: 2100.98 samples/sec#011loss=2.794242\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] Epoch[116] Batch[10] avg_epoch_loss=2.838817\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=2.892307090759277\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] Epoch[116] Batch [10]#011Speed: 1983.86 samples/sec#011loss=2.892307\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747868116.582149, \"EndTime\": 1747868117.5267673, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.3464279174805, \"count\": 1, \"min\": 944.3464279174805, \"max\": 944.3464279174805}}}\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1399.7841802752275 records/second\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.8388172929937188\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] Epoch[117] Batch[0] avg_epoch_loss=2.645959\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.645958662033081\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] Epoch[117] Batch[5] avg_epoch_loss=2.756181\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.756180683771769\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] Epoch[117] Batch [5]#011Speed: 2122.09 samples/sec#011loss=2.756181\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] Epoch[117] Batch[10] avg_epoch_loss=2.783390\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.8160403251647947\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] Epoch[117] Batch [10]#011Speed: 1982.98 samples/sec#011loss=2.816040\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747868117.5268245, \"EndTime\": 1747868118.4670541, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.9833679199219, \"count\": 1, \"min\": 939.9833679199219, \"max\": 939.9833679199219}}}\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1456.2798369230964 records/second\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.78338961167769\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] loss did not improve\n",
      "\n",
      "2025-05-21 22:55:24 Uploading - Uploading generated training model[05/21/2025 22:55:18 INFO 140039678244672] Epoch[118] Batch[0] avg_epoch_loss=2.818308\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.8183083534240723\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] Epoch[118] Batch[5] avg_epoch_loss=2.659153\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.659152865409851\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] Epoch[118] Batch [5]#011Speed: 2046.90 samples/sec#011loss=2.659153\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] Epoch[118] Batch[10] avg_epoch_loss=2.641338\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.619959592819214\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] Epoch[118] Batch [10]#011Speed: 2015.52 samples/sec#011loss=2.619960\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747868118.4671097, \"EndTime\": 1747868119.4202003, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.7978897094727, \"count\": 1, \"min\": 952.7978897094727, \"max\": 952.7978897094727}}}\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1381.072651568965 records/second\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.641337741505016\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] Epoch[119] Batch[0] avg_epoch_loss=2.735101\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.735100746154785\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[119] Batch[5] avg_epoch_loss=2.698972\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.69897198677063\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[119] Batch [5]#011Speed: 2134.16 samples/sec#011loss=2.698972\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[119] Batch[10] avg_epoch_loss=2.553305\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=2.3785037279129027\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[119] Batch [10]#011Speed: 2068.00 samples/sec#011loss=2.378504\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747868119.420257, \"EndTime\": 1747868120.3524597, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.6122531890869, \"count\": 1, \"min\": 931.6122531890869, \"max\": 931.6122531890869}}}\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1393.1558803968348 records/second\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.553304596380754\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[120] Batch[0] avg_epoch_loss=2.741342\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.7413418292999268\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[120] Batch[5] avg_epoch_loss=2.689299\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.6892987489700317\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[120] Batch [5]#011Speed: 2009.75 samples/sec#011loss=2.689299\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747868120.3525167, \"EndTime\": 1747868121.2500675, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.2265720367432, \"count\": 1, \"min\": 897.2265720367432, \"max\": 897.2265720367432}}}\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1418.6760363841775 records/second\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.6485931158065794\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] Epoch[121] Batch[0] avg_epoch_loss=2.723799\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.723799228668213\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] Epoch[121] Batch[5] avg_epoch_loss=2.658221\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.658221483230591\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] Epoch[121] Batch [5]#011Speed: 2091.90 samples/sec#011loss=2.658221\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] Epoch[121] Batch[10] avg_epoch_loss=2.702426\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=2.755470561981201\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] Epoch[121] Batch [10]#011Speed: 1950.74 samples/sec#011loss=2.755471\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747868121.2501256, \"EndTime\": 1747868122.2060935, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.0905227661133, \"count\": 1, \"min\": 955.0905227661133, \"max\": 955.0905227661133}}}\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1404.955113369742 records/second\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.7024256099354136\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] Epoch[122] Batch[0] avg_epoch_loss=2.863546\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.863546371459961\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] Epoch[122] Batch[5] avg_epoch_loss=2.821329\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.8213289976119995\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] Epoch[122] Batch [5]#011Speed: 2100.40 samples/sec#011loss=2.821329\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Epoch[122] Batch[10] avg_epoch_loss=2.989230\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=3.190711736679077\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Epoch[122] Batch [10]#011Speed: 2068.36 samples/sec#011loss=3.190712\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747868122.206159, \"EndTime\": 1747868123.1417396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.2045059204102, \"count\": 1, \"min\": 935.2045059204102, \"max\": 935.2045059204102}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1385.66527262781 records/second\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.9892302426424893\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Loading parameters from best epoch (82)\n",
      "#metrics {\"StartTime\": 1747868123.141797, \"EndTime\": 1747868123.1470907, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 4.97126579284668, \"count\": 1, \"min\": 4.97126579284668, \"max\": 4.97126579284668}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] stopping training now\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Final loss: 2.5158283602107656 (occurred at epoch 82)\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #quality_metric: host=algo-1, train final_loss <loss>=2.5158283602107656\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Worker algo-1 finished training.\n",
      "[05/21/2025 22:55:23 WARNING 140039678244672] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747868123.1471436, \"EndTime\": 1747868123.1964884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 48.979759216308594, \"count\": 1, \"min\": 48.979759216308594, \"max\": 48.979759216308594}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747868123.1965415, \"EndTime\": 1747868123.221122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 73.63533973693848, \"count\": 1, \"min\": 73.63533973693848, \"max\": 73.63533973693848}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868123.2211618, \"EndTime\": 1747868123.2257152, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 4.5146942138671875, \"count\": 1, \"min\": 4.5146942138671875, \"max\": 4.5146942138671875}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Successfully serialized the model for prediction.\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Evaluating model accuracy on testset using 100 samples\n",
      "#metrics {\"StartTime\": 1747868123.2257519, \"EndTime\": 1747868123.2273743, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}}}\n",
      "#metrics {\"StartTime\": 1747868123.2274091, \"EndTime\": 1747868123.4119763, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 184.62276458740234, \"count\": 1, \"min\": 184.62276458740234, \"max\": 184.62276458740234}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, RMSE): 39.07367798834659\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, mean_absolute_QuantileLoss): 1628.8888888888887\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, mean_wQuantileLoss): 0.583831142970928\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.1]): 0.22086021505376346\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.2]): 0.3720430107526882\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.3]): 0.49899641577060944\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.4]): 0.6005734767025089\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.5]): 0.6835125448028674\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.6]): 0.7416487455197132\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.7]): 0.7602150537634409\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.8]): 0.7449462365591398\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.9]): 0.63168458781362\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #quality_metric: host=algo-1, test RMSE <loss>=39.07367798834659\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.583831142970928\n",
      "#metrics {\"StartTime\": 1747868123.4120512, \"EndTime\": 1747868123.422676, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 4.419565200805664, \"count\": 1, \"min\": 4.419565200805664, \"max\": 4.419565200805664}, \"totaltime\": {\"sum\": 117487.07842826843, \"count\": 1, \"min\": 117487.07842826843, \"max\": 117487.07842826843}}}\n",
      "\n",
      "2025-05-21 22:55:38 Completed - Training job completed\n",
      "Training seconds: 271\n",
      "Billable seconds: 271\n",
      "CPU times: total: 9.92 s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "ddb84337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-21 22:55:38 Starting - Preparing the instances for training\n",
      "2025-05-21 22:55:38 Downloading - Downloading the training image\n",
      "2025-05-21 22:55:38 Training - Training image download completed. Training in progress.\n",
      "2025-05-21 22:55:38 Uploading - Uploading generated training model\n",
      "2025-05-21 22:55:38 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-21-22-50-26-760',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ce6db267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 17:57:50] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-57-50-381 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 17:57:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-57-50-381 \u001b]8;id=222346;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=403041;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 17:57:51] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-57-50-381                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 17:57:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=238830;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=813013;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-57-50-381                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-57-50-381                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=503750;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=857256;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-57-50-381                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "c6c75c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_list = convertir_a_series(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "4410c5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0.1   0.5   0.9\n",
       "2024-11-01   4.0   9.0  17.0\n",
       "2024-12-01  12.0  26.0  40.0\n",
       "2025-01-01   8.0  16.0  24.0\n",
       "2025-02-01   8.0  14.0  19.0\n",
       "2025-03-01   2.0   5.0  16.0\n",
       "2025-04-01   3.0   8.0  18.0"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=2\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "bd0d8d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    30\n",
       "2024-12-01    36\n",
       "2025-01-01     6\n",
       "2025-02-01    11\n",
       "2025-03-01     4\n",
       "2025-04-01    18\n",
       "Freq: MS, Name: cantidad, dtype: int32"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[i].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e8268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "ea59b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"likelihood\": \"student-T\",\n",
    "    \"learning_rate\": \"0.001\",\n",
    "}\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "4d7f6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    #\"likelihood\": CategoricalParameter([\"gaussian\", \"negative-binomial\", \"student-T\"]),\n",
    "    \"mini_batch_size\": IntegerParameter(32,512),\n",
    "    \"num_cells\": IntegerParameter(30, 200),  # Rango amplio\n",
    "    #\"learning_rate\": ContinuousParameter(0.0001, 0.1),\n",
    "    #\"num_layers\": IntegerParameter(1, 4),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "e5e74383",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"test:RMSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "9e9fe4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=10,\n",
    "    strategy=\"Bayesian\",\n",
    "    objective_type=\"Minimize\",\n",
    "    max_parallel_jobs=2,\n",
    "    early_stopping_type=\"Auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "1d3d50b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 18:18:47] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating hyperparameter tuning job with name:                          <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#3383\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3383</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250521</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1818</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 18:18:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating hyperparameter tuning job with name:                          \u001b]8;id=517022;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=312894;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#3383\u001b\\\u001b[2m3383\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         forecasting-deepar-\u001b[1;36m250521\u001b[0m-\u001b[1;36m1818\u001b[0m                                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\"train\": \"{}/train/\".format(s3_data_path) , \"test\": \"{}/test/\".format(s3_data_path)}, include_cls_metadata=False)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('forecasting-deepar-250521-1818-009-87cebbdc',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ccf324ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 21:58:37] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-02-58-36-412   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 21:58:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: forecasting-deepar-\u001b[1;36m2025\u001b[0m-05-22-02-58-36-412   \u001b]8;id=476931;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=454284;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 21:58:38] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-02-58-36-412                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 21:58:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=808770;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=504010;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         forecasting-deepar-\u001b[1;36m2025\u001b[0m-05-22-02-58-36-412                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-02-58-36-412 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name forecasting-deepar-\u001b[1;36m2025\u001b[0m-05-22-02-58-36-412 \u001b]8;id=479013;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=82651;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "f8f09a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>Tipo_Producto</th>\n",
       "      <th>segmento_producto</th>\n",
       "      <th>supergrupo_producto</th>\n",
       "      <th>grupo_producto</th>\n",
       "      <th>subgrupo_producto</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               material  Tipo_Producto  segmento_producto  \\\n",
       "2024-11-01  20000337001              0                  0   \n",
       "2024-12-01  20000337001              0                  0   \n",
       "2025-01-01  20000337001              0                  0   \n",
       "2025-02-01  20000337001              0                  0   \n",
       "2025-03-01  20000337001              0                  0   \n",
       "2025-04-01  20000337001              0                  0   \n",
       "\n",
       "            supergrupo_producto  grupo_producto  subgrupo_producto  cantidad  \\\n",
       "2024-11-01                    0               0                  0        33   \n",
       "2024-12-01                    0               0                  0        44   \n",
       "2025-01-01                    0               0                  0        17   \n",
       "2025-02-01                    0               0                  0        10   \n",
       "2025-03-01                    0               0                  0        14   \n",
       "2025-04-01                    0               0                  0         4   \n",
       "\n",
       "            month  quarter  \n",
       "2024-11-01     11        4  \n",
       "2024-12-01     12        4  \n",
       "2025-01-01      1        1  \n",
       "2025-02-01      2        1  \n",
       "2025-03-01      3        1  \n",
       "2025-04-01      4        2  "
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[0].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "7946e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "materiales = [df['material'].unique()[0] for df in timeseries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "6dae477c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000337001"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "materiales[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "8a685d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>10.772312</td>\n",
       "      <td>13.156721</td>\n",
       "      <td>15.081972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>17.859997</td>\n",
       "      <td>20.791840</td>\n",
       "      <td>23.978069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>7.654194</td>\n",
       "      <td>13.237596</td>\n",
       "      <td>17.679573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>-2.515227</td>\n",
       "      <td>14.570486</td>\n",
       "      <td>43.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>-14.742406</td>\n",
       "      <td>2.468850</td>\n",
       "      <td>19.240965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>-15.199956</td>\n",
       "      <td>-0.681237</td>\n",
       "      <td>19.299246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01  10.772312  13.156721  15.081972\n",
       "2024-12-01  17.859997  20.791840  23.978069\n",
       "2025-01-01   7.654194  13.237596  17.679573\n",
       "2025-02-01  -2.515227  14.570486  43.232300\n",
       "2025-03-01 -14.742406   2.468850  19.240965\n",
       "2025-04-01 -15.199956  -0.681237  19.299246"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=0\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "b6991007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    33\n",
       "2024-12-01    44\n",
       "2025-01-01    17\n",
       "2025-02-01    10\n",
       "2025-03-01    14\n",
       "2025-04-01     4\n",
       "Freq: MS, Name: cantidad, dtype: int32"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[i].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "e87945f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_predicciones_por_material(materiales, timeseries_list, vectores_cat, dynamic_list, predictor, horizon_pred=6):\n",
    "    \"\"\"\n",
    "    Genera predicciones para cada material y las devuelve en un diccionario.\n",
    "    \n",
    "    Args:\n",
    "        materiales: Lista con los nombres de materiales\n",
    "        timeseries_list: Lista de series temporales\n",
    "        vectores_cat: Lista de vectores categóricos\n",
    "        dynamic_list: Lista de features dinámicas\n",
    "        predictor: Modelo predictor entrenado\n",
    "        horizon_pred: Horizonte de predicción (default: 6)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con materiales como keys y dataframes de predicciones como values\n",
    "    \"\"\"\n",
    "    predicciones_dict = {}\n",
    "    \n",
    "    for i in range(len(materiales)):\n",
    "        material = materiales[i]\n",
    "        \n",
    "        # Generar predicción para el índice i\n",
    "        prediccion = predictor.predict(\n",
    "            ts = timeseries_list[i][:-horizon_pred], \n",
    "            cat=vectores_cat[i],\n",
    "            dynamic_feat=dynamic_list[i],\n",
    "            quantiles=[0.1, 0.5, 0.9],\n",
    "        )\n",
    "        \n",
    "        # Guardar en el diccionario\n",
    "        predicciones_dict[material] = prediccion\n",
    "        \n",
    "    return predicciones_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "bb403277",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_por_material = generar_predicciones_por_material(\n",
    "    materiales=materiales,\n",
    "    timeseries_list=timeseries_list,\n",
    "    vectores_cat=vectores_cat,\n",
    "    dynamic_list=dynamic_list,\n",
    "    predictor=predictor,\n",
    "    horizon_pred=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "ae35c96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([20000337001, 20000400003, 20000815002, 20000815003, 20000837001, 20000837002, 20001016001, 20001374001, 20003147001, 20003257001, 20003257002, 20003257004, 20008046001, 25109225001, 25109232001])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_por_material.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "4cf5c956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>11.174452</td>\n",
       "      <td>13.033033</td>\n",
       "      <td>15.327240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>17.000874</td>\n",
       "      <td>20.702934</td>\n",
       "      <td>24.452698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>7.063230</td>\n",
       "      <td>12.199194</td>\n",
       "      <td>17.474936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>-5.257400</td>\n",
       "      <td>16.376047</td>\n",
       "      <td>34.438889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>-14.730208</td>\n",
       "      <td>1.734847</td>\n",
       "      <td>24.478224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>-19.101561</td>\n",
       "      <td>1.368773</td>\n",
       "      <td>17.366959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01  11.174452  13.033033  15.327240\n",
       "2024-12-01  17.000874  20.702934  24.452698\n",
       "2025-01-01   7.063230  12.199194  17.474936\n",
       "2025-02-01  -5.257400  16.376047  34.438889\n",
       "2025-03-01 -14.730208   1.734847  24.478224\n",
       "2025-04-01 -19.101561   1.368773  17.366959"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_por_material[20000337001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "994789f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado: mensual_modificado_test.xlsx\n",
      "Orden de columnas: ['Material', 'Fecha', '0.1', '0.5', '0.9']\n",
      "Formato de fecha: YYYY-MM-DD\n"
     ]
    }
   ],
   "source": [
    "def exportar_predicciones_consolidado(predicciones_dict, nombre_archivo=\"mensual_modificado_test.xlsx\"):\n",
    "    \"\"\"\n",
    "    Exporta todas las predicciones con Material y Fecha como primeras dos columnas.\n",
    "    \"\"\"\n",
    "    \n",
    "    dfs_list = []\n",
    "    \n",
    "    for material, prediccion in predicciones_dict.items():\n",
    "        try:\n",
    "            # Convertir a DataFrame\n",
    "            if hasattr(prediccion, 'to_dataframe'):\n",
    "                df_pred = prediccion.to_dataframe()\n",
    "            elif hasattr(prediccion, 'to_pandas'):\n",
    "                df_pred = prediccion.to_pandas()\n",
    "            else:\n",
    "                df_pred = prediccion\n",
    "            \n",
    "            # Resetear índice y renombrar a 'Fecha'\n",
    "            df_pred = df_pred.reset_index()\n",
    "            date_col = df_pred.columns[0]\n",
    "            df_pred = df_pred.rename(columns={date_col: 'Fecha'})\n",
    "            \n",
    "            # Formatear fechas\n",
    "            df_pred['Fecha'] = pd.to_datetime(df_pred['Fecha']).dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Agregar columna de material\n",
    "            df_pred['Material'] = material\n",
    "            \n",
    "            dfs_list.append(df_pred)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {material}: {e}\")\n",
    "    \n",
    "    # Concatenar todos los DataFrames\n",
    "    if dfs_list:\n",
    "        df_final = pd.concat(dfs_list, ignore_index=True)\n",
    "        \n",
    "        # Reorganizar columnas: Material, Fecha, luego el resto en orden\n",
    "        other_cols = [col for col in df_final.columns if col not in ['Material', 'Fecha']]\n",
    "        cols = ['Material', 'Fecha'] + other_cols\n",
    "        df_final = df_final[cols]\n",
    "        \n",
    "        # Exportar\n",
    "        df_final.to_excel(nombre_archivo, index=False)\n",
    "        print(f\"Archivo guardado: {nombre_archivo}\")\n",
    "        print(f\"Orden de columnas: {list(df_final.columns)}\")\n",
    "        print(\"Formato de fecha: YYYY-MM-DD\")\n",
    "    else:\n",
    "        print(\"Error: No se pudieron procesar las predicciones\")\n",
    "\n",
    "# Ejecutar\n",
    "exportar_predicciones_consolidado(predicciones_por_material, \"mensual_modificado_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000caab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### ENTRENAMIENTO CON TODA LA DATA CON HYPERPARÁMETROS OPTIMIZADOS #####################\n",
    "#DATA TEST (COMPLETA) --> PARA TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "8504224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.2xlarge\",\n",
    "   # use_spot_instances=True,\n",
    "   # max_run=1800,  # max training time in seconds\n",
    "   # max_wait=1800,  # seconds to wait for spot instance\n",
    "    base_job_name=\"lilipink-forecasting\",\n",
    "    output_path=s3_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "318d25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"learning_rate\": \"1E-3\",\n",
    "    \"likelihood\":\"student-T\",\n",
    "    \"mini_batch_size\": \"449\",\n",
    "    \"num_cells\": \"56\",  # Rango amplio\n",
    "    #\"learning_rate\": \"0.001\",\n",
    "    \"num_layers\": \"2\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "e3b6549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "888e4f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 22:48:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 22:48:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=842486;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=413242;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 22:48:30] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-03-48-30-015                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 22:48:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=168109;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=613742;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-03-48-30-015                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-22 03:48:32 Starting - Starting the training job...\n",
      "2025-05-22 03:49:08 Downloading - Downloading input data...\n",
      "2025-05-22 03:49:23 Downloading - Downloading the training image.........\n",
      "2025-05-22 03:51:19 Training - Training image download completed. Training in progress....Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '18', 'early_stopping_patience': '40', 'epochs': '400', 'learning_rate': '1E-3', 'likelihood': 'student-T', 'mini_batch_size': '449', 'num_cells': '56', 'num_layers': '2', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '1E-3', 'likelihood': 'student-T', 'mini_batch_size': '449', 'num_cells': '56', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '18', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Detected entry point for worker worker\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Using early stopping with patience 40\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] random_seed is None\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/test.json` and will be used for training.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/test.json` and will be used for training.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] [cardinality=auto] Inferred value of cardinality=[2, 4, 5, 6, 6] from dataset.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Training set statistics:\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Integer time series\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] number of time series: 15\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] number of observations: 672\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] mean target length: 44.8\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] min/mean/max target: 1.0/30.99702380952381/388.0\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] mean abs(target): 30.99702380952381\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] contains missing values: no\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Small number of time series. Doing 300 passes over dataset with prob 0.9977777777777778 per epoch.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] No test channel found not running evaluations\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] #memory_usage::<batchbuffer> = 2.1889572143554688 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] nvidia-smi: took 0.106 seconds to run.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] nvidia-smi identified 0 GPUs.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Number of GPUs being used: 0\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Create Store: local\n",
      "#metrics {\"StartTime\": 1747885899.4719648, \"EndTime\": 1747885899.520339, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 47.48106002807617, \"count\": 1, \"min\": 47.48106002807617, \"max\": 47.48106002807617}}}\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Number of GPUs being used: 0\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] #memory_usage::<model> = 102 mb\n",
      "#metrics {\"StartTime\": 1747885899.5204067, \"EndTime\": 1747885899.597773, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 125.68855285644531, \"count\": 1, \"min\": 125.68855285644531, \"max\": 125.68855285644531}}}\n",
      "[03:51:40] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 100576 bytes with malloc directly\n",
      "[05/22/2025 03:51:40 INFO 140041726678848] Epoch[0] Batch[0] avg_epoch_loss=3.674480\n",
      "[05/22/2025 03:51:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.674479801033547\n",
      "[05/22/2025 03:51:41 INFO 140041726678848] Epoch[0] Batch[5] avg_epoch_loss=3.655242\n",
      "[05/22/2025 03:51:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.655241855091755\n",
      "[05/22/2025 03:51:41 INFO 140041726678848] Epoch[0] Batch [5]#011Speed: 2217.95 samples/sec#011loss=3.655242\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] Epoch[0] Batch[10] avg_epoch_loss=3.592270\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.5167035143200165\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] Epoch[0] Batch [10]#011Speed: 1977.04 samples/sec#011loss=3.516704\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] processed a total of 4614 examples\n",
      "#metrics {\"StartTime\": 1747885899.5978258, \"EndTime\": 1747885902.2660196, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 2668.1220531463623, \"count\": 1, \"min\": 2668.1220531463623, \"max\": 2668.1220531463623}}}\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1729.241452002058 records/second\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.5922698820136922\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_5a5c4cca-daec-4fee-8b9c-e84ba25542b5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885902.2660825, \"EndTime\": 1747885902.2770402, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.645151138305664, \"count\": 1, \"min\": 10.645151138305664, \"max\": 10.645151138305664}}}\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] Epoch[1] Batch[0] avg_epoch_loss=3.650374\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.6503737689657574\n",
      "[05/22/2025 03:51:43 INFO 140041726678848] Epoch[1] Batch[5] avg_epoch_loss=3.553188\n",
      "[05/22/2025 03:51:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.5531879020073545\n",
      "[05/22/2025 03:51:43 INFO 140041726678848] Epoch[1] Batch [5]#011Speed: 1786.02 samples/sec#011loss=3.553188\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] Epoch[1] Batch[10] avg_epoch_loss=3.484337\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.4017167055261694\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] Epoch[1] Batch [10]#011Speed: 1990.47 samples/sec#011loss=3.401717\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] processed a total of 4666 examples\n",
      "#metrics {\"StartTime\": 1747885902.2770839, \"EndTime\": 1747885905.0903966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2813.264846801758, \"count\": 1, \"min\": 2813.264846801758, \"max\": 2813.264846801758}}}\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1658.5208620373176 records/second\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.48433735815227\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_b5d4b7d1-798d-45a5-8a32-32c76a8e16a9-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885905.090455, \"EndTime\": 1747885905.1021864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.363506317138672, \"count\": 1, \"min\": 11.363506317138672, \"max\": 11.363506317138672}}}\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] Epoch[2] Batch[0] avg_epoch_loss=3.532750\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.532750458919126\n",
      "[05/22/2025 03:51:46 INFO 140041726678848] Epoch[2] Batch[5] avg_epoch_loss=3.463854\n",
      "[05/22/2025 03:51:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.4638541376670378\n",
      "[05/22/2025 03:51:46 INFO 140041726678848] Epoch[2] Batch [5]#011Speed: 2257.32 samples/sec#011loss=3.463854\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] Epoch[2] Batch[10] avg_epoch_loss=3.383008\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.285991602432489\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] Epoch[2] Batch [10]#011Speed: 2044.67 samples/sec#011loss=3.285992\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] processed a total of 4589 examples\n",
      "#metrics {\"StartTime\": 1747885905.102238, \"EndTime\": 1747885907.6247246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.4356651306152, \"count\": 1, \"min\": 2522.4356651306152, \"max\": 2522.4356651306152}}}\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1819.2140339031173 records/second\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.3830075307422427\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_7277c9da-459d-4cd9-9389-d324ad214921-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885907.624779, \"EndTime\": 1747885907.6346512, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.490251541137695, \"count\": 1, \"min\": 9.490251541137695, \"max\": 9.490251541137695}}}\n",
      "[05/22/2025 03:51:48 INFO 140041726678848] Epoch[3] Batch[0] avg_epoch_loss=3.366224\n",
      "[05/22/2025 03:51:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.366224259204482\n",
      "[05/22/2025 03:51:49 INFO 140041726678848] Epoch[3] Batch[5] avg_epoch_loss=3.442951\n",
      "[05/22/2025 03:51:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.442950706793453\n",
      "[05/22/2025 03:51:49 INFO 140041726678848] Epoch[3] Batch [5]#011Speed: 2291.17 samples/sec#011loss=3.442951\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] Epoch[3] Batch[10] avg_epoch_loss=3.433691\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=3.4225801259743873\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] Epoch[3] Batch [10]#011Speed: 2006.64 samples/sec#011loss=3.422580\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] processed a total of 4562 examples\n",
      "#metrics {\"StartTime\": 1747885907.6347108, \"EndTime\": 1747885910.1574924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.728681564331, \"count\": 1, \"min\": 2522.728681564331, \"max\": 2522.728681564331}}}\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1808.2968014707237 records/second\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.433691351875696\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] Epoch[4] Batch[0] avg_epoch_loss=3.413021\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.4130206883351892\n",
      "[05/22/2025 03:51:51 INFO 140041726678848] Epoch[4] Batch[5] avg_epoch_loss=3.426347\n",
      "[05/22/2025 03:51:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.4263467427616927\n",
      "[05/22/2025 03:51:51 INFO 140041726678848] Epoch[4] Batch [5]#011Speed: 2274.81 samples/sec#011loss=3.426347\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] Epoch[4] Batch[10] avg_epoch_loss=3.329502\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.213288264285217\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] Epoch[4] Batch [10]#011Speed: 2000.97 samples/sec#011loss=3.213288\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] processed a total of 4733 examples\n",
      "#metrics {\"StartTime\": 1747885910.1575532, \"EndTime\": 1747885912.6887782, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2530.925750732422, \"count\": 1, \"min\": 2530.925750732422, \"max\": 2530.925750732422}}}\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1870.0025915999456 records/second\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.3295019798178402\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_c588414d-c887-485a-acd1-3cfd61b77d26-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885912.6888385, \"EndTime\": 1747885912.6991992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.085582733154297, \"count\": 1, \"min\": 10.085582733154297, \"max\": 10.085582733154297}}}\n",
      "[05/22/2025 03:51:53 INFO 140041726678848] Epoch[5] Batch[0] avg_epoch_loss=3.472590\n",
      "[05/22/2025 03:51:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.472589913349109\n",
      "[05/22/2025 03:51:54 INFO 140041726678848] Epoch[5] Batch[5] avg_epoch_loss=3.436483\n",
      "[05/22/2025 03:51:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.4364830192673534\n",
      "[05/22/2025 03:51:54 INFO 140041726678848] Epoch[5] Batch [5]#011Speed: 2294.40 samples/sec#011loss=3.436483\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] Epoch[5] Batch[10] avg_epoch_loss=3.385087\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.32341254219446\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] Epoch[5] Batch [10]#011Speed: 2027.05 samples/sec#011loss=3.323413\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] processed a total of 4711 examples\n",
      "#metrics {\"StartTime\": 1747885912.6992507, \"EndTime\": 1747885915.2127838, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2513.4832859039307, \"count\": 1, \"min\": 2513.4832859039307, \"max\": 2513.4832859039307}}}\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1874.1953571770373 records/second\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.3850873478705834\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] Epoch[6] Batch[0] avg_epoch_loss=3.393776\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.3937759909173164\n",
      "[05/22/2025 03:51:56 INFO 140041726678848] Epoch[6] Batch[5] avg_epoch_loss=3.388423\n",
      "[05/22/2025 03:51:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.3884229313114793\n",
      "[05/22/2025 03:51:56 INFO 140041726678848] Epoch[6] Batch [5]#011Speed: 2293.32 samples/sec#011loss=3.388423\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] Epoch[6] Batch[10] avg_epoch_loss=3.404573\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.4239522071617485\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] Epoch[6] Batch [10]#011Speed: 2013.73 samples/sec#011loss=3.423952\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] processed a total of 4653 examples\n",
      "#metrics {\"StartTime\": 1747885915.2128837, \"EndTime\": 1747885917.758852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2545.6950664520264, \"count\": 1, \"min\": 2545.6950664520264, \"max\": 2545.6950664520264}}}\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1827.7308090618887 records/second\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.4045726021525105\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:51:58 INFO 140041726678848] Epoch[7] Batch[0] avg_epoch_loss=3.318570\n",
      "[05/22/2025 03:51:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.3185698035565143\n",
      "[05/22/2025 03:51:59 INFO 140041726678848] Epoch[7] Batch[5] avg_epoch_loss=3.369144\n",
      "[05/22/2025 03:51:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.3691442499536004\n",
      "[05/22/2025 03:51:59 INFO 140041726678848] Epoch[7] Batch [5]#011Speed: 2306.82 samples/sec#011loss=3.369144\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] Epoch[7] Batch[10] avg_epoch_loss=3.282125\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.1777028922779786\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] Epoch[7] Batch [10]#011Speed: 2015.70 samples/sec#011loss=3.177703\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] processed a total of 4676 examples\n",
      "#metrics {\"StartTime\": 1747885917.7589107, \"EndTime\": 1747885920.264536, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2505.356550216675, \"count\": 1, \"min\": 2505.356550216675, \"max\": 2505.356550216675}}}\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1866.3393819180415 records/second\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.282125451010136\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_cf1f2cd9-d599-4a11-91f0-0dd52a663962-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885920.2645917, \"EndTime\": 1747885920.2753098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.443687438964844, \"count\": 1, \"min\": 10.443687438964844, \"max\": 10.443687438964844}}}\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] Epoch[8] Batch[0] avg_epoch_loss=3.324413\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.3244125943937917\n",
      "[05/22/2025 03:52:01 INFO 140041726678848] Epoch[8] Batch[5] avg_epoch_loss=3.299807\n",
      "[05/22/2025 03:52:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.2998072702794405\n",
      "[05/22/2025 03:52:01 INFO 140041726678848] Epoch[8] Batch [5]#011Speed: 2200.58 samples/sec#011loss=3.299807\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] Epoch[8] Batch[10] avg_epoch_loss=3.348431\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.406779605721047\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] Epoch[8] Batch [10]#011Speed: 2025.23 samples/sec#011loss=3.406780\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] processed a total of 4660 examples\n",
      "#metrics {\"StartTime\": 1747885920.2753785, \"EndTime\": 1747885922.8368292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2561.398983001709, \"count\": 1, \"min\": 2561.398983001709, \"max\": 2561.398983001709}}}\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1819.2561356923943 records/second\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.348431059116534\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:03 INFO 140041726678848] Epoch[9] Batch[0] avg_epoch_loss=3.329106\n",
      "[05/22/2025 03:52:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.3291059124443207\n",
      "[05/22/2025 03:52:04 INFO 140041726678848] Epoch[9] Batch[5] avg_epoch_loss=3.315991\n",
      "[05/22/2025 03:52:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.315990558445852\n",
      "[05/22/2025 03:52:04 INFO 140041726678848] Epoch[9] Batch [5]#011Speed: 2248.52 samples/sec#011loss=3.315991\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] Epoch[9] Batch[10] avg_epoch_loss=3.397756\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.495875165297884\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] Epoch[9] Batch [10]#011Speed: 2008.75 samples/sec#011loss=3.495875\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] processed a total of 4600 examples\n",
      "#metrics {\"StartTime\": 1747885922.8368883, \"EndTime\": 1747885925.3739715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2536.8082523345947, \"count\": 1, \"min\": 2536.8082523345947, \"max\": 2536.8082523345947}}}\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1813.2393228372239 records/second\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.3977562888331394\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] Epoch[10] Batch[0] avg_epoch_loss=3.196760\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.196760215844237\n",
      "[05/22/2025 03:52:06 INFO 140041726678848] Epoch[10] Batch[5] avg_epoch_loss=3.326190\n",
      "[05/22/2025 03:52:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.326189909144163\n",
      "[05/22/2025 03:52:06 INFO 140041726678848] Epoch[10] Batch [5]#011Speed: 2209.69 samples/sec#011loss=3.326190\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] Epoch[10] Batch[10] avg_epoch_loss=3.291234\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.2492865003827953\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] Epoch[10] Batch [10]#011Speed: 1964.42 samples/sec#011loss=3.249287\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] processed a total of 4582 examples\n",
      "#metrics {\"StartTime\": 1747885925.374032, \"EndTime\": 1747885927.994217, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2619.926691055298, \"count\": 1, \"min\": 2619.926691055298, \"max\": 2619.926691055298}}}\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1748.8469218710459 records/second\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.291233814252632\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:08 INFO 140041726678848] Epoch[11] Batch[0] avg_epoch_loss=3.175697\n",
      "[05/22/2025 03:52:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.175696697957266\n",
      "[05/22/2025 03:52:09 INFO 140041726678848] Epoch[11] Batch[5] avg_epoch_loss=3.268217\n",
      "[05/22/2025 03:52:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.2682174308793845\n",
      "[05/22/2025 03:52:09 INFO 140041726678848] Epoch[11] Batch [5]#011Speed: 2223.79 samples/sec#011loss=3.268217\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] Epoch[11] Batch[10] avg_epoch_loss=3.400359\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=3.558929565701559\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] Epoch[11] Batch [10]#011Speed: 2061.41 samples/sec#011loss=3.558930\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] processed a total of 4626 examples\n",
      "#metrics {\"StartTime\": 1747885927.9942756, \"EndTime\": 1747885930.527696, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2533.1645011901855, \"count\": 1, \"min\": 2533.1645011901855, \"max\": 2533.1645011901855}}}\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1826.1188208958245 records/second\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.4003593103440095\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] Epoch[12] Batch[0] avg_epoch_loss=3.298322\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.298322172101197\n",
      "[05/22/2025 03:52:11 INFO 140041726678848] Epoch[12] Batch[5] avg_epoch_loss=3.281908\n",
      "[05/22/2025 03:52:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.281907883766588\n",
      "[05/22/2025 03:52:11 INFO 140041726678848] Epoch[12] Batch [5]#011Speed: 2273.86 samples/sec#011loss=3.281908\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] Epoch[12] Batch[10] avg_epoch_loss=3.246372\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=3.203728989768931\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] Epoch[12] Batch [10]#011Speed: 1979.71 samples/sec#011loss=3.203729\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] processed a total of 4642 examples\n",
      "#metrics {\"StartTime\": 1747885930.527748, \"EndTime\": 1747885933.083429, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2555.4513931274414, \"count\": 1, \"min\": 2555.4513931274414, \"max\": 2555.4513931274414}}}\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1816.4451010736734 records/second\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.2463720228585617\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_ca4ad5c7-bfa2-4ac6-a978-1441251f7d69-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885933.0834901, \"EndTime\": 1747885933.0938268, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.057687759399414, \"count\": 1, \"min\": 10.057687759399414, \"max\": 10.057687759399414}}}\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] Epoch[13] Batch[0] avg_epoch_loss=3.147404\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.147403844480791\n",
      "[05/22/2025 03:52:14 INFO 140041726678848] Epoch[13] Batch[5] avg_epoch_loss=3.229156\n",
      "[05/22/2025 03:52:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.229155565246265\n",
      "[05/22/2025 03:52:14 INFO 140041726678848] Epoch[13] Batch [5]#011Speed: 2251.94 samples/sec#011loss=3.229156\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] Epoch[13] Batch[10] avg_epoch_loss=3.315482\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.419074125226197\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] Epoch[13] Batch [10]#011Speed: 2047.55 samples/sec#011loss=3.419074\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] processed a total of 4545 examples\n",
      "#metrics {\"StartTime\": 1747885933.0938761, \"EndTime\": 1747885935.6113665, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2517.4381732940674, \"count\": 1, \"min\": 2517.4381732940674, \"max\": 2517.4381732940674}}}\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1805.3420005909493 records/second\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.315482183418961\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:16 INFO 140041726678848] Epoch[14] Batch[0] avg_epoch_loss=3.228868\n",
      "[05/22/2025 03:52:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.228867698618458\n",
      "[05/22/2025 03:52:17 INFO 140041726678848] Epoch[14] Batch[5] avg_epoch_loss=3.275035\n",
      "[05/22/2025 03:52:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.2750349717398617\n",
      "[05/22/2025 03:52:17 INFO 140041726678848] Epoch[14] Batch [5]#011Speed: 2239.24 samples/sec#011loss=3.275035\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] Epoch[14] Batch[10] avg_epoch_loss=3.324063\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=3.382897650160078\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] Epoch[14] Batch [10]#011Speed: 2023.80 samples/sec#011loss=3.382898\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] processed a total of 4617 examples\n",
      "#metrics {\"StartTime\": 1747885935.6114283, \"EndTime\": 1747885938.1513963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2539.705753326416, \"count\": 1, \"min\": 2539.705753326416, \"max\": 2539.705753326416}}}\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1817.862284770083 records/second\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.3240634619308693\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] Epoch[15] Batch[0] avg_epoch_loss=3.262094\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.2620942045691814\n",
      "[05/22/2025 03:52:19 INFO 140041726678848] Epoch[15] Batch[5] avg_epoch_loss=3.274038\n",
      "[05/22/2025 03:52:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=3.274038109499698\n",
      "[05/22/2025 03:52:19 INFO 140041726678848] Epoch[15] Batch [5]#011Speed: 2227.93 samples/sec#011loss=3.274038\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] Epoch[15] Batch[10] avg_epoch_loss=3.192752\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=3.095208101336303\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] Epoch[15] Batch [10]#011Speed: 2023.95 samples/sec#011loss=3.095208\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] processed a total of 4648 examples\n",
      "#metrics {\"StartTime\": 1747885938.1514587, \"EndTime\": 1747885940.695989, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2544.2426204681396, \"count\": 1, \"min\": 2544.2426204681396, \"max\": 2544.2426204681396}}}\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1826.8071422219512 records/second\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=15, train loss <loss>=3.1927517421527005\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_5dc35adb-fe9a-4cf7-a9bc-3c44fef5dc1f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885940.6960487, \"EndTime\": 1747885940.7071753, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.849237442016602, \"count\": 1, \"min\": 10.849237442016602, \"max\": 10.849237442016602}}}\n",
      "[05/22/2025 03:52:21 INFO 140041726678848] Epoch[16] Batch[0] avg_epoch_loss=3.339991\n",
      "[05/22/2025 03:52:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.339990832492344\n",
      "[05/22/2025 03:52:22 INFO 140041726678848] Epoch[16] Batch[5] avg_epoch_loss=3.257571\n",
      "[05/22/2025 03:52:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=3.2575712593378805\n",
      "[05/22/2025 03:52:22 INFO 140041726678848] Epoch[16] Batch [5]#011Speed: 2277.57 samples/sec#011loss=3.257571\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] Epoch[16] Batch[10] avg_epoch_loss=3.268604\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=3.281844148019905\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] Epoch[16] Batch [10]#011Speed: 1936.48 samples/sec#011loss=3.281844\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] processed a total of 4550 examples\n",
      "#metrics {\"StartTime\": 1747885940.7072263, \"EndTime\": 1747885943.2799032, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2572.624683380127, \"count\": 1, \"min\": 2572.624683380127, \"max\": 2572.624683380127}}}\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1768.5614459363205 records/second\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.2686043905569826\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] Epoch[17] Batch[0] avg_epoch_loss=3.266548\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.266548003810551\n",
      "[05/22/2025 03:52:24 INFO 140041726678848] Epoch[17] Batch[5] avg_epoch_loss=3.209086\n",
      "[05/22/2025 03:52:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.2090861908842565\n",
      "[05/22/2025 03:52:24 INFO 140041726678848] Epoch[17] Batch [5]#011Speed: 2285.73 samples/sec#011loss=3.209086\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] Epoch[17] Batch[10] avg_epoch_loss=3.201363\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.1920962599178733\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] Epoch[17] Batch [10]#011Speed: 1998.48 samples/sec#011loss=3.192096\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] processed a total of 4697 examples\n",
      "#metrics {\"StartTime\": 1747885943.279964, \"EndTime\": 1747885945.8080451, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2527.827739715576, \"count\": 1, \"min\": 2527.827739715576, \"max\": 2527.827739715576}}}\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1858.053154988714 records/second\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.201363494990446\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:26 INFO 140041726678848] Epoch[18] Batch[0] avg_epoch_loss=3.191032\n",
      "[05/22/2025 03:52:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.191032154788419\n",
      "[05/22/2025 03:52:27 INFO 140041726678848] Epoch[18] Batch[5] avg_epoch_loss=3.190338\n",
      "[05/22/2025 03:52:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.190338066797745\n",
      "[05/22/2025 03:52:27 INFO 140041726678848] Epoch[18] Batch [5]#011Speed: 2211.23 samples/sec#011loss=3.190338\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] Epoch[18] Batch[10] avg_epoch_loss=3.224782\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.2661152387249444\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] Epoch[18] Batch [10]#011Speed: 2041.62 samples/sec#011loss=3.266115\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] processed a total of 4579 examples\n",
      "#metrics {\"StartTime\": 1747885945.808105, \"EndTime\": 1747885948.349201, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2540.8434867858887, \"count\": 1, \"min\": 2540.8434867858887, \"max\": 2540.8434867858887}}}\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1802.0945378825425 records/second\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.224782235855563\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] Epoch[19] Batch[0] avg_epoch_loss=3.207947\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.20794718515103\n",
      "[05/22/2025 03:52:29 INFO 140041726678848] Epoch[19] Batch[5] avg_epoch_loss=3.198905\n",
      "[05/22/2025 03:52:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=3.1989050555777885\n",
      "[05/22/2025 03:52:29 INFO 140041726678848] Epoch[19] Batch [5]#011Speed: 2283.07 samples/sec#011loss=3.198905\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] Epoch[19] Batch[10] avg_epoch_loss=3.169087\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=3.133305729311665\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] Epoch[19] Batch [10]#011Speed: 2061.26 samples/sec#011loss=3.133306\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] processed a total of 4548 examples\n",
      "#metrics {\"StartTime\": 1747885948.3492622, \"EndTime\": 1747885950.852879, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2503.3621788024902, \"count\": 1, \"min\": 2503.3621788024902, \"max\": 2503.3621788024902}}}\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1816.6655151537718 records/second\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=19, train loss <loss>=3.1690871800022777\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_f7a44def-3042-4797-b10b-25cb04e4f8c2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885950.852978, \"EndTime\": 1747885950.86375, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.483503341674805, \"count\": 1, \"min\": 10.483503341674805, \"max\": 10.483503341674805}}}\n",
      "[05/22/2025 03:52:31 INFO 140041726678848] Epoch[20] Batch[0] avg_epoch_loss=3.197749\n",
      "[05/22/2025 03:52:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.1977490125626393\n",
      "[05/22/2025 03:52:32 INFO 140041726678848] Epoch[20] Batch[5] avg_epoch_loss=3.152172\n",
      "[05/22/2025 03:52:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=3.1521717006397316\n",
      "[05/22/2025 03:52:32 INFO 140041726678848] Epoch[20] Batch [5]#011Speed: 2208.46 samples/sec#011loss=3.152172\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] Epoch[20] Batch[10] avg_epoch_loss=3.136058\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=3.1167204791028675\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] Epoch[20] Batch [10]#011Speed: 1986.83 samples/sec#011loss=3.116720\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] processed a total of 4703 examples\n",
      "#metrics {\"StartTime\": 1747885950.8638005, \"EndTime\": 1747885953.4342048, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2570.354223251343, \"count\": 1, \"min\": 2570.354223251343, \"max\": 2570.354223251343}}}\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1829.647634291074 records/second\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.1360575090320664\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_a914f27a-a483-4cea-a2a2-2ea57cad1280-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885953.4342637, \"EndTime\": 1747885953.4447055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.167598724365234, \"count\": 1, \"min\": 10.167598724365234, \"max\": 10.167598724365234}}}\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] Epoch[21] Batch[0] avg_epoch_loss=3.104306\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.1043059555087695\n",
      "[05/22/2025 03:52:34 INFO 140041726678848] Epoch[21] Batch[5] avg_epoch_loss=3.129884\n",
      "[05/22/2025 03:52:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.1298836281145603\n",
      "[05/22/2025 03:52:34 INFO 140041726678848] Epoch[21] Batch [5]#011Speed: 2194.13 samples/sec#011loss=3.129884\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] Epoch[21] Batch[10] avg_epoch_loss=3.182809\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=3.246319620858853\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] Epoch[21] Batch [10]#011Speed: 1950.34 samples/sec#011loss=3.246320\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] processed a total of 4632 examples\n",
      "#metrics {\"StartTime\": 1747885953.4447608, \"EndTime\": 1747885956.0586467, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2613.8336658477783, \"count\": 1, \"min\": 2613.8336658477783, \"max\": 2613.8336658477783}}}\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1772.051351867557 records/second\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=21, train loss <loss>=3.182809079361966\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] Epoch[22] Batch[0] avg_epoch_loss=3.193355\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=3.1933550250556793\n",
      "[05/22/2025 03:52:37 INFO 140041726678848] Epoch[22] Batch[5] avg_epoch_loss=3.136931\n",
      "[05/22/2025 03:52:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=3.1369308097856345\n",
      "[05/22/2025 03:52:37 INFO 140041726678848] Epoch[22] Batch [5]#011Speed: 2264.19 samples/sec#011loss=3.136931\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] Epoch[22] Batch[10] avg_epoch_loss=3.150773\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=3.167384389354816\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] Epoch[22] Batch [10]#011Speed: 1977.88 samples/sec#011loss=3.167384\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] processed a total of 4659 examples\n",
      "#metrics {\"StartTime\": 1747885956.058705, \"EndTime\": 1747885958.6235404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2564.5241737365723, \"count\": 1, \"min\": 2564.5241737365723, \"max\": 2564.5241737365723}}}\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1816.6484551211768 records/second\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=22, train loss <loss>=3.1507733459534446\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:39 INFO 140041726678848] Epoch[23] Batch[0] avg_epoch_loss=3.130802\n",
      "[05/22/2025 03:52:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=3.130802281980791\n",
      "[05/22/2025 03:52:40 INFO 140041726678848] Epoch[23] Batch[5] avg_epoch_loss=3.124068\n",
      "[05/22/2025 03:52:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=3.1240676619339274\n",
      "[05/22/2025 03:52:40 INFO 140041726678848] Epoch[23] Batch [5]#011Speed: 2204.35 samples/sec#011loss=3.124068\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] Epoch[23] Batch[10] avg_epoch_loss=3.069765\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=3.00460218671701\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] Epoch[23] Batch [10]#011Speed: 2027.86 samples/sec#011loss=3.004602\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] processed a total of 4571 examples\n",
      "#metrics {\"StartTime\": 1747885958.6236012, \"EndTime\": 1747885961.1842616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2560.4023933410645, \"count\": 1, \"min\": 2560.4023933410645, \"max\": 2560.4023933410645}}}\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1785.2050839733863 records/second\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=23, train loss <loss>=3.069765173198965\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_5c3e08b1-aacb-45f0-965a-03aae38e8428-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885961.184322, \"EndTime\": 1747885961.195462, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.859966278076172, \"count\": 1, \"min\": 10.859966278076172, \"max\": 10.859966278076172}}}\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] Epoch[24] Batch[0] avg_epoch_loss=3.027233\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=3.0272325545483016\n",
      "[05/22/2025 03:52:42 INFO 140041726678848] Epoch[24] Batch[5] avg_epoch_loss=3.104290\n",
      "[05/22/2025 03:52:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=3.104289960401007\n",
      "[05/22/2025 03:52:42 INFO 140041726678848] Epoch[24] Batch [5]#011Speed: 2271.75 samples/sec#011loss=3.104290\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] Epoch[24] Batch[10] avg_epoch_loss=2.960121\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.7871180205143373\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] Epoch[24] Batch [10]#011Speed: 1970.47 samples/sec#011loss=2.787118\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] processed a total of 4588 examples\n",
      "#metrics {\"StartTime\": 1747885961.1955144, \"EndTime\": 1747885963.7644222, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2568.854570388794, \"count\": 1, \"min\": 2568.854570388794, \"max\": 2568.854570388794}}}\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1785.9501809665744 records/second\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.960120896816157\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_54c9ef4e-99fb-4849-9af7-9e5b955f7094-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885963.7644815, \"EndTime\": 1747885963.7753017, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.550260543823242, \"count\": 1, \"min\": 10.550260543823242, \"max\": 10.550260543823242}}}\n",
      "[05/22/2025 03:52:44 INFO 140041726678848] Epoch[25] Batch[0] avg_epoch_loss=3.090392\n",
      "[05/22/2025 03:52:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=3.0903915711128898\n",
      "[05/22/2025 03:52:45 INFO 140041726678848] Epoch[25] Batch[5] avg_epoch_loss=3.087562\n",
      "[05/22/2025 03:52:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=3.087561932332266\n",
      "[05/22/2025 03:52:45 INFO 140041726678848] Epoch[25] Batch [5]#011Speed: 2197.74 samples/sec#011loss=3.087562\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] Epoch[25] Batch[10] avg_epoch_loss=3.204268\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=3.3443148946443486\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] Epoch[25] Batch [10]#011Speed: 1987.88 samples/sec#011loss=3.344315\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] processed a total of 4575 examples\n",
      "#metrics {\"StartTime\": 1747885963.7753763, \"EndTime\": 1747885966.3844414, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2609.0140342712402, \"count\": 1, \"min\": 2609.0140342712402, \"max\": 2609.0140342712402}}}\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1753.4786220972799 records/second\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=25, train loss <loss>=3.2042678242923035\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] Epoch[26] Batch[0] avg_epoch_loss=3.023362\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=3.0233621915889475\n",
      "[05/22/2025 03:52:47 INFO 140041726678848] Epoch[26] Batch[5] avg_epoch_loss=3.064099\n",
      "[05/22/2025 03:52:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=3.064098831097462\n",
      "[05/22/2025 03:52:47 INFO 140041726678848] Epoch[26] Batch [5]#011Speed: 2228.66 samples/sec#011loss=3.064099\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] Epoch[26] Batch[10] avg_epoch_loss=3.073204\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=3.08412977188892\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] Epoch[26] Batch [10]#011Speed: 1914.86 samples/sec#011loss=3.084130\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] processed a total of 4663 examples\n",
      "#metrics {\"StartTime\": 1747885966.3844988, \"EndTime\": 1747885968.993293, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2608.5407733917236, \"count\": 1, \"min\": 2608.5407733917236, \"max\": 2608.5407733917236}}}\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1787.5290127399799 records/second\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=26, train loss <loss>=3.0732038041844882\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:49 INFO 140041726678848] Epoch[27] Batch[0] avg_epoch_loss=3.081393\n",
      "[05/22/2025 03:52:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=3.0813928956709353\n",
      "[05/22/2025 03:52:50 INFO 140041726678848] Epoch[27] Batch[5] avg_epoch_loss=3.083502\n",
      "[05/22/2025 03:52:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=3.083502074923441\n",
      "[05/22/2025 03:52:50 INFO 140041726678848] Epoch[27] Batch [5]#011Speed: 2214.18 samples/sec#011loss=3.083502\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] processed a total of 4487 examples\n",
      "#metrics {\"StartTime\": 1747885968.9933524, \"EndTime\": 1747885971.4261658, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2432.528257369995, \"count\": 1, \"min\": 2432.528257369995, \"max\": 2432.528257369995}}}\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1844.5123823978724 records/second\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=27, train loss <loss>=3.059638661000139\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] Epoch[28] Batch[0] avg_epoch_loss=3.102289\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=3.102288940701559\n",
      "[05/22/2025 03:52:52 INFO 140041726678848] Epoch[28] Batch[5] avg_epoch_loss=3.038419\n",
      "[05/22/2025 03:52:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=3.0384192972954946\n",
      "[05/22/2025 03:52:52 INFO 140041726678848] Epoch[28] Batch [5]#011Speed: 2242.82 samples/sec#011loss=3.038419\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] Epoch[28] Batch[10] avg_epoch_loss=3.069780\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=3.107413120737055\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] Epoch[28] Batch [10]#011Speed: 2031.01 samples/sec#011loss=3.107413\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] processed a total of 4619 examples\n",
      "#metrics {\"StartTime\": 1747885971.4262288, \"EndTime\": 1747885973.9661572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2539.6368503570557, \"count\": 1, \"min\": 2539.6368503570557, \"max\": 2539.6368503570557}}}\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1818.7040407947159 records/second\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=28, train loss <loss>=3.0697801261325672\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:54 INFO 140041726678848] Epoch[29] Batch[0] avg_epoch_loss=3.076329\n",
      "[05/22/2025 03:52:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=3.076329288610106\n",
      "[05/22/2025 03:52:55 INFO 140041726678848] Epoch[29] Batch[5] avg_epoch_loss=3.081015\n",
      "[05/22/2025 03:52:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=3.0810145411388734\n",
      "[05/22/2025 03:52:55 INFO 140041726678848] Epoch[29] Batch [5]#011Speed: 2256.90 samples/sec#011loss=3.081015\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] Epoch[29] Batch[10] avg_epoch_loss=3.045516\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=3.002916746415646\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] Epoch[29] Batch [10]#011Speed: 2056.75 samples/sec#011loss=3.002917\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] processed a total of 4499 examples\n",
      "#metrics {\"StartTime\": 1747885973.9662151, \"EndTime\": 1747885976.4885888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.115707397461, \"count\": 1, \"min\": 2522.115707397461, \"max\": 2522.115707397461}}}\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1783.7581098803787 records/second\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=29, train loss <loss>=3.045515543537406\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] Epoch[30] Batch[0] avg_epoch_loss=3.056129\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=3.056129234670796\n",
      "[05/22/2025 03:52:57 INFO 140041726678848] Epoch[30] Batch[5] avg_epoch_loss=3.041557\n",
      "[05/22/2025 03:52:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=3.041557329003689\n",
      "[05/22/2025 03:52:57 INFO 140041726678848] Epoch[30] Batch [5]#011Speed: 2252.79 samples/sec#011loss=3.041557\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] Epoch[30] Batch[10] avg_epoch_loss=3.009194\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=2.9703570869292872\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] Epoch[30] Batch [10]#011Speed: 2050.49 samples/sec#011loss=2.970357\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] processed a total of 4573 examples\n",
      "#metrics {\"StartTime\": 1747885976.4886484, \"EndTime\": 1747885979.0051377, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2516.242027282715, \"count\": 1, \"min\": 2516.242027282715, \"max\": 2516.242027282715}}}\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1817.331613581993 records/second\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=30, train loss <loss>=3.0091935826062337\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] Epoch[31] Batch[0] avg_epoch_loss=3.036905\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=3.0369049276169267\n",
      "[05/22/2025 03:53:00 INFO 140041726678848] Epoch[31] Batch[5] avg_epoch_loss=3.082184\n",
      "[05/22/2025 03:53:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=3.082183543363145\n",
      "[05/22/2025 03:53:00 INFO 140041726678848] Epoch[31] Batch [5]#011Speed: 2243.00 samples/sec#011loss=3.082184\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] processed a total of 4375 examples\n",
      "#metrics {\"StartTime\": 1747885979.0051963, \"EndTime\": 1747885981.3997245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2394.2604064941406, \"count\": 1, \"min\": 2394.2604064941406, \"max\": 2394.2604064941406}}}\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1827.2134727678667 records/second\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=31, train loss <loss>=3.039898831169961\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] Epoch[32] Batch[0] avg_epoch_loss=3.008687\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=3.0086873825515035\n",
      "[05/22/2025 03:53:02 INFO 140041726678848] Epoch[32] Batch[5] avg_epoch_loss=3.009034\n",
      "[05/22/2025 03:53:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=3.00903361093228\n",
      "[05/22/2025 03:53:02 INFO 140041726678848] Epoch[32] Batch [5]#011Speed: 2201.88 samples/sec#011loss=3.009034\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] Epoch[32] Batch[10] avg_epoch_loss=3.048549\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=3.0959673297431793\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] Epoch[32] Batch [10]#011Speed: 1974.44 samples/sec#011loss=3.095967\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] processed a total of 4654 examples\n",
      "#metrics {\"StartTime\": 1747885981.399789, \"EndTime\": 1747885984.0165718, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2616.455554962158, \"count\": 1, \"min\": 2616.455554962158, \"max\": 2616.455554962158}}}\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1778.682265380543 records/second\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=32, train loss <loss>=3.048548937664507\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] Epoch[33] Batch[0] avg_epoch_loss=2.882610\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.882610227589087\n",
      "[05/22/2025 03:53:05 INFO 140041726678848] Epoch[33] Batch[5] avg_epoch_loss=2.980484\n",
      "[05/22/2025 03:53:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.9804843373004823\n",
      "[05/22/2025 03:53:05 INFO 140041726678848] Epoch[33] Batch [5]#011Speed: 2261.18 samples/sec#011loss=2.980484\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] Epoch[33] Batch[10] avg_epoch_loss=3.022661\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=3.073273561473413\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] Epoch[33] Batch [10]#011Speed: 1977.53 samples/sec#011loss=3.073274\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] processed a total of 4688 examples\n",
      "#metrics {\"StartTime\": 1747885984.0166316, \"EndTime\": 1747885986.5761867, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2559.3008995056152, \"count\": 1, \"min\": 2559.3008995056152, \"max\": 2559.3008995056152}}}\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1831.6887966534405 records/second\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=33, train loss <loss>=3.022661257379087\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] Epoch[34] Batch[0] avg_epoch_loss=3.013511\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=3.0135114708031736\n",
      "[05/22/2025 03:53:07 INFO 140041726678848] Epoch[34] Batch[5] avg_epoch_loss=3.034111\n",
      "[05/22/2025 03:53:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=3.0341113118127088\n",
      "[05/22/2025 03:53:07 INFO 140041726678848] Epoch[34] Batch [5]#011Speed: 2236.76 samples/sec#011loss=3.034111\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] Epoch[34] Batch[10] avg_epoch_loss=3.062200\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=3.0959070286400334\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] Epoch[34] Batch [10]#011Speed: 1947.87 samples/sec#011loss=3.095907\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] processed a total of 4744 examples\n",
      "#metrics {\"StartTime\": 1747885986.5762463, \"EndTime\": 1747885989.1512783, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2574.7807025909424, \"count\": 1, \"min\": 2574.7807025909424, \"max\": 2574.7807025909424}}}\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1842.4116042298715 records/second\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=34, train loss <loss>=3.062200274006947\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] Epoch[35] Batch[0] avg_epoch_loss=2.996250\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.9962503479955456\n",
      "[05/22/2025 03:53:10 INFO 140041726678848] Epoch[35] Batch[5] avg_epoch_loss=2.985260\n",
      "[05/22/2025 03:53:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.985259760550065\n",
      "[05/22/2025 03:53:10 INFO 140041726678848] Epoch[35] Batch [5]#011Speed: 2234.92 samples/sec#011loss=2.985260\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] Epoch[35] Batch[10] avg_epoch_loss=3.026529\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=3.0760530671457404\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] Epoch[35] Batch [10]#011Speed: 1977.57 samples/sec#011loss=3.076053\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] processed a total of 4567 examples\n",
      "#metrics {\"StartTime\": 1747885989.151356, \"EndTime\": 1747885991.7204378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2568.8130855560303, \"count\": 1, \"min\": 2568.8130855560303, \"max\": 2568.8130855560303}}}\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1777.8036542478767 records/second\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=35, train loss <loss>=3.026529445366281\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:12 INFO 140041726678848] Epoch[36] Batch[0] avg_epoch_loss=2.924002\n",
      "[05/22/2025 03:53:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.9240023946443485\n",
      "[05/22/2025 03:53:13 INFO 140041726678848] Epoch[36] Batch[5] avg_epoch_loss=2.955042\n",
      "[05/22/2025 03:53:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.9550418301520742\n",
      "[05/22/2025 03:53:13 INFO 140041726678848] Epoch[36] Batch [5]#011Speed: 2233.12 samples/sec#011loss=2.955042\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] Epoch[36] Batch[10] avg_epoch_loss=2.966493\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.9802342880011135\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] Epoch[36] Batch [10]#011Speed: 1971.19 samples/sec#011loss=2.980234\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] processed a total of 4619 examples\n",
      "#metrics {\"StartTime\": 1747885991.7204974, \"EndTime\": 1747885994.3029332, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2582.1194648742676, \"count\": 1, \"min\": 2582.1194648742676, \"max\": 2582.1194648742676}}}\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.7767945945648 records/second\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.966492947356183\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] Epoch[37] Batch[0] avg_epoch_loss=2.998889\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.9988885892260577\n",
      "[05/22/2025 03:53:15 INFO 140041726678848] Epoch[37] Batch[5] avg_epoch_loss=2.953542\n",
      "[05/22/2025 03:53:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.953542368095188\n",
      "[05/22/2025 03:53:15 INFO 140041726678848] Epoch[37] Batch [5]#011Speed: 2265.76 samples/sec#011loss=2.953542\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] Epoch[37] Batch[10] avg_epoch_loss=2.929969\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=2.9016814709771714\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] Epoch[37] Batch [10]#011Speed: 1946.55 samples/sec#011loss=2.901681\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] processed a total of 4669 examples\n",
      "#metrics {\"StartTime\": 1747885994.3029912, \"EndTime\": 1747885996.882844, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2579.5962810516357, \"count\": 1, \"min\": 2579.5962810516357, \"max\": 2579.5962810516357}}}\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1809.9124245585062 records/second\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.9299692330415446\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_1772fb02-2d96-4c41-afab-8184651db75a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885996.8829033, \"EndTime\": 1747885996.8937898, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.57291030883789, \"count\": 1, \"min\": 10.57291030883789, \"max\": 10.57291030883789}}}\n",
      "[05/22/2025 03:53:17 INFO 140041726678848] Epoch[38] Batch[0] avg_epoch_loss=2.943506\n",
      "[05/22/2025 03:53:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.9435061856208242\n",
      "[05/22/2025 03:53:18 INFO 140041726678848] Epoch[38] Batch[5] avg_epoch_loss=2.929111\n",
      "[05/22/2025 03:53:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.9291106792583057\n",
      "[05/22/2025 03:53:18 INFO 140041726678848] Epoch[38] Batch [5]#011Speed: 2289.82 samples/sec#011loss=2.929111\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] Epoch[38] Batch[10] avg_epoch_loss=2.981355\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=3.044047536191537\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] Epoch[38] Batch [10]#011Speed: 1987.29 samples/sec#011loss=3.044048\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] processed a total of 4654 examples\n",
      "#metrics {\"StartTime\": 1747885996.8938417, \"EndTime\": 1747885999.4359734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.0680046081543, \"count\": 1, \"min\": 2542.0680046081543, \"max\": 2542.0680046081543}}}\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1830.7253996891377 records/second\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.981354705137047\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] Epoch[39] Batch[0] avg_epoch_loss=2.903089\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.9030892217079622\n",
      "[05/22/2025 03:53:20 INFO 140041726678848] Epoch[39] Batch[5] avg_epoch_loss=2.915301\n",
      "[05/22/2025 03:53:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.915300738838043\n",
      "[05/22/2025 03:53:20 INFO 140041726678848] Epoch[39] Batch [5]#011Speed: 2271.35 samples/sec#011loss=2.915301\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] Epoch[39] Batch[10] avg_epoch_loss=3.009228\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=3.1219408472821546\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] Epoch[39] Batch [10]#011Speed: 1945.84 samples/sec#011loss=3.121941\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] processed a total of 4638 examples\n",
      "#metrics {\"StartTime\": 1747885999.436026, \"EndTime\": 1747886001.9984713, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2562.199831008911, \"count\": 1, \"min\": 2562.199831008911, \"max\": 2562.199831008911}}}\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.1021188408904 records/second\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=39, train loss <loss>=3.009228060858094\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:22 INFO 140041726678848] Epoch[40] Batch[0] avg_epoch_loss=2.927527\n",
      "[05/22/2025 03:53:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.927526937030206\n",
      "[05/22/2025 03:53:23 INFO 140041726678848] Epoch[40] Batch[5] avg_epoch_loss=2.941609\n",
      "[05/22/2025 03:53:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.941609428649313\n",
      "[05/22/2025 03:53:23 INFO 140041726678848] Epoch[40] Batch [5]#011Speed: 2249.47 samples/sec#011loss=2.941609\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] Epoch[40] Batch[10] avg_epoch_loss=3.041634\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=3.161664321321687\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] Epoch[40] Batch [10]#011Speed: 1940.79 samples/sec#011loss=3.161664\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] processed a total of 4661 examples\n",
      "#metrics {\"StartTime\": 1747886001.9985304, \"EndTime\": 1747886004.5864933, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2587.7158641815186, \"count\": 1, \"min\": 2587.7158641815186, \"max\": 2587.7158641815186}}}\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1801.1439766228527 records/second\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=40, train loss <loss>=3.041634379864029\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:25 INFO 140041726678848] Epoch[41] Batch[0] avg_epoch_loss=2.892891\n",
      "[05/22/2025 03:53:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.892890777248051\n",
      "[05/22/2025 03:53:26 INFO 140041726678848] Epoch[41] Batch[5] avg_epoch_loss=2.978307\n",
      "[05/22/2025 03:53:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.978306510489166\n",
      "[05/22/2025 03:53:26 INFO 140041726678848] Epoch[41] Batch [5]#011Speed: 2203.35 samples/sec#011loss=2.978307\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] Epoch[41] Batch[10] avg_epoch_loss=2.995107\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=3.0152684676886135\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] Epoch[41] Batch [10]#011Speed: 1963.67 samples/sec#011loss=3.015268\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] processed a total of 4577 examples\n",
      "#metrics {\"StartTime\": 1747886004.5865507, \"EndTime\": 1747886007.181191, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2594.3856239318848, \"count\": 1, \"min\": 2594.3856239318848, \"max\": 2594.3856239318848}}}\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1764.1325672747216 records/second\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.995107400125278\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] Epoch[42] Batch[0] avg_epoch_loss=2.883955\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.883954632255707\n",
      "[05/22/2025 03:53:28 INFO 140041726678848] Epoch[42] Batch[5] avg_epoch_loss=2.974679\n",
      "[05/22/2025 03:53:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.9746792912925715\n",
      "[05/22/2025 03:53:28 INFO 140041726678848] Epoch[42] Batch [5]#011Speed: 2252.00 samples/sec#011loss=2.974679\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] Epoch[42] Batch[10] avg_epoch_loss=2.929455\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.8751851716923023\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] Epoch[42] Batch [10]#011Speed: 2023.94 samples/sec#011loss=2.875185\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] processed a total of 4530 examples\n",
      "#metrics {\"StartTime\": 1747886007.1812522, \"EndTime\": 1747886009.7231703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2541.6507720947266, \"count\": 1, \"min\": 2541.6507720947266, \"max\": 2541.6507720947266}}}\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1782.2460419540118 records/second\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.9294546914742674\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_13e342f6-1912-4474-b4c5-5dfc8c9c385e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886009.7232282, \"EndTime\": 1747886009.7340448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.50257682800293, \"count\": 1, \"min\": 10.50257682800293, \"max\": 10.50257682800293}}}\n",
      "[05/22/2025 03:53:30 INFO 140041726678848] Epoch[43] Batch[0] avg_epoch_loss=3.002949\n",
      "[05/22/2025 03:53:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=3.002948718506403\n",
      "[05/22/2025 03:53:31 INFO 140041726678848] Epoch[43] Batch[5] avg_epoch_loss=2.959776\n",
      "[05/22/2025 03:53:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.95977583830677\n",
      "[05/22/2025 03:53:31 INFO 140041726678848] Epoch[43] Batch [5]#011Speed: 2220.60 samples/sec#011loss=2.959776\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] Epoch[43] Batch[10] avg_epoch_loss=2.925211\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.883732404475223\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] Epoch[43] Batch [10]#011Speed: 1978.11 samples/sec#011loss=2.883732\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] processed a total of 4616 examples\n",
      "#metrics {\"StartTime\": 1747886009.7341492, \"EndTime\": 1747886012.3109787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2576.779842376709, \"count\": 1, \"min\": 2576.779842376709, \"max\": 2576.779842376709}}}\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1791.319508128194 records/second\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.925210641110612\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_412913f9-d839-44af-9094-f095b7c767ac-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886012.3110435, \"EndTime\": 1747886012.3219361, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.527849197387695, \"count\": 1, \"min\": 10.527849197387695, \"max\": 10.527849197387695}}}\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] Epoch[44] Batch[0] avg_epoch_loss=2.914469\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.9144689479224666\n",
      "[05/22/2025 03:53:33 INFO 140041726678848] Epoch[44] Batch[5] avg_epoch_loss=2.891656\n",
      "[05/22/2025 03:53:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.891656118051689\n",
      "[05/22/2025 03:53:33 INFO 140041726678848] Epoch[44] Batch [5]#011Speed: 2231.81 samples/sec#011loss=2.891656\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] Epoch[44] Batch[10] avg_epoch_loss=2.898864\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=2.907513930696687\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] Epoch[44] Batch [10]#011Speed: 2037.37 samples/sec#011loss=2.907514\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] processed a total of 4566 examples\n",
      "#metrics {\"StartTime\": 1747886012.321993, \"EndTime\": 1747886014.860677, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2538.634777069092, \"count\": 1, \"min\": 2538.634777069092, \"max\": 2538.634777069092}}}\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1798.5450689217796 records/second\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.898864214708506\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_e2f1d34f-4d93-471a-b2bb-ed9f7711b55d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886014.8607347, \"EndTime\": 1747886014.871525, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.51950454711914, \"count\": 1, \"min\": 10.51950454711914, \"max\": 10.51950454711914}}}\n",
      "[05/22/2025 03:53:35 INFO 140041726678848] Epoch[45] Batch[0] avg_epoch_loss=2.989974\n",
      "[05/22/2025 03:53:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.9899744658268372\n",
      "[05/22/2025 03:53:36 INFO 140041726678848] Epoch[45] Batch[5] avg_epoch_loss=2.953714\n",
      "[05/22/2025 03:53:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.9537144174554566\n",
      "[05/22/2025 03:53:36 INFO 140041726678848] Epoch[45] Batch [5]#011Speed: 2243.03 samples/sec#011loss=2.953714\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] Epoch[45] Batch[10] avg_epoch_loss=3.043436\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=3.1511028740082128\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] Epoch[45] Batch [10]#011Speed: 1991.25 samples/sec#011loss=3.151103\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] processed a total of 4672 examples\n",
      "#metrics {\"StartTime\": 1747886014.8715758, \"EndTime\": 1747886017.4351819, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2563.5547637939453, \"count\": 1, \"min\": 2563.5547637939453, \"max\": 2563.5547637939453}}}\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1822.4071535554574 records/second\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=45, train loss <loss>=3.0434364431612546\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] Epoch[46] Batch[0] avg_epoch_loss=2.995776\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.995776475936108\n",
      "[05/22/2025 03:53:38 INFO 140041726678848] Epoch[46] Batch[5] avg_epoch_loss=2.997587\n",
      "[05/22/2025 03:53:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.9975871855715246\n",
      "[05/22/2025 03:53:38 INFO 140041726678848] Epoch[46] Batch [5]#011Speed: 2296.26 samples/sec#011loss=2.997587\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] Epoch[46] Batch[10] avg_epoch_loss=2.994035\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.9897730090304844\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] Epoch[46] Batch [10]#011Speed: 2024.73 samples/sec#011loss=2.989773\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] processed a total of 4583 examples\n",
      "#metrics {\"StartTime\": 1747886017.4352427, \"EndTime\": 1747886019.9572418, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2521.7161178588867, \"count\": 1, \"min\": 2521.7161178588867, \"max\": 2521.7161178588867}}}\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1817.3497339989276 records/second\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.994035287143779\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:40 INFO 140041726678848] Epoch[47] Batch[0] avg_epoch_loss=2.903438\n",
      "[05/22/2025 03:53:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.9034377609966593\n",
      "[05/22/2025 03:53:41 INFO 140041726678848] Epoch[47] Batch[5] avg_epoch_loss=2.934909\n",
      "[05/22/2025 03:53:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.9349089737901353\n",
      "[05/22/2025 03:53:41 INFO 140041726678848] Epoch[47] Batch [5]#011Speed: 2258.37 samples/sec#011loss=2.934909\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] Epoch[47] Batch[10] avg_epoch_loss=3.087479\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=3.270563274290089\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] Epoch[47] Batch [10]#011Speed: 2008.94 samples/sec#011loss=3.270563\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] processed a total of 4661 examples\n",
      "#metrics {\"StartTime\": 1747886019.957302, \"EndTime\": 1747886022.4989843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2541.429281234741, \"count\": 1, \"min\": 2541.429281234741, \"max\": 2541.429281234741}}}\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1833.9449041219 records/second\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=47, train loss <loss>=3.0874791103810235\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] Epoch[48] Batch[0] avg_epoch_loss=2.939310\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.9393103924519766\n",
      "[05/22/2025 03:53:43 INFO 140041726678848] Epoch[48] Batch[5] avg_epoch_loss=2.882280\n",
      "[05/22/2025 03:53:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.882280447435273\n",
      "[05/22/2025 03:53:43 INFO 140041726678848] Epoch[48] Batch [5]#011Speed: 2287.24 samples/sec#011loss=2.882280\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] Epoch[48] Batch[10] avg_epoch_loss=2.874060\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=2.864196152039254\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] Epoch[48] Batch [10]#011Speed: 2027.00 samples/sec#011loss=2.864196\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] processed a total of 4608 examples\n",
      "#metrics {\"StartTime\": 1747886022.4990432, \"EndTime\": 1747886025.0119205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2512.591600418091, \"count\": 1, \"min\": 2512.591600418091, \"max\": 2512.591600418091}}}\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1833.899993879837 records/second\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.874060313164355\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_a7b2b896-0f57-423d-a2c6-b2e754f5179b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886025.011979, \"EndTime\": 1747886025.0223646, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.068655014038086, \"count\": 1, \"min\": 10.068655014038086, \"max\": 10.068655014038086}}}\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] Epoch[49] Batch[0] avg_epoch_loss=2.887537\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.8875368114038142\n",
      "[05/22/2025 03:53:46 INFO 140041726678848] Epoch[49] Batch[5] avg_epoch_loss=2.914137\n",
      "[05/22/2025 03:53:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.914137174044172\n",
      "[05/22/2025 03:53:46 INFO 140041726678848] Epoch[49] Batch [5]#011Speed: 2214.87 samples/sec#011loss=2.914137\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] Epoch[49] Batch[10] avg_epoch_loss=2.898782\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=2.8803567389337417\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] Epoch[49] Batch [10]#011Speed: 2011.03 samples/sec#011loss=2.880357\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] processed a total of 4646 examples\n",
      "#metrics {\"StartTime\": 1747886025.0224133, \"EndTime\": 1747886027.581076, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2558.6118698120117, \"count\": 1, \"min\": 2558.6118698120117, \"max\": 2558.6118698120117}}}\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1815.7649125216608 records/second\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.898782430812158\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:48 INFO 140041726678848] Epoch[50] Batch[0] avg_epoch_loss=2.855810\n",
      "[05/22/2025 03:53:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.855809676886136\n",
      "[05/22/2025 03:53:48 INFO 140041726678848] Epoch[50] Batch[5] avg_epoch_loss=2.850577\n",
      "[05/22/2025 03:53:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.8505765579325586\n",
      "[05/22/2025 03:53:48 INFO 140041726678848] Epoch[50] Batch [5]#011Speed: 2284.48 samples/sec#011loss=2.850577\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] Epoch[50] Batch[10] avg_epoch_loss=2.882357\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.9204940558010857\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] Epoch[50] Batch [10]#011Speed: 2013.34 samples/sec#011loss=2.920494\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] processed a total of 4514 examples\n",
      "#metrics {\"StartTime\": 1747886027.5811362, \"EndTime\": 1747886030.1050978, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2523.707628250122, \"count\": 1, \"min\": 2523.707628250122, \"max\": 2523.707628250122}}}\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.5772536506815 records/second\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.882357238781889\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] Epoch[51] Batch[0] avg_epoch_loss=2.860143\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.860142765172606\n",
      "[05/22/2025 03:53:51 INFO 140041726678848] Epoch[51] Batch[5] avg_epoch_loss=2.858774\n",
      "[05/22/2025 03:53:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.8587738014453414\n",
      "[05/22/2025 03:53:51 INFO 140041726678848] Epoch[51] Batch [5]#011Speed: 2248.08 samples/sec#011loss=2.858774\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] Epoch[51] Batch[10] avg_epoch_loss=2.868537\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.8802529927616924\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] Epoch[51] Batch [10]#011Speed: 2047.19 samples/sec#011loss=2.880253\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] processed a total of 4522 examples\n",
      "#metrics {\"StartTime\": 1747886030.1051555, \"EndTime\": 1747886032.6250334, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2519.5765495300293, \"count\": 1, \"min\": 2519.5765495300293, \"max\": 2519.5765495300293}}}\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.6870969814493 records/second\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.8685370702255013\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_1501dc37-2f14-446a-9cac-abb4d112fc69-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886032.6250904, \"EndTime\": 1747886032.6356413, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.288715362548828, \"count\": 1, \"min\": 10.288715362548828, \"max\": 10.288715362548828}}}\n",
      "[05/22/2025 03:53:53 INFO 140041726678848] Epoch[52] Batch[0] avg_epoch_loss=2.866098\n",
      "[05/22/2025 03:53:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.8660975670761415\n",
      "[05/22/2025 03:53:54 INFO 140041726678848] Epoch[52] Batch[5] avg_epoch_loss=2.886904\n",
      "[05/22/2025 03:53:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.88690357732171\n",
      "[05/22/2025 03:53:54 INFO 140041726678848] Epoch[52] Batch [5]#011Speed: 2240.23 samples/sec#011loss=2.886904\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] Epoch[52] Batch[10] avg_epoch_loss=2.800819\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=2.697516508038697\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] Epoch[52] Batch [10]#011Speed: 1990.73 samples/sec#011loss=2.697517\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] processed a total of 4595 examples\n",
      "#metrics {\"StartTime\": 1747886032.6356883, \"EndTime\": 1747886035.1836524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2547.9159355163574, \"count\": 1, \"min\": 2547.9159355163574, \"max\": 2547.9159355163574}}}\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1803.3616280161057 records/second\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.8008185458294315\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_fcfb1c77-f0e0-4419-a8a7-ff8385365256-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886035.1837275, \"EndTime\": 1747886035.1945777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.575056076049805, \"count\": 1, \"min\": 10.575056076049805, \"max\": 10.575056076049805}}}\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] Epoch[53] Batch[0] avg_epoch_loss=2.796311\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.7963108665959076\n",
      "[05/22/2025 03:53:56 INFO 140041726678848] Epoch[53] Batch[5] avg_epoch_loss=2.775311\n",
      "[05/22/2025 03:53:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.7753109666446267\n",
      "[05/22/2025 03:53:56 INFO 140041726678848] Epoch[53] Batch [5]#011Speed: 2211.47 samples/sec#011loss=2.775311\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] Epoch[53] Batch[10] avg_epoch_loss=2.808736\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.848846286017539\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] Epoch[53] Batch [10]#011Speed: 2029.50 samples/sec#011loss=2.848846\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] processed a total of 4574 examples\n",
      "#metrics {\"StartTime\": 1747886035.1946235, \"EndTime\": 1747886037.743362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.6695766448975, \"count\": 1, \"min\": 2548.6695766448975, \"max\": 2548.6695766448975}}}\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.580575300464 records/second\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.8087361118141323\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:58 INFO 140041726678848] Epoch[54] Batch[0] avg_epoch_loss=3.023384\n",
      "[05/22/2025 03:53:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=3.023384213182071\n",
      "[05/22/2025 03:53:59 INFO 140041726678848] Epoch[54] Batch[5] avg_epoch_loss=2.911436\n",
      "[05/22/2025 03:53:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.91143599455677\n",
      "[05/22/2025 03:53:59 INFO 140041726678848] Epoch[54] Batch [5]#011Speed: 2272.41 samples/sec#011loss=2.911436\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] processed a total of 4490 examples\n",
      "#metrics {\"StartTime\": 1747886037.74343, \"EndTime\": 1747886040.1262162, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2382.446765899658, \"count\": 1, \"min\": 2382.446765899658, \"max\": 2382.446765899658}}}\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1884.5401903750924 records/second\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.911467350405415\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] Epoch[55] Batch[0] avg_epoch_loss=2.747521\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.7475205317371936\n",
      "[05/22/2025 03:54:01 INFO 140041726678848] Epoch[55] Batch[5] avg_epoch_loss=2.774154\n",
      "[05/22/2025 03:54:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.7741539267672373\n",
      "[05/22/2025 03:54:01 INFO 140041726678848] Epoch[55] Batch [5]#011Speed: 2226.26 samples/sec#011loss=2.774154\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] Epoch[55] Batch[10] avg_epoch_loss=2.805759\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.8436849683324055\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] Epoch[55] Batch [10]#011Speed: 1876.01 samples/sec#011loss=2.843685\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] processed a total of 4699 examples\n",
      "#metrics {\"StartTime\": 1747886040.1262822, \"EndTime\": 1747886042.75458, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2628.0009746551514, \"count\": 1, \"min\": 2628.0009746551514, \"max\": 2628.0009746551514}}}\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1787.9834456010913 records/second\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.8057589456604957\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:03 INFO 140041726678848] Epoch[56] Batch[0] avg_epoch_loss=2.784593\n",
      "[05/22/2025 03:54:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.7845926603389475\n",
      "[05/22/2025 03:54:04 INFO 140041726678848] Epoch[56] Batch[5] avg_epoch_loss=2.846169\n",
      "[05/22/2025 03:54:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.8461687956019164\n",
      "[05/22/2025 03:54:04 INFO 140041726678848] Epoch[56] Batch [5]#011Speed: 2295.63 samples/sec#011loss=2.846169\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] Epoch[56] Batch[10] avg_epoch_loss=2.833201\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=2.8176407098239142\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] Epoch[56] Batch [10]#011Speed: 1980.11 samples/sec#011loss=2.817641\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] processed a total of 4611 examples\n",
      "#metrics {\"StartTime\": 1747886042.7546525, \"EndTime\": 1747886045.3032367, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.325777053833, \"count\": 1, \"min\": 2548.325777053833, \"max\": 2548.325777053833}}}\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1809.3603126629914 records/second\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.8332014838846424\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] Epoch[57] Batch[0] avg_epoch_loss=2.775035\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.7750350170517817\n",
      "[05/22/2025 03:54:06 INFO 140041726678848] Epoch[57] Batch[5] avg_epoch_loss=2.752183\n",
      "[05/22/2025 03:54:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.7521829923701975\n",
      "[05/22/2025 03:54:06 INFO 140041726678848] Epoch[57] Batch [5]#011Speed: 2256.01 samples/sec#011loss=2.752183\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] Epoch[57] Batch[10] avg_epoch_loss=2.900909\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=3.0793799045622214\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] Epoch[57] Batch [10]#011Speed: 2031.19 samples/sec#011loss=3.079380\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] processed a total of 4592 examples\n",
      "#metrics {\"StartTime\": 1747886045.3032968, \"EndTime\": 1747886047.8330033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2529.3829441070557, \"count\": 1, \"min\": 2529.3829441070557, \"max\": 2529.3829441070557}}}\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1815.4000878092056 records/second\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.9009088615483902\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:08 INFO 140041726678848] Epoch[58] Batch[0] avg_epoch_loss=2.866679\n",
      "[05/22/2025 03:54:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.8666788283859965\n",
      "[05/22/2025 03:54:09 INFO 140041726678848] Epoch[58] Batch[5] avg_epoch_loss=2.816774\n",
      "[05/22/2025 03:54:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.81677413747854\n",
      "[05/22/2025 03:54:09 INFO 140041726678848] Epoch[58] Batch [5]#011Speed: 2249.24 samples/sec#011loss=2.816774\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] Epoch[58] Batch[10] avg_epoch_loss=2.855458\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.901879284695156\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] Epoch[58] Batch [10]#011Speed: 2019.35 samples/sec#011loss=2.901879\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] processed a total of 4622 examples\n",
      "#metrics {\"StartTime\": 1747886047.8330626, \"EndTime\": 1747886050.3799453, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2546.627998352051, \"count\": 1, \"min\": 2546.627998352051, \"max\": 2546.627998352051}}}\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1814.883777849926 records/second\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.855458295304275\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] Epoch[59] Batch[0] avg_epoch_loss=2.697822\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.697821602258491\n",
      "[05/22/2025 03:54:11 INFO 140041726678848] Epoch[59] Batch[5] avg_epoch_loss=2.758002\n",
      "[05/22/2025 03:54:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.758002085073311\n",
      "[05/22/2025 03:54:11 INFO 140041726678848] Epoch[59] Batch [5]#011Speed: 2211.49 samples/sec#011loss=2.758002\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] Epoch[59] Batch[10] avg_epoch_loss=2.782318\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=2.811497718454204\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] Epoch[59] Batch [10]#011Speed: 2003.49 samples/sec#011loss=2.811498\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] processed a total of 4641 examples\n",
      "#metrics {\"StartTime\": 1747886050.3800075, \"EndTime\": 1747886052.9473019, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2567.020893096924, \"count\": 1, \"min\": 2567.020893096924, \"max\": 2567.020893096924}}}\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1807.8423062499198 records/second\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.782318282064626\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_b7c5894d-c138-4b05-9b59-93493bbf2771-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886052.947395, \"EndTime\": 1747886052.9584403, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.604381561279297, \"count\": 1, \"min\": 10.604381561279297, \"max\": 10.604381561279297}}}\n",
      "[05/22/2025 03:54:13 INFO 140041726678848] Epoch[60] Batch[0] avg_epoch_loss=2.821534\n",
      "[05/22/2025 03:54:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.8215342906110803\n",
      "[05/22/2025 03:54:14 INFO 140041726678848] Epoch[60] Batch[5] avg_epoch_loss=2.883717\n",
      "[05/22/2025 03:54:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.883716563427988\n",
      "[05/22/2025 03:54:14 INFO 140041726678848] Epoch[60] Batch [5]#011Speed: 2238.09 samples/sec#011loss=2.883717\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] Epoch[60] Batch[10] avg_epoch_loss=3.001099\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=3.1419579316884745\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] Epoch[60] Batch [10]#011Speed: 1902.53 samples/sec#011loss=3.141958\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] processed a total of 4635 examples\n",
      "#metrics {\"StartTime\": 1747886052.958493, \"EndTime\": 1747886055.5636926, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2605.147123336792, \"count\": 1, \"min\": 2605.147123336792, \"max\": 2605.147123336792}}}\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1779.1120234981975 records/second\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=60, train loss <loss>=3.001099003546391\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:16 INFO 140041726678848] Epoch[61] Batch[0] avg_epoch_loss=2.850000\n",
      "[05/22/2025 03:54:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.849999510631264\n",
      "[05/22/2025 03:54:17 INFO 140041726678848] Epoch[61] Batch[5] avg_epoch_loss=2.873962\n",
      "[05/22/2025 03:54:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.8739615867291897\n",
      "[05/22/2025 03:54:17 INFO 140041726678848] Epoch[61] Batch [5]#011Speed: 2196.05 samples/sec#011loss=2.873962\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] Epoch[61] Batch[10] avg_epoch_loss=2.878943\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=2.8849205917664253\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] Epoch[61] Batch [10]#011Speed: 1956.62 samples/sec#011loss=2.884921\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] processed a total of 4549 examples\n",
      "#metrics {\"StartTime\": 1747886055.56375, \"EndTime\": 1747886058.1734676, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2609.4272136688232, \"count\": 1, \"min\": 2609.4272136688232, \"max\": 2609.4272136688232}}}\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1743.235366468033 records/second\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.878942952655206\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] Epoch[62] Batch[0] avg_epoch_loss=2.822592\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.8225924145670938\n",
      "[05/22/2025 03:54:19 INFO 140041726678848] Epoch[62] Batch[5] avg_epoch_loss=2.868327\n",
      "[05/22/2025 03:54:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.8683265963570665\n",
      "[05/22/2025 03:54:19 INFO 140041726678848] Epoch[62] Batch [5]#011Speed: 2245.31 samples/sec#011loss=2.868327\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] Epoch[62] Batch[10] avg_epoch_loss=2.846341\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.81995836015799\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] Epoch[62] Batch [10]#011Speed: 2030.44 samples/sec#011loss=2.819958\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] processed a total of 4574 examples\n",
      "#metrics {\"StartTime\": 1747886058.1735287, \"EndTime\": 1747886060.711471, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2537.6787185668945, \"count\": 1, \"min\": 2537.6787185668945, \"max\": 2537.6787185668945}}}\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1802.3716363740218 records/second\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.8463410344483955\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:21 INFO 140041726678848] Epoch[63] Batch[0] avg_epoch_loss=2.834434\n",
      "[05/22/2025 03:54:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.8344335067511137\n",
      "[05/22/2025 03:54:22 INFO 140041726678848] Epoch[63] Batch[5] avg_epoch_loss=2.807329\n",
      "[05/22/2025 03:54:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.8073285505695527\n",
      "[05/22/2025 03:54:22 INFO 140041726678848] Epoch[63] Batch [5]#011Speed: 2271.95 samples/sec#011loss=2.807329\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] Epoch[63] Batch[10] avg_epoch_loss=2.835425\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.869140733748608\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] Epoch[63] Batch [10]#011Speed: 1955.84 samples/sec#011loss=2.869141\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] processed a total of 4675 examples\n",
      "#metrics {\"StartTime\": 1747886060.7115319, \"EndTime\": 1747886063.2743902, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2562.595844268799, \"count\": 1, \"min\": 2562.595844268799, \"max\": 2562.595844268799}}}\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1824.261926602944 records/second\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.8354249974691235\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] Epoch[64] Batch[0] avg_epoch_loss=2.858397\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.8583968062708798\n",
      "[05/22/2025 03:54:24 INFO 140041726678848] Epoch[64] Batch[5] avg_epoch_loss=2.878937\n",
      "[05/22/2025 03:54:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.878936608986405\n",
      "[05/22/2025 03:54:24 INFO 140041726678848] Epoch[64] Batch [5]#011Speed: 2249.39 samples/sec#011loss=2.878937\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] Epoch[64] Batch[10] avg_epoch_loss=2.847566\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=2.809921788001114\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] Epoch[64] Batch [10]#011Speed: 2004.66 samples/sec#011loss=2.809922\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] processed a total of 4627 examples\n",
      "#metrics {\"StartTime\": 1747886063.2744477, \"EndTime\": 1747886065.8165417, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2541.7869091033936, \"count\": 1, \"min\": 2541.7869091033936, \"max\": 2541.7869091033936}}}\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1820.310234102595 records/second\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.8475662358112723\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:26 INFO 140041726678848] Epoch[65] Batch[0] avg_epoch_loss=2.704420\n",
      "[05/22/2025 03:54:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.7044199240499722\n",
      "[05/22/2025 03:54:27 INFO 140041726678848] Epoch[65] Batch[5] avg_epoch_loss=2.756668\n",
      "[05/22/2025 03:54:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.7566681927721324\n",
      "[05/22/2025 03:54:27 INFO 140041726678848] Epoch[65] Batch [5]#011Speed: 2172.94 samples/sec#011loss=2.756668\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] Epoch[65] Batch[10] avg_epoch_loss=2.779680\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.807293660391147\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] Epoch[65] Batch [10]#011Speed: 2030.20 samples/sec#011loss=2.807294\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] processed a total of 4662 examples\n",
      "#metrics {\"StartTime\": 1747886065.8166013, \"EndTime\": 1747886068.3882685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2571.4099407196045, \"count\": 1, \"min\": 2571.4099407196045, \"max\": 2571.4099407196045}}}\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1812.9532938777527 records/second\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.779679768962594\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_563ade2d-115c-4291-973c-3dab17f8883d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886068.3883264, \"EndTime\": 1747886068.3992443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.64300537109375, \"count\": 1, \"min\": 10.64300537109375, \"max\": 10.64300537109375}}}\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] Epoch[66] Batch[0] avg_epoch_loss=2.794592\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.794591551103146\n",
      "[05/22/2025 03:54:29 INFO 140041726678848] Epoch[66] Batch[5] avg_epoch_loss=2.812195\n",
      "[05/22/2025 03:54:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.81219482421875\n",
      "[05/22/2025 03:54:29 INFO 140041726678848] Epoch[66] Batch [5]#011Speed: 2263.03 samples/sec#011loss=2.812195\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] Epoch[66] Batch[10] avg_epoch_loss=2.690994\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.5455540306584075\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] Epoch[66] Batch [10]#011Speed: 2058.13 samples/sec#011loss=2.545554\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] processed a total of 4549 examples\n",
      "#metrics {\"StartTime\": 1747886068.3992963, \"EndTime\": 1747886070.908662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2509.298086166382, \"count\": 1, \"min\": 2509.298086166382, \"max\": 2509.298086166382}}}\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1812.7834945291718 records/second\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.6909944635095036\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_ec7e6c70-0f88-4ec5-b345-efa0f539e916-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886070.9087214, \"EndTime\": 1747886070.919626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.606050491333008, \"count\": 1, \"min\": 10.606050491333008, \"max\": 10.606050491333008}}}\n",
      "[05/22/2025 03:54:31 INFO 140041726678848] Epoch[67] Batch[0] avg_epoch_loss=2.736314\n",
      "[05/22/2025 03:54:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.7363137158094375\n",
      "[05/22/2025 03:54:32 INFO 140041726678848] Epoch[67] Batch[5] avg_epoch_loss=2.723590\n",
      "[05/22/2025 03:54:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.7235904005428733\n",
      "[05/22/2025 03:54:32 INFO 140041726678848] Epoch[67] Batch [5]#011Speed: 2218.88 samples/sec#011loss=2.723590\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] Epoch[67] Batch[10] avg_epoch_loss=2.691595\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.6531994927964924\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] Epoch[67] Batch [10]#011Speed: 2059.85 samples/sec#011loss=2.653199\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] processed a total of 4574 examples\n",
      "#metrics {\"StartTime\": 1747886070.919677, \"EndTime\": 1747886073.4497144, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2529.9878120422363, \"count\": 1, \"min\": 2529.9878120422363, \"max\": 2529.9878120422363}}}\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1807.8521750110724 records/second\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.691594533385427\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] Epoch[68] Batch[0] avg_epoch_loss=2.742240\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.7422399712033685\n",
      "[05/22/2025 03:54:34 INFO 140041726678848] Epoch[68] Batch[5] avg_epoch_loss=2.762723\n",
      "[05/22/2025 03:54:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.7627234058904047\n",
      "[05/22/2025 03:54:34 INFO 140041726678848] Epoch[68] Batch [5]#011Speed: 2288.50 samples/sec#011loss=2.762723\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] Epoch[68] Batch[10] avg_epoch_loss=2.672682\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.5646319620858855\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] Epoch[68] Batch [10]#011Speed: 2039.50 samples/sec#011loss=2.564632\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] processed a total of 4566 examples\n",
      "#metrics {\"StartTime\": 1747886073.4497733, \"EndTime\": 1747886075.9561276, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2506.101131439209, \"count\": 1, \"min\": 2506.101131439209, \"max\": 2506.101131439209}}}\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1821.8972774557812 records/second\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.672681840524714\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_a221d3fa-6142-47fe-84e9-63001371419c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886075.9561806, \"EndTime\": 1747886075.967235, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.761737823486328, \"count\": 1, \"min\": 10.761737823486328, \"max\": 10.761737823486328}}}\n",
      "[05/22/2025 03:54:36 INFO 140041726678848] Epoch[69] Batch[0] avg_epoch_loss=2.674850\n",
      "[05/22/2025 03:54:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.674850090043847\n",
      "[05/22/2025 03:54:37 INFO 140041726678848] Epoch[69] Batch[5] avg_epoch_loss=2.775347\n",
      "[05/22/2025 03:54:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.775347080244873\n",
      "[05/22/2025 03:54:37 INFO 140041726678848] Epoch[69] Batch [5]#011Speed: 2253.45 samples/sec#011loss=2.775347\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] Epoch[69] Batch[10] avg_epoch_loss=2.755324\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.7312964900299277\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] Epoch[69] Batch [10]#011Speed: 2038.90 samples/sec#011loss=2.731296\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] processed a total of 4705 examples\n",
      "#metrics {\"StartTime\": 1747886075.9672842, \"EndTime\": 1747886078.4946735, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2527.340888977051, \"count\": 1, \"min\": 2527.340888977051, \"max\": 2527.340888977051}}}\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1861.5770418016682 records/second\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.7553240846926252\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] Epoch[70] Batch[0] avg_epoch_loss=2.721877\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.721876522480512\n",
      "[05/22/2025 03:54:39 INFO 140041726678848] Epoch[70] Batch[5] avg_epoch_loss=2.742227\n",
      "[05/22/2025 03:54:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.7422270573061667\n",
      "[05/22/2025 03:54:39 INFO 140041726678848] Epoch[70] Batch [5]#011Speed: 2245.86 samples/sec#011loss=2.742227\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] Epoch[70] Batch[10] avg_epoch_loss=2.839006\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.955140764198218\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] Epoch[70] Batch [10]#011Speed: 2018.40 samples/sec#011loss=2.955141\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] processed a total of 4565 examples\n",
      "#metrics {\"StartTime\": 1747886078.4947329, \"EndTime\": 1747886081.0270789, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2532.0777893066406, \"count\": 1, \"min\": 2532.0777893066406, \"max\": 2532.0777893066406}}}\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1802.793361177598 records/second\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.839006014984372\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] Epoch[71] Batch[0] avg_epoch_loss=2.675203\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.6752029792768655\n",
      "[05/22/2025 03:54:42 INFO 140041726678848] Epoch[71] Batch[5] avg_epoch_loss=2.730294\n",
      "[05/22/2025 03:54:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.7302942991079715\n",
      "[05/22/2025 03:54:42 INFO 140041726678848] Epoch[71] Batch [5]#011Speed: 2215.91 samples/sec#011loss=2.730294\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] Epoch[71] Batch[10] avg_epoch_loss=2.759830\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.7952723717636414\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] Epoch[71] Batch [10]#011Speed: 2057.75 samples/sec#011loss=2.795272\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] processed a total of 4565 examples\n",
      "#metrics {\"StartTime\": 1747886081.027151, \"EndTime\": 1747886083.5985346, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2571.0301399230957, \"count\": 1, \"min\": 2571.0301399230957, \"max\": 2571.0301399230957}}}\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1775.4814358450892 records/second\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.7598297866787305\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:44 INFO 140041726678848] Epoch[72] Batch[0] avg_epoch_loss=2.884513\n",
      "[05/22/2025 03:54:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.884513328229399\n",
      "[05/22/2025 03:54:45 INFO 140041726678848] Epoch[72] Batch[5] avg_epoch_loss=2.849905\n",
      "[05/22/2025 03:54:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.8499050805899686\n",
      "[05/22/2025 03:54:45 INFO 140041726678848] Epoch[72] Batch [5]#011Speed: 2271.45 samples/sec#011loss=2.849905\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] Epoch[72] Batch[10] avg_epoch_loss=2.790944\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.720189994693068\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] Epoch[72] Batch [10]#011Speed: 1984.86 samples/sec#011loss=2.720190\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] processed a total of 4656 examples\n",
      "#metrics {\"StartTime\": 1747886083.598609, \"EndTime\": 1747886086.1357348, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2536.8733406066895, \"count\": 1, \"min\": 2536.8733406066895, \"max\": 2536.8733406066895}}}\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1835.2640392391513 records/second\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.790943677909559\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] Epoch[73] Batch[0] avg_epoch_loss=2.775353\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.775353106730234\n",
      "[05/22/2025 03:54:47 INFO 140041726678848] Epoch[73] Batch[5] avg_epoch_loss=2.763383\n",
      "[05/22/2025 03:54:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.7633825130788328\n",
      "[05/22/2025 03:54:47 INFO 140041726678848] Epoch[73] Batch [5]#011Speed: 2259.66 samples/sec#011loss=2.763383\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] Epoch[73] Batch[10] avg_epoch_loss=2.724225\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=2.677235001391982\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] Epoch[73] Batch [10]#011Speed: 2026.09 samples/sec#011loss=2.677235\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] processed a total of 4657 examples\n",
      "#metrics {\"StartTime\": 1747886086.1357968, \"EndTime\": 1747886088.6637383, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2527.6200771331787, \"count\": 1, \"min\": 2527.6200771331787, \"max\": 2527.6200771331787}}}\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1842.3810104024976 records/second\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.7242245532211733\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:49 INFO 140041726678848] Epoch[74] Batch[0] avg_epoch_loss=2.716284\n",
      "[05/22/2025 03:54:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.716283581570156\n",
      "[05/22/2025 03:54:50 INFO 140041726678848] Epoch[74] Batch[5] avg_epoch_loss=2.729015\n",
      "[05/22/2025 03:54:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.7290147811108016\n",
      "[05/22/2025 03:54:50 INFO 140041726678848] Epoch[74] Batch [5]#011Speed: 2282.69 samples/sec#011loss=2.729015\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] Epoch[74] Batch[10] avg_epoch_loss=2.788058\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.858910371572244\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] Epoch[74] Batch [10]#011Speed: 1992.97 samples/sec#011loss=2.858910\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] processed a total of 4698 examples\n",
      "#metrics {\"StartTime\": 1747886088.6637979, \"EndTime\": 1747886091.201589, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2537.5359058380127, \"count\": 1, \"min\": 2537.5359058380127, \"max\": 2537.5359058380127}}}\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1851.3435801169442 records/second\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.788058231320548\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] Epoch[75] Batch[0] avg_epoch_loss=2.689610\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.689610266738586\n",
      "[05/22/2025 03:54:52 INFO 140041726678848] Epoch[75] Batch[5] avg_epoch_loss=2.687048\n",
      "[05/22/2025 03:54:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.687048330781366\n",
      "[05/22/2025 03:54:52 INFO 140041726678848] Epoch[75] Batch [5]#011Speed: 2274.86 samples/sec#011loss=2.687048\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] Epoch[75] Batch[10] avg_epoch_loss=2.687383\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=2.687785492283199\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] Epoch[75] Batch [10]#011Speed: 1994.65 samples/sec#011loss=2.687785\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] processed a total of 4711 examples\n",
      "#metrics {\"StartTime\": 1747886091.2016432, \"EndTime\": 1747886093.738722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2536.8268489837646, \"count\": 1, \"min\": 2536.8268489837646, \"max\": 2536.8268489837646}}}\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1856.9813596697325 records/second\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.68738340419129\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:54 INFO 140041726678848] Epoch[76] Batch[0] avg_epoch_loss=2.632513\n",
      "[05/22/2025 03:54:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.632512897584911\n",
      "[05/22/2025 03:54:55 INFO 140041726678848] Epoch[76] Batch[5] avg_epoch_loss=2.675116\n",
      "[05/22/2025 03:54:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.675116206950051\n",
      "[05/22/2025 03:54:55 INFO 140041726678848] Epoch[76] Batch [5]#011Speed: 2252.73 samples/sec#011loss=2.675116\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] Epoch[76] Batch[10] avg_epoch_loss=2.644913\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.608668868100988\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] Epoch[76] Batch [10]#011Speed: 2001.63 samples/sec#011loss=2.608669\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] processed a total of 4581 examples\n",
      "#metrics {\"StartTime\": 1747886093.7387812, \"EndTime\": 1747886096.2843888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2545.34649848938, \"count\": 1, \"min\": 2545.34649848938, \"max\": 2545.34649848938}}}\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1799.6622513336993 records/second\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.644912871109568\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_42414ee0-5a3e-493b-bfef-509b7bb6c430-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886096.2844918, \"EndTime\": 1747886096.2956398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.850906372070312, \"count\": 1, \"min\": 10.850906372070312, \"max\": 10.850906372070312}}}\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] Epoch[77] Batch[0] avg_epoch_loss=2.706676\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.7066756420517817\n",
      "[05/22/2025 03:54:57 INFO 140041726678848] Epoch[77] Batch[5] avg_epoch_loss=2.655692\n",
      "[05/22/2025 03:54:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.6556921649527885\n",
      "[05/22/2025 03:54:57 INFO 140041726678848] Epoch[77] Batch [5]#011Speed: 2227.04 samples/sec#011loss=2.655692\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] Epoch[77] Batch[10] avg_epoch_loss=2.584938\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.5000325158337975\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] Epoch[77] Batch [10]#011Speed: 1977.33 samples/sec#011loss=2.500033\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] processed a total of 4626 examples\n",
      "#metrics {\"StartTime\": 1747886096.2956924, \"EndTime\": 1747886098.8710036, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2575.2577781677246, \"count\": 1, \"min\": 2575.2577781677246, \"max\": 2575.2577781677246}}}\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.2654927358215 records/second\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.5849377789896106\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_18acd0a5-6113-448e-a05a-e538c4bf2000-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886098.8710616, \"EndTime\": 1747886098.882204, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.851621627807617, \"count\": 1, \"min\": 10.851621627807617, \"max\": 10.851621627807617}}}\n",
      "[05/22/2025 03:54:59 INFO 140041726678848] Epoch[78] Batch[0] avg_epoch_loss=2.711300\n",
      "[05/22/2025 03:54:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.711299904736219\n",
      "[05/22/2025 03:55:00 INFO 140041726678848] Epoch[78] Batch[5] avg_epoch_loss=2.670223\n",
      "[05/22/2025 03:55:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.670223108644209\n",
      "[05/22/2025 03:55:00 INFO 140041726678848] Epoch[78] Batch [5]#011Speed: 2178.87 samples/sec#011loss=2.670223\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] Epoch[78] Batch[10] avg_epoch_loss=2.679940\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.6915991700306234\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] Epoch[78] Batch [10]#011Speed: 1964.67 samples/sec#011loss=2.691599\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] processed a total of 4631 examples\n",
      "#metrics {\"StartTime\": 1747886098.882255, \"EndTime\": 1747886101.496359, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2614.0520572662354, \"count\": 1, \"min\": 2614.0520572662354, \"max\": 2614.0520572662354}}}\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1771.519967312676 records/second\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.6799395001834885\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] Epoch[79] Batch[0] avg_epoch_loss=2.655106\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.6551062365151727\n",
      "[05/22/2025 03:55:02 INFO 140041726678848] Epoch[79] Batch[5] avg_epoch_loss=2.627417\n",
      "[05/22/2025 03:55:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.627416575317836\n",
      "[05/22/2025 03:55:02 INFO 140041726678848] Epoch[79] Batch [5]#011Speed: 2294.22 samples/sec#011loss=2.627417\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] Epoch[79] Batch[10] avg_epoch_loss=2.605323\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.5788100074819043\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] Epoch[79] Batch [10]#011Speed: 2033.45 samples/sec#011loss=2.578810\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] processed a total of 4683 examples\n",
      "#metrics {\"StartTime\": 1747886101.4964185, \"EndTime\": 1747886104.0201046, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2523.4334468841553, \"count\": 1, \"min\": 2523.4334468841553, \"max\": 2523.4334468841553}}}\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1855.743822107924 records/second\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.605322680846958\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] Epoch[80] Batch[0] avg_epoch_loss=2.655098\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.655098352241091\n",
      "[05/22/2025 03:55:05 INFO 140041726678848] Epoch[80] Batch[5] avg_epoch_loss=2.630104\n",
      "[05/22/2025 03:55:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.6301040252934764\n",
      "[05/22/2025 03:55:05 INFO 140041726678848] Epoch[80] Batch [5]#011Speed: 2283.17 samples/sec#011loss=2.630104\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] Epoch[80] Batch[10] avg_epoch_loss=2.641123\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.65434488751044\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] Epoch[80] Batch [10]#011Speed: 2033.19 samples/sec#011loss=2.654345\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] processed a total of 4555 examples\n",
      "#metrics {\"StartTime\": 1747886104.0201616, \"EndTime\": 1747886106.5349042, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2514.4400596618652, \"count\": 1, \"min\": 2514.4400596618652, \"max\": 2514.4400596618652}}}\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1811.47142353939 records/second\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.64112259902846\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] Epoch[81] Batch[0] avg_epoch_loss=2.615154\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.6151544447731068\n",
      "[05/22/2025 03:55:07 INFO 140041726678848] Epoch[81] Batch[5] avg_epoch_loss=2.673076\n",
      "[05/22/2025 03:55:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.673076037751717\n",
      "[05/22/2025 03:55:07 INFO 140041726678848] Epoch[81] Batch [5]#011Speed: 2237.50 samples/sec#011loss=2.673076\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] Epoch[81] Batch[10] avg_epoch_loss=2.668208\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.662366184837834\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] Epoch[81] Batch [10]#011Speed: 2002.30 samples/sec#011loss=2.662366\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] processed a total of 4612 examples\n",
      "#metrics {\"StartTime\": 1747886106.5349672, \"EndTime\": 1747886109.0863225, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2551.0947704315186, \"count\": 1, \"min\": 2551.0947704315186, \"max\": 2551.0947704315186}}}\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1807.771050101948 records/second\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.668207922790861\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] Epoch[82] Batch[0] avg_epoch_loss=2.653652\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.6536517238829345\n",
      "[05/22/2025 03:55:10 INFO 140041726678848] Epoch[82] Batch[5] avg_epoch_loss=2.714064\n",
      "[05/22/2025 03:55:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.714064384975872\n",
      "[05/22/2025 03:55:10 INFO 140041726678848] Epoch[82] Batch [5]#011Speed: 2275.50 samples/sec#011loss=2.714064\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] Epoch[82] Batch[10] avg_epoch_loss=2.715445\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=2.717102295465618\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] Epoch[82] Batch [10]#011Speed: 1966.01 samples/sec#011loss=2.717102\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] processed a total of 4798 examples\n",
      "#metrics {\"StartTime\": 1747886109.0864089, \"EndTime\": 1747886111.6433535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2556.6418170928955, \"count\": 1, \"min\": 2556.6418170928955, \"max\": 2556.6418170928955}}}\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1876.6016353928799 records/second\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.7154452533803024\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:12 INFO 140041726678848] Epoch[83] Batch[0] avg_epoch_loss=2.640444\n",
      "[05/22/2025 03:55:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.6404442054391706\n",
      "[05/22/2025 03:55:13 INFO 140041726678848] Epoch[83] Batch[5] avg_epoch_loss=2.690635\n",
      "[05/22/2025 03:55:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.6906353583049136\n",
      "[05/22/2025 03:55:13 INFO 140041726678848] Epoch[83] Batch [5]#011Speed: 2218.21 samples/sec#011loss=2.690635\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] Epoch[83] Batch[10] avg_epoch_loss=2.760798\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.8449928878410358\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] Epoch[83] Batch [10]#011Speed: 1977.19 samples/sec#011loss=2.844993\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] processed a total of 4612 examples\n",
      "#metrics {\"StartTime\": 1747886111.6434164, \"EndTime\": 1747886114.229359, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2585.1457118988037, \"count\": 1, \"min\": 2585.1457118988037, \"max\": 2585.1457118988037}}}\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1783.979142044972 records/second\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.7607978717304236\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] Epoch[84] Batch[0] avg_epoch_loss=2.836983\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.8369833897376115\n",
      "[05/22/2025 03:55:15 INFO 140041726678848] Epoch[84] Batch[5] avg_epoch_loss=2.837342\n",
      "[05/22/2025 03:55:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.8373420788963903\n",
      "[05/22/2025 03:55:15 INFO 140041726678848] Epoch[84] Batch [5]#011Speed: 2247.70 samples/sec#011loss=2.837342\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] Epoch[84] Batch[10] avg_epoch_loss=2.814960\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.7881024129141148\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] Epoch[84] Batch [10]#011Speed: 1884.08 samples/sec#011loss=2.788102\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] processed a total of 4719 examples\n",
      "#metrics {\"StartTime\": 1747886114.229418, \"EndTime\": 1747886116.8589542, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2629.284143447876, \"count\": 1, \"min\": 2629.284143447876, \"max\": 2629.284143447876}}}\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.7258601239837 records/second\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.8149604125408105\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:17 INFO 140041726678848] Epoch[85] Batch[0] avg_epoch_loss=2.761566\n",
      "[05/22/2025 03:55:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.761565958205735\n",
      "[05/22/2025 03:55:18 INFO 140041726678848] Epoch[85] Batch[5] avg_epoch_loss=2.847027\n",
      "[05/22/2025 03:55:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.847026912743017\n",
      "[05/22/2025 03:55:18 INFO 140041726678848] Epoch[85] Batch [5]#011Speed: 2276.53 samples/sec#011loss=2.847027\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] Epoch[85] Batch[10] avg_epoch_loss=2.769125\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=2.6756436286365535\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] Epoch[85] Batch [10]#011Speed: 2058.18 samples/sec#011loss=2.675644\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] processed a total of 4576 examples\n",
      "#metrics {\"StartTime\": 1747886116.8590124, \"EndTime\": 1747886119.37398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2514.6710872650146, \"count\": 1, \"min\": 2514.6710872650146, \"max\": 2514.6710872650146}}}\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1819.658631675262 records/second\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.769125419967352\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] Epoch[86] Batch[0] avg_epoch_loss=2.663274\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.6632735288488307\n",
      "[05/22/2025 03:55:20 INFO 140041726678848] Epoch[86] Batch[5] avg_epoch_loss=2.727740\n",
      "[05/22/2025 03:55:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.727739658369873\n",
      "[05/22/2025 03:55:20 INFO 140041726678848] Epoch[86] Batch [5]#011Speed: 2242.75 samples/sec#011loss=2.727740\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] Epoch[86] Batch[10] avg_epoch_loss=2.631984\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.517077555157294\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] Epoch[86] Batch [10]#011Speed: 1972.73 samples/sec#011loss=2.517078\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] processed a total of 4686 examples\n",
      "#metrics {\"StartTime\": 1747886119.374038, \"EndTime\": 1747886121.940569, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2566.2741661071777, \"count\": 1, \"min\": 2566.2741661071777, \"max\": 2566.2741661071777}}}\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1825.9317728248109 records/second\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.63198415690961\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:22 INFO 140041726678848] Epoch[87] Batch[0] avg_epoch_loss=2.656132\n",
      "[05/22/2025 03:55:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.656132007760301\n",
      "[05/22/2025 03:55:23 INFO 140041726678848] Epoch[87] Batch[5] avg_epoch_loss=2.648318\n",
      "[05/22/2025 03:55:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.6483178312192606\n",
      "[05/22/2025 03:55:23 INFO 140041726678848] Epoch[87] Batch [5]#011Speed: 2269.18 samples/sec#011loss=2.648318\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] Epoch[87] Batch[10] avg_epoch_loss=2.733702\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.836162555244293\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] Epoch[87] Batch [10]#011Speed: 2050.89 samples/sec#011loss=2.836163\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] processed a total of 4566 examples\n",
      "#metrics {\"StartTime\": 1747886121.9406278, \"EndTime\": 1747886124.463808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.927761077881, \"count\": 1, \"min\": 2522.927761077881, \"max\": 2522.927761077881}}}\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1809.7403769147445 records/second\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.7337017966851844\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] Epoch[88] Batch[0] avg_epoch_loss=2.612507\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.612507231782433\n",
      "[05/22/2025 03:55:25 INFO 140041726678848] Epoch[88] Batch[5] avg_epoch_loss=2.688510\n",
      "[05/22/2025 03:55:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.6885095495777653\n",
      "[05/22/2025 03:55:25 INFO 140041726678848] Epoch[88] Batch [5]#011Speed: 2277.69 samples/sec#011loss=2.688510\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] Epoch[88] Batch[10] avg_epoch_loss=2.773952\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=2.876481917281459\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] Epoch[88] Batch [10]#011Speed: 2032.95 samples/sec#011loss=2.876482\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] processed a total of 4562 examples\n",
      "#metrics {\"StartTime\": 1747886124.4638677, \"EndTime\": 1747886126.9928362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2528.7156105041504, \"count\": 1, \"min\": 2528.7156105041504, \"max\": 2528.7156105041504}}}\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1804.0146467652985 records/second\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.773951534897626\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:27 INFO 140041726678848] Epoch[89] Batch[0] avg_epoch_loss=2.643766\n",
      "[05/22/2025 03:55:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.6437662035425946\n",
      "[05/22/2025 03:55:28 INFO 140041726678848] Epoch[89] Batch[5] avg_epoch_loss=2.642149\n",
      "[05/22/2025 03:55:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.6421486133102494\n",
      "[05/22/2025 03:55:28 INFO 140041726678848] Epoch[89] Batch [5]#011Speed: 2247.54 samples/sec#011loss=2.642149\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] processed a total of 4456 examples\n",
      "#metrics {\"StartTime\": 1747886126.9928968, \"EndTime\": 1747886129.3795164, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2386.364221572876, \"count\": 1, \"min\": 2386.364221572876, \"max\": 2386.364221572876}}}\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1867.1999934462542 records/second\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.6759632679826697\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] Epoch[90] Batch[0] avg_epoch_loss=2.630460\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.6304599957370547\n",
      "[05/22/2025 03:55:30 INFO 140041726678848] Epoch[90] Batch[5] avg_epoch_loss=2.596529\n",
      "[05/22/2025 03:55:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.5965294331732554\n",
      "[05/22/2025 03:55:30 INFO 140041726678848] Epoch[90] Batch [5]#011Speed: 2282.39 samples/sec#011loss=2.596529\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] Epoch[90] Batch[10] avg_epoch_loss=2.569989\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.5381394418151446\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] Epoch[90] Batch [10]#011Speed: 1933.47 samples/sec#011loss=2.538139\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] processed a total of 4623 examples\n",
      "#metrics {\"StartTime\": 1747886129.3795805, \"EndTime\": 1747886131.949862, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2569.9799060821533, \"count\": 1, \"min\": 2569.9799060821533, \"max\": 2569.9799060821533}}}\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1798.784505248315 records/second\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.569988528010478\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_67fed88c-162e-4f54-b4a4-4cdccd2bc970-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886131.9499228, \"EndTime\": 1747886131.9603155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.045528411865234, \"count\": 1, \"min\": 10.045528411865234, \"max\": 10.045528411865234}}}\n",
      "[05/22/2025 03:55:32 INFO 140041726678848] Epoch[91] Batch[0] avg_epoch_loss=2.626037\n",
      "[05/22/2025 03:55:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.62603691797745\n",
      "[05/22/2025 03:55:33 INFO 140041726678848] Epoch[91] Batch[5] avg_epoch_loss=2.617285\n",
      "[05/22/2025 03:55:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.6172848753160958\n",
      "[05/22/2025 03:55:33 INFO 140041726678848] Epoch[91] Batch [5]#011Speed: 2288.89 samples/sec#011loss=2.617285\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] Epoch[91] Batch[10] avg_epoch_loss=2.524127\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=2.4123367683393653\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] Epoch[91] Batch [10]#011Speed: 2028.32 samples/sec#011loss=2.412337\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] processed a total of 4557 examples\n",
      "#metrics {\"StartTime\": 1747886131.9603674, \"EndTime\": 1747886134.4832273, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.80855178833, \"count\": 1, \"min\": 2522.80855178833, \"max\": 2522.80855178833}}}\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1806.254802746865 records/second\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.5241266448721276\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_5971f7c6-d790-42ff-ba7d-6abaf6255816-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886134.4832897, \"EndTime\": 1747886134.4938457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.254144668579102, \"count\": 1, \"min\": 10.254144668579102, \"max\": 10.254144668579102}}}\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] Epoch[92] Batch[0] avg_epoch_loss=2.696514\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.696514172118597\n",
      "[05/22/2025 03:55:35 INFO 140041726678848] Epoch[92] Batch[5] avg_epoch_loss=2.673122\n",
      "[05/22/2025 03:55:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.673121621543244\n",
      "[05/22/2025 03:55:35 INFO 140041726678848] Epoch[92] Batch [5]#011Speed: 2279.31 samples/sec#011loss=2.673122\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] Epoch[92] Batch[10] avg_epoch_loss=2.630438\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.5792169991474108\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] Epoch[92] Batch [10]#011Speed: 2004.81 samples/sec#011loss=2.579217\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] processed a total of 4576 examples\n",
      "#metrics {\"StartTime\": 1747886134.4939005, \"EndTime\": 1747886137.0587711, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2564.818859100342, \"count\": 1, \"min\": 2564.818859100342, \"max\": 2564.818859100342}}}\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1784.0820532536331 records/second\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.630437702272411\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] Epoch[93] Batch[0] avg_epoch_loss=2.553278\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.553278389911609\n",
      "[05/22/2025 03:55:38 INFO 140041726678848] Epoch[93] Batch[5] avg_epoch_loss=2.581497\n",
      "[05/22/2025 03:55:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.5814971130869524\n",
      "[05/22/2025 03:55:38 INFO 140041726678848] Epoch[93] Batch [5]#011Speed: 2211.61 samples/sec#011loss=2.581497\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] Epoch[93] Batch[10] avg_epoch_loss=2.651433\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.7353555861984966\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] Epoch[93] Batch [10]#011Speed: 2017.35 samples/sec#011loss=2.735356\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] processed a total of 4496 examples\n",
      "#metrics {\"StartTime\": 1747886137.0588288, \"EndTime\": 1747886139.6169517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2557.8346252441406, \"count\": 1, \"min\": 2557.8346252441406, \"max\": 2557.8346252441406}}}\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1757.6764895368538 records/second\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.651432782683109\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:40 INFO 140041726678848] Epoch[94] Batch[0] avg_epoch_loss=2.538933\n",
      "[05/22/2025 03:55:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.5389333610279787\n",
      "[05/22/2025 03:55:41 INFO 140041726678848] Epoch[94] Batch[5] avg_epoch_loss=2.668659\n",
      "[05/22/2025 03:55:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.668659394284753\n",
      "[05/22/2025 03:55:41 INFO 140041726678848] Epoch[94] Batch [5]#011Speed: 2253.89 samples/sec#011loss=2.668659\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] Epoch[94] Batch[10] avg_epoch_loss=2.625105\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=2.572839654527422\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] Epoch[94] Batch [10]#011Speed: 1974.81 samples/sec#011loss=2.572840\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] processed a total of 4731 examples\n",
      "#metrics {\"StartTime\": 1747886139.6170115, \"EndTime\": 1747886142.194225, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2576.932430267334, \"count\": 1, \"min\": 2576.932430267334, \"max\": 2576.932430267334}}}\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1835.8387306071588 records/second\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.62510496712233\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] Epoch[95] Batch[0] avg_epoch_loss=2.516796\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.516796222508352\n",
      "[05/22/2025 03:55:43 INFO 140041726678848] Epoch[95] Batch[5] avg_epoch_loss=2.545486\n",
      "[05/22/2025 03:55:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.5454855099729725\n",
      "[05/22/2025 03:55:43 INFO 140041726678848] Epoch[95] Batch [5]#011Speed: 2273.72 samples/sec#011loss=2.545486\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] Epoch[95] Batch[10] avg_epoch_loss=2.475183\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.39081949688544\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] Epoch[95] Batch [10]#011Speed: 1952.51 samples/sec#011loss=2.390819\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] processed a total of 4712 examples\n",
      "#metrics {\"StartTime\": 1747886142.1942863, \"EndTime\": 1747886144.7577274, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2563.1911754608154, \"count\": 1, \"min\": 2563.1911754608154, \"max\": 2563.1911754608154}}}\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1838.272547917857 records/second\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.4751827767513666\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_84a266c7-b892-4f1a-ad81-0cee33b2a6e9-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886144.7577858, \"EndTime\": 1747886144.76834, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.285377502441406, \"count\": 1, \"min\": 10.285377502441406, \"max\": 10.285377502441406}}}\n",
      "[05/22/2025 03:55:45 INFO 140041726678848] Epoch[96] Batch[0] avg_epoch_loss=2.550665\n",
      "[05/22/2025 03:55:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.550664888989421\n",
      "[05/22/2025 03:55:46 INFO 140041726678848] Epoch[96] Batch[5] avg_epoch_loss=2.603125\n",
      "[05/22/2025 03:55:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.603124583130336\n",
      "[05/22/2025 03:55:46 INFO 140041726678848] Epoch[96] Batch [5]#011Speed: 2254.99 samples/sec#011loss=2.603125\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] Epoch[96] Batch[10] avg_epoch_loss=2.708689\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.8353666241822104\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] Epoch[96] Batch [10]#011Speed: 1989.27 samples/sec#011loss=2.835367\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] processed a total of 4539 examples\n",
      "#metrics {\"StartTime\": 1747886144.7683938, \"EndTime\": 1747886147.3274841, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2559.0388774871826, \"count\": 1, \"min\": 2559.0388774871826, \"max\": 2559.0388774871826}}}\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.65380206571 records/second\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.7086891472448245\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] Epoch[97] Batch[0] avg_epoch_loss=2.555862\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.5558617130950725\n",
      "[05/22/2025 03:55:48 INFO 140041726678848] Epoch[97] Batch[5] avg_epoch_loss=2.637614\n",
      "[05/22/2025 03:55:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.6376136604201466\n",
      "[05/22/2025 03:55:48 INFO 140041726678848] Epoch[97] Batch [5]#011Speed: 2241.05 samples/sec#011loss=2.637614\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] Epoch[97] Batch[10] avg_epoch_loss=2.746071\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.876219670013224\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] Epoch[97] Batch [10]#011Speed: 2019.66 samples/sec#011loss=2.876220\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] processed a total of 4573 examples\n",
      "#metrics {\"StartTime\": 1747886147.327542, \"EndTime\": 1747886149.869888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.093276977539, \"count\": 1, \"min\": 2542.093276977539, \"max\": 2542.093276977539}}}\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1798.8512810162786 records/second\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.746070937507909\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:50 INFO 140041726678848] Epoch[98] Batch[0] avg_epoch_loss=2.577486\n",
      "[05/22/2025 03:55:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.577485558184855\n",
      "[05/22/2025 03:55:51 INFO 140041726678848] Epoch[98] Batch[5] avg_epoch_loss=2.572655\n",
      "[05/22/2025 03:55:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.572654945016704\n",
      "[05/22/2025 03:55:51 INFO 140041726678848] Epoch[98] Batch [5]#011Speed: 2227.15 samples/sec#011loss=2.572655\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] Epoch[98] Batch[10] avg_epoch_loss=2.620349\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=2.677581256959911\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] Epoch[98] Batch [10]#011Speed: 2049.68 samples/sec#011loss=2.677581\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] processed a total of 4549 examples\n",
      "#metrics {\"StartTime\": 1747886149.8699455, \"EndTime\": 1747886152.4022264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2532.028913497925, \"count\": 1, \"min\": 2532.028913497925, \"max\": 2532.028913497925}}}\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.5225688991131 records/second\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.620348723172707\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] Epoch[99] Batch[0] avg_epoch_loss=2.536207\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.5362070334249722\n",
      "[05/22/2025 03:55:53 INFO 140041726678848] Epoch[99] Batch[5] avg_epoch_loss=2.641748\n",
      "[05/22/2025 03:55:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.641747920001624\n",
      "[05/22/2025 03:55:53 INFO 140041726678848] Epoch[99] Batch [5]#011Speed: 2246.06 samples/sec#011loss=2.641748\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] Epoch[99] Batch[10] avg_epoch_loss=2.549816\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=2.4394977391164394\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] Epoch[99] Batch [10]#011Speed: 2056.15 samples/sec#011loss=2.439498\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] processed a total of 4573 examples\n",
      "#metrics {\"StartTime\": 1747886152.4022844, \"EndTime\": 1747886154.9300654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2527.526617050171, \"count\": 1, \"min\": 2527.526617050171, \"max\": 2527.526617050171}}}\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1809.2155269235684 records/second\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.5498160195992674\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:55 INFO 140041726678848] Epoch[100] Batch[0] avg_epoch_loss=2.585198\n",
      "[05/22/2025 03:55:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.5851982813369987\n",
      "[05/22/2025 03:55:56 INFO 140041726678848] Epoch[100] Batch[5] avg_epoch_loss=2.659792\n",
      "[05/22/2025 03:55:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.6597923499704206\n",
      "[05/22/2025 03:55:56 INFO 140041726678848] Epoch[100] Batch [5]#011Speed: 2266.37 samples/sec#011loss=2.659792\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] Epoch[100] Batch[10] avg_epoch_loss=2.659833\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.6598807897758907\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] Epoch[100] Batch [10]#011Speed: 2037.16 samples/sec#011loss=2.659881\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] processed a total of 4523 examples\n",
      "#metrics {\"StartTime\": 1747886154.9301248, \"EndTime\": 1747886157.4597118, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2529.332399368286, \"count\": 1, \"min\": 2529.332399368286, \"max\": 2529.332399368286}}}\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.1588942370001 records/second\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.659832549881998\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] Epoch[101] Batch[0] avg_epoch_loss=2.735483\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.7354826045726615\n",
      "[05/22/2025 03:55:58 INFO 140041726678848] Epoch[101] Batch[5] avg_epoch_loss=2.662055\n",
      "[05/22/2025 03:55:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.6620551366317513\n",
      "[05/22/2025 03:55:58 INFO 140041726678848] Epoch[101] Batch [5]#011Speed: 2236.10 samples/sec#011loss=2.662055\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] Epoch[101] Batch[10] avg_epoch_loss=2.697508\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=2.740050535478146\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] Epoch[101] Batch [10]#011Speed: 2046.71 samples/sec#011loss=2.740051\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] processed a total of 4581 examples\n",
      "#metrics {\"StartTime\": 1747886157.4597704, \"EndTime\": 1747886159.986422, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2526.40438079834, \"count\": 1, \"min\": 2526.40438079834, \"max\": 2526.40438079834}}}\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1813.1878271545406 records/second\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.69750759065284\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:00 INFO 140041726678848] Epoch[102] Batch[0] avg_epoch_loss=2.665199\n",
      "[05/22/2025 03:56:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.665198922953786\n",
      "[05/22/2025 03:56:01 INFO 140041726678848] Epoch[102] Batch[5] avg_epoch_loss=2.607296\n",
      "[05/22/2025 03:56:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.607295998486219\n",
      "[05/22/2025 03:56:01 INFO 140041726678848] Epoch[102] Batch [5]#011Speed: 2155.03 samples/sec#011loss=2.607296\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] Epoch[102] Batch[10] avg_epoch_loss=2.585783\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=2.559966429304705\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] Epoch[102] Batch [10]#011Speed: 2064.69 samples/sec#011loss=2.559966\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] processed a total of 4524 examples\n",
      "#metrics {\"StartTime\": 1747886159.9864817, \"EndTime\": 1747886162.555866, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2569.1404342651367, \"count\": 1, \"min\": 2569.1404342651367, \"max\": 2569.1404342651367}}}\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1760.8399397742694 records/second\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.5857825579491673\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] Epoch[103] Batch[0] avg_epoch_loss=2.561838\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.5618379928486914\n",
      "[05/22/2025 03:56:03 INFO 140041726678848] Epoch[103] Batch[5] avg_epoch_loss=2.574823\n",
      "[05/22/2025 03:56:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.574823392260579\n",
      "[05/22/2025 03:56:03 INFO 140041726678848] Epoch[103] Batch [5]#011Speed: 2281.90 samples/sec#011loss=2.574823\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] Epoch[103] Batch[10] avg_epoch_loss=2.591838\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.6122556962520878\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] Epoch[103] Batch [10]#011Speed: 2020.68 samples/sec#011loss=2.612256\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] processed a total of 4631 examples\n",
      "#metrics {\"StartTime\": 1747886162.5559251, \"EndTime\": 1747886165.073232, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2517.056941986084, \"count\": 1, \"min\": 2517.056941986084, \"max\": 2517.056941986084}}}\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1839.7816095546766 records/second\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.591838075893083\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] Epoch[104] Batch[0] avg_epoch_loss=2.562786\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.562786008839087\n",
      "[05/22/2025 03:56:06 INFO 140041726678848] Epoch[104] Batch[5] avg_epoch_loss=2.619773\n",
      "[05/22/2025 03:56:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.6197728169079437\n",
      "[05/22/2025 03:56:06 INFO 140041726678848] Epoch[104] Batch [5]#011Speed: 2259.02 samples/sec#011loss=2.619773\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] Epoch[104] Batch[10] avg_epoch_loss=2.657153\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=2.702008858661609\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] Epoch[104] Batch [10]#011Speed: 2014.77 samples/sec#011loss=2.702009\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] processed a total of 4599 examples\n",
      "#metrics {\"StartTime\": 1747886165.0732944, \"EndTime\": 1747886167.6260107, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2552.45041847229, \"count\": 1, \"min\": 2552.45041847229, \"max\": 2552.45041847229}}}\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1801.7375585086352 records/second\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.6571528358868823\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:08 INFO 140041726678848] Epoch[105] Batch[0] avg_epoch_loss=2.473209\n",
      "[05/22/2025 03:56:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.4732092366717704\n",
      "[05/22/2025 03:56:09 INFO 140041726678848] Epoch[105] Batch[5] avg_epoch_loss=2.493332\n",
      "[05/22/2025 03:56:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.4933322150351476\n",
      "[05/22/2025 03:56:09 INFO 140041726678848] Epoch[105] Batch [5]#011Speed: 2273.29 samples/sec#011loss=2.493332\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] Epoch[105] Batch[10] avg_epoch_loss=2.466043\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.433295099135231\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] Epoch[105] Batch [10]#011Speed: 2030.35 samples/sec#011loss=2.433295\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] processed a total of 4655 examples\n",
      "#metrics {\"StartTime\": 1747886167.62607, \"EndTime\": 1747886170.1514232, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2525.0749588012695, \"count\": 1, \"min\": 2525.0749588012695, \"max\": 2525.0749588012695}}}\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1843.4460973004534 records/second\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.466042616898822\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_979c1879-04b8-4a37-bcef-69605095dd8b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886170.1514823, \"EndTime\": 1747886170.1623468, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.590791702270508, \"count\": 1, \"min\": 10.590791702270508, \"max\": 10.590791702270508}}}\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] Epoch[106] Batch[0] avg_epoch_loss=2.502928\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.5029280562708798\n",
      "[05/22/2025 03:56:11 INFO 140041726678848] Epoch[106] Batch[5] avg_epoch_loss=2.507579\n",
      "[05/22/2025 03:56:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.5075789170523617\n",
      "[05/22/2025 03:56:11 INFO 140041726678848] Epoch[106] Batch [5]#011Speed: 2286.19 samples/sec#011loss=2.507579\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] processed a total of 4423 examples\n",
      "#metrics {\"StartTime\": 1747886170.1623986, \"EndTime\": 1747886172.5082233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2345.7727432250977, \"count\": 1, \"min\": 2345.7727432250977, \"max\": 2345.7727432250977}}}\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1885.4421658805156 records/second\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.591900784294961\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] Epoch[107] Batch[0] avg_epoch_loss=2.499576\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.4995764241717704\n",
      "[05/22/2025 03:56:13 INFO 140041726678848] Epoch[107] Batch[5] avg_epoch_loss=2.572090\n",
      "[05/22/2025 03:56:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.5720897241265313\n",
      "[05/22/2025 03:56:13 INFO 140041726678848] Epoch[107] Batch [5]#011Speed: 2303.20 samples/sec#011loss=2.572090\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] Epoch[107] Batch[10] avg_epoch_loss=2.640798\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.723248223047745\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] Epoch[107] Batch [10]#011Speed: 2027.31 samples/sec#011loss=2.723248\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] processed a total of 4610 examples\n",
      "#metrics {\"StartTime\": 1747886172.5082896, \"EndTime\": 1747886175.0209548, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2512.373447418213, \"count\": 1, \"min\": 2512.373447418213, \"max\": 2512.373447418213}}}\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1834.8552612350327 records/second\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.640798132727083\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] Epoch[108] Batch[0] avg_epoch_loss=2.453504\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.453503717027422\n",
      "[05/22/2025 03:56:16 INFO 140041726678848] Epoch[108] Batch[5] avg_epoch_loss=2.487790\n",
      "[05/22/2025 03:56:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.4877902953467195\n",
      "[05/22/2025 03:56:16 INFO 140041726678848] Epoch[108] Batch [5]#011Speed: 2279.01 samples/sec#011loss=2.487790\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] Epoch[108] Batch[10] avg_epoch_loss=2.538301\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.598914743266286\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] Epoch[108] Batch [10]#011Speed: 2020.77 samples/sec#011loss=2.598915\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] processed a total of 4559 examples\n",
      "#metrics {\"StartTime\": 1747886175.0210133, \"EndTime\": 1747886177.5501454, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2528.848171234131, \"count\": 1, \"min\": 2528.848171234131, \"max\": 2528.848171234131}}}\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1802.704753640912 records/second\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.5383014080374315\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] Epoch[109] Batch[0] avg_epoch_loss=2.523732\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.5237319368562083\n",
      "[05/22/2025 03:56:18 INFO 140041726678848] Epoch[109] Batch[5] avg_epoch_loss=2.633583\n",
      "[05/22/2025 03:56:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.6335831651354864\n",
      "[05/22/2025 03:56:18 INFO 140041726678848] Epoch[109] Batch [5]#011Speed: 2276.25 samples/sec#011loss=2.633583\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] Epoch[109] Batch[10] avg_epoch_loss=2.580657\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.5171459580317372\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] Epoch[109] Batch [10]#011Speed: 1988.33 samples/sec#011loss=2.517146\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] processed a total of 4698 examples\n",
      "#metrics {\"StartTime\": 1747886177.5502186, \"EndTime\": 1747886180.0852327, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.688711166382, \"count\": 1, \"min\": 2534.688711166382, \"max\": 2534.688711166382}}}\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1853.417359865744 records/second\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.5806571619065095\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] Epoch[110] Batch[0] avg_epoch_loss=2.562974\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.5629738720594375\n",
      "[05/22/2025 03:56:21 INFO 140041726678848] Epoch[110] Batch[5] avg_epoch_loss=2.539652\n",
      "[05/22/2025 03:56:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.5396518721435366\n",
      "[05/22/2025 03:56:21 INFO 140041726678848] Epoch[110] Batch [5]#011Speed: 2255.52 samples/sec#011loss=2.539652\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] Epoch[110] Batch[10] avg_epoch_loss=2.603760\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.680689618422884\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] Epoch[110] Batch [10]#011Speed: 2048.62 samples/sec#011loss=2.680690\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] processed a total of 4498 examples\n",
      "#metrics {\"StartTime\": 1747886180.085293, \"EndTime\": 1747886182.6352928, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2549.748182296753, \"count\": 1, \"min\": 2549.748182296753, \"max\": 2549.748182296753}}}\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1764.011653747304 records/second\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.6037599386341492\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:23 INFO 140041726678848] Epoch[111] Batch[0] avg_epoch_loss=2.510902\n",
      "[05/22/2025 03:56:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.510901504210746\n",
      "[05/22/2025 03:56:24 INFO 140041726678848] Epoch[111] Batch[5] avg_epoch_loss=2.483952\n",
      "[05/22/2025 03:56:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.4839522850982507\n",
      "[05/22/2025 03:56:24 INFO 140041726678848] Epoch[111] Batch [5]#011Speed: 2176.90 samples/sec#011loss=2.483952\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] Epoch[111] Batch[10] avg_epoch_loss=2.530718\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=2.5868364703681794\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] Epoch[111] Batch [10]#011Speed: 1963.84 samples/sec#011loss=2.586836\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] processed a total of 4587 examples\n",
      "#metrics {\"StartTime\": 1747886182.635387, \"EndTime\": 1747886185.2369795, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2601.3197898864746, \"count\": 1, \"min\": 2601.3197898864746, \"max\": 2601.3197898864746}}}\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1763.272975426707 records/second\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.530717823857309\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] Epoch[112] Batch[0] avg_epoch_loss=2.536052\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.536052066658547\n",
      "[05/22/2025 03:56:26 INFO 140041726678848] Epoch[112] Batch[5] avg_epoch_loss=2.483650\n",
      "[05/22/2025 03:56:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.4836496467845213\n",
      "[05/22/2025 03:56:26 INFO 140041726678848] Epoch[112] Batch [5]#011Speed: 2230.76 samples/sec#011loss=2.483650\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] Epoch[112] Batch[10] avg_epoch_loss=2.466578\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.446092635326768\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] Epoch[112] Batch [10]#011Speed: 1990.65 samples/sec#011loss=2.446093\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] processed a total of 4691 examples\n",
      "#metrics {\"StartTime\": 1747886185.2370431, \"EndTime\": 1747886187.7984703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2561.0876083374023, \"count\": 1, \"min\": 2561.0876083374023, \"max\": 2561.0876083374023}}}\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1831.5698776429467 records/second\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.466578277940088\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:28 INFO 140041726678848] Epoch[113] Batch[0] avg_epoch_loss=2.476687\n",
      "[05/22/2025 03:56:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.4766870171561806\n",
      "[05/22/2025 03:56:29 INFO 140041726678848] Epoch[113] Batch[5] avg_epoch_loss=2.463489\n",
      "[05/22/2025 03:56:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.463489195463298\n",
      "[05/22/2025 03:56:29 INFO 140041726678848] Epoch[113] Batch [5]#011Speed: 2302.36 samples/sec#011loss=2.463489\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] Epoch[113] Batch[10] avg_epoch_loss=2.550477\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.654862259013085\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] Epoch[113] Batch [10]#011Speed: 2002.63 samples/sec#011loss=2.654862\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] processed a total of 4603 examples\n",
      "#metrics {\"StartTime\": 1747886187.7985437, \"EndTime\": 1747886190.3182106, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2519.4151401519775, \"count\": 1, \"min\": 2519.4151401519775, \"max\": 2519.4151401519775}}}\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1826.9480503491866 records/second\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.550476951622292\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] Epoch[114] Batch[0] avg_epoch_loss=2.484623\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.484622946826281\n",
      "[05/22/2025 03:56:31 INFO 140041726678848] Epoch[114] Batch[5] avg_epoch_loss=2.544760\n",
      "[05/22/2025 03:56:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.5447603380051733\n",
      "[05/22/2025 03:56:31 INFO 140041726678848] Epoch[114] Batch [5]#011Speed: 2244.70 samples/sec#011loss=2.544760\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] Epoch[114] Batch[10] avg_epoch_loss=2.573477\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=2.6079373977763085\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] Epoch[114] Batch [10]#011Speed: 2021.21 samples/sec#011loss=2.607937\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] processed a total of 4637 examples\n",
      "#metrics {\"StartTime\": 1747886190.3182693, \"EndTime\": 1747886192.8698146, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2551.262140274048, \"count\": 1, \"min\": 2551.262140274048, \"max\": 2551.262140274048}}}\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1817.470798218655 records/second\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.5734771833556893\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:33 INFO 140041726678848] Epoch[115] Batch[0] avg_epoch_loss=2.458391\n",
      "[05/22/2025 03:56:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.4583908794717426\n",
      "[05/22/2025 03:56:34 INFO 140041726678848] Epoch[115] Batch[5] avg_epoch_loss=2.440297\n",
      "[05/22/2025 03:56:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.4402970595101383\n",
      "[05/22/2025 03:56:34 INFO 140041726678848] Epoch[115] Batch [5]#011Speed: 2209.68 samples/sec#011loss=2.440297\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] processed a total of 4427 examples\n",
      "#metrics {\"StartTime\": 1747886192.869872, \"EndTime\": 1747886195.2582653, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2388.144016265869, \"count\": 1, \"min\": 2388.144016265869, \"max\": 2388.144016265869}}}\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1853.6688121213247 records/second\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.454100692511136\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_1d64495a-e395-4cef-9f40-849854f19aad-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886195.258328, \"EndTime\": 1747886195.269224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.536909103393555, \"count\": 1, \"min\": 10.536909103393555, \"max\": 10.536909103393555}}}\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] Epoch[116] Batch[0] avg_epoch_loss=2.429065\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.429064642347578\n",
      "[05/22/2025 03:56:36 INFO 140041726678848] Epoch[116] Batch[5] avg_epoch_loss=2.534806\n",
      "[05/22/2025 03:56:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.5348058529225828\n",
      "[05/22/2025 03:56:36 INFO 140041726678848] Epoch[116] Batch [5]#011Speed: 2219.71 samples/sec#011loss=2.534806\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] Epoch[116] Batch[10] avg_epoch_loss=2.586175\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=2.647816926068346\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] Epoch[116] Batch [10]#011Speed: 1950.62 samples/sec#011loss=2.647817\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] processed a total of 4649 examples\n",
      "#metrics {\"StartTime\": 1747886195.269273, \"EndTime\": 1747886197.8729696, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2603.6462783813477, \"count\": 1, \"min\": 2603.6462783813477, \"max\": 2603.6462783813477}}}\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1785.5137854259447 records/second\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.5861745225342934\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:38 INFO 140041726678848] Epoch[117] Batch[0] avg_epoch_loss=2.487937\n",
      "[05/22/2025 03:56:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.4879373325271437\n",
      "[05/22/2025 03:56:39 INFO 140041726678848] Epoch[117] Batch[5] avg_epoch_loss=2.437657\n",
      "[05/22/2025 03:56:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.4376569604909055\n",
      "[05/22/2025 03:56:39 INFO 140041726678848] Epoch[117] Batch [5]#011Speed: 2298.43 samples/sec#011loss=2.437657\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] Epoch[117] Batch[10] avg_epoch_loss=2.488544\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.549608450636832\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] Epoch[117] Batch [10]#011Speed: 2037.97 samples/sec#011loss=2.549608\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] processed a total of 4529 examples\n",
      "#metrics {\"StartTime\": 1747886197.8730288, \"EndTime\": 1747886200.3970602, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2523.7767696380615, \"count\": 1, \"min\": 2523.7767696380615, \"max\": 2523.7767696380615}}}\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.4661016372754 records/second\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.4885440014663267\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] Epoch[118] Batch[0] avg_epoch_loss=2.584655\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.5846545382969097\n",
      "[05/22/2025 03:56:41 INFO 140041726678848] Epoch[118] Batch[5] avg_epoch_loss=2.585593\n",
      "[05/22/2025 03:56:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.5855929481602637\n",
      "[05/22/2025 03:56:41 INFO 140041726678848] Epoch[118] Batch [5]#011Speed: 2223.26 samples/sec#011loss=2.585593\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] Epoch[118] Batch[10] avg_epoch_loss=2.592738\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.601312758821687\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] Epoch[118] Batch [10]#011Speed: 2045.97 samples/sec#011loss=2.601313\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] processed a total of 4567 examples\n",
      "#metrics {\"StartTime\": 1747886200.397123, \"EndTime\": 1747886202.9331446, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2535.6481075286865, \"count\": 1, \"min\": 2535.6481075286865, \"max\": 2535.6481075286865}}}\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1801.0517222850244 records/second\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.5927383166427287\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:43 INFO 140041726678848] Epoch[119] Batch[0] avg_epoch_loss=2.511971\n",
      "[05/22/2025 03:56:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.511970774899081\n",
      "[05/22/2025 03:56:44 INFO 140041726678848] Epoch[119] Batch[5] avg_epoch_loss=2.503728\n",
      "[05/22/2025 03:56:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.5037278116590107\n",
      "[05/22/2025 03:56:44 INFO 140041726678848] Epoch[119] Batch [5]#011Speed: 2276.87 samples/sec#011loss=2.503728\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] Epoch[119] Batch[10] avg_epoch_loss=2.436321\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=2.3554318842218818\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] Epoch[119] Batch [10]#011Speed: 1943.16 samples/sec#011loss=2.355432\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] processed a total of 4692 examples\n",
      "#metrics {\"StartTime\": 1747886202.9332054, \"EndTime\": 1747886205.4992363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2565.7734870910645, \"count\": 1, \"min\": 2565.7734870910645, \"max\": 2565.7734870910645}}}\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1828.6252764238634 records/second\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.4363205719148615\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_6d7fa614-1138-4c93-b0d9-c2ee125fe6cf-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886205.4992967, \"EndTime\": 1747886205.510397, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.796546936035156, \"count\": 1, \"min\": 10.796546936035156, \"max\": 10.796546936035156}}}\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] Epoch[120] Batch[0] avg_epoch_loss=2.433695\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.4336948862054566\n",
      "[05/22/2025 03:56:46 INFO 140041726678848] Epoch[120] Batch[5] avg_epoch_loss=2.409278\n",
      "[05/22/2025 03:56:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.409277742494896\n",
      "[05/22/2025 03:56:46 INFO 140041726678848] Epoch[120] Batch [5]#011Speed: 2247.59 samples/sec#011loss=2.409278\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] Epoch[120] Batch[10] avg_epoch_loss=2.507548\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=2.6254733283163976\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] Epoch[120] Batch [10]#011Speed: 2002.91 samples/sec#011loss=2.625473\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] processed a total of 4562 examples\n",
      "#metrics {\"StartTime\": 1747886205.51045, \"EndTime\": 1747886208.062288, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2551.786184310913, \"count\": 1, \"min\": 2551.786184310913, \"max\": 2551.786184310913}}}\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1787.707543964142 records/second\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.507548463322851\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] Epoch[121] Batch[0] avg_epoch_loss=2.527487\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.5274867544195434\n",
      "[05/22/2025 03:56:49 INFO 140041726678848] Epoch[121] Batch[5] avg_epoch_loss=2.570689\n",
      "[05/22/2025 03:56:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.5706890873671817\n",
      "[05/22/2025 03:56:49 INFO 140041726678848] Epoch[121] Batch [5]#011Speed: 2264.53 samples/sec#011loss=2.570689\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] Epoch[121] Batch[10] avg_epoch_loss=2.618911\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=2.676778094115395\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] Epoch[121] Batch [10]#011Speed: 2013.33 samples/sec#011loss=2.676778\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] processed a total of 4651 examples\n",
      "#metrics {\"StartTime\": 1747886208.0623457, \"EndTime\": 1747886210.6030602, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2540.4176712036133, \"count\": 1, \"min\": 2540.4176712036133, \"max\": 2540.4176712036133}}}\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1830.7360202048412 records/second\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.6189113631618244\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:51 INFO 140041726678848] Epoch[122] Batch[0] avg_epoch_loss=2.461295\n",
      "[05/22/2025 03:56:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.4612947391773385\n",
      "[05/22/2025 03:56:52 INFO 140041726678848] Epoch[122] Batch[5] avg_epoch_loss=2.554026\n",
      "[05/22/2025 03:56:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.554025945967892\n",
      "[05/22/2025 03:56:52 INFO 140041726678848] Epoch[122] Batch [5]#011Speed: 2272.52 samples/sec#011loss=2.554026\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] Epoch[122] Batch[10] avg_epoch_loss=2.461090\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=2.349566908668569\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] Epoch[122] Batch [10]#011Speed: 1960.92 samples/sec#011loss=2.349567\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] processed a total of 4656 examples\n",
      "#metrics {\"StartTime\": 1747886210.6031215, \"EndTime\": 1747886213.1597424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2556.335210800171, \"count\": 1, \"min\": 2556.335210800171, \"max\": 2556.335210800171}}}\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1821.2962279831386 records/second\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.461090019922745\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] Epoch[123] Batch[0] avg_epoch_loss=2.547620\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.547619656093402\n",
      "[05/22/2025 03:56:54 INFO 140041726678848] Epoch[123] Batch[5] avg_epoch_loss=2.487128\n",
      "[05/22/2025 03:56:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.487128061635811\n",
      "[05/22/2025 03:56:54 INFO 140041726678848] Epoch[123] Batch [5]#011Speed: 2272.43 samples/sec#011loss=2.487128\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] Epoch[123] Batch[10] avg_epoch_loss=2.392380\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=2.278681548188683\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] Epoch[123] Batch [10]#011Speed: 2030.41 samples/sec#011loss=2.278682\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] processed a total of 4640 examples\n",
      "#metrics {\"StartTime\": 1747886213.1598005, \"EndTime\": 1747886215.6825814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.489070892334, \"count\": 1, \"min\": 2522.489070892334, \"max\": 2522.489070892334}}}\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1839.3886388261526 records/second\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] #progress_metric: host=algo-1, completed 31.0 % of epochs\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.392379646432571\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_d55dd34f-a2ba-4263-8295-b32d96eb93b4-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886215.6826413, \"EndTime\": 1747886215.6930084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.099172592163086, \"count\": 1, \"min\": 10.099172592163086, \"max\": 10.099172592163086}}}\n",
      "[05/22/2025 03:56:56 INFO 140041726678848] Epoch[124] Batch[0] avg_epoch_loss=2.396659\n",
      "[05/22/2025 03:56:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.3966589165158685\n",
      "[05/22/2025 03:56:57 INFO 140041726678848] Epoch[124] Batch[5] avg_epoch_loss=2.402287\n",
      "[05/22/2025 03:56:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.4022870194761508\n",
      "[05/22/2025 03:56:57 INFO 140041726678848] Epoch[124] Batch [5]#011Speed: 2286.43 samples/sec#011loss=2.402287\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] Epoch[124] Batch[10] avg_epoch_loss=2.417422\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=2.435583523280902\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] Epoch[124] Batch [10]#011Speed: 1975.01 samples/sec#011loss=2.435584\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] processed a total of 4703 examples\n",
      "#metrics {\"StartTime\": 1747886215.6930633, \"EndTime\": 1747886218.231984, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2538.867950439453, \"count\": 1, \"min\": 2538.867950439453, \"max\": 2538.867950439453}}}\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1852.3369061696856 records/second\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] #progress_metric: host=algo-1, completed 31.25 % of epochs\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.417421793932856\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] Epoch[125] Batch[0] avg_epoch_loss=2.538808\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.5388080282572383\n",
      "[05/22/2025 03:56:59 INFO 140041726678848] Epoch[125] Batch[5] avg_epoch_loss=2.510003\n",
      "[05/22/2025 03:56:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.510003286020439\n",
      "[05/22/2025 03:56:59 INFO 140041726678848] Epoch[125] Batch [5]#011Speed: 2255.99 samples/sec#011loss=2.510003\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] Epoch[125] Batch[10] avg_epoch_loss=2.424945\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=2.32287584062674\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] Epoch[125] Batch [10]#011Speed: 1993.37 samples/sec#011loss=2.322876\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] processed a total of 4541 examples\n",
      "#metrics {\"StartTime\": 1747886218.2320428, \"EndTime\": 1747886220.7745323, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.234182357788, \"count\": 1, \"min\": 2542.234182357788, \"max\": 2542.234182357788}}}\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.1597895658253 records/second\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] #progress_metric: host=algo-1, completed 31.5 % of epochs\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.42494535629603\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:01 INFO 140041726678848] Epoch[126] Batch[0] avg_epoch_loss=2.523755\n",
      "[05/22/2025 03:57:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.523754774063892\n",
      "[05/22/2025 03:57:02 INFO 140041726678848] Epoch[126] Batch[5] avg_epoch_loss=2.553108\n",
      "[05/22/2025 03:57:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.553108379587741\n",
      "[05/22/2025 03:57:02 INFO 140041726678848] Epoch[126] Batch [5]#011Speed: 2250.13 samples/sec#011loss=2.553108\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] Epoch[126] Batch[10] avg_epoch_loss=2.633953\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=2.7309656767643373\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] Epoch[126] Batch [10]#011Speed: 1996.94 samples/sec#011loss=2.730966\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] processed a total of 4697 examples\n",
      "#metrics {\"StartTime\": 1747886220.7745943, \"EndTime\": 1747886223.3219438, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2546.9894409179688, \"count\": 1, \"min\": 2546.9894409179688, \"max\": 2546.9894409179688}}}\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1844.0723990913607 records/second\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] #progress_metric: host=algo-1, completed 31.75 % of epochs\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.633952605577103\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] Epoch[127] Batch[0] avg_epoch_loss=2.491777\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.4917772458762526\n",
      "[05/22/2025 03:57:04 INFO 140041726678848] Epoch[127] Batch[5] avg_epoch_loss=2.564333\n",
      "[05/22/2025 03:57:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.56433304841198\n",
      "[05/22/2025 03:57:04 INFO 140041726678848] Epoch[127] Batch [5]#011Speed: 2250.40 samples/sec#011loss=2.564333\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] Epoch[127] Batch[10] avg_epoch_loss=2.556149\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=2.5463283207474943\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] Epoch[127] Batch [10]#011Speed: 1967.62 samples/sec#011loss=2.546328\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] processed a total of 4641 examples\n",
      "#metrics {\"StartTime\": 1747886223.322001, \"EndTime\": 1747886225.891034, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2568.7124729156494, \"count\": 1, \"min\": 2568.7124729156494, \"max\": 2568.7124729156494}}}\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1806.6845410496198 records/second\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] #progress_metric: host=algo-1, completed 32.0 % of epochs\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.5561490812917596\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:06 INFO 140041726678848] Epoch[128] Batch[0] avg_epoch_loss=2.480115\n",
      "[05/22/2025 03:57:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.480114501409382\n",
      "[05/22/2025 03:57:07 INFO 140041726678848] Epoch[128] Batch[5] avg_epoch_loss=2.437706\n",
      "[05/22/2025 03:57:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.4377057161168336\n",
      "[05/22/2025 03:57:07 INFO 140041726678848] Epoch[128] Batch [5]#011Speed: 2235.92 samples/sec#011loss=2.437706\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] Epoch[128] Batch[10] avg_epoch_loss=2.448918\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=2.4623724922570993\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] Epoch[128] Batch [10]#011Speed: 2026.77 samples/sec#011loss=2.462372\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] processed a total of 4566 examples\n",
      "#metrics {\"StartTime\": 1747886225.8910868, \"EndTime\": 1747886228.4419117, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2550.5359172821045, \"count\": 1, \"min\": 2550.5359172821045, \"max\": 2550.5359172821045}}}\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1790.1107597374094 records/second\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] #progress_metric: host=algo-1, completed 32.25 % of epochs\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.4489178870896815\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] Epoch[129] Batch[0] avg_epoch_loss=2.372604\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.372603996293847\n",
      "[05/22/2025 03:57:09 INFO 140041726678848] Epoch[129] Batch[5] avg_epoch_loss=2.485529\n",
      "[05/22/2025 03:57:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.485529411786029\n",
      "[05/22/2025 03:57:09 INFO 140041726678848] Epoch[129] Batch [5]#011Speed: 2259.08 samples/sec#011loss=2.485529\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] Epoch[129] Batch[10] avg_epoch_loss=2.404272\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=2.30676296718402\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] Epoch[129] Batch [10]#011Speed: 1994.43 samples/sec#011loss=2.306763\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] processed a total of 4556 examples\n",
      "#metrics {\"StartTime\": 1747886228.4420247, \"EndTime\": 1747886230.9896383, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2547.307014465332, \"count\": 1, \"min\": 2547.307014465332, \"max\": 2547.307014465332}}}\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.4925703978715 records/second\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 32.5 % of epochs\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.4042719369669343\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:11 INFO 140041726678848] Epoch[130] Batch[0] avg_epoch_loss=2.411401\n",
      "[05/22/2025 03:57:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.411401149690284\n",
      "[05/22/2025 03:57:12 INFO 140041726678848] Epoch[130] Batch[5] avg_epoch_loss=2.371448\n",
      "[05/22/2025 03:57:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.371448225150218\n",
      "[05/22/2025 03:57:12 INFO 140041726678848] Epoch[130] Batch [5]#011Speed: 2188.08 samples/sec#011loss=2.371448\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] Epoch[130] Batch[10] avg_epoch_loss=2.331212\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=2.282928018208867\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] Epoch[130] Batch [10]#011Speed: 2026.38 samples/sec#011loss=2.282928\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] processed a total of 4578 examples\n",
      "#metrics {\"StartTime\": 1747886230.9896991, \"EndTime\": 1747886233.559296, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2569.29874420166, \"count\": 1, \"min\": 2569.29874420166, \"max\": 2569.29874420166}}}\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1781.729949589395 records/second\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] #progress_metric: host=algo-1, completed 32.75 % of epochs\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.331211767449604\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_ca454f7c-5452-4c0c-ba6a-8e0214c8ecfd-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886233.5593812, \"EndTime\": 1747886233.5703459, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.68568229675293, \"count\": 1, \"min\": 10.68568229675293, \"max\": 10.68568229675293}}}\n",
      "[05/22/2025 03:57:14 INFO 140041726678848] Epoch[131] Batch[0] avg_epoch_loss=2.377934\n",
      "[05/22/2025 03:57:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.3779343093158407\n",
      "[05/22/2025 03:57:14 INFO 140041726678848] Epoch[131] Batch[5] avg_epoch_loss=2.347467\n",
      "[05/22/2025 03:57:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.347467072733969\n",
      "[05/22/2025 03:57:14 INFO 140041726678848] Epoch[131] Batch [5]#011Speed: 2274.15 samples/sec#011loss=2.347467\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] Epoch[131] Batch[10] avg_epoch_loss=2.490040\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=2.661126885700863\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] Epoch[131] Batch [10]#011Speed: 2022.83 samples/sec#011loss=2.661127\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] processed a total of 4643 examples\n",
      "#metrics {\"StartTime\": 1747886233.5703962, \"EndTime\": 1747886236.1004183, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2529.9718379974365, \"count\": 1, \"min\": 2529.9718379974365, \"max\": 2529.9718379974365}}}\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1835.1336145599564 records/second\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] #progress_metric: host=algo-1, completed 33.0 % of epochs\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.490039714991648\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] Epoch[132] Batch[0] avg_epoch_loss=2.416108\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.416107517573775\n",
      "[05/22/2025 03:57:17 INFO 140041726678848] Epoch[132] Batch[5] avg_epoch_loss=2.501582\n",
      "[05/22/2025 03:57:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.5015819750632193\n",
      "[05/22/2025 03:57:17 INFO 140041726678848] Epoch[132] Batch [5]#011Speed: 2276.88 samples/sec#011loss=2.501582\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] Epoch[132] Batch[10] avg_epoch_loss=2.562521\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=2.635648881194321\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] Epoch[132] Batch [10]#011Speed: 2023.46 samples/sec#011loss=2.635649\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] processed a total of 4613 examples\n",
      "#metrics {\"StartTime\": 1747886236.1004786, \"EndTime\": 1747886238.623259, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.5281715393066, \"count\": 1, \"min\": 2522.5281715393066, \"max\": 2522.5281715393066}}}\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1828.644856998929 records/second\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] #progress_metric: host=algo-1, completed 33.25 % of epochs\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.5625214778500833\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:19 INFO 140041726678848] Epoch[133] Batch[0] avg_epoch_loss=2.387518\n",
      "[05/22/2025 03:57:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.387517508525891\n",
      "[05/22/2025 03:57:20 INFO 140041726678848] Epoch[133] Batch[5] avg_epoch_loss=2.530757\n",
      "[05/22/2025 03:57:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.5307571875579993\n",
      "[05/22/2025 03:57:20 INFO 140041726678848] Epoch[133] Batch [5]#011Speed: 2264.20 samples/sec#011loss=2.530757\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] processed a total of 4484 examples\n",
      "#metrics {\"StartTime\": 1747886238.6233346, \"EndTime\": 1747886241.020033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2396.365165710449, \"count\": 1, \"min\": 2396.365165710449, \"max\": 2396.365165710449}}}\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1871.092779533848 records/second\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] #progress_metric: host=algo-1, completed 33.5 % of epochs\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.474232778570434\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] Epoch[134] Batch[0] avg_epoch_loss=2.363325\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.3633252931862474\n",
      "[05/22/2025 03:57:22 INFO 140041726678848] Epoch[134] Batch[5] avg_epoch_loss=2.367450\n",
      "[05/22/2025 03:57:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.367450173200283\n",
      "[05/22/2025 03:57:22 INFO 140041726678848] Epoch[134] Batch [5]#011Speed: 2273.13 samples/sec#011loss=2.367450\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] Epoch[134] Batch[10] avg_epoch_loss=2.404033\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.4479319820956293\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] Epoch[134] Batch [10]#011Speed: 1978.68 samples/sec#011loss=2.447932\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] processed a total of 4593 examples\n",
      "#metrics {\"StartTime\": 1747886241.0200965, \"EndTime\": 1747886243.575521, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2555.13072013855, \"count\": 1, \"min\": 2555.13072013855, \"max\": 2555.13072013855}}}\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1797.498476490479 records/second\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 33.75 % of epochs\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.4040328136072584\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:24 INFO 140041726678848] Epoch[135] Batch[0] avg_epoch_loss=2.397218\n",
      "[05/22/2025 03:57:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.3972178843610803\n",
      "[05/22/2025 03:57:25 INFO 140041726678848] Epoch[135] Batch[5] avg_epoch_loss=2.399963\n",
      "[05/22/2025 03:57:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.3999625632916897\n",
      "[05/22/2025 03:57:25 INFO 140041726678848] Epoch[135] Batch [5]#011Speed: 2238.76 samples/sec#011loss=2.399963\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] Epoch[135] Batch[10] avg_epoch_loss=2.468971\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=2.551781030327812\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] Epoch[135] Batch [10]#011Speed: 1999.98 samples/sec#011loss=2.551781\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] processed a total of 4642 examples\n",
      "#metrics {\"StartTime\": 1747886243.5755801, \"EndTime\": 1747886246.1329813, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2557.1515560150146, \"count\": 1, \"min\": 2557.1515560150146, \"max\": 2557.1515560150146}}}\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1815.2388049084086 records/second\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] #progress_metric: host=algo-1, completed 34.0 % of epochs\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.468970957399018\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] Epoch[136] Batch[0] avg_epoch_loss=2.368310\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.368310057506264\n",
      "[05/22/2025 03:57:27 INFO 140041726678848] Epoch[136] Batch[5] avg_epoch_loss=2.379589\n",
      "[05/22/2025 03:57:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.3795887834510716\n",
      "[05/22/2025 03:57:27 INFO 140041726678848] Epoch[136] Batch [5]#011Speed: 2263.84 samples/sec#011loss=2.379589\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] Epoch[136] Batch[10] avg_epoch_loss=2.448466\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=2.5311197191675947\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] Epoch[136] Batch [10]#011Speed: 2040.98 samples/sec#011loss=2.531120\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] processed a total of 4532 examples\n",
      "#metrics {\"StartTime\": 1747886246.133041, \"EndTime\": 1747886248.6618524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2528.557538986206, \"count\": 1, \"min\": 2528.557538986206, \"max\": 2528.557538986206}}}\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1792.2613362363652 records/second\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 34.25 % of epochs\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.448466481504037\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:29 INFO 140041726678848] Epoch[137] Batch[0] avg_epoch_loss=2.352606\n",
      "[05/22/2025 03:57:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.352605671022411\n",
      "[05/22/2025 03:57:30 INFO 140041726678848] Epoch[137] Batch[5] avg_epoch_loss=2.391588\n",
      "[05/22/2025 03:57:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.391587697052478\n",
      "[05/22/2025 03:57:30 INFO 140041726678848] Epoch[137] Batch [5]#011Speed: 2259.78 samples/sec#011loss=2.391588\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] Epoch[137] Batch[10] avg_epoch_loss=2.467626\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=2.5588724726823497\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] Epoch[137] Batch [10]#011Speed: 2033.34 samples/sec#011loss=2.558872\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] processed a total of 4567 examples\n",
      "#metrics {\"StartTime\": 1747886248.6619153, \"EndTime\": 1747886251.2275693, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2565.350294113159, \"count\": 1, \"min\": 2565.350294113159, \"max\": 2565.350294113159}}}\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1780.1804779430283 records/second\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] #progress_metric: host=algo-1, completed 34.5 % of epochs\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.4676262314296924\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] Epoch[138] Batch[0] avg_epoch_loss=2.417905\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.4179051320643095\n",
      "[05/22/2025 03:57:32 INFO 140041726678848] Epoch[138] Batch[5] avg_epoch_loss=2.399348\n",
      "[05/22/2025 03:57:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.399347544601429\n",
      "[05/22/2025 03:57:32 INFO 140041726678848] Epoch[138] Batch [5]#011Speed: 2266.25 samples/sec#011loss=2.399348\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] Epoch[138] Batch[10] avg_epoch_loss=2.458058\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.528509861323775\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] Epoch[138] Batch [10]#011Speed: 2019.44 samples/sec#011loss=2.528510\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] processed a total of 4554 examples\n",
      "#metrics {\"StartTime\": 1747886251.22766, \"EndTime\": 1747886253.7700741, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.1266555786133, \"count\": 1, \"min\": 2542.1266555786133, \"max\": 2542.1266555786133}}}\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1791.3513341965195 records/second\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 34.75 % of epochs\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.458057688566132\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:34 INFO 140041726678848] Epoch[139] Batch[0] avg_epoch_loss=2.353017\n",
      "[05/22/2025 03:57:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.3530170126322383\n",
      "[05/22/2025 03:57:35 INFO 140041726678848] Epoch[139] Batch[5] avg_epoch_loss=2.426891\n",
      "[05/22/2025 03:57:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.426891120168662\n",
      "[05/22/2025 03:57:35 INFO 140041726678848] Epoch[139] Batch [5]#011Speed: 2097.57 samples/sec#011loss=2.426891\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] Epoch[139] Batch[10] avg_epoch_loss=2.556661\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=2.712385270218541\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] Epoch[139] Batch [10]#011Speed: 1981.80 samples/sec#011loss=2.712385\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] processed a total of 4624 examples\n",
      "#metrics {\"StartTime\": 1747886253.7701344, \"EndTime\": 1747886256.4016125, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2631.2265396118164, \"count\": 1, \"min\": 2631.2265396118164, \"max\": 2631.2265396118164}}}\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1757.2959431024424 records/second\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 35.0 % of epochs\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.5566611883731523\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] Epoch[140] Batch[0] avg_epoch_loss=2.624928\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.6249284977902283\n",
      "[05/22/2025 03:57:37 INFO 140041726678848] Epoch[140] Batch[5] avg_epoch_loss=2.600696\n",
      "[05/22/2025 03:57:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.600695547034498\n",
      "[05/22/2025 03:57:37 INFO 140041726678848] Epoch[140] Batch [5]#011Speed: 2295.47 samples/sec#011loss=2.600696\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] Epoch[140] Batch[10] avg_epoch_loss=2.551340\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=2.4921131159521157\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] Epoch[140] Batch [10]#011Speed: 2013.76 samples/sec#011loss=2.492113\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] processed a total of 4579 examples\n",
      "#metrics {\"StartTime\": 1747886256.401672, \"EndTime\": 1747886258.9224718, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2520.5440521240234, \"count\": 1, \"min\": 2520.5440521240234, \"max\": 2520.5440521240234}}}\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1816.6077059121867 records/second\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 35.25 % of epochs\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.551339896542506\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:39 INFO 140041726678848] Epoch[141] Batch[0] avg_epoch_loss=2.535085\n",
      "[05/22/2025 03:57:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.5350847477902283\n",
      "[05/22/2025 03:57:40 INFO 140041726678848] Epoch[141] Batch[5] avg_epoch_loss=2.478133\n",
      "[05/22/2025 03:57:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.4781330111474573\n",
      "[05/22/2025 03:57:40 INFO 140041726678848] Epoch[141] Batch [5]#011Speed: 2270.23 samples/sec#011loss=2.478133\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] Epoch[141] Batch[10] avg_epoch_loss=2.591714\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=2.7280109227101894\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] Epoch[141] Batch [10]#011Speed: 1979.16 samples/sec#011loss=2.728011\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] processed a total of 4693 examples\n",
      "#metrics {\"StartTime\": 1747886258.9225323, \"EndTime\": 1747886261.4932172, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2570.424795150757, \"count\": 1, \"min\": 2570.424795150757, \"max\": 2570.424795150757}}}\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1825.6983196117517 records/second\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 35.5 % of epochs\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.5917138800396082\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] Epoch[142] Batch[0] avg_epoch_loss=2.428561\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.4285614081639757\n",
      "[05/22/2025 03:57:42 INFO 140041726678848] Epoch[142] Batch[5] avg_epoch_loss=2.417518\n",
      "[05/22/2025 03:57:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.417517669836326\n",
      "[05/22/2025 03:57:42 INFO 140041726678848] Epoch[142] Batch [5]#011Speed: 2252.30 samples/sec#011loss=2.417518\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] Epoch[142] Batch[10] avg_epoch_loss=2.330217\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=2.2254564722821546\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] Epoch[142] Batch [10]#011Speed: 2023.12 samples/sec#011loss=2.225456\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] processed a total of 4599 examples\n",
      "#metrics {\"StartTime\": 1747886261.493285, \"EndTime\": 1747886264.033086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2539.4515991210938, \"count\": 1, \"min\": 2539.4515991210938, \"max\": 2539.4515991210938}}}\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.9580226523672 records/second\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] #progress_metric: host=algo-1, completed 35.75 % of epochs\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.330217125493521\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_775fae88-f743-4072-b1be-7f406890834f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886264.0331464, \"EndTime\": 1747886264.0442657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.84446907043457, \"count\": 1, \"min\": 10.84446907043457, \"max\": 10.84446907043457}}}\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] Epoch[143] Batch[0] avg_epoch_loss=2.336717\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.3367166837764475\n",
      "[05/22/2025 03:57:45 INFO 140041726678848] Epoch[143] Batch[5] avg_epoch_loss=2.456225\n",
      "[05/22/2025 03:57:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.456225332190748\n",
      "[05/22/2025 03:57:45 INFO 140041726678848] Epoch[143] Batch [5]#011Speed: 2288.60 samples/sec#011loss=2.456225\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] Epoch[143] Batch[10] avg_epoch_loss=2.446751\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=2.435381495554357\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] Epoch[143] Batch [10]#011Speed: 1976.81 samples/sec#011loss=2.435381\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] processed a total of 4674 examples\n",
      "#metrics {\"StartTime\": 1747886264.0443192, \"EndTime\": 1747886266.5875294, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2543.1575775146484, \"count\": 1, \"min\": 2543.1575775146484, \"max\": 2543.1575775146484}}}\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1837.809342031944 records/second\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 36.0 % of epochs\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.4467508609923883\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:47 INFO 140041726678848] Epoch[144] Batch[0] avg_epoch_loss=2.324071\n",
      "[05/22/2025 03:57:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.3240705800215755\n",
      "[05/22/2025 03:57:47 INFO 140041726678848] Epoch[144] Batch[5] avg_epoch_loss=2.345777\n",
      "[05/22/2025 03:57:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.3457773006130522\n",
      "[05/22/2025 03:57:47 INFO 140041726678848] Epoch[144] Batch [5]#011Speed: 2283.99 samples/sec#011loss=2.345777\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] Epoch[144] Batch[10] avg_epoch_loss=2.389159\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=2.441217571165089\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] Epoch[144] Batch [10]#011Speed: 2024.83 samples/sec#011loss=2.441218\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] processed a total of 4569 examples\n",
      "#metrics {\"StartTime\": 1747886266.5875902, \"EndTime\": 1747886269.103412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2515.566349029541, \"count\": 1, \"min\": 2515.566349029541, \"max\": 2515.566349029541}}}\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1816.2286518836202 records/second\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 36.25 % of epochs\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.389159241773069\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] Epoch[145] Batch[0] avg_epoch_loss=2.390622\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.3906220094132795\n",
      "[05/22/2025 03:57:50 INFO 140041726678848] Epoch[145] Batch[5] avg_epoch_loss=2.466208\n",
      "[05/22/2025 03:57:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.4662078653518233\n",
      "[05/22/2025 03:57:50 INFO 140041726678848] Epoch[145] Batch [5]#011Speed: 2243.78 samples/sec#011loss=2.466208\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] processed a total of 4459 examples\n",
      "#metrics {\"StartTime\": 1747886269.1034713, \"EndTime\": 1747886271.5460577, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2442.326307296753, \"count\": 1, \"min\": 2442.326307296753, \"max\": 2442.326307296753}}}\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1825.6472587863368 records/second\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 36.5 % of epochs\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.428204277735245\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] Epoch[146] Batch[0] avg_epoch_loss=2.395186\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.3951856447487474\n",
      "[05/22/2025 03:57:53 INFO 140041726678848] Epoch[146] Batch[5] avg_epoch_loss=2.339390\n",
      "[05/22/2025 03:57:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.3393896339376856\n",
      "[05/22/2025 03:57:53 INFO 140041726678848] Epoch[146] Batch [5]#011Speed: 2154.28 samples/sec#011loss=2.339390\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] Epoch[146] Batch[10] avg_epoch_loss=2.303116\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=2.2595867335398108\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] Epoch[146] Batch [10]#011Speed: 2008.35 samples/sec#011loss=2.259587\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] processed a total of 4530 examples\n",
      "#metrics {\"StartTime\": 1747886271.546122, \"EndTime\": 1747886274.1423612, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2595.909357070923, \"count\": 1, \"min\": 2595.909357070923, \"max\": 2595.909357070923}}}\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1744.995210037843 records/second\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 36.75 % of epochs\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.303115588302288\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_d3c5f3f3-a30b-4ec3-a341-4cfe2e5f33ca-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886274.1424205, \"EndTime\": 1747886274.1528268, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.142326354980469, \"count\": 1, \"min\": 10.142326354980469, \"max\": 10.142326354980469}}}\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] Epoch[147] Batch[0] avg_epoch_loss=2.320619\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=2.32061944294613\n",
      "[05/22/2025 03:57:55 INFO 140041726678848] Epoch[147] Batch[5] avg_epoch_loss=2.341309\n",
      "[05/22/2025 03:57:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=2.34130877499768\n",
      "[05/22/2025 03:57:55 INFO 140041726678848] Epoch[147] Batch [5]#011Speed: 2250.12 samples/sec#011loss=2.341309\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] Epoch[147] Batch[10] avg_epoch_loss=2.366586\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=2.396917683828647\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] Epoch[147] Batch [10]#011Speed: 2008.33 samples/sec#011loss=2.396918\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] processed a total of 4520 examples\n",
      "#metrics {\"StartTime\": 1747886274.1528757, \"EndTime\": 1747886276.7015643, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.6385822296143, \"count\": 1, \"min\": 2548.6385822296143, \"max\": 2548.6385822296143}}}\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.4310032519638 records/second\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 37.0 % of epochs\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.366585551739029\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:57 INFO 140041726678848] Epoch[148] Batch[0] avg_epoch_loss=2.343230\n",
      "[05/22/2025 03:57:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.343229909782155\n",
      "[05/22/2025 03:57:58 INFO 140041726678848] Epoch[148] Batch[5] avg_epoch_loss=2.318303\n",
      "[05/22/2025 03:57:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.3183031429072707\n",
      "[05/22/2025 03:57:58 INFO 140041726678848] Epoch[148] Batch [5]#011Speed: 2311.23 samples/sec#011loss=2.318303\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] Epoch[148] Batch[10] avg_epoch_loss=2.343569\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=2.37388834454169\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] Epoch[148] Batch [10]#011Speed: 2011.51 samples/sec#011loss=2.373888\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] processed a total of 4643 examples\n",
      "#metrics {\"StartTime\": 1747886276.7016296, \"EndTime\": 1747886279.2156496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2513.7391090393066, \"count\": 1, \"min\": 2513.7391090393066, \"max\": 2513.7391090393066}}}\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1846.9835831825096 records/second\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 37.25 % of epochs\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.3435691436501886\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] Epoch[149] Batch[0] avg_epoch_loss=2.447253\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.447253390781598\n",
      "[05/22/2025 03:58:00 INFO 140041726678848] Epoch[149] Batch[5] avg_epoch_loss=2.408223\n",
      "[05/22/2025 03:58:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.408222563813683\n",
      "[05/22/2025 03:58:00 INFO 140041726678848] Epoch[149] Batch [5]#011Speed: 2283.34 samples/sec#011loss=2.408223\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] Epoch[149] Batch[10] avg_epoch_loss=2.573564\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=2.771972710624304\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] Epoch[149] Batch [10]#011Speed: 1823.93 samples/sec#011loss=2.771973\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] processed a total of 4668 examples\n",
      "#metrics {\"StartTime\": 1747886279.215712, \"EndTime\": 1747886281.8676622, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2651.6966819763184, \"count\": 1, \"min\": 2651.6966819763184, \"max\": 2651.6966819763184}}}\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1760.3244080318004 records/second\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] #progress_metric: host=algo-1, completed 37.5 % of epochs\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.5735635396366927\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:02 INFO 140041726678848] Epoch[150] Batch[0] avg_epoch_loss=2.587040\n",
      "[05/22/2025 03:58:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.5870404827568207\n",
      "[05/22/2025 03:58:03 INFO 140041726678848] Epoch[150] Batch[5] avg_epoch_loss=2.572142\n",
      "[05/22/2025 03:58:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.5721424672014197\n",
      "[05/22/2025 03:58:03 INFO 140041726678848] Epoch[150] Batch [5]#011Speed: 2258.10 samples/sec#011loss=2.572142\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] Epoch[150] Batch[10] avg_epoch_loss=2.486849\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=2.3844961459493317\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] Epoch[150] Batch [10]#011Speed: 2033.27 samples/sec#011loss=2.384496\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] processed a total of 4581 examples\n",
      "#metrics {\"StartTime\": 1747886281.8677213, \"EndTime\": 1747886284.398283, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2530.311346054077, \"count\": 1, \"min\": 2530.311346054077, \"max\": 2530.311346054077}}}\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.3959174639674 records/second\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 37.75 % of epochs\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.486848684814107\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] Epoch[151] Batch[0] avg_epoch_loss=2.567582\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.5675820943241927\n",
      "[05/22/2025 03:58:05 INFO 140041726678848] Epoch[151] Batch[5] avg_epoch_loss=2.437797\n",
      "[05/22/2025 03:58:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.4377966571402885\n",
      "[05/22/2025 03:58:05 INFO 140041726678848] Epoch[151] Batch [5]#011Speed: 2214.16 samples/sec#011loss=2.437797\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] Epoch[151] Batch[10] avg_epoch_loss=2.400330\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=2.3553695440823357\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] Epoch[151] Batch [10]#011Speed: 2010.81 samples/sec#011loss=2.355370\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] processed a total of 4603 examples\n",
      "#metrics {\"StartTime\": 1747886284.3983335, \"EndTime\": 1747886286.9595098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2560.8856678009033, \"count\": 1, \"min\": 2560.8856678009033, \"max\": 2560.8856678009033}}}\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1797.3353407184675 records/second\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] #progress_metric: host=algo-1, completed 38.0 % of epochs\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.400329787568492\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:07 INFO 140041726678848] Epoch[152] Batch[0] avg_epoch_loss=2.450338\n",
      "[05/22/2025 03:58:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.4503383169195434\n",
      "[05/22/2025 03:58:08 INFO 140041726678848] Epoch[152] Batch[5] avg_epoch_loss=2.529229\n",
      "[05/22/2025 03:58:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.529229314927269\n",
      "[05/22/2025 03:58:08 INFO 140041726678848] Epoch[152] Batch [5]#011Speed: 2270.72 samples/sec#011loss=2.529229\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] Epoch[152] Batch[10] avg_epoch_loss=2.557858\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=2.5922127840513642\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] Epoch[152] Batch [10]#011Speed: 2056.17 samples/sec#011loss=2.592213\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] processed a total of 4588 examples\n",
      "#metrics {\"StartTime\": 1747886286.9596076, \"EndTime\": 1747886289.4816575, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2521.7843055725098, \"count\": 1, \"min\": 2521.7843055725098, \"max\": 2521.7843055725098}}}\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1819.2825614892286 records/second\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] #progress_metric: host=algo-1, completed 38.25 % of epochs\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.5578581645291303\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] Epoch[153] Batch[0] avg_epoch_loss=2.480253\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.4802526121415647\n",
      "[05/22/2025 03:58:10 INFO 140041726678848] Epoch[153] Batch[5] avg_epoch_loss=2.563698\n",
      "[05/22/2025 03:58:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.563697503421956\n",
      "[05/22/2025 03:58:10 INFO 140041726678848] Epoch[153] Batch [5]#011Speed: 2254.94 samples/sec#011loss=2.563698\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] Epoch[153] Batch[10] avg_epoch_loss=2.595509\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=2.6336824344898386\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] Epoch[153] Batch [10]#011Speed: 1922.22 samples/sec#011loss=2.633682\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] processed a total of 4662 examples\n",
      "#metrics {\"StartTime\": 1747886289.481717, \"EndTime\": 1747886292.0953975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2613.4214401245117, \"count\": 1, \"min\": 2613.4214401245117, \"max\": 2613.4214401245117}}}\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1783.7927587512038 records/second\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 38.5 % of epochs\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.595508835725539\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] Epoch[154] Batch[0] avg_epoch_loss=2.464652\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.4646523524498885\n",
      "[05/22/2025 03:58:13 INFO 140041726678848] Epoch[154] Batch[5] avg_epoch_loss=2.567210\n",
      "[05/22/2025 03:58:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.5672102647086117\n",
      "[05/22/2025 03:58:13 INFO 140041726678848] Epoch[154] Batch [5]#011Speed: 2207.96 samples/sec#011loss=2.567210\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] Epoch[154] Batch[10] avg_epoch_loss=2.555399\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=2.5412254010648665\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] Epoch[154] Batch [10]#011Speed: 2024.77 samples/sec#011loss=2.541225\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] processed a total of 4611 examples\n",
      "#metrics {\"StartTime\": 1747886292.095479, \"EndTime\": 1747886294.6544938, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2558.729410171509, \"count\": 1, \"min\": 2558.729410171509, \"max\": 2558.729410171509}}}\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1802.0034864317724 records/second\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] #progress_metric: host=algo-1, completed 38.75 % of epochs\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.555398963052364\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:15 INFO 140041726678848] Epoch[155] Batch[0] avg_epoch_loss=2.532463\n",
      "[05/22/2025 03:58:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.5324633625939588\n",
      "[05/22/2025 03:58:16 INFO 140041726678848] Epoch[155] Batch[5] avg_epoch_loss=2.494310\n",
      "[05/22/2025 03:58:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.494310363452348\n",
      "[05/22/2025 03:58:16 INFO 140041726678848] Epoch[155] Batch [5]#011Speed: 2252.34 samples/sec#011loss=2.494310\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] Epoch[155] Batch[10] avg_epoch_loss=2.487012\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=2.478252942737333\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] Epoch[155] Batch [10]#011Speed: 1994.78 samples/sec#011loss=2.478253\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] processed a total of 4654 examples\n",
      "#metrics {\"StartTime\": 1747886294.6545558, \"EndTime\": 1747886297.2318747, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2576.9991874694824, \"count\": 1, \"min\": 2576.9991874694824, \"max\": 2576.9991874694824}}}\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1805.9135215297858 records/second\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] #progress_metric: host=algo-1, completed 39.0 % of epochs\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.487011535854614\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] Epoch[156] Batch[0] avg_epoch_loss=2.333759\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.333758721638363\n",
      "[05/22/2025 03:58:18 INFO 140041726678848] Epoch[156] Batch[5] avg_epoch_loss=2.464123\n",
      "[05/22/2025 03:58:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.464123381095722\n",
      "[05/22/2025 03:58:18 INFO 140041726678848] Epoch[156] Batch [5]#011Speed: 2181.08 samples/sec#011loss=2.464123\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] Epoch[156] Batch[10] avg_epoch_loss=2.477163\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=2.49281128201559\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] Epoch[156] Batch [10]#011Speed: 1969.48 samples/sec#011loss=2.492811\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] processed a total of 4557 examples\n",
      "#metrics {\"StartTime\": 1747886297.2319357, \"EndTime\": 1747886299.8302572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2598.0615615844727, \"count\": 1, \"min\": 2598.0615615844727, \"max\": 2598.0615615844727}}}\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1753.94142028428 records/second\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] #progress_metric: host=algo-1, completed 39.25 % of epochs\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.4771633360592986\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:20 INFO 140041726678848] Epoch[157] Batch[0] avg_epoch_loss=2.282409\n",
      "[05/22/2025 03:58:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.2824087164184297\n",
      "[05/22/2025 03:58:21 INFO 140041726678848] Epoch[157] Batch[5] avg_epoch_loss=2.314213\n",
      "[05/22/2025 03:58:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.3142127226084006\n",
      "[05/22/2025 03:58:21 INFO 140041726678848] Epoch[157] Batch [5]#011Speed: 2274.23 samples/sec#011loss=2.314213\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] Epoch[157] Batch[10] avg_epoch_loss=2.338036\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=2.366624454081988\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] Epoch[157] Batch [10]#011Speed: 1946.40 samples/sec#011loss=2.366624\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] processed a total of 4687 examples\n",
      "#metrics {\"StartTime\": 1747886299.8303158, \"EndTime\": 1747886302.406239, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2575.6731033325195, \"count\": 1, \"min\": 2575.6731033325195, \"max\": 2575.6731033325195}}}\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1819.6588745694687 records/second\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] #progress_metric: host=algo-1, completed 39.5 % of epochs\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.3380362369145766\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] Epoch[158] Batch[0] avg_epoch_loss=2.301254\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.3012540345733576\n",
      "[05/22/2025 03:58:23 INFO 140041726678848] Epoch[158] Batch[5] avg_epoch_loss=2.337236\n",
      "[05/22/2025 03:58:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.3372363208750926\n",
      "[05/22/2025 03:58:23 INFO 140041726678848] Epoch[158] Batch [5]#011Speed: 2279.19 samples/sec#011loss=2.337236\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] Epoch[158] Batch[10] avg_epoch_loss=2.438829\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=2.5607402300250555\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] Epoch[158] Batch [10]#011Speed: 1981.07 samples/sec#011loss=2.560740\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] processed a total of 4684 examples\n",
      "#metrics {\"StartTime\": 1747886302.4062974, \"EndTime\": 1747886304.9634526, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2556.90598487854, \"count\": 1, \"min\": 2556.90598487854, \"max\": 2556.90598487854}}}\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1831.8386775932327 records/second\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] #progress_metric: host=algo-1, completed 39.75 % of epochs\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.4388290068523486\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:25 INFO 140041726678848] Epoch[159] Batch[0] avg_epoch_loss=2.285080\n",
      "[05/22/2025 03:58:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.2850798541028676\n",
      "[05/22/2025 03:58:26 INFO 140041726678848] Epoch[159] Batch[5] avg_epoch_loss=2.343099\n",
      "[05/22/2025 03:58:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.3430992755167734\n",
      "[05/22/2025 03:58:26 INFO 140041726678848] Epoch[159] Batch [5]#011Speed: 2276.18 samples/sec#011loss=2.343099\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] Epoch[159] Batch[10] avg_epoch_loss=2.327259\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=2.3082502403344236\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] Epoch[159] Batch [10]#011Speed: 2025.73 samples/sec#011loss=2.308250\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] processed a total of 4652 examples\n",
      "#metrics {\"StartTime\": 1747886304.9635134, \"EndTime\": 1747886307.4868953, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2523.0298042297363, \"count\": 1, \"min\": 2523.0298042297363, \"max\": 2523.0298042297363}}}\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1843.7276338001418 records/second\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] #progress_metric: host=algo-1, completed 40.0 % of epochs\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.327258804979342\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] Epoch[160] Batch[0] avg_epoch_loss=2.298074\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.2980744971464366\n",
      "[05/22/2025 03:58:28 INFO 140041726678848] Epoch[160] Batch[5] avg_epoch_loss=2.414221\n",
      "[05/22/2025 03:58:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.414220593288906\n",
      "[05/22/2025 03:58:28 INFO 140041726678848] Epoch[160] Batch [5]#011Speed: 2304.70 samples/sec#011loss=2.414221\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] Epoch[160] Batch[10] avg_epoch_loss=2.380640\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=2.340343612976754\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] Epoch[160] Batch [10]#011Speed: 2037.44 samples/sec#011loss=2.340344\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] processed a total of 4603 examples\n",
      "#metrics {\"StartTime\": 1747886307.486985, \"EndTime\": 1747886310.002331, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2515.0749683380127, \"count\": 1, \"min\": 2515.0749683380127, \"max\": 2515.0749683380127}}}\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1830.1013315416276 records/second\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 40.25 % of epochs\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.380640147692473\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] Epoch[161] Batch[0] avg_epoch_loss=2.320380\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.320379924136971\n",
      "[05/22/2025 03:58:31 INFO 140041726678848] Epoch[161] Batch[5] avg_epoch_loss=2.396386\n",
      "[05/22/2025 03:58:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.396385640326304\n",
      "[05/22/2025 03:58:31 INFO 140041726678848] Epoch[161] Batch [5]#011Speed: 2228.81 samples/sec#011loss=2.396386\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] Epoch[161] Batch[10] avg_epoch_loss=2.329386\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=2.248985511422954\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] Epoch[161] Batch [10]#011Speed: 2053.88 samples/sec#011loss=2.248986\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] processed a total of 4492 examples\n",
      "#metrics {\"StartTime\": 1747886310.0023904, \"EndTime\": 1747886312.535879, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2533.1883430480957, \"count\": 1, \"min\": 2533.1883430480957, \"max\": 2533.1883430480957}}}\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.1984689035924 records/second\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] #progress_metric: host=algo-1, completed 40.5 % of epochs\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.329385581733872\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] Epoch[162] Batch[0] avg_epoch_loss=2.289526\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.2895260409416758\n",
      "[05/22/2025 03:58:33 INFO 140041726678848] Epoch[162] Batch[5] avg_epoch_loss=2.296795\n",
      "[05/22/2025 03:58:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.296794684621787\n",
      "[05/22/2025 03:58:33 INFO 140041726678848] Epoch[162] Batch [5]#011Speed: 2262.11 samples/sec#011loss=2.296795\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] processed a total of 4458 examples\n",
      "#metrics {\"StartTime\": 1747886312.5359378, \"EndTime\": 1747886314.9081178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2371.882915496826, \"count\": 1, \"min\": 2371.882915496826, \"max\": 2371.882915496826}}}\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1879.4442294323856 records/second\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] #progress_metric: host=algo-1, completed 40.75 % of epochs\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.2968481798745475\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_2a342124-fb1b-41e3-9aa1-3abae1e8db9c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886314.9081817, \"EndTime\": 1747886314.91954, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.00778579711914, \"count\": 1, \"min\": 11.00778579711914, \"max\": 11.00778579711914}}}\n",
      "[05/22/2025 03:58:35 INFO 140041726678848] Epoch[163] Batch[0] avg_epoch_loss=2.264567\n",
      "[05/22/2025 03:58:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.2645672838512665\n",
      "[05/22/2025 03:58:36 INFO 140041726678848] Epoch[163] Batch[5] avg_epoch_loss=2.263344\n",
      "[05/22/2025 03:58:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.2633438166991464\n",
      "[05/22/2025 03:58:36 INFO 140041726678848] Epoch[163] Batch [5]#011Speed: 2264.00 samples/sec#011loss=2.263344\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] Epoch[163] Batch[10] avg_epoch_loss=2.171475\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=2.061232861219376\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] Epoch[163] Batch [10]#011Speed: 2034.03 samples/sec#011loss=2.061233\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] processed a total of 4589 examples\n",
      "#metrics {\"StartTime\": 1747886314.9195852, \"EndTime\": 1747886317.4448187, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2525.1853466033936, \"count\": 1, \"min\": 2525.1853466033936, \"max\": 2525.1853466033936}}}\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1817.2280040068847 records/second\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] #progress_metric: host=algo-1, completed 41.0 % of epochs\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.171475200571978\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_0c747134-0291-4237-805a-d6075a1f67e2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886317.4448788, \"EndTime\": 1747886317.4557412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.581254959106445, \"count\": 1, \"min\": 10.581254959106445, \"max\": 10.581254959106445}}}\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] Epoch[164] Batch[0] avg_epoch_loss=2.216451\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.2164509184907435\n",
      "[05/22/2025 03:58:38 INFO 140041726678848] Epoch[164] Batch[5] avg_epoch_loss=2.362040\n",
      "[05/22/2025 03:58:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.3620404283825165\n",
      "[05/22/2025 03:58:38 INFO 140041726678848] Epoch[164] Batch [5]#011Speed: 2262.37 samples/sec#011loss=2.362040\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] Epoch[164] Batch[10] avg_epoch_loss=2.249069\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=2.1135033962190284\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] Epoch[164] Batch [10]#011Speed: 2073.81 samples/sec#011loss=2.113503\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] processed a total of 4519 examples\n",
      "#metrics {\"StartTime\": 1747886317.455793, \"EndTime\": 1747886319.9663115, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2510.4668140411377, \"count\": 1, \"min\": 2510.4668140411377, \"max\": 2510.4668140411377}}}\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1800.0000357073905 records/second\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] #progress_metric: host=algo-1, completed 41.25 % of epochs\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.2490690501263857\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:40 INFO 140041726678848] Epoch[165] Batch[0] avg_epoch_loss=2.270510\n",
      "[05/22/2025 03:58:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.2705098515364\n",
      "[05/22/2025 03:58:41 INFO 140041726678848] Epoch[165] Batch[5] avg_epoch_loss=2.242770\n",
      "[05/22/2025 03:58:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.2427703019151353\n",
      "[05/22/2025 03:58:41 INFO 140041726678848] Epoch[165] Batch [5]#011Speed: 2209.96 samples/sec#011loss=2.242770\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] Epoch[165] Batch[10] avg_epoch_loss=2.384433\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=2.5544279170726614\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] Epoch[165] Batch [10]#011Speed: 2013.24 samples/sec#011loss=2.554428\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] processed a total of 4544 examples\n",
      "#metrics {\"StartTime\": 1747886319.9663708, \"EndTime\": 1747886322.5261884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2559.5641136169434, \"count\": 1, \"min\": 2559.5641136169434, \"max\": 2559.5641136169434}}}\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1775.2414247522206 records/second\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] #progress_metric: host=algo-1, completed 41.5 % of epochs\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.3844328542594653\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] Epoch[166] Batch[0] avg_epoch_loss=2.283518\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.2835184959632517\n",
      "[05/22/2025 03:58:43 INFO 140041726678848] Epoch[166] Batch[5] avg_epoch_loss=2.238686\n",
      "[05/22/2025 03:58:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.2386856588860664\n",
      "[05/22/2025 03:58:43 INFO 140041726678848] Epoch[166] Batch [5]#011Speed: 2198.77 samples/sec#011loss=2.238686\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] Epoch[166] Batch[10] avg_epoch_loss=2.239009\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=2.2393965757238306\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] Epoch[166] Batch [10]#011Speed: 1999.94 samples/sec#011loss=2.239397\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] processed a total of 4532 examples\n",
      "#metrics {\"StartTime\": 1747886322.5262465, \"EndTime\": 1747886325.0980093, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2571.5060234069824, \"count\": 1, \"min\": 2571.5060234069824, \"max\": 2571.5060234069824}}}\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1762.333028587428 records/second\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] #progress_metric: host=algo-1, completed 41.75 % of epochs\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.239008802903232\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] Epoch[167] Batch[0] avg_epoch_loss=2.234433\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=2.2344331805052895\n",
      "[05/22/2025 03:58:46 INFO 140041726678848] Epoch[167] Batch[5] avg_epoch_loss=2.361281\n",
      "[05/22/2025 03:58:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.361280502172072\n",
      "[05/22/2025 03:58:46 INFO 140041726678848] Epoch[167] Batch [5]#011Speed: 2249.98 samples/sec#011loss=2.361281\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] Epoch[167] Batch[10] avg_epoch_loss=2.447581\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=2.551142621624443\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] Epoch[167] Batch [10]#011Speed: 1940.09 samples/sec#011loss=2.551143\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] processed a total of 4647 examples\n",
      "#metrics {\"StartTime\": 1747886325.0980668, \"EndTime\": 1747886327.6963975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2598.102569580078, \"count\": 1, \"min\": 2598.102569580078, \"max\": 2598.102569580078}}}\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.5548861922264 records/second\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] #progress_metric: host=algo-1, completed 42.0 % of epochs\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.4475814655595136\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:48 INFO 140041726678848] Epoch[168] Batch[0] avg_epoch_loss=2.229743\n",
      "[05/22/2025 03:58:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.229742581169961\n",
      "[05/22/2025 03:58:49 INFO 140041726678848] Epoch[168] Batch[5] avg_epoch_loss=2.246868\n",
      "[05/22/2025 03:58:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.2468677455616066\n",
      "[05/22/2025 03:58:49 INFO 140041726678848] Epoch[168] Batch [5]#011Speed: 2291.37 samples/sec#011loss=2.246868\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] Epoch[168] Batch[10] avg_epoch_loss=2.168423\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=2.074290143461164\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] Epoch[168] Batch [10]#011Speed: 1982.24 samples/sec#011loss=2.074290\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] processed a total of 4673 examples\n",
      "#metrics {\"StartTime\": 1747886327.6964555, \"EndTime\": 1747886330.245658, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.898696899414, \"count\": 1, \"min\": 2548.898696899414, \"max\": 2548.898696899414}}}\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1833.2785617804668 records/second\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] #progress_metric: host=algo-1, completed 42.25 % of epochs\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.1684233809704963\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_778e7b9b-cc95-4fcb-a964-75b27fc30727-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886330.2457159, \"EndTime\": 1747886330.2566876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.700702667236328, \"count\": 1, \"min\": 10.700702667236328, \"max\": 10.700702667236328}}}\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] Epoch[169] Batch[0] avg_epoch_loss=2.231558\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.2315584110523385\n",
      "[05/22/2025 03:58:51 INFO 140041726678848] Epoch[169] Batch[5] avg_epoch_loss=2.244715\n",
      "[05/22/2025 03:58:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.244714500466894\n",
      "[05/22/2025 03:58:51 INFO 140041726678848] Epoch[169] Batch [5]#011Speed: 1914.27 samples/sec#011loss=2.244715\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] Epoch[169] Batch[10] avg_epoch_loss=2.302724\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.3723364747181237\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] Epoch[169] Batch [10]#011Speed: 1847.37 samples/sec#011loss=2.372336\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] processed a total of 4573 examples\n",
      "#metrics {\"StartTime\": 1747886330.2567382, \"EndTime\": 1747886333.12975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2872.9591369628906, \"count\": 1, \"min\": 2872.9591369628906, \"max\": 2872.9591369628906}}}\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1591.6888180274896 records/second\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] #progress_metric: host=algo-1, completed 42.5 % of epochs\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.3027244887629075\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] Epoch[170] Batch[0] avg_epoch_loss=2.339475\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.3394748203472995\n",
      "[05/22/2025 03:58:54 INFO 140041726678848] Epoch[170] Batch[5] avg_epoch_loss=2.329258\n",
      "[05/22/2025 03:58:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.3292576620644256\n",
      "[05/22/2025 03:58:54 INFO 140041726678848] Epoch[170] Batch [5]#011Speed: 2213.10 samples/sec#011loss=2.329258\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] Epoch[170] Batch[10] avg_epoch_loss=2.495568\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=2.695140949070852\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] Epoch[170] Batch [10]#011Speed: 1979.30 samples/sec#011loss=2.695141\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] processed a total of 4515 examples\n",
      "#metrics {\"StartTime\": 1747886333.129811, \"EndTime\": 1747886335.7121813, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2582.1142196655273, \"count\": 1, \"min\": 2582.1142196655273, \"max\": 2582.1142196655273}}}\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1748.5062446972909 records/second\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] #progress_metric: host=algo-1, completed 42.75 % of epochs\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.4955682470673466\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:56 INFO 140041726678848] Epoch[171] Batch[0] avg_epoch_loss=2.556953\n",
      "[05/22/2025 03:58:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.556953277248051\n",
      "[05/22/2025 03:58:57 INFO 140041726678848] Epoch[171] Batch[5] avg_epoch_loss=2.687788\n",
      "[05/22/2025 03:58:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.6877883197470074\n",
      "[05/22/2025 03:58:57 INFO 140041726678848] Epoch[171] Batch [5]#011Speed: 2171.50 samples/sec#011loss=2.687788\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] Epoch[171] Batch[10] avg_epoch_loss=2.730209\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=2.7811144448601057\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] Epoch[171] Batch [10]#011Speed: 2000.24 samples/sec#011loss=2.781114\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] processed a total of 4604 examples\n",
      "#metrics {\"StartTime\": 1747886335.7122428, \"EndTime\": 1747886338.3041625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2591.6671752929688, \"count\": 1, \"min\": 2591.6671752929688, \"max\": 2591.6671752929688}}}\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1776.4040064397554 records/second\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] #progress_metric: host=algo-1, completed 43.0 % of epochs\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.7302092857075064\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] Epoch[172] Batch[0] avg_epoch_loss=2.470966\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.4709660247598833\n",
      "[05/22/2025 03:58:59 INFO 140041726678848] Epoch[172] Batch[5] avg_epoch_loss=2.506643\n",
      "[05/22/2025 03:58:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.5066425915373283\n",
      "[05/22/2025 03:58:59 INFO 140041726678848] Epoch[172] Batch [5]#011Speed: 2243.85 samples/sec#011loss=2.506643\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] Epoch[172] Batch[10] avg_epoch_loss=2.555645\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=2.614446817580735\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] Epoch[172] Batch [10]#011Speed: 1998.42 samples/sec#011loss=2.614447\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] processed a total of 4556 examples\n",
      "#metrics {\"StartTime\": 1747886338.304222, \"EndTime\": 1747886340.863406, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2558.9303970336914, \"count\": 1, \"min\": 2558.9303970336914, \"max\": 2558.9303970336914}}}\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1780.3708426217966 records/second\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] #progress_metric: host=algo-1, completed 43.25 % of epochs\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.5556445124661495\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:01 INFO 140041726678848] Epoch[173] Batch[0] avg_epoch_loss=2.372348\n",
      "[05/22/2025 03:59:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.3723476214504453\n",
      "[05/22/2025 03:59:02 INFO 140041726678848] Epoch[173] Batch[5] avg_epoch_loss=2.366395\n",
      "[05/22/2025 03:59:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.3663948132713903\n",
      "[05/22/2025 03:59:02 INFO 140041726678848] Epoch[173] Batch [5]#011Speed: 2183.44 samples/sec#011loss=2.366395\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] Epoch[173] Batch[10] avg_epoch_loss=2.372409\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=2.37962496955039\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] Epoch[173] Batch [10]#011Speed: 1997.76 samples/sec#011loss=2.379625\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] processed a total of 4637 examples\n",
      "#metrics {\"StartTime\": 1747886340.8634653, \"EndTime\": 1747886343.459238, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2595.5135822296143, \"count\": 1, \"min\": 2595.5135822296143, \"max\": 2595.5135822296143}}}\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.4842399546824 records/second\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] #progress_metric: host=algo-1, completed 43.5 % of epochs\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.3724085206709353\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] Epoch[174] Batch[0] avg_epoch_loss=2.285979\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.285978933219655\n",
      "[05/22/2025 03:59:04 INFO 140041726678848] Epoch[174] Batch[5] avg_epoch_loss=2.402644\n",
      "[05/22/2025 03:59:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.402643828190249\n",
      "[05/22/2025 03:59:04 INFO 140041726678848] Epoch[174] Batch [5]#011Speed: 2289.26 samples/sec#011loss=2.402644\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] Epoch[174] Batch[10] avg_epoch_loss=2.407380\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=2.41306329060238\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] Epoch[174] Batch [10]#011Speed: 1883.66 samples/sec#011loss=2.413063\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] processed a total of 4639 examples\n",
      "#metrics {\"StartTime\": 1747886343.459297, \"EndTime\": 1747886346.057465, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2597.874402999878, \"count\": 1, \"min\": 2597.874402999878, \"max\": 2597.874402999878}}}\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1785.6308234464937 records/second\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] #progress_metric: host=algo-1, completed 43.75 % of epochs\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.4073799474684905\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] Epoch[175] Batch[0] avg_epoch_loss=2.222388\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.222388320616996\n",
      "[05/22/2025 03:59:07 INFO 140041726678848] Epoch[175] Batch[5] avg_epoch_loss=2.250364\n",
      "[05/22/2025 03:59:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.2503640133093796\n",
      "[05/22/2025 03:59:07 INFO 140041726678848] Epoch[175] Batch [5]#011Speed: 2201.42 samples/sec#011loss=2.250364\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] Epoch[175] Batch[10] avg_epoch_loss=2.242074\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=2.2321258884761277\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] Epoch[175] Batch [10]#011Speed: 2022.06 samples/sec#011loss=2.232126\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] processed a total of 4560 examples\n",
      "#metrics {\"StartTime\": 1747886346.0575244, \"EndTime\": 1747886348.6248124, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2567.04044342041, \"count\": 1, \"min\": 2567.04044342041, \"max\": 2567.04044342041}}}\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1776.3043076481283 records/second\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] #progress_metric: host=algo-1, completed 44.0 % of epochs\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.2420739565669923\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:09 INFO 140041726678848] Epoch[176] Batch[0] avg_epoch_loss=2.277927\n",
      "[05/22/2025 03:59:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.2779270503462556\n",
      "[05/22/2025 03:59:10 INFO 140041726678848] Epoch[176] Batch[5] avg_epoch_loss=2.283462\n",
      "[05/22/2025 03:59:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.2834620146549622\n",
      "[05/22/2025 03:59:10 INFO 140041726678848] Epoch[176] Batch [5]#011Speed: 2278.15 samples/sec#011loss=2.283462\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] Epoch[176] Batch[10] avg_epoch_loss=2.170469\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.0348773098204345\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] Epoch[176] Batch [10]#011Speed: 1957.38 samples/sec#011loss=2.034877\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] processed a total of 4578 examples\n",
      "#metrics {\"StartTime\": 1747886348.6248717, \"EndTime\": 1747886351.1881056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2562.983274459839, \"count\": 1, \"min\": 2562.983274459839, \"max\": 2562.983274459839}}}\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.1389049995548 records/second\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] #progress_metric: host=algo-1, completed 44.25 % of epochs\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.170468967002904\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] Epoch[177] Batch[0] avg_epoch_loss=2.244805\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.244804535251949\n",
      "[05/22/2025 03:59:12 INFO 140041726678848] Epoch[177] Batch[5] avg_epoch_loss=2.233703\n",
      "[05/22/2025 03:59:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.23370306953821\n",
      "[05/22/2025 03:59:12 INFO 140041726678848] Epoch[177] Batch [5]#011Speed: 2269.97 samples/sec#011loss=2.233703\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] Epoch[177] Batch[10] avg_epoch_loss=2.186035\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=2.1288337690527563\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] Epoch[177] Batch [10]#011Speed: 1969.83 samples/sec#011loss=2.128834\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] processed a total of 4597 examples\n",
      "#metrics {\"StartTime\": 1747886351.188164, \"EndTime\": 1747886353.7476494, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2559.2312812805176, \"count\": 1, \"min\": 2559.2312812805176, \"max\": 2559.2312812805176}}}\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.180254329798 records/second\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] #progress_metric: host=algo-1, completed 44.5 % of epochs\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.1860352056811854\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:14 INFO 140041726678848] Epoch[178] Batch[0] avg_epoch_loss=2.234104\n",
      "[05/22/2025 03:59:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.2341040800302756\n",
      "[05/22/2025 03:59:15 INFO 140041726678848] Epoch[178] Batch[5] avg_epoch_loss=2.229940\n",
      "[05/22/2025 03:59:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.2299396200541133\n",
      "[05/22/2025 03:59:15 INFO 140041726678848] Epoch[178] Batch [5]#011Speed: 2246.61 samples/sec#011loss=2.229940\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] Epoch[178] Batch[10] avg_epoch_loss=2.213441\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=2.1936434263641424\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] Epoch[178] Batch [10]#011Speed: 2039.32 samples/sec#011loss=2.193643\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] processed a total of 4559 examples\n",
      "#metrics {\"StartTime\": 1747886353.7477086, \"EndTime\": 1747886356.282644, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.627914428711, \"count\": 1, \"min\": 2534.627914428711, \"max\": 2534.627914428711}}}\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1798.622655677182 records/second\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] #progress_metric: host=algo-1, completed 44.75 % of epochs\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.2134413501950356\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] Epoch[179] Batch[0] avg_epoch_loss=2.545320\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.5453204386483854\n",
      "[05/22/2025 03:59:17 INFO 140041726678848] Epoch[179] Batch[5] avg_epoch_loss=2.455989\n",
      "[05/22/2025 03:59:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.4559891664636693\n",
      "[05/22/2025 03:59:17 INFO 140041726678848] Epoch[179] Batch [5]#011Speed: 2256.23 samples/sec#011loss=2.455989\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] Epoch[179] Batch[10] avg_epoch_loss=2.366473\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=2.2590531313074194\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] Epoch[179] Batch [10]#011Speed: 2022.23 samples/sec#011loss=2.259053\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] processed a total of 4566 examples\n",
      "#metrics {\"StartTime\": 1747886356.2827027, \"EndTime\": 1747886358.8360631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2553.0338287353516, \"count\": 1, \"min\": 2553.0338287353516, \"max\": 2553.0338287353516}}}\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.384281276754 records/second\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] #progress_metric: host=algo-1, completed 45.0 % of epochs\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.366472786847192\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:19 INFO 140041726678848] Epoch[180] Batch[0] avg_epoch_loss=2.372282\n",
      "[05/22/2025 03:59:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.3722815566710747\n",
      "[05/22/2025 03:59:20 INFO 140041726678848] Epoch[180] Batch[5] avg_epoch_loss=2.339374\n",
      "[05/22/2025 03:59:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.339374250540843\n",
      "[05/22/2025 03:59:20 INFO 140041726678848] Epoch[180] Batch [5]#011Speed: 2299.24 samples/sec#011loss=2.339374\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] Epoch[180] Batch[10] avg_epoch_loss=2.441980\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=2.565106649759883\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] Epoch[180] Batch [10]#011Speed: 1974.37 samples/sec#011loss=2.565107\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] processed a total of 4675 examples\n",
      "#metrics {\"StartTime\": 1747886358.8361342, \"EndTime\": 1747886361.382065, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2545.5691814422607, \"count\": 1, \"min\": 2545.5691814422607, \"max\": 2545.5691814422607}}}\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1836.4559767933602 records/second\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] #progress_metric: host=algo-1, completed 45.25 % of epochs\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.4419798865494977\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] Epoch[181] Batch[0] avg_epoch_loss=2.280211\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.2802113148576697\n",
      "[05/22/2025 03:59:22 INFO 140041726678848] Epoch[181] Batch[5] avg_epoch_loss=2.293684\n",
      "[05/22/2025 03:59:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.2936840892811574\n",
      "[05/22/2025 03:59:22 INFO 140041726678848] Epoch[181] Batch [5]#011Speed: 2258.00 samples/sec#011loss=2.293684\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] Epoch[181] Batch[10] avg_epoch_loss=2.310346\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=2.3303398557123467\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] Epoch[181] Batch [10]#011Speed: 2003.03 samples/sec#011loss=2.330340\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] processed a total of 4611 examples\n",
      "#metrics {\"StartTime\": 1747886361.3821287, \"EndTime\": 1747886363.9253066, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.8404808044434, \"count\": 1, \"min\": 2542.8404808044434, \"max\": 2542.8404808044434}}}\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1813.26528384259 records/second\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 45.5 % of epochs\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.3103458012953344\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:24 INFO 140041726678848] Epoch[182] Batch[0] avg_epoch_loss=2.236033\n",
      "[05/22/2025 03:59:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.2360334162722717\n",
      "[05/22/2025 03:59:25 INFO 140041726678848] Epoch[182] Batch[5] avg_epoch_loss=2.378952\n",
      "[05/22/2025 03:59:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.3789519244153676\n",
      "[05/22/2025 03:59:25 INFO 140041726678848] Epoch[182] Batch [5]#011Speed: 2280.04 samples/sec#011loss=2.378952\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] Epoch[182] Batch[10] avg_epoch_loss=2.363945\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=2.345936744197174\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] Epoch[182] Batch [10]#011Speed: 1956.23 samples/sec#011loss=2.345937\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] processed a total of 4570 examples\n",
      "#metrics {\"StartTime\": 1747886363.9253645, \"EndTime\": 1747886366.487058, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2561.4497661590576, \"count\": 1, \"min\": 2561.4497661590576, \"max\": 2561.4497661590576}}}\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1784.0840866387916 records/second\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] #progress_metric: host=algo-1, completed 45.75 % of epochs\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.363945024316189\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] Epoch[183] Batch[0] avg_epoch_loss=2.172942\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.1729415519731345\n",
      "[05/22/2025 03:59:27 INFO 140041726678848] Epoch[183] Batch[5] avg_epoch_loss=2.342495\n",
      "[05/22/2025 03:59:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.342494837159834\n",
      "[05/22/2025 03:59:27 INFO 140041726678848] Epoch[183] Batch [5]#011Speed: 2244.87 samples/sec#011loss=2.342495\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] Epoch[183] Batch[10] avg_epoch_loss=2.423071\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=2.519762395166342\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] Epoch[183] Batch [10]#011Speed: 1948.45 samples/sec#011loss=2.519762\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] processed a total of 4718 examples\n",
      "#metrics {\"StartTime\": 1747886366.4871192, \"EndTime\": 1747886369.0640068, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2576.5748023986816, \"count\": 1, \"min\": 2576.5748023986816, \"max\": 2576.5748023986816}}}\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1831.0494422573454 records/second\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] #progress_metric: host=algo-1, completed 46.0 % of epochs\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.423070999890065\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] Epoch[184] Batch[0] avg_epoch_loss=2.293916\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.293915678504315\n",
      "[05/22/2025 03:59:30 INFO 140041726678848] Epoch[184] Batch[5] avg_epoch_loss=2.269663\n",
      "[05/22/2025 03:59:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.2696630850312616\n",
      "[05/22/2025 03:59:30 INFO 140041726678848] Epoch[184] Batch [5]#011Speed: 2294.24 samples/sec#011loss=2.269663\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] Epoch[184] Batch[10] avg_epoch_loss=2.376049\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=2.503711861863168\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] Epoch[184] Batch [10]#011Speed: 2028.17 samples/sec#011loss=2.503712\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] processed a total of 4593 examples\n",
      "#metrics {\"StartTime\": 1747886369.0640678, \"EndTime\": 1747886371.5775938, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2513.227939605713, \"count\": 1, \"min\": 2513.227939605713, \"max\": 2513.227939605713}}}\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1827.4671119372133 records/second\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] #progress_metric: host=algo-1, completed 46.25 % of epochs\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.376048892682128\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:32 INFO 140041726678848] Epoch[185] Batch[0] avg_epoch_loss=2.201363\n",
      "[05/22/2025 03:59:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.201362592871311\n",
      "[05/22/2025 03:59:32 INFO 140041726678848] Epoch[185] Batch[5] avg_epoch_loss=2.284149\n",
      "[05/22/2025 03:59:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.284148716802675\n",
      "[05/22/2025 03:59:32 INFO 140041726678848] Epoch[185] Batch [5]#011Speed: 2269.11 samples/sec#011loss=2.284149\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] Epoch[185] Batch[10] avg_epoch_loss=2.309568\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=2.3400710074036053\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] Epoch[185] Batch [10]#011Speed: 2035.69 samples/sec#011loss=2.340071\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] processed a total of 4571 examples\n",
      "#metrics {\"StartTime\": 1747886371.577653, \"EndTime\": 1747886374.1022065, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2524.296283721924, \"count\": 1, \"min\": 2524.296283721924, \"max\": 2524.296283721924}}}\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.7380785750863 records/second\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] #progress_metric: host=algo-1, completed 46.5 % of epochs\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.309567939803098\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] Epoch[186] Batch[0] avg_epoch_loss=2.269843\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.2698434944407713\n",
      "[05/22/2025 03:59:35 INFO 140041726678848] Epoch[186] Batch[5] avg_epoch_loss=2.350050\n",
      "[05/22/2025 03:59:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.350049965454192\n",
      "[05/22/2025 03:59:35 INFO 140041726678848] Epoch[186] Batch [5]#011Speed: 2284.14 samples/sec#011loss=2.350050\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] Epoch[186] Batch[10] avg_epoch_loss=2.208368\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=2.038350223804635\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] Epoch[186] Batch [10]#011Speed: 2019.31 samples/sec#011loss=2.038350\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] processed a total of 4517 examples\n",
      "#metrics {\"StartTime\": 1747886374.102266, \"EndTime\": 1747886376.631215, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2528.6638736724854, \"count\": 1, \"min\": 2528.6638736724854, \"max\": 2528.6638736724854}}}\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.257904630124 records/second\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 46.75 % of epochs\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.2083682647043936\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:37 INFO 140041726678848] Epoch[187] Batch[0] avg_epoch_loss=2.324329\n",
      "[05/22/2025 03:59:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.324329401708658\n",
      "[05/22/2025 03:59:38 INFO 140041726678848] Epoch[187] Batch[5] avg_epoch_loss=2.275759\n",
      "[05/22/2025 03:59:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.2757586484143\n",
      "[05/22/2025 03:59:38 INFO 140041726678848] Epoch[187] Batch [5]#011Speed: 2296.70 samples/sec#011loss=2.275759\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] Epoch[187] Batch[10] avg_epoch_loss=2.295521\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=2.3192351547275196\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] Epoch[187] Batch [10]#011Speed: 1994.37 samples/sec#011loss=2.319235\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] processed a total of 4707 examples\n",
      "#metrics {\"StartTime\": 1747886376.631274, \"EndTime\": 1747886379.1610084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2529.4506549835205, \"count\": 1, \"min\": 2529.4506549835205, \"max\": 2529.4506549835205}}}\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1860.817152410724 records/second\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] #progress_metric: host=algo-1, completed 47.0 % of epochs\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.2955206967384907\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] Epoch[188] Batch[0] avg_epoch_loss=2.287865\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.2878646340826836\n",
      "[05/22/2025 03:59:40 INFO 140041726678848] Epoch[188] Batch[5] avg_epoch_loss=2.251654\n",
      "[05/22/2025 03:59:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.251654360855431\n",
      "[05/22/2025 03:59:40 INFO 140041726678848] Epoch[188] Batch [5]#011Speed: 2230.87 samples/sec#011loss=2.251654\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] Epoch[188] Batch[10] avg_epoch_loss=2.367824\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=2.507227269365952\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] Epoch[188] Batch [10]#011Speed: 2032.65 samples/sec#011loss=2.507227\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] processed a total of 4518 examples\n",
      "#metrics {\"StartTime\": 1747886379.161063, \"EndTime\": 1747886381.7015934, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2540.1759147644043, \"count\": 1, \"min\": 2540.1759147644043, \"max\": 2540.1759147644043}}}\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1778.5547082150008 records/second\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 47.25 % of epochs\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.36782386472385\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:42 INFO 140041726678848] Epoch[189] Batch[0] avg_epoch_loss=2.371622\n",
      "[05/22/2025 03:59:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.3716217244919267\n",
      "[05/22/2025 03:59:43 INFO 140041726678848] Epoch[189] Batch[5] avg_epoch_loss=2.310413\n",
      "[05/22/2025 03:59:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.310412525157178\n",
      "[05/22/2025 03:59:43 INFO 140041726678848] Epoch[189] Batch [5]#011Speed: 2302.14 samples/sec#011loss=2.310413\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] Epoch[189] Batch[10] avg_epoch_loss=2.365160\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=2.4308564387875835\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] Epoch[189] Batch [10]#011Speed: 2037.14 samples/sec#011loss=2.430856\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] processed a total of 4557 examples\n",
      "#metrics {\"StartTime\": 1747886381.701653, \"EndTime\": 1747886384.2382195, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2536.3128185272217, \"count\": 1, \"min\": 2536.3128185272217, \"max\": 2536.3128185272217}}}\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.6408518998992 records/second\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] #progress_metric: host=algo-1, completed 47.5 % of epochs\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.365159758625544\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] Epoch[190] Batch[0] avg_epoch_loss=2.187367\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.187366647019418\n",
      "[05/22/2025 03:59:45 INFO 140041726678848] Epoch[190] Batch[5] avg_epoch_loss=2.318740\n",
      "[05/22/2025 03:59:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.3187395193529023\n",
      "[05/22/2025 03:59:45 INFO 140041726678848] Epoch[190] Batch [5]#011Speed: 2270.43 samples/sec#011loss=2.318740\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] Epoch[190] Batch[10] avg_epoch_loss=2.362071\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=2.414069514285217\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] Epoch[190] Batch [10]#011Speed: 2020.33 samples/sec#011loss=2.414070\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] processed a total of 4621 examples\n",
      "#metrics {\"StartTime\": 1747886384.238278, \"EndTime\": 1747886386.7630951, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2524.4200229644775, \"count\": 1, \"min\": 2524.4200229644775, \"max\": 2524.4200229644775}}}\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1830.454640102148 records/second\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 47.75 % of epochs\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.362071335231227\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:47 INFO 140041726678848] Epoch[191] Batch[0] avg_epoch_loss=2.277672\n",
      "[05/22/2025 03:59:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.277672034860454\n",
      "[05/22/2025 03:59:48 INFO 140041726678848] Epoch[191] Batch[5] avg_epoch_loss=2.265384\n",
      "[05/22/2025 03:59:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.2653839632415207\n",
      "[05/22/2025 03:59:48 INFO 140041726678848] Epoch[191] Batch [5]#011Speed: 2202.02 samples/sec#011loss=2.265384\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] Epoch[191] Batch[10] avg_epoch_loss=2.300354\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=2.3423182973882932\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] Epoch[191] Batch [10]#011Speed: 2016.04 samples/sec#011loss=2.342318\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] processed a total of 4561 examples\n",
      "#metrics {\"StartTime\": 1747886386.7631555, \"EndTime\": 1747886389.3347597, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2571.2385177612305, \"count\": 1, \"min\": 2571.2385177612305, \"max\": 2571.2385177612305}}}\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.7913201686092 records/second\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 48.0 % of epochs\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.3003541151264173\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] Epoch[192] Batch[0] avg_epoch_loss=2.517767\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.517767075706431\n",
      "[05/22/2025 03:59:50 INFO 140041726678848] Epoch[192] Batch[5] avg_epoch_loss=2.413924\n",
      "[05/22/2025 03:59:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.4139241173962973\n",
      "[05/22/2025 03:59:50 INFO 140041726678848] Epoch[192] Batch [5]#011Speed: 2271.50 samples/sec#011loss=2.413924\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] Epoch[192] Batch[10] avg_epoch_loss=2.307745\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=2.180328980851545\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] Epoch[192] Batch [10]#011Speed: 1980.77 samples/sec#011loss=2.180329\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] processed a total of 4600 examples\n",
      "#metrics {\"StartTime\": 1747886389.3348207, \"EndTime\": 1747886391.8849556, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2549.8735904693604, \"count\": 1, \"min\": 2549.8735904693604, \"max\": 2549.8735904693604}}}\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1803.9480827031043 records/second\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 48.25 % of epochs\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.3077445098759553\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:52 INFO 140041726678848] Epoch[193] Batch[0] avg_epoch_loss=2.406749\n",
      "[05/22/2025 03:59:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.4067491561108016\n",
      "[05/22/2025 03:59:53 INFO 140041726678848] Epoch[193] Batch[5] avg_epoch_loss=2.291080\n",
      "[05/22/2025 03:59:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.2910802397979304\n",
      "[05/22/2025 03:59:53 INFO 140041726678848] Epoch[193] Batch [5]#011Speed: 2280.95 samples/sec#011loss=2.291080\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] Epoch[193] Batch[10] avg_epoch_loss=2.363149\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=2.44963229376914\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] Epoch[193] Batch [10]#011Speed: 1985.95 samples/sec#011loss=2.449632\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] processed a total of 4610 examples\n",
      "#metrics {\"StartTime\": 1747886391.885017, \"EndTime\": 1747886394.4333308, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.0029582977295, \"count\": 1, \"min\": 2548.0029582977295, \"max\": 2548.0029582977295}}}\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1809.198275662028 records/second\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 48.5 % of epochs\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.3631493552393894\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] Epoch[194] Batch[0] avg_epoch_loss=2.276865\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.2768653920604818\n",
      "[05/22/2025 03:59:55 INFO 140041726678848] Epoch[194] Batch[5] avg_epoch_loss=2.208675\n",
      "[05/22/2025 03:59:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.2086747813065495\n",
      "[05/22/2025 03:59:55 INFO 140041726678848] Epoch[194] Batch [5]#011Speed: 2259.18 samples/sec#011loss=2.208675\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] Epoch[194] Batch[10] avg_epoch_loss=2.285407\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=2.3774866184837835\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] Epoch[194] Batch [10]#011Speed: 1963.96 samples/sec#011loss=2.377487\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] processed a total of 4657 examples\n",
      "#metrics {\"StartTime\": 1747886394.4333882, \"EndTime\": 1747886396.9981093, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2564.4659996032715, \"count\": 1, \"min\": 2564.4659996032715, \"max\": 2564.4659996032715}}}\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1815.9101389668779 records/second\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 48.75 % of epochs\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.2854074345689286\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:57 INFO 140041726678848] Epoch[195] Batch[0] avg_epoch_loss=2.260371\n",
      "[05/22/2025 03:59:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.2603709469393793\n",
      "[05/22/2025 03:59:58 INFO 140041726678848] Epoch[195] Batch[5] avg_epoch_loss=2.224154\n",
      "[05/22/2025 03:59:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.2241542620754453\n",
      "[05/22/2025 03:59:58 INFO 140041726678848] Epoch[195] Batch [5]#011Speed: 2256.98 samples/sec#011loss=2.224154\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] Epoch[195] Batch[10] avg_epoch_loss=2.260843\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=2.3048688111167177\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] Epoch[195] Batch [10]#011Speed: 2057.90 samples/sec#011loss=2.304869\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] processed a total of 4495 examples\n",
      "#metrics {\"StartTime\": 1747886396.9981678, \"EndTime\": 1747886399.5207427, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.3217010498047, \"count\": 1, \"min\": 2522.3217010498047, \"max\": 2522.3217010498047}}}\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1782.027158116352 records/second\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 49.0 % of epochs\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.260842693457842\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] Epoch[196] Batch[0] avg_epoch_loss=2.168927\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.168927097108157\n",
      "[05/22/2025 04:00:01 INFO 140041726678848] Epoch[196] Batch[5] avg_epoch_loss=2.175385\n",
      "[05/22/2025 04:00:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.175384657420135\n",
      "[05/22/2025 04:00:01 INFO 140041726678848] Epoch[196] Batch [5]#011Speed: 2163.01 samples/sec#011loss=2.175385\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] Epoch[196] Batch[10] avg_epoch_loss=2.220020\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.273583495006264\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] Epoch[196] Batch [10]#011Speed: 1875.75 samples/sec#011loss=2.273583\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] processed a total of 4598 examples\n",
      "#metrics {\"StartTime\": 1747886399.5208018, \"EndTime\": 1747886402.2153697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2694.283962249756, \"count\": 1, \"min\": 2694.283962249756, \"max\": 2694.283962249756}}}\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1706.4851154921223 records/second\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 49.25 % of epochs\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.220020492686557\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] Epoch[197] Batch[0] avg_epoch_loss=2.188937\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.1889368409834353\n",
      "[05/22/2025 04:00:03 INFO 140041726678848] Epoch[197] Batch[5] avg_epoch_loss=2.321206\n",
      "[05/22/2025 04:00:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.3212061869983063\n",
      "[05/22/2025 04:00:03 INFO 140041726678848] Epoch[197] Batch [5]#011Speed: 2290.00 samples/sec#011loss=2.321206\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] Epoch[197] Batch[10] avg_epoch_loss=2.388140\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=2.4684603208953924\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] Epoch[197] Batch [10]#011Speed: 2023.85 samples/sec#011loss=2.468460\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] processed a total of 4595 examples\n",
      "#metrics {\"StartTime\": 1747886402.215484, \"EndTime\": 1747886404.751713, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2535.9318256378174, \"count\": 1, \"min\": 2535.9318256378174, \"max\": 2535.9318256378174}}}\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1811.8972651697345 records/second\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 49.5 % of epochs\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.3881398842242545\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:05 INFO 140041726678848] Epoch[198] Batch[0] avg_epoch_loss=2.200172\n",
      "[05/22/2025 04:00:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.200171659677756\n",
      "[05/22/2025 04:00:06 INFO 140041726678848] Epoch[198] Batch[5] avg_epoch_loss=2.304919\n",
      "[05/22/2025 04:00:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.304919270470838\n",
      "[05/22/2025 04:00:06 INFO 140041726678848] Epoch[198] Batch [5]#011Speed: 2230.90 samples/sec#011loss=2.304919\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] Epoch[198] Batch[10] avg_epoch_loss=2.265377\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.217925794299833\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] Epoch[198] Batch [10]#011Speed: 1926.31 samples/sec#011loss=2.217926\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] processed a total of 4617 examples\n",
      "#metrics {\"StartTime\": 1747886404.751771, \"EndTime\": 1747886407.3575091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2605.487108230591, \"count\": 1, \"min\": 2605.487108230591, \"max\": 2605.487108230591}}}\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1771.9691747608128 records/second\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 49.75 % of epochs\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.265376781302199\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] Epoch[199] Batch[0] avg_epoch_loss=2.155877\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.1558765844672187\n",
      "[05/22/2025 04:00:08 INFO 140041726678848] Epoch[199] Batch[5] avg_epoch_loss=2.294075\n",
      "[05/22/2025 04:00:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.2940747233435412\n",
      "[05/22/2025 04:00:08 INFO 140041726678848] Epoch[199] Batch [5]#011Speed: 2267.54 samples/sec#011loss=2.294075\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] Epoch[199] Batch[10] avg_epoch_loss=2.258406\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=2.2156038212085885\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] Epoch[199] Batch [10]#011Speed: 1977.09 samples/sec#011loss=2.215604\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] processed a total of 4733 examples\n",
      "#metrics {\"StartTime\": 1747886407.3575685, \"EndTime\": 1747886409.9153626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2557.5242042541504, \"count\": 1, \"min\": 2557.5242042541504, \"max\": 2557.5242042541504}}}\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1850.538688955565 records/second\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] #progress_metric: host=algo-1, completed 50.0 % of epochs\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.2584061314640174\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:10 INFO 140041726678848] Epoch[200] Batch[0] avg_epoch_loss=2.123245\n",
      "[05/22/2025 04:00:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.1232445255950725\n",
      "[05/22/2025 04:00:11 INFO 140041726678848] Epoch[200] Batch[5] avg_epoch_loss=2.149097\n",
      "[05/22/2025 04:00:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.149096924371868\n",
      "[05/22/2025 04:00:11 INFO 140041726678848] Epoch[200] Batch [5]#011Speed: 2244.03 samples/sec#011loss=2.149097\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] Epoch[200] Batch[10] avg_epoch_loss=2.389941\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=2.6789533925215756\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] Epoch[200] Batch [10]#011Speed: 1961.77 samples/sec#011loss=2.678953\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] processed a total of 4585 examples\n",
      "#metrics {\"StartTime\": 1747886409.9154255, \"EndTime\": 1747886412.493204, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2577.517509460449, \"count\": 1, \"min\": 2577.517509460449, \"max\": 2577.517509460449}}}\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1778.7849856727905 records/second\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 50.25 % of epochs\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.3899407735308262\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] Epoch[201] Batch[0] avg_epoch_loss=2.208269\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.2082688091592426\n",
      "[05/22/2025 04:00:14 INFO 140041726678848] Epoch[201] Batch[5] avg_epoch_loss=2.160618\n",
      "[05/22/2025 04:00:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.1606181144006356\n",
      "[05/22/2025 04:00:14 INFO 140041726678848] Epoch[201] Batch [5]#011Speed: 1925.47 samples/sec#011loss=2.160618\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] Epoch[201] Batch[10] avg_epoch_loss=2.194865\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=2.235961615003828\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] Epoch[201] Batch [10]#011Speed: 1932.39 samples/sec#011loss=2.235962\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] processed a total of 4595 examples\n",
      "#metrics {\"StartTime\": 1747886412.4932623, \"EndTime\": 1747886415.2945287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2801.0175228118896, \"count\": 1, \"min\": 2801.0175228118896, \"max\": 2801.0175228118896}}}\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1640.424731933738 records/second\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 50.5 % of epochs\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.1948651601293596\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] Epoch[202] Batch[0] avg_epoch_loss=2.134483\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.1344828786191536\n",
      "[05/22/2025 04:00:16 INFO 140041726678848] Epoch[202] Batch[5] avg_epoch_loss=2.148250\n",
      "[05/22/2025 04:00:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.148249568811769\n",
      "[05/22/2025 04:00:16 INFO 140041726678848] Epoch[202] Batch [5]#011Speed: 2214.69 samples/sec#011loss=2.148250\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] Epoch[202] Batch[10] avg_epoch_loss=2.239648\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=2.3493254867587696\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] Epoch[202] Batch [10]#011Speed: 1961.79 samples/sec#011loss=2.349325\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] processed a total of 4636 examples\n",
      "#metrics {\"StartTime\": 1747886415.2945886, \"EndTime\": 1747886417.8760211, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2581.1798572540283, \"count\": 1, \"min\": 2581.1798572540283, \"max\": 2581.1798572540283}}}\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.0183060037618 records/second\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] #progress_metric: host=algo-1, completed 50.75 % of epochs\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.239647713333133\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:18 INFO 140041726678848] Epoch[203] Batch[0] avg_epoch_loss=2.182985\n",
      "[05/22/2025 04:00:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.1829846218593403\n",
      "[05/22/2025 04:00:19 INFO 140041726678848] Epoch[203] Batch[5] avg_epoch_loss=2.187489\n",
      "[05/22/2025 04:00:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.187488807955758\n",
      "[05/22/2025 04:00:19 INFO 140041726678848] Epoch[203] Batch [5]#011Speed: 2170.20 samples/sec#011loss=2.187489\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] Epoch[203] Batch[10] avg_epoch_loss=2.301119\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=2.43747477032294\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] Epoch[203] Batch [10]#011Speed: 2019.33 samples/sec#011loss=2.437475\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] processed a total of 4538 examples\n",
      "#metrics {\"StartTime\": 1747886417.8760798, \"EndTime\": 1747886420.4609072, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2584.571599960327, \"count\": 1, \"min\": 2584.571599960327, \"max\": 2584.571599960327}}}\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1755.7449234796452 records/second\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 51.0 % of epochs\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.3011187908499315\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] Epoch[204] Batch[0] avg_epoch_loss=2.285132\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.285131781563196\n",
      "[05/22/2025 04:00:21 INFO 140041726678848] Epoch[204] Batch[5] avg_epoch_loss=2.211808\n",
      "[05/22/2025 04:00:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.2118075794879823\n",
      "[05/22/2025 04:00:21 INFO 140041726678848] Epoch[204] Batch [5]#011Speed: 2083.51 samples/sec#011loss=2.211808\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] Epoch[204] Batch[10] avg_epoch_loss=2.229709\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=2.2511911235036193\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] Epoch[204] Batch [10]#011Speed: 1957.78 samples/sec#011loss=2.251191\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] processed a total of 4564 examples\n",
      "#metrics {\"StartTime\": 1747886420.4609663, \"EndTime\": 1747886423.1341832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2672.9588508605957, \"count\": 1, \"min\": 2672.9588508605957, \"max\": 2672.9588508605957}}}\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1707.4152115551356 records/second\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 51.25 % of epochs\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.229709190404181\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] Epoch[205] Batch[0] avg_epoch_loss=2.117304\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.117303589139059\n",
      "[05/22/2025 04:00:24 INFO 140041726678848] Epoch[205] Batch[5] avg_epoch_loss=2.144824\n",
      "[05/22/2025 04:00:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.144823806411528\n",
      "[05/22/2025 04:00:24 INFO 140041726678848] Epoch[205] Batch [5]#011Speed: 2180.04 samples/sec#011loss=2.144824\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] processed a total of 4446 examples\n",
      "#metrics {\"StartTime\": 1747886423.1342425, \"EndTime\": 1747886425.6484616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2513.9424800872803, \"count\": 1, \"min\": 2513.9424800872803, \"max\": 2513.9424800872803}}}\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1768.468454562775 records/second\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 51.5 % of epochs\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.1600739137101543\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_1255de04-c69c-4d81-a68d-863f9a45eee6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886425.6485293, \"EndTime\": 1747886425.6592808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.41269302368164, \"count\": 1, \"min\": 10.41269302368164, \"max\": 10.41269302368164}}}\n",
      "[05/22/2025 04:00:26 INFO 140041726678848] Epoch[206] Batch[0] avg_epoch_loss=2.084883\n",
      "[05/22/2025 04:00:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.084882502566467\n",
      "[05/22/2025 04:00:27 INFO 140041726678848] Epoch[206] Batch[5] avg_epoch_loss=2.119127\n",
      "[05/22/2025 04:00:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.119127076735918\n",
      "[05/22/2025 04:00:27 INFO 140041726678848] Epoch[206] Batch [5]#011Speed: 2087.71 samples/sec#011loss=2.119127\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] Epoch[206] Batch[10] avg_epoch_loss=2.196408\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=2.2891458286208937\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] Epoch[206] Batch [10]#011Speed: 1896.44 samples/sec#011loss=2.289146\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] processed a total of 4663 examples\n",
      "#metrics {\"StartTime\": 1747886425.6593513, \"EndTime\": 1747886428.363004, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2703.6006450653076, \"count\": 1, \"min\": 2703.6006450653076, \"max\": 2703.6006450653076}}}\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1724.6790286932112 records/second\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 51.75 % of epochs\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.196408327592725\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] Epoch[207] Batch[0] avg_epoch_loss=2.245833\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.2458328892765174\n",
      "[05/22/2025 04:00:29 INFO 140041726678848] Epoch[207] Batch[5] avg_epoch_loss=2.242056\n",
      "[05/22/2025 04:00:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.2420559141842986\n",
      "[05/22/2025 04:00:29 INFO 140041726678848] Epoch[207] Batch [5]#011Speed: 2211.45 samples/sec#011loss=2.242056\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] Epoch[207] Batch[10] avg_epoch_loss=2.296378\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=2.3615640007307905\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] Epoch[207] Batch [10]#011Speed: 1881.77 samples/sec#011loss=2.361564\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] processed a total of 4644 examples\n",
      "#metrics {\"StartTime\": 1747886428.3630662, \"EndTime\": 1747886431.0418293, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2678.447484970093, \"count\": 1, \"min\": 2678.447484970093, \"max\": 2678.447484970093}}}\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1733.784824037067 records/second\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] #progress_metric: host=algo-1, completed 52.0 % of epochs\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.2963777717054312\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] Epoch[208] Batch[0] avg_epoch_loss=2.714060\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.7140602162792318\n",
      "[05/22/2025 04:00:32 INFO 140041726678848] Epoch[208] Batch[5] avg_epoch_loss=2.625315\n",
      "[05/22/2025 04:00:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.6253147819082914\n",
      "[05/22/2025 04:00:32 INFO 140041726678848] Epoch[208] Batch [5]#011Speed: 1983.01 samples/sec#011loss=2.625315\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] Epoch[208] Batch[10] avg_epoch_loss=2.656569\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.6940730377401167\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] Epoch[208] Batch [10]#011Speed: 1944.97 samples/sec#011loss=2.694073\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] processed a total of 4638 examples\n",
      "#metrics {\"StartTime\": 1747886431.041887, \"EndTime\": 1747886433.773564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2731.4085960388184, \"count\": 1, \"min\": 2731.4085960388184, \"max\": 2731.4085960388184}}}\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1697.9698353718732 records/second\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 52.25 % of epochs\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.6565685345591215\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:34 INFO 140041726678848] Epoch[209] Batch[0] avg_epoch_loss=2.457250\n",
      "[05/22/2025 04:00:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.457249562830596\n",
      "[05/22/2025 04:00:35 INFO 140041726678848] Epoch[209] Batch[5] avg_epoch_loss=2.487341\n",
      "[05/22/2025 04:00:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.4873410729717658\n",
      "[05/22/2025 04:00:35 INFO 140041726678848] Epoch[209] Batch [5]#011Speed: 2189.90 samples/sec#011loss=2.487341\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] Epoch[209] Batch[10] avg_epoch_loss=2.486852\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=2.4862661654805818\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] Epoch[209] Batch [10]#011Speed: 1890.22 samples/sec#011loss=2.486266\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] processed a total of 4630 examples\n",
      "#metrics {\"StartTime\": 1747886433.7736242, \"EndTime\": 1747886436.4367118, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2662.8310680389404, \"count\": 1, \"min\": 2662.8310680389404, \"max\": 2662.8310680389404}}}\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1738.6925533288363 records/second\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 52.5 % of epochs\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.486852478657591\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] Epoch[210] Batch[0] avg_epoch_loss=2.316521\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.3165209797814588\n",
      "[05/22/2025 04:00:37 INFO 140041726678848] Epoch[210] Batch[5] avg_epoch_loss=2.402508\n",
      "[05/22/2025 04:00:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.402508345549427\n",
      "[05/22/2025 04:00:37 INFO 140041726678848] Epoch[210] Batch [5]#011Speed: 2258.83 samples/sec#011loss=2.402508\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] Epoch[210] Batch[10] avg_epoch_loss=2.249408\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=2.065687693572522\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] Epoch[210] Batch [10]#011Speed: 1983.98 samples/sec#011loss=2.065688\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] processed a total of 4669 examples\n",
      "#metrics {\"StartTime\": 1747886436.4367733, \"EndTime\": 1747886438.99474, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2557.6629638671875, \"count\": 1, \"min\": 2557.6629638671875, \"max\": 2557.6629638671875}}}\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1825.4296259190205 records/second\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 52.75 % of epochs\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.2494080491962887\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:39 INFO 140041726678848] Epoch[211] Batch[0] avg_epoch_loss=2.212450\n",
      "[05/22/2025 04:00:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.2124503290732878\n",
      "[05/22/2025 04:00:40 INFO 140041726678848] Epoch[211] Batch[5] avg_epoch_loss=2.336691\n",
      "[05/22/2025 04:00:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.336690561454563\n",
      "[05/22/2025 04:00:40 INFO 140041726678848] Epoch[211] Batch [5]#011Speed: 2243.36 samples/sec#011loss=2.336691\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] Epoch[211] Batch[10] avg_epoch_loss=2.320057\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=2.300096623138224\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] Epoch[211] Batch [10]#011Speed: 1988.36 samples/sec#011loss=2.300097\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] processed a total of 4591 examples\n",
      "#metrics {\"StartTime\": 1747886438.9948018, \"EndTime\": 1747886441.5633945, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2568.2778358459473, \"count\": 1, \"min\": 2568.2778358459473, \"max\": 2568.2778358459473}}}\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1787.5114818725303 records/second\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 53.0 % of epochs\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.3200569531289545\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] Epoch[212] Batch[0] avg_epoch_loss=2.224287\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.224286799441467\n",
      "[05/22/2025 04:00:42 INFO 140041726678848] Epoch[212] Batch[5] avg_epoch_loss=2.329386\n",
      "[05/22/2025 04:00:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.3293857815182464\n",
      "[05/22/2025 04:00:42 INFO 140041726678848] Epoch[212] Batch [5]#011Speed: 2323.27 samples/sec#011loss=2.329386\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] Epoch[212] Batch[10] avg_epoch_loss=2.189077\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.0207061427738724\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] Epoch[212] Batch [10]#011Speed: 1973.25 samples/sec#011loss=2.020706\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] processed a total of 4666 examples\n",
      "#metrics {\"StartTime\": 1747886441.5634615, \"EndTime\": 1747886444.0960112, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2532.2811603546143, \"count\": 1, \"min\": 2532.2811603546143, \"max\": 2532.2811603546143}}}\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1842.5432109714545 records/second\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] #progress_metric: host=algo-1, completed 53.25 % of epochs\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.1890768548162582\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] Epoch[213] Batch[0] avg_epoch_loss=2.134836\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.1348359037879314\n",
      "[05/22/2025 04:00:45 INFO 140041726678848] Epoch[213] Batch[5] avg_epoch_loss=2.278937\n",
      "[05/22/2025 04:00:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.278937483506461\n",
      "[05/22/2025 04:00:45 INFO 140041726678848] Epoch[213] Batch [5]#011Speed: 2256.64 samples/sec#011loss=2.278937\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] Epoch[213] Batch[10] avg_epoch_loss=2.193085\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=2.0900625793864838\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] Epoch[213] Batch [10]#011Speed: 1955.27 samples/sec#011loss=2.090063\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] processed a total of 4572 examples\n",
      "#metrics {\"StartTime\": 1747886444.0960722, \"EndTime\": 1747886446.679581, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2583.2598209381104, \"count\": 1, \"min\": 2583.2598209381104, \"max\": 2583.2598209381104}}}\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1769.7973592155522 records/second\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 53.5 % of epochs\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.193085254361017\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:47 INFO 140041726678848] Epoch[214] Batch[0] avg_epoch_loss=2.211963\n",
      "[05/22/2025 04:00:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.211962727502088\n",
      "[05/22/2025 04:00:48 INFO 140041726678848] Epoch[214] Batch[5] avg_epoch_loss=2.163665\n",
      "[05/22/2025 04:00:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.1636649105578947\n",
      "[05/22/2025 04:00:48 INFO 140041726678848] Epoch[214] Batch [5]#011Speed: 2268.52 samples/sec#011loss=2.163665\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] Epoch[214] Batch[10] avg_epoch_loss=2.298415\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=2.4601156867692096\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] Epoch[214] Batch [10]#011Speed: 1984.30 samples/sec#011loss=2.460116\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] processed a total of 4681 examples\n",
      "#metrics {\"StartTime\": 1747886446.6796398, \"EndTime\": 1747886449.2274728, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2547.576427459717, \"count\": 1, \"min\": 2547.576427459717, \"max\": 2547.576427459717}}}\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1837.3684699424455 records/second\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 53.75 % of epochs\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.29841526338122\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] Epoch[215] Batch[0] avg_epoch_loss=2.176040\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.176039527944042\n",
      "[05/22/2025 04:00:50 INFO 140041726678848] Epoch[215] Batch[5] avg_epoch_loss=2.159852\n",
      "[05/22/2025 04:00:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.1598520257690703\n",
      "[05/22/2025 04:00:50 INFO 140041726678848] Epoch[215] Batch [5]#011Speed: 2228.89 samples/sec#011loss=2.159852\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] Epoch[215] Batch[10] avg_epoch_loss=2.251827\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=2.3621967001322384\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] Epoch[215] Batch [10]#011Speed: 1789.90 samples/sec#011loss=2.362197\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] processed a total of 4603 examples\n",
      "#metrics {\"StartTime\": 1747886449.2275324, \"EndTime\": 1747886451.9218652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2694.0762996673584, \"count\": 1, \"min\": 2694.0762996673584, \"max\": 2694.0762996673584}}}\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1708.5089082564057 records/second\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 54.0 % of epochs\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.2518268777523285\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:52 INFO 140041726678848] Epoch[216] Batch[0] avg_epoch_loss=2.284958\n",
      "[05/22/2025 04:00:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.2849583275334076\n",
      "[05/22/2025 04:00:53 INFO 140041726678848] Epoch[216] Batch[5] avg_epoch_loss=2.270037\n",
      "[05/22/2025 04:00:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.270036727123643\n",
      "[05/22/2025 04:00:53 INFO 140041726678848] Epoch[216] Batch [5]#011Speed: 2242.17 samples/sec#011loss=2.270037\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] Epoch[216] Batch[10] avg_epoch_loss=2.354499\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=2.455854807558463\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] Epoch[216] Batch [10]#011Speed: 1983.43 samples/sec#011loss=2.455855\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] processed a total of 4585 examples\n",
      "#metrics {\"StartTime\": 1747886451.9219236, \"EndTime\": 1747886454.4853122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2563.138723373413, \"count\": 1, \"min\": 2563.138723373413, \"max\": 2563.138723373413}}}\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.755859813005 records/second\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 54.25 % of epochs\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.354499490957652\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] Epoch[217] Batch[0] avg_epoch_loss=2.205379\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.2053789508369293\n",
      "[05/22/2025 04:00:55 INFO 140041726678848] Epoch[217] Batch[5] avg_epoch_loss=2.322139\n",
      "[05/22/2025 04:00:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.3221387969358993\n",
      "[05/22/2025 04:00:55 INFO 140041726678848] Epoch[217] Batch [5]#011Speed: 2188.81 samples/sec#011loss=2.322139\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] Epoch[217] Batch[10] avg_epoch_loss=2.392472\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=2.4768708294908826\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] Epoch[217] Batch [10]#011Speed: 1882.93 samples/sec#011loss=2.476871\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] processed a total of 4634 examples\n",
      "#metrics {\"StartTime\": 1747886454.4853785, \"EndTime\": 1747886457.1508, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2665.0757789611816, \"count\": 1, \"min\": 2665.0757789611816, \"max\": 2665.0757789611816}}}\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1738.7285339127304 records/second\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] #progress_metric: host=algo-1, completed 54.5 % of epochs\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.3924715390063462\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] Epoch[218] Batch[0] avg_epoch_loss=2.227486\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=2.2274863194251115\n",
      "[05/22/2025 04:00:58 INFO 140041726678848] Epoch[218] Batch[5] avg_epoch_loss=2.212915\n",
      "[05/22/2025 04:00:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.212915093436804\n",
      "[05/22/2025 04:00:58 INFO 140041726678848] Epoch[218] Batch [5]#011Speed: 2135.71 samples/sec#011loss=2.212915\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] Epoch[218] Batch[10] avg_epoch_loss=2.326052\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=2.461816351875696\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] Epoch[218] Batch [10]#011Speed: 2014.71 samples/sec#011loss=2.461816\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] processed a total of 4637 examples\n",
      "#metrics {\"StartTime\": 1747886457.150859, \"EndTime\": 1747886459.746267, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2595.1435565948486, \"count\": 1, \"min\": 2595.1435565948486, \"max\": 2595.1435565948486}}}\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.7397759633234 records/second\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 54.75 % of epochs\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.326052029090846\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:00 INFO 140041726678848] Epoch[219] Batch[0] avg_epoch_loss=2.116261\n",
      "[05/22/2025 04:01:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.116260554052408\n",
      "[05/22/2025 04:01:01 INFO 140041726678848] Epoch[219] Batch[5] avg_epoch_loss=2.157392\n",
      "[05/22/2025 04:01:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.1573919736639873\n",
      "[05/22/2025 04:01:01 INFO 140041726678848] Epoch[219] Batch [5]#011Speed: 2255.20 samples/sec#011loss=2.157392\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] Epoch[219] Batch[10] avg_epoch_loss=2.115708\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=2.065687095455178\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] Epoch[219] Batch [10]#011Speed: 1897.61 samples/sec#011loss=2.065687\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] processed a total of 4640 examples\n",
      "#metrics {\"StartTime\": 1747886459.746324, \"EndTime\": 1747886462.3549511, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2608.3762645721436, \"count\": 1, \"min\": 2608.3762645721436, \"max\": 2608.3762645721436}}}\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1778.817795846037 records/second\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 55.0 % of epochs\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.1157079381145283\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_8db9697e-a48f-4d27-a5c0-1b5b2e80a1e8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886462.35502, \"EndTime\": 1747886462.3654473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.1470947265625, \"count\": 1, \"min\": 10.1470947265625, \"max\": 10.1470947265625}}}\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] Epoch[220] Batch[0] avg_epoch_loss=2.083635\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.0836347482252227\n",
      "[05/22/2025 04:01:03 INFO 140041726678848] Epoch[220] Batch[5] avg_epoch_loss=2.082737\n",
      "[05/22/2025 04:01:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.0827373229935158\n",
      "[05/22/2025 04:01:03 INFO 140041726678848] Epoch[220] Batch [5]#011Speed: 2271.96 samples/sec#011loss=2.082737\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] Epoch[220] Batch[10] avg_epoch_loss=2.233614\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=2.4146657829029787\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] Epoch[220] Batch [10]#011Speed: 1949.77 samples/sec#011loss=2.414666\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] processed a total of 4695 examples\n",
      "#metrics {\"StartTime\": 1747886462.3654969, \"EndTime\": 1747886464.958857, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2593.3079719543457, \"count\": 1, \"min\": 2593.3079719543457, \"max\": 2593.3079719543457}}}\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.3671010988376 records/second\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 55.25 % of epochs\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.2336138956796354\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:05 INFO 140041726678848] Epoch[221] Batch[0] avg_epoch_loss=2.080468\n",
      "[05/22/2025 04:01:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.080467580952464\n",
      "[05/22/2025 04:01:06 INFO 140041726678848] Epoch[221] Batch[5] avg_epoch_loss=2.103714\n",
      "[05/22/2025 04:01:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.1037141591775126\n",
      "[05/22/2025 04:01:06 INFO 140041726678848] Epoch[221] Batch [5]#011Speed: 2250.06 samples/sec#011loss=2.103714\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] Epoch[221] Batch[10] avg_epoch_loss=2.229253\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=2.379899016042595\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] Epoch[221] Batch [10]#011Speed: 1988.05 samples/sec#011loss=2.379899\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] processed a total of 4623 examples\n",
      "#metrics {\"StartTime\": 1747886464.9589171, \"EndTime\": 1747886467.517596, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2558.408498764038, \"count\": 1, \"min\": 2558.408498764038, \"max\": 2558.408498764038}}}\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1806.9211105767354 records/second\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 55.5 % of epochs\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.2292527304798226\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] Epoch[222] Batch[0] avg_epoch_loss=2.158919\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=2.1589188267765174\n",
      "[05/22/2025 04:01:08 INFO 140041726678848] Epoch[222] Batch[5] avg_epoch_loss=2.221422\n",
      "[05/22/2025 04:01:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.2214218400191976\n",
      "[05/22/2025 04:01:08 INFO 140041726678848] Epoch[222] Batch [5]#011Speed: 2236.02 samples/sec#011loss=2.221422\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] Epoch[222] Batch[10] avg_epoch_loss=2.306232\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=2.408003489742831\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] Epoch[222] Batch [10]#011Speed: 2020.56 samples/sec#011loss=2.408003\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] processed a total of 4582 examples\n",
      "#metrics {\"StartTime\": 1747886467.5176537, \"EndTime\": 1747886470.0577748, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2539.8690700531006, \"count\": 1, \"min\": 2539.8690700531006, \"max\": 2539.8690700531006}}}\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1803.9670064500808 records/second\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 55.75 % of epochs\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.3062316808026675\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] Epoch[223] Batch[0] avg_epoch_loss=2.085795\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.0857953111950165\n",
      "[05/22/2025 04:01:11 INFO 140041726678848] Epoch[223] Batch[5] avg_epoch_loss=2.094368\n",
      "[05/22/2025 04:01:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.094367669437581\n",
      "[05/22/2025 04:01:11 INFO 140041726678848] Epoch[223] Batch [5]#011Speed: 2159.98 samples/sec#011loss=2.094368\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] Epoch[223] Batch[10] avg_epoch_loss=2.007080\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=1.9023352132342706\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] Epoch[223] Batch [10]#011Speed: 1960.22 samples/sec#011loss=1.902335\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] processed a total of 4596 examples\n",
      "#metrics {\"StartTime\": 1747886470.057836, \"EndTime\": 1747886472.6857393, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2627.6421546936035, \"count\": 1, \"min\": 2627.6421546936035, \"max\": 2627.6421546936035}}}\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1749.035199419463 records/second\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 56.0 % of epochs\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.0070801893451673\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_6aac2aba-0b10-4463-9968-71beb7bdd322-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886472.6858013, \"EndTime\": 1747886472.696488, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.410308837890625, \"count\": 1, \"min\": 10.410308837890625, \"max\": 10.410308837890625}}}\n",
      "[05/22/2025 04:01:13 INFO 140041726678848] Epoch[224] Batch[0] avg_epoch_loss=2.034826\n",
      "[05/22/2025 04:01:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.034825518295866\n",
      "[05/22/2025 04:01:14 INFO 140041726678848] Epoch[224] Batch[5] avg_epoch_loss=2.065635\n",
      "[05/22/2025 04:01:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.065635154401274\n",
      "[05/22/2025 04:01:14 INFO 140041726678848] Epoch[224] Batch [5]#011Speed: 2131.56 samples/sec#011loss=2.065635\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] Epoch[224] Batch[10] avg_epoch_loss=2.061352\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=2.0562112583083936\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] Epoch[224] Batch [10]#011Speed: 1932.15 samples/sec#011loss=2.056211\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] processed a total of 4673 examples\n",
      "#metrics {\"StartTime\": 1747886472.6965468, \"EndTime\": 1747886475.3464608, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2649.860620498657, \"count\": 1, \"min\": 2649.860620498657, \"max\": 2649.860620498657}}}\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1763.4320189155244 records/second\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 56.25 % of epochs\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.0613515652681462\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] Epoch[225] Batch[0] avg_epoch_loss=2.257361\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.257361057340966\n",
      "[05/22/2025 04:01:16 INFO 140041726678848] Epoch[225] Batch[5] avg_epoch_loss=2.175206\n",
      "[05/22/2025 04:01:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.1752058339278255\n",
      "[05/22/2025 04:01:16 INFO 140041726678848] Epoch[225] Batch [5]#011Speed: 2234.59 samples/sec#011loss=2.175206\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] Epoch[225] Batch[10] avg_epoch_loss=2.146901\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=2.112935021619223\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] Epoch[225] Batch [10]#011Speed: 1887.71 samples/sec#011loss=2.112935\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] processed a total of 4647 examples\n",
      "#metrics {\"StartTime\": 1747886475.3465195, \"EndTime\": 1747886477.968272, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2621.485471725464, \"count\": 1, \"min\": 2621.485471725464, \"max\": 2621.485471725464}}}\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1772.6002274349398 records/second\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] #progress_metric: host=algo-1, completed 56.5 % of epochs\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.146900919242097\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:18 INFO 140041726678848] Epoch[226] Batch[0] avg_epoch_loss=2.118643\n",
      "[05/22/2025 04:01:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=2.118642556375278\n",
      "[05/22/2025 04:01:19 INFO 140041726678848] Epoch[226] Batch[5] avg_epoch_loss=2.144430\n",
      "[05/22/2025 04:01:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.1444296380193832\n",
      "[05/22/2025 04:01:19 INFO 140041726678848] Epoch[226] Batch [5]#011Speed: 2201.72 samples/sec#011loss=2.144430\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] Epoch[226] Batch[10] avg_epoch_loss=2.108791\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=2.0660238898942094\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] Epoch[226] Batch [10]#011Speed: 1889.48 samples/sec#011loss=2.066024\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] processed a total of 4637 examples\n",
      "#metrics {\"StartTime\": 1747886477.968333, \"EndTime\": 1747886480.6086378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2640.0232315063477, \"count\": 1, \"min\": 2640.0232315063477, \"max\": 2640.0232315063477}}}\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1756.3335282107132 records/second\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 56.75 % of epochs\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.10879066159885\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:21 INFO 140041726678848] Epoch[227] Batch[0] avg_epoch_loss=2.112046\n",
      "[05/22/2025 04:01:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.1120462736201975\n",
      "[05/22/2025 04:01:22 INFO 140041726678848] Epoch[227] Batch[5] avg_epoch_loss=2.263053\n",
      "[05/22/2025 04:01:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.2630532766680584\n",
      "[05/22/2025 04:01:22 INFO 140041726678848] Epoch[227] Batch [5]#011Speed: 2220.82 samples/sec#011loss=2.263053\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] Epoch[227] Batch[10] avg_epoch_loss=2.204515\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=2.1342695138502226\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] Epoch[227] Batch [10]#011Speed: 2008.20 samples/sec#011loss=2.134270\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] processed a total of 4550 examples\n",
      "#metrics {\"StartTime\": 1747886480.608744, \"EndTime\": 1747886483.1792855, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2570.265769958496, \"count\": 1, \"min\": 2570.265769958496, \"max\": 2570.265769958496}}}\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1770.1708953228233 records/second\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 57.0 % of epochs\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.2045152026599513\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] Epoch[228] Batch[0] avg_epoch_loss=2.189061\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.189061494075376\n",
      "[05/22/2025 04:01:24 INFO 140041726678848] Epoch[228] Batch[5] avg_epoch_loss=2.118567\n",
      "[05/22/2025 04:01:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.118567089372506\n",
      "[05/22/2025 04:01:24 INFO 140041726678848] Epoch[228] Batch [5]#011Speed: 2263.85 samples/sec#011loss=2.118567\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] Epoch[228] Batch[10] avg_epoch_loss=2.148370\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=2.1841340402717844\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] Epoch[228] Batch [10]#011Speed: 1942.37 samples/sec#011loss=2.184134\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] processed a total of 4578 examples\n",
      "#metrics {\"StartTime\": 1747886483.179365, \"EndTime\": 1747886485.7564592, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2576.829671859741, \"count\": 1, \"min\": 2576.829671859741, \"max\": 2576.829671859741}}}\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1776.5399053678982 records/second\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 57.25 % of epochs\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.148370248872178\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:26 INFO 140041726678848] Epoch[229] Batch[0] avg_epoch_loss=2.077095\n",
      "[05/22/2025 04:01:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.077095422553591\n",
      "[05/22/2025 04:01:27 INFO 140041726678848] Epoch[229] Batch[5] avg_epoch_loss=2.231610\n",
      "[05/22/2025 04:01:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.2316096588338667\n",
      "[05/22/2025 04:01:27 INFO 140041726678848] Epoch[229] Batch [5]#011Speed: 2187.79 samples/sec#011loss=2.231610\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] Epoch[229] Batch[10] avg_epoch_loss=2.082081\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=229, batch=10 train loss <loss>=1.9026468595576977\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] Epoch[229] Batch [10]#011Speed: 1949.20 samples/sec#011loss=1.902647\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] processed a total of 4582 examples\n",
      "#metrics {\"StartTime\": 1747886485.7565207, \"EndTime\": 1747886488.373291, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2616.516351699829, \"count\": 1, \"min\": 2616.516351699829, \"max\": 2616.516351699829}}}\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1751.1230846764734 records/second\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 57.5 % of epochs\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.0820811137083353\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] Epoch[230] Batch[0] avg_epoch_loss=2.196012\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.1960118894853147\n",
      "[05/22/2025 04:01:29 INFO 140041726678848] Epoch[230] Batch[5] avg_epoch_loss=2.336289\n",
      "[05/22/2025 04:01:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.336288825971778\n",
      "[05/22/2025 04:01:29 INFO 140041726678848] Epoch[230] Batch [5]#011Speed: 2183.98 samples/sec#011loss=2.336289\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] Epoch[230] Batch[10] avg_epoch_loss=2.303253\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=2.263609779544822\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] Epoch[230] Batch [10]#011Speed: 2003.18 samples/sec#011loss=2.263610\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] processed a total of 4553 examples\n",
      "#metrics {\"StartTime\": 1747886488.3733535, \"EndTime\": 1747886490.9785604, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2604.9487590789795, \"count\": 1, \"min\": 2604.9487590789795, \"max\": 2604.9487590789795}}}\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1747.7424662809858 records/second\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 57.75 % of epochs\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.3032528957777068\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:31 INFO 140041726678848] Epoch[231] Batch[0] avg_epoch_loss=2.200574\n",
      "[05/22/2025 04:01:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.200573621720142\n",
      "[05/22/2025 04:01:32 INFO 140041726678848] Epoch[231] Batch[5] avg_epoch_loss=2.262668\n",
      "[05/22/2025 04:01:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.2626676042609155\n",
      "[05/22/2025 04:01:32 INFO 140041726678848] Epoch[231] Batch [5]#011Speed: 2190.39 samples/sec#011loss=2.262668\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] Epoch[231] Batch[10] avg_epoch_loss=2.287491\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=2.317279854755359\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] Epoch[231] Batch [10]#011Speed: 1997.78 samples/sec#011loss=2.317280\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] processed a total of 4578 examples\n",
      "#metrics {\"StartTime\": 1747886490.978659, \"EndTime\": 1747886493.5668733, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2587.9077911376953, \"count\": 1, \"min\": 2587.9077911376953, \"max\": 2587.9077911376953}}}\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1768.9338249227972 records/second\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 58.0 % of epochs\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.2874913544856628\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:34 INFO 140041726678848] Epoch[232] Batch[0] avg_epoch_loss=2.100642\n",
      "[05/22/2025 04:01:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.1006418070973694\n",
      "[05/22/2025 04:01:35 INFO 140041726678848] Epoch[232] Batch[5] avg_epoch_loss=2.099899\n",
      "[05/22/2025 04:01:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.0998988502009674\n",
      "[05/22/2025 04:01:35 INFO 140041726678848] Epoch[232] Batch [5]#011Speed: 2198.77 samples/sec#011loss=2.099899\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] Epoch[232] Batch[10] avg_epoch_loss=2.212571\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=2.347777586259396\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] Epoch[232] Batch [10]#011Speed: 1915.84 samples/sec#011loss=2.347778\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] processed a total of 4595 examples\n",
      "#metrics {\"StartTime\": 1747886493.5669374, \"EndTime\": 1747886496.1948814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2627.6352405548096, \"count\": 1, \"min\": 2627.6352405548096, \"max\": 2627.6352405548096}}}\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1748.6663842475073 records/second\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 58.25 % of epochs\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.2125710029547987\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] Epoch[233] Batch[0] avg_epoch_loss=2.159025\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.1590248566693346\n",
      "[05/22/2025 04:01:37 INFO 140041726678848] Epoch[233] Batch[5] avg_epoch_loss=2.208072\n",
      "[05/22/2025 04:01:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.2080718382429705\n",
      "[05/22/2025 04:01:37 INFO 140041726678848] Epoch[233] Batch [5]#011Speed: 2206.31 samples/sec#011loss=2.208072\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] Epoch[233] Batch[10] avg_epoch_loss=2.276382\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=2.3583533883891286\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] Epoch[233] Batch [10]#011Speed: 1918.26 samples/sec#011loss=2.358353\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] processed a total of 4653 examples\n",
      "#metrics {\"StartTime\": 1747886496.194935, \"EndTime\": 1747886498.813966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2618.6625957489014, \"count\": 1, \"min\": 2618.6625957489014, \"max\": 2618.6625957489014}}}\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1776.79957989222 records/second\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 58.5 % of epochs\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.2763816337639513\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:39 INFO 140041726678848] Epoch[234] Batch[0] avg_epoch_loss=2.104518\n",
      "[05/22/2025 04:01:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.104518151230164\n",
      "[05/22/2025 04:01:40 INFO 140041726678848] Epoch[234] Batch[5] avg_epoch_loss=2.119217\n",
      "[05/22/2025 04:01:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.1192167037136924\n",
      "[05/22/2025 04:01:40 INFO 140041726678848] Epoch[234] Batch [5]#011Speed: 2203.94 samples/sec#011loss=2.119217\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] Epoch[234] Batch[10] avg_epoch_loss=2.117005\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=2.1143518800459353\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] Epoch[234] Batch [10]#011Speed: 1979.55 samples/sec#011loss=2.114352\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] processed a total of 4619 examples\n",
      "#metrics {\"StartTime\": 1747886498.814027, \"EndTime\": 1747886501.3995097, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2585.222005844116, \"count\": 1, \"min\": 2585.222005844116, \"max\": 2585.222005844116}}}\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.630807936376 records/second\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 58.75 % of epochs\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.1170054202283484\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] Epoch[235] Batch[0] avg_epoch_loss=2.038940\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.03893988594446\n",
      "[05/22/2025 04:01:42 INFO 140041726678848] Epoch[235] Batch[5] avg_epoch_loss=2.192833\n",
      "[05/22/2025 04:01:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.192832601273954\n",
      "[05/22/2025 04:01:42 INFO 140041726678848] Epoch[235] Batch [5]#011Speed: 2240.18 samples/sec#011loss=2.192833\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] Epoch[235] Batch[10] avg_epoch_loss=2.142968\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=2.083129937186804\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] Epoch[235] Batch [10]#011Speed: 2004.65 samples/sec#011loss=2.083130\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] processed a total of 4543 examples\n",
      "#metrics {\"StartTime\": 1747886501.3995721, \"EndTime\": 1747886503.9472654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2547.4350452423096, \"count\": 1, \"min\": 2547.4350452423096, \"max\": 2547.4350452423096}}}\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1783.2885115431122 records/second\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] #progress_metric: host=algo-1, completed 59.0 % of epochs\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.1429677539616128\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:44 INFO 140041726678848] Epoch[236] Batch[0] avg_epoch_loss=2.041728\n",
      "[05/22/2025 04:01:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.0417275205752365\n",
      "[05/22/2025 04:01:45 INFO 140041726678848] Epoch[236] Batch[5] avg_epoch_loss=2.193585\n",
      "[05/22/2025 04:01:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.1935848924258767\n",
      "[05/22/2025 04:01:45 INFO 140041726678848] Epoch[236] Batch [5]#011Speed: 2263.51 samples/sec#011loss=2.193585\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] Epoch[236] Batch[10] avg_epoch_loss=2.132820\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=2.0599017238829345\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] Epoch[236] Batch [10]#011Speed: 1963.14 samples/sec#011loss=2.059902\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] processed a total of 4636 examples\n",
      "#metrics {\"StartTime\": 1747886503.947326, \"EndTime\": 1747886506.5123656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2564.751386642456, \"count\": 1, \"min\": 2564.751386642456, \"max\": 2564.751386642456}}}\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1807.5187578193795 records/second\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 59.25 % of epochs\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.1328198158154485\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] Epoch[237] Batch[0] avg_epoch_loss=2.140355\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.140354895644836\n",
      "[05/22/2025 04:01:48 INFO 140041726678848] Epoch[237] Batch[5] avg_epoch_loss=2.267091\n",
      "[05/22/2025 04:01:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.2670913390433602\n",
      "[05/22/2025 04:01:48 INFO 140041726678848] Epoch[237] Batch [5]#011Speed: 2133.51 samples/sec#011loss=2.267091\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] Epoch[237] Batch[10] avg_epoch_loss=2.323060\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=2.390222249530206\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] Epoch[237] Batch [10]#011Speed: 1937.16 samples/sec#011loss=2.390222\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] processed a total of 4593 examples\n",
      "#metrics {\"StartTime\": 1747886506.5124266, \"EndTime\": 1747886509.1633828, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2650.653839111328, \"count\": 1, \"min\": 2650.653839111328, \"max\": 2650.653839111328}}}\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1732.7203235896716 records/second\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 59.5 % of epochs\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.323059934719199\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] Epoch[238] Batch[0] avg_epoch_loss=2.065501\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.0655010537740117\n",
      "[05/22/2025 04:01:50 INFO 140041726678848] Epoch[238] Batch[5] avg_epoch_loss=2.115808\n",
      "[05/22/2025 04:01:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.115808250466894\n",
      "[05/22/2025 04:01:50 INFO 140041726678848] Epoch[238] Batch [5]#011Speed: 2240.50 samples/sec#011loss=2.115808\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] Epoch[238] Batch[10] avg_epoch_loss=2.094523\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=2.0689811723534937\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] Epoch[238] Batch [10]#011Speed: 1883.96 samples/sec#011loss=2.068981\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] processed a total of 4692 examples\n",
      "#metrics {\"StartTime\": 1747886509.1634462, \"EndTime\": 1747886511.7833178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2619.6019649505615, \"count\": 1, \"min\": 2619.6019649505615, \"max\": 2619.6019649505615}}}\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1791.0342117767364 records/second\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 59.75 % of epochs\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.094523214960803\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:52 INFO 140041726678848] Epoch[239] Batch[0] avg_epoch_loss=2.113983\n",
      "[05/22/2025 04:01:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.113983222264755\n",
      "[05/22/2025 04:01:53 INFO 140041726678848] Epoch[239] Batch[5] avg_epoch_loss=2.070707\n",
      "[05/22/2025 04:01:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.0707073027590246\n",
      "[05/22/2025 04:01:53 INFO 140041726678848] Epoch[239] Batch [5]#011Speed: 2185.46 samples/sec#011loss=2.070707\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] Epoch[239] Batch[10] avg_epoch_loss=2.037869\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=1.9984634365430123\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] Epoch[239] Batch [10]#011Speed: 2023.20 samples/sec#011loss=1.998463\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] processed a total of 4578 examples\n",
      "#metrics {\"StartTime\": 1747886511.783401, \"EndTime\": 1747886514.3596292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2575.921058654785, \"count\": 1, \"min\": 2575.921058654785, \"max\": 2575.921058654785}}}\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1777.1696535710455 records/second\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 60.0 % of epochs\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.0378691817517463\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] Epoch[240] Batch[0] avg_epoch_loss=2.055154\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.0551544393356767\n",
      "[05/22/2025 04:01:55 INFO 140041726678848] Epoch[240] Batch[5] avg_epoch_loss=2.055715\n",
      "[05/22/2025 04:01:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.0557154915292086\n",
      "[05/22/2025 04:01:55 INFO 140041726678848] Epoch[240] Batch [5]#011Speed: 2248.54 samples/sec#011loss=2.055715\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] Epoch[240] Batch[10] avg_epoch_loss=2.011285\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=1.9579677658250974\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] Epoch[240] Batch [10]#011Speed: 2022.26 samples/sec#011loss=1.957968\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] processed a total of 4561 examples\n",
      "#metrics {\"StartTime\": 1747886514.3596864, \"EndTime\": 1747886516.8942142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.2800617218018, \"count\": 1, \"min\": 2534.2800617218018, \"max\": 2534.2800617218018}}}\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1799.628878470666 records/second\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 60.25 % of epochs\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.0112847071182487\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:57 INFO 140041726678848] Epoch[241] Batch[0] avg_epoch_loss=2.066881\n",
      "[05/22/2025 04:01:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.066880937673998\n",
      "[05/22/2025 04:01:58 INFO 140041726678848] Epoch[241] Batch[5] avg_epoch_loss=2.090462\n",
      "[05/22/2025 04:01:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.0904616006852614\n",
      "[05/22/2025 04:01:58 INFO 140041726678848] Epoch[241] Batch [5]#011Speed: 2269.82 samples/sec#011loss=2.090462\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] Epoch[241] Batch[10] avg_epoch_loss=2.118577\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.1523162094150194\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] Epoch[241] Batch [10]#011Speed: 2009.92 samples/sec#011loss=2.152316\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] processed a total of 4553 examples\n",
      "#metrics {\"StartTime\": 1747886516.8943157, \"EndTime\": 1747886519.4513495, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2556.7238330841064, \"count\": 1, \"min\": 2556.7238330841064, \"max\": 2556.7238330841064}}}\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1780.7170541536927 records/second\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 60.5 % of epochs\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.1185773319260606\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] Epoch[242] Batch[0] avg_epoch_loss=2.079402\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.0794017086581293\n",
      "[05/22/2025 04:02:00 INFO 140041726678848] Epoch[242] Batch[5] avg_epoch_loss=2.234388\n",
      "[05/22/2025 04:02:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.2343884349842824\n",
      "[05/22/2025 04:02:00 INFO 140041726678848] Epoch[242] Batch [5]#011Speed: 2199.07 samples/sec#011loss=2.234388\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] Epoch[242] Batch[10] avg_epoch_loss=2.222084\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=2.2073176666463667\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] Epoch[242] Batch [10]#011Speed: 1758.62 samples/sec#011loss=2.207318\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] processed a total of 4631 examples\n",
      "#metrics {\"StartTime\": 1747886519.4514103, \"EndTime\": 1747886522.1826086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2730.8809757232666, \"count\": 1, \"min\": 2730.8809757232666, \"max\": 2730.8809757232666}}}\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1695.7123352680321 records/second\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 60.75 % of epochs\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.22208354028523\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] Epoch[243] Batch[0] avg_epoch_loss=2.384603\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=2.3846033177025334\n",
      "[05/22/2025 04:02:03 INFO 140041726678848] Epoch[243] Batch[5] avg_epoch_loss=2.368256\n",
      "[05/22/2025 04:02:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.368255751170135\n",
      "[05/22/2025 04:02:03 INFO 140041726678848] Epoch[243] Batch [5]#011Speed: 2043.68 samples/sec#011loss=2.368256\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] Epoch[243] Batch[10] avg_epoch_loss=2.485471\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=2.626129354294265\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] Epoch[243] Batch [10]#011Speed: 1936.23 samples/sec#011loss=2.626129\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] processed a total of 4590 examples\n",
      "#metrics {\"StartTime\": 1747886522.1827052, \"EndTime\": 1747886524.8826406, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2699.624538421631, \"count\": 1, \"min\": 2699.624538421631, \"max\": 2699.624538421631}}}\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1700.172470069251 records/second\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 61.0 % of epochs\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.4854710253174668\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:05 INFO 140041726678848] Epoch[244] Batch[0] avg_epoch_loss=2.284338\n",
      "[05/22/2025 04:02:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.284337644853146\n",
      "[05/22/2025 04:02:06 INFO 140041726678848] Epoch[244] Batch[5] avg_epoch_loss=2.312302\n",
      "[05/22/2025 04:02:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.3123017376940074\n",
      "[05/22/2025 04:02:06 INFO 140041726678848] Epoch[244] Batch [5]#011Speed: 2184.04 samples/sec#011loss=2.312302\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] Epoch[244] Batch[10] avg_epoch_loss=2.490999\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=2.7054348204342986\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] Epoch[244] Batch [10]#011Speed: 1976.53 samples/sec#011loss=2.705435\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] processed a total of 4561 examples\n",
      "#metrics {\"StartTime\": 1747886524.8827105, \"EndTime\": 1747886527.4848993, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2601.85170173645, \"count\": 1, \"min\": 2601.85170173645, \"max\": 2601.85170173645}}}\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1752.8981398327444 records/second\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 61.25 % of epochs\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.490998593485049\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] Epoch[245] Batch[0] avg_epoch_loss=2.130105\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.1301046596603563\n",
      "[05/22/2025 04:02:08 INFO 140041726678848] Epoch[245] Batch[5] avg_epoch_loss=2.230063\n",
      "[05/22/2025 04:02:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.2300629364444133\n",
      "[05/22/2025 04:02:08 INFO 140041726678848] Epoch[245] Batch [5]#011Speed: 2280.84 samples/sec#011loss=2.230063\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] Epoch[245] Batch[10] avg_epoch_loss=2.438073\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=2.6876853076280622\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] Epoch[245] Batch [10]#011Speed: 1994.18 samples/sec#011loss=2.687685\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] processed a total of 4705 examples\n",
      "#metrics {\"StartTime\": 1747886527.484991, \"EndTime\": 1747886530.0343628, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2549.0217208862305, \"count\": 1, \"min\": 2549.0217208862305, \"max\": 2549.0217208862305}}}\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1845.7307196565146 records/second\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 61.5 % of epochs\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.438073105164254\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] Epoch[246] Batch[0] avg_epoch_loss=2.156886\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.156886043421144\n",
      "[05/22/2025 04:02:11 INFO 140041726678848] Epoch[246] Batch[5] avg_epoch_loss=2.259021\n",
      "[05/22/2025 04:02:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.259021172810238\n",
      "[05/22/2025 04:02:11 INFO 140041726678848] Epoch[246] Batch [5]#011Speed: 2227.69 samples/sec#011loss=2.259021\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] Epoch[246] Batch[10] avg_epoch_loss=2.315387\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=2.383026517260579\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] Epoch[246] Batch [10]#011Speed: 2042.33 samples/sec#011loss=2.383027\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] processed a total of 4502 examples\n",
      "#metrics {\"StartTime\": 1747886530.0344338, \"EndTime\": 1747886532.5739157, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2539.1180515289307, \"count\": 1, \"min\": 2539.1180515289307, \"max\": 2539.1180515289307}}}\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1772.985838277345 records/second\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 61.75 % of epochs\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=246, train loss <loss>=2.315387238469484\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:13 INFO 140041726678848] Epoch[247] Batch[0] avg_epoch_loss=2.073249\n",
      "[05/22/2025 04:02:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.0732489842880013\n",
      "[05/22/2025 04:02:13 INFO 140041726678848] Epoch[247] Batch[5] avg_epoch_loss=2.071788\n",
      "[05/22/2025 04:02:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.0717884451704016\n",
      "[05/22/2025 04:02:13 INFO 140041726678848] Epoch[247] Batch [5]#011Speed: 2294.05 samples/sec#011loss=2.071788\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] Epoch[247] Batch[10] avg_epoch_loss=1.984900\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=1.8806330147724108\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] Epoch[247] Batch [10]#011Speed: 2040.01 samples/sec#011loss=1.880633\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] processed a total of 4603 examples\n",
      "#metrics {\"StartTime\": 1747886532.5739832, \"EndTime\": 1747886535.0884933, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2514.122247695923, \"count\": 1, \"min\": 2514.122247695923, \"max\": 2514.122247695923}}}\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1830.783709210606 records/second\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 62.0 % of epochs\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=247, train loss <loss>=1.984899613171315\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_cf91f473-ba7a-45c0-bf4d-cbdbbacb2bde-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886535.0885644, \"EndTime\": 1747886535.0991123, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.190248489379883, \"count\": 1, \"min\": 10.190248489379883, \"max\": 10.190248489379883}}}\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] Epoch[248] Batch[0] avg_epoch_loss=2.052729\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.0527292094411194\n",
      "[05/22/2025 04:02:16 INFO 140041726678848] Epoch[248] Batch[5] avg_epoch_loss=2.037276\n",
      "[05/22/2025 04:02:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.037275964273907\n",
      "[05/22/2025 04:02:16 INFO 140041726678848] Epoch[248] Batch [5]#011Speed: 2275.27 samples/sec#011loss=2.037276\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] Epoch[248] Batch[10] avg_epoch_loss=2.136567\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=2.2557152287200726\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] Epoch[248] Batch [10]#011Speed: 1916.26 samples/sec#011loss=2.255715\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] processed a total of 4663 examples\n",
      "#metrics {\"StartTime\": 1747886535.0991688, \"EndTime\": 1747886537.6887662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2589.545726776123, \"count\": 1, \"min\": 2589.545726776123, \"max\": 2589.545726776123}}}\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1800.6404286322056 records/second\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] #progress_metric: host=algo-1, completed 62.25 % of epochs\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.136566539022164\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:18 INFO 140041726678848] Epoch[249] Batch[0] avg_epoch_loss=2.050815\n",
      "[05/22/2025 04:02:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.0508145542612053\n",
      "[05/22/2025 04:02:19 INFO 140041726678848] Epoch[249] Batch[5] avg_epoch_loss=2.165300\n",
      "[05/22/2025 04:02:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.165300398998643\n",
      "[05/22/2025 04:02:19 INFO 140041726678848] Epoch[249] Batch [5]#011Speed: 2292.75 samples/sec#011loss=2.165300\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] Epoch[249] Batch[10] avg_epoch_loss=2.056986\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=1.9270094024046491\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] Epoch[249] Batch [10]#011Speed: 2023.78 samples/sec#011loss=1.927009\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] processed a total of 4514 examples\n",
      "#metrics {\"StartTime\": 1747886537.6888258, \"EndTime\": 1747886540.2118576, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.2537517547607, \"count\": 1, \"min\": 2522.2537517547607, \"max\": 2522.2537517547607}}}\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1789.2286777252511 records/second\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 62.5 % of epochs\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.0569863096377365\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] Epoch[250] Batch[0] avg_epoch_loss=2.030156\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.0301555811960608\n",
      "[05/22/2025 04:02:21 INFO 140041726678848] Epoch[250] Batch[5] avg_epoch_loss=2.148559\n",
      "[05/22/2025 04:02:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.1485591171933\n",
      "[05/22/2025 04:02:21 INFO 140041726678848] Epoch[250] Batch [5]#011Speed: 2160.43 samples/sec#011loss=2.148559\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] Epoch[250] Batch[10] avg_epoch_loss=2.233753\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=2.335986110627784\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] Epoch[250] Batch [10]#011Speed: 2004.75 samples/sec#011loss=2.335986\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] processed a total of 4605 examples\n",
      "#metrics {\"StartTime\": 1747886540.211924, \"EndTime\": 1747886542.8080695, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2595.863103866577, \"count\": 1, \"min\": 2595.863103866577, \"max\": 2595.863103866577}}}\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.9076901260908 records/second\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] #progress_metric: host=algo-1, completed 62.75 % of epochs\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.2337532051180653\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:23 INFO 140041726678848] Epoch[251] Batch[0] avg_epoch_loss=2.028305\n",
      "[05/22/2025 04:02:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.0283048158233576\n",
      "[05/22/2025 04:02:24 INFO 140041726678848] Epoch[251] Batch[5] avg_epoch_loss=2.162556\n",
      "[05/22/2025 04:02:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.162555538820353\n",
      "[05/22/2025 04:02:24 INFO 140041726678848] Epoch[251] Batch [5]#011Speed: 2300.91 samples/sec#011loss=2.162556\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] Epoch[251] Batch[10] avg_epoch_loss=2.136774\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=2.10583713590966\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] Epoch[251] Batch [10]#011Speed: 2021.92 samples/sec#011loss=2.105837\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] processed a total of 4593 examples\n",
      "#metrics {\"StartTime\": 1747886542.8081381, \"EndTime\": 1747886545.329214, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2520.68829536438, \"count\": 1, \"min\": 2520.68829536438, \"max\": 2520.68829536438}}}\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1822.0574283091948 records/second\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 63.0 % of epochs\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.13677444658822\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] Epoch[252] Batch[0] avg_epoch_loss=2.014216\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=2.014215753975849\n",
      "[05/22/2025 04:02:26 INFO 140041726678848] Epoch[252] Batch[5] avg_epoch_loss=2.146617\n",
      "[05/22/2025 04:02:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.1466170483017817\n",
      "[05/22/2025 04:02:26 INFO 140041726678848] Epoch[252] Batch [5]#011Speed: 2288.99 samples/sec#011loss=2.146617\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] Epoch[252] Batch[10] avg_epoch_loss=2.257665\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=2.3909216662026727\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] Epoch[252] Batch [10]#011Speed: 1967.15 samples/sec#011loss=2.390922\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] processed a total of 4555 examples\n",
      "#metrics {\"StartTime\": 1747886545.3292725, \"EndTime\": 1747886547.8782947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.7608909606934, \"count\": 1, \"min\": 2548.7608909606934, \"max\": 2548.7608909606934}}}\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1787.0677020311432 records/second\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] #progress_metric: host=algo-1, completed 63.25 % of epochs\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.257664601893096\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:28 INFO 140041726678848] Epoch[253] Batch[0] avg_epoch_loss=1.999599\n",
      "[05/22/2025 04:02:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=1.9995993973152144\n",
      "[05/22/2025 04:02:29 INFO 140041726678848] Epoch[253] Batch[5] avg_epoch_loss=2.168054\n",
      "[05/22/2025 04:02:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.168054004377494\n",
      "[05/22/2025 04:02:29 INFO 140041726678848] Epoch[253] Batch [5]#011Speed: 2286.62 samples/sec#011loss=2.168054\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] Epoch[253] Batch[10] avg_epoch_loss=2.071973\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=1.9566766207892539\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] Epoch[253] Batch [10]#011Speed: 1998.34 samples/sec#011loss=1.956677\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] processed a total of 4658 examples\n",
      "#metrics {\"StartTime\": 1747886547.8783727, \"EndTime\": 1747886550.4074996, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2528.8262367248535, \"count\": 1, \"min\": 2528.8262367248535, \"max\": 2528.8262367248535}}}\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1841.898933207002 records/second\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 63.5 % of epochs\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.0719733754737484\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] Epoch[254] Batch[0] avg_epoch_loss=2.050081\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.050080637092845\n",
      "[05/22/2025 04:02:31 INFO 140041726678848] Epoch[254] Batch[5] avg_epoch_loss=2.049747\n",
      "[05/22/2025 04:02:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.0497473226092704\n",
      "[05/22/2025 04:02:31 INFO 140041726678848] Epoch[254] Batch [5]#011Speed: 2270.55 samples/sec#011loss=2.049747\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] Epoch[254] Batch[10] avg_epoch_loss=2.138657\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=254, batch=10 train loss <loss>=2.2453479792333657\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] Epoch[254] Batch [10]#011Speed: 2011.10 samples/sec#011loss=2.245348\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] processed a total of 4516 examples\n",
      "#metrics {\"StartTime\": 1747886550.4075584, \"EndTime\": 1747886552.949023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2541.212320327759, \"count\": 1, \"min\": 2541.212320327759, \"max\": 2541.212320327759}}}\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1777.0433714883145 records/second\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] #progress_metric: host=algo-1, completed 63.75 % of epochs\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.1386567119838595\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:33 INFO 140041726678848] Epoch[255] Batch[0] avg_epoch_loss=1.997429\n",
      "[05/22/2025 04:02:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=1.9974293188422187\n",
      "[05/22/2025 04:02:34 INFO 140041726678848] Epoch[255] Batch[5] avg_epoch_loss=2.035438\n",
      "[05/22/2025 04:02:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.0354382034222462\n",
      "[05/22/2025 04:02:34 INFO 140041726678848] Epoch[255] Batch [5]#011Speed: 2238.54 samples/sec#011loss=2.035438\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] Epoch[255] Batch[10] avg_epoch_loss=2.140923\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=2.267505073122564\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] Epoch[255] Batch [10]#011Speed: 1996.43 samples/sec#011loss=2.267505\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] processed a total of 4533 examples\n",
      "#metrics {\"StartTime\": 1747886552.9490812, \"EndTime\": 1747886555.499909, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2550.5709648132324, \"count\": 1, \"min\": 2550.5709648132324, \"max\": 2550.5709648132324}}}\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1777.1863235924238 records/second\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] #progress_metric: host=algo-1, completed 64.0 % of epochs\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.140923144195118\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] Epoch[256] Batch[0] avg_epoch_loss=2.005990\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.0059897373938615\n",
      "[05/22/2025 04:02:36 INFO 140041726678848] Epoch[256] Batch[5] avg_epoch_loss=2.012605\n",
      "[05/22/2025 04:02:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.012604552724225\n",
      "[05/22/2025 04:02:36 INFO 140041726678848] Epoch[256] Batch [5]#011Speed: 2273.73 samples/sec#011loss=2.012605\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] Epoch[256] Batch[10] avg_epoch_loss=2.113037\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=2.2335553073670655\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] Epoch[256] Batch [10]#011Speed: 2047.67 samples/sec#011loss=2.233555\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] processed a total of 4533 examples\n",
      "#metrics {\"StartTime\": 1747886555.4999712, \"EndTime\": 1747886558.025633, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2525.3610610961914, \"count\": 1, \"min\": 2525.3610610961914, \"max\": 2525.3610610961914}}}\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.9291679694757 records/second\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 64.25 % of epochs\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.113036713925516\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] Epoch[257] Batch[0] avg_epoch_loss=2.076847\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.0768474757273108\n",
      "[05/22/2025 04:02:39 INFO 140041726678848] Epoch[257] Batch[5] avg_epoch_loss=2.200935\n",
      "[05/22/2025 04:02:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.200934871002401\n",
      "[05/22/2025 04:02:39 INFO 140041726678848] Epoch[257] Batch [5]#011Speed: 2250.05 samples/sec#011loss=2.200935\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] Epoch[257] Batch[10] avg_epoch_loss=2.183774\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=2.1631812012806235\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] Epoch[257] Batch [10]#011Speed: 2054.52 samples/sec#011loss=2.163181\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] processed a total of 4552 examples\n",
      "#metrics {\"StartTime\": 1747886558.025692, \"EndTime\": 1747886560.56426, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2538.316488265991, \"count\": 1, \"min\": 2538.316488265991, \"max\": 2538.316488265991}}}\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1793.25479800271 records/second\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] #progress_metric: host=algo-1, completed 64.5 % of epochs\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.183774112037957\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] Epoch[258] Batch[0] avg_epoch_loss=2.030968\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.0309675254906736\n",
      "[05/22/2025 04:02:41 INFO 140041726678848] Epoch[258] Batch[5] avg_epoch_loss=2.168106\n",
      "[05/22/2025 04:02:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.1681061130855026\n",
      "[05/22/2025 04:02:41 INFO 140041726678848] Epoch[258] Batch [5]#011Speed: 2258.11 samples/sec#011loss=2.168106\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] Epoch[258] Batch[10] avg_epoch_loss=2.268151\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=2.388205506594516\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] Epoch[258] Batch [10]#011Speed: 2028.37 samples/sec#011loss=2.388206\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] processed a total of 4602 examples\n",
      "#metrics {\"StartTime\": 1747886560.564317, \"EndTime\": 1747886563.0995631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.994125366211, \"count\": 1, \"min\": 2534.994125366211, \"max\": 2534.994125366211}}}\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1815.32462678145 records/second\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] #progress_metric: host=algo-1, completed 64.75 % of epochs\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.268151291953236\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] Epoch[259] Batch[0] avg_epoch_loss=2.018435\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.0184349280954206\n",
      "[05/22/2025 04:02:44 INFO 140041726678848] Epoch[259] Batch[5] avg_epoch_loss=2.177851\n",
      "[05/22/2025 04:02:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.177851189129779\n",
      "[05/22/2025 04:02:44 INFO 140041726678848] Epoch[259] Batch [5]#011Speed: 2252.09 samples/sec#011loss=2.177851\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] Epoch[259] Batch[10] avg_epoch_loss=2.099317\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=2.0050754334719514\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] Epoch[259] Batch [10]#011Speed: 1947.05 samples/sec#011loss=2.005075\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] processed a total of 4652 examples\n",
      "#metrics {\"StartTime\": 1747886563.0996246, \"EndTime\": 1747886565.6818047, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2581.9246768951416, \"count\": 1, \"min\": 2581.9246768951416, \"max\": 2581.9246768951416}}}\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1801.696107783187 records/second\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] #progress_metric: host=algo-1, completed 65.0 % of epochs\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.0993167547398577\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:46 INFO 140041726678848] Epoch[260] Batch[0] avg_epoch_loss=2.045194\n",
      "[05/22/2025 04:02:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=2.0451937465200447\n",
      "[05/22/2025 04:02:47 INFO 140041726678848] Epoch[260] Batch[5] avg_epoch_loss=2.026772\n",
      "[05/22/2025 04:02:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.026771754977786\n",
      "[05/22/2025 04:02:47 INFO 140041726678848] Epoch[260] Batch [5]#011Speed: 2217.12 samples/sec#011loss=2.026772\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] Epoch[260] Batch[10] avg_epoch_loss=2.123444\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=260, batch=10 train loss <loss>=2.2394501887875835\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] Epoch[260] Batch [10]#011Speed: 2031.47 samples/sec#011loss=2.239450\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] processed a total of 4590 examples\n",
      "#metrics {\"StartTime\": 1747886565.6818645, \"EndTime\": 1747886568.232552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2550.4355430603027, \"count\": 1, \"min\": 2550.4355430603027, \"max\": 2550.4355430603027}}}\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1799.630869117375 records/second\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] #progress_metric: host=algo-1, completed 65.25 % of epochs\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.123443770345876\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] Epoch[261] Batch[0] avg_epoch_loss=2.018534\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.0185336174571966\n",
      "[05/22/2025 04:02:49 INFO 140041726678848] Epoch[261] Batch[5] avg_epoch_loss=2.169521\n",
      "[05/22/2025 04:02:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.169521204347334\n",
      "[05/22/2025 04:02:49 INFO 140041726678848] Epoch[261] Batch [5]#011Speed: 2245.37 samples/sec#011loss=2.169521\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] Epoch[261] Batch[10] avg_epoch_loss=2.204698\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=2.24691012580039\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] Epoch[261] Batch [10]#011Speed: 1998.28 samples/sec#011loss=2.246910\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] processed a total of 4733 examples\n",
      "#metrics {\"StartTime\": 1747886568.2326117, \"EndTime\": 1747886570.7803464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2547.480821609497, \"count\": 1, \"min\": 2547.480821609497, \"max\": 2547.480821609497}}}\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1857.8492069604908 records/second\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] #progress_metric: host=algo-1, completed 65.5 % of epochs\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=261, train loss <loss>=2.204697986825996\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:51 INFO 140041726678848] Epoch[262] Batch[0] avg_epoch_loss=2.092935\n",
      "[05/22/2025 04:02:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.0929354729259466\n",
      "[05/22/2025 04:02:52 INFO 140041726678848] Epoch[262] Batch[5] avg_epoch_loss=2.030815\n",
      "[05/22/2025 04:02:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.0308149829119686\n",
      "[05/22/2025 04:02:52 INFO 140041726678848] Epoch[262] Batch [5]#011Speed: 2268.95 samples/sec#011loss=2.030815\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] Epoch[262] Batch[10] avg_epoch_loss=2.061721\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=2.098808740560621\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] Epoch[262] Batch [10]#011Speed: 2011.05 samples/sec#011loss=2.098809\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] processed a total of 4656 examples\n",
      "#metrics {\"StartTime\": 1747886570.7804067, \"EndTime\": 1747886573.3142617, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2533.6008071899414, \"count\": 1, \"min\": 2533.6008071899414, \"max\": 2533.6008071899414}}}\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1837.6358617104795 records/second\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] #progress_metric: host=algo-1, completed 65.75 % of epochs\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.0617212363886286\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] Epoch[263] Batch[0] avg_epoch_loss=2.121130\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.121129908912166\n",
      "[05/22/2025 04:02:54 INFO 140041726678848] Epoch[263] Batch[5] avg_epoch_loss=2.224084\n",
      "[05/22/2025 04:02:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.224084368438834\n",
      "[05/22/2025 04:02:54 INFO 140041726678848] Epoch[263] Batch [5]#011Speed: 2280.25 samples/sec#011loss=2.224084\n",
      "[05/22/2025 04:02:55 INFO 140041726678848] processed a total of 4432 examples\n",
      "#metrics {\"StartTime\": 1747886573.314321, \"EndTime\": 1747886575.6814544, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2366.8017387390137, \"count\": 1, \"min\": 2366.8017387390137, \"max\": 2366.8017387390137}}}\n",
      "[05/22/2025 04:02:55 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1872.4918476925097 records/second\n",
      "[05/22/2025 04:02:55 INFO 140041726678848] #progress_metric: host=algo-1, completed 66.0 % of epochs\n",
      "[05/22/2025 04:02:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=263, train loss <loss>=2.271190903287688\n",
      "[05/22/2025 04:02:55 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:56 INFO 140041726678848] Epoch[264] Batch[0] avg_epoch_loss=2.160736\n",
      "[05/22/2025 04:02:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.160735608209215\n",
      "[05/22/2025 04:02:57 INFO 140041726678848] Epoch[264] Batch[5] avg_epoch_loss=2.087013\n",
      "[05/22/2025 04:02:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.0870129104534962\n",
      "[05/22/2025 04:02:57 INFO 140041726678848] Epoch[264] Batch [5]#011Speed: 2270.25 samples/sec#011loss=2.087013\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] Epoch[264] Batch[10] avg_epoch_loss=2.056066\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=2.018929054583101\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] Epoch[264] Batch [10]#011Speed: 1997.50 samples/sec#011loss=2.018929\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] processed a total of 4709 examples\n",
      "#metrics {\"StartTime\": 1747886575.6815202, \"EndTime\": 1747886578.224683, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.8521633148193, \"count\": 1, \"min\": 2542.8521633148193, \"max\": 2542.8521633148193}}}\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1851.7915816564512 records/second\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] #progress_metric: host=algo-1, completed 66.25 % of epochs\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.0560657032396805\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] Epoch[265] Batch[0] avg_epoch_loss=2.106053\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.106053409703856\n",
      "[05/22/2025 04:02:59 INFO 140041726678848] Epoch[265] Batch[5] avg_epoch_loss=2.201214\n",
      "[05/22/2025 04:02:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.2012142416452067\n",
      "[05/22/2025 04:02:59 INFO 140041726678848] Epoch[265] Batch [5]#011Speed: 2247.20 samples/sec#011loss=2.201214\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] Epoch[265] Batch[10] avg_epoch_loss=2.187596\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=2.1712540454482183\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] Epoch[265] Batch [10]#011Speed: 1986.64 samples/sec#011loss=2.171254\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] processed a total of 4618 examples\n",
      "#metrics {\"StartTime\": 1747886578.2247448, \"EndTime\": 1747886580.775241, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2550.2381324768066, \"count\": 1, \"min\": 2550.2381324768066, \"max\": 2550.2381324768066}}}\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.7491615515273 records/second\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] #progress_metric: host=algo-1, completed 66.5 % of epochs\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.1875959706465755\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:01 INFO 140041726678848] Epoch[266] Batch[0] avg_epoch_loss=2.221576\n",
      "[05/22/2025 04:03:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.221575968515103\n",
      "[05/22/2025 04:03:02 INFO 140041726678848] Epoch[266] Batch[5] avg_epoch_loss=2.199505\n",
      "[05/22/2025 04:03:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.199505483829807\n",
      "[05/22/2025 04:03:02 INFO 140041726678848] Epoch[266] Batch [5]#011Speed: 2230.91 samples/sec#011loss=2.199505\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] Epoch[266] Batch[10] avg_epoch_loss=2.314432\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=2.452344184994432\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] Epoch[266] Batch [10]#011Speed: 2010.37 samples/sec#011loss=2.452344\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] processed a total of 4702 examples\n",
      "#metrics {\"StartTime\": 1747886580.7753012, \"EndTime\": 1747886583.3575797, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2581.9859504699707, \"count\": 1, \"min\": 2581.9859504699707, \"max\": 2581.9859504699707}}}\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1821.0156230696002 records/second\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] #progress_metric: host=algo-1, completed 66.75 % of epochs\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.314432166177364\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] Epoch[267] Batch[0] avg_epoch_loss=2.033029\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.0330293990986914\n",
      "[05/22/2025 04:03:04 INFO 140041726678848] Epoch[267] Batch[5] avg_epoch_loss=2.117537\n",
      "[05/22/2025 04:03:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.1175374439582173\n",
      "[05/22/2025 04:03:04 INFO 140041726678848] Epoch[267] Batch [5]#011Speed: 2269.26 samples/sec#011loss=2.117537\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] Epoch[267] Batch[10] avg_epoch_loss=2.260255\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=2.4315163253410357\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] Epoch[267] Batch [10]#011Speed: 1973.63 samples/sec#011loss=2.431516\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] processed a total of 4548 examples\n",
      "#metrics {\"StartTime\": 1747886583.3576407, \"EndTime\": 1747886585.921603, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2563.7168884277344, \"count\": 1, \"min\": 2563.7168884277344, \"max\": 2563.7168884277344}}}\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.9251327628833 records/second\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] #progress_metric: host=algo-1, completed 67.0 % of epochs\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.2602551173140437\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:06 INFO 140041726678848] Epoch[268] Batch[0] avg_epoch_loss=2.107744\n",
      "[05/22/2025 04:03:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.107744450558533\n",
      "[05/22/2025 04:03:07 INFO 140041726678848] Epoch[268] Batch[5] avg_epoch_loss=2.102267\n",
      "[05/22/2025 04:03:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.1022671909799553\n",
      "[05/22/2025 04:03:07 INFO 140041726678848] Epoch[268] Batch [5]#011Speed: 2270.55 samples/sec#011loss=2.102267\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] Epoch[268] Batch[10] avg_epoch_loss=2.131531\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=268, batch=10 train loss <loss>=2.1666469106695434\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] Epoch[268] Batch [10]#011Speed: 2054.24 samples/sec#011loss=2.166647\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] processed a total of 4506 examples\n",
      "#metrics {\"StartTime\": 1747886585.9216638, \"EndTime\": 1747886588.4566042, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.6839427948, \"count\": 1, \"min\": 2534.6839427948, \"max\": 2534.6839427948}}}\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1777.6737318242485 records/second\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] #progress_metric: host=algo-1, completed 67.25 % of epochs\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.131530699929768\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] Epoch[269] Batch[0] avg_epoch_loss=2.073568\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=2.0735678895810135\n",
      "[05/22/2025 04:03:09 INFO 140041726678848] Epoch[269] Batch[5] avg_epoch_loss=2.072379\n",
      "[05/22/2025 04:03:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=2.0723790180798187\n",
      "[05/22/2025 04:03:09 INFO 140041726678848] Epoch[269] Batch [5]#011Speed: 2287.14 samples/sec#011loss=2.072379\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] Epoch[269] Batch[10] avg_epoch_loss=2.102755\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=269, batch=10 train loss <loss>=2.1392058306653676\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] Epoch[269] Batch [10]#011Speed: 2028.48 samples/sec#011loss=2.139206\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] processed a total of 4670 examples\n",
      "#metrics {\"StartTime\": 1747886588.4566653, \"EndTime\": 1747886590.9733527, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2516.4425373077393, \"count\": 1, \"min\": 2516.4425373077393, \"max\": 2516.4425373077393}}}\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1855.7312930906091 records/second\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 67.5 % of epochs\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=269, train loss <loss>=2.1027548419823407\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:11 INFO 140041726678848] Epoch[270] Batch[0] avg_epoch_loss=2.006003\n",
      "[05/22/2025 04:03:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=2.0060033309698637\n",
      "[05/22/2025 04:03:12 INFO 140041726678848] Epoch[270] Batch[5] avg_epoch_loss=2.159276\n",
      "[05/22/2025 04:03:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=2.159276428449216\n",
      "[05/22/2025 04:03:12 INFO 140041726678848] Epoch[270] Batch [5]#011Speed: 2246.62 samples/sec#011loss=2.159276\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] Epoch[270] Batch[10] avg_epoch_loss=2.184166\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=2.2140342797362194\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] Epoch[270] Batch [10]#011Speed: 2083.79 samples/sec#011loss=2.214034\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] processed a total of 4503 examples\n",
      "#metrics {\"StartTime\": 1747886590.9734087, \"EndTime\": 1747886593.4831, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2509.439468383789, \"count\": 1, \"min\": 2509.439468383789, \"max\": 2509.439468383789}}}\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.3610451536592 records/second\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] #progress_metric: host=algo-1, completed 67.75 % of epochs\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=270, train loss <loss>=2.1841663608523993\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] Epoch[271] Batch[0] avg_epoch_loss=2.086800\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=2.0868004202046215\n",
      "[05/22/2025 04:03:14 INFO 140041726678848] Epoch[271] Batch[5] avg_epoch_loss=2.077081\n",
      "[05/22/2025 04:03:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=2.077080968051109\n",
      "[05/22/2025 04:03:14 INFO 140041726678848] Epoch[271] Batch [5]#011Speed: 2314.03 samples/sec#011loss=2.077081\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] Epoch[271] Batch[10] avg_epoch_loss=2.133768\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=271, batch=10 train loss <loss>=2.2017914701941814\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] Epoch[271] Batch [10]#011Speed: 2022.94 samples/sec#011loss=2.201791\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] processed a total of 4602 examples\n",
      "#metrics {\"StartTime\": 1747886593.4831595, \"EndTime\": 1747886595.987221, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2503.774404525757, \"count\": 1, \"min\": 2503.774404525757, \"max\": 2503.774404525757}}}\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1837.9607886453173 records/second\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 68.0 % of epochs\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=271, train loss <loss>=2.1337675599343235\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:16 INFO 140041726678848] Epoch[272] Batch[0] avg_epoch_loss=2.049540\n",
      "[05/22/2025 04:03:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=2.0495400205752365\n",
      "[05/22/2025 04:03:17 INFO 140041726678848] Epoch[272] Batch[5] avg_epoch_loss=2.164182\n",
      "[05/22/2025 04:03:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=2.1641815797257795\n",
      "[05/22/2025 04:03:17 INFO 140041726678848] Epoch[272] Batch [5]#011Speed: 2281.46 samples/sec#011loss=2.164182\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] Epoch[272] Batch[10] avg_epoch_loss=2.095486\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=2.0130507845124583\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] Epoch[272] Batch [10]#011Speed: 1990.32 samples/sec#011loss=2.013051\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] processed a total of 4672 examples\n",
      "#metrics {\"StartTime\": 1747886595.9872808, \"EndTime\": 1747886598.5292864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2541.6617393493652, \"count\": 1, \"min\": 2541.6617393493652, \"max\": 2541.6617393493652}}}\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1838.0930121131976 records/second\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] #progress_metric: host=algo-1, completed 68.25 % of epochs\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=272, train loss <loss>=2.0954857637197244\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] Epoch[273] Batch[0] avg_epoch_loss=2.063702\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=2.063702487733157\n",
      "[05/22/2025 04:03:19 INFO 140041726678848] Epoch[273] Batch[5] avg_epoch_loss=2.169467\n",
      "[05/22/2025 04:03:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=2.1694670566029255\n",
      "[05/22/2025 04:03:19 INFO 140041726678848] Epoch[273] Batch [5]#011Speed: 2255.55 samples/sec#011loss=2.169467\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] Epoch[273] Batch[10] avg_epoch_loss=2.400984\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=273, batch=10 train loss <loss>=2.6788053856660636\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] Epoch[273] Batch [10]#011Speed: 2027.35 samples/sec#011loss=2.678805\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] processed a total of 4576 examples\n",
      "#metrics {\"StartTime\": 1747886598.529344, \"EndTime\": 1747886601.0553615, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2525.747299194336, \"count\": 1, \"min\": 2525.747299194336, \"max\": 2525.747299194336}}}\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1811.6649241089249 records/second\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] #progress_metric: host=algo-1, completed 68.5 % of epochs\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=273, train loss <loss>=2.400984478904352\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] Epoch[274] Batch[0] avg_epoch_loss=2.294411\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=2.2944107565423164\n",
      "[05/22/2025 04:03:22 INFO 140041726678848] Epoch[274] Batch[5] avg_epoch_loss=2.255412\n",
      "[05/22/2025 04:03:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=2.2554115119826466\n",
      "[05/22/2025 04:03:22 INFO 140041726678848] Epoch[274] Batch [5]#011Speed: 2281.38 samples/sec#011loss=2.255412\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] Epoch[274] Batch[10] avg_epoch_loss=2.333920\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=274, batch=10 train loss <loss>=2.428130790863377\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] Epoch[274] Batch [10]#011Speed: 2016.34 samples/sec#011loss=2.428131\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] processed a total of 4663 examples\n",
      "#metrics {\"StartTime\": 1747886601.0554216, \"EndTime\": 1747886603.5882645, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2532.5801372528076, \"count\": 1, \"min\": 2532.5801372528076, \"max\": 2532.5801372528076}}}\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1841.1415272783138 records/second\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 68.75 % of epochs\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=274, train loss <loss>=2.3339202751102515\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:24 INFO 140041726678848] Epoch[275] Batch[0] avg_epoch_loss=2.145881\n",
      "[05/22/2025 04:03:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=2.1458813639685412\n",
      "[05/22/2025 04:03:24 INFO 140041726678848] Epoch[275] Batch[5] avg_epoch_loss=2.233757\n",
      "[05/22/2025 04:03:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=2.233756945411099\n",
      "[05/22/2025 04:03:24 INFO 140041726678848] Epoch[275] Batch [5]#011Speed: 2278.51 samples/sec#011loss=2.233757\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] Epoch[275] Batch[10] avg_epoch_loss=2.133497\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=275, batch=10 train loss <loss>=2.013184572487472\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] Epoch[275] Batch [10]#011Speed: 2027.08 samples/sec#011loss=2.013185\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] processed a total of 4592 examples\n",
      "#metrics {\"StartTime\": 1747886603.588324, \"EndTime\": 1747886606.1070924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2518.5177326202393, \"count\": 1, \"min\": 2518.5177326202393, \"max\": 2518.5177326202393}}}\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1823.2294444606948 records/second\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] #progress_metric: host=algo-1, completed 69.0 % of epochs\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=275, train loss <loss>=2.1334967759003596\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] Epoch[276] Batch[0] avg_epoch_loss=2.113456\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=2.1134559274516285\n",
      "[05/22/2025 04:03:27 INFO 140041726678848] Epoch[276] Batch[5] avg_epoch_loss=2.090510\n",
      "[05/22/2025 04:03:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=2.090509948503909\n",
      "[05/22/2025 04:03:27 INFO 140041726678848] Epoch[276] Batch [5]#011Speed: 2216.48 samples/sec#011loss=2.090510\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] Epoch[276] Batch[10] avg_epoch_loss=2.111744\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=2.1372244854015867\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] Epoch[276] Batch [10]#011Speed: 2025.55 samples/sec#011loss=2.137224\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] processed a total of 4574 examples\n",
      "#metrics {\"StartTime\": 1747886606.1071537, \"EndTime\": 1747886608.6594818, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2552.065849304199, \"count\": 1, \"min\": 2552.065849304199, \"max\": 2552.065849304199}}}\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1792.2085397880223 records/second\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 69.25 % of epochs\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=276, train loss <loss>=2.1117438289119446\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:29 INFO 140041726678848] Epoch[277] Batch[0] avg_epoch_loss=2.012956\n",
      "[05/22/2025 04:03:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=2.0129556294804427\n",
      "[05/22/2025 04:03:30 INFO 140041726678848] Epoch[277] Batch[5] avg_epoch_loss=2.146563\n",
      "[05/22/2025 04:03:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=2.146562764621613\n",
      "[05/22/2025 04:03:30 INFO 140041726678848] Epoch[277] Batch [5]#011Speed: 2260.33 samples/sec#011loss=2.146563\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] Epoch[277] Batch[10] avg_epoch_loss=2.117162\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=277, batch=10 train loss <loss>=2.0818806331778954\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] Epoch[277] Batch [10]#011Speed: 1993.79 samples/sec#011loss=2.081881\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] processed a total of 4515 examples\n",
      "#metrics {\"StartTime\": 1747886608.6595442, \"EndTime\": 1747886611.2126398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2552.663803100586, \"count\": 1, \"min\": 2552.663803100586, \"max\": 2552.663803100586}}}\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1768.674480585125 records/second\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] #progress_metric: host=algo-1, completed 69.5 % of epochs\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=277, train loss <loss>=2.1171617957835593\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] Epoch[278] Batch[0] avg_epoch_loss=1.952386\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=1.952385917272759\n",
      "[05/22/2025 04:03:32 INFO 140041726678848] Epoch[278] Batch[5] avg_epoch_loss=1.982834\n",
      "[05/22/2025 04:03:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=1.9828337150409474\n",
      "[05/22/2025 04:03:32 INFO 140041726678848] Epoch[278] Batch [5]#011Speed: 2196.02 samples/sec#011loss=1.982834\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] Epoch[278] Batch[10] avg_epoch_loss=2.103239\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=2.2477257131733714\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] Epoch[278] Batch [10]#011Speed: 2009.47 samples/sec#011loss=2.247726\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] processed a total of 4597 examples\n",
      "#metrics {\"StartTime\": 1747886611.2127023, \"EndTime\": 1747886613.801005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2587.97025680542, \"count\": 1, \"min\": 2587.97025680542, \"max\": 2587.97025680542}}}\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1776.2336757096564 records/second\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 69.75 % of epochs\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=278, train loss <loss>=2.103239168737504\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:34 INFO 140041726678848] Epoch[279] Batch[0] avg_epoch_loss=1.993597\n",
      "[05/22/2025 04:03:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=1.993597153831431\n",
      "[05/22/2025 04:03:35 INFO 140041726678848] Epoch[279] Batch[5] avg_epoch_loss=2.002925\n",
      "[05/22/2025 04:03:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=2.0029253602116395\n",
      "[05/22/2025 04:03:35 INFO 140041726678848] Epoch[279] Batch [5]#011Speed: 2215.27 samples/sec#011loss=2.002925\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] Epoch[279] Batch[10] avg_epoch_loss=2.084894\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=2.183256466192233\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] Epoch[279] Batch [10]#011Speed: 1957.67 samples/sec#011loss=2.183256\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] processed a total of 4642 examples\n",
      "#metrics {\"StartTime\": 1747886613.8010645, \"EndTime\": 1747886616.3869433, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2585.6237411499023, \"count\": 1, \"min\": 2585.6237411499023, \"max\": 2585.6237411499023}}}\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1795.2434494453498 records/second\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 70.0 % of epochs\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=279, train loss <loss>=2.084894044748273\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] Epoch[280] Batch[0] avg_epoch_loss=1.971065\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=1.9710649859931793\n",
      "[05/22/2025 04:03:37 INFO 140041726678848] Epoch[280] Batch[5] avg_epoch_loss=1.963411\n",
      "[05/22/2025 04:03:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=1.9634107605297653\n",
      "[05/22/2025 04:03:37 INFO 140041726678848] Epoch[280] Batch [5]#011Speed: 2214.03 samples/sec#011loss=1.963411\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] Epoch[280] Batch[10] avg_epoch_loss=2.115505\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=2.2980185731747635\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] Epoch[280] Batch [10]#011Speed: 1964.38 samples/sec#011loss=2.298019\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] processed a total of 4638 examples\n",
      "#metrics {\"StartTime\": 1747886616.3870115, \"EndTime\": 1747886618.9776125, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2590.3382301330566, \"count\": 1, \"min\": 2590.3382301330566, \"max\": 2590.3382301330566}}}\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1790.4386291551516 records/second\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 70.25 % of epochs\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=280, train loss <loss>=2.1155052208229463\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:39 INFO 140041726678848] Epoch[281] Batch[0] avg_epoch_loss=2.018122\n",
      "[05/22/2025 04:03:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=2.018122003975849\n",
      "[05/22/2025 04:03:40 INFO 140041726678848] Epoch[281] Batch[5] avg_epoch_loss=2.015269\n",
      "[05/22/2025 04:03:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=2.0152694373637017\n",
      "[05/22/2025 04:03:40 INFO 140041726678848] Epoch[281] Batch [5]#011Speed: 2186.76 samples/sec#011loss=2.015269\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] Epoch[281] Batch[10] avg_epoch_loss=2.045460\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=281, batch=10 train loss <loss>=2.081688855007656\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] Epoch[281] Batch [10]#011Speed: 1967.02 samples/sec#011loss=2.081689\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] processed a total of 4619 examples\n",
      "#metrics {\"StartTime\": 1747886618.977673, \"EndTime\": 1747886621.602157, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2624.229669570923, \"count\": 1, \"min\": 2624.229669570923, \"max\": 2624.229669570923}}}\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1760.0781686419841 records/second\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 70.5 % of epochs\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=281, train loss <loss>=2.045460081747317\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:42 INFO 140041726678848] Epoch[282] Batch[0] avg_epoch_loss=1.941126\n",
      "[05/22/2025 04:03:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=1.9411263582701141\n",
      "[05/22/2025 04:03:43 INFO 140041726678848] Epoch[282] Batch[5] avg_epoch_loss=2.143804\n",
      "[05/22/2025 04:03:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=2.143804129619641\n",
      "[05/22/2025 04:03:43 INFO 140041726678848] Epoch[282] Batch [5]#011Speed: 2196.09 samples/sec#011loss=2.143804\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] Epoch[282] Batch[10] avg_epoch_loss=2.081190\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=282, batch=10 train loss <loss>=2.006053899072592\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] Epoch[282] Batch [10]#011Speed: 1968.41 samples/sec#011loss=2.006054\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] processed a total of 4615 examples\n",
      "#metrics {\"StartTime\": 1747886621.6022155, \"EndTime\": 1747886624.1972282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2594.7606563568115, \"count\": 1, \"min\": 2594.7606563568115, \"max\": 2594.7606563568115}}}\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1778.5231267482745 records/second\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] #progress_metric: host=algo-1, completed 70.75 % of epochs\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=282, train loss <loss>=2.0811903884618914\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] Epoch[283] Batch[0] avg_epoch_loss=2.225425\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=2.2254249895601337\n",
      "[05/22/2025 04:03:45 INFO 140041726678848] Epoch[283] Batch[5] avg_epoch_loss=2.112742\n",
      "[05/22/2025 04:03:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=2.112741766280392\n",
      "[05/22/2025 04:03:45 INFO 140041726678848] Epoch[283] Batch [5]#011Speed: 2206.83 samples/sec#011loss=2.112742\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] Epoch[283] Batch[10] avg_epoch_loss=2.106553\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=283, batch=10 train loss <loss>=2.0991253893200166\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] Epoch[283] Batch [10]#011Speed: 2052.24 samples/sec#011loss=2.099125\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] processed a total of 4513 examples\n",
      "#metrics {\"StartTime\": 1747886624.1972883, \"EndTime\": 1747886626.7610767, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2563.532829284668, \"count\": 1, \"min\": 2563.532829284668, \"max\": 2563.532829284668}}}\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1760.400754235834 records/second\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 71.0 % of epochs\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=283, train loss <loss>=2.1065525040256756\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:47 INFO 140041726678848] Epoch[284] Batch[0] avg_epoch_loss=2.148447\n",
      "[05/22/2025 04:03:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=2.1484474233104818\n",
      "[05/22/2025 04:03:48 INFO 140041726678848] Epoch[284] Batch[5] avg_epoch_loss=2.136024\n",
      "[05/22/2025 04:03:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=2.1360237331149663\n",
      "[05/22/2025 04:03:48 INFO 140041726678848] Epoch[284] Batch [5]#011Speed: 2291.32 samples/sec#011loss=2.136024\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] Epoch[284] Batch[10] avg_epoch_loss=2.197257\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=284, batch=10 train loss <loss>=2.2707369458170934\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] Epoch[284] Batch [10]#011Speed: 2007.70 samples/sec#011loss=2.270737\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] processed a total of 4700 examples\n",
      "#metrics {\"StartTime\": 1747886626.7611358, \"EndTime\": 1747886629.3121154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2550.731658935547, \"count\": 1, \"min\": 2550.731658935547, \"max\": 2550.731658935547}}}\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1842.5477691765795 records/second\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 71.25 % of epochs\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=284, train loss <loss>=2.197257011615933\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] Epoch[285] Batch[0] avg_epoch_loss=2.049505\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=2.0495045413418707\n",
      "[05/22/2025 04:03:50 INFO 140041726678848] Epoch[285] Batch[5] avg_epoch_loss=2.250559\n",
      "[05/22/2025 04:03:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=2.2505589905011716\n",
      "[05/22/2025 04:03:50 INFO 140041726678848] Epoch[285] Batch [5]#011Speed: 2345.88 samples/sec#011loss=2.250559\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] Epoch[285] Batch[10] avg_epoch_loss=2.326205\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=2.4169807145218543\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] Epoch[285] Batch [10]#011Speed: 2011.07 samples/sec#011loss=2.416981\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] processed a total of 4652 examples\n",
      "#metrics {\"StartTime\": 1747886629.312173, \"EndTime\": 1747886631.8116963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2499.236583709717, \"count\": 1, \"min\": 2499.236583709717, \"max\": 2499.236583709717}}}\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1861.301103688785 records/second\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 71.5 % of epochs\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=285, train loss <loss>=2.326205228692391\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:52 INFO 140041726678848] Epoch[286] Batch[0] avg_epoch_loss=2.066531\n",
      "[05/22/2025 04:03:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=2.0665313108992205\n",
      "[05/22/2025 04:03:53 INFO 140041726678848] Epoch[286] Batch[5] avg_epoch_loss=2.185694\n",
      "[05/22/2025 04:03:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=2.185693889524464\n",
      "[05/22/2025 04:03:53 INFO 140041726678848] Epoch[286] Batch [5]#011Speed: 2270.99 samples/sec#011loss=2.185694\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] Epoch[286] Batch[10] avg_epoch_loss=2.203128\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=286, batch=10 train loss <loss>=2.2240496187273804\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] Epoch[286] Batch [10]#011Speed: 1949.98 samples/sec#011loss=2.224050\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] processed a total of 4619 examples\n",
      "#metrics {\"StartTime\": 1747886631.811758, \"EndTime\": 1747886634.3829358, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2570.9197521209717, \"count\": 1, \"min\": 2570.9197521209717, \"max\": 2570.9197521209717}}}\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.5666420521718 records/second\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 71.75 % of epochs\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=286, train loss <loss>=2.203128311889426\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] Epoch[287] Batch[0] avg_epoch_loss=2.046450\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=2.0464500648141706\n",
      "[05/22/2025 04:03:55 INFO 140041726678848] Epoch[287] Batch[5] avg_epoch_loss=2.015746\n",
      "[05/22/2025 04:03:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=2.0157460507943\n",
      "[05/22/2025 04:03:55 INFO 140041726678848] Epoch[287] Batch [5]#011Speed: 2188.97 samples/sec#011loss=2.015746\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] Epoch[287] Batch[10] avg_epoch_loss=2.059423\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=2.111834512893235\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] Epoch[287] Batch [10]#011Speed: 1938.28 samples/sec#011loss=2.111835\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] processed a total of 4691 examples\n",
      "#metrics {\"StartTime\": 1747886634.3830018, \"EndTime\": 1747886636.995526, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2612.229347229004, \"count\": 1, \"min\": 2612.229347229004, \"max\": 2612.229347229004}}}\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1795.7225029798683 records/second\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 72.0 % of epochs\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=287, train loss <loss>=2.059422624475634\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] Loading parameters from best epoch (247)\n",
      "#metrics {\"StartTime\": 1747886636.9955842, \"EndTime\": 1747886637.0016906, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 5.7582855224609375, \"count\": 1, \"min\": 5.7582855224609375, \"max\": 5.7582855224609375}}}\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] stopping training now\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Final loss: 1.984899613171315 (occurred at epoch 247)\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] #quality_metric: host=algo-1, train final_loss <loss>=1.984899613171315\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Worker algo-1 finished training.\n",
      "[05/22/2025 04:03:57 WARNING 140041726678848] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747886637.001743, \"EndTime\": 1747886637.0547369, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 52.58369445800781, \"count\": 1, \"min\": 52.58369445800781, \"max\": 52.58369445800781}}}\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747886637.054791, \"EndTime\": 1747886637.07669, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 74.56636428833008, \"count\": 1, \"min\": 74.56636428833008, \"max\": 74.56636428833008}}}\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886637.0767348, \"EndTime\": 1747886637.0806744, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 3.9129257202148438, \"count\": 1, \"min\": 3.9129257202148438, \"max\": 3.9129257202148438}}}\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Successfully serialized the model for prediction.\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] No test data passed, skipping evaluation.\n",
      "#metrics {\"StartTime\": 1747886637.0807133, \"EndTime\": 1747886637.0837772, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 3.8564205169677734, \"count\": 1, \"min\": 3.8564205169677734, \"max\": 3.8564205169677734}, \"totaltime\": {\"sum\": 738025.7954597473, \"count\": 1, \"min\": 738025.7954597473, \"max\": 738025.7954597473}}}\n",
      "\n",
      "2025-05-22 04:04:15 Uploading - Uploading generated training model\n",
      "2025-05-22 04:04:15 Completed - Training job completed\n",
      "Training seconds: 907\n",
      "Billable seconds: 907\n",
      "CPU times: total: 25.7 s\n",
      "Wall time: 16min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ff2079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-22 04:04:15 Starting - Preparing the instances for training\n",
      "2025-05-22 04:04:15 Downloading - Downloading the training image\n",
      "2025-05-22 04:04:15 Training - Training image download completed. Training in progress.\n",
      "2025-05-22 04:04:15 Uploading - Uploading generated training model\n",
      "2025-05-22 04:04:15 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-22-03-48-30-015',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "966544f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/22/25 00:37:32] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-05-37-31-368 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/22/25 00:37:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-05-37-31-368 \u001b]8;id=770152;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=687007;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-05-37-31-368                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=41190;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=613768;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-05-37-31-368                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/22/25 00:37:33] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-05-37-31-368                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/22/25 00:37:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=336164;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=933419;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-05-37-31-368                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f677e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_to_excel(timeseries_list, output_filename='timeseries_export.xlsx'):\n",
    "    \"\"\"\n",
    "    Exporta los últimos 6 puntos de una lista de dataframes timeseries a un archivo Excel.\n",
    "    \n",
    "    Parámetros:\n",
    "    timeseries_list (list): Lista de DataFrames que contienen columnas 'material' y 'cantidad'\n",
    "    output_filename (str): Nombre del archivo Excel de salida\n",
    "    \n",
    "    Returns:\n",
    "    str: Ruta del archivo creado\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lista para almacenar todos los datos procesados\n",
    "    all_data = []\n",
    "    \n",
    "    # Procesar cada dataframe en la lista\n",
    "    for i, df in enumerate(timeseries_list):\n",
    "        # Verificar que el dataframe tiene las columnas necesarias\n",
    "        if 'material' not in df.columns or 'cantidad' not in df.columns:\n",
    "            print(f\"Advertencia: DataFrame {i+1} no tiene las columnas 'material' y/o 'cantidad'\")\n",
    "            continue\n",
    "        \n",
    "        # Tomar los últimos 6 puntos\n",
    "        last_6_points = df.tail(6)\n",
    "        \n",
    "        # Agregar solo las columnas necesarias\n",
    "        data_to_add = last_6_points[['material', 'cantidad']].copy()\n",
    "        \n",
    "        # Opcional: agregar una columna para identificar de qué dataframe viene\n",
    "        data_to_add['dataframe_origen'] = f'TS_{i+1}'\n",
    "        \n",
    "        all_data.append(data_to_add)\n",
    "    \n",
    "    # Combinar todos los datos\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Si no quieres la columna de origen, descomenta la siguiente línea:\n",
    "        # final_df = final_df[['material', 'cantidad']]\n",
    "        \n",
    "        # Exportar a Excel\n",
    "        final_df.to_excel(output_filename, index=False)\n",
    "        print(f\"Archivo '{output_filename}' creado exitosamente con {len(final_df)} registros\")\n",
    "        \n",
    "        return output_filename\n",
    "    else:\n",
    "        print(\"No se encontraron datos válidos para exportar\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cad0f8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'data_real.xlsx' creado exitosamente con 90 registros\n"
     ]
    }
   ],
   "source": [
    "archivo_creado = timeseries_to_excel(timeseries, 'data_real.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "dbaa02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "materiales = [df['material'].unique()[0] for df in timeseries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "f3e5bdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>28.570580</td>\n",
       "      <td>33.706036</td>\n",
       "      <td>37.759369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>40.106171</td>\n",
       "      <td>44.941391</td>\n",
       "      <td>48.891117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>15.922655</td>\n",
       "      <td>17.287342</td>\n",
       "      <td>18.594730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>9.118885</td>\n",
       "      <td>10.537629</td>\n",
       "      <td>12.171485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>5.690591</td>\n",
       "      <td>10.755075</td>\n",
       "      <td>14.273312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>2.132280</td>\n",
       "      <td>6.541682</td>\n",
       "      <td>10.474480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01  28.570580  33.706036  37.759369\n",
       "2024-12-01  40.106171  44.941391  48.891117\n",
       "2025-01-01  15.922655  17.287342  18.594730\n",
       "2025-02-01   9.118885  10.537629  12.171485\n",
       "2025-03-01   5.690591  10.755075  14.273312\n",
       "2025-04-01   2.132280   6.541682  10.474480"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=0\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "060d36e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    33\n",
       "2024-12-01    44\n",
       "2025-01-01    17\n",
       "2025-02-01    10\n",
       "2025-03-01    14\n",
       "2025-04-01     4\n",
       "Freq: MS, Name: cantidad, dtype: int32"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[i].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "96ce0939",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_por_material = generar_predicciones_por_material(\n",
    "    materiales=materiales,\n",
    "    timeseries_list=timeseries_list,\n",
    "    vectores_cat=vectores_cat,\n",
    "    dynamic_list=dynamic_list,\n",
    "    predictor=predictor,\n",
    "    horizon_pred=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "e47761a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([20000337001, 20000400003, 20000815002, 20000815003, 20000837001, 20000837002, 20001016001, 20001374001, 20003147001, 20003257001, 20003257002, 20003257004, 20008046001, 25109225001, 25109232001])"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_por_material.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "21f49e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>3.511388</td>\n",
       "      <td>5.638802</td>\n",
       "      <td>7.351160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>10.944141</td>\n",
       "      <td>13.902410</td>\n",
       "      <td>17.068285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>4.117705</td>\n",
       "      <td>4.820570</td>\n",
       "      <td>5.672948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>2.737851</td>\n",
       "      <td>3.517854</td>\n",
       "      <td>4.493963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>2.222531</td>\n",
       "      <td>4.483961</td>\n",
       "      <td>6.030576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>-1.047628</td>\n",
       "      <td>1.319560</td>\n",
       "      <td>3.686026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01   3.511388   5.638802   7.351160\n",
       "2024-12-01  10.944141  13.902410  17.068285\n",
       "2025-01-01   4.117705   4.820570   5.672948\n",
       "2025-02-01   2.737851   3.517854   4.493963\n",
       "2025-03-01   2.222531   4.483961   6.030576\n",
       "2025-04-01  -1.047628   1.319560   3.686026"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_por_material[20000400003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "c15acda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado: mensual_modificado_completo.xlsx\n",
      "Orden de columnas: ['Material', 'Fecha', '0.1', '0.5', '0.9']\n",
      "Formato de fecha: YYYY-MM-DD\n"
     ]
    }
   ],
   "source": [
    "exportar_predicciones_consolidado(predicciones_por_material, \"mensual_modificado_completo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "982f5a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 23:28:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-04-06-24-816 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#5356\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5356</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 23:28:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-04-06-24-816 \u001b]8;id=565771;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=19646;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#5356\u001b\\\u001b[2m5356\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 23:28:27] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration with name:                             <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4995\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4995</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-04-06-24-816                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 23:28:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration with name:                             \u001b]8;id=136362;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=750951;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4995\u001b\\\u001b[2m4995\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-04-06-24-816                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint with name:                                           <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4985\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4985</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-04-06-24-816                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint with name:                                           \u001b]8;id=660670;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=695552;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4985\u001b\\\u001b[2m4985\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-04-06-24-816                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
