{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "293a981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:198: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/23/25 13:44:05] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/23/25 13:44:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=516125;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=765871;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\u001b\\\u001b[2m1352\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\Usuario\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "#importación de librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from pandas import DateOffset\n",
    "import boto3\n",
    "import sagemaker\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d70a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data_csv/27_materiales_mod.csv',sep=',',index_col=0,parse_dates=True,decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e02f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los materiales son [20000337001 20000400003 20000815002 20000815003 20000837001 20000837002\n",
      " 20001016001 20001374001 20001497002 20001770001 20003147001 20003257001\n",
      " 20003257002 20003257004 20003259001 20006083001 20007769001 20008046001\n",
      " 20008540001 25101938001 25101940001 25109220001 25109223001 25109225001\n",
      " 25109232001 25109241001 25110068001]\n"
     ]
    }
   ],
   "source": [
    "materiales = df['material'].unique()\n",
    "print(f'Los materiales son {materiales}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6478e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = []\n",
    "materiales = df['material'].unique()\n",
    "for mat in materiales:\n",
    "    serie = df[df['material'] == mat].sort_index()\n",
    "    timeseries.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08a2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumar_cantidades_fechas(lista_dataframes, fechas=['2023-11-01', '2023-11-02']):\n",
    "    \"\"\"\n",
    "    Suma la columna 'cantidad' para las fechas especificadas en cada dataframe\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha\n",
    "        fechas: Lista de fechas a considerar (por defecto '2023-11-01' y '2023-11-02')\n",
    "    \n",
    "    Returns:\n",
    "        Un diccionario con las sumas por cada dataframe\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        suma = 0\n",
    "        for fecha in fechas:\n",
    "            if fecha in df.index:\n",
    "                suma += df.loc[fecha, 'cantidad']\n",
    "        resultados[f'dataframe_{i}'] = suma\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e31e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = sumar_cantidades_fechas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "660f22ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataframe_0': 33.0,\n",
       " 'dataframe_1': 20.0,\n",
       " 'dataframe_2': 25.0,\n",
       " 'dataframe_3': 31.0,\n",
       " 'dataframe_4': 28.0,\n",
       " 'dataframe_5': 44.0,\n",
       " 'dataframe_6': 4.0,\n",
       " 'dataframe_7': 5.0,\n",
       " 'dataframe_8': 41.0,\n",
       " 'dataframe_9': 49.0,\n",
       " 'dataframe_10': 133.0,\n",
       " 'dataframe_11': 46.0,\n",
       " 'dataframe_12': 60.0,\n",
       " 'dataframe_13': 26.0,\n",
       " 'dataframe_14': 254.0,\n",
       " 'dataframe_15': 280.0,\n",
       " 'dataframe_16': 50.0,\n",
       " 'dataframe_17': 43.0,\n",
       " 'dataframe_18': 46.0,\n",
       " 'dataframe_19': 360.0,\n",
       " 'dataframe_20': 77.0,\n",
       " 'dataframe_21': 87.0,\n",
       " 'dataframe_22': 100.0,\n",
       " 'dataframe_23': 82.0,\n",
       " 'dataframe_24': 43.0,\n",
       " 'dataframe_25': 76.0,\n",
       " 'dataframe_26': 486.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1469fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_fechas(lista_dataframes, fechas=['2023-11-01', '2023-11-02']):\n",
    "    \"\"\"\n",
    "    Elimina los registros de las fechas especificadas en cada dataframe\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha\n",
    "        fechas: Lista de fechas a eliminar (por defecto '2023-11-01' y '2023-11-02')\n",
    "    \n",
    "    Returns:\n",
    "        Una nueva lista de dataframes sin los registros de las fechas indicadas\n",
    "    \"\"\"\n",
    "    nuevos_dataframes = []\n",
    "    \n",
    "    for df in lista_dataframes:\n",
    "        # Crear una copia para no modificar el original\n",
    "        df_nuevo = df.copy()\n",
    "        # Eliminar las fechas especificadas si existen en el índice\n",
    "        df_nuevo = df_nuevo.drop(fechas, errors='ignore')\n",
    "        nuevos_dataframes.append(df_nuevo)\n",
    "    \n",
    "    return nuevos_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a27fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = eliminar_fechas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f61924e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_por_mes(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Agrupa los datos por mes-año, sumando la columna 'cantidad' y manteniendo las columnas categóricas.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha en formato 'YYYY-MM-DD'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con datos agrupados por mes-año\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    dataframes_agrupados = []\n",
    "    \n",
    "    for df in lista_dataframes:\n",
    "        # Verificar que el índice sea de tipo datetime\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Crear una columna con el mes-año para agrupar\n",
    "        df_copia = df.copy()\n",
    "        df_copia['mes_anio'] = df_copia.index.strftime('%Y-%m')\n",
    "        \n",
    "        # Identificar columnas categóricas (todas excepto 'cantidad')\n",
    "        cols_categoricas = [col for col in df_copia.columns if col != 'cantidad' and col != 'mes_anio']\n",
    "        \n",
    "        # Realizar la agrupación\n",
    "        if cols_categoricas:\n",
    "            # Si hay columnas categóricas, agrupar por mes_anio y columnas categóricas\n",
    "            grupos = df_copia.groupby(['mes_anio'] + cols_categoricas)\n",
    "            # Sumar la cantidad para cada grupo\n",
    "            agrupado = grupos['cantidad'].sum().reset_index()\n",
    "            # Convertir 'mes_anio' en índice de datetime (primer día del mes)\n",
    "            agrupado['fecha'] = pd.to_datetime(agrupado['mes_anio'] + '-01')\n",
    "            agrupado = agrupado.set_index('fecha')\n",
    "            agrupado = agrupado.drop('mes_anio', axis=1)\n",
    "        else:\n",
    "            # Si no hay columnas categóricas, agrupar solo por mes_anio\n",
    "            agrupado = df_copia.groupby('mes_anio')['cantidad'].sum().reset_index()\n",
    "            agrupado['fecha'] = pd.to_datetime(agrupado['mes_anio'] + '-01')\n",
    "            agrupado = agrupado.set_index('fecha')\n",
    "            agrupado = agrupado.drop('mes_anio', axis=1)\n",
    "        \n",
    "        dataframes_agrupados.append(agrupado)\n",
    "    \n",
    "    return dataframes_agrupados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f46803",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = agrupar_por_mes(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7171f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_excel_simple(lista_dataframes, nombre_archivo='datos_simple.xlsx'):\n",
    "    \"\"\"\n",
    "    Versión simplificada que crea un solo Excel con todos los últimos 7 registros\n",
    "    \"\"\"\n",
    "    todos_los_datos = []\n",
    "    \n",
    "    for df in lista_dataframes:\n",
    "        if 'material' in df.columns and 'cantidad' in df.columns:\n",
    "            # Últimos 7 registros\n",
    "            ultimos = df.tail(7).copy()\n",
    "            # Convertir índice a columna\n",
    "            ultimos = ultimos.reset_index()\n",
    "            if ultimos.columns[0] != 'fecha':\n",
    "                ultimos = ultimos.rename(columns={ultimos.columns[0]: 'fecha'})\n",
    "            # Solo las columnas necesarias\n",
    "            todos_los_datos.append(ultimos[['fecha', 'material', 'cantidad']])\n",
    "    \n",
    "    if todos_los_datos:\n",
    "        resultado = pd.concat(todos_los_datos, ignore_index=True)\n",
    "        resultado.to_excel(nombre_archivo, index=False)\n",
    "        print(f\"Archivo '{nombre_archivo}' creado con {len(resultado)} registros\")\n",
    "        return resultado\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf47b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'datos_rmse_deepar.xlsx' creado con 189 registros\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>material</th>\n",
       "      <th>cantidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>20000337001</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>20000337001</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>20000337001</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>20000337001</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>20000337001</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>25110068001</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>25110068001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>25110068001</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>25110068001</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>25110068001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fecha     material  cantidad\n",
       "0   2024-11-01  20000337001      33.0\n",
       "1   2024-12-01  20000337001      44.0\n",
       "2   2025-01-01  20000337001      17.0\n",
       "3   2025-02-01  20000337001      10.0\n",
       "4   2025-03-01  20000337001      14.0\n",
       "..         ...          ...       ...\n",
       "184 2024-01-01  25110068001     134.0\n",
       "185 2024-02-01  25110068001       1.0\n",
       "186 2024-09-01  25110068001       2.0\n",
       "187 2024-11-01  25110068001       2.0\n",
       "188 2025-01-01  25110068001       1.0\n",
       "\n",
       "[189 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crear_excel_simple(timeseries,nombre_archivo='datos_rmse_deepar.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55b6fdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>Tipo_Producto</th>\n",
       "      <th>segmento_producto</th>\n",
       "      <th>supergrupo_producto</th>\n",
       "      <th>grupo_producto</th>\n",
       "      <th>subgrupo_producto</th>\n",
       "      <th>cantidad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fecha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>LILI PINK</td>\n",
       "      <td>JUVENIL</td>\n",
       "      <td>INTERIOR JUVENIL</td>\n",
       "      <td>PANTY PAQX3</td>\n",
       "      <td>ALGODON</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               material Tipo_Producto segmento_producto supergrupo_producto  \\\n",
       "fecha                                                                         \n",
       "2021-08-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2021-09-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2021-10-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2021-11-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2021-12-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-01-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-02-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-03-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-04-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-05-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-06-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-07-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-08-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-09-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-10-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-11-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2022-12-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-01-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-02-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-03-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-04-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-05-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-06-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-07-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-08-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-09-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-11-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2023-12-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-01-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-02-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-03-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-04-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-05-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-06-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-07-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-08-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-09-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-10-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-11-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2024-12-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2025-01-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2025-02-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2025-03-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2025-04-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "2025-05-01  20000337001     LILI PINK           JUVENIL    INTERIOR JUVENIL   \n",
       "\n",
       "           grupo_producto subgrupo_producto  cantidad  \n",
       "fecha                                                  \n",
       "2021-08-01    PANTY PAQX3           ALGODON      10.0  \n",
       "2021-09-01    PANTY PAQX3           ALGODON      12.0  \n",
       "2021-10-01    PANTY PAQX3           ALGODON      14.0  \n",
       "2021-11-01    PANTY PAQX3           ALGODON       1.0  \n",
       "2021-12-01    PANTY PAQX3           ALGODON      43.0  \n",
       "2022-01-01    PANTY PAQX3           ALGODON      21.0  \n",
       "2022-02-01    PANTY PAQX3           ALGODON      13.0  \n",
       "2022-03-01    PANTY PAQX3           ALGODON      18.0  \n",
       "2022-04-01    PANTY PAQX3           ALGODON      33.0  \n",
       "2022-05-01    PANTY PAQX3           ALGODON      26.0  \n",
       "2022-06-01    PANTY PAQX3           ALGODON      30.0  \n",
       "2022-07-01    PANTY PAQX3           ALGODON      16.0  \n",
       "2022-08-01    PANTY PAQX3           ALGODON      11.0  \n",
       "2022-09-01    PANTY PAQX3           ALGODON       6.0  \n",
       "2022-10-01    PANTY PAQX3           ALGODON      13.0  \n",
       "2022-11-01    PANTY PAQX3           ALGODON      19.0  \n",
       "2022-12-01    PANTY PAQX3           ALGODON      44.0  \n",
       "2023-01-01    PANTY PAQX3           ALGODON      28.0  \n",
       "2023-02-01    PANTY PAQX3           ALGODON      12.0  \n",
       "2023-03-01    PANTY PAQX3           ALGODON      14.0  \n",
       "2023-04-01    PANTY PAQX3           ALGODON      29.0  \n",
       "2023-05-01    PANTY PAQX3           ALGODON      26.0  \n",
       "2023-06-01    PANTY PAQX3           ALGODON      40.0  \n",
       "2023-07-01    PANTY PAQX3           ALGODON      47.0  \n",
       "2023-08-01    PANTY PAQX3           ALGODON      40.0  \n",
       "2023-09-01    PANTY PAQX3           ALGODON       9.0  \n",
       "2023-11-01    PANTY PAQX3           ALGODON      19.0  \n",
       "2023-12-01    PANTY PAQX3           ALGODON      13.0  \n",
       "2024-01-01    PANTY PAQX3           ALGODON      10.0  \n",
       "2024-02-01    PANTY PAQX3           ALGODON       4.0  \n",
       "2024-03-01    PANTY PAQX3           ALGODON      29.0  \n",
       "2024-04-01    PANTY PAQX3           ALGODON       5.0  \n",
       "2024-05-01    PANTY PAQX3           ALGODON       7.0  \n",
       "2024-06-01    PANTY PAQX3           ALGODON      57.0  \n",
       "2024-07-01    PANTY PAQX3           ALGODON      38.0  \n",
       "2024-08-01    PANTY PAQX3           ALGODON      14.0  \n",
       "2024-09-01    PANTY PAQX3           ALGODON      14.0  \n",
       "2024-10-01    PANTY PAQX3           ALGODON      18.0  \n",
       "2024-11-01    PANTY PAQX3           ALGODON      33.0  \n",
       "2024-12-01    PANTY PAQX3           ALGODON      44.0  \n",
       "2025-01-01    PANTY PAQX3           ALGODON      17.0  \n",
       "2025-02-01    PANTY PAQX3           ALGODON      10.0  \n",
       "2025-03-01    PANTY PAQX3           ALGODON      14.0  \n",
       "2025-04-01    PANTY PAQX3           ALGODON       4.0  \n",
       "2025-05-01    PANTY PAQX3           ALGODON       4.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a5bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_ultimo_registro(dataframes_agrupados):\n",
    "    \"\"\"\n",
    "    Elimina el último registro de cada dataframe en la lista.\n",
    "    \n",
    "    Args:\n",
    "        dataframes_agrupados: Lista de dataframes con datos agrupados por mes-año\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con el último registro eliminado en cada uno\n",
    "    \"\"\"\n",
    "    resultado = []\n",
    "    \n",
    "    for df in dataframes_agrupados:\n",
    "        # Si el dataframe tiene al menos un registro\n",
    "        if len(df) > 0:\n",
    "            # Eliminar el último registro\n",
    "            df_sin_ultimo = df.iloc[:-1].copy()\n",
    "            resultado.append(df_sin_ultimo)\n",
    "        else:\n",
    "            # Si el dataframe está vacío, agregarlo sin cambios\n",
    "            resultado.append(df.copy())\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eb5b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = eliminar_ultimo_registro(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2fea5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajustar_para_mantener_ratios(timeseries, resultados):\n",
    "    \"\"\"\n",
    "    Ajusta los valores de 2023-09 y 2023-10 sumando cantidades para que mantengan \n",
    "    los mismos ratios que 2022-09 y 2022-10, utilizando los valores de 'resultados'.\n",
    "    \n",
    "    Args:\n",
    "        timeseries: Lista de dataframes mensuales\n",
    "        resultados: Diccionario con las sumas de cantidades\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con las cantidades ajustadas\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    dataframes_ajustados = []\n",
    "    \n",
    "    for i, df in enumerate(timeseries):\n",
    "        df_ajustado = df.copy()\n",
    "        clave_resultado = f'dataframe_{i}'\n",
    "        \n",
    "        # Verificar que exista el valor en resultados\n",
    "        if clave_resultado in resultados:\n",
    "            valor_a_distribuir = resultados[clave_resultado]\n",
    "            \n",
    "            # 1. Calcular los ratios objetivo de 2022-09 y 2022-10\n",
    "            if '2022-09-01' in df_ajustado.index and '2022-10-01' in df_ajustado.index:\n",
    "                valor_sep_2022 = df_ajustado.loc['2022-09-01', 'cantidad']\n",
    "                valor_oct_2022 = df_ajustado.loc['2022-10-01', 'cantidad']\n",
    "                \n",
    "                # Ratio objetivo (proporción de sep respecto a la suma)\n",
    "                if valor_sep_2022 + valor_oct_2022 > 0:\n",
    "                    ratio_objetivo = valor_sep_2022 / (valor_sep_2022 + valor_oct_2022)\n",
    "                else:\n",
    "                    ratio_objetivo = 0.5\n",
    "                \n",
    "                # Valores actuales o cero si no existen\n",
    "                valor_sep_2023 = df_ajustado.loc['2023-09-01', 'cantidad'] if '2023-09-01' in df_ajustado.index else 0\n",
    "                valor_oct_2023 = df_ajustado.loc['2023-10-01', 'cantidad'] if '2023-10-01' in df_ajustado.index else 0\n",
    "                \n",
    "                # 2. Calcular cuánto agregar a cada mes para mantener el ratio objetivo\n",
    "                # Resolviendo el sistema de ecuaciones:\n",
    "                # (valor_sep_2023 + x) / (valor_sep_2023 + x + valor_oct_2023 + y) = ratio_objetivo\n",
    "                # x + y = valor_a_distribuir\n",
    "                \n",
    "                # Si ambos valores son cero, distribuimos según el ratio objetivo\n",
    "                if valor_sep_2023 == 0 and valor_oct_2023 == 0:\n",
    "                    incremento_sep = valor_a_distribuir * ratio_objetivo\n",
    "                    incremento_oct = valor_a_distribuir * (1 - ratio_objetivo)\n",
    "                else:\n",
    "                    # Para mantener el ratio: (a + x) / (a + b + x + y) = r, donde x + y = v\n",
    "                    # Resolviendo: x = (r*(a+b) - a) + r*v\n",
    "                    a = valor_sep_2023\n",
    "                    b = valor_oct_2023\n",
    "                    r = ratio_objetivo\n",
    "                    v = valor_a_distribuir\n",
    "                    \n",
    "                    # Calculamos los incrementos\n",
    "                    incremento_sep = max(0, (r*(a+b) - a) + r*v)\n",
    "                    incremento_oct = max(0, v - incremento_sep)\n",
    "                    \n",
    "                    # Si hay valores negativos, ajustamos la distribución\n",
    "                    if incremento_sep < 0 or incremento_oct < 0:\n",
    "                        incremento_sep = v * r\n",
    "                        incremento_oct = v * (1 - r)\n",
    "                \n",
    "                # Actualizar o crear los registros para 2023-09\n",
    "                if '2023-09-01' in df_ajustado.index:\n",
    "                    # Sumar el incremento calculado\n",
    "                    df_ajustado.loc['2023-09-01', 'cantidad'] += incremento_sep\n",
    "                else:\n",
    "                    # Crear nuevo registro\n",
    "                    nuevo_registro = pd.DataFrame(index=[pd.to_datetime('2023-09-01')])\n",
    "                    \n",
    "                    # Copiar valores categóricos\n",
    "                    if len(df_ajustado) > 0:\n",
    "                        for col in df_ajustado.columns:\n",
    "                            if col != 'cantidad':\n",
    "                                nuevo_registro[col] = df_ajustado[col].iloc[0]\n",
    "                    \n",
    "                    # Asignar el valor calculado\n",
    "                    nuevo_registro['cantidad'] = incremento_sep\n",
    "                    \n",
    "                    # Concatenar\n",
    "                    df_ajustado = pd.concat([df_ajustado, nuevo_registro])\n",
    "                \n",
    "                # Actualizar o crear los registros para 2023-10\n",
    "                if '2023-10-01' in df_ajustado.index:\n",
    "                    # Sumar el incremento calculado\n",
    "                    df_ajustado.loc['2023-10-01', 'cantidad'] += incremento_oct\n",
    "                else:\n",
    "                    # Crear nuevo registro\n",
    "                    nuevo_registro = pd.DataFrame(index=[pd.to_datetime('2023-10-01')])\n",
    "                    \n",
    "                    # Copiar valores categóricos\n",
    "                    if len(df_ajustado) > 0:\n",
    "                        for col in df_ajustado.columns:\n",
    "                            if col != 'cantidad':\n",
    "                                nuevo_registro[col] = df_ajustado[col].iloc[0]\n",
    "                    \n",
    "                    # Asignar el valor calculado\n",
    "                    nuevo_registro['cantidad'] = incremento_oct\n",
    "                    \n",
    "                    # Concatenar\n",
    "                    df_ajustado = pd.concat([df_ajustado, nuevo_registro])\n",
    "                \n",
    "                # Ordenar por fecha\n",
    "                df_ajustado = df_ajustado.sort_index()\n",
    "        \n",
    "        dataframes_ajustados.append(df_ajustado)\n",
    "    \n",
    "    return dataframes_ajustados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cfb4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = ajustar_para_mantener_ratios(timeseries,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5df8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completar_registros_mensuales(timeseries):\n",
    "    \"\"\"\n",
    "    Completa los registros faltantes en una lista de dataframes con índices de fecha.\n",
    "    Rellena todos los meses desde el primer índice hasta el último índice.\n",
    "    \n",
    "    Args:\n",
    "        timeseries: Lista de dataframes con índices de fecha YYYY-MM-DD\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con registros completos\n",
    "    \"\"\"\n",
    "    \n",
    "    timeseries_completos = []\n",
    "    \n",
    "    for i, df in enumerate(timeseries):\n",
    "        try:\n",
    "            # Asegurar que el índice sea datetime\n",
    "            if not isinstance(df.index, pd.DatetimeIndex):\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "            \n",
    "            # Encontrar el rango completo de fechas (primer y último mes)\n",
    "            fecha_inicio = df.index.min()\n",
    "            fecha_fin = df.index.max()\n",
    "            \n",
    "            # Crear rango completo de fechas mensuales\n",
    "            rango_completo = pd.date_range(\n",
    "                start=fecha_inicio.replace(day=1),  # Primer día del mes inicial\n",
    "                end=fecha_fin,\n",
    "                freq='MS'  # Month Start - primer día de cada mes\n",
    "            )\n",
    "            \n",
    "            # Reindexar el dataframe para incluir todas las fechas\n",
    "            df_completo = df.reindex(rango_completo)\n",
    "            \n",
    "            # Rellenar valores constantes (todas las columnas excepto 'cantidad')\n",
    "            columnas_constantes = [col for col in df_completo.columns if col != 'cantidad']\n",
    "            \n",
    "            for col in columnas_constantes:\n",
    "                # Rellenar hacia adelante y hacia atrás para mantener valores constantes\n",
    "                df_completo[col] = df_completo[col].fillna(method='ffill').fillna(method='bfill')\n",
    "            \n",
    "            # La columna 'cantidad' se queda con NaN donde no había datos\n",
    "            \n",
    "            timeseries_completos.append(df_completo)\n",
    "            print(f\"✓ Dataframe {i}: Completado de {len(df)} a {len(df_completo)} registros\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error en dataframe {i}: {e}\")\n",
    "            timeseries_completos.append(df)  # Agregar el dataframe original si hay error\n",
    "    \n",
    "    return timeseries_completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d83c10ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataframe 0: Completado de 45 a 45 registros\n",
      "✓ Dataframe 1: Completado de 45 a 45 registros\n",
      "✓ Dataframe 2: Completado de 45 a 45 registros\n",
      "✓ Dataframe 3: Completado de 45 a 45 registros\n",
      "✓ Dataframe 4: Completado de 45 a 45 registros\n",
      "✓ Dataframe 5: Completado de 45 a 45 registros\n",
      "✓ Dataframe 6: Completado de 45 a 45 registros\n",
      "✓ Dataframe 7: Completado de 44 a 44 registros\n",
      "✓ Dataframe 8: Completado de 38 a 43 registros\n",
      "✓ Dataframe 9: Completado de 42 a 45 registros\n",
      "✓ Dataframe 10: Completado de 45 a 45 registros\n",
      "✓ Dataframe 11: Completado de 45 a 45 registros\n",
      "✓ Dataframe 12: Completado de 45 a 45 registros\n",
      "✓ Dataframe 13: Completado de 45 a 45 registros\n",
      "✓ Dataframe 14: Completado de 44 a 45 registros\n",
      "✓ Dataframe 15: Completado de 44 a 45 registros\n",
      "✓ Dataframe 16: Completado de 44 a 44 registros\n",
      "✓ Dataframe 17: Completado de 43 a 43 registros\n",
      "✓ Dataframe 18: Completado de 36 a 36 registros\n",
      "✓ Dataframe 19: Completado de 29 a 30 registros\n",
      "✓ Dataframe 20: Completado de 30 a 30 registros\n",
      "✓ Dataframe 21: Completado de 34 a 34 registros\n",
      "✓ Dataframe 22: Completado de 40 a 43 registros\n",
      "✓ Dataframe 23: Completado de 45 a 45 registros\n",
      "✓ Dataframe 24: Completado de 45 a 45 registros\n",
      "✓ Dataframe 25: Completado de 43 a 43 registros\n",
      "✓ Dataframe 26: Completado de 31 a 39 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\2743928301.py:40: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_completo[col] = df_completo[col].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "timeseries = completar_registros_mensuales(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c88d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_columnas_temporales(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Agrega las columnas 'month' y 'quarter' a cada dataframe, calculadas a partir del índice de fecha.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con las nuevas columnas 'month' y 'quarter'\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    resultado = []\n",
    "    \n",
    "    for df in lista_dataframes:\n",
    "        # Crear una copia del dataframe\n",
    "        df_nuevo = df.copy()\n",
    "        \n",
    "        # Asegurarse de que el índice es de tipo datetime\n",
    "        if not isinstance(df_nuevo.index, pd.DatetimeIndex):\n",
    "            df_nuevo.index = pd.to_datetime(df_nuevo.index)\n",
    "        \n",
    "        # Agregar columna de mes (valores 1-12)\n",
    "        df_nuevo['month'] = df_nuevo.index.month\n",
    "        \n",
    "        # Agregar columna de trimestre (valores 1-4)\n",
    "        df_nuevo['quarter'] = df_nuevo.index.quarter\n",
    "        \n",
    "        # Añadir a la lista de resultados\n",
    "        resultado.append(df_nuevo)\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "135b69cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = agregar_columnas_temporales(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5602e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificar_columnas_categoricas(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Codifica las columnas categóricas usando códigos numéricos únicos para cada valor.\n",
    "    Las columnas a codificar son: Tipo_Producto, segmento_producto, supergrupo_producto, \n",
    "    grupo_producto y subgrupo_producto.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con columnas categóricas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dataframes con columnas categóricas codificadas y diccionario de mapeos\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Columnas categóricas a codificar\n",
    "    columnas_categoricas = [\n",
    "        'Tipo_Producto', \n",
    "        'segmento_producto', \n",
    "        'supergrupo_producto', \n",
    "        'grupo_producto', \n",
    "        'subgrupo_producto'\n",
    "    ]\n",
    "    \n",
    "    # Diccionario para almacenar los mapeos para cada columna\n",
    "    mapeos = {col: {} for col in columnas_categoricas}\n",
    "    \n",
    "    # Lista para almacenar los dataframes codificados\n",
    "    dataframes_codificados = []\n",
    "    \n",
    "    # Crear mapeos para cada columna categórica\n",
    "    codigo_actual = {}\n",
    "    for col in columnas_categoricas:\n",
    "        codigo_actual[col] = 0\n",
    "    \n",
    "    # Iterar sobre cada dataframe para crear los mapeos\n",
    "    for df in lista_dataframes:\n",
    "        for col in columnas_categoricas:\n",
    "            if col in df.columns:\n",
    "                # Obtener el valor único en esta columna para este dataframe\n",
    "                # (asumiendo que cada dataframe tiene un solo valor para cada columna categórica)\n",
    "                if len(df) > 0:\n",
    "                    valor = df[col].iloc[0]\n",
    "                    \n",
    "                    # Si el valor no está en el mapeo, asignarle un código\n",
    "                    if valor not in mapeos[col]:\n",
    "                        mapeos[col][valor] = codigo_actual[col]\n",
    "                        codigo_actual[col] += 1\n",
    "    \n",
    "    # Aplicar los mapeos a cada dataframe\n",
    "    for df in lista_dataframes:\n",
    "        df_codificado = df.copy()\n",
    "        \n",
    "        for col in columnas_categoricas:\n",
    "            if col in df.columns:\n",
    "                if len(df) > 0:\n",
    "                    valor = df[col].iloc[0]\n",
    "                    codigo = mapeos[col][valor]\n",
    "                    \n",
    "                    # Reemplazar el valor categórico con su código\n",
    "                    df_codificado[col] = codigo\n",
    "        \n",
    "        dataframes_codificados.append(df_codificado)\n",
    "    \n",
    "    return dataframes_codificados, mapeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fc8d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries,mapeos = codificar_columnas_categoricas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76a7acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tipo_Producto': {'LILI PINK': 0, 'YOI': 1},\n",
       " 'segmento_producto': {'JUVENIL': 0,\n",
       "  'TEEN': 1,\n",
       "  'ADULTO': 2,\n",
       "  'UNISEX': 3,\n",
       "  'GIRLS': 4},\n",
       " 'supergrupo_producto': {'INTERIOR JUVENIL': 0,\n",
       "  'INTERIOR TEEN': 1,\n",
       "  'LINEA SECRET': 2,\n",
       "  'VESTIDO DE BANO': 3,\n",
       "  'INTERIOR MUJER': 4,\n",
       "  'LINEA EXTERIOR': 5,\n",
       "  'BELLEZA Y BIENESTAR': 6},\n",
       " 'grupo_producto': {'PANTY PAQX3': 0,\n",
       "  'BRASIER PAQX2': 1,\n",
       "  'PANTY PAQX2': 2,\n",
       "  'PANTY': 3,\n",
       "  'BRASIER SILICONA': 4,\n",
       "  'ACCESORIOS': 5,\n",
       "  'V. BANO 2 PIEZAS IS': 6,\n",
       "  'CALZADO': 7,\n",
       "  'PREVENCION Y CUIDADO': 8,\n",
       "  'FRAGANCIAS': 9},\n",
       " 'subgrupo_producto': {'ALGODON': 0,\n",
       "  'MICROFIBRA': 1,\n",
       "  'SEAMLESS': 2,\n",
       "  'ENCAJE': 3,\n",
       "  'SILICONA': 4,\n",
       "  'SURTIDO': 5,\n",
       "  'NO APLICA': 6}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "950521f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_registros_mensuales(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Verifica que existan registros para todos los meses desde la primera hasta la última fecha\n",
    "    en cada dataframe, e identifica los meses faltantes.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índice de fecha en formato 'YYYY-MM-DD'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de tuplas (dataframe_id, completo, meses_faltantes) donde:\n",
    "        - dataframe_id: Índice del dataframe en la lista\n",
    "        - completo: Boolean indicando si tiene todos los meses\n",
    "        - meses_faltantes: Lista de fechas de meses faltantes en formato 'YYYY-MM-01'\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Asegurarse de que el índice es de tipo datetime\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df = df.copy()\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Verificar que hay registros en el dataframe\n",
    "        if len(df) == 0:\n",
    "            resultados.append((i, True, []))\n",
    "            continue\n",
    "        \n",
    "        # Obtener la primera y última fecha\n",
    "        primera_fecha = df.index.min()\n",
    "        ultima_fecha = df.index.max()\n",
    "        \n",
    "        # Crear un rango de todos los meses entre la primera y última fecha\n",
    "        todos_los_meses = pd.date_range(\n",
    "            start=pd.Timestamp(year=primera_fecha.year, month=primera_fecha.month, day=1),\n",
    "            end=pd.Timestamp(year=ultima_fecha.year, month=ultima_fecha.month, day=1),\n",
    "            freq='MS'  # Inicio de mes (Month Start)\n",
    "        )\n",
    "        \n",
    "        # Convertir los índices del dataframe a inicio de mes\n",
    "        meses_presentes = df.index.to_period('M').to_timestamp()\n",
    "        meses_presentes = meses_presentes.unique()  # Eliminar duplicados\n",
    "        \n",
    "        # Encontrar meses faltantes\n",
    "        meses_faltantes = [fecha for fecha in todos_los_meses if fecha not in meses_presentes]\n",
    "        \n",
    "        # Determinar si está completo\n",
    "        completo = len(meses_faltantes) == 0\n",
    "        \n",
    "        # Guardar resultados\n",
    "        resultados.append((i, completo, meses_faltantes))\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5323dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, True, []),\n",
       " (1, True, []),\n",
       " (2, True, []),\n",
       " (3, True, []),\n",
       " (4, True, []),\n",
       " (5, True, []),\n",
       " (6, True, []),\n",
       " (7, True, []),\n",
       " (8, True, []),\n",
       " (9, True, []),\n",
       " (10, True, []),\n",
       " (11, True, []),\n",
       " (12, True, []),\n",
       " (13, True, []),\n",
       " (14, True, []),\n",
       " (15, True, []),\n",
       " (16, True, []),\n",
       " (17, True, []),\n",
       " (18, True, []),\n",
       " (19, True, []),\n",
       " (20, True, []),\n",
       " (21, True, []),\n",
       " (22, True, []),\n",
       " (23, True, []),\n",
       " (24, True, []),\n",
       " (25, True, []),\n",
       " (26, True, [])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verificar_registros_mensuales(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "982031b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_vectores_categoricos(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae los valores categóricos del primer registro de cada dataframe y crea\n",
    "    un vector con estos valores.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes que contienen columnas categóricas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de vectores categóricos, uno por cada dataframe\n",
    "    \"\"\"\n",
    "    # Definir las columnas categóricas\n",
    "    columnas_categoricas = [\n",
    "        'Tipo_Producto', \n",
    "        'segmento_producto', \n",
    "        'supergrupo_producto', \n",
    "        'grupo_producto', \n",
    "        'subgrupo_producto'\n",
    "    ]\n",
    "    \n",
    "    vectores_categoricos = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío, se usará un vector de ceros.\")\n",
    "            vectores_categoricos.append([0] * len(columnas_categoricas))\n",
    "            continue\n",
    "        \n",
    "        # Crear el vector para este dataframe\n",
    "        vector = []\n",
    "        \n",
    "        for col in columnas_categoricas:\n",
    "            # Verificar si la columna existe en el dataframe\n",
    "            if col in df.columns:\n",
    "                # Obtener el valor del primer registro\n",
    "                valor = df[col].iloc[0]\n",
    "                \n",
    "                # Convertir a entero si es posible, de lo contrario usar un código hash\n",
    "                try:\n",
    "                    valor_numerico = int(valor)\n",
    "                except (ValueError, TypeError):\n",
    "                    # Si no se puede convertir a entero, usar un código hash simple\n",
    "                    if valor is None:\n",
    "                        valor_numerico = 0\n",
    "                    else:\n",
    "                        # Hash simple basado en la representación string del valor\n",
    "                        valor_numerico = hash(str(valor)) % 10000  # Limitar a 4 dígitos\n",
    "            else:\n",
    "                # Si la columna no existe, usar 0\n",
    "                valor_numerico = 0\n",
    "            \n",
    "            vector.append(valor_numerico)\n",
    "        \n",
    "        vectores_categoricos.append(vector)\n",
    "        \n",
    "    return vectores_categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d63ec96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_cat = extraer_vectores_categoricos(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c101280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectores_cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a31cbf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_vectores_cantidad(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae los valores de la columna 'cantidad' de cada dataframe y crea \n",
    "    un vector con estos valores.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes que contienen la columna 'cantidad'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de vectores, donde cada vector contiene los valores de 'cantidad' de un dataframe\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    vectores_cantidad = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío.\")\n",
    "            vectores_cantidad.append([])\n",
    "            continue\n",
    "        \n",
    "        # Verificar que exista la columna 'cantidad'\n",
    "        if 'cantidad' not in df.columns:\n",
    "            print(f\"Advertencia: Dataframe {i} no tiene columna 'cantidad'.\")\n",
    "            vectores_cantidad.append([])\n",
    "            continue\n",
    "        \n",
    "        # Extraer los valores de 'cantidad' como una lista\n",
    "        valores = df['cantidad'].tolist()\n",
    "        \n",
    "        # Opcionalmente, puedes manejar valores NaN\n",
    "        # valores = [0 if pd.isna(x) else x for x in valores]  # Convierte NaN a 0\n",
    "        # O simplemente:\n",
    "        valores = df['cantidad'].fillna(0).tolist()  # Rellena NaN con 0\n",
    "        \n",
    "        vectores_cantidad.append(valores)\n",
    "    \n",
    "    return vectores_cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5db630e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_target = extraer_vectores_cantidad(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "327fa6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_vectores_temporales(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae los valores de las columnas 'month' y 'quarter' de cada dataframe\n",
    "    y crea un conjunto de vectores con estos valores.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes que contienen las columnas 'month' y 'quarter'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de conjuntos de vectores, donde cada conjunto contiene los vectores\n",
    "        de 'month' y 'quarter' para un dataframe\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    conjuntos_vectores = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío.\")\n",
    "            conjuntos_vectores.append(([], []))\n",
    "            continue\n",
    "        \n",
    "        # Verificar que existan las columnas necesarias\n",
    "        columnas_faltantes = []\n",
    "        if 'month' not in df.columns:\n",
    "            columnas_faltantes.append('month')\n",
    "        if 'quarter' not in df.columns:\n",
    "            columnas_faltantes.append('quarter')\n",
    "        \n",
    "        if columnas_faltantes:\n",
    "            print(f\"Advertencia: Dataframe {i} no tiene las columnas: {columnas_faltantes}\")\n",
    "            \n",
    "            # Si faltan las columnas, podemos crearlas a partir del índice si es de tipo fecha\n",
    "            df_temp = df.copy()\n",
    "            \n",
    "            if isinstance(df_temp.index, pd.DatetimeIndex):\n",
    "                if 'month' not in df_temp.columns:\n",
    "                    df_temp['month'] = df_temp.index.month\n",
    "                if 'quarter' not in df_temp.columns:\n",
    "                    df_temp['quarter'] = df_temp.index.quarter\n",
    "            else:\n",
    "                # Si el índice no es de tipo fecha, tratar de convertirlo\n",
    "                try:\n",
    "                    df_temp.index = pd.to_datetime(df_temp.index)\n",
    "                    if 'month' not in df_temp.columns:\n",
    "                        df_temp['month'] = df_temp.index.month\n",
    "                    if 'quarter' not in df_temp.columns:\n",
    "                        df_temp['quarter'] = df_temp.index.quarter\n",
    "                except:\n",
    "                    # Si no se puede convertir, usar valores vacíos\n",
    "                    month_vector = []\n",
    "                    quarter_vector = []\n",
    "                    conjuntos_vectores.append((month_vector, quarter_vector))\n",
    "                    continue\n",
    "            \n",
    "            # Usar el dataframe temporal con las columnas agregadas\n",
    "            df = df_temp\n",
    "        \n",
    "        # Extraer los vectores\n",
    "        month_vector = df['month'].tolist()\n",
    "        quarter_vector = df['quarter'].tolist()\n",
    "        \n",
    "        # Guardar el conjunto de vectores\n",
    "        conjuntos_vectores.append((month_vector, quarter_vector))\n",
    "    \n",
    "    return conjuntos_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ebcdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_dynamic = extraer_vectores_temporales(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf970b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_primeros_indices(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Extrae el primer índice de cada dataframe y lo devuelve en formato \"YYYY-MM-DD 00:00:00\".\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con índices de fecha\n",
    "    \n",
    "    Returns:\n",
    "        Lista de strings con los primeros índices en formato \"YYYY-MM-DD 00:00:00\"\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    primeros_indices = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío. Se usará fecha por defecto.\")\n",
    "            primeros_indices.append(\"2000-01-01 00:00:00\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener el primer índice\n",
    "        primer_indice = df.index[0]\n",
    "        \n",
    "        # Convertir a datetime si no lo es\n",
    "        if not isinstance(primer_indice, pd.Timestamp) and not isinstance(primer_indice, datetime):\n",
    "            try:\n",
    "                primer_indice = pd.to_datetime(primer_indice)\n",
    "            except:\n",
    "                print(f\"Advertencia: No se pudo convertir el índice del Dataframe {i} a fecha. Se usará fecha por defecto.\")\n",
    "                primeros_indices.append(\"2000-01-01 00:00:00\")\n",
    "                continue\n",
    "        \n",
    "        # Formatear a \"YYYY-MM-DD 00:00:00\"\n",
    "        indice_formateado = primer_indice.strftime(\"%Y-%m-%d 00:00:00\")\n",
    "        \n",
    "        primeros_indices.append(indice_formateado)\n",
    "    \n",
    "    return primeros_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4042f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = extraer_primeros_indices(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18af2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_test(start, vectores_target, vectores_cat, vectores_dynamic):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios con la estructura requerida para entrenamiento,\n",
    "    donde start son las fechas de inicio de cada serie (un valor por dataframe).\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else float(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic\n",
    "        if len(target_data) != len(month_vector) or len(target_data) != len(quarter_vector):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes - target: {len(target_data)}, \"\n",
    "                  f\"month: {len(month_vector)}, quarter: {len(quarter_vector)}\")\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector, quarter_vector]  # Usar valores originales sin normalizar\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e92b152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = crear_diccionarios_test(start,vectores_target,vectores_cat,vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "731b34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_entrenamiento(start, vectores_target, vectores_cat, vectores_dynamic, puntos_a_excluir=6):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios excluyendo los últimos 'puntos_a_excluir' valores de \n",
    "    target y dynamic_feat para cada serie.\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "        puntos_a_excluir: Número de puntos a excluir del final de las series (default=6)\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else float(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar que hay suficientes puntos para excluir\n",
    "        if len(target_data) <= puntos_a_excluir:\n",
    "            print(f\"Advertencia: Serie {i} tiene menos puntos ({len(target_data)}) que los requeridos a excluir ({puntos_a_excluir}). Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Excluir los últimos 'puntos_a_excluir' valores\n",
    "        target_data_recortado = target_data[:-puntos_a_excluir]\n",
    "        month_vector_recortado = month_vector[:-puntos_a_excluir]\n",
    "        quarter_vector_recortado = quarter_vector[:-puntos_a_excluir]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic después del recorte\n",
    "        if len(target_data_recortado) != len(month_vector_recortado) or len(target_data_recortado) != len(quarter_vector_recortado):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes después del recorte - target: {len(target_data_recortado)}, \"\n",
    "                  f\"month: {len(month_vector_recortado)}, quarter: {len(quarter_vector_recortado)}\")\n",
    "            # Ajustar a la longitud mínima\n",
    "            min_len = min(len(target_data_recortado), len(month_vector_recortado), len(quarter_vector_recortado))\n",
    "            target_data_recortado = target_data_recortado[:min_len]\n",
    "            month_vector_recortado = month_vector_recortado[:min_len]\n",
    "            quarter_vector_recortado = quarter_vector_recortado[:min_len]\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data_recortado),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector_recortado, quarter_vector_recortado]\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1abad3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = crear_diccionarios_entrenamiento(start,vectores_target, vectores_cat, vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14b00d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, \"wb\") as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef54ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"data_json/mensual_modificado_float_27/train.json\", train)\n",
    "write_dicts_to_file(\"data_json/mensual_modificado_float_27/test.json\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "110638ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/22/25 12:45:49] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/22/25 12:45:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=250279;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=138821;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\u001b\\\u001b[2m1352\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boto_session = boto3.Session(profile_name='lilipink', region_name='us-east-1')\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "s3_client = boto_session.client('s3')\n",
    "sm_client= boto_session.client('sagemaker')\n",
    "s3 = boto_session.resource(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7439c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region=None):\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration=location\n",
    "            )\n",
    "        print(f\"Bucket S3 '{bucket_name}' creado exitosamente en {region if region else 'la región por defecto'}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        print(f\"Error al crear el bucket S3: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd32a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket S3 'forecasting-mensual-27-v1' creado exitosamente en la región por defecto\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"forecasting-mensual-27-v1\"\n",
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b5a1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = bucket_name  # replace with an existing bucket if needed\n",
    "s3_bucket_prefix = (\n",
    "        \"lilipink\"  \n",
    "    )\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "if default_bucket_prefix:\n",
    "    s3_prefix = f\"{default_bucket_prefix}/{s3_bucket_prefix}\"\n",
    "else:\n",
    "    s3_prefix = s3_bucket_prefix\n",
    "\n",
    "role = \"arn:aws:iam::844598627082:role/service-role/AmazonSageMaker-ExecutionRole-20250513T105052\"  # IAM role to use by SageMaker\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea21564f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/22/25 12:45:51] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Same images used for training and inference. Defaulting to image     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         scope: inference.                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/22/25 12:45:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Same images used for training and inference. Defaulting to image     \u001b]8;id=255529;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=281749;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         scope: inference.                                                    \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#530\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=33358;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=789401;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\image_uris.py#530\u001b\\\u001b[2m530\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_name = sagemaker.image_uris.retrieve(\"forecasting-deepar\", region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc300d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith(\"s3://\")\n",
    "    split = s3_path.split(\"/\")\n",
    "    bucket = split[2]\n",
    "    path = \"/\".join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "\n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print(\n",
    "                \"File s3://{}/{} already exists.\\nSet override to upload anyway.\\n\".format(\n",
    "                    s3_bucket, s3_path\n",
    "                )\n",
    "            )\n",
    "            return\n",
    "        else:\n",
    "            print(\"Overwriting existing file\")\n",
    "    with open(local_file, \"rb\") as data:\n",
    "        print(\"Uploading file to {}\".format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7061e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file\n",
      "Uploading file to s3://forecasting-mensual-27-v1/lilipink/data/train/train.json\n",
      "Overwriting existing file\n",
      "Uploading file to s3://forecasting-mensual-27-v1/lilipink/data/test/test.json\n"
     ]
    }
   ],
   "source": [
    "local_file = 'data_json/mensual_modificado_float_27/'\n",
    "copy_to_s3(local_file + 'train.json', s3_data_path + \"/train/train.json\",override=True)\n",
    "copy_to_s3(local_file + 'test.json', s3_data_path + \"/test/test.json\",override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35a4dcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/22/25 12:45:52] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/22/25 12:45:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=696603;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=494736;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\botocore\\credentials.py#1352\u001b\\\u001b[2m1352\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.2xlarge\",\n",
    "   # use_spot_instances=True,\n",
    "   # max_run=1800,  # max training time in seconds\n",
    "   # max_wait=1800,  # seconds to wait for spot instance\n",
    "    base_job_name=\"lilipink-forecasting\",\n",
    "    output_path=s3_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb5e23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###ENTRENAMIENTO###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "067612dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    #\"learning_rate\": \"1E-3\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8e98ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91d8d854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 23:59:33] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 23:59:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=265622;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=826630;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-04-59-33-931                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=742067;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=973774;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-04-59-33-931                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-22 04:59:38 Starting - Starting the training job...\n",
      "2025-05-22 05:00:12 Downloading - Downloading input data...\n",
      "2025-05-22 05:00:28 Downloading - Downloading the training image...............\n",
      "2025-05-22 05:03:04 Training - Training image download completed. Training in progress.Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '18', 'early_stopping_patience': '40', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '18', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Detected entry point for worker worker\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Using early stopping with patience 40\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] random_seed is None\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] [cardinality=auto] Inferred value of cardinality=[2, 5, 7, 10, 7] from dataset.\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Training set statistics:\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Real time series\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] number of time series: 27\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] number of observations: 987\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] mean target length: 36.55555555555556\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] min/mean/max target: 0.0/76.53596757852077/2534.0\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] mean abs(target): 76.53596757852077\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] contains missing values: no\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Small number of time series. Doing 48 passes over dataset with prob 0.9876543209876543 per epoch.\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Test set statistics:\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Real time series\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] number of time series: 27\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] number of observations: 1149\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] mean target length: 42.55555555555556\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] min/mean/max target: 0.0/71.42993907745866/2534.0\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] mean abs(target): 71.42993907745866\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] contains missing values: no\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] #memory_usage::<batchbuffer> = 2.0458984375 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] nvidia-smi: took 0.056 seconds to run.\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] nvidia-smi identified 0 GPUs.\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Number of GPUs being used: 0\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Create Store: local\n",
      "#metrics {\"StartTime\": 1747890200.7424896, \"EndTime\": 1747890200.791741, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 48.29144477844238, \"count\": 1, \"min\": 48.29144477844238, \"max\": 48.29144477844238}}}\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] Number of GPUs being used: 0\n",
      "[05/22/2025 05:03:20 INFO 140551403046720] #memory_usage::<model> = 21 mb\n",
      "#metrics {\"StartTime\": 1747890200.7918348, \"EndTime\": 1747890200.8753054, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 132.68041610717773, \"count\": 1, \"min\": 132.68041610717773, \"max\": 132.68041610717773}}}\n",
      "[05:03:21] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 20480 bytes with malloc directly\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] Epoch[0] Batch[0] avg_epoch_loss=4.357642\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.357641696929932\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] Epoch[0] Batch[5] avg_epoch_loss=4.088139\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=4.0881392161051435\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] Epoch[0] Batch [5]#011Speed: 2092.11 samples/sec#011loss=4.088139\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] Epoch[0] Batch[10] avg_epoch_loss=3.846603\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.556758499145508\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] Epoch[0] Batch [10]#011Speed: 2090.27 samples/sec#011loss=3.556758\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747890200.8753626, \"EndTime\": 1747890201.8517504, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 976.3133525848389, \"count\": 1, \"min\": 976.3133525848389, \"max\": 976.3133525848389}}}\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1324.2088413662664 records/second\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.846602526578036\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:21 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_4bdec3d2-9d6a-4c07-a8a9-3510fb05691c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890201.8518362, \"EndTime\": 1747890201.864017, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.850595474243164, \"count\": 1, \"min\": 11.850595474243164, \"max\": 11.850595474243164}}}\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] Epoch[1] Batch[0] avg_epoch_loss=3.937551\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.9375510215759277\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] Epoch[1] Batch[5] avg_epoch_loss=3.885000\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.884999712308248\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] Epoch[1] Batch [5]#011Speed: 2122.10 samples/sec#011loss=3.885000\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] Epoch[1] Batch[10] avg_epoch_loss=3.792847\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.682264471054077\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] Epoch[1] Batch [10]#011Speed: 1914.78 samples/sec#011loss=3.682264\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747890201.864064, \"EndTime\": 1747890202.8087692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.6578025817871, \"count\": 1, \"min\": 944.6578025817871, \"max\": 944.6578025817871}}}\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1429.9598364954013 records/second\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.7928473299199883\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:22 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_630e5f5b-18cc-4e8b-9184-2f29f8096817-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890202.8088653, \"EndTime\": 1747890202.8193784, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.231494903564453, \"count\": 1, \"min\": 10.231494903564453, \"max\": 10.231494903564453}}}\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] Epoch[2] Batch[0] avg_epoch_loss=3.789324\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.789323568344116\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] Epoch[2] Batch[5] avg_epoch_loss=3.801147\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.8011467854181924\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] Epoch[2] Batch [5]#011Speed: 2089.62 samples/sec#011loss=3.801147\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] Epoch[2] Batch[10] avg_epoch_loss=3.845382\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.8984634399414064\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] Epoch[2] Batch [10]#011Speed: 2114.77 samples/sec#011loss=3.898463\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747890202.81946, \"EndTime\": 1747890203.7568345, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.3250007629395, \"count\": 1, \"min\": 937.3250007629395, \"max\": 937.3250007629395}}}\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1399.601210850449 records/second\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.8453816283832896\n",
      "[05/22/2025 05:03:23 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] Epoch[3] Batch[0] avg_epoch_loss=3.906690\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.9066898822784424\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] Epoch[3] Batch[5] avg_epoch_loss=3.773006\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.773006478945414\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] Epoch[3] Batch [5]#011Speed: 2022.27 samples/sec#011loss=3.773006\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] Epoch[3] Batch[10] avg_epoch_loss=3.676295\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=3.5602421283721926\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] Epoch[3] Batch [10]#011Speed: 2061.82 samples/sec#011loss=3.560242\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747890203.7568905, \"EndTime\": 1747890204.701512, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.3359375, \"count\": 1, \"min\": 944.3359375, \"max\": 944.3359375}}}\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1365.9182521989012 records/second\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.6762954105030405\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:24 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_1093bbb5-393c-470e-afb5-0661a131ac39-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890204.7015672, \"EndTime\": 1747890204.712023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.181427001953125, \"count\": 1, \"min\": 10.181427001953125, \"max\": 10.181427001953125}}}\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] Epoch[4] Batch[0] avg_epoch_loss=3.662756\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.6627564430236816\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] Epoch[4] Batch[5] avg_epoch_loss=3.677439\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.677439292271932\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] Epoch[4] Batch [5]#011Speed: 1788.04 samples/sec#011loss=3.677439\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] Epoch[4] Batch[10] avg_epoch_loss=3.597408\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.50137038230896\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] Epoch[4] Batch [10]#011Speed: 1730.32 samples/sec#011loss=3.501370\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747890204.7121115, \"EndTime\": 1747890205.7471192, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1034.9557399749756, \"count\": 1, \"min\": 1034.9557399749756, \"max\": 1034.9557399749756}}}\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1272.4100239375964 records/second\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.5974079695614902\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:25 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_0693606a-a111-4187-aec7-33f9da6bb0fb-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890205.7471766, \"EndTime\": 1747890205.7579176, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.465860366821289, \"count\": 1, \"min\": 10.465860366821289, \"max\": 10.465860366821289}}}\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] Epoch[5] Batch[0] avg_epoch_loss=3.802731\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.8027307987213135\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] Epoch[5] Batch[5] avg_epoch_loss=3.666666\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.666666269302368\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] Epoch[5] Batch [5]#011Speed: 1770.42 samples/sec#011loss=3.666666\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] Epoch[5] Batch[10] avg_epoch_loss=3.649391\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.6286596298217773\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] Epoch[5] Batch [10]#011Speed: 2014.77 samples/sec#011loss=3.628660\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] processed a total of 1383 examples\n",
      "#metrics {\"StartTime\": 1747890205.7579687, \"EndTime\": 1747890206.7907796, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1032.7603816986084, \"count\": 1, \"min\": 1032.7603816986084, \"max\": 1032.7603816986084}}}\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1339.0170834992468 records/second\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.649390524083918\n",
      "[05/22/2025 05:03:26 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] Epoch[6] Batch[0] avg_epoch_loss=3.748548\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.7485480308532715\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] Epoch[6] Batch[5] avg_epoch_loss=3.681341\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.68134073416392\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] Epoch[6] Batch [5]#011Speed: 2167.02 samples/sec#011loss=3.681341\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] Epoch[6] Batch[10] avg_epoch_loss=3.709711\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.7437559604644775\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] Epoch[6] Batch [10]#011Speed: 2041.13 samples/sec#011loss=3.743756\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747890206.790837, \"EndTime\": 1747890207.7112558, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.168399810791, \"count\": 1, \"min\": 920.168399810791, \"max\": 920.168399810791}}}\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1423.5207780253136 records/second\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.709711291573264\n",
      "[05/22/2025 05:03:27 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] Epoch[7] Batch[0] avg_epoch_loss=3.719929\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.719928741455078\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] Epoch[7] Batch[5] avg_epoch_loss=3.587988\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.587988257408142\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] Epoch[7] Batch [5]#011Speed: 2134.38 samples/sec#011loss=3.587988\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] Epoch[7] Batch[10] avg_epoch_loss=3.697341\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.828565073013306\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] Epoch[7] Batch [10]#011Speed: 2101.26 samples/sec#011loss=3.828565\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747890207.7113132, \"EndTime\": 1747890208.634885, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.2654571533203, \"count\": 1, \"min\": 923.2654571533203, \"max\": 923.2654571533203}}}\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1388.423164684858 records/second\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.6973413554104892\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] Epoch[8] Batch[0] avg_epoch_loss=3.590317\n",
      "[05/22/2025 05:03:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.590317487716675\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] Epoch[8] Batch[5] avg_epoch_loss=3.538216\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.53821595509847\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] Epoch[8] Batch [5]#011Speed: 2149.69 samples/sec#011loss=3.538216\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] Epoch[8] Batch[10] avg_epoch_loss=3.599276\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.6725473403930664\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] Epoch[8] Batch [10]#011Speed: 1966.22 samples/sec#011loss=3.672547\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] processed a total of 1435 examples\n",
      "#metrics {\"StartTime\": 1747890208.6349406, \"EndTime\": 1747890209.6358976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1000.6997585296631, \"count\": 1, \"min\": 1000.6997585296631, \"max\": 1000.6997585296631}}}\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1433.8616087062378 records/second\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.6455359061559043\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] Epoch[9] Batch[0] avg_epoch_loss=3.566155\n",
      "[05/22/2025 05:03:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.566155195236206\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] Epoch[9] Batch[5] avg_epoch_loss=3.667087\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.6670867602030435\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] Epoch[9] Batch [5]#011Speed: 2128.39 samples/sec#011loss=3.667087\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] Epoch[9] Batch[10] avg_epoch_loss=3.676131\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.6869845390319824\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] Epoch[9] Batch [10]#011Speed: 2117.10 samples/sec#011loss=3.686985\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747890209.6359625, \"EndTime\": 1747890210.5556798, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.3401336669922, \"count\": 1, \"min\": 919.3401336669922, \"max\": 919.3401336669922}}}\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1404.1249678131203 records/second\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.6761312051252886\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] Epoch[10] Batch[0] avg_epoch_loss=3.473200\n",
      "[05/22/2025 05:03:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.4731998443603516\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] Epoch[10] Batch[5] avg_epoch_loss=3.553784\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.5537837743759155\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] Epoch[10] Batch [5]#011Speed: 2111.68 samples/sec#011loss=3.553784\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] Epoch[10] Batch[10] avg_epoch_loss=3.604271\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.6648552894592283\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] Epoch[10] Batch [10]#011Speed: 1870.07 samples/sec#011loss=3.664855\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] processed a total of 1372 examples\n",
      "#metrics {\"StartTime\": 1747890210.555741, \"EndTime\": 1747890211.510501, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.4110298156738, \"count\": 1, \"min\": 954.4110298156738, \"max\": 954.4110298156738}}}\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1437.4072269703515 records/second\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.604270826686512\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] Epoch[11] Batch[0] avg_epoch_loss=3.533716\n",
      "[05/22/2025 05:03:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.5337162017822266\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] Epoch[11] Batch[5] avg_epoch_loss=3.536469\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.536468505859375\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] Epoch[11] Batch [5]#011Speed: 2073.68 samples/sec#011loss=3.536469\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] Epoch[11] Batch[10] avg_epoch_loss=3.579046\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=3.6301398277282715\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] Epoch[11] Batch [10]#011Speed: 2051.86 samples/sec#011loss=3.630140\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747890211.510553, \"EndTime\": 1747890212.4440126, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.1490993499756, \"count\": 1, \"min\": 933.1490993499756, \"max\": 933.1490993499756}}}\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1401.5713296298047 records/second\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.579046379436146\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_ac81c351-021f-4e80-81be-d48127a47061-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890212.4440722, \"EndTime\": 1747890212.4550133, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.676860809326172, \"count\": 1, \"min\": 10.676860809326172, \"max\": 10.676860809326172}}}\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] Epoch[12] Batch[0] avg_epoch_loss=3.393158\n",
      "[05/22/2025 05:03:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.393158197402954\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] Epoch[12] Batch[5] avg_epoch_loss=3.498238\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.49823792775472\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] Epoch[12] Batch [5]#011Speed: 2116.21 samples/sec#011loss=3.498238\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] Epoch[12] Batch[10] avg_epoch_loss=3.515350\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=3.5358838081359862\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] Epoch[12] Batch [10]#011Speed: 1937.33 samples/sec#011loss=3.535884\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747890212.4550653, \"EndTime\": 1747890213.40041, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.2962875366211, \"count\": 1, \"min\": 945.2962875366211, \"max\": 945.2962875366211}}}\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1444.9340506111078 records/second\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.5153496915643867\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_097fd89f-3241-4c8d-bad3-3e231a17748b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890213.4004593, \"EndTime\": 1747890213.4109476, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.24937629699707, \"count\": 1, \"min\": 10.24937629699707, \"max\": 10.24937629699707}}}\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] Epoch[13] Batch[0] avg_epoch_loss=3.566039\n",
      "[05/22/2025 05:03:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.5660393238067627\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] Epoch[13] Batch[5] avg_epoch_loss=3.530713\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.5307130813598633\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] Epoch[13] Batch [5]#011Speed: 2086.16 samples/sec#011loss=3.530713\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] Epoch[13] Batch[10] avg_epoch_loss=3.566922\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.6103734016418456\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] Epoch[13] Batch [10]#011Speed: 2033.51 samples/sec#011loss=3.610373\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747890213.4109964, \"EndTime\": 1747890214.3445787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.5370063781738, \"count\": 1, \"min\": 933.5370063781738, \"max\": 933.5370063781738}}}\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1448.124095321297 records/second\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.5669223178516734\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] Epoch[14] Batch[0] avg_epoch_loss=3.335263\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.335263252258301\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] Epoch[14] Batch[5] avg_epoch_loss=3.516649\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.5166491270065308\n",
      "[05/22/2025 05:03:34 INFO 140551403046720] Epoch[14] Batch [5]#011Speed: 2142.15 samples/sec#011loss=3.516649\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] Epoch[14] Batch[10] avg_epoch_loss=3.459234\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=3.3903350830078125\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] Epoch[14] Batch [10]#011Speed: 1954.00 samples/sec#011loss=3.390335\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747890214.344636, \"EndTime\": 1747890215.2828035, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.9193782806396, \"count\": 1, \"min\": 937.9193782806396, \"max\": 937.9193782806396}}}\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1420.0322315154515 records/second\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.4592336524616587\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_7c3ad951-333a-4a92-b9bd-ed6583d245f2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890215.282863, \"EndTime\": 1747890215.293258, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.092496871948242, \"count\": 1, \"min\": 10.092496871948242, \"max\": 10.092496871948242}}}\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] Epoch[15] Batch[0] avg_epoch_loss=3.499070\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.4990696907043457\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] Epoch[15] Batch[5] avg_epoch_loss=3.498663\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=3.4986632664998374\n",
      "[05/22/2025 05:03:35 INFO 140551403046720] Epoch[15] Batch [5]#011Speed: 2156.78 samples/sec#011loss=3.498663\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] Epoch[15] Batch[10] avg_epoch_loss=3.652665\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=3.8374672889709474\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] Epoch[15] Batch [10]#011Speed: 2133.39 samples/sec#011loss=3.837467\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747890215.2933083, \"EndTime\": 1747890216.1976264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 903.7618637084961, \"count\": 1, \"min\": 903.7618637084961, \"max\": 903.7618637084961}}}\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1443.7736277063996 records/second\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=15, train loss <loss>=3.6526650948957964\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] Epoch[16] Batch[0] avg_epoch_loss=3.537444\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.5374436378479004\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] Epoch[16] Batch[5] avg_epoch_loss=3.492957\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=3.4929569164911904\n",
      "[05/22/2025 05:03:36 INFO 140551403046720] Epoch[16] Batch [5]#011Speed: 1982.82 samples/sec#011loss=3.492957\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] Epoch[16] Batch[10] avg_epoch_loss=3.401164\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=3.2910125732421873\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] Epoch[16] Batch [10]#011Speed: 2055.83 samples/sec#011loss=3.291013\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747890216.197717, \"EndTime\": 1747890217.1414142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.4304237365723, \"count\": 1, \"min\": 943.4304237365723, \"max\": 943.4304237365723}}}\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1424.458766551928 records/second\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.401164033196189\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_3cb1d62d-ea6e-476e-8c3d-f8aa3d144ce4-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890217.1414704, \"EndTime\": 1747890217.1524427, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.701179504394531, \"count\": 1, \"min\": 10.701179504394531, \"max\": 10.701179504394531}}}\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] Epoch[17] Batch[0] avg_epoch_loss=3.593940\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.593940019607544\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] Epoch[17] Batch[5] avg_epoch_loss=3.498282\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.498281796773275\n",
      "[05/22/2025 05:03:37 INFO 140551403046720] Epoch[17] Batch [5]#011Speed: 2100.15 samples/sec#011loss=3.498282\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] Epoch[17] Batch[10] avg_epoch_loss=3.412542\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.3096537590026855\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] Epoch[17] Batch [10]#011Speed: 1930.37 samples/sec#011loss=3.309654\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] processed a total of 1364 examples\n",
      "#metrics {\"StartTime\": 1747890217.152497, \"EndTime\": 1747890218.09205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.5039081573486, \"count\": 1, \"min\": 939.5039081573486, \"max\": 939.5039081573486}}}\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1451.7003671988016 records/second\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.412541779604825\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] Epoch[18] Batch[0] avg_epoch_loss=3.434291\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.434291124343872\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] Epoch[18] Batch[5] avg_epoch_loss=3.447417\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.447416623433431\n",
      "[05/22/2025 05:03:38 INFO 140551403046720] Epoch[18] Batch [5]#011Speed: 2112.31 samples/sec#011loss=3.447417\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] Epoch[18] Batch[10] avg_epoch_loss=3.435296\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.420752239227295\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] Epoch[18] Batch [10]#011Speed: 1937.54 samples/sec#011loss=3.420752\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] processed a total of 1395 examples\n",
      "#metrics {\"StartTime\": 1747890218.0921066, \"EndTime\": 1747890219.0306647, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.2693767547607, \"count\": 1, \"min\": 938.2693767547607, \"max\": 938.2693767547607}}}\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1486.634408700504 records/second\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.4352964487942783\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] Epoch[19] Batch[0] avg_epoch_loss=3.482193\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.4821925163269043\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] Epoch[19] Batch[5] avg_epoch_loss=3.483230\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=3.4832303126653037\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] Epoch[19] Batch [5]#011Speed: 2165.80 samples/sec#011loss=3.483230\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] processed a total of 1231 examples\n",
      "#metrics {\"StartTime\": 1747890219.030728, \"EndTime\": 1747890219.876008, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 845.0231552124023, \"count\": 1, \"min\": 845.0231552124023, \"max\": 845.0231552124023}}}\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1456.6074116412065 records/second\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=19, train loss <loss>=3.4964919328689574\n",
      "[05/22/2025 05:03:39 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] Epoch[20] Batch[0] avg_epoch_loss=3.575674\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.575673818588257\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] Epoch[20] Batch[5] avg_epoch_loss=3.517916\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=3.5179163217544556\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] Epoch[20] Batch [5]#011Speed: 2188.00 samples/sec#011loss=3.517916\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] Epoch[20] Batch[10] avg_epoch_loss=3.316334\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=3.0744361162185667\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] Epoch[20] Batch [10]#011Speed: 2154.62 samples/sec#011loss=3.074436\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747890219.8760693, \"EndTime\": 1747890220.7784498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 902.0516872406006, \"count\": 1, \"min\": 902.0516872406006, \"max\": 902.0516872406006}}}\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1437.6855344848182 records/second\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.3163344101472334\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:40 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_2a44c1a6-3ff8-44c9-a5b2-914c79c77bc1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890220.7785115, \"EndTime\": 1747890220.7889628, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.124683380126953, \"count\": 1, \"min\": 10.124683380126953, \"max\": 10.124683380126953}}}\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] Epoch[21] Batch[0] avg_epoch_loss=3.415358\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.415358304977417\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] Epoch[21] Batch[5] avg_epoch_loss=3.346358\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.346358299255371\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] Epoch[21] Batch [5]#011Speed: 2094.87 samples/sec#011loss=3.346358\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] Epoch[21] Batch[10] avg_epoch_loss=3.383092\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=3.4271714210510256\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] Epoch[21] Batch [10]#011Speed: 1982.94 samples/sec#011loss=3.427171\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] processed a total of 1384 examples\n",
      "#metrics {\"StartTime\": 1747890220.7890165, \"EndTime\": 1747890221.7242799, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.2095127105713, \"count\": 1, \"min\": 935.2095127105713, \"max\": 935.2095127105713}}}\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1479.7510148739416 records/second\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=21, train loss <loss>=3.383091536435214\n",
      "[05/22/2025 05:03:41 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] Epoch[22] Batch[0] avg_epoch_loss=3.241615\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=3.241615056991577\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] Epoch[22] Batch[5] avg_epoch_loss=3.447894\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=3.4478943745295205\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] Epoch[22] Batch [5]#011Speed: 2066.75 samples/sec#011loss=3.447894\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] Epoch[22] Batch[10] avg_epoch_loss=3.363196\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=3.2615570545196535\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] Epoch[22] Batch [10]#011Speed: 1983.53 samples/sec#011loss=3.261557\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747890221.724332, \"EndTime\": 1747890222.6687412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.1084861755371, \"count\": 1, \"min\": 944.1084861755371, \"max\": 944.1084861755371}}}\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1445.6076363463746 records/second\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=22, train loss <loss>=3.3631955927068535\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] Epoch[23] Batch[0] avg_epoch_loss=3.551842\n",
      "[05/22/2025 05:03:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=3.551842451095581\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] Epoch[23] Batch[5] avg_epoch_loss=3.325525\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=3.3255249659220376\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] Epoch[23] Batch [5]#011Speed: 1966.33 samples/sec#011loss=3.325525\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] Epoch[23] Batch[10] avg_epoch_loss=3.397834\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=3.4846055030822756\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] Epoch[23] Batch [10]#011Speed: 2044.04 samples/sec#011loss=3.484606\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747890222.6688375, \"EndTime\": 1747890223.622398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.2206058502197, \"count\": 1, \"min\": 953.2206058502197, \"max\": 953.2206058502197}}}\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1408.7817099354625 records/second\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=23, train loss <loss>=3.397834300994873\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] Epoch[24] Batch[0] avg_epoch_loss=3.461085\n",
      "[05/22/2025 05:03:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=3.461085319519043\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] Epoch[24] Batch[5] avg_epoch_loss=3.384245\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=3.384244521458944\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] Epoch[24] Batch [5]#011Speed: 2155.28 samples/sec#011loss=3.384245\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] Epoch[24] Batch[10] avg_epoch_loss=3.336604\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=3.2794354915618897\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] Epoch[24] Batch [10]#011Speed: 1996.33 samples/sec#011loss=3.279435\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747890223.622455, \"EndTime\": 1747890224.5526187, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.8596382141113, \"count\": 1, \"min\": 929.8596382141113, \"max\": 929.8596382141113}}}\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1458.1533801739024 records/second\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=24, train loss <loss>=3.336604053323919\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] Epoch[25] Batch[0] avg_epoch_loss=3.450039\n",
      "[05/22/2025 05:03:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=3.4500389099121094\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] Epoch[25] Batch[5] avg_epoch_loss=3.387284\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=3.38728400071462\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] Epoch[25] Batch [5]#011Speed: 2006.03 samples/sec#011loss=3.387284\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] Epoch[25] Batch[10] avg_epoch_loss=3.417775\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=3.4543641567230225\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] Epoch[25] Batch [10]#011Speed: 2089.98 samples/sec#011loss=3.454364\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747890224.5526736, \"EndTime\": 1747890225.4904935, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.5731945037842, \"count\": 1, \"min\": 937.5731945037842, \"max\": 937.5731945037842}}}\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1403.4970471585034 records/second\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=25, train loss <loss>=3.4177749807184394\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] Epoch[26] Batch[0] avg_epoch_loss=3.533367\n",
      "[05/22/2025 05:03:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=3.533367395401001\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] Epoch[26] Batch[5] avg_epoch_loss=3.357516\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=3.3575156927108765\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] Epoch[26] Batch [5]#011Speed: 2080.86 samples/sec#011loss=3.357516\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] Epoch[26] Batch[10] avg_epoch_loss=3.393247\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=3.436124658584595\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] Epoch[26] Batch [10]#011Speed: 1940.83 samples/sec#011loss=3.436125\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747890225.4905488, \"EndTime\": 1747890226.4365227, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.7142353057861, \"count\": 1, \"min\": 945.7142353057861, \"max\": 945.7142353057861}}}\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1416.7906344664482 records/second\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=26, train loss <loss>=3.393247040835294\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] Epoch[27] Batch[0] avg_epoch_loss=3.333783\n",
      "[05/22/2025 05:03:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=3.3337831497192383\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] Epoch[27] Batch[5] avg_epoch_loss=3.400382\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=3.400381604830424\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] Epoch[27] Batch [5]#011Speed: 1998.75 samples/sec#011loss=3.400382\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] Epoch[27] Batch[10] avg_epoch_loss=3.268868\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=3.1110526084899903\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] Epoch[27] Batch [10]#011Speed: 2002.56 samples/sec#011loss=3.111053\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747890226.4365792, \"EndTime\": 1747890227.3855956, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.735237121582, \"count\": 1, \"min\": 948.735237121582, \"max\": 948.735237121582}}}\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1413.3357080898857 records/second\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=27, train loss <loss>=3.268868424675681\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_99159530-fa16-4527-904a-9dbbe1bddc91-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890227.385651, \"EndTime\": 1747890227.3967671, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.848283767700195, \"count\": 1, \"min\": 10.848283767700195, \"max\": 10.848283767700195}}}\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] Epoch[28] Batch[0] avg_epoch_loss=3.334161\n",
      "[05/22/2025 05:03:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=3.3341610431671143\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] Epoch[28] Batch[5] avg_epoch_loss=3.458487\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=3.4584868351618447\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] Epoch[28] Batch [5]#011Speed: 2044.48 samples/sec#011loss=3.458487\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] Epoch[28] Batch[10] avg_epoch_loss=3.382538\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=3.2913984775543215\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] Epoch[28] Batch [10]#011Speed: 1878.70 samples/sec#011loss=3.291398\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747890227.3968153, \"EndTime\": 1747890228.3607302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.8683795928955, \"count\": 1, \"min\": 963.8683795928955, \"max\": 963.8683795928955}}}\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1408.7799127356875 records/second\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=28, train loss <loss>=3.3825375817038794\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] Epoch[29] Batch[0] avg_epoch_loss=3.318990\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=3.3189897537231445\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] Epoch[29] Batch[5] avg_epoch_loss=3.360650\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=3.3606501817703247\n",
      "[05/22/2025 05:03:48 INFO 140551403046720] Epoch[29] Batch [5]#011Speed: 2062.60 samples/sec#011loss=3.360650\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] Epoch[29] Batch[10] avg_epoch_loss=3.342574\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=3.320883560180664\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] Epoch[29] Batch [10]#011Speed: 1954.85 samples/sec#011loss=3.320884\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747890228.3607879, \"EndTime\": 1747890229.3107145, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 949.5108127593994, \"count\": 1, \"min\": 949.5108127593994, \"max\": 949.5108127593994}}}\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1387.9493648003563 records/second\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=29, train loss <loss>=3.3425744446841152\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] Epoch[30] Batch[0] avg_epoch_loss=3.457263\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=3.457263231277466\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] Epoch[30] Batch[5] avg_epoch_loss=3.372523\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=3.372523307800293\n",
      "[05/22/2025 05:03:49 INFO 140551403046720] Epoch[30] Batch [5]#011Speed: 2163.63 samples/sec#011loss=3.372523\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] Epoch[30] Batch[10] avg_epoch_loss=3.439587\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=3.5200642585754394\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] Epoch[30] Batch [10]#011Speed: 1899.65 samples/sec#011loss=3.520064\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747890229.3107708, \"EndTime\": 1747890230.2570055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.9841251373291, \"count\": 1, \"min\": 945.9841251373291, \"max\": 945.9841251373291}}}\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1388.9071345318093 records/second\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=30, train loss <loss>=3.4395873763344507\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] Epoch[31] Batch[0] avg_epoch_loss=3.343405\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=3.343404531478882\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] Epoch[31] Batch[5] avg_epoch_loss=3.337576\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=3.3375761906305947\n",
      "[05/22/2025 05:03:50 INFO 140551403046720] Epoch[31] Batch [5]#011Speed: 2160.12 samples/sec#011loss=3.337576\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] Epoch[31] Batch[10] avg_epoch_loss=3.302934\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=3.2613636016845704\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] Epoch[31] Batch [10]#011Speed: 1956.11 samples/sec#011loss=3.261364\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747890230.2570622, \"EndTime\": 1747890231.1924026, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.0926876068115, \"count\": 1, \"min\": 935.0926876068115, \"max\": 935.0926876068115}}}\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1459.6173428869715 records/second\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=31, train loss <loss>=3.302934104746038\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] Epoch[32] Batch[0] avg_epoch_loss=3.195606\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=3.195605516433716\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] Epoch[32] Batch[5] avg_epoch_loss=3.262260\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=3.262259523073832\n",
      "[05/22/2025 05:03:51 INFO 140551403046720] Epoch[32] Batch [5]#011Speed: 2082.00 samples/sec#011loss=3.262260\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] Epoch[32] Batch[10] avg_epoch_loss=3.194502\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=3.113192081451416\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] Epoch[32] Batch [10]#011Speed: 2025.65 samples/sec#011loss=3.113192\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747890231.1924577, \"EndTime\": 1747890232.129746, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.0467662811279, \"count\": 1, \"min\": 937.0467662811279, \"max\": 937.0467662811279}}}\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1388.280220047214 records/second\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=32, train loss <loss>=3.194501595063643\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_a1d7222c-ca5c-4af2-9274-7162127b7db5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890232.1298027, \"EndTime\": 1747890232.140806, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.657787322998047, \"count\": 1, \"min\": 10.657787322998047, \"max\": 10.657787322998047}}}\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] Epoch[33] Batch[0] avg_epoch_loss=3.304394\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=3.304394006729126\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] Epoch[33] Batch[5] avg_epoch_loss=3.286606\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=3.2866059144337973\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] Epoch[33] Batch [5]#011Speed: 2176.33 samples/sec#011loss=3.286606\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] processed a total of 1268 examples\n",
      "#metrics {\"StartTime\": 1747890232.1408606, \"EndTime\": 1747890232.9898028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 848.8912582397461, \"count\": 1, \"min\": 848.8912582397461, \"max\": 848.8912582397461}}}\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1493.5465765023218 records/second\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=33, train loss <loss>=3.3156259536743162\n",
      "[05/22/2025 05:03:52 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] Epoch[34] Batch[0] avg_epoch_loss=3.411328\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=3.4113283157348633\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] Epoch[34] Batch[5] avg_epoch_loss=3.377150\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=3.377149780591329\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] Epoch[34] Batch [5]#011Speed: 2139.33 samples/sec#011loss=3.377150\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] Epoch[34] Batch[10] avg_epoch_loss=3.249053\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=3.095337152481079\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] Epoch[34] Batch [10]#011Speed: 1975.15 samples/sec#011loss=3.095337\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747890232.9898667, \"EndTime\": 1747890233.9345694, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.3809986114502, \"count\": 1, \"min\": 944.3809986114502, \"max\": 944.3809986114502}}}\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1390.2026950204222 records/second\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=34, train loss <loss>=3.249053131450306\n",
      "[05/22/2025 05:03:53 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] Epoch[35] Batch[0] avg_epoch_loss=3.312672\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=3.3126718997955322\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] Epoch[35] Batch[5] avg_epoch_loss=3.269012\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=3.269011696179708\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] Epoch[35] Batch [5]#011Speed: 2164.30 samples/sec#011loss=3.269012\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] Epoch[35] Batch[10] avg_epoch_loss=3.331433\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=3.406338405609131\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] Epoch[35] Batch [10]#011Speed: 2084.33 samples/sec#011loss=3.406338\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747890233.9346266, \"EndTime\": 1747890234.8529885, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.0989265441895, \"count\": 1, \"min\": 918.0989265441895, \"max\": 918.0989265441895}}}\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1443.0624394986228 records/second\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=35, train loss <loss>=3.3314329277385366\n",
      "[05/22/2025 05:03:54 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] Epoch[36] Batch[0] avg_epoch_loss=3.308361\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=3.308361053466797\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] Epoch[36] Batch[5] avg_epoch_loss=3.352450\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=3.352450172106425\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] Epoch[36] Batch [5]#011Speed: 2124.08 samples/sec#011loss=3.352450\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] Epoch[36] Batch[10] avg_epoch_loss=3.306917\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=3.2522767066955565\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] Epoch[36] Batch [10]#011Speed: 1949.91 samples/sec#011loss=3.252277\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] processed a total of 1374 examples\n",
      "#metrics {\"StartTime\": 1747890234.8530464, \"EndTime\": 1747890235.7929275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.6262168884277, \"count\": 1, \"min\": 939.6262168884277, \"max\": 939.6262168884277}}}\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1462.091420835621 records/second\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=36, train loss <loss>=3.3069167787378486\n",
      "[05/22/2025 05:03:55 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] Epoch[37] Batch[0] avg_epoch_loss=3.285727\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=3.285726547241211\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] Epoch[37] Batch[5] avg_epoch_loss=3.278647\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=3.2786473830540976\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] Epoch[37] Batch [5]#011Speed: 2057.43 samples/sec#011loss=3.278647\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] Epoch[37] Batch[10] avg_epoch_loss=3.285569\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=3.293875217437744\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] Epoch[37] Batch [10]#011Speed: 1980.61 samples/sec#011loss=3.293875\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747890235.7930238, \"EndTime\": 1747890236.7372956, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.0138339996338, \"count\": 1, \"min\": 944.0138339996338, \"max\": 944.0138339996338}}}\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1422.4564426002319 records/second\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=37, train loss <loss>=3.285569125955755\n",
      "[05/22/2025 05:03:56 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] Epoch[38] Batch[0] avg_epoch_loss=3.360235\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=3.3602352142333984\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] Epoch[38] Batch[5] avg_epoch_loss=3.322623\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=3.322622815767924\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] Epoch[38] Batch [5]#011Speed: 2091.58 samples/sec#011loss=3.322623\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] Epoch[38] Batch[10] avg_epoch_loss=3.327617\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=3.3336094856262206\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] Epoch[38] Batch [10]#011Speed: 1975.14 samples/sec#011loss=3.333609\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747890236.7373931, \"EndTime\": 1747890237.680733, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.0708885192871, \"count\": 1, \"min\": 943.0708885192871, \"max\": 943.0708885192871}}}\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1418.6423127091823 records/second\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=38, train loss <loss>=3.3276167566126045\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] Epoch[39] Batch[0] avg_epoch_loss=3.288022\n",
      "[05/22/2025 05:03:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=3.2880215644836426\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] Epoch[39] Batch[5] avg_epoch_loss=3.312709\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=3.312708854675293\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] Epoch[39] Batch [5]#011Speed: 1915.03 samples/sec#011loss=3.312709\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] Epoch[39] Batch[10] avg_epoch_loss=3.258266\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=3.19293532371521\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] Epoch[39] Batch [10]#011Speed: 1908.87 samples/sec#011loss=3.192935\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747890237.6807892, \"EndTime\": 1747890238.6639402, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 982.9063415527344, \"count\": 1, \"min\": 982.9063415527344, \"max\": 982.9063415527344}}}\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1382.512546413739 records/second\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=39, train loss <loss>=3.258266340602528\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] Epoch[40] Batch[0] avg_epoch_loss=3.302402\n",
      "[05/22/2025 05:03:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=3.3024017810821533\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] Epoch[40] Batch[5] avg_epoch_loss=3.231674\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=3.2316741943359375\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] Epoch[40] Batch [5]#011Speed: 2057.76 samples/sec#011loss=3.231674\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] Epoch[40] Batch[10] avg_epoch_loss=3.305987\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=3.395162582397461\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] Epoch[40] Batch [10]#011Speed: 2035.27 samples/sec#011loss=3.395163\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747890238.6639984, \"EndTime\": 1747890239.6047401, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.4952526092529, \"count\": 1, \"min\": 940.4952526092529, \"max\": 940.4952526092529}}}\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1383.1952164998208 records/second\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=40, train loss <loss>=3.305987098000266\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] Epoch[41] Batch[0] avg_epoch_loss=3.146627\n",
      "[05/22/2025 05:03:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=3.146627426147461\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] Epoch[41] Batch[5] avg_epoch_loss=3.203502\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=3.2035016616185508\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] Epoch[41] Batch [5]#011Speed: 2100.03 samples/sec#011loss=3.203502\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] Epoch[41] Batch[10] avg_epoch_loss=3.219724\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=3.239191675186157\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] Epoch[41] Batch [10]#011Speed: 1999.35 samples/sec#011loss=3.239192\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] processed a total of 1373 examples\n",
      "#metrics {\"StartTime\": 1747890239.6047935, \"EndTime\": 1747890240.568443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.3979797363281, \"count\": 1, \"min\": 963.3979797363281, \"max\": 963.3979797363281}}}\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1425.0386814212527 records/second\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=41, train loss <loss>=3.2197243950583716\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] Epoch[42] Batch[0] avg_epoch_loss=3.068182\n",
      "[05/22/2025 05:04:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=3.0681824684143066\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] Epoch[42] Batch[5] avg_epoch_loss=3.200142\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=3.2001417875289917\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] Epoch[42] Batch [5]#011Speed: 2044.01 samples/sec#011loss=3.200142\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] Epoch[42] Batch[10] avg_epoch_loss=3.215043\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=3.2329240322113035\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] Epoch[42] Batch [10]#011Speed: 1762.37 samples/sec#011loss=3.232924\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] processed a total of 1413 examples\n",
      "#metrics {\"StartTime\": 1747890240.568501, \"EndTime\": 1747890241.6100078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1041.2333011627197, \"count\": 1, \"min\": 1041.2333011627197, \"max\": 1041.2333011627197}}}\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1356.9016507281049 records/second\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=42, train loss <loss>=3.195561726888021\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] Epoch[43] Batch[0] avg_epoch_loss=3.313039\n",
      "[05/22/2025 05:04:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=3.3130393028259277\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] Epoch[43] Batch[5] avg_epoch_loss=3.229600\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=3.2296003500620523\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] Epoch[43] Batch [5]#011Speed: 2198.97 samples/sec#011loss=3.229600\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] Epoch[43] Batch[10] avg_epoch_loss=3.351825\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=3.49849534034729\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] Epoch[43] Batch [10]#011Speed: 2059.66 samples/sec#011loss=3.498495\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747890241.6100876, \"EndTime\": 1747890242.555663, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.2714920043945, \"count\": 1, \"min\": 945.2714920043945, \"max\": 945.2714920043945}}}\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1376.2019859232082 records/second\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=43, train loss <loss>=3.3518253456462515\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] Epoch[44] Batch[0] avg_epoch_loss=3.269652\n",
      "[05/22/2025 05:04:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=3.2696518898010254\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] Epoch[44] Batch[5] avg_epoch_loss=3.188814\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=3.18881364663442\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] Epoch[44] Batch [5]#011Speed: 2031.76 samples/sec#011loss=3.188814\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] Epoch[44] Batch[10] avg_epoch_loss=3.232140\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=3.2841314315795898\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] Epoch[44] Batch [10]#011Speed: 1943.45 samples/sec#011loss=3.284131\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] processed a total of 1392 examples\n",
      "#metrics {\"StartTime\": 1747890242.5557194, \"EndTime\": 1747890243.5128915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.8910598754883, \"count\": 1, \"min\": 956.8910598754883, \"max\": 956.8910598754883}}}\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1454.578767504672 records/second\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=44, train loss <loss>=3.232139912518588\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] Epoch[45] Batch[0] avg_epoch_loss=3.305323\n",
      "[05/22/2025 05:04:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=3.3053226470947266\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] Epoch[45] Batch[5] avg_epoch_loss=3.253622\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=3.2536219358444214\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] Epoch[45] Batch [5]#011Speed: 1993.45 samples/sec#011loss=3.253622\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] Epoch[45] Batch[10] avg_epoch_loss=3.295564\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=3.3458955764770506\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] Epoch[45] Batch [10]#011Speed: 1944.39 samples/sec#011loss=3.345896\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747890243.512951, \"EndTime\": 1747890244.4738898, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.6928825378418, \"count\": 1, \"min\": 960.6928825378418, \"max\": 960.6928825378418}}}\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1423.8464477340528 records/second\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=45, train loss <loss>=3.2955644997683438\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] Epoch[46] Batch[0] avg_epoch_loss=3.094189\n",
      "[05/22/2025 05:04:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=3.094188928604126\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] Epoch[46] Batch[5] avg_epoch_loss=3.210162\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=3.2101620038350425\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] Epoch[46] Batch [5]#011Speed: 2085.53 samples/sec#011loss=3.210162\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] Epoch[46] Batch[10] avg_epoch_loss=3.022442\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.79717698097229\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] Epoch[46] Batch [10]#011Speed: 2085.53 samples/sec#011loss=2.797177\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747890244.473947, \"EndTime\": 1747890245.4438255, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 969.6123600006104, \"count\": 1, \"min\": 969.6123600006104, \"max\": 969.6123600006104}}}\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1334.4115410705379 records/second\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=46, train loss <loss>=3.0224415388974277\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_c1267941-df3a-4679-9724-c26f18dfe7b7-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890245.4438798, \"EndTime\": 1747890245.4550078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.802745819091797, \"count\": 1, \"min\": 10.802745819091797, \"max\": 10.802745819091797}}}\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] Epoch[47] Batch[0] avg_epoch_loss=3.284361\n",
      "[05/22/2025 05:04:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=3.2843613624572754\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] Epoch[47] Batch[5] avg_epoch_loss=3.251620\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=3.2516196171442666\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] Epoch[47] Batch [5]#011Speed: 2147.39 samples/sec#011loss=3.251620\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] Epoch[47] Batch[10] avg_epoch_loss=3.294322\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=3.3455645561218263\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] Epoch[47] Batch [10]#011Speed: 2010.55 samples/sec#011loss=3.345565\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747890245.4550612, \"EndTime\": 1747890246.3839462, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.8380146026611, \"count\": 1, \"min\": 928.8380146026611, \"max\": 928.8380146026611}}}\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1415.618036617871 records/second\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=47, train loss <loss>=3.2943218621340664\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] Epoch[48] Batch[0] avg_epoch_loss=3.201534\n",
      "[05/22/2025 05:04:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=3.2015342712402344\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] Epoch[48] Batch[5] avg_epoch_loss=3.175254\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=3.1752540270487466\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] Epoch[48] Batch [5]#011Speed: 2072.98 samples/sec#011loss=3.175254\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] Epoch[48] Batch[10] avg_epoch_loss=3.181768\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=3.1895846366882323\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] Epoch[48] Batch [10]#011Speed: 2004.59 samples/sec#011loss=3.189585\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747890246.3840032, \"EndTime\": 1747890247.3278277, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.5453414916992, \"count\": 1, \"min\": 943.5453414916992, \"max\": 943.5453414916992}}}\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1441.2093897795407 records/second\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=48, train loss <loss>=3.1817679405212402\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] Epoch[49] Batch[0] avg_epoch_loss=2.979077\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.9790773391723633\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] Epoch[49] Batch[5] avg_epoch_loss=3.097008\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=3.097008148829142\n",
      "[05/22/2025 05:04:07 INFO 140551403046720] Epoch[49] Batch [5]#011Speed: 2124.79 samples/sec#011loss=3.097008\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] Epoch[49] Batch[10] avg_epoch_loss=3.213286\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=3.35281925201416\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] Epoch[49] Batch [10]#011Speed: 1903.84 samples/sec#011loss=3.352819\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] processed a total of 1377 examples\n",
      "#metrics {\"StartTime\": 1747890247.327888, \"EndTime\": 1747890248.2703435, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.1937465667725, \"count\": 1, \"min\": 942.1937465667725, \"max\": 942.1937465667725}}}\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1461.3460262935967 records/second\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=49, train loss <loss>=3.2132859230041504\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] Epoch[50] Batch[0] avg_epoch_loss=3.217297\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=3.217296600341797\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] Epoch[50] Batch[5] avg_epoch_loss=3.226914\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=3.2269142071406045\n",
      "[05/22/2025 05:04:08 INFO 140551403046720] Epoch[50] Batch [5]#011Speed: 2145.98 samples/sec#011loss=3.226914\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] Epoch[50] Batch[10] avg_epoch_loss=3.289729\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=3.3651075839996336\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] Epoch[50] Batch [10]#011Speed: 1970.29 samples/sec#011loss=3.365108\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747890248.2704034, \"EndTime\": 1747890249.207532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.8739128112793, \"count\": 1, \"min\": 936.8739128112793, \"max\": 936.8739128112793}}}\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1396.0012834922388 records/second\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=50, train loss <loss>=3.2897293784401636\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] Epoch[51] Batch[0] avg_epoch_loss=3.109418\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=3.109417676925659\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] Epoch[51] Batch[5] avg_epoch_loss=3.217960\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=3.217960317929586\n",
      "[05/22/2025 05:04:09 INFO 140551403046720] Epoch[51] Batch [5]#011Speed: 2117.02 samples/sec#011loss=3.217960\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] Epoch[51] Batch[10] avg_epoch_loss=3.071145\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.8949663639068604\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] Epoch[51] Batch [10]#011Speed: 2056.09 samples/sec#011loss=2.894966\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747890249.2075906, \"EndTime\": 1747890250.1428287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.9668025970459, \"count\": 1, \"min\": 934.9668025970459, \"max\": 934.9668025970459}}}\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1408.475426827667 records/second\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=51, train loss <loss>=3.0711448842828926\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] Epoch[52] Batch[0] avg_epoch_loss=3.138371\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=3.138371467590332\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] Epoch[52] Batch[5] avg_epoch_loss=3.129455\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=3.1294548908869424\n",
      "[05/22/2025 05:04:10 INFO 140551403046720] Epoch[52] Batch [5]#011Speed: 2164.66 samples/sec#011loss=3.129455\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] Epoch[52] Batch[10] avg_epoch_loss=3.397100\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=3.7182742595672607\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] Epoch[52] Batch [10]#011Speed: 2046.12 samples/sec#011loss=3.718274\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747890250.142887, \"EndTime\": 1747890251.0682108, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.025463104248, \"count\": 1, \"min\": 925.025463104248, \"max\": 925.025463104248}}}\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1414.962701961031 records/second\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=52, train loss <loss>=3.3971000584689053\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] Epoch[53] Batch[0] avg_epoch_loss=3.315952\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=3.3159515857696533\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] Epoch[53] Batch[5] avg_epoch_loss=3.237459\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=3.2374590635299683\n",
      "[05/22/2025 05:04:11 INFO 140551403046720] Epoch[53] Batch [5]#011Speed: 2068.99 samples/sec#011loss=3.237459\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] Epoch[53] Batch[10] avg_epoch_loss=3.212037\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=3.1815306663513185\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] Epoch[53] Batch [10]#011Speed: 1970.65 samples/sec#011loss=3.181531\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] processed a total of 1375 examples\n",
      "#metrics {\"StartTime\": 1747890251.0682688, \"EndTime\": 1747890252.017193, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.671817779541, \"count\": 1, \"min\": 948.671817779541, \"max\": 948.671817779541}}}\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1449.2629505098785 records/second\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=53, train loss <loss>=3.2120370648124\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] Epoch[54] Batch[0] avg_epoch_loss=2.997961\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.9979605674743652\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] Epoch[54] Batch[5] avg_epoch_loss=3.166048\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=3.166048049926758\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] Epoch[54] Batch [5]#011Speed: 2163.62 samples/sec#011loss=3.166048\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] Epoch[54] Batch[10] avg_epoch_loss=3.225297\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=3.2963955879211424\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] Epoch[54] Batch [10]#011Speed: 2022.46 samples/sec#011loss=3.296396\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747890252.0172498, \"EndTime\": 1747890252.9468925, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.3911457061768, \"count\": 1, \"min\": 929.3911457061768, \"max\": 929.3911457061768}}}\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1425.5299643428514 records/second\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=54, train loss <loss>=3.2252969308332964\n",
      "[05/22/2025 05:04:12 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] Epoch[55] Batch[0] avg_epoch_loss=3.148515\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=3.148515224456787\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] Epoch[55] Batch[5] avg_epoch_loss=3.201590\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=3.2015901803970337\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] Epoch[55] Batch [5]#011Speed: 2134.63 samples/sec#011loss=3.201590\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] Epoch[55] Batch[10] avg_epoch_loss=3.213972\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=3.2288299083709715\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] Epoch[55] Batch [10]#011Speed: 2035.71 samples/sec#011loss=3.228830\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747890252.9469512, \"EndTime\": 1747890253.8793695, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.1298599243164, \"count\": 1, \"min\": 932.1298599243164, \"max\": 932.1298599243164}}}\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1434.217805393613 records/second\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=55, train loss <loss>=3.213971874930642\n",
      "[05/22/2025 05:04:13 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] Epoch[56] Batch[0] avg_epoch_loss=3.210294\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=3.210294246673584\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] Epoch[56] Batch[5] avg_epoch_loss=3.219907\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=3.2199068864186606\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] Epoch[56] Batch [5]#011Speed: 2190.18 samples/sec#011loss=3.219907\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] Epoch[56] Batch[10] avg_epoch_loss=3.143577\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=3.0519802570343018\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] Epoch[56] Batch [10]#011Speed: 2096.82 samples/sec#011loss=3.051980\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747890253.8794262, \"EndTime\": 1747890254.7947564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.081262588501, \"count\": 1, \"min\": 915.081262588501, \"max\": 915.081262588501}}}\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1432.5293889921995 records/second\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=56, train loss <loss>=3.143576600334861\n",
      "[05/22/2025 05:04:14 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] Epoch[57] Batch[0] avg_epoch_loss=3.174590\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=3.1745896339416504\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] Epoch[57] Batch[5] avg_epoch_loss=3.179163\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=3.179162859916687\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] Epoch[57] Batch [5]#011Speed: 2184.23 samples/sec#011loss=3.179163\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] Epoch[57] Batch[10] avg_epoch_loss=3.115097\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=3.038218688964844\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] Epoch[57] Batch [10]#011Speed: 2131.08 samples/sec#011loss=3.038219\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747890254.794812, \"EndTime\": 1747890255.6990142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 903.7935733795166, \"count\": 1, \"min\": 903.7935733795166, \"max\": 903.7935733795166}}}\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1472.543127253774 records/second\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=57, train loss <loss>=3.115097327665849\n",
      "[05/22/2025 05:04:15 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] Epoch[58] Batch[0] avg_epoch_loss=3.166729\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=3.166729211807251\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] Epoch[58] Batch[5] avg_epoch_loss=3.150253\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=3.1502525806427\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] Epoch[58] Batch [5]#011Speed: 2176.47 samples/sec#011loss=3.150253\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] Epoch[58] Batch[10] avg_epoch_loss=3.016015\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.85493061542511\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] Epoch[58] Batch [10]#011Speed: 2044.98 samples/sec#011loss=2.854931\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747890255.6990702, \"EndTime\": 1747890256.6108365, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.5176200866699, \"count\": 1, \"min\": 911.5176200866699, \"max\": 911.5176200866699}}}\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1461.1635582446306 records/second\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=58, train loss <loss>=3.0160153237256138\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_cabf6b79-9b63-490c-87d3-f0589ec501c6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890256.6108923, \"EndTime\": 1747890256.6218915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.72835922241211, \"count\": 1, \"min\": 10.72835922241211, \"max\": 10.72835922241211}}}\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] Epoch[59] Batch[0] avg_epoch_loss=3.115420\n",
      "[05/22/2025 05:04:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=3.115419626235962\n",
      "[05/22/2025 05:04:17 INFO 140551403046720] Epoch[59] Batch[5] avg_epoch_loss=3.111832\n",
      "[05/22/2025 05:04:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=3.1118319034576416\n",
      "[05/22/2025 05:04:17 INFO 140551403046720] Epoch[59] Batch [5]#011Speed: 2163.76 samples/sec#011loss=3.111832\n",
      "[05/22/2025 05:04:17 INFO 140551403046720] processed a total of 1225 examples\n",
      "#metrics {\"StartTime\": 1747890256.621943, \"EndTime\": 1747890257.4587648, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 836.7717266082764, \"count\": 1, \"min\": 836.7717266082764, \"max\": 836.7717266082764}}}\n",
      "[05/22/2025 05:04:17 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1463.7994404082667 records/second\n",
      "[05/22/2025 05:04:17 INFO 140551403046720] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/22/2025 05:04:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=59, train loss <loss>=3.101026725769043\n",
      "[05/22/2025 05:04:17 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:17 INFO 140551403046720] Epoch[60] Batch[0] avg_epoch_loss=3.089666\n",
      "[05/22/2025 05:04:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=3.0896663665771484\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] Epoch[60] Batch[5] avg_epoch_loss=3.119649\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=3.119648734728495\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] Epoch[60] Batch [5]#011Speed: 2197.17 samples/sec#011loss=3.119649\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] Epoch[60] Batch[10] avg_epoch_loss=3.176415\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=3.24453444480896\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] Epoch[60] Batch [10]#011Speed: 2029.24 samples/sec#011loss=3.244534\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747890257.4588265, \"EndTime\": 1747890258.371456, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.3365879058838, \"count\": 1, \"min\": 912.3365879058838, \"max\": 912.3365879058838}}}\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1454.30828451533 records/second\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=60, train loss <loss>=3.176414966583252\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] Epoch[61] Batch[0] avg_epoch_loss=3.224069\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=3.224069356918335\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] Epoch[61] Batch[5] avg_epoch_loss=3.228725\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=3.2287245988845825\n",
      "[05/22/2025 05:04:18 INFO 140551403046720] Epoch[61] Batch [5]#011Speed: 2175.95 samples/sec#011loss=3.228725\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] Epoch[61] Batch[10] avg_epoch_loss=3.272574\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=3.3251935958862306\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] Epoch[61] Batch [10]#011Speed: 2088.80 samples/sec#011loss=3.325194\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747890258.3715515, \"EndTime\": 1747890259.2880943, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.2483215332031, \"count\": 1, \"min\": 916.2483215332031, \"max\": 916.2483215332031}}}\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1420.8823775978144 records/second\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=61, train loss <loss>=3.2725741429762407\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] Epoch[62] Batch[0] avg_epoch_loss=3.015898\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=3.015897750854492\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] Epoch[62] Batch[5] avg_epoch_loss=3.199438\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=3.1994382540384927\n",
      "[05/22/2025 05:04:19 INFO 140551403046720] Epoch[62] Batch [5]#011Speed: 2216.96 samples/sec#011loss=3.199438\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] Epoch[62] Batch[10] avg_epoch_loss=3.184359\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=3.166263961791992\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] Epoch[62] Batch [10]#011Speed: 2070.92 samples/sec#011loss=3.166264\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] processed a total of 1399 examples\n",
      "#metrics {\"StartTime\": 1747890259.2881489, \"EndTime\": 1747890260.1948543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.456470489502, \"count\": 1, \"min\": 906.456470489502, \"max\": 906.456470489502}}}\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1543.2280103410822 records/second\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=62, train loss <loss>=3.1843590302900835\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] Epoch[63] Batch[0] avg_epoch_loss=3.033805\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=3.0338051319122314\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] Epoch[63] Batch[5] avg_epoch_loss=3.085398\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=3.0853976011276245\n",
      "[05/22/2025 05:04:20 INFO 140551403046720] Epoch[63] Batch [5]#011Speed: 2270.27 samples/sec#011loss=3.085398\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747890260.1949103, \"EndTime\": 1747890261.0273986, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 832.2043418884277, \"count\": 1, \"min\": 832.2043418884277, \"max\": 832.2043418884277}}}\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1533.1081682876895 records/second\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=63, train loss <loss>=3.077025055885315\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] Epoch[64] Batch[0] avg_epoch_loss=2.900107\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.900106906890869\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] Epoch[64] Batch[5] avg_epoch_loss=3.067662\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=3.067662080128988\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] Epoch[64] Batch [5]#011Speed: 2207.80 samples/sec#011loss=3.067662\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] Epoch[64] Batch[10] avg_epoch_loss=3.126575\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=3.197269821166992\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] Epoch[64] Batch [10]#011Speed: 2106.10 samples/sec#011loss=3.197270\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747890261.0274603, \"EndTime\": 1747890261.9299664, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 902.1813869476318, \"count\": 1, \"min\": 902.1813869476318, \"max\": 902.1813869476318}}}\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1476.2923679972857 records/second\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=64, train loss <loss>=3.126574689691717\n",
      "[05/22/2025 05:04:21 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] Epoch[65] Batch[0] avg_epoch_loss=3.274837\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=3.274836540222168\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] Epoch[65] Batch[5] avg_epoch_loss=3.102922\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=3.102922042210897\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] Epoch[65] Batch [5]#011Speed: 2196.11 samples/sec#011loss=3.102922\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] Epoch[65] Batch[10] avg_epoch_loss=3.124109\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=3.149533414840698\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] Epoch[65] Batch [10]#011Speed: 2211.90 samples/sec#011loss=3.149533\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747890261.930017, \"EndTime\": 1747890262.8250325, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 894.7832584381104, \"count\": 1, \"min\": 894.7832584381104, \"max\": 894.7832584381104}}}\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1449.376326782469 records/second\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=65, train loss <loss>=3.1241090297698975\n",
      "[05/22/2025 05:04:22 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] Epoch[66] Batch[0] avg_epoch_loss=3.247208\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=3.2472081184387207\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] Epoch[66] Batch[5] avg_epoch_loss=3.125701\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=3.1257009506225586\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] Epoch[66] Batch [5]#011Speed: 2186.57 samples/sec#011loss=3.125701\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] Epoch[66] Batch[10] avg_epoch_loss=3.086141\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=3.0386696338653563\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] Epoch[66] Batch [10]#011Speed: 2193.91 samples/sec#011loss=3.038670\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747890262.8250887, \"EndTime\": 1747890263.721218, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 895.8814144134521, \"count\": 1, \"min\": 895.8814144134521, \"max\": 895.8814144134521}}}\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1486.66742452788 records/second\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=66, train loss <loss>=3.086141261187467\n",
      "[05/22/2025 05:04:23 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] Epoch[67] Batch[0] avg_epoch_loss=3.160764\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=3.160764217376709\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] Epoch[67] Batch[5] avg_epoch_loss=3.109322\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=3.109322468439738\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] Epoch[67] Batch [5]#011Speed: 2029.36 samples/sec#011loss=3.109322\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] Epoch[67] Batch[10] avg_epoch_loss=3.106021\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=3.102058506011963\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] Epoch[67] Batch [10]#011Speed: 2149.76 samples/sec#011loss=3.102059\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747890263.7212732, \"EndTime\": 1747890264.6494215, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.9017448425293, \"count\": 1, \"min\": 927.9017448425293, \"max\": 927.9017448425293}}}\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1418.1271712061587 records/second\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=67, train loss <loss>=3.1060206673362036\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] Epoch[68] Batch[0] avg_epoch_loss=3.085759\n",
      "[05/22/2025 05:04:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=3.085758924484253\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] Epoch[68] Batch[5] avg_epoch_loss=3.056872\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=3.056871692339579\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] Epoch[68] Batch [5]#011Speed: 2209.65 samples/sec#011loss=3.056872\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] Epoch[68] Batch[10] avg_epoch_loss=3.015217\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.9652318954467773\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] Epoch[68] Batch [10]#011Speed: 2017.16 samples/sec#011loss=2.965232\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747890264.6494768, \"EndTime\": 1747890265.569761, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.0363159179688, \"count\": 1, \"min\": 920.0363159179688, \"max\": 920.0363159179688}}}\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1426.9837155900307 records/second\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=68, train loss <loss>=3.0152172392064873\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_54e93a6a-fce9-42fe-b3e9-1558fc4e2bdd-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890265.5698192, \"EndTime\": 1747890265.5808215, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.732173919677734, \"count\": 1, \"min\": 10.732173919677734, \"max\": 10.732173919677734}}}\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] Epoch[69] Batch[0] avg_epoch_loss=2.967711\n",
      "[05/22/2025 05:04:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.9677107334136963\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] Epoch[69] Batch[5] avg_epoch_loss=3.067924\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=3.0679244995117188\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] Epoch[69] Batch [5]#011Speed: 2070.46 samples/sec#011loss=3.067924\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] Epoch[69] Batch[10] avg_epoch_loss=3.054755\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=3.038950777053833\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] Epoch[69] Batch [10]#011Speed: 1978.05 samples/sec#011loss=3.038951\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747890265.5808725, \"EndTime\": 1747890266.5223048, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.3812160491943, \"count\": 1, \"min\": 941.3812160491943, \"max\": 941.3812160491943}}}\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1422.2311110053138 records/second\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=69, train loss <loss>=3.054754625667225\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] Epoch[70] Batch[0] avg_epoch_loss=3.005112\n",
      "[05/22/2025 05:04:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=3.0051121711730957\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] Epoch[70] Batch[5] avg_epoch_loss=3.134222\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=3.1342221101125083\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] Epoch[70] Batch [5]#011Speed: 2129.67 samples/sec#011loss=3.134222\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] Epoch[70] Batch[10] avg_epoch_loss=3.101580\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=3.0624093532562258\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] Epoch[70] Batch [10]#011Speed: 2074.41 samples/sec#011loss=3.062409\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747890266.5223703, \"EndTime\": 1747890267.4452846, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.5776195526123, \"count\": 1, \"min\": 922.5776195526123, \"max\": 922.5776195526123}}}\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1450.1469408553833 records/second\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=70, train loss <loss>=3.101579947905107\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] Epoch[71] Batch[0] avg_epoch_loss=2.940614\n",
      "[05/22/2025 05:04:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.9406144618988037\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] Epoch[71] Batch[5] avg_epoch_loss=3.039209\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=3.0392090876897178\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] Epoch[71] Batch [5]#011Speed: 2182.58 samples/sec#011loss=3.039209\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] Epoch[71] Batch[10] avg_epoch_loss=3.054153\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=3.0720863819122313\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] Epoch[71] Batch [10]#011Speed: 1888.67 samples/sec#011loss=3.072086\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] processed a total of 1373 examples\n",
      "#metrics {\"StartTime\": 1747890267.4453413, \"EndTime\": 1747890268.3875747, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.9128894805908, \"count\": 1, \"min\": 941.9128894805908, \"max\": 941.9128894805908}}}\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1457.540979756134 records/second\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=71, train loss <loss>=3.054153312336315\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] Epoch[72] Batch[0] avg_epoch_loss=3.130433\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=3.130432605743408\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] Epoch[72] Batch[5] avg_epoch_loss=3.080210\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=3.0802104473114014\n",
      "[05/22/2025 05:04:28 INFO 140551403046720] Epoch[72] Batch [5]#011Speed: 2183.99 samples/sec#011loss=3.080210\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] Epoch[72] Batch[10] avg_epoch_loss=3.090434\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=3.102701997756958\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] Epoch[72] Batch [10]#011Speed: 2078.80 samples/sec#011loss=3.102702\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747890268.3876317, \"EndTime\": 1747890269.2986531, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.7143878936768, \"count\": 1, \"min\": 910.7143878936768, \"max\": 910.7143878936768}}}\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1442.5945049482793 records/second\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=72, train loss <loss>=3.090433879332109\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] Epoch[73] Batch[0] avg_epoch_loss=3.075829\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=3.075829029083252\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] Epoch[73] Batch[5] avg_epoch_loss=3.093462\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=3.093461831410726\n",
      "[05/22/2025 05:04:29 INFO 140551403046720] Epoch[73] Batch [5]#011Speed: 2173.73 samples/sec#011loss=3.093462\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] Epoch[73] Batch[10] avg_epoch_loss=3.132474\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=3.179289197921753\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] Epoch[73] Batch [10]#011Speed: 2094.65 samples/sec#011loss=3.179289\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747890269.2987683, \"EndTime\": 1747890270.2061713, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.1366786956787, \"count\": 1, \"min\": 907.1366786956787, \"max\": 907.1366786956787}}}\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1473.7304152279416 records/second\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=73, train loss <loss>=3.13247427073392\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] Epoch[74] Batch[0] avg_epoch_loss=3.117452\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=3.1174516677856445\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] Epoch[74] Batch[5] avg_epoch_loss=3.024079\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=3.024079124132792\n",
      "[05/22/2025 05:04:30 INFO 140551403046720] Epoch[74] Batch [5]#011Speed: 2168.68 samples/sec#011loss=3.024079\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] Epoch[74] Batch[10] avg_epoch_loss=3.009817\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.992701864242554\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] Epoch[74] Batch [10]#011Speed: 2097.17 samples/sec#011loss=2.992702\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747890270.206229, \"EndTime\": 1747890271.115492, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.0142250061035, \"count\": 1, \"min\": 909.0142250061035, \"max\": 909.0142250061035}}}\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1505.8852438250728 records/second\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=74, train loss <loss>=3.009816733273593\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_fde44383-b984-40d9-9b86-9cf7e5732bb8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890271.115549, \"EndTime\": 1747890271.1256266, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.814739227294922, \"count\": 1, \"min\": 9.814739227294922, \"max\": 9.814739227294922}}}\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] Epoch[75] Batch[0] avg_epoch_loss=3.123350\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=3.123350143432617\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] Epoch[75] Batch[5] avg_epoch_loss=3.063434\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=3.063434441884359\n",
      "[05/22/2025 05:04:31 INFO 140551403046720] Epoch[75] Batch [5]#011Speed: 2137.85 samples/sec#011loss=3.063434\n",
      "[05/22/2025 05:04:32 INFO 140551403046720] Epoch[75] Batch[10] avg_epoch_loss=3.105418\n",
      "[05/22/2025 05:04:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=3.1557990074157716\n",
      "[05/22/2025 05:04:32 INFO 140551403046720] Epoch[75] Batch [10]#011Speed: 2091.26 samples/sec#011loss=3.155799\n",
      "[05/22/2025 05:04:32 INFO 140551403046720] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747890271.1256776, \"EndTime\": 1747890272.0437984, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.0750846862793, \"count\": 1, \"min\": 918.0750846862793, \"max\": 918.0750846862793}}}\n",
      "[05/22/2025 05:04:32 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1452.8700318892836 records/second\n",
      "[05/22/2025 05:04:32 INFO 140551403046720] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/22/2025 05:04:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=75, train loss <loss>=3.105418335307728\n",
      "[05/22/2025 05:04:32 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:37 INFO 140551403046720] processed a total of 1265 examples\n",
      "#metrics {\"StartTime\": 1747890276.5161574, \"EndTime\": 1747890277.3667722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 850.2931594848633, \"count\": 1, \"min\": 850.2931594848633, \"max\": 850.2931594848633}}}\n",
      "[05/22/2025 05:04:37 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1487.5586831820297 records/second\n",
      "[05/22/2025 05:04:37 INFO 140551403046720] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/22/2025 05:04:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=81, train loss <loss>=3.0067787647247313\n",
      "[05/22/2025 05:04:37 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:37 INFO 140551403046720] Epoch[82] Batch[0] avg_epoch_loss=3.009158\n",
      "[05/22/2025 05:04:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=3.009158134460449\n",
      "[05/22/2025 05:04:37 INFO 140551403046720] Epoch[82] Batch[5] avg_epoch_loss=2.944525\n",
      "[05/22/2025 05:04:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.9445246855417886\n",
      "[05/22/2025 05:04:37 INFO 140551403046720] Epoch[82] Batch [5]#011Speed: 2233.30 samples/sec#011loss=2.944525\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] processed a total of 1263 examples\n",
      "#metrics {\"StartTime\": 1747890277.3668346, \"EndTime\": 1747890278.1977718, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 830.5721282958984, \"count\": 1, \"min\": 830.5721282958984, \"max\": 830.5721282958984}}}\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1520.4665904721667 records/second\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.9384124755859373\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_371ca3f5-0e6a-4cb3-80b8-b6784812766a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890278.1978335, \"EndTime\": 1747890278.2086518, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.430097579956055, \"count\": 1, \"min\": 10.430097579956055, \"max\": 10.430097579956055}}}\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] Epoch[83] Batch[0] avg_epoch_loss=3.049378\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=3.0493781566619873\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] Epoch[83] Batch[5] avg_epoch_loss=2.990988\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.990987777709961\n",
      "[05/22/2025 05:04:38 INFO 140551403046720] Epoch[83] Batch [5]#011Speed: 2250.46 samples/sec#011loss=2.990988\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] Epoch[83] Batch[10] avg_epoch_loss=2.970050\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.9449253559112547\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] Epoch[83] Batch [10]#011Speed: 2078.20 samples/sec#011loss=2.944925\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747890278.2087002, \"EndTime\": 1747890279.1101098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 901.3638496398926, \"count\": 1, \"min\": 901.3638496398926, \"max\": 901.3638496398926}}}\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1490.9333834089316 records/second\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.9700503132560034\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] Epoch[84] Batch[0] avg_epoch_loss=3.055149\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=3.0551490783691406\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] Epoch[84] Batch[5] avg_epoch_loss=3.031250\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=3.031250278155009\n",
      "[05/22/2025 05:04:39 INFO 140551403046720] Epoch[84] Batch [5]#011Speed: 2193.62 samples/sec#011loss=3.031250\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] Epoch[84] Batch[10] avg_epoch_loss=3.131132\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=3.250990867614746\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] Epoch[84] Batch [10]#011Speed: 2200.27 samples/sec#011loss=3.250991\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747890279.1101665, \"EndTime\": 1747890280.0061371, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 895.721435546875, \"count\": 1, \"min\": 895.721435546875, \"max\": 895.721435546875}}}\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1469.0265138903637 records/second\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=84, train loss <loss>=3.1311323642730713\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] Epoch[85] Batch[0] avg_epoch_loss=2.881986\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.881986379623413\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] Epoch[85] Batch[5] avg_epoch_loss=3.028411\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=3.0284109115600586\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] Epoch[85] Batch [5]#011Speed: 2171.26 samples/sec#011loss=3.028411\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] Epoch[85] Batch[10] avg_epoch_loss=3.177677\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=3.356795406341553\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] Epoch[85] Batch [10]#011Speed: 2004.06 samples/sec#011loss=3.356795\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747890280.0062182, \"EndTime\": 1747890280.9332654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.7745018005371, \"count\": 1, \"min\": 926.7745018005371, \"max\": 926.7745018005371}}}\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1425.2428042374454 records/second\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=85, train loss <loss>=3.1776765910061924\n",
      "[05/22/2025 05:04:40 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] Epoch[86] Batch[0] avg_epoch_loss=3.002187\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=3.002187490463257\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] Epoch[86] Batch[5] avg_epoch_loss=2.997933\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.997933348019918\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] Epoch[86] Batch [5]#011Speed: 2069.31 samples/sec#011loss=2.997933\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] Epoch[86] Batch[10] avg_epoch_loss=2.982658\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.9643274307250977\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] Epoch[86] Batch [10]#011Speed: 1927.59 samples/sec#011loss=2.964327\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747890280.933322, \"EndTime\": 1747890281.886258, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.6660442352295, \"count\": 1, \"min\": 952.6660442352295, \"max\": 952.6660442352295}}}\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1398.0555011835197 records/second\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.982657931067727\n",
      "[05/22/2025 05:04:41 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] Epoch[87] Batch[0] avg_epoch_loss=3.084707\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=3.0847067832946777\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] Epoch[87] Batch[5] avg_epoch_loss=3.076753\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=3.076752781867981\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] Epoch[87] Batch [5]#011Speed: 2247.77 samples/sec#011loss=3.076753\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] Epoch[87] Batch[10] avg_epoch_loss=3.002913\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.9143046379089355\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] Epoch[87] Batch [10]#011Speed: 1908.21 samples/sec#011loss=2.914305\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] processed a total of 1385 examples\n",
      "#metrics {\"StartTime\": 1747890281.8863158, \"EndTime\": 1747890282.815525, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.9040565490723, \"count\": 1, \"min\": 928.9040565490723, \"max\": 928.9040565490723}}}\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1490.8658405509811 records/second\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=87, train loss <loss>=3.0029127164320513\n",
      "[05/22/2025 05:04:42 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] Epoch[88] Batch[0] avg_epoch_loss=2.978762\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.97876238822937\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] Epoch[88] Batch[5] avg_epoch_loss=2.943978\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.9439779122670493\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] Epoch[88] Batch [5]#011Speed: 2154.86 samples/sec#011loss=2.943978\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] Epoch[88] Batch[10] avg_epoch_loss=3.166260\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=3.432998704910278\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] Epoch[88] Batch [10]#011Speed: 2002.89 samples/sec#011loss=3.432999\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747890282.8155818, \"EndTime\": 1747890283.7559888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.079927444458, \"count\": 1, \"min\": 940.079927444458, \"max\": 940.079927444458}}}\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1371.038654132421 records/second\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=88, train loss <loss>=3.166260090741244\n",
      "[05/22/2025 05:04:43 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] Epoch[89] Batch[0] avg_epoch_loss=3.028371\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=3.0283708572387695\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] Epoch[89] Batch[5] avg_epoch_loss=2.994636\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.994635542233785\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] Epoch[89] Batch [5]#011Speed: 2125.75 samples/sec#011loss=2.994636\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] Epoch[89] Batch[10] avg_epoch_loss=3.002852\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=3.0127126693725588\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] Epoch[89] Batch [10]#011Speed: 2035.08 samples/sec#011loss=3.012713\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747890283.7560441, \"EndTime\": 1747890284.6835732, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.2716045379639, \"count\": 1, \"min\": 927.2716045379639, \"max\": 927.2716045379639}}}\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1425.5622780942626 records/second\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=89, train loss <loss>=3.0028524182059546\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:44 INFO 140551403046720] Epoch[90] Batch[0] avg_epoch_loss=2.899906\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.8999063968658447\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] Epoch[90] Batch[5] avg_epoch_loss=3.000530\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=3.0005298852920532\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] Epoch[90] Batch [5]#011Speed: 2104.67 samples/sec#011loss=3.000530\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747890284.683627, \"EndTime\": 1747890285.557107, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 873.1575012207031, \"count\": 1, \"min\": 873.1575012207031, \"max\": 873.1575012207031}}}\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1460.060179928211 records/second\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.9744932651519775\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] Epoch[91] Batch[0] avg_epoch_loss=2.902324\n",
      "[05/22/2025 05:04:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.9023239612579346\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] Epoch[91] Batch[5] avg_epoch_loss=3.051308\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=3.051307956377665\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] Epoch[91] Batch [5]#011Speed: 2176.77 samples/sec#011loss=3.051308\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] Epoch[91] Batch[10] avg_epoch_loss=3.120645\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=3.203850030899048\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] Epoch[91] Batch [10]#011Speed: 2163.14 samples/sec#011loss=3.203850\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747890285.5571694, \"EndTime\": 1747890286.4585416, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 901.0252952575684, \"count\": 1, \"min\": 901.0252952575684, \"max\": 901.0252952575684}}}\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1459.2870764886793 records/second\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=91, train loss <loss>=3.1206452629782935\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] Epoch[92] Batch[0] avg_epoch_loss=2.982171\n",
      "[05/22/2025 05:04:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.9821712970733643\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] Epoch[92] Batch[5] avg_epoch_loss=3.028187\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=3.028187354405721\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] Epoch[92] Batch [5]#011Speed: 2050.53 samples/sec#011loss=3.028187\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] processed a total of 1239 examples\n",
      "#metrics {\"StartTime\": 1747890286.4586072, \"EndTime\": 1747890287.3208127, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 861.2923622131348, \"count\": 1, \"min\": 861.2923622131348, \"max\": 861.2923622131348}}}\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1438.3830235273213 records/second\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.9367959976196287\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_7039fda1-e213-469c-8d40-6b81714412ec-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890287.3208735, \"EndTime\": 1747890287.3315916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.412216186523438, \"count\": 1, \"min\": 10.412216186523438, \"max\": 10.412216186523438}}}\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] Epoch[93] Batch[0] avg_epoch_loss=2.900642\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.900641679763794\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] Epoch[93] Batch[5] avg_epoch_loss=2.909221\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.9092214902242026\n",
      "[05/22/2025 05:04:47 INFO 140551403046720] Epoch[93] Batch [5]#011Speed: 2169.45 samples/sec#011loss=2.909221\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] processed a total of 1272 examples\n",
      "#metrics {\"StartTime\": 1747890287.3316424, \"EndTime\": 1747890288.198292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 866.6017055511475, \"count\": 1, \"min\": 866.6017055511475, \"max\": 866.6017055511475}}}\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1467.6416241356364 records/second\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.9213284730911253\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_98711853-390f-4664-9f56-0f90218cecb8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890288.1983566, \"EndTime\": 1747890288.2082653, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.51528549194336, \"count\": 1, \"min\": 9.51528549194336, \"max\": 9.51528549194336}}}\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] Epoch[94] Batch[0] avg_epoch_loss=2.910262\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.910261869430542\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] Epoch[94] Batch[5] avg_epoch_loss=2.951420\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.9514201879501343\n",
      "[05/22/2025 05:04:48 INFO 140551403046720] Epoch[94] Batch [5]#011Speed: 2126.83 samples/sec#011loss=2.951420\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] Epoch[94] Batch[10] avg_epoch_loss=2.945356\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=2.9380800247192385\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] Epoch[94] Batch [10]#011Speed: 1975.11 samples/sec#011loss=2.938080\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747890288.2083144, \"EndTime\": 1747890289.165614, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.2513103485107, \"count\": 1, \"min\": 957.2513103485107, \"max\": 957.2513103485107}}}\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1419.5555283269366 records/second\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.945356477390636\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] Epoch[95] Batch[0] avg_epoch_loss=2.953012\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.9530115127563477\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] Epoch[95] Batch[5] avg_epoch_loss=2.951596\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.9515955448150635\n",
      "[05/22/2025 05:04:49 INFO 140551403046720] Epoch[95] Batch [5]#011Speed: 2178.82 samples/sec#011loss=2.951596\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] Epoch[95] Batch[10] avg_epoch_loss=2.933973\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.9128252983093263\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] Epoch[95] Batch [10]#011Speed: 1934.93 samples/sec#011loss=2.912825\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747890289.1656737, \"EndTime\": 1747890290.0968275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.8230876922607, \"count\": 1, \"min\": 930.8230876922607, \"max\": 930.8230876922607}}}\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1471.678075666151 records/second\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.933972705494274\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] Epoch[96] Batch[0] avg_epoch_loss=3.096153\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=3.0961527824401855\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] Epoch[96] Batch[5] avg_epoch_loss=2.931449\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.9314485788345337\n",
      "[05/22/2025 05:04:50 INFO 140551403046720] Epoch[96] Batch [5]#011Speed: 2148.97 samples/sec#011loss=2.931449\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] Epoch[96] Batch[10] avg_epoch_loss=2.925664\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.918722152709961\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] Epoch[96] Batch [10]#011Speed: 2007.94 samples/sec#011loss=2.918722\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747890290.0968838, \"EndTime\": 1747890291.0278454, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.7191371917725, \"count\": 1, \"min\": 930.7191371917725, \"max\": 930.7191371917725}}}\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1456.7994651762638 records/second\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.9256638396870005\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] Epoch[97] Batch[0] avg_epoch_loss=2.602899\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.6028990745544434\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] Epoch[97] Batch[5] avg_epoch_loss=2.888910\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.888909618059794\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] Epoch[97] Batch [5]#011Speed: 2098.79 samples/sec#011loss=2.888910\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] Epoch[97] Batch[10] avg_epoch_loss=2.937701\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.996250772476196\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] Epoch[97] Batch [10]#011Speed: 2053.51 samples/sec#011loss=2.996251\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] processed a total of 1364 examples\n",
      "#metrics {\"StartTime\": 1747890291.0279052, \"EndTime\": 1747890291.9512808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.1276512145996, \"count\": 1, \"min\": 923.1276512145996, \"max\": 923.1276512145996}}}\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1477.4500026212265 records/second\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.9377010518854316\n",
      "[05/22/2025 05:04:51 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] Epoch[98] Batch[0] avg_epoch_loss=2.891267\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.8912665843963623\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] Epoch[98] Batch[5] avg_epoch_loss=2.925531\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.925530989964803\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] Epoch[98] Batch [5]#011Speed: 2143.02 samples/sec#011loss=2.925531\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] Epoch[98] Batch[10] avg_epoch_loss=2.921670\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=2.9170377254486084\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] Epoch[98] Batch [10]#011Speed: 2164.56 samples/sec#011loss=2.917038\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747890291.951338, \"EndTime\": 1747890292.8642828, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.6970767974854, \"count\": 1, \"min\": 912.6970767974854, \"max\": 912.6970767974854}}}\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1414.3600835632333 records/second\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.9216704151847144\n",
      "[05/22/2025 05:04:52 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:53 INFO 140551403046720] Epoch[99] Batch[0] avg_epoch_loss=2.981103\n",
      "[05/22/2025 05:04:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.9811034202575684\n",
      "[05/22/2025 05:04:53 INFO 140551403046720] Epoch[99] Batch[5] avg_epoch_loss=2.966644\n",
      "[05/22/2025 05:04:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.966643969217936\n",
      "[05/22/2025 05:04:53 INFO 140551403046720] Epoch[99] Batch [5]#011Speed: 2149.49 samples/sec#011loss=2.966644\n",
      "[05/22/2025 05:04:53 INFO 140551403046720] processed a total of 1272 examples\n",
      "#metrics {\"StartTime\": 1747890292.8643384, \"EndTime\": 1747890293.7292335, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.6390438079834, \"count\": 1, \"min\": 864.6390438079834, \"max\": 864.6390438079834}}}\n",
      "[05/22/2025 05:04:53 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1470.9807995010667 records/second\n",
      "[05/22/2025 05:04:53 INFO 140551403046720] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/22/2025 05:04:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.9437423229217528\n",
      "[05/22/2025 05:04:53 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] Epoch[100] Batch[0] avg_epoch_loss=2.952213\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.9522125720977783\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] Epoch[100] Batch[5] avg_epoch_loss=2.923077\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.923076629638672\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] Epoch[100] Batch [5]#011Speed: 2124.25 samples/sec#011loss=2.923077\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] Epoch[100] Batch[10] avg_epoch_loss=3.009345\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=3.1128663539886476\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] Epoch[100] Batch [10]#011Speed: 2107.59 samples/sec#011loss=3.112866\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747890293.729285, \"EndTime\": 1747890294.6516619, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.5426445007324, \"count\": 1, \"min\": 921.5426445007324, \"max\": 921.5426445007324}}}\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1418.0781154773028 records/second\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=100, train loss <loss>=3.009344686161388\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] Epoch[101] Batch[0] avg_epoch_loss=3.091935\n",
      "[05/22/2025 05:04:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=3.0919349193573\n",
      "[05/22/2025 05:04:55 INFO 140551403046720] Epoch[101] Batch[5] avg_epoch_loss=2.984977\n",
      "[05/22/2025 05:04:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.984976887702942\n",
      "[05/22/2025 05:04:55 INFO 140551403046720] Epoch[101] Batch [5]#011Speed: 2175.13 samples/sec#011loss=2.984977\n",
      "[05/22/2025 05:04:55 INFO 140551403046720] processed a total of 1277 examples\n",
      "#metrics {\"StartTime\": 1747890294.6517534, \"EndTime\": 1747890295.4986985, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 846.5445041656494, \"count\": 1, \"min\": 846.5445041656494, \"max\": 846.5445041656494}}}\n",
      "[05/22/2025 05:04:55 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1508.3095048012167 records/second\n",
      "[05/22/2025 05:04:55 INFO 140551403046720] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/22/2025 05:04:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.9828045129776\n",
      "[05/22/2025 05:04:55 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:04:55 INFO 140551403046720] Epoch[102] Batch[0] avg_epoch_loss=2.915355\n",
      "[05/22/2025 05:04:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.9153549671173096\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] Epoch[102] Batch[5] avg_epoch_loss=2.866976\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.866976261138916\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] Epoch[102] Batch [5]#011Speed: 2149.29 samples/sec#011loss=2.866976\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] processed a total of 1245 examples\n",
      "#metrics {\"StartTime\": 1747890295.498767, \"EndTime\": 1747890296.3699858, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 870.8643913269043, \"count\": 1, \"min\": 870.8643913269043, \"max\": 870.8643913269043}}}\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1429.472025026875 records/second\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.917825126647949\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_339f1726-0a80-4636-a922-1f4ce1b948f5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890296.3700407, \"EndTime\": 1747890296.3805614, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.126113891601562, \"count\": 1, \"min\": 10.126113891601562, \"max\": 10.126113891601562}}}\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] Epoch[103] Batch[0] avg_epoch_loss=2.896106\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.896106004714966\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] Epoch[103] Batch[5] avg_epoch_loss=2.919735\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.9197352727254233\n",
      "[05/22/2025 05:04:56 INFO 140551403046720] Epoch[103] Batch [5]#011Speed: 2198.67 samples/sec#011loss=2.919735\n",
      "[05/22/2025 05:04:57 INFO 140551403046720] processed a total of 1250 examples\n",
      "#metrics {\"StartTime\": 1747890296.3806183, \"EndTime\": 1747890297.229742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 849.0726947784424, \"count\": 1, \"min\": 849.0726947784424, \"max\": 849.0726947784424}}}\n",
      "[05/22/2025 05:04:57 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1472.0368368593208 records/second\n",
      "[05/22/2025 05:04:57 INFO 140551403046720] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/22/2025 05:04:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=103, train loss <loss>=3.0220282793045046\n",
      "[05/22/2025 05:04:57 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:05:57 INFO 140551403046720] Epoch[169] Batch[10] avg_epoch_loss=2.825394\n",
      "[05/22/2025 05:05:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.843037414550781\n",
      "[05/22/2025 05:05:57 INFO 140551403046720] Epoch[169] Batch [10]#011Speed: 2023.40 samples/sec#011loss=2.843037\n",
      "[05/22/2025 05:05:57 INFO 140551403046720] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747890356.5676305, \"EndTime\": 1747890357.4924364, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.536943435669, \"count\": 1, \"min\": 924.536943435669, \"max\": 924.536943435669}}}\n",
      "[05/22/2025 05:05:57 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1480.6026622989507 records/second\n",
      "[05/22/2025 05:05:57 INFO 140551403046720] #progress_metric: host=algo-1, completed 42.5 % of epochs\n",
      "[05/22/2025 05:05:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.825394023548473\n",
      "[05/22/2025 05:05:57 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:05:57 INFO 140551403046720] Epoch[170] Batch[0] avg_epoch_loss=2.812287\n",
      "[05/22/2025 05:05:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.812286853790283\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] Epoch[170] Batch[5] avg_epoch_loss=2.752139\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.75213893254598\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] Epoch[170] Batch [5]#011Speed: 2166.83 samples/sec#011loss=2.752139\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] Epoch[170] Batch[10] avg_epoch_loss=2.721175\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=2.6840188980102537\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] Epoch[170] Batch [10]#011Speed: 2036.72 samples/sec#011loss=2.684019\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747890357.4924943, \"EndTime\": 1747890358.4093156, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.4578914642334, \"count\": 1, \"min\": 916.4578914642334, \"max\": 916.4578914642334}}}\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1482.7377651992051 records/second\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] #progress_metric: host=algo-1, completed 42.75 % of epochs\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.721175280484286\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] Epoch[171] Batch[0] avg_epoch_loss=2.808134\n",
      "[05/22/2025 05:05:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.808134078979492\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] Epoch[171] Batch[5] avg_epoch_loss=2.760886\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.760885993639628\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] Epoch[171] Batch [5]#011Speed: 2096.98 samples/sec#011loss=2.760886\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] Epoch[171] Batch[10] avg_epoch_loss=2.841364\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=2.937937021255493\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] Epoch[171] Batch [10]#011Speed: 2091.58 samples/sec#011loss=2.937937\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747890358.409373, \"EndTime\": 1747890359.3347564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0948429107666, \"count\": 1, \"min\": 925.0948429107666, \"max\": 925.0948429107666}}}\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1449.4462462214824 records/second\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] #progress_metric: host=algo-1, completed 43.0 % of epochs\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.8413637334650215\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] Epoch[172] Batch[0] avg_epoch_loss=3.128490\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=3.1284897327423096\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] Epoch[172] Batch[5] avg_epoch_loss=3.077451\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=3.0774505535761514\n",
      "[05/22/2025 05:05:59 INFO 140551403046720] Epoch[172] Batch [5]#011Speed: 2180.97 samples/sec#011loss=3.077451\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] Epoch[172] Batch[10] avg_epoch_loss=3.047523\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=3.011609172821045\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] Epoch[172] Batch [10]#011Speed: 2112.81 samples/sec#011loss=3.011609\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747890359.3348134, \"EndTime\": 1747890360.246974, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.9131565093994, \"count\": 1, \"min\": 911.9131565093994, \"max\": 911.9131565093994}}}\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1453.952403957762 records/second\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] #progress_metric: host=algo-1, completed 43.25 % of epochs\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=172, train loss <loss>=3.0475226532329214\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] Epoch[173] Batch[0] avg_epoch_loss=3.189180\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=3.189180374145508\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] Epoch[173] Batch[5] avg_epoch_loss=2.991018\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.9910184144973755\n",
      "[05/22/2025 05:06:00 INFO 140551403046720] Epoch[173] Batch [5]#011Speed: 2124.91 samples/sec#011loss=2.991018\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] Epoch[173] Batch[10] avg_epoch_loss=3.034298\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=3.086232805252075\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] Epoch[173] Batch [10]#011Speed: 2128.34 samples/sec#011loss=3.086233\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747890360.2470303, \"EndTime\": 1747890361.162323, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.0471687316895, \"count\": 1, \"min\": 915.0471687316895, \"max\": 915.0471687316895}}}\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1436.9499771385845 records/second\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] #progress_metric: host=algo-1, completed 43.5 % of epochs\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=173, train loss <loss>=3.034297683022239\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] Epoch[174] Batch[0] avg_epoch_loss=2.794709\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.7947092056274414\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] Epoch[174] Batch[5] avg_epoch_loss=2.893850\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.893850326538086\n",
      "[05/22/2025 05:06:01 INFO 140551403046720] Epoch[174] Batch [5]#011Speed: 1842.38 samples/sec#011loss=2.893850\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] Epoch[174] Batch[10] avg_epoch_loss=2.785448\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=2.655365991592407\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] Epoch[174] Batch [10]#011Speed: 2061.34 samples/sec#011loss=2.655366\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747890361.1623788, \"EndTime\": 1747890362.135562, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 972.9316234588623, \"count\": 1, \"min\": 972.9316234588623, \"max\": 972.9316234588623}}}\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1364.7963959805165 records/second\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] #progress_metric: host=algo-1, completed 43.75 % of epochs\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.785448356108232\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] Epoch[175] Batch[0] avg_epoch_loss=2.835657\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.8356566429138184\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] Epoch[175] Batch[5] avg_epoch_loss=2.789917\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.78991707166036\n",
      "[05/22/2025 05:06:02 INFO 140551403046720] Epoch[175] Batch [5]#011Speed: 2111.99 samples/sec#011loss=2.789917\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] Epoch[175] Batch[10] avg_epoch_loss=2.811245\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=2.8368389129638674\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] Epoch[175] Batch [10]#011Speed: 2038.57 samples/sec#011loss=2.836839\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747890362.1356378, \"EndTime\": 1747890363.0691118, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.098316192627, \"count\": 1, \"min\": 933.098316192627, \"max\": 933.098316192627}}}\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1418.7826262020321 records/second\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] #progress_metric: host=algo-1, completed 44.0 % of epochs\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.811245181343772\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] Epoch[176] Batch[0] avg_epoch_loss=2.715841\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.7158405780792236\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] Epoch[176] Batch[5] avg_epoch_loss=2.736297\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.7362974882125854\n",
      "[05/22/2025 05:06:03 INFO 140551403046720] Epoch[176] Batch [5]#011Speed: 2109.33 samples/sec#011loss=2.736297\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] Epoch[176] Batch[10] avg_epoch_loss=2.699999\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.6564406394958495\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] Epoch[176] Batch [10]#011Speed: 2016.60 samples/sec#011loss=2.656441\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747890363.069177, \"EndTime\": 1747890364.006951, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.4661445617676, \"count\": 1, \"min\": 937.4661445617676, \"max\": 937.4661445617676}}}\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1421.7813343315372 records/second\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] #progress_metric: host=algo-1, completed 44.25 % of epochs\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.6999989206140693\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] Epoch[177] Batch[0] avg_epoch_loss=2.787604\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.7876040935516357\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] Epoch[177] Batch[5] avg_epoch_loss=2.777184\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.7771840492884317\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] Epoch[177] Batch [5]#011Speed: 2078.56 samples/sec#011loss=2.777184\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] Epoch[177] Batch[10] avg_epoch_loss=2.792780\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=2.8114950180053713\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] Epoch[177] Batch [10]#011Speed: 2016.25 samples/sec#011loss=2.811495\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747890364.0070114, \"EndTime\": 1747890364.9471529, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.8519992828369, \"count\": 1, \"min\": 939.8519992828369, \"max\": 939.8519992828369}}}\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1402.2001267234875 records/second\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] #progress_metric: host=algo-1, completed 44.5 % of epochs\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.792779944159768\n",
      "[05/22/2025 05:06:04 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] Epoch[178] Batch[0] avg_epoch_loss=2.764641\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.764641046524048\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] Epoch[178] Batch[5] avg_epoch_loss=2.805663\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.805662512779236\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] Epoch[178] Batch [5]#011Speed: 2056.89 samples/sec#011loss=2.805663\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] Epoch[178] Batch[10] avg_epoch_loss=2.868519\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=2.94394588470459\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] Epoch[178] Batch [10]#011Speed: 2063.84 samples/sec#011loss=2.943946\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747890364.9472177, \"EndTime\": 1747890365.88558, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.0548000335693, \"count\": 1, \"min\": 938.0548000335693, \"max\": 938.0548000335693}}}\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1394.2412322255611 records/second\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] #progress_metric: host=algo-1, completed 44.75 % of epochs\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.868518590927124\n",
      "[05/22/2025 05:06:05 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:06 INFO 140551403046720] Epoch[179] Batch[0] avg_epoch_loss=2.973043\n",
      "[05/22/2025 05:06:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.973043441772461\n",
      "[05/22/2025 05:06:06 INFO 140551403046720] Epoch[179] Batch[5] avg_epoch_loss=2.768904\n",
      "[05/22/2025 05:06:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.7689038117726645\n",
      "[05/22/2025 05:06:06 INFO 140551403046720] Epoch[179] Batch [5]#011Speed: 2092.26 samples/sec#011loss=2.768904\n",
      "[05/22/2025 05:06:06 INFO 140551403046720] processed a total of 1262 examples\n",
      "#metrics {\"StartTime\": 1747890365.8856418, \"EndTime\": 1747890366.7621822, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 876.2021064758301, \"count\": 1, \"min\": 876.2021064758301, \"max\": 876.2021064758301}}}\n",
      "[05/22/2025 05:06:06 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1439.2961484256612 records/second\n",
      "[05/22/2025 05:06:06 INFO 140551403046720] #progress_metric: host=algo-1, completed 45.0 % of epochs\n",
      "[05/22/2025 05:06:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.7659720182418823\n",
      "[05/22/2025 05:06:06 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] Epoch[180] Batch[0] avg_epoch_loss=2.707059\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.707059144973755\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] Epoch[180] Batch[5] avg_epoch_loss=2.760807\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.7608071168263755\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] Epoch[180] Batch [5]#011Speed: 2234.63 samples/sec#011loss=2.760807\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] Epoch[180] Batch[10] avg_epoch_loss=2.743358\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=2.7224201202392577\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] Epoch[180] Batch [10]#011Speed: 2085.64 samples/sec#011loss=2.722420\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747890366.762762, \"EndTime\": 1747890367.6673722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.2322635650635, \"count\": 1, \"min\": 904.2322635650635, \"max\": 904.2322635650635}}}\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1489.4871377240963 records/second\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] #progress_metric: host=algo-1, completed 45.25 % of epochs\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.7433584820140493\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] Epoch[181] Batch[0] avg_epoch_loss=2.973180\n",
      "[05/22/2025 05:06:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.973179578781128\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] Epoch[181] Batch[5] avg_epoch_loss=2.792253\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.7922526597976685\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] Epoch[181] Batch [5]#011Speed: 2028.45 samples/sec#011loss=2.792253\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] Epoch[181] Batch[10] avg_epoch_loss=2.769915\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=2.7431103229522704\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] Epoch[181] Batch [10]#011Speed: 1915.22 samples/sec#011loss=2.743110\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] processed a total of 1389 examples\n",
      "#metrics {\"StartTime\": 1747890367.6674433, \"EndTime\": 1747890368.6247766, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.0131301879883, \"count\": 1, \"min\": 957.0131301879883, \"max\": 957.0131301879883}}}\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1451.1846726452172 records/second\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] #progress_metric: host=algo-1, completed 45.5 % of epochs\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.769915233958851\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] Epoch[182] Batch[0] avg_epoch_loss=2.820495\n",
      "[05/22/2025 05:06:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.8204948902130127\n",
      "[05/22/2025 05:06:09 INFO 140551403046720] Epoch[182] Batch[5] avg_epoch_loss=2.735908\n",
      "[05/22/2025 05:06:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.7359077533086142\n",
      "[05/22/2025 05:06:09 INFO 140551403046720] Epoch[182] Batch [5]#011Speed: 2049.90 samples/sec#011loss=2.735908\n",
      "[05/22/2025 05:06:09 INFO 140551403046720] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747890368.6248782, \"EndTime\": 1747890369.4976733, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 872.4501132965088, \"count\": 1, \"min\": 872.4501132965088, \"max\": 872.4501132965088}}}\n",
      "[05/22/2025 05:06:09 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1458.9525279844272 records/second\n",
      "[05/22/2025 05:06:09 INFO 140551403046720] #progress_metric: host=algo-1, completed 45.75 % of epochs\n",
      "[05/22/2025 05:06:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.7280574560165407\n",
      "[05/22/2025 05:06:09 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:09 INFO 140551403046720] Epoch[183] Batch[0] avg_epoch_loss=2.630681\n",
      "[05/22/2025 05:06:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.630680799484253\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] Epoch[183] Batch[5] avg_epoch_loss=2.719676\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.7196763356526694\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] Epoch[183] Batch [5]#011Speed: 2068.71 samples/sec#011loss=2.719676\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] Epoch[183] Batch[10] avg_epoch_loss=2.726119\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=2.733849859237671\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] Epoch[183] Batch [10]#011Speed: 2088.02 samples/sec#011loss=2.733850\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747890369.4977365, \"EndTime\": 1747890370.431299, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.2842826843262, \"count\": 1, \"min\": 933.2842826843262, \"max\": 933.2842826843262}}}\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1389.5888072961422 records/second\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] #progress_metric: host=algo-1, completed 46.0 % of epochs\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.7261188463731245\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] Epoch[184] Batch[0] avg_epoch_loss=2.772628\n",
      "[05/22/2025 05:06:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.772627830505371\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] Epoch[184] Batch[5] avg_epoch_loss=2.714783\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.7147830724716187\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] Epoch[184] Batch [5]#011Speed: 2179.51 samples/sec#011loss=2.714783\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] processed a total of 1206 examples\n",
      "#metrics {\"StartTime\": 1747890370.4313567, \"EndTime\": 1747890371.2704606, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 838.8214111328125, \"count\": 1, \"min\": 838.8214111328125, \"max\": 838.8214111328125}}}\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1437.5721862457945 records/second\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] #progress_metric: host=algo-1, completed 46.25 % of epochs\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.6934485912322996\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] Epoch[185] Batch[0] avg_epoch_loss=2.810771\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.8107712268829346\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] Epoch[185] Batch[5] avg_epoch_loss=2.763091\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.7630911270777383\n",
      "[05/22/2025 05:06:11 INFO 140551403046720] Epoch[185] Batch [5]#011Speed: 2160.63 samples/sec#011loss=2.763091\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] Epoch[185] Batch[10] avg_epoch_loss=2.765650\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=2.7687212467193603\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] Epoch[185] Batch [10]#011Speed: 2100.37 samples/sec#011loss=2.768721\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747890371.2705224, \"EndTime\": 1747890372.1931028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.2939014434814, \"count\": 1, \"min\": 922.2939014434814, \"max\": 922.2939014434814}}}\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1433.2499266556881 records/second\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] #progress_metric: host=algo-1, completed 46.5 % of epochs\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.7656502723693848\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] Epoch[186] Batch[0] avg_epoch_loss=2.657969\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.6579692363739014\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] Epoch[186] Batch[5] avg_epoch_loss=2.761210\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.7612096071243286\n",
      "[05/22/2025 05:06:12 INFO 140551403046720] Epoch[186] Batch [5]#011Speed: 2090.40 samples/sec#011loss=2.761210\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] Epoch[186] Batch[10] avg_epoch_loss=2.778165\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=2.7985104084014893\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] Epoch[186] Batch [10]#011Speed: 1901.72 samples/sec#011loss=2.798510\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747890372.1931593, \"EndTime\": 1747890373.1472538, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.8452625274658, \"count\": 1, \"min\": 953.8452625274658, \"max\": 953.8452625274658}}}\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1425.653484623171 records/second\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] #progress_metric: host=algo-1, completed 46.75 % of epochs\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.778164516795765\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] Epoch[187] Batch[0] avg_epoch_loss=2.883330\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.8833303451538086\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] Epoch[187] Batch[5] avg_epoch_loss=2.736225\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.7362252473831177\n",
      "[05/22/2025 05:06:13 INFO 140551403046720] Epoch[187] Batch [5]#011Speed: 2178.68 samples/sec#011loss=2.736225\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] Epoch[187] Batch[10] avg_epoch_loss=2.722323\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=2.7056408405303953\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] Epoch[187] Batch [10]#011Speed: 2159.96 samples/sec#011loss=2.705641\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747890373.1473272, \"EndTime\": 1747890374.0522122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.6540260314941, \"count\": 1, \"min\": 904.6540260314941, \"max\": 904.6540260314941}}}\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1460.0912904315599 records/second\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] #progress_metric: host=algo-1, completed 47.0 % of epochs\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.722323244268244\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] Epoch[188] Batch[0] avg_epoch_loss=2.631110\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.6311097145080566\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] Epoch[188] Batch[5] avg_epoch_loss=2.681995\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.6819947163263955\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] Epoch[188] Batch [5]#011Speed: 2157.07 samples/sec#011loss=2.681995\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747890374.0522676, \"EndTime\": 1747890374.9049451, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 852.4293899536133, \"count\": 1, \"min\": 852.4293899536133, \"max\": 852.4293899536133}}}\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1499.088019451182 records/second\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] #progress_metric: host=algo-1, completed 47.25 % of epochs\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.658214783668518\n",
      "[05/22/2025 05:06:14 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] Epoch[189] Batch[0] avg_epoch_loss=2.706831\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.7068309783935547\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] Epoch[189] Batch[5] avg_epoch_loss=2.710631\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.7106305360794067\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] Epoch[189] Batch [5]#011Speed: 2156.22 samples/sec#011loss=2.710631\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] Epoch[189] Batch[10] avg_epoch_loss=2.694805\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=2.67581467628479\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] Epoch[189] Batch [10]#011Speed: 2097.69 samples/sec#011loss=2.675815\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747890374.9050043, \"EndTime\": 1747890375.821746, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.4102077484131, \"count\": 1, \"min\": 916.4102077484131, \"max\": 916.4102077484131}}}\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1415.1699339502143 records/second\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] #progress_metric: host=algo-1, completed 47.5 % of epochs\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.694805145263672\n",
      "[05/22/2025 05:06:15 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] Epoch[190] Batch[0] avg_epoch_loss=2.647133\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.6471333503723145\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] Epoch[190] Batch[5] avg_epoch_loss=2.708137\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.708137273788452\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] Epoch[190] Batch [5]#011Speed: 2170.27 samples/sec#011loss=2.708137\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] Epoch[190] Batch[10] avg_epoch_loss=2.839635\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=2.9974324226379396\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] Epoch[190] Batch [10]#011Speed: 2001.02 samples/sec#011loss=2.997432\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747890375.8218048, \"EndTime\": 1747890376.751091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.0049076080322, \"count\": 1, \"min\": 929.0049076080322, \"max\": 929.0049076080322}}}\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1413.2121916958224 records/second\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] #progress_metric: host=algo-1, completed 47.75 % of epochs\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.839635068720037\n",
      "[05/22/2025 05:06:16 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] Epoch[191] Batch[0] avg_epoch_loss=2.832369\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.8323686122894287\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] Epoch[191] Batch[5] avg_epoch_loss=2.705574\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.7055739164352417\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] Epoch[191] Batch [5]#011Speed: 2190.36 samples/sec#011loss=2.705574\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] Epoch[191] Batch[10] avg_epoch_loss=2.710404\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=2.716200113296509\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] Epoch[191] Batch [10]#011Speed: 2049.02 samples/sec#011loss=2.716200\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747890376.7511454, \"EndTime\": 1747890377.67193, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.5379486083984, \"count\": 1, \"min\": 920.5379486083984, \"max\": 920.5379486083984}}}\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1444.6674176915567 records/second\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] #progress_metric: host=algo-1, completed 48.0 % of epochs\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.7104040059176358\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] Epoch[192] Batch[0] avg_epoch_loss=2.770267\n",
      "[05/22/2025 05:06:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.7702674865722656\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] Epoch[192] Batch[5] avg_epoch_loss=2.694943\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.694943348566691\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] Epoch[192] Batch [5]#011Speed: 2040.41 samples/sec#011loss=2.694943\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] Epoch[192] Batch[10] avg_epoch_loss=2.743999\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=2.8028666019439696\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] Epoch[192] Batch [10]#011Speed: 2074.26 samples/sec#011loss=2.802867\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747890377.67199, \"EndTime\": 1747890378.6085088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.2599849700928, \"count\": 1, \"min\": 936.2599849700928, \"max\": 936.2599849700928}}}\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1430.0272160219224 records/second\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] #progress_metric: host=algo-1, completed 48.25 % of epochs\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.7439993728290903\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] Epoch[193] Batch[0] avg_epoch_loss=2.440463\n",
      "[05/22/2025 05:06:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.440462589263916\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] Epoch[193] Batch[5] avg_epoch_loss=2.618867\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.6188665628433228\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] Epoch[193] Batch [5]#011Speed: 2174.47 samples/sec#011loss=2.618867\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] Epoch[193] Batch[10] avg_epoch_loss=2.629929\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=2.643204402923584\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] Epoch[193] Batch [10]#011Speed: 2133.00 samples/sec#011loss=2.643204\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747890378.608566, \"EndTime\": 1747890379.5210383, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.2259616851807, \"count\": 1, \"min\": 912.2259616851807, \"max\": 912.2259616851807}}}\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1445.7776508272675 records/second\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] #progress_metric: host=algo-1, completed 48.5 % of epochs\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.6299292174252598\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_29d2a519-57f9-4a29-85ba-aa2ecee915b8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890379.5210953, \"EndTime\": 1747890379.5316858, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.277509689331055, \"count\": 1, \"min\": 10.277509689331055, \"max\": 10.277509689331055}}}\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] Epoch[194] Batch[0] avg_epoch_loss=2.534680\n",
      "[05/22/2025 05:06:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.534680128097534\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] Epoch[194] Batch[5] avg_epoch_loss=2.658668\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.6586680014928183\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] Epoch[194] Batch [5]#011Speed: 2142.63 samples/sec#011loss=2.658668\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] Epoch[194] Batch[10] avg_epoch_loss=2.732704\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=2.821546745300293\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] Epoch[194] Batch [10]#011Speed: 2089.49 samples/sec#011loss=2.821547\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747890379.531735, \"EndTime\": 1747890380.4544742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.6927757263184, \"count\": 1, \"min\": 922.6927757263184, \"max\": 922.6927757263184}}}\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1423.962029852659 records/second\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] #progress_metric: host=algo-1, completed 48.75 % of epochs\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.7327037941325796\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] Epoch[195] Batch[0] avg_epoch_loss=2.733938\n",
      "[05/22/2025 05:06:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.7339375019073486\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] Epoch[195] Batch[5] avg_epoch_loss=2.720509\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.7205089728037515\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] Epoch[195] Batch [5]#011Speed: 2062.68 samples/sec#011loss=2.720509\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] Epoch[195] Batch[10] avg_epoch_loss=2.821356\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=2.9423724174499513\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] Epoch[195] Batch [10]#011Speed: 2038.07 samples/sec#011loss=2.942372\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747890380.4545317, \"EndTime\": 1747890381.3908448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.0599517822266, \"count\": 1, \"min\": 936.0599517822266, \"max\": 936.0599517822266}}}\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1423.9296873547516 records/second\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] #progress_metric: host=algo-1, completed 49.0 % of epochs\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.8213559930974785\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] Epoch[196] Batch[0] avg_epoch_loss=2.707462\n",
      "[05/22/2025 05:06:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.7074615955352783\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] Epoch[196] Batch[5] avg_epoch_loss=2.645850\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.6458499431610107\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] Epoch[196] Batch [5]#011Speed: 2104.15 samples/sec#011loss=2.645850\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] Epoch[196] Batch[10] avg_epoch_loss=2.729812\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.8305665969848635\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] Epoch[196] Batch [10]#011Speed: 2042.19 samples/sec#011loss=2.830567\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747890381.3908994, \"EndTime\": 1747890382.3257823, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.6377849578857, \"count\": 1, \"min\": 934.6377849578857, \"max\": 934.6377849578857}}}\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1416.451729378234 records/second\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] #progress_metric: host=algo-1, completed 49.25 % of epochs\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.7298120585354892\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] Epoch[197] Batch[0] avg_epoch_loss=2.556066\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.556065559387207\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] Epoch[197] Batch[5] avg_epoch_loss=2.649786\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.6497862736384072\n",
      "[05/22/2025 05:06:22 INFO 140551403046720] Epoch[197] Batch [5]#011Speed: 2078.17 samples/sec#011loss=2.649786\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] Epoch[197] Batch[10] avg_epoch_loss=2.760130\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=2.8925415515899657\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] Epoch[197] Batch [10]#011Speed: 2044.44 samples/sec#011loss=2.892542\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747890382.3258457, \"EndTime\": 1747890383.2606635, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.0991973876953, \"count\": 1, \"min\": 934.0991973876953, \"max\": 934.0991973876953}}}\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1418.328662528319 records/second\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] #progress_metric: host=algo-1, completed 49.5 % of epochs\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.7601295817982066\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] Epoch[198] Batch[0] avg_epoch_loss=2.731969\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.731968879699707\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] Epoch[198] Batch[5] avg_epoch_loss=2.770119\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.770118792851766\n",
      "[05/22/2025 05:06:23 INFO 140551403046720] Epoch[198] Batch [5]#011Speed: 2160.82 samples/sec#011loss=2.770119\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] Epoch[198] Batch[10] avg_epoch_loss=2.843588\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.9317501068115233\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] Epoch[198] Batch [10]#011Speed: 2031.25 samples/sec#011loss=2.931750\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747890383.2607346, \"EndTime\": 1747890384.185721, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.7329235076904, \"count\": 1, \"min\": 924.7329235076904, \"max\": 924.7329235076904}}}\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1445.6856940963073 records/second\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] #progress_metric: host=algo-1, completed 49.75 % of epochs\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.843587571924383\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] Epoch[199] Batch[0] avg_epoch_loss=2.949067\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.9490671157836914\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] Epoch[199] Batch[5] avg_epoch_loss=2.795974\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.7959738969802856\n",
      "[05/22/2025 05:06:24 INFO 140551403046720] Epoch[199] Batch [5]#011Speed: 2113.36 samples/sec#011loss=2.795974\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] Epoch[199] Batch[10] avg_epoch_loss=2.790268\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=2.7834200859069824\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] Epoch[199] Batch [10]#011Speed: 2035.56 samples/sec#011loss=2.783420\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747890384.18578, \"EndTime\": 1747890385.1115801, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.5170822143555, \"count\": 1, \"min\": 925.5170822143555, \"max\": 925.5170822143555}}}\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1452.0302855302982 records/second\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] #progress_metric: host=algo-1, completed 50.0 % of epochs\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.7902676192196934\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] Epoch[200] Batch[0] avg_epoch_loss=2.637030\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.6370301246643066\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] Epoch[200] Batch[5] avg_epoch_loss=2.633168\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.6331684986750283\n",
      "[05/22/2025 05:06:25 INFO 140551403046720] Epoch[200] Batch [5]#011Speed: 2117.57 samples/sec#011loss=2.633168\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] Epoch[200] Batch[10] avg_epoch_loss=2.621469\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=2.6074304580688477\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] Epoch[200] Batch [10]#011Speed: 2105.23 samples/sec#011loss=2.607430\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747890385.1116354, \"EndTime\": 1747890386.0324125, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.5126762390137, \"count\": 1, \"min\": 920.5126762390137, \"max\": 920.5126762390137}}}\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1406.6942983496613 records/second\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] #progress_metric: host=algo-1, completed 50.25 % of epochs\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.6214693893085825\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_e338293b-d5d6-4a92-b45f-7108fdc217be-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890386.0324697, \"EndTime\": 1747890386.0428925, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.14089584350586, \"count\": 1, \"min\": 10.14089584350586, \"max\": 10.14089584350586}}}\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] Epoch[201] Batch[0] avg_epoch_loss=2.801746\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.801745653152466\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] Epoch[201] Batch[5] avg_epoch_loss=2.677252\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.6772520542144775\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] Epoch[201] Batch [5]#011Speed: 2176.44 samples/sec#011loss=2.677252\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] Epoch[201] Batch[10] avg_epoch_loss=2.634997\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=2.584290361404419\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] Epoch[201] Batch [10]#011Speed: 2001.07 samples/sec#011loss=2.584290\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747890386.0429437, \"EndTime\": 1747890386.968805, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.8139133453369, \"count\": 1, \"min\": 925.8139133453369, \"max\": 925.8139133453369}}}\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1432.1245517567427 records/second\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] #progress_metric: host=algo-1, completed 50.5 % of epochs\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.6349967393008145\n",
      "[05/22/2025 05:06:26 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] Epoch[202] Batch[0] avg_epoch_loss=2.823632\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.823632001876831\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] Epoch[202] Batch[5] avg_epoch_loss=2.659950\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.659950017929077\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] Epoch[202] Batch [5]#011Speed: 2203.63 samples/sec#011loss=2.659950\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] Epoch[202] Batch[10] avg_epoch_loss=2.664641\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=2.670270586013794\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] Epoch[202] Batch [10]#011Speed: 1988.19 samples/sec#011loss=2.670271\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] processed a total of 1375 examples\n",
      "#metrics {\"StartTime\": 1747890386.9688616, \"EndTime\": 1747890387.8908775, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.7705726623535, \"count\": 1, \"min\": 921.7705726623535, \"max\": 921.7705726623535}}}\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1491.5485687033758 records/second\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] #progress_metric: host=algo-1, completed 50.75 % of epochs\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.664641185240312\n",
      "[05/22/2025 05:06:27 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] Epoch[203] Batch[0] avg_epoch_loss=2.819239\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.8192389011383057\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] Epoch[203] Batch[5] avg_epoch_loss=2.728967\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.7289671500523887\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] Epoch[203] Batch [5]#011Speed: 2060.69 samples/sec#011loss=2.728967\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] Epoch[203] Batch[10] avg_epoch_loss=2.724701\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=2.719580888748169\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] Epoch[203] Batch [10]#011Speed: 2040.22 samples/sec#011loss=2.719581\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747890387.8909385, \"EndTime\": 1747890388.8338006, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.5754547119141, \"count\": 1, \"min\": 942.5754547119141, \"max\": 942.5754547119141}}}\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1376.8927996600894 records/second\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] #progress_metric: host=algo-1, completed 51.0 % of epochs\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.7247006676413794\n",
      "[05/22/2025 05:06:28 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] Epoch[204] Batch[0] avg_epoch_loss=2.691756\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.691756248474121\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] Epoch[204] Batch[5] avg_epoch_loss=2.667085\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.6670854489008584\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] Epoch[204] Batch [5]#011Speed: 2150.68 samples/sec#011loss=2.667085\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] Epoch[204] Batch[10] avg_epoch_loss=2.614499\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=2.5513962745666503\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] Epoch[204] Batch [10]#011Speed: 2117.84 samples/sec#011loss=2.551396\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747890388.8338988, \"EndTime\": 1747890389.7521977, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.0386066436768, \"count\": 1, \"min\": 918.0386066436768, \"max\": 918.0386066436768}}}\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1466.0375420780554 records/second\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] #progress_metric: host=algo-1, completed 51.25 % of epochs\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.6144994605671275\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:06:29 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_45705f87-bf4f-49c7-acfe-b35e5a101afb-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890389.7522514, \"EndTime\": 1747890389.7633476, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.829687118530273, \"count\": 1, \"min\": 10.829687118530273, \"max\": 10.829687118530273}}}\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] Epoch[205] Batch[0] avg_epoch_loss=2.841812\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.8418116569519043\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] Epoch[205] Batch[5] avg_epoch_loss=2.651359\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.651359041531881\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] Epoch[205] Batch [5]#011Speed: 2202.95 samples/sec#011loss=2.651359\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] Epoch[205] Batch[10] avg_epoch_loss=2.771803\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=2.916336679458618\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] Epoch[205] Batch [10]#011Speed: 2087.08 samples/sec#011loss=2.916337\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747890389.7633982, \"EndTime\": 1747890390.6748447, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.3960266113281, \"count\": 1, \"min\": 911.3960266113281, \"max\": 911.3960266113281}}}\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1462.4349397776296 records/second\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] #progress_metric: host=algo-1, completed 51.5 % of epochs\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.7718034224076704\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] Epoch[206] Batch[0] avg_epoch_loss=2.662189\n",
      "[05/22/2025 05:06:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.6621885299682617\n",
      "[05/22/2025 05:06:31 INFO 140551403046720] Epoch[206] Batch[5] avg_epoch_loss=2.737795\n",
      "[05/22/2025 05:06:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.737794836362203\n",
      "[05/22/2025 05:06:31 INFO 140551403046720] Epoch[206] Batch [5]#011Speed: 2169.41 samples/sec#011loss=2.737795\n",
      "[05/22/2025 05:06:31 INFO 140551403046720] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747890390.6749113, \"EndTime\": 1747890391.528713, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 853.4419536590576, \"count\": 1, \"min\": 853.4419536590576, \"max\": 853.4419536590576}}}\n",
      "[05/22/2025 05:06:31 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1484.4182429104992 records/second\n",
      "[05/22/2025 05:06:31 INFO 140551403046720] #progress_metric: host=algo-1, completed 51.75 % of epochs\n",
      "[05/22/2025 05:06:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.7365285396575927\n",
      "[05/22/2025 05:06:31 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:31 INFO 140551403046720] Epoch[207] Batch[0] avg_epoch_loss=2.823905\n",
      "[05/22/2025 05:06:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.8239054679870605\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] Epoch[207] Batch[5] avg_epoch_loss=2.699455\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.699454744656881\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] Epoch[207] Batch [5]#011Speed: 2148.88 samples/sec#011loss=2.699455\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] Epoch[207] Batch[10] avg_epoch_loss=2.712064\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=2.7271955013275146\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] Epoch[207] Batch [10]#011Speed: 2128.92 samples/sec#011loss=2.727196\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747890391.528775, \"EndTime\": 1747890392.455947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.8333911895752, \"count\": 1, \"min\": 926.8333911895752, \"max\": 926.8333911895752}}}\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1416.5218714962305 records/second\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] #progress_metric: host=algo-1, completed 52.0 % of epochs\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.712064179507169\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] Epoch[208] Batch[0] avg_epoch_loss=2.864167\n",
      "[05/22/2025 05:06:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.864166736602783\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] Epoch[208] Batch[5] avg_epoch_loss=2.734209\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.7342092990875244\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] Epoch[208] Batch [5]#011Speed: 1946.92 samples/sec#011loss=2.734209\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] Epoch[208] Batch[10] avg_epoch_loss=2.694457\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.646753740310669\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] Epoch[208] Batch [10]#011Speed: 1980.43 samples/sec#011loss=2.646754\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] processed a total of 1379 examples\n",
      "#metrics {\"StartTime\": 1747890392.4560027, \"EndTime\": 1747890393.4189148, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 962.6715183258057, \"count\": 1, \"min\": 962.6715183258057, \"max\": 962.6715183258057}}}\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1432.3474911888993 records/second\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] #progress_metric: host=algo-1, completed 52.25 % of epochs\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.694456772370772\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] Epoch[209] Batch[0] avg_epoch_loss=2.801332\n",
      "[05/22/2025 05:06:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.8013315200805664\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] Epoch[209] Batch[5] avg_epoch_loss=2.670047\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.670046806335449\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] Epoch[209] Batch [5]#011Speed: 2107.78 samples/sec#011loss=2.670047\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] Epoch[209] Batch[10] avg_epoch_loss=2.879041\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=3.1298345565795898\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] Epoch[209] Batch [10]#011Speed: 2037.92 samples/sec#011loss=3.129835\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747890393.4189715, \"EndTime\": 1747890394.3460782, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.8639087677002, \"count\": 1, \"min\": 926.8639087677002, \"max\": 926.8639087677002}}}\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1455.313830264711 records/second\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] #progress_metric: host=algo-1, completed 52.5 % of epochs\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.879041238264604\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] Epoch[210] Batch[0] avg_epoch_loss=2.890218\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.8902182579040527\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] Epoch[210] Batch[5] avg_epoch_loss=2.875939\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.8759385347366333\n",
      "[05/22/2025 05:06:34 INFO 140551403046720] Epoch[210] Batch [5]#011Speed: 2030.50 samples/sec#011loss=2.875939\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] Epoch[210] Batch[10] avg_epoch_loss=2.917379\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=2.9671081066131593\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] Epoch[210] Batch [10]#011Speed: 2034.13 samples/sec#011loss=2.967108\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747890394.3461337, \"EndTime\": 1747890395.2877243, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.2937164306641, \"count\": 1, \"min\": 941.2937164306641, \"max\": 941.2937164306641}}}\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1435.1289345711928 records/second\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] #progress_metric: host=algo-1, completed 52.75 % of epochs\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.9173792492259634\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] Epoch[211] Batch[0] avg_epoch_loss=2.864533\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.864532709121704\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] Epoch[211] Batch[5] avg_epoch_loss=2.778404\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.7784037590026855\n",
      "[05/22/2025 05:06:35 INFO 140551403046720] Epoch[211] Batch [5]#011Speed: 2188.76 samples/sec#011loss=2.778404\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] Epoch[211] Batch[10] avg_epoch_loss=2.710627\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=2.629294729232788\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] Epoch[211] Batch [10]#011Speed: 2055.40 samples/sec#011loss=2.629295\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747890395.2877805, \"EndTime\": 1747890396.2082193, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.1657772064209, \"count\": 1, \"min\": 920.1657772064209, \"max\": 920.1657772064209}}}\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1423.5274165404728 records/second\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] #progress_metric: host=algo-1, completed 53.0 % of epochs\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.7106269272890957\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] Epoch[212] Batch[0] avg_epoch_loss=2.826016\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.826016426086426\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] Epoch[212] Batch[5] avg_epoch_loss=2.721186\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.721186399459839\n",
      "[05/22/2025 05:06:36 INFO 140551403046720] Epoch[212] Batch [5]#011Speed: 2236.96 samples/sec#011loss=2.721186\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] Epoch[212] Batch[10] avg_epoch_loss=2.713730\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.7047831535339357\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] Epoch[212] Batch [10]#011Speed: 2139.36 samples/sec#011loss=2.704783\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747890396.2082753, \"EndTime\": 1747890397.108324, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 899.8076915740967, \"count\": 1, \"min\": 899.8076915740967, \"max\": 899.8076915740967}}}\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1432.393204471253 records/second\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] #progress_metric: host=algo-1, completed 53.25 % of epochs\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.7137303785844282\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] Epoch[213] Batch[0] avg_epoch_loss=2.762345\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.762345314025879\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] Epoch[213] Batch[5] avg_epoch_loss=2.708154\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.7081538438796997\n",
      "[05/22/2025 05:06:37 INFO 140551403046720] Epoch[213] Batch [5]#011Speed: 2198.68 samples/sec#011loss=2.708154\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] Epoch[213] Batch[10] avg_epoch_loss=2.726163\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=2.7477742195129395\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] Epoch[213] Batch [10]#011Speed: 2004.83 samples/sec#011loss=2.747774\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747890397.1083803, \"EndTime\": 1747890398.0313532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.7192401885986, \"count\": 1, \"min\": 922.7192401885986, \"max\": 922.7192401885986}}}\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1458.5962328107944 records/second\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] #progress_metric: host=algo-1, completed 53.5 % of epochs\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.7261631055311724\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] Epoch[214] Batch[0] avg_epoch_loss=2.743252\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.7432522773742676\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] Epoch[214] Batch[5] avg_epoch_loss=2.696809\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.6968085765838623\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] Epoch[214] Batch [5]#011Speed: 2159.03 samples/sec#011loss=2.696809\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] Epoch[214] Batch[10] avg_epoch_loss=2.715078\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=2.7370012760162354\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] Epoch[214] Batch [10]#011Speed: 2009.83 samples/sec#011loss=2.737001\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747890398.0314102, \"EndTime\": 1747890398.9568422, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.1813888549805, \"count\": 1, \"min\": 925.1813888549805, \"max\": 925.1813888549805}}}\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1470.8748761913203 records/second\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] #progress_metric: host=algo-1, completed 53.75 % of epochs\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.7150779854167593\n",
      "[05/22/2025 05:06:38 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] Epoch[215] Batch[0] avg_epoch_loss=2.650530\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.6505298614501953\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] Epoch[215] Batch[5] avg_epoch_loss=2.642248\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.6422483921051025\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] Epoch[215] Batch [5]#011Speed: 2214.28 samples/sec#011loss=2.642248\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] Epoch[215] Batch[10] avg_epoch_loss=2.591024\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=2.529554080963135\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] Epoch[215] Batch [10]#011Speed: 2064.82 samples/sec#011loss=2.529554\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747890398.9569304, \"EndTime\": 1747890399.8696873, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.4965667724609, \"count\": 1, \"min\": 912.4965667724609, \"max\": 912.4965667724609}}}\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1471.5449011942792 records/second\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] #progress_metric: host=algo-1, completed 54.0 % of epochs\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.59102370522239\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:06:39 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_52ad1803-89a9-49fa-9ed9-68d61ef3872a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890399.869803, \"EndTime\": 1747890399.8803353, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.182619094848633, \"count\": 1, \"min\": 10.182619094848633, \"max\": 10.182619094848633}}}\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] Epoch[216] Batch[0] avg_epoch_loss=2.559281\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.559281349182129\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] Epoch[216] Batch[5] avg_epoch_loss=2.656409\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.6564090649286904\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] Epoch[216] Batch [5]#011Speed: 2269.09 samples/sec#011loss=2.656409\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] Epoch[216] Batch[10] avg_epoch_loss=2.691046\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=2.7326106071472167\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] Epoch[216] Batch [10]#011Speed: 2126.93 samples/sec#011loss=2.732611\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747890399.880385, \"EndTime\": 1747890400.7892735, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.8482856750488, \"count\": 1, \"min\": 908.8482856750488, \"max\": 908.8482856750488}}}\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1448.9483830183483 records/second\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] #progress_metric: host=algo-1, completed 54.25 % of epochs\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.691046129573475\n",
      "[05/22/2025 05:06:40 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] Epoch[217] Batch[0] avg_epoch_loss=2.644848\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.644848108291626\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] Epoch[217] Batch[5] avg_epoch_loss=2.647140\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.6471397479375205\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] Epoch[217] Batch [5]#011Speed: 2128.82 samples/sec#011loss=2.647140\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] Epoch[217] Batch[10] avg_epoch_loss=2.664881\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=2.686169910430908\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] Epoch[217] Batch [10]#011Speed: 2137.86 samples/sec#011loss=2.686170\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747890400.7893336, \"EndTime\": 1747890401.7076657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.0505275726318, \"count\": 1, \"min\": 918.0505275726318, \"max\": 918.0505275726318}}}\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1412.6463995645736 records/second\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] #progress_metric: host=algo-1, completed 54.5 % of epochs\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.66488073088906\n",
      "[05/22/2025 05:06:41 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] Epoch[218] Batch[0] avg_epoch_loss=2.676970\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=2.6769704818725586\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] Epoch[218] Batch[5] avg_epoch_loss=2.749599\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.749598821004232\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] Epoch[218] Batch [5]#011Speed: 2277.54 samples/sec#011loss=2.749599\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] Epoch[218] Batch[10] avg_epoch_loss=2.761382\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=2.7755210399627686\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] Epoch[218] Batch [10]#011Speed: 2084.67 samples/sec#011loss=2.775521\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747890401.707721, \"EndTime\": 1747890402.6129508, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.9582481384277, \"count\": 1, \"min\": 904.9582481384277, \"max\": 904.9582481384277}}}\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1509.3183548817171 records/second\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] #progress_metric: host=algo-1, completed 54.75 % of epochs\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.761381647803567\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] Epoch[219] Batch[0] avg_epoch_loss=2.788026\n",
      "[05/22/2025 05:06:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.7880263328552246\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] Epoch[219] Batch[5] avg_epoch_loss=2.773522\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.7735220988591514\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] Epoch[219] Batch [5]#011Speed: 2142.48 samples/sec#011loss=2.773522\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] Epoch[219] Batch[10] avg_epoch_loss=2.782501\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=2.7932765007019045\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] Epoch[219] Batch [10]#011Speed: 2223.98 samples/sec#011loss=2.793277\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747890402.6130075, \"EndTime\": 1747890403.5234246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.1765155792236, \"count\": 1, \"min\": 910.1765155792236, \"max\": 910.1765155792236}}}\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1420.404503610704 records/second\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] #progress_metric: host=algo-1, completed 55.0 % of epochs\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.782501372424039\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] Epoch[220] Batch[0] avg_epoch_loss=2.584996\n",
      "[05/22/2025 05:06:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.584995746612549\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] Epoch[220] Batch[5] avg_epoch_loss=2.657052\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.657051682472229\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] Epoch[220] Batch [5]#011Speed: 2196.62 samples/sec#011loss=2.657052\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] Epoch[220] Batch[10] avg_epoch_loss=2.657686\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=2.6584470748901365\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] Epoch[220] Batch [10]#011Speed: 2198.23 samples/sec#011loss=2.658447\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747890403.5235229, \"EndTime\": 1747890404.4176497, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 893.8672542572021, \"count\": 1, \"min\": 893.8672542572021, \"max\": 893.8672542572021}}}\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1475.469715101364 records/second\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] #progress_metric: host=algo-1, completed 55.25 % of epochs\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.657685951753096\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] Epoch[221] Batch[0] avg_epoch_loss=2.458256\n",
      "[05/22/2025 05:06:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.4582557678222656\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] Epoch[221] Batch[5] avg_epoch_loss=2.679538\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.679538289705912\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] Epoch[221] Batch [5]#011Speed: 2207.12 samples/sec#011loss=2.679538\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] Epoch[221] Batch[10] avg_epoch_loss=2.737573\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=2.807214307785034\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] Epoch[221] Batch [10]#011Speed: 2188.97 samples/sec#011loss=2.807214\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747890404.4177074, \"EndTime\": 1747890405.3120344, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 894.089937210083, \"count\": 1, \"min\": 894.089937210083, \"max\": 894.089937210083}}}\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1469.5097397775464 records/second\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] #progress_metric: host=algo-1, completed 55.5 % of epochs\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.7375728433782403\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] Epoch[222] Batch[0] avg_epoch_loss=2.611761\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=2.6117613315582275\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] Epoch[222] Batch[5] avg_epoch_loss=2.654500\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.6545000076293945\n",
      "[05/22/2025 05:06:45 INFO 140551403046720] Epoch[222] Batch [5]#011Speed: 2272.87 samples/sec#011loss=2.654500\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] Epoch[222] Batch[10] avg_epoch_loss=2.650328\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=2.6453221321105955\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] Epoch[222] Batch [10]#011Speed: 2088.38 samples/sec#011loss=2.645322\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747890405.3120923, \"EndTime\": 1747890406.2088735, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 896.4900970458984, \"count\": 1, \"min\": 896.4900970458984, \"max\": 896.4900970458984}}}\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1511.308569276884 records/second\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] #progress_metric: host=algo-1, completed 55.75 % of epochs\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.6503282460299404\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] Epoch[223] Batch[0] avg_epoch_loss=2.617440\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.6174399852752686\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] Epoch[223] Batch[5] avg_epoch_loss=2.653591\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.6535913149515786\n",
      "[05/22/2025 05:06:46 INFO 140551403046720] Epoch[223] Batch [5]#011Speed: 2150.36 samples/sec#011loss=2.653591\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] Epoch[223] Batch[10] avg_epoch_loss=2.641807\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=2.627666139602661\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] Epoch[223] Batch [10]#011Speed: 2051.32 samples/sec#011loss=2.627666\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747890406.20893, \"EndTime\": 1747890407.1272337, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.0593490600586, \"count\": 1, \"min\": 918.0593490600586, \"max\": 918.0593490600586}}}\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1476.891382916236 records/second\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] #progress_metric: host=algo-1, completed 56.0 % of epochs\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.6418071443384346\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] Epoch[224] Batch[0] avg_epoch_loss=2.472483\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.472482681274414\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] Epoch[224] Batch[5] avg_epoch_loss=2.574881\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.5748809973398843\n",
      "[05/22/2025 05:06:47 INFO 140551403046720] Epoch[224] Batch [5]#011Speed: 2225.99 samples/sec#011loss=2.574881\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] Epoch[224] Batch[10] avg_epoch_loss=2.641845\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=2.722201108932495\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] Epoch[224] Batch [10]#011Speed: 2188.68 samples/sec#011loss=2.722201\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747890407.127291, \"EndTime\": 1747890408.0226343, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 895.0958251953125, \"count\": 1, \"min\": 895.0958251953125, \"max\": 895.0958251953125}}}\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1432.0955430331962 records/second\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] #progress_metric: host=algo-1, completed 56.25 % of epochs\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.6418446844274346\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] Epoch[225] Batch[0] avg_epoch_loss=2.618127\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.618126630783081\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] Epoch[225] Batch[5] avg_epoch_loss=2.652128\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.6521275838216147\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] Epoch[225] Batch [5]#011Speed: 2173.16 samples/sec#011loss=2.652128\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] Epoch[225] Batch[10] avg_epoch_loss=2.729167\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=2.8216147422790527\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] Epoch[225] Batch [10]#011Speed: 2030.65 samples/sec#011loss=2.821615\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747890408.0227005, \"EndTime\": 1747890408.94596, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.0101108551025, \"count\": 1, \"min\": 923.0101108551025, \"max\": 923.0101108551025}}}\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1425.6284566563759 records/second\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] #progress_metric: host=algo-1, completed 56.5 % of epochs\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.729167201302268\n",
      "[05/22/2025 05:06:48 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] Epoch[226] Batch[0] avg_epoch_loss=2.692188\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=2.692188024520874\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] Epoch[226] Batch[5] avg_epoch_loss=2.636781\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.6367814540863037\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] Epoch[226] Batch [5]#011Speed: 2187.55 samples/sec#011loss=2.636781\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] Epoch[226] Batch[10] avg_epoch_loss=2.537199\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=2.417699670791626\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] Epoch[226] Batch [10]#011Speed: 2064.64 samples/sec#011loss=2.417700\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747890408.9460235, \"EndTime\": 1747890409.8661358, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.8288917541504, \"count\": 1, \"min\": 919.8288917541504, \"max\": 919.8288917541504}}}\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1415.339780521902 records/second\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] #progress_metric: host=algo-1, completed 56.75 % of epochs\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.5371988253159956\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:06:49 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_041f8de1-e0df-42fb-bc8c-d05852f54c97-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890409.8661973, \"EndTime\": 1747890409.876655, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.141849517822266, \"count\": 1, \"min\": 10.141849517822266, \"max\": 10.141849517822266}}}\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] Epoch[227] Batch[0] avg_epoch_loss=2.773271\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.773271083831787\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] Epoch[227] Batch[5] avg_epoch_loss=2.706084\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.706084211667379\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] Epoch[227] Batch [5]#011Speed: 2130.54 samples/sec#011loss=2.706084\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] Epoch[227] Batch[10] avg_epoch_loss=2.711863\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=2.718798208236694\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] Epoch[227] Batch [10]#011Speed: 2093.22 samples/sec#011loss=2.718798\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747890409.8767126, \"EndTime\": 1747890410.8020046, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.241231918335, \"count\": 1, \"min\": 925.241231918335, \"max\": 925.241231918335}}}\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1441.6516780659117 records/second\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] #progress_metric: host=algo-1, completed 57.0 % of epochs\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.711863301017068\n",
      "[05/22/2025 05:06:50 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] Epoch[228] Batch[0] avg_epoch_loss=2.701408\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.7014079093933105\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] Epoch[228] Batch[5] avg_epoch_loss=2.641027\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.6410268545150757\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] Epoch[228] Batch [5]#011Speed: 2102.65 samples/sec#011loss=2.641027\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] Epoch[228] Batch[10] avg_epoch_loss=2.542104\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=2.4233967065811157\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] Epoch[228] Batch [10]#011Speed: 2103.69 samples/sec#011loss=2.423397\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747890410.8020608, \"EndTime\": 1747890411.723281, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.971155166626, \"count\": 1, \"min\": 920.971155166626, \"max\": 920.971155166626}}}\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1423.3650680577098 records/second\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] #progress_metric: host=algo-1, completed 57.25 % of epochs\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.542104059999639\n",
      "[05/22/2025 05:06:51 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] Epoch[229] Batch[0] avg_epoch_loss=2.712658\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.712658166885376\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] Epoch[229] Batch[5] avg_epoch_loss=2.602292\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.6022923787434897\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] Epoch[229] Batch [5]#011Speed: 2084.12 samples/sec#011loss=2.602292\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] processed a total of 1248 examples\n",
      "#metrics {\"StartTime\": 1747890411.7233377, \"EndTime\": 1747890412.572894, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 849.3139743804932, \"count\": 1, \"min\": 849.3139743804932, \"max\": 849.3139743804932}}}\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1469.2661662349196 records/second\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] #progress_metric: host=algo-1, completed 57.5 % of epochs\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.6054630994796755\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] Epoch[230] Batch[0] avg_epoch_loss=2.534010\n",
      "[05/22/2025 05:06:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.534010410308838\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] Epoch[230] Batch[5] avg_epoch_loss=2.587286\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.5872863133748374\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] Epoch[230] Batch [5]#011Speed: 2008.50 samples/sec#011loss=2.587286\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] Epoch[230] Batch[10] avg_epoch_loss=2.720201\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=2.87969913482666\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] Epoch[230] Batch [10]#011Speed: 2073.81 samples/sec#011loss=2.879699\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747890412.572955, \"EndTime\": 1747890413.5108302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.5882148742676, \"count\": 1, \"min\": 937.5882148742676, \"max\": 937.5882148742676}}}\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1418.4062272908263 records/second\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] #progress_metric: host=algo-1, completed 57.75 % of epochs\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.7202012322165747\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] Epoch[231] Batch[0] avg_epoch_loss=2.488417\n",
      "[05/22/2025 05:06:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.488416910171509\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] Epoch[231] Batch[5] avg_epoch_loss=2.676189\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.676189104715983\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] Epoch[231] Batch [5]#011Speed: 2059.32 samples/sec#011loss=2.676189\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] Epoch[231] Batch[10] avg_epoch_loss=2.725924\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=2.785606098175049\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] Epoch[231] Batch [10]#011Speed: 2008.90 samples/sec#011loss=2.785606\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747890413.5108852, \"EndTime\": 1747890414.4506023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.4302368164062, \"count\": 1, \"min\": 939.4302368164062, \"max\": 939.4302368164062}}}\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1447.5508041366038 records/second\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] #progress_metric: host=algo-1, completed 58.0 % of epochs\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.725924101742831\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] Epoch[232] Batch[0] avg_epoch_loss=2.620877\n",
      "[05/22/2025 05:06:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.6208770275115967\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] Epoch[232] Batch[5] avg_epoch_loss=2.651832\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.6518323024113974\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] Epoch[232] Batch [5]#011Speed: 2173.11 samples/sec#011loss=2.651832\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] Epoch[232] Batch[10] avg_epoch_loss=2.621043\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=2.5840954303741457\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] Epoch[232] Batch [10]#011Speed: 2116.24 samples/sec#011loss=2.584095\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747890414.450661, \"EndTime\": 1747890415.3628078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.8874073028564, \"count\": 1, \"min\": 911.8874073028564, \"max\": 911.8874073028564}}}\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1470.4390390814333 records/second\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] #progress_metric: host=algo-1, completed 58.25 % of epochs\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.6210428151217373\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] Epoch[233] Batch[0] avg_epoch_loss=2.553903\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.5539028644561768\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] Epoch[233] Batch[5] avg_epoch_loss=2.702014\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.7020140488942466\n",
      "[05/22/2025 05:06:55 INFO 140551403046720] Epoch[233] Batch [5]#011Speed: 2190.45 samples/sec#011loss=2.702014\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] Epoch[233] Batch[10] avg_epoch_loss=2.692781\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=2.681700658798218\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] Epoch[233] Batch [10]#011Speed: 2055.67 samples/sec#011loss=2.681701\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747890415.3628645, \"EndTime\": 1747890416.2806811, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.5200462341309, \"count\": 1, \"min\": 917.5200462341309, \"max\": 917.5200462341309}}}\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1441.7984706564018 records/second\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] #progress_metric: host=algo-1, completed 58.5 % of epochs\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.692780689759688\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] Epoch[234] Batch[0] avg_epoch_loss=2.735343\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.7353429794311523\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] Epoch[234] Batch[5] avg_epoch_loss=2.731888\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.7318877379099527\n",
      "[05/22/2025 05:06:56 INFO 140551403046720] Epoch[234] Batch [5]#011Speed: 2152.11 samples/sec#011loss=2.731888\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] Epoch[234] Batch[10] avg_epoch_loss=2.655984\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=2.5648996353149416\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] Epoch[234] Batch [10]#011Speed: 1980.40 samples/sec#011loss=2.564900\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747890416.2807372, \"EndTime\": 1747890417.2143807, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.3491325378418, \"count\": 1, \"min\": 933.3491325378418, \"max\": 933.3491325378418}}}\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1441.9836306255038 records/second\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] #progress_metric: host=algo-1, completed 58.75 % of epochs\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.6559840549122202\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] Epoch[235] Batch[0] avg_epoch_loss=2.687576\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.6875762939453125\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] Epoch[235] Batch[5] avg_epoch_loss=2.657590\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.657589912414551\n",
      "[05/22/2025 05:06:57 INFO 140551403046720] Epoch[235] Batch [5]#011Speed: 2201.45 samples/sec#011loss=2.657590\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] Epoch[235] Batch[10] avg_epoch_loss=2.740468\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=2.8399211883544924\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] Epoch[235] Batch [10]#011Speed: 1918.87 samples/sec#011loss=2.839921\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747890417.2144399, \"EndTime\": 1747890418.169858, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.1715850830078, \"count\": 1, \"min\": 955.1715850830078, \"max\": 955.1715850830078}}}\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1388.1040530118678 records/second\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] #progress_metric: host=algo-1, completed 59.0 % of epochs\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.740467765114524\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] Epoch[236] Batch[0] avg_epoch_loss=2.699414\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.699413776397705\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] Epoch[236] Batch[5] avg_epoch_loss=2.754795\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.754794637362162\n",
      "[05/22/2025 05:06:58 INFO 140551403046720] Epoch[236] Batch [5]#011Speed: 2196.03 samples/sec#011loss=2.754795\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] Epoch[236] Batch[10] avg_epoch_loss=2.682715\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=2.5962202548980713\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] Epoch[236] Batch [10]#011Speed: 2056.12 samples/sec#011loss=2.596220\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747890418.1699173, \"EndTime\": 1747890419.089053, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.8854694366455, \"count\": 1, \"min\": 918.8854694366455, \"max\": 918.8854694366455}}}\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1449.447540928741 records/second\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] #progress_metric: host=algo-1, completed 59.25 % of epochs\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.6827153726057573\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] Epoch[237] Batch[0] avg_epoch_loss=2.662395\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.6623952388763428\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] Epoch[237] Batch[5] avg_epoch_loss=2.641811\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.6418107748031616\n",
      "[05/22/2025 05:06:59 INFO 140551403046720] Epoch[237] Batch [5]#011Speed: 2176.42 samples/sec#011loss=2.641811\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] Epoch[237] Batch[10] avg_epoch_loss=2.835328\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=3.067548084259033\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] Epoch[237] Batch [10]#011Speed: 2076.44 samples/sec#011loss=3.067548\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] processed a total of 1311 examples\n",
      "#metrics {\"StartTime\": 1747890419.0891106, \"EndTime\": 1747890420.0241587, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.802770614624, \"count\": 1, \"min\": 934.802770614624, \"max\": 934.802770614624}}}\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1402.3025361769064 records/second\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] #progress_metric: host=algo-1, completed 59.5 % of epochs\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.8353277336467397\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] Epoch[238] Batch[0] avg_epoch_loss=2.451130\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.451129674911499\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] Epoch[238] Batch[5] avg_epoch_loss=2.675650\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.6756500800450644\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] Epoch[238] Batch [5]#011Speed: 2114.52 samples/sec#011loss=2.675650\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] Epoch[238] Batch[10] avg_epoch_loss=2.684770\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=2.6957146644592287\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] Epoch[238] Batch [10]#011Speed: 2059.95 samples/sec#011loss=2.695715\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747890420.0242174, \"EndTime\": 1747890420.9532602, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.7865161895752, \"count\": 1, \"min\": 928.7865161895752, \"max\": 928.7865161895752}}}\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1421.078303437499 records/second\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] #progress_metric: host=algo-1, completed 59.75 % of epochs\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.684770345687866\n",
      "[05/22/2025 05:07:00 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:01 INFO 140551403046720] Epoch[239] Batch[0] avg_epoch_loss=2.603397\n",
      "[05/22/2025 05:07:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.6033971309661865\n",
      "[05/22/2025 05:07:01 INFO 140551403046720] Epoch[239] Batch[5] avg_epoch_loss=2.724320\n",
      "[05/22/2025 05:07:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.7243202129999795\n",
      "[05/22/2025 05:07:01 INFO 140551403046720] Epoch[239] Batch [5]#011Speed: 2062.48 samples/sec#011loss=2.724320\n",
      "[05/22/2025 05:07:01 INFO 140551403046720] processed a total of 1270 examples\n",
      "#metrics {\"StartTime\": 1747890420.9533176, \"EndTime\": 1747890421.8407245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 886.6376876831055, \"count\": 1, \"min\": 886.6376876831055, \"max\": 886.6376876831055}}}\n",
      "[05/22/2025 05:07:01 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1432.2220501436855 records/second\n",
      "[05/22/2025 05:07:01 INFO 140551403046720] #progress_metric: host=algo-1, completed 60.0 % of epochs\n",
      "[05/22/2025 05:07:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.7204812288284304\n",
      "[05/22/2025 05:07:01 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] Epoch[240] Batch[0] avg_epoch_loss=2.674714\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.6747140884399414\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] Epoch[240] Batch[5] avg_epoch_loss=2.647250\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.6472496589024863\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] Epoch[240] Batch [5]#011Speed: 2097.64 samples/sec#011loss=2.647250\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] Epoch[240] Batch[10] avg_epoch_loss=2.610901\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=2.567283535003662\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] Epoch[240] Batch [10]#011Speed: 1983.04 samples/sec#011loss=2.567284\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] processed a total of 1373 examples\n",
      "#metrics {\"StartTime\": 1747890421.8407893, \"EndTime\": 1747890422.7955847, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.5111656188965, \"count\": 1, \"min\": 954.5111656188965, \"max\": 954.5111656188965}}}\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1438.3036487957024 records/second\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] #progress_metric: host=algo-1, completed 60.25 % of epochs\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.610901420766657\n",
      "[05/22/2025 05:07:02 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] Epoch[241] Batch[0] avg_epoch_loss=2.582948\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.5829482078552246\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] Epoch[241] Batch[5] avg_epoch_loss=2.649395\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.649394671122233\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] Epoch[241] Batch [5]#011Speed: 1994.02 samples/sec#011loss=2.649395\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] Epoch[241] Batch[10] avg_epoch_loss=2.575782\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.4874459743499755\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] Epoch[241] Batch [10]#011Speed: 1951.74 samples/sec#011loss=2.487446\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747890422.7956424, \"EndTime\": 1747890423.7721195, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 976.1817455291748, \"count\": 1, \"min\": 976.1817455291748, \"max\": 976.1817455291748}}}\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1371.5532254196467 records/second\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] #progress_metric: host=algo-1, completed 60.5 % of epochs\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.5757816271348433\n",
      "[05/22/2025 05:07:03 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] Epoch[242] Batch[0] avg_epoch_loss=2.604035\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.6040353775024414\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] Epoch[242] Batch[5] avg_epoch_loss=2.649560\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.6495598554611206\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] Epoch[242] Batch [5]#011Speed: 2091.53 samples/sec#011loss=2.649560\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] Epoch[242] Batch[10] avg_epoch_loss=2.571987\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=2.4789005279541017\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] Epoch[242] Batch [10]#011Speed: 2033.30 samples/sec#011loss=2.478901\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747890423.7721753, \"EndTime\": 1747890424.7131357, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.7105445861816, \"count\": 1, \"min\": 940.7105445861816, \"max\": 940.7105445861816}}}\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1399.8785519657454 records/second\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] #progress_metric: host=algo-1, completed 60.75 % of epochs\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.571987433867021\n",
      "[05/22/2025 05:07:04 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] Epoch[243] Batch[0] avg_epoch_loss=2.516115\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=2.516115188598633\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] Epoch[243] Batch[5] avg_epoch_loss=2.540486\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.5404857794443765\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] Epoch[243] Batch [5]#011Speed: 1992.99 samples/sec#011loss=2.540486\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] Epoch[243] Batch[10] avg_epoch_loss=2.487548\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=2.4240219593048096\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] Epoch[243] Batch [10]#011Speed: 2086.29 samples/sec#011loss=2.424022\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747890424.7131934, \"EndTime\": 1747890425.6613457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.9057788848877, \"count\": 1, \"min\": 947.9057788848877, \"max\": 947.9057788848877}}}\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1373.432640612531 records/second\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] #progress_metric: host=algo-1, completed 61.0 % of epochs\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.487547679380937\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_afb1e292-f76b-4ae3-9af8-e05d91795e1b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890425.6614022, \"EndTime\": 1747890425.6721447, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.47658920288086, \"count\": 1, \"min\": 10.47658920288086, \"max\": 10.47658920288086}}}\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] Epoch[244] Batch[0] avg_epoch_loss=2.621908\n",
      "[05/22/2025 05:07:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.6219077110290527\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] Epoch[244] Batch[5] avg_epoch_loss=2.575546\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.5755461851755777\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] Epoch[244] Batch [5]#011Speed: 2116.01 samples/sec#011loss=2.575546\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] Epoch[244] Batch[10] avg_epoch_loss=2.646766\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=2.7322295665740968\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] Epoch[244] Batch [10]#011Speed: 2041.91 samples/sec#011loss=2.732230\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747890425.672195, \"EndTime\": 1747890426.5994685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.2274971008301, \"count\": 1, \"min\": 927.2274971008301, \"max\": 927.2274971008301}}}\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1441.7996160880991 records/second\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] #progress_metric: host=algo-1, completed 61.25 % of epochs\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.6467659039930864\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] Epoch[245] Batch[0] avg_epoch_loss=2.628308\n",
      "[05/22/2025 05:07:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.628307580947876\n",
      "[05/22/2025 05:07:07 INFO 140551403046720] Epoch[245] Batch[5] avg_epoch_loss=2.615012\n",
      "[05/22/2025 05:07:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.615012288093567\n",
      "[05/22/2025 05:07:07 INFO 140551403046720] Epoch[245] Batch [5]#011Speed: 2134.88 samples/sec#011loss=2.615012\n",
      "[05/22/2025 05:07:07 INFO 140551403046720] processed a total of 1256 examples\n",
      "#metrics {\"StartTime\": 1747890426.599526, \"EndTime\": 1747890427.4650478, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 865.2775287628174, \"count\": 1, \"min\": 865.2775287628174, \"max\": 865.2775287628174}}}\n",
      "[05/22/2025 05:07:07 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1451.4078296544726 records/second\n",
      "[05/22/2025 05:07:07 INFO 140551403046720] #progress_metric: host=algo-1, completed 61.5 % of epochs\n",
      "[05/22/2025 05:07:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.663702654838562\n",
      "[05/22/2025 05:07:07 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:07 INFO 140551403046720] Epoch[246] Batch[0] avg_epoch_loss=2.727976\n",
      "[05/22/2025 05:07:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.7279763221740723\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] Epoch[246] Batch[5] avg_epoch_loss=2.583808\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.5838084618250527\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] Epoch[246] Batch [5]#011Speed: 2134.20 samples/sec#011loss=2.583808\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] Epoch[246] Batch[10] avg_epoch_loss=2.597578\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=2.6141013145446776\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] Epoch[246] Batch [10]#011Speed: 2025.29 samples/sec#011loss=2.614101\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747890427.4651077, \"EndTime\": 1747890428.3970935, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.6480159759521, \"count\": 1, \"min\": 931.6480159759521, \"max\": 931.6480159759521}}}\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1405.9834266810783 records/second\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] #progress_metric: host=algo-1, completed 61.75 % of epochs\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=246, train loss <loss>=2.597577940333973\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] Epoch[247] Batch[0] avg_epoch_loss=2.519786\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.5197861194610596\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] Epoch[247] Batch[5] avg_epoch_loss=2.545832\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.5458319187164307\n",
      "[05/22/2025 05:07:08 INFO 140551403046720] Epoch[247] Batch [5]#011Speed: 2204.05 samples/sec#011loss=2.545832\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] Epoch[247] Batch[10] avg_epoch_loss=2.543566\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=2.540846061706543\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] Epoch[247] Batch [10]#011Speed: 2065.21 samples/sec#011loss=2.540846\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747890428.3971465, \"EndTime\": 1747890429.3090463, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.5860462188721, \"count\": 1, \"min\": 911.5860462188721, \"max\": 911.5860462188721}}}\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1447.8583000493475 records/second\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] #progress_metric: host=algo-1, completed 62.0 % of epochs\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=247, train loss <loss>=2.5435656200755727\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] Epoch[248] Batch[0] avg_epoch_loss=2.475823\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.475823163986206\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] Epoch[248] Batch[5] avg_epoch_loss=2.575565\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.575564980506897\n",
      "[05/22/2025 05:07:09 INFO 140551403046720] Epoch[248] Batch [5]#011Speed: 2143.54 samples/sec#011loss=2.575565\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] Epoch[248] Batch[10] avg_epoch_loss=2.524258\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=2.4626901865005495\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] Epoch[248] Batch [10]#011Speed: 2107.17 samples/sec#011loss=2.462690\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747890429.3091216, \"EndTime\": 1747890430.225292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.917158126831, \"count\": 1, \"min\": 915.917158126831, \"max\": 915.917158126831}}}\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1434.4894022782375 records/second\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] #progress_metric: host=algo-1, completed 62.25 % of epochs\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.524258255958557\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] Epoch[249] Batch[0] avg_epoch_loss=2.670885\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.6708853244781494\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] Epoch[249] Batch[5] avg_epoch_loss=2.564723\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.5647230545679727\n",
      "[05/22/2025 05:07:10 INFO 140551403046720] Epoch[249] Batch [5]#011Speed: 2045.32 samples/sec#011loss=2.564723\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] Epoch[249] Batch[10] avg_epoch_loss=2.677058\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=2.811858892440796\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] Epoch[249] Batch [10]#011Speed: 2056.02 samples/sec#011loss=2.811859\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747890430.2253513, \"EndTime\": 1747890431.1633918, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.7903938293457, \"count\": 1, \"min\": 937.7903938293457, \"max\": 937.7903938293457}}}\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1409.5741150869915 records/second\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] #progress_metric: host=algo-1, completed 62.5 % of epochs\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.677057526328347\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] Epoch[250] Batch[0] avg_epoch_loss=2.872288\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.8722879886627197\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] Epoch[250] Batch[5] avg_epoch_loss=2.753588\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.753587524096171\n",
      "[05/22/2025 05:07:11 INFO 140551403046720] Epoch[250] Batch [5]#011Speed: 2123.44 samples/sec#011loss=2.753588\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] Epoch[250] Batch[10] avg_epoch_loss=2.694435\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=2.62345232963562\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] Epoch[250] Batch [10]#011Speed: 2026.34 samples/sec#011loss=2.623452\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747890431.163445, \"EndTime\": 1747890432.097393, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.2380294799805, \"count\": 1, \"min\": 933.2380294799805, \"max\": 933.2380294799805}}}\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1413.5868921638792 records/second\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] #progress_metric: host=algo-1, completed 62.75 % of epochs\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.6944351629777388\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] Epoch[251] Batch[0] avg_epoch_loss=2.792183\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.7921831607818604\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] Epoch[251] Batch[5] avg_epoch_loss=2.677310\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.6773096323013306\n",
      "[05/22/2025 05:07:12 INFO 140551403046720] Epoch[251] Batch [5]#011Speed: 2230.28 samples/sec#011loss=2.677310\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] Epoch[251] Batch[10] avg_epoch_loss=2.705253\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=2.7387860298156737\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] Epoch[251] Batch [10]#011Speed: 2117.82 samples/sec#011loss=2.738786\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747890432.0974545, \"EndTime\": 1747890433.014688, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.9406890869141, \"count\": 1, \"min\": 916.9406890869141, \"max\": 916.9406890869141}}}\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1425.2364393445419 records/second\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] #progress_metric: host=algo-1, completed 63.0 % of epochs\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.7052534493533047\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] Epoch[252] Batch[0] avg_epoch_loss=2.491749\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=2.491748571395874\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] Epoch[252] Batch[5] avg_epoch_loss=2.661998\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.6619977951049805\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] Epoch[252] Batch [5]#011Speed: 2233.92 samples/sec#011loss=2.661998\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] processed a total of 1235 examples\n",
      "#metrics {\"StartTime\": 1747890433.0147574, \"EndTime\": 1747890433.8497689, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 834.749698638916, \"count\": 1, \"min\": 834.749698638916, \"max\": 834.749698638916}}}\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1479.3261196188796 records/second\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] #progress_metric: host=algo-1, completed 63.25 % of epochs\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.7689984321594237\n",
      "[05/22/2025 05:07:13 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] Epoch[253] Batch[0] avg_epoch_loss=2.619073\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=2.619072914123535\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] Epoch[253] Batch[5] avg_epoch_loss=2.725806\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.725806395212809\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] Epoch[253] Batch [5]#011Speed: 2068.12 samples/sec#011loss=2.725806\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] Epoch[253] Batch[10] avg_epoch_loss=2.881706\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=3.0687864303588865\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] Epoch[253] Batch [10]#011Speed: 2172.09 samples/sec#011loss=3.068786\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747890433.8498297, \"EndTime\": 1747890434.7624638, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.3063087463379, \"count\": 1, \"min\": 912.3063087463379, \"max\": 912.3063087463379}}}\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1467.5722660384033 records/second\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] #progress_metric: host=algo-1, completed 63.5 % of epochs\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.881706411188299\n",
      "[05/22/2025 05:07:14 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] Epoch[254] Batch[0] avg_epoch_loss=2.965227\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.9652273654937744\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] Epoch[254] Batch[5] avg_epoch_loss=2.729985\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.729984760284424\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] Epoch[254] Batch [5]#011Speed: 2193.76 samples/sec#011loss=2.729985\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] Epoch[254] Batch[10] avg_epoch_loss=2.678378\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=254, batch=10 train loss <loss>=2.616449069976807\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] Epoch[254] Batch [10]#011Speed: 2217.56 samples/sec#011loss=2.616449\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747890434.7625206, \"EndTime\": 1747890435.6561298, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 893.3553695678711, \"count\": 1, \"min\": 893.3553695678711, \"max\": 893.3553695678711}}}\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1457.2105071032886 records/second\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] #progress_metric: host=algo-1, completed 63.75 % of epochs\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.678377628326416\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] Epoch[255] Batch[0] avg_epoch_loss=2.699147\n",
      "[05/22/2025 05:07:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=2.6991474628448486\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] Epoch[255] Batch[5] avg_epoch_loss=2.713085\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.713085333506266\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] Epoch[255] Batch [5]#011Speed: 2197.60 samples/sec#011loss=2.713085\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] Epoch[255] Batch[10] avg_epoch_loss=2.581619\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=2.4238600969314574\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] Epoch[255] Batch [10]#011Speed: 2086.55 samples/sec#011loss=2.423860\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747890435.656232, \"EndTime\": 1747890436.566645, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.1333618164062, \"count\": 1, \"min\": 910.1333618164062, \"max\": 910.1333618164062}}}\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1446.9303813035554 records/second\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] #progress_metric: host=algo-1, completed 64.0 % of epochs\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.581619316881353\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] Epoch[256] Batch[0] avg_epoch_loss=2.675267\n",
      "[05/22/2025 05:07:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.6752665042877197\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] Epoch[256] Batch[5] avg_epoch_loss=2.665159\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.665158828099569\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] Epoch[256] Batch [5]#011Speed: 2161.42 samples/sec#011loss=2.665159\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] Epoch[256] Batch[10] avg_epoch_loss=2.700873\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=2.743731069564819\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] Epoch[256] Batch [10]#011Speed: 2134.57 samples/sec#011loss=2.743731\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747890436.5666893, \"EndTime\": 1747890437.486953, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.0351238250732, \"count\": 1, \"min\": 920.0351238250732, \"max\": 920.0351238250732}}}\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1420.4665262599294 records/second\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] #progress_metric: host=algo-1, completed 64.25 % of epochs\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.7008734833110464\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] Epoch[257] Batch[0] avg_epoch_loss=2.588505\n",
      "[05/22/2025 05:07:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.5885047912597656\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] Epoch[257] Batch[5] avg_epoch_loss=2.752519\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.7525190512339273\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] Epoch[257] Batch [5]#011Speed: 2104.58 samples/sec#011loss=2.752519\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] Epoch[257] Batch[10] avg_epoch_loss=2.649046\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=2.5248789548873902\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] Epoch[257] Batch [10]#011Speed: 1959.60 samples/sec#011loss=2.524879\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747890437.4870079, \"EndTime\": 1747890438.4298444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.5137042999268, \"count\": 1, \"min\": 942.5137042999268, \"max\": 942.5137042999268}}}\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1407.8010507462748 records/second\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] #progress_metric: host=algo-1, completed 64.5 % of epochs\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.6490462801673194\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] Epoch[258] Batch[0] avg_epoch_loss=2.676914\n",
      "[05/22/2025 05:07:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.6769144535064697\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] Epoch[258] Batch[5] avg_epoch_loss=2.722316\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.7223164240519204\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] Epoch[258] Batch [5]#011Speed: 2089.12 samples/sec#011loss=2.722316\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] Epoch[258] Batch[10] avg_epoch_loss=2.721761\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=2.721094083786011\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] Epoch[258] Batch [10]#011Speed: 1920.41 samples/sec#011loss=2.721094\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747890438.429905, \"EndTime\": 1747890439.386375, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.1824798583984, \"count\": 1, \"min\": 956.1824798583984, \"max\": 956.1824798583984}}}\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1399.2119185781241 records/second\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] #progress_metric: host=algo-1, completed 64.75 % of epochs\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.7217608148401435\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] Epoch[259] Batch[0] avg_epoch_loss=2.677990\n",
      "[05/22/2025 05:07:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.677989959716797\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] Epoch[259] Batch[5] avg_epoch_loss=2.594155\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.5941547950108848\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] Epoch[259] Batch [5]#011Speed: 2115.24 samples/sec#011loss=2.594155\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] Epoch[259] Batch[10] avg_epoch_loss=2.601055\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=2.6093343257904054\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] Epoch[259] Batch [10]#011Speed: 1923.47 samples/sec#011loss=2.609334\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747890439.3864186, \"EndTime\": 1747890440.337682, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.0390758514404, \"count\": 1, \"min\": 951.0390758514404, \"max\": 951.0390758514404}}}\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1394.142151862847 records/second\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] #progress_metric: host=algo-1, completed 65.0 % of epochs\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.6010545817288486\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] Epoch[260] Batch[0] avg_epoch_loss=2.584319\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=2.5843188762664795\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] Epoch[260] Batch[5] avg_epoch_loss=2.613579\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.6135791540145874\n",
      "[05/22/2025 05:07:20 INFO 140551403046720] Epoch[260] Batch [5]#011Speed: 2076.12 samples/sec#011loss=2.613579\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] Epoch[260] Batch[10] avg_epoch_loss=2.721907\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=260, batch=10 train loss <loss>=2.8518996715545653\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] Epoch[260] Batch [10]#011Speed: 2137.03 samples/sec#011loss=2.851900\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747890440.3377385, \"EndTime\": 1747890441.268359, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.3805828094482, \"count\": 1, \"min\": 930.3805828094482, \"max\": 930.3805828094482}}}\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1383.1779856646383 records/second\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] #progress_metric: host=algo-1, completed 65.25 % of epochs\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.7219066619873047\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] Epoch[261] Batch[0] avg_epoch_loss=2.653291\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.6532907485961914\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] Epoch[261] Batch[5] avg_epoch_loss=2.603862\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.6038617690404258\n",
      "[05/22/2025 05:07:21 INFO 140551403046720] Epoch[261] Batch [5]#011Speed: 2134.91 samples/sec#011loss=2.603862\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] Epoch[261] Batch[10] avg_epoch_loss=2.617096\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=2.632977104187012\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] Epoch[261] Batch [10]#011Speed: 2080.80 samples/sec#011loss=2.632977\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747890441.2684157, \"EndTime\": 1747890442.1916573, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.9919910430908, \"count\": 1, \"min\": 922.9919910430908, \"max\": 922.9919910430908}}}\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1406.1711088261268 records/second\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] #progress_metric: host=algo-1, completed 65.5 % of epochs\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=261, train loss <loss>=2.617096012288874\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] Epoch[262] Batch[0] avg_epoch_loss=2.671248\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.671248197555542\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] Epoch[262] Batch[5] avg_epoch_loss=2.638437\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.6384365955988565\n",
      "[05/22/2025 05:07:22 INFO 140551403046720] Epoch[262] Batch [5]#011Speed: 2166.53 samples/sec#011loss=2.638437\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] Epoch[262] Batch[10] avg_epoch_loss=2.574135\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=2.4969720363616945\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] Epoch[262] Batch [10]#011Speed: 2038.15 samples/sec#011loss=2.496972\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747890442.1917126, \"EndTime\": 1747890443.1163287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.344539642334, \"count\": 1, \"min\": 924.344539642334, \"max\": 924.344539642334}}}\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1452.7944093357244 records/second\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] #progress_metric: host=algo-1, completed 65.75 % of epochs\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.574134523218328\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] Epoch[263] Batch[0] avg_epoch_loss=2.646516\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.6465163230895996\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] Epoch[263] Batch[5] avg_epoch_loss=2.676699\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.6766991217931113\n",
      "[05/22/2025 05:07:23 INFO 140551403046720] Epoch[263] Batch [5]#011Speed: 2199.83 samples/sec#011loss=2.676699\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] Epoch[263] Batch[10] avg_epoch_loss=2.681621\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=263, batch=10 train loss <loss>=2.6875281810760496\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] Epoch[263] Batch [10]#011Speed: 2098.26 samples/sec#011loss=2.687528\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747890443.1163807, \"EndTime\": 1747890444.0268548, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.2506637573242, \"count\": 1, \"min\": 910.2506637573242, \"max\": 910.2506637573242}}}\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1474.1786167000853 records/second\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] #progress_metric: host=algo-1, completed 66.0 % of epochs\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=263, train loss <loss>=2.6816214214671743\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] Epoch[264] Batch[0] avg_epoch_loss=2.606029\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.6060292720794678\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] Epoch[264] Batch[5] avg_epoch_loss=2.625098\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.6250977516174316\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] Epoch[264] Batch [5]#011Speed: 2098.80 samples/sec#011loss=2.625098\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] Epoch[264] Batch[10] avg_epoch_loss=2.646349\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=2.6718513488769533\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] Epoch[264] Batch [10]#011Speed: 2084.22 samples/sec#011loss=2.671851\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747890444.0269117, \"EndTime\": 1747890444.9512894, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.1061210632324, \"count\": 1, \"min\": 924.1061210632324, \"max\": 924.1061210632324}}}\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1451.0036346281595 records/second\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] #progress_metric: host=algo-1, completed 66.25 % of epochs\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.646349386735396\n",
      "[05/22/2025 05:07:24 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] Epoch[265] Batch[0] avg_epoch_loss=2.779362\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.779362440109253\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] Epoch[265] Batch[5] avg_epoch_loss=2.642222\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.642222205797831\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] Epoch[265] Batch [5]#011Speed: 2113.38 samples/sec#011loss=2.642222\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] Epoch[265] Batch[10] avg_epoch_loss=2.624123\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=2.602404069900513\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] Epoch[265] Batch [10]#011Speed: 2045.11 samples/sec#011loss=2.602404\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747890444.9513435, \"EndTime\": 1747890445.8805475, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.9615154266357, \"count\": 1, \"min\": 928.9615154266357, \"max\": 928.9615154266357}}}\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1434.8251796993673 records/second\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] #progress_metric: host=algo-1, completed 66.5 % of epochs\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.624123053117232\n",
      "[05/22/2025 05:07:25 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] Epoch[266] Batch[0] avg_epoch_loss=2.626176\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.626176357269287\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] Epoch[266] Batch[5] avg_epoch_loss=2.572398\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.5723976691563926\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] Epoch[266] Batch [5]#011Speed: 2100.37 samples/sec#011loss=2.572398\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] Epoch[266] Batch[10] avg_epoch_loss=2.685541\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=2.821313762664795\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] Epoch[266] Batch [10]#011Speed: 2002.20 samples/sec#011loss=2.821314\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747890445.8805938, \"EndTime\": 1747890446.8180723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.1788501739502, \"count\": 1, \"min\": 937.1788501739502, \"max\": 937.1788501739502}}}\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1437.1589096194575 records/second\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] #progress_metric: host=algo-1, completed 66.75 % of epochs\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.685541348023848\n",
      "[05/22/2025 05:07:26 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] Epoch[267] Batch[0] avg_epoch_loss=2.514169\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.514169454574585\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] Epoch[267] Batch[5] avg_epoch_loss=2.568880\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.568880041440328\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] Epoch[267] Batch [5]#011Speed: 1976.69 samples/sec#011loss=2.568880\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] Epoch[267] Batch[10] avg_epoch_loss=2.662765\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=2.775426435470581\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] Epoch[267] Batch [10]#011Speed: 2003.90 samples/sec#011loss=2.775426\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747890446.8181317, \"EndTime\": 1747890447.7735255, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.1169872283936, \"count\": 1, \"min\": 955.1169872283936, \"max\": 955.1169872283936}}}\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1420.6407001178861 records/second\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] #progress_metric: host=algo-1, completed 67.0 % of epochs\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.6627647659995337\n",
      "[05/22/2025 05:07:27 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] Epoch[268] Batch[0] avg_epoch_loss=2.583489\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.583489179611206\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] Epoch[268] Batch[5] avg_epoch_loss=2.610859\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.610858599344889\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] Epoch[268] Batch [5]#011Speed: 2133.99 samples/sec#011loss=2.610859\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] Epoch[268] Batch[10] avg_epoch_loss=2.616998\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=268, batch=10 train loss <loss>=2.6243648529052734\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] Epoch[268] Batch [10]#011Speed: 2041.89 samples/sec#011loss=2.624365\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] processed a total of 1385 examples\n",
      "#metrics {\"StartTime\": 1747890447.7735822, \"EndTime\": 1747890448.695158, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.3278293609619, \"count\": 1, \"min\": 921.3278293609619, \"max\": 921.3278293609619}}}\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1503.1266558594039 records/second\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] #progress_metric: host=algo-1, completed 67.25 % of epochs\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.6169978055087\n",
      "[05/22/2025 05:07:28 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] Epoch[269] Batch[0] avg_epoch_loss=2.579111\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=2.579111099243164\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] Epoch[269] Batch[5] avg_epoch_loss=2.561397\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=2.5613969961802163\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] Epoch[269] Batch [5]#011Speed: 2166.31 samples/sec#011loss=2.561397\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] Epoch[269] Batch[10] avg_epoch_loss=2.520975\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=269, batch=10 train loss <loss>=2.472469615936279\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] Epoch[269] Batch [10]#011Speed: 2020.37 samples/sec#011loss=2.472470\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747890448.695215, \"EndTime\": 1747890449.6186066, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.1064319610596, \"count\": 1, \"min\": 923.1064319610596, \"max\": 923.1064319610596}}}\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1435.1680226096082 records/second\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] #progress_metric: host=algo-1, completed 67.5 % of epochs\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=269, train loss <loss>=2.5209754597056997\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] Epoch[270] Batch[0] avg_epoch_loss=2.645785\n",
      "[05/22/2025 05:07:29 INFO 140551403046720] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=2.645784616470337\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] Epoch[270] Batch[5] avg_epoch_loss=2.536560\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=2.536559542020162\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] Epoch[270] Batch [5]#011Speed: 2161.37 samples/sec#011loss=2.536560\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] Epoch[270] Batch[10] avg_epoch_loss=2.677851\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=2.8474001407623293\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] Epoch[270] Batch [10]#011Speed: 2152.11 samples/sec#011loss=2.847400\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747890449.6187077, \"EndTime\": 1747890450.5262794, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.3085784912109, \"count\": 1, \"min\": 907.3085784912109, \"max\": 907.3085784912109}}}\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1474.5521220151834 records/second\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] #progress_metric: host=algo-1, completed 67.75 % of epochs\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=270, train loss <loss>=2.6778507232666016\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] Epoch[271] Batch[0] avg_epoch_loss=2.671942\n",
      "[05/22/2025 05:07:30 INFO 140551403046720] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=2.6719415187835693\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] Epoch[271] Batch[5] avg_epoch_loss=2.533400\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=2.533400217692057\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] Epoch[271] Batch [5]#011Speed: 2117.77 samples/sec#011loss=2.533400\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] Epoch[271] Batch[10] avg_epoch_loss=2.559306\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=271, batch=10 train loss <loss>=2.5903930187225344\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] Epoch[271] Batch [10]#011Speed: 2102.03 samples/sec#011loss=2.590393\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747890450.526336, \"EndTime\": 1747890451.4618745, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.2858066558838, \"count\": 1, \"min\": 935.2858066558838, \"max\": 935.2858066558838}}}\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1390.8920720936576 records/second\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] #progress_metric: host=algo-1, completed 68.0 % of epochs\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=271, train loss <loss>=2.559306036342274\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] Epoch[272] Batch[0] avg_epoch_loss=2.676887\n",
      "[05/22/2025 05:07:31 INFO 140551403046720] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=2.676886796951294\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] Epoch[272] Batch[5] avg_epoch_loss=2.578461\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=2.5784610509872437\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] Epoch[272] Batch [5]#011Speed: 2140.11 samples/sec#011loss=2.578461\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] Epoch[272] Batch[10] avg_epoch_loss=2.571790\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=2.563784646987915\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] Epoch[272] Batch [10]#011Speed: 1979.27 samples/sec#011loss=2.563785\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747890451.4619312, \"EndTime\": 1747890452.3990283, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.8336200714111, \"count\": 1, \"min\": 936.8336200714111, \"max\": 936.8336200714111}}}\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1413.1435562839083 records/second\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] #progress_metric: host=algo-1, completed 68.25 % of epochs\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=272, train loss <loss>=2.571789958260276\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] Epoch[273] Batch[0] avg_epoch_loss=2.705631\n",
      "[05/22/2025 05:07:32 INFO 140551403046720] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=2.7056307792663574\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] Epoch[273] Batch[5] avg_epoch_loss=2.603874\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=2.603874087333679\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] Epoch[273] Batch [5]#011Speed: 2162.78 samples/sec#011loss=2.603874\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] Epoch[273] Batch[10] avg_epoch_loss=2.619833\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=273, batch=10 train loss <loss>=2.6389842987060548\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] Epoch[273] Batch [10]#011Speed: 2010.29 samples/sec#011loss=2.638984\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747890452.3990858, \"EndTime\": 1747890453.3289773, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.6164512634277, \"count\": 1, \"min\": 929.6164512634277, \"max\": 929.6164512634277}}}\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1426.2641341050316 records/second\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] #progress_metric: host=algo-1, completed 68.5 % of epochs\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=273, train loss <loss>=2.6198332743211226\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] Epoch[274] Batch[0] avg_epoch_loss=2.596818\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=2.596817970275879\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] Epoch[274] Batch[5] avg_epoch_loss=2.567204\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=2.5672040383021035\n",
      "[05/22/2025 05:07:33 INFO 140551403046720] Epoch[274] Batch [5]#011Speed: 2158.25 samples/sec#011loss=2.567204\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] Epoch[274] Batch[10] avg_epoch_loss=2.483611\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=274, batch=10 train loss <loss>=2.3832995176315306\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] Epoch[274] Batch [10]#011Speed: 2072.43 samples/sec#011loss=2.383300\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747890453.3290336, \"EndTime\": 1747890454.2481678, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.889045715332, \"count\": 1, \"min\": 918.889045715332, \"max\": 918.889045715332}}}\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1427.6785083661568 records/second\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] #progress_metric: host=algo-1, completed 68.75 % of epochs\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=274, train loss <loss>=2.483611074360934\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_06579a5f-0fea-42c1-9b17-76ad51f1f905-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890454.2482245, \"EndTime\": 1747890454.2590432, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.536670684814453, \"count\": 1, \"min\": 10.536670684814453, \"max\": 10.536670684814453}}}\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] Epoch[275] Batch[0] avg_epoch_loss=2.652526\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=2.652526378631592\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] Epoch[275] Batch[5] avg_epoch_loss=2.530619\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=2.5306185483932495\n",
      "[05/22/2025 05:07:34 INFO 140551403046720] Epoch[275] Batch [5]#011Speed: 2193.87 samples/sec#011loss=2.530619\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] Epoch[275] Batch[10] avg_epoch_loss=2.464868\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=275, batch=10 train loss <loss>=2.385968327522278\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] Epoch[275] Batch [10]#011Speed: 2093.93 samples/sec#011loss=2.385968\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747890454.2590945, \"EndTime\": 1747890455.189031, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.8889636993408, \"count\": 1, \"min\": 929.8889636993408, \"max\": 929.8889636993408}}}\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1386.0640463233317 records/second\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] #progress_metric: host=algo-1, completed 69.0 % of epochs\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=275, train loss <loss>=2.4648684479973535\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_0a6cad2b-a723-445e-9ea6-387757c5abdc-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890455.189086, \"EndTime\": 1747890455.1995811, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.230779647827148, \"count\": 1, \"min\": 10.230779647827148, \"max\": 10.230779647827148}}}\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] Epoch[276] Batch[0] avg_epoch_loss=2.437221\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=2.437221050262451\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] Epoch[276] Batch[5] avg_epoch_loss=2.507539\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=2.507538676261902\n",
      "[05/22/2025 05:07:35 INFO 140551403046720] Epoch[276] Batch [5]#011Speed: 2111.92 samples/sec#011loss=2.507539\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] Epoch[276] Batch[10] avg_epoch_loss=2.509182\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=2.5111546993255613\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] Epoch[276] Batch [10]#011Speed: 1968.03 samples/sec#011loss=2.511155\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] processed a total of 1387 examples\n",
      "#metrics {\"StartTime\": 1747890455.199633, \"EndTime\": 1747890456.1347408, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.0600242614746, \"count\": 1, \"min\": 935.0600242614746, \"max\": 935.0600242614746}}}\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1483.1907119494315 records/second\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] #progress_metric: host=algo-1, completed 69.25 % of epochs\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=276, train loss <loss>=2.50918232310902\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] Epoch[277] Batch[0] avg_epoch_loss=2.708753\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=2.7087526321411133\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] Epoch[277] Batch[5] avg_epoch_loss=2.579852\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=2.5798521439234414\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] Epoch[277] Batch [5]#011Speed: 2125.72 samples/sec#011loss=2.579852\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747890456.134799, \"EndTime\": 1747890456.997124, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 862.0717525482178, \"count\": 1, \"min\": 862.0717525482178, \"max\": 862.0717525482178}}}\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1483.4743750523687 records/second\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] #progress_metric: host=algo-1, completed 69.5 % of epochs\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] #quality_metric: host=algo-1, epoch=277, train loss <loss>=2.5442200899124146\n",
      "[05/22/2025 05:07:36 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] Epoch[278] Batch[0] avg_epoch_loss=2.496992\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=2.4969916343688965\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] Epoch[278] Batch[5] avg_epoch_loss=2.544583\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=2.5445825258890786\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] Epoch[278] Batch [5]#011Speed: 2112.59 samples/sec#011loss=2.544583\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] Epoch[278] Batch[10] avg_epoch_loss=2.577590\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=2.6171994686126707\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] Epoch[278] Batch [10]#011Speed: 1957.80 samples/sec#011loss=2.617199\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] processed a total of 1407 examples\n",
      "#metrics {\"StartTime\": 1747890456.9971864, \"EndTime\": 1747890457.9349906, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.5262260437012, \"count\": 1, \"min\": 937.5262260437012, \"max\": 937.5262260437012}}}\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1500.6217797924899 records/second\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] #progress_metric: host=algo-1, completed 69.75 % of epochs\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] #quality_metric: host=algo-1, epoch=278, train loss <loss>=2.577590227127075\n",
      "[05/22/2025 05:07:37 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] Epoch[279] Batch[0] avg_epoch_loss=2.471449\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=2.4714488983154297\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] Epoch[279] Batch[5] avg_epoch_loss=2.527040\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=2.5270395278930664\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] Epoch[279] Batch [5]#011Speed: 2143.07 samples/sec#011loss=2.527040\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] Epoch[279] Batch[10] avg_epoch_loss=2.606461\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=2.7017659664154055\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] Epoch[279] Batch [10]#011Speed: 2037.73 samples/sec#011loss=2.701766\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747890457.935049, \"EndTime\": 1747890458.8603106, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.015926361084, \"count\": 1, \"min\": 925.015926361084, \"max\": 925.015926361084}}}\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1452.8120291915723 records/second\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] #progress_metric: host=algo-1, completed 70.0 % of epochs\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] #quality_metric: host=algo-1, epoch=279, train loss <loss>=2.6064606363123115\n",
      "[05/22/2025 05:07:38 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] Epoch[280] Batch[0] avg_epoch_loss=2.429356\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=2.429356336593628\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] Epoch[280] Batch[5] avg_epoch_loss=2.528432\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=2.5284319718678794\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] Epoch[280] Batch [5]#011Speed: 2149.42 samples/sec#011loss=2.528432\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] Epoch[280] Batch[10] avg_epoch_loss=2.556783\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=2.5908042430877685\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] Epoch[280] Batch [10]#011Speed: 1961.25 samples/sec#011loss=2.590804\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] processed a total of 1385 examples\n",
      "#metrics {\"StartTime\": 1747890458.8603678, \"EndTime\": 1747890459.789528, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.9138317108154, \"count\": 1, \"min\": 928.9138317108154, \"max\": 928.9138317108154}}}\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1490.8562751171373 records/second\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] #progress_metric: host=algo-1, completed 70.25 % of epochs\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] #quality_metric: host=algo-1, epoch=280, train loss <loss>=2.556783004240556\n",
      "[05/22/2025 05:07:39 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] Epoch[281] Batch[0] avg_epoch_loss=2.426706\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=2.426705837249756\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] Epoch[281] Batch[5] avg_epoch_loss=2.535036\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=2.535036087036133\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] Epoch[281] Batch [5]#011Speed: 2158.73 samples/sec#011loss=2.535036\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] Epoch[281] Batch[10] avg_epoch_loss=2.531938\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=281, batch=10 train loss <loss>=2.528219795227051\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] Epoch[281] Batch [10]#011Speed: 2037.58 samples/sec#011loss=2.528220\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747890459.7895834, \"EndTime\": 1747890460.7256484, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.7876777648926, \"count\": 1, \"min\": 935.7876777648926, \"max\": 935.7876777648926}}}\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1408.3132068675009 records/second\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] #progress_metric: host=algo-1, completed 70.5 % of epochs\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] #quality_metric: host=algo-1, epoch=281, train loss <loss>=2.531937772577459\n",
      "[05/22/2025 05:07:40 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] Epoch[282] Batch[0] avg_epoch_loss=2.593914\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=2.593914270401001\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] Epoch[282] Batch[5] avg_epoch_loss=2.563023\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=2.563023090362549\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] Epoch[282] Batch [5]#011Speed: 2074.10 samples/sec#011loss=2.563023\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] Epoch[282] Batch[10] avg_epoch_loss=2.588834\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=282, batch=10 train loss <loss>=2.619807481765747\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] Epoch[282] Batch [10]#011Speed: 1978.70 samples/sec#011loss=2.619807\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747890460.7257037, \"EndTime\": 1747890461.6679888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.042350769043, \"count\": 1, \"min\": 942.042350769043, \"max\": 942.042350769043}}}\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1462.6470933444411 records/second\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] #progress_metric: host=algo-1, completed 70.75 % of epochs\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=282, train loss <loss>=2.5888341773640025\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] Epoch[283] Batch[0] avg_epoch_loss=2.487784\n",
      "[05/22/2025 05:07:41 INFO 140551403046720] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=2.487783670425415\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] Epoch[283] Batch[5] avg_epoch_loss=2.541992\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=2.5419921477635703\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] Epoch[283] Batch [5]#011Speed: 2207.66 samples/sec#011loss=2.541992\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] Epoch[283] Batch[10] avg_epoch_loss=2.599652\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=283, batch=10 train loss <loss>=2.668844127655029\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] Epoch[283] Batch [10]#011Speed: 2079.47 samples/sec#011loss=2.668844\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747890461.6680458, \"EndTime\": 1747890462.5746627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.3706398010254, \"count\": 1, \"min\": 906.3706398010254, \"max\": 906.3706398010254}}}\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1506.9626532595644 records/second\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] #progress_metric: host=algo-1, completed 71.0 % of epochs\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=283, train loss <loss>=2.5996521386233242\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] Epoch[284] Batch[0] avg_epoch_loss=2.498659\n",
      "[05/22/2025 05:07:42 INFO 140551403046720] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=2.498659133911133\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] Epoch[284] Batch[5] avg_epoch_loss=2.524581\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=2.524581034978231\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] Epoch[284] Batch [5]#011Speed: 2080.66 samples/sec#011loss=2.524581\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] Epoch[284] Batch[10] avg_epoch_loss=2.637163\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=284, batch=10 train loss <loss>=2.7722609519958494\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] Epoch[284] Batch [10]#011Speed: 2111.51 samples/sec#011loss=2.772261\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747890462.574723, \"EndTime\": 1747890463.501598, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.6281127929688, \"count\": 1, \"min\": 926.6281127929688, \"max\": 926.6281127929688}}}\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1388.7848566248535 records/second\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] #progress_metric: host=algo-1, completed 71.25 % of epochs\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=284, train loss <loss>=2.6371628154407847\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] Epoch[285] Batch[0] avg_epoch_loss=2.593708\n",
      "[05/22/2025 05:07:43 INFO 140551403046720] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=2.593707799911499\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] Epoch[285] Batch[5] avg_epoch_loss=2.535735\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=2.5357354084650674\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] Epoch[285] Batch [5]#011Speed: 2182.93 samples/sec#011loss=2.535735\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] Epoch[285] Batch[10] avg_epoch_loss=2.622371\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=2.726333427429199\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] Epoch[285] Batch [10]#011Speed: 2042.68 samples/sec#011loss=2.726333\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747890463.5016525, \"EndTime\": 1747890464.4232128, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.2391376495361, \"count\": 1, \"min\": 921.2391376495361, \"max\": 921.2391376495361}}}\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1430.5480739421548 records/second\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] #progress_metric: host=algo-1, completed 71.5 % of epochs\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=285, train loss <loss>=2.622370871630582\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] Epoch[286] Batch[0] avg_epoch_loss=2.769697\n",
      "[05/22/2025 05:07:44 INFO 140551403046720] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=2.7696967124938965\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] Epoch[286] Batch[5] avg_epoch_loss=2.629895\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=2.629895488421122\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] Epoch[286] Batch [5]#011Speed: 2080.91 samples/sec#011loss=2.629895\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] Epoch[286] Batch[10] avg_epoch_loss=2.555571\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=286, batch=10 train loss <loss>=2.4663817405700685\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] Epoch[286] Batch [10]#011Speed: 2135.86 samples/sec#011loss=2.466382\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747890464.4232702, \"EndTime\": 1747890465.3499699, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.4585971832275, \"count\": 1, \"min\": 926.4585971832275, \"max\": 926.4585971832275}}}\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1390.1125035574541 records/second\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] #progress_metric: host=algo-1, completed 71.75 % of epochs\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=286, train loss <loss>=2.555571057579734\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] Epoch[287] Batch[0] avg_epoch_loss=2.492140\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=2.492140293121338\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] Epoch[287] Batch[5] avg_epoch_loss=2.609315\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=2.609315037727356\n",
      "[05/22/2025 05:07:45 INFO 140551403046720] Epoch[287] Batch [5]#011Speed: 2189.88 samples/sec#011loss=2.609315\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] Epoch[287] Batch[10] avg_epoch_loss=2.614056\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=2.619744873046875\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] Epoch[287] Batch [10]#011Speed: 2106.08 samples/sec#011loss=2.619745\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747890465.350027, \"EndTime\": 1747890466.2680361, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.7682399749756, \"count\": 1, \"min\": 917.7682399749756, \"max\": 917.7682399749756}}}\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1400.0035950274328 records/second\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] #progress_metric: host=algo-1, completed 72.0 % of epochs\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=287, train loss <loss>=2.614055871963501\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] Epoch[288] Batch[0] avg_epoch_loss=2.669928\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=2.6699278354644775\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] Epoch[288] Batch[5] avg_epoch_loss=2.587302\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=2.5873021682103476\n",
      "[05/22/2025 05:07:46 INFO 140551403046720] Epoch[288] Batch [5]#011Speed: 2200.96 samples/sec#011loss=2.587302\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] Epoch[288] Batch[10] avg_epoch_loss=2.627445\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=288, batch=10 train loss <loss>=2.6756174087524416\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] Epoch[288] Batch [10]#011Speed: 2097.02 samples/sec#011loss=2.675617\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747890466.2680929, \"EndTime\": 1747890467.1811464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.8119945526123, \"count\": 1, \"min\": 912.8119945526123, \"max\": 912.8119945526123}}}\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1428.4209556423095 records/second\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] #progress_metric: host=algo-1, completed 72.25 % of epochs\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=288, train loss <loss>=2.6274454593658447\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] Epoch[289] Batch[0] avg_epoch_loss=2.423938\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=2.4239375591278076\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] Epoch[289] Batch[5] avg_epoch_loss=2.522341\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=2.5223412911097207\n",
      "[05/22/2025 05:07:47 INFO 140551403046720] Epoch[289] Batch [5]#011Speed: 2056.94 samples/sec#011loss=2.522341\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] Epoch[289] Batch[10] avg_epoch_loss=2.443027\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=289, batch=10 train loss <loss>=2.3478501081466674\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] Epoch[289] Batch [10]#011Speed: 2039.96 samples/sec#011loss=2.347850\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747890467.1812024, \"EndTime\": 1747890468.1262197, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.7588920593262, \"count\": 1, \"min\": 944.7588920593262, \"max\": 944.7588920593262}}}\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1367.3683537478203 records/second\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] #progress_metric: host=algo-1, completed 72.5 % of epochs\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=289, train loss <loss>=2.4430271170356055\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] best epoch loss so far\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/state_604a4b9e-eea8-4b3f-bc55-e182b42c1c54-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890468.126311, \"EndTime\": 1747890468.1372132, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.630369186401367, \"count\": 1, \"min\": 10.630369186401367, \"max\": 10.630369186401367}}}\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] Epoch[290] Batch[0] avg_epoch_loss=2.557708\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=2.5577080249786377\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] Epoch[290] Batch[5] avg_epoch_loss=2.582702\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=2.5827024380366006\n",
      "[05/22/2025 05:07:48 INFO 140551403046720] Epoch[290] Batch [5]#011Speed: 2173.76 samples/sec#011loss=2.582702\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] Epoch[290] Batch[10] avg_epoch_loss=2.581830\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=290, batch=10 train loss <loss>=2.580783748626709\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] Epoch[290] Batch [10]#011Speed: 2022.44 samples/sec#011loss=2.580784\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747890468.1372578, \"EndTime\": 1747890469.0571737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.8687076568604, \"count\": 1, \"min\": 919.8687076568604, \"max\": 919.8687076568604}}}\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1465.293975625091 records/second\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] #progress_metric: host=algo-1, completed 72.75 % of epochs\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=290, train loss <loss>=2.58183030648665\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] Epoch[291] Batch[0] avg_epoch_loss=2.561141\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=2.5611412525177\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] Epoch[291] Batch[5] avg_epoch_loss=2.516900\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=2.5169000228246055\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] Epoch[291] Batch [5]#011Speed: 2174.44 samples/sec#011loss=2.516900\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] Epoch[291] Batch[10] avg_epoch_loss=2.594335\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=291, batch=10 train loss <loss>=2.68725643157959\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] Epoch[291] Batch [10]#011Speed: 2039.41 samples/sec#011loss=2.687256\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747890469.0572295, \"EndTime\": 1747890469.9799223, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.4495887756348, \"count\": 1, \"min\": 922.4495887756348, \"max\": 922.4495887756348}}}\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1449.263477595898 records/second\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] #progress_metric: host=algo-1, completed 73.0 % of epochs\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] #quality_metric: host=algo-1, epoch=291, train loss <loss>=2.594334754076871\n",
      "[05/22/2025 05:07:49 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] Epoch[292] Batch[0] avg_epoch_loss=2.521146\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=2.521146297454834\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] Epoch[292] Batch[5] avg_epoch_loss=2.570967\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=2.570967197418213\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] Epoch[292] Batch [5]#011Speed: 2212.02 samples/sec#011loss=2.570967\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] Epoch[292] Batch[10] avg_epoch_loss=2.640786\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=292, batch=10 train loss <loss>=2.7245688438415527\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] Epoch[292] Batch [10]#011Speed: 2154.40 samples/sec#011loss=2.724569\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747890469.9799798, \"EndTime\": 1747890470.8795671, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 899.3403911590576, \"count\": 1, \"min\": 899.3403911590576, \"max\": 899.3403911590576}}}\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1429.801568417883 records/second\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] #progress_metric: host=algo-1, completed 73.25 % of epochs\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] #quality_metric: host=algo-1, epoch=292, train loss <loss>=2.64078612761064\n",
      "[05/22/2025 05:07:50 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] Epoch[293] Batch[0] avg_epoch_loss=2.549087\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=2.549086809158325\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] Epoch[293] Batch[5] avg_epoch_loss=2.576620\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=2.576619505882263\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] Epoch[293] Batch [5]#011Speed: 2235.92 samples/sec#011loss=2.576620\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] Epoch[293] Batch[10] avg_epoch_loss=2.593287\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=293, batch=10 train loss <loss>=2.61328763961792\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] Epoch[293] Batch [10]#011Speed: 2227.96 samples/sec#011loss=2.613288\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747890470.8796237, \"EndTime\": 1747890471.7699244, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 890.031099319458, \"count\": 1, \"min\": 890.031099319458, \"max\": 890.031099319458}}}\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1455.917510244126 records/second\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] #progress_metric: host=algo-1, completed 73.5 % of epochs\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] #quality_metric: host=algo-1, epoch=293, train loss <loss>=2.5932868393984707\n",
      "[05/22/2025 05:07:51 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] Epoch[294] Batch[0] avg_epoch_loss=2.721306\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=2.7213058471679688\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] Epoch[294] Batch[5] avg_epoch_loss=2.669351\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=2.669351061185201\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] Epoch[294] Batch [5]#011Speed: 2178.75 samples/sec#011loss=2.669351\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] Epoch[294] Batch[10] avg_epoch_loss=2.588519\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=294, batch=10 train loss <loss>=2.49152090549469\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] Epoch[294] Batch [10]#011Speed: 2132.14 samples/sec#011loss=2.491521\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747890471.7700243, \"EndTime\": 1747890472.677841, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.5524806976318, \"count\": 1, \"min\": 907.5524806976318, \"max\": 907.5524806976318}}}\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1447.7162817124577 records/second\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] #progress_metric: host=algo-1, completed 73.75 % of epochs\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=294, train loss <loss>=2.5885191722349687\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] Epoch[295] Batch[0] avg_epoch_loss=2.615921\n",
      "[05/22/2025 05:07:52 INFO 140551403046720] #quality_metric: host=algo-1, epoch=295, batch=0 train loss <loss>=2.6159207820892334\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] Epoch[295] Batch[5] avg_epoch_loss=2.566677\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=295, batch=5 train loss <loss>=2.5666772524515786\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] Epoch[295] Batch [5]#011Speed: 2074.23 samples/sec#011loss=2.566677\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] Epoch[295] Batch[10] avg_epoch_loss=2.524312\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=295, batch=10 train loss <loss>=2.4734739303588866\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] Epoch[295] Batch [10]#011Speed: 2029.94 samples/sec#011loss=2.473474\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747890472.677896, \"EndTime\": 1747890473.6152687, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.5324974060059, \"count\": 1, \"min\": 936.5324974060059, \"max\": 936.5324974060059}}}\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1413.5957233146908 records/second\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] #progress_metric: host=algo-1, completed 74.0 % of epochs\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=295, train loss <loss>=2.5243121060458096\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] Epoch[296] Batch[0] avg_epoch_loss=2.542633\n",
      "[05/22/2025 05:07:53 INFO 140551403046720] #quality_metric: host=algo-1, epoch=296, batch=0 train loss <loss>=2.542633056640625\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] Epoch[296] Batch[5] avg_epoch_loss=2.560606\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=296, batch=5 train loss <loss>=2.5606056451797485\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] Epoch[296] Batch [5]#011Speed: 2148.90 samples/sec#011loss=2.560606\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] Epoch[296] Batch[10] avg_epoch_loss=2.692783\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=296, batch=10 train loss <loss>=2.851396417617798\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] Epoch[296] Batch [10]#011Speed: 2106.61 samples/sec#011loss=2.851396\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747890473.6153276, \"EndTime\": 1747890474.5308912, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.2772426605225, \"count\": 1, \"min\": 915.2772426605225, \"max\": 915.2772426605225}}}\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1430.0295562601939 records/second\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] #progress_metric: host=algo-1, completed 74.25 % of epochs\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=296, train loss <loss>=2.6927832690152256\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] Epoch[297] Batch[0] avg_epoch_loss=2.547453\n",
      "[05/22/2025 05:07:54 INFO 140551403046720] #quality_metric: host=algo-1, epoch=297, batch=0 train loss <loss>=2.5474534034729004\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] Epoch[297] Batch[5] avg_epoch_loss=2.543796\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=297, batch=5 train loss <loss>=2.543795585632324\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] Epoch[297] Batch [5]#011Speed: 2065.01 samples/sec#011loss=2.543796\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] Epoch[297] Batch[10] avg_epoch_loss=2.562511\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=297, batch=10 train loss <loss>=2.58496994972229\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] Epoch[297] Batch [10]#011Speed: 2030.58 samples/sec#011loss=2.584970\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] processed a total of 1384 examples\n",
      "#metrics {\"StartTime\": 1747890474.5309494, \"EndTime\": 1747890475.4665093, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.3134632110596, \"count\": 1, \"min\": 935.3134632110596, \"max\": 935.3134632110596}}}\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1479.5846846897364 records/second\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] #progress_metric: host=algo-1, completed 74.5 % of epochs\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=297, train loss <loss>=2.5625112056732178\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] Epoch[298] Batch[0] avg_epoch_loss=2.657727\n",
      "[05/22/2025 05:07:55 INFO 140551403046720] #quality_metric: host=algo-1, epoch=298, batch=0 train loss <loss>=2.657726764678955\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] Epoch[298] Batch[5] avg_epoch_loss=2.549519\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=298, batch=5 train loss <loss>=2.549518585205078\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] Epoch[298] Batch [5]#011Speed: 2105.92 samples/sec#011loss=2.549519\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] processed a total of 1256 examples\n",
      "#metrics {\"StartTime\": 1747890475.466566, \"EndTime\": 1747890476.3308961, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.0785217285156, \"count\": 1, \"min\": 864.0785217285156, \"max\": 864.0785217285156}}}\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1453.399560838782 records/second\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] #progress_metric: host=algo-1, completed 74.75 % of epochs\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=298, train loss <loss>=2.4901817560195925\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] Epoch[299] Batch[0] avg_epoch_loss=2.513892\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=299, batch=0 train loss <loss>=2.51389217376709\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] Epoch[299] Batch[5] avg_epoch_loss=2.459345\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] #quality_metric: host=algo-1, epoch=299, batch=5 train loss <loss>=2.4593449036280313\n",
      "[05/22/2025 05:07:56 INFO 140551403046720] Epoch[299] Batch [5]#011Speed: 2089.51 samples/sec#011loss=2.459345\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] Epoch[299] Batch[10] avg_epoch_loss=2.517695\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=299, batch=10 train loss <loss>=2.5877156257629395\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] Epoch[299] Batch [10]#011Speed: 1995.16 samples/sec#011loss=2.587716\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747890476.3309665, \"EndTime\": 1747890477.26743, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.0702037811279, \"count\": 1, \"min\": 936.0702037811279, \"max\": 936.0702037811279}}}\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1443.1149109695743 records/second\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] #progress_metric: host=algo-1, completed 75.0 % of epochs\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=299, train loss <loss>=2.5176952318711714\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] Epoch[300] Batch[0] avg_epoch_loss=2.584621\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=300, batch=0 train loss <loss>=2.5846211910247803\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] Epoch[300] Batch[5] avg_epoch_loss=2.533332\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] #quality_metric: host=algo-1, epoch=300, batch=5 train loss <loss>=2.533332188924154\n",
      "[05/22/2025 05:07:57 INFO 140551403046720] Epoch[300] Batch [5]#011Speed: 2093.43 samples/sec#011loss=2.533332\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] Epoch[300] Batch[10] avg_epoch_loss=2.790807\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=300, batch=10 train loss <loss>=3.099776363372803\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] Epoch[300] Batch [10]#011Speed: 2061.04 samples/sec#011loss=3.099776\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747890477.2674987, \"EndTime\": 1747890478.198001, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.1609992980957, \"count\": 1, \"min\": 930.1609992980957, \"max\": 930.1609992980957}}}\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1400.6546884907098 records/second\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] #progress_metric: host=algo-1, completed 75.25 % of epochs\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=300, train loss <loss>=2.7908068136735396\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] Epoch[301] Batch[0] avg_epoch_loss=2.858909\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=301, batch=0 train loss <loss>=2.8589091300964355\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] Epoch[301] Batch[5] avg_epoch_loss=2.909527\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] #quality_metric: host=algo-1, epoch=301, batch=5 train loss <loss>=2.9095272620519004\n",
      "[05/22/2025 05:07:58 INFO 140551403046720] Epoch[301] Batch [5]#011Speed: 2105.42 samples/sec#011loss=2.909527\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] Epoch[301] Batch[10] avg_epoch_loss=3.224405\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=301, batch=10 train loss <loss>=3.6022575378417967\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] Epoch[301] Batch [10]#011Speed: 2099.49 samples/sec#011loss=3.602258\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747890478.1980724, \"EndTime\": 1747890479.1257818, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.3703098297119, \"count\": 1, \"min\": 927.3703098297119, \"max\": 927.3703098297119}}}\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1393.0427480189971 records/second\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] #progress_metric: host=algo-1, completed 75.5 % of epochs\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=301, train loss <loss>=3.224404660138217\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] Epoch[302] Batch[0] avg_epoch_loss=2.787352\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=302, batch=0 train loss <loss>=2.7873523235321045\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] Epoch[302] Batch[5] avg_epoch_loss=2.992301\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] #quality_metric: host=algo-1, epoch=302, batch=5 train loss <loss>=2.992301066716512\n",
      "[05/22/2025 05:07:59 INFO 140551403046720] Epoch[302] Batch [5]#011Speed: 2155.19 samples/sec#011loss=2.992301\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] Epoch[302] Batch[10] avg_epoch_loss=2.929424\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=302, batch=10 train loss <loss>=2.8539708137512205\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] Epoch[302] Batch [10]#011Speed: 2067.63 samples/sec#011loss=2.853971\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747890479.1258447, \"EndTime\": 1747890480.0472357, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.0739135742188, \"count\": 1, \"min\": 921.0739135742188, \"max\": 921.0739135742188}}}\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1469.8843020383167 records/second\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] #progress_metric: host=algo-1, completed 75.75 % of epochs\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=302, train loss <loss>=2.929423679005016\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] Epoch[303] Batch[0] avg_epoch_loss=2.715353\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=303, batch=0 train loss <loss>=2.715353012084961\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] Epoch[303] Batch[5] avg_epoch_loss=2.781140\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=303, batch=5 train loss <loss>=2.781139850616455\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] Epoch[303] Batch [5]#011Speed: 2147.49 samples/sec#011loss=2.781140\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] Epoch[303] Batch[10] avg_epoch_loss=2.886258\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=303, batch=10 train loss <loss>=3.012400722503662\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] Epoch[303] Batch [10]#011Speed: 2097.05 samples/sec#011loss=3.012401\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747890480.047293, \"EndTime\": 1747890480.9649398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.4120426177979, \"count\": 1, \"min\": 917.4120426177979, \"max\": 917.4120426177979}}}\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1415.8023136582128 records/second\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] #progress_metric: host=algo-1, completed 76.0 % of epochs\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] #quality_metric: host=algo-1, epoch=303, train loss <loss>=2.886258428747004\n",
      "[05/22/2025 05:08:00 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] Epoch[304] Batch[0] avg_epoch_loss=2.828182\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=304, batch=0 train loss <loss>=2.828181743621826\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] Epoch[304] Batch[5] avg_epoch_loss=2.901984\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=304, batch=5 train loss <loss>=2.9019835392634072\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] Epoch[304] Batch [5]#011Speed: 2054.81 samples/sec#011loss=2.901984\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] Epoch[304] Batch[10] avg_epoch_loss=2.898487\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=304, batch=10 train loss <loss>=2.894290590286255\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] Epoch[304] Batch [10]#011Speed: 1958.59 samples/sec#011loss=2.894291\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747890480.9650002, \"EndTime\": 1747890481.9123242, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.066068649292, \"count\": 1, \"min\": 947.066068649292, \"max\": 947.066068649292}}}\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1425.2784011176068 records/second\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] #progress_metric: host=algo-1, completed 76.25 % of epochs\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] #quality_metric: host=algo-1, epoch=304, train loss <loss>=2.8984867442737925\n",
      "[05/22/2025 05:08:01 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] Epoch[305] Batch[0] avg_epoch_loss=2.729099\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=305, batch=0 train loss <loss>=2.7290992736816406\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] Epoch[305] Batch[5] avg_epoch_loss=2.729966\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=305, batch=5 train loss <loss>=2.7299656867980957\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] Epoch[305] Batch [5]#011Speed: 2052.15 samples/sec#011loss=2.729966\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] Epoch[305] Batch[10] avg_epoch_loss=2.694706\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=305, batch=10 train loss <loss>=2.652394962310791\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] Epoch[305] Batch [10]#011Speed: 2042.94 samples/sec#011loss=2.652395\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747890481.912409, \"EndTime\": 1747890482.856755, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.8588619232178, \"count\": 1, \"min\": 943.8588619232178, \"max\": 943.8588619232178}}}\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1451.3268932588853 records/second\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] #progress_metric: host=algo-1, completed 76.5 % of epochs\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] #quality_metric: host=algo-1, epoch=305, train loss <loss>=2.6947062665765937\n",
      "[05/22/2025 05:08:02 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] Epoch[306] Batch[0] avg_epoch_loss=2.633524\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=306, batch=0 train loss <loss>=2.633524179458618\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] Epoch[306] Batch[5] avg_epoch_loss=2.574645\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=306, batch=5 train loss <loss>=2.574645241101583\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] Epoch[306] Batch [5]#011Speed: 2093.79 samples/sec#011loss=2.574645\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] Epoch[306] Batch[10] avg_epoch_loss=2.525301\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=306, batch=10 train loss <loss>=2.46608829498291\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] Epoch[306] Batch [10]#011Speed: 1983.64 samples/sec#011loss=2.466088\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747890482.8568249, \"EndTime\": 1747890483.8004518, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.2761669158936, \"count\": 1, \"min\": 943.2761669158936, \"max\": 943.2761669158936}}}\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1432.1112367754438 records/second\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] #progress_metric: host=algo-1, completed 76.75 % of epochs\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] #quality_metric: host=algo-1, epoch=306, train loss <loss>=2.5253011746840044\n",
      "[05/22/2025 05:08:03 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] Epoch[307] Batch[0] avg_epoch_loss=2.689471\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=307, batch=0 train loss <loss>=2.6894707679748535\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] Epoch[307] Batch[5] avg_epoch_loss=2.570490\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=307, batch=5 train loss <loss>=2.5704897244771323\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] Epoch[307] Batch [5]#011Speed: 2123.23 samples/sec#011loss=2.570490\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] Epoch[307] Batch[10] avg_epoch_loss=2.556248\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=307, batch=10 train loss <loss>=2.539158248901367\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] Epoch[307] Batch [10]#011Speed: 2041.57 samples/sec#011loss=2.539158\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747890483.8005092, \"EndTime\": 1747890484.725157, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.410343170166, \"count\": 1, \"min\": 924.410343170166, \"max\": 924.410343170166}}}\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1465.653728308666 records/second\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] #progress_metric: host=algo-1, completed 77.0 % of epochs\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] #quality_metric: host=algo-1, epoch=307, train loss <loss>=2.5562481446699663\n",
      "[05/22/2025 05:08:04 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] Epoch[308] Batch[0] avg_epoch_loss=2.655110\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=308, batch=0 train loss <loss>=2.6551103591918945\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] Epoch[308] Batch[5] avg_epoch_loss=2.601671\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=308, batch=5 train loss <loss>=2.6016707022984824\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] Epoch[308] Batch [5]#011Speed: 2129.51 samples/sec#011loss=2.601671\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] Epoch[308] Batch[10] avg_epoch_loss=2.651697\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=308, batch=10 train loss <loss>=2.7117294311523437\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] Epoch[308] Batch [10]#011Speed: 2113.39 samples/sec#011loss=2.711729\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747890484.725223, \"EndTime\": 1747890485.6460624, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.5601215362549, \"count\": 1, \"min\": 920.5601215362549, \"max\": 920.5601215362549}}}\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1440.2703342975453 records/second\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] #progress_metric: host=algo-1, completed 77.25 % of epochs\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=308, train loss <loss>=2.6516973972320557\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] Epoch[309] Batch[0] avg_epoch_loss=2.596060\n",
      "[05/22/2025 05:08:05 INFO 140551403046720] #quality_metric: host=algo-1, epoch=309, batch=0 train loss <loss>=2.596060037612915\n",
      "[05/22/2025 05:08:06 INFO 140551403046720] Epoch[309] Batch[5] avg_epoch_loss=2.548302\n",
      "[05/22/2025 05:08:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=309, batch=5 train loss <loss>=2.548302173614502\n",
      "[05/22/2025 05:08:06 INFO 140551403046720] Epoch[309] Batch [5]#011Speed: 2114.74 samples/sec#011loss=2.548302\n",
      "[05/22/2025 05:08:06 INFO 140551403046720] processed a total of 1260 examples\n",
      "#metrics {\"StartTime\": 1747890485.6461298, \"EndTime\": 1747890486.5088027, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 862.3721599578857, \"count\": 1, \"min\": 862.3721599578857, \"max\": 862.3721599578857}}}\n",
      "[05/22/2025 05:08:06 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1460.923356592786 records/second\n",
      "[05/22/2025 05:08:06 INFO 140551403046720] #progress_metric: host=algo-1, completed 77.5 % of epochs\n",
      "[05/22/2025 05:08:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=309, train loss <loss>=2.5766114711761476\n",
      "[05/22/2025 05:08:06 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:06 INFO 140551403046720] Epoch[310] Batch[0] avg_epoch_loss=2.577688\n",
      "[05/22/2025 05:08:06 INFO 140551403046720] #quality_metric: host=algo-1, epoch=310, batch=0 train loss <loss>=2.577687978744507\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] Epoch[310] Batch[5] avg_epoch_loss=2.605086\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=310, batch=5 train loss <loss>=2.6050856510798135\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] Epoch[310] Batch [5]#011Speed: 2136.29 samples/sec#011loss=2.605086\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] Epoch[310] Batch[10] avg_epoch_loss=2.535445\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=310, batch=10 train loss <loss>=2.4518753051757813\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] Epoch[310] Batch [10]#011Speed: 2017.40 samples/sec#011loss=2.451875\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747890486.5088654, \"EndTime\": 1747890487.441387, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.1842193603516, \"count\": 1, \"min\": 932.1842193603516, \"max\": 932.1842193603516}}}\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1443.7887740871936 records/second\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] #progress_metric: host=algo-1, completed 77.75 % of epochs\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=310, train loss <loss>=2.535444584759799\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] Epoch[311] Batch[0] avg_epoch_loss=2.538707\n",
      "[05/22/2025 05:08:07 INFO 140551403046720] #quality_metric: host=algo-1, epoch=311, batch=0 train loss <loss>=2.5387065410614014\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] Epoch[311] Batch[5] avg_epoch_loss=2.569727\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=311, batch=5 train loss <loss>=2.569726506868998\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] Epoch[311] Batch [5]#011Speed: 2114.40 samples/sec#011loss=2.569727\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] Epoch[311] Batch[10] avg_epoch_loss=2.590443\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=311, batch=10 train loss <loss>=2.6153018951416014\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] Epoch[311] Batch [10]#011Speed: 1993.15 samples/sec#011loss=2.615302\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747890487.441443, \"EndTime\": 1747890488.3795297, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.8402233123779, \"count\": 1, \"min\": 937.8402233123779, \"max\": 937.8402233123779}}}\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1432.951335302521 records/second\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] #progress_metric: host=algo-1, completed 78.0 % of epochs\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=311, train loss <loss>=2.590442592447454\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] Epoch[312] Batch[0] avg_epoch_loss=2.438663\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=312, batch=0 train loss <loss>=2.438662528991699\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] Epoch[312] Batch[5] avg_epoch_loss=2.499790\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] #quality_metric: host=algo-1, epoch=312, batch=5 train loss <loss>=2.499790151913961\n",
      "[05/22/2025 05:08:08 INFO 140551403046720] Epoch[312] Batch [5]#011Speed: 2219.95 samples/sec#011loss=2.499790\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] Epoch[312] Batch[10] avg_epoch_loss=2.512013\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=312, batch=10 train loss <loss>=2.526681089401245\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] Epoch[312] Batch [10]#011Speed: 2151.51 samples/sec#011loss=2.526681\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747890488.3795857, \"EndTime\": 1747890489.27741, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.5574970245361, \"count\": 1, \"min\": 897.5574970245361, \"max\": 897.5574970245361}}}\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1480.5407538281581 records/second\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] #progress_metric: host=algo-1, completed 78.25 % of epochs\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=312, train loss <loss>=2.512013305317272\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] Epoch[313] Batch[0] avg_epoch_loss=2.564349\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=313, batch=0 train loss <loss>=2.5643486976623535\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] Epoch[313] Batch[5] avg_epoch_loss=2.531578\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] #quality_metric: host=algo-1, epoch=313, batch=5 train loss <loss>=2.5315779050191245\n",
      "[05/22/2025 05:08:09 INFO 140551403046720] Epoch[313] Batch [5]#011Speed: 2175.42 samples/sec#011loss=2.531578\n",
      "[05/22/2025 05:08:10 INFO 140551403046720] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747890489.2774675, \"EndTime\": 1747890490.1212823, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 843.5590267181396, \"count\": 1, \"min\": 843.5590267181396, \"max\": 843.5590267181396}}}\n",
      "[05/22/2025 05:08:10 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1517.2205297361945 records/second\n",
      "[05/22/2025 05:08:10 INFO 140551403046720] #progress_metric: host=algo-1, completed 78.5 % of epochs\n",
      "[05/22/2025 05:08:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=313, train loss <loss>=2.520165491104126\n",
      "[05/22/2025 05:08:10 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:10 INFO 140551403046720] Epoch[314] Batch[0] avg_epoch_loss=2.467287\n",
      "[05/22/2025 05:08:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=314, batch=0 train loss <loss>=2.467287063598633\n",
      "[05/22/2025 05:08:10 INFO 140551403046720] Epoch[314] Batch[5] avg_epoch_loss=2.538267\n",
      "[05/22/2025 05:08:10 INFO 140551403046720] #quality_metric: host=algo-1, epoch=314, batch=5 train loss <loss>=2.5382666985193887\n",
      "[05/22/2025 05:08:10 INFO 140551403046720] Epoch[314] Batch [5]#011Speed: 2188.85 samples/sec#011loss=2.538267\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] Epoch[314] Batch[10] avg_epoch_loss=2.590480\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=314, batch=10 train loss <loss>=2.653136157989502\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] Epoch[314] Batch [10]#011Speed: 2021.38 samples/sec#011loss=2.653136\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] processed a total of 1372 examples\n",
      "#metrics {\"StartTime\": 1747890490.121342, \"EndTime\": 1747890491.0367732, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.1082038879395, \"count\": 1, \"min\": 915.1082038879395, \"max\": 915.1082038879395}}}\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1499.1317403269722 records/second\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] #progress_metric: host=algo-1, completed 78.75 % of epochs\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=314, train loss <loss>=2.590480089187622\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] Epoch[315] Batch[0] avg_epoch_loss=2.621880\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=315, batch=0 train loss <loss>=2.621880054473877\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] Epoch[315] Batch[5] avg_epoch_loss=2.481766\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=315, batch=5 train loss <loss>=2.481765866279602\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] Epoch[315] Batch [5]#011Speed: 2157.88 samples/sec#011loss=2.481766\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] processed a total of 1277 examples\n",
      "#metrics {\"StartTime\": 1747890491.0368326, \"EndTime\": 1747890491.8899887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 852.9002666473389, \"count\": 1, \"min\": 852.9002666473389, \"max\": 852.9002666473389}}}\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1497.0801777111928 records/second\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] #progress_metric: host=algo-1, completed 79.0 % of epochs\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] #quality_metric: host=algo-1, epoch=315, train loss <loss>=2.47219078540802\n",
      "[05/22/2025 05:08:11 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] Epoch[316] Batch[0] avg_epoch_loss=2.419828\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=316, batch=0 train loss <loss>=2.419828414916992\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] Epoch[316] Batch[5] avg_epoch_loss=2.466788\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=316, batch=5 train loss <loss>=2.4667884508768716\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] Epoch[316] Batch [5]#011Speed: 2166.10 samples/sec#011loss=2.466788\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] Epoch[316] Batch[10] avg_epoch_loss=2.460525\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=316, batch=10 train loss <loss>=2.453009748458862\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] Epoch[316] Batch [10]#011Speed: 2017.53 samples/sec#011loss=2.453010\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747890491.89005, \"EndTime\": 1747890492.8198686, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.4788837432861, \"count\": 1, \"min\": 929.4788837432861, \"max\": 929.4788837432861}}}\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1413.5594050822644 records/second\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] #progress_metric: host=algo-1, completed 79.25 % of epochs\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] #quality_metric: host=algo-1, epoch=316, train loss <loss>=2.460525404323231\n",
      "[05/22/2025 05:08:12 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] Epoch[317] Batch[0] avg_epoch_loss=2.418079\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=317, batch=0 train loss <loss>=2.418079376220703\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] Epoch[317] Batch[5] avg_epoch_loss=2.480370\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=317, batch=5 train loss <loss>=2.4803702433904014\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] Epoch[317] Batch [5]#011Speed: 2132.24 samples/sec#011loss=2.480370\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] Epoch[317] Batch[10] avg_epoch_loss=2.474470\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=317, batch=10 train loss <loss>=2.4673894882202148\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] Epoch[317] Batch [10]#011Speed: 2022.41 samples/sec#011loss=2.467389\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747890492.8199272, \"EndTime\": 1747890493.7502859, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.0882816314697, \"count\": 1, \"min\": 930.0882816314697, \"max\": 930.0882816314697}}}\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1467.4713373739114 records/second\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] #progress_metric: host=algo-1, completed 79.5 % of epochs\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] #quality_metric: host=algo-1, epoch=317, train loss <loss>=2.4744699001312256\n",
      "[05/22/2025 05:08:13 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] Epoch[318] Batch[0] avg_epoch_loss=2.428042\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=318, batch=0 train loss <loss>=2.42804217338562\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] Epoch[318] Batch[5] avg_epoch_loss=2.533551\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=318, batch=5 train loss <loss>=2.533551255861918\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] Epoch[318] Batch [5]#011Speed: 2155.63 samples/sec#011loss=2.533551\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] Epoch[318] Batch[10] avg_epoch_loss=2.662636\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=318, batch=10 train loss <loss>=2.817538261413574\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] Epoch[318] Batch [10]#011Speed: 2110.57 samples/sec#011loss=2.817538\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747890493.7503414, \"EndTime\": 1747890494.6673675, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.7830944061279, \"count\": 1, \"min\": 916.7830944061279, \"max\": 916.7830944061279}}}\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1401.5082162111842 records/second\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] #progress_metric: host=algo-1, completed 79.75 % of epochs\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=318, train loss <loss>=2.662636258385398\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] Epoch[319] Batch[0] avg_epoch_loss=2.694855\n",
      "[05/22/2025 05:08:14 INFO 140551403046720] #quality_metric: host=algo-1, epoch=319, batch=0 train loss <loss>=2.694854974746704\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] Epoch[319] Batch[5] avg_epoch_loss=2.609392\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=319, batch=5 train loss <loss>=2.6093918085098267\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] Epoch[319] Batch [5]#011Speed: 2089.00 samples/sec#011loss=2.609392\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] Epoch[319] Batch[10] avg_epoch_loss=2.645644\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=319, batch=10 train loss <loss>=2.6891473293304444\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] Epoch[319] Batch [10]#011Speed: 2024.91 samples/sec#011loss=2.689147\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747890494.6674254, \"EndTime\": 1747890495.603697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.0229969024658, \"count\": 1, \"min\": 936.0229969024658, \"max\": 936.0229969024658}}}\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1420.7662945907255 records/second\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] #progress_metric: host=algo-1, completed 80.0 % of epochs\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=319, train loss <loss>=2.6456443179737437\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] Epoch[320] Batch[0] avg_epoch_loss=2.820566\n",
      "[05/22/2025 05:08:15 INFO 140551403046720] #quality_metric: host=algo-1, epoch=320, batch=0 train loss <loss>=2.820565700531006\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] Epoch[320] Batch[5] avg_epoch_loss=2.723640\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=320, batch=5 train loss <loss>=2.723639726638794\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] Epoch[320] Batch [5]#011Speed: 2072.55 samples/sec#011loss=2.723640\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] Epoch[320] Batch[10] avg_epoch_loss=2.655420\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=320, batch=10 train loss <loss>=2.573555898666382\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] Epoch[320] Batch [10]#011Speed: 2062.31 samples/sec#011loss=2.573556\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747890495.6037593, \"EndTime\": 1747890496.5384197, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.2951774597168, \"count\": 1, \"min\": 934.2951774597168, \"max\": 934.2951774597168}}}\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1419.1122570649457 records/second\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] #progress_metric: host=algo-1, completed 80.25 % of epochs\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=320, train loss <loss>=2.655419804833152\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] Epoch[321] Batch[0] avg_epoch_loss=2.662066\n",
      "[05/22/2025 05:08:16 INFO 140551403046720] #quality_metric: host=algo-1, epoch=321, batch=0 train loss <loss>=2.6620655059814453\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] Epoch[321] Batch[5] avg_epoch_loss=2.697348\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=321, batch=5 train loss <loss>=2.697347561518351\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] Epoch[321] Batch [5]#011Speed: 2101.58 samples/sec#011loss=2.697348\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] Epoch[321] Batch[10] avg_epoch_loss=2.749154\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=321, batch=10 train loss <loss>=2.8113224506378174\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] Epoch[321] Batch [10]#011Speed: 2097.95 samples/sec#011loss=2.811322\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747890496.538482, \"EndTime\": 1747890497.4673247, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.5438060760498, \"count\": 1, \"min\": 928.5438060760498, \"max\": 928.5438060760498}}}\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1384.8387562555392 records/second\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] #progress_metric: host=algo-1, completed 80.5 % of epochs\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=321, train loss <loss>=2.7491543292999268\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] Epoch[322] Batch[0] avg_epoch_loss=2.484990\n",
      "[05/22/2025 05:08:17 INFO 140551403046720] #quality_metric: host=algo-1, epoch=322, batch=0 train loss <loss>=2.484989881515503\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] Epoch[322] Batch[5] avg_epoch_loss=2.593344\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=322, batch=5 train loss <loss>=2.5933443307876587\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] Epoch[322] Batch [5]#011Speed: 1963.62 samples/sec#011loss=2.593344\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] Epoch[322] Batch[10] avg_epoch_loss=2.625762\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=322, batch=10 train loss <loss>=2.664662265777588\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] Epoch[322] Batch [10]#011Speed: 1981.01 samples/sec#011loss=2.664662\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747890497.4673815, \"EndTime\": 1747890498.4373875, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 969.7585105895996, \"count\": 1, \"min\": 969.7585105895996, \"max\": 969.7585105895996}}}\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1327.0196837908518 records/second\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] #progress_metric: host=algo-1, completed 80.75 % of epochs\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=322, train loss <loss>=2.6257615739648994\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] Epoch[323] Batch[0] avg_epoch_loss=2.665149\n",
      "[05/22/2025 05:08:18 INFO 140551403046720] #quality_metric: host=algo-1, epoch=323, batch=0 train loss <loss>=2.665149450302124\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] Epoch[323] Batch[5] avg_epoch_loss=2.583845\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=323, batch=5 train loss <loss>=2.583844780921936\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] Epoch[323] Batch [5]#011Speed: 2134.10 samples/sec#011loss=2.583845\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] Epoch[323] Batch[10] avg_epoch_loss=2.597249\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=323, batch=10 train loss <loss>=2.613333511352539\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] Epoch[323] Batch [10]#011Speed: 2050.00 samples/sec#011loss=2.613334\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747890498.4374433, \"EndTime\": 1747890499.3673131, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.6219348907471, \"count\": 1, \"min\": 929.6219348907471, \"max\": 929.6219348907471}}}\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1438.091093545164 records/second\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] #progress_metric: host=algo-1, completed 81.0 % of epochs\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=323, train loss <loss>=2.597248749299483\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] Epoch[324] Batch[0] avg_epoch_loss=2.736094\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=324, batch=0 train loss <loss>=2.7360939979553223\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] Epoch[324] Batch[5] avg_epoch_loss=2.587195\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] #quality_metric: host=algo-1, epoch=324, batch=5 train loss <loss>=2.5871949195861816\n",
      "[05/22/2025 05:08:19 INFO 140551403046720] Epoch[324] Batch [5]#011Speed: 2112.00 samples/sec#011loss=2.587195\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] Epoch[324] Batch[10] avg_epoch_loss=2.552293\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=324, batch=10 train loss <loss>=2.5104110717773436\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] Epoch[324] Batch [10]#011Speed: 1980.69 samples/sec#011loss=2.510411\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747890499.3673692, \"EndTime\": 1747890500.3038504, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.2344741821289, \"count\": 1, \"min\": 936.2344741821289, \"max\": 936.2344741821289}}}\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1453.5609306949248 records/second\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] #progress_metric: host=algo-1, completed 81.25 % of epochs\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=324, train loss <loss>=2.5522931705821645\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] Epoch[325] Batch[0] avg_epoch_loss=2.468880\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=325, batch=0 train loss <loss>=2.4688804149627686\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] Epoch[325] Batch[5] avg_epoch_loss=2.468803\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] #quality_metric: host=algo-1, epoch=325, batch=5 train loss <loss>=2.4688032468159995\n",
      "[05/22/2025 05:08:20 INFO 140551403046720] Epoch[325] Batch [5]#011Speed: 2133.18 samples/sec#011loss=2.468803\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] Epoch[325] Batch[10] avg_epoch_loss=2.543491\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=325, batch=10 train loss <loss>=2.633115863800049\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] Epoch[325] Batch [10]#011Speed: 2063.21 samples/sec#011loss=2.633116\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747890500.303908, \"EndTime\": 1747890501.224094, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.9354648590088, \"count\": 1, \"min\": 919.9354648590088, \"max\": 919.9354648590088}}}\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1447.7944503587084 records/second\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] #progress_metric: host=algo-1, completed 81.5 % of epochs\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=325, train loss <loss>=2.5434907999905674\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] Epoch[326] Batch[0] avg_epoch_loss=2.426524\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=326, batch=0 train loss <loss>=2.4265244007110596\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] Epoch[326] Batch[5] avg_epoch_loss=2.420400\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] #quality_metric: host=algo-1, epoch=326, batch=5 train loss <loss>=2.4203999042510986\n",
      "[05/22/2025 05:08:21 INFO 140551403046720] Epoch[326] Batch [5]#011Speed: 2128.53 samples/sec#011loss=2.420400\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] Epoch[326] Batch[10] avg_epoch_loss=2.470009\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=326, batch=10 train loss <loss>=2.529539108276367\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] Epoch[326] Batch [10]#011Speed: 2014.36 samples/sec#011loss=2.529539\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747890501.2241511, \"EndTime\": 1747890502.1559868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.5950870513916, \"count\": 1, \"min\": 931.5950870513916, \"max\": 931.5950870513916}}}\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1441.4762074996834 records/second\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] #progress_metric: host=algo-1, completed 81.75 % of epochs\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=326, train loss <loss>=2.4700086333534936\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] Epoch[327] Batch[0] avg_epoch_loss=2.511939\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=327, batch=0 train loss <loss>=2.5119385719299316\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] Epoch[327] Batch[5] avg_epoch_loss=2.460789\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] #quality_metric: host=algo-1, epoch=327, batch=5 train loss <loss>=2.4607894023259482\n",
      "[05/22/2025 05:08:22 INFO 140551403046720] Epoch[327] Batch [5]#011Speed: 2149.73 samples/sec#011loss=2.460789\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] Epoch[327] Batch[10] avg_epoch_loss=2.530676\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=327, batch=10 train loss <loss>=2.614539384841919\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] Epoch[327] Batch [10]#011Speed: 2061.30 samples/sec#011loss=2.614539\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747890502.1560462, \"EndTime\": 1747890503.0751996, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.8799858093262, \"count\": 1, \"min\": 918.8799858093262, \"max\": 918.8799858093262}}}\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1439.6618201120687 records/second\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] #progress_metric: host=algo-1, completed 82.0 % of epochs\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=327, train loss <loss>=2.530675758015026\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] Epoch[328] Batch[0] avg_epoch_loss=2.496366\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=328, batch=0 train loss <loss>=2.496366262435913\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] Epoch[328] Batch[5] avg_epoch_loss=2.470894\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] #quality_metric: host=algo-1, epoch=328, batch=5 train loss <loss>=2.4708938201268515\n",
      "[05/22/2025 05:08:23 INFO 140551403046720] Epoch[328] Batch [5]#011Speed: 2095.67 samples/sec#011loss=2.470894\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] Epoch[328] Batch[10] avg_epoch_loss=2.475026\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=328, batch=10 train loss <loss>=2.4799852848052977\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] Epoch[328] Batch [10]#011Speed: 2097.37 samples/sec#011loss=2.479985\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747890503.0752578, \"EndTime\": 1747890504.0033398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.8354644775391, \"count\": 1, \"min\": 927.8354644775391, \"max\": 927.8354644775391}}}\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1424.6886970588546 records/second\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #progress_metric: host=algo-1, completed 82.25 % of epochs\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=328, train loss <loss>=2.4750263040715996\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] Epoch[329] Batch[0] avg_epoch_loss=2.501371\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=329, batch=0 train loss <loss>=2.501370668411255\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] Epoch[329] Batch[5] avg_epoch_loss=2.500845\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=329, batch=5 train loss <loss>=2.5008449157079062\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] Epoch[329] Batch [5]#011Speed: 2074.17 samples/sec#011loss=2.500845\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] Epoch[329] Batch[10] avg_epoch_loss=2.703811\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=329, batch=10 train loss <loss>=2.947371006011963\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] Epoch[329] Batch [10]#011Speed: 2156.38 samples/sec#011loss=2.947371\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747890504.0033977, \"EndTime\": 1747890504.9417827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.1475448608398, \"count\": 1, \"min\": 938.1475448608398, \"max\": 938.1475448608398}}}\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #throughput_metric: host=algo-1, train throughput=1367.4663912738981 records/second\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #progress_metric: host=algo-1, completed 82.5 % of epochs\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #quality_metric: host=algo-1, epoch=329, train loss <loss>=2.7038113203915684\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] loss did not improve\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] Loading parameters from best epoch (289)\n",
      "#metrics {\"StartTime\": 1747890504.9418397, \"EndTime\": 1747890504.9477417, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 5.623102188110352, \"count\": 1, \"min\": 5.623102188110352, \"max\": 5.623102188110352}}}\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] stopping training now\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] Final loss: 2.4430271170356055 (occurred at epoch 289)\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] #quality_metric: host=algo-1, train final_loss <loss>=2.4430271170356055\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] Worker algo-1 finished training.\n",
      "[05/22/2025 05:08:24 WARNING 140551403046720] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/22/2025 05:08:24 INFO 140551403046720] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747890504.947793, \"EndTime\": 1747890505.0000463, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 51.76091194152832, \"count\": 1, \"min\": 51.76091194152832, \"max\": 51.76091194152832}}}\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747890505.000097, \"EndTime\": 1747890505.0240257, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 75.76560974121094, \"count\": 1, \"min\": 75.76560974121094, \"max\": 75.76560974121094}}}\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747890505.024073, \"EndTime\": 1747890505.0279672, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 3.8645267486572266, \"count\": 1, \"min\": 3.8645267486572266, \"max\": 3.8645267486572266}}}\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] Successfully serialized the model for prediction.\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #memory_usage::<batchbuffer> = 2.0458984375 mb\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] Evaluating model accuracy on testset using 100 samples\n",
      "#metrics {\"StartTime\": 1747890505.0280075, \"EndTime\": 1747890505.0296886, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.030517578125, \"count\": 1, \"min\": 0.030517578125, \"max\": 0.030517578125}}}\n",
      "#metrics {\"StartTime\": 1747890505.0297387, \"EndTime\": 1747890505.2351627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 205.50775527954102, \"count\": 1, \"min\": 205.50775527954102, \"max\": 205.50775527954102}}}\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, RMSE): 45.2166119343856\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, mean_absolute_QuantileLoss): 3676.2149209366908\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, mean_wQuantileLoss): 0.5628008145953293\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, wQuantileLoss[0.1]): 0.3467730562962861\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, wQuantileLoss[0.2]): 0.4434671181517005\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, wQuantileLoss[0.3]): 0.5155124673650663\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, wQuantileLoss[0.4]): 0.5719290366584512\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, wQuantileLoss[0.5]): 0.6104451197462438\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, wQuantileLoss[0.6]): 0.6405538374999514\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, wQuantileLoss[0.7]): 0.6568151015411908\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, wQuantileLoss[0.8]): 0.6549533593457533\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #test_score (algo-1, wQuantileLoss[0.9]): 0.6247582347533196\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #quality_metric: host=algo-1, test RMSE <loss>=45.2166119343856\n",
      "[05/22/2025 05:08:25 INFO 140551403046720] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.5628008145953293\n",
      "#metrics {\"StartTime\": 1747890505.2352276, \"EndTime\": 1747890505.244757, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 3.566265106201172, \"count\": 1, \"min\": 3.566265106201172, \"max\": 3.566265106201172}, \"totaltime\": {\"sum\": 304717.3511981964, \"count\": 1, \"min\": 304717.3511981964, \"max\": 304717.3511981964}}}\n",
      "\n",
      "2025-05-22 05:09:06 Uploading - Uploading generated training model\n",
      "2025-05-22 05:09:14 Completed - Training job completed\n",
      "Training seconds: 542\n",
      "Billable seconds: 542\n",
      "CPU times: total: 16.8 s\n",
      "Wall time: 10min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bade9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-22 05:09:14 Starting - Preparing the instances for training\n",
      "2025-05-22 05:09:14 Downloading - Downloading the training image\n",
      "2025-05-22 05:09:14 Training - Training image download completed. Training in progress.\n",
      "2025-05-22 05:09:14 Uploading - Uploading generated training model\n",
      "2025-05-22 05:09:14 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-22-04-59-33-931',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec135f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "62e6bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.Predictor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            # serializer=JSONSerializer(),\n",
    "            serializer=IdentitySerializer(content_type=\"application/json\"),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        ts,\n",
    "        cat=None,\n",
    "        dynamic_feat=None,\n",
    "        num_samples=100,\n",
    "        return_samples=False,\n",
    "        quantiles=[\"0.1\", \"0.5\", \"0.9\"],\n",
    "    ):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "\n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "\n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + ts.index.freq\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "\n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(\n",
    "            ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None\n",
    "        )\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles,\n",
    "        }\n",
    "\n",
    "        http_request_data = {\"instances\": [instance], \"configuration\": configuration}\n",
    "\n",
    "        return json.dumps(http_request_data).encode(\"utf-8\")\n",
    "\n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode(\"utf-8\"))[\"predictions\"][0]\n",
    "        prediction_length = len(next(iter(predictions[\"quantiles\"].values())))\n",
    "        prediction_index = pd.date_range(\n",
    "            start=prediction_time, freq=freq, periods=prediction_length\n",
    "        )\n",
    "        if return_samples:\n",
    "            dict_of_samples = {\"sample_\" + str(i): s for i, s in enumerate(predictions[\"samples\"])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(\n",
    "            data={**predictions[\"quantiles\"], **dict_of_samples}, index=prediction_index\n",
    "        )\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "\n",
    "\n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]\n",
    "\n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04c071b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/22/25 00:11:41] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-05-11-41-488 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/22/25 00:11:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-05-11-41-488 \u001b]8;id=757411;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=638720;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/22/25 00:11:42] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-05-11-41-488                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/22/25 00:11:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=51053;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=555250;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-05-11-41-488                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-05-11-41-488                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=756885;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=824566;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-05-11-41-488                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49cd1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_a_series(timeseries):\n",
    "    series_list = []\n",
    "    \n",
    "    for ts in timeseries:\n",
    "        # Verificar que la columna 'cantidad' existe\n",
    "        if 'cantidad' in ts.columns:\n",
    "            # Extraer la columna 'cantidad' como una serie\n",
    "            serie = ts['cantidad']\n",
    "\n",
    "            # Asegurarse de que el índice esté ordenado\n",
    "            serie = serie.sort_index()\n",
    "\n",
    "            # Intentar inferir la frecuencia del índice\n",
    "            try:\n",
    "                freq = pd.infer_freq(serie.index)\n",
    "                if freq is not None:\n",
    "                    serie.index.freq = freq\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo inferir frecuencia para una serie: {e}\")\n",
    "\n",
    "            series_list.append(serie)\n",
    "        else:\n",
    "            print(f\"Advertencia: Un dataframe no contiene la columna 'cantidad'\")\n",
    "    \n",
    "    return series_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6fce0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_list = convertir_a_series(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ef79e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_lista_features_dinamicas(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Crea una lista de listas con los vectores de 'month' y 'quarter' para cada dataframe.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con columnas 'month' y 'quarter'\n",
    "    \n",
    "    Returns:\n",
    "        Lista de listas donde cada elemento es [month_vector, quarter_vector] para un dataframe\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    lista_features = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Verificar que el dataframe tenga registros\n",
    "        if len(df) == 0:\n",
    "            print(f\"Advertencia: Dataframe {i} está vacío. Se añadirá una lista vacía.\")\n",
    "            lista_features.append([[], []])\n",
    "            continue\n",
    "        \n",
    "        # Verificar que existan las columnas necesarias\n",
    "        columnas_faltantes = []\n",
    "        if 'month' not in df.columns:\n",
    "            columnas_faltantes.append('month')\n",
    "        if 'quarter' not in df.columns:\n",
    "            columnas_faltantes.append('quarter')\n",
    "        \n",
    "        if columnas_faltantes:\n",
    "            # Si faltan columnas, intentar generarlas a partir del índice si es posible\n",
    "            df_temp = df.copy()\n",
    "                \n",
    "            # Generar columnas de fechas si el índice es de tipo datetime\n",
    "            if ('month' in columnas_faltantes or 'quarter' in columnas_faltantes) and isinstance(df_temp.index, pd.DatetimeIndex):\n",
    "                if 'month' not in df_temp.columns:\n",
    "                    df_temp['month'] = df_temp.index.month\n",
    "                if 'quarter' not in df_temp.columns:\n",
    "                    df_temp['quarter'] = df_temp.index.quarter\n",
    "                df = df_temp\n",
    "            elif 'month' in columnas_faltantes or 'quarter' in columnas_faltantes:\n",
    "                # Intentar convertir el índice a datetime si no lo es\n",
    "                try:\n",
    "                    df_temp.index = pd.to_datetime(df_temp.index)\n",
    "                    if 'month' not in df_temp.columns:\n",
    "                        df_temp['month'] = df_temp.index.month\n",
    "                    if 'quarter' not in df_temp.columns:\n",
    "                        df_temp['quarter'] = df_temp.index.quarter\n",
    "                    df = df_temp\n",
    "                except:\n",
    "                    print(f\"Error: No se pueden generar las columnas {columnas_faltantes} para el Dataframe {i}. Se añadirá una lista vacía.\")\n",
    "                    lista_features.append([[], []])\n",
    "                    continue\n",
    "        \n",
    "        # Crear los vectores de características dinámicas\n",
    "        month_vector = df['month'].tolist()\n",
    "        quarter_vector = df['quarter'].tolist()\n",
    "        \n",
    "        # Añadir los vectores a la lista\n",
    "        lista_features.append([month_vector, quarter_vector])\n",
    "        \n",
    "    return lista_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bf2f1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_list = crear_lista_features_dinamicas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1877063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-08-01</th>\n",
       "      <td>15.101313</td>\n",
       "      <td>29.300190</td>\n",
       "      <td>45.797787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-01</th>\n",
       "      <td>106.833649</td>\n",
       "      <td>110.023758</td>\n",
       "      <td>113.551270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-01</th>\n",
       "      <td>42.552490</td>\n",
       "      <td>48.929893</td>\n",
       "      <td>54.538902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01</th>\n",
       "      <td>57.626801</td>\n",
       "      <td>64.374611</td>\n",
       "      <td>72.074570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>37.824520</td>\n",
       "      <td>48.200249</td>\n",
       "      <td>58.112583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>37.360271</td>\n",
       "      <td>42.553612</td>\n",
       "      <td>48.575874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.1         0.5         0.9\n",
       "2023-08-01   15.101313   29.300190   45.797787\n",
       "2023-09-01  106.833649  110.023758  113.551270\n",
       "2023-10-01   42.552490   48.929893   54.538902\n",
       "2023-11-01   57.626801   64.374611   72.074570\n",
       "2023-12-01   37.824520   48.200249   58.112583\n",
       "2024-01-01   37.360271   42.553612   48.575874"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=20\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "75e29775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023-08-01    115.000000\n",
       "2023-09-01     65.885135\n",
       "2023-10-01     32.114865\n",
       "2023-11-01      6.000000\n",
       "2023-12-01     18.000000\n",
       "2024-01-01     45.000000\n",
       "Freq: MS, Name: cantidad, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[i].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9343aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_predicciones_por_material(materiales, timeseries_list, vectores_cat, dynamic_list, predictor, horizon_pred=6):\n",
    "    \"\"\"\n",
    "    Genera predicciones para cada material y las devuelve en un diccionario.\n",
    "    \n",
    "    Args:\n",
    "        materiales: Lista con los nombres de materiales\n",
    "        timeseries_list: Lista de series temporales\n",
    "        vectores_cat: Lista de vectores categóricos\n",
    "        dynamic_list: Lista de features dinámicas\n",
    "        predictor: Modelo predictor entrenado\n",
    "        horizon_pred: Horizonte de predicción (default: 6)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con materiales como keys y dataframes de predicciones como values\n",
    "    \"\"\"\n",
    "    predicciones_dict = {}\n",
    "    \n",
    "    for i in range(len(materiales)):\n",
    "        material = materiales[i]\n",
    "        \n",
    "        # Generar predicción para el índice i\n",
    "        prediccion = predictor.predict(\n",
    "            ts = timeseries_list[i][:-horizon_pred], \n",
    "            cat=vectores_cat[i],\n",
    "            dynamic_feat=dynamic_list[i],\n",
    "            quantiles=[0.1, 0.5, 0.9],\n",
    "        )\n",
    "        \n",
    "        # Guardar en el diccionario\n",
    "        predicciones_dict[material] = prediccion\n",
    "        \n",
    "    return predicciones_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a32feb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_por_material = generar_predicciones_por_material(\n",
    "    materiales=materiales,\n",
    "    timeseries_list=timeseries_list,\n",
    "    vectores_cat=vectores_cat,\n",
    "    dynamic_list=dynamic_list,\n",
    "    predictor=predictor,\n",
    "    horizon_pred=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "759c54af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado: mensual_modificado_test_27.xlsx\n",
      "Orden de columnas: ['Material', 'Fecha', '0.1', '0.5', '0.9']\n",
      "Formato de fecha: YYYY-MM-DD\n"
     ]
    }
   ],
   "source": [
    "def exportar_predicciones_consolidado(predicciones_dict, nombre_archivo=\"mensual_modificado_test_27.xlsx\"):\n",
    "    \"\"\"\n",
    "    Exporta todas las predicciones con Material y Fecha como primeras dos columnas.\n",
    "    \"\"\"\n",
    "    \n",
    "    dfs_list = []\n",
    "    \n",
    "    for material, prediccion in predicciones_dict.items():\n",
    "        try:\n",
    "            # Convertir a DataFrame\n",
    "            if hasattr(prediccion, 'to_dataframe'):\n",
    "                df_pred = prediccion.to_dataframe()\n",
    "            elif hasattr(prediccion, 'to_pandas'):\n",
    "                df_pred = prediccion.to_pandas()\n",
    "            else:\n",
    "                df_pred = prediccion\n",
    "            \n",
    "            # Resetear índice y renombrar a 'Fecha'\n",
    "            df_pred = df_pred.reset_index()\n",
    "            date_col = df_pred.columns[0]\n",
    "            df_pred = df_pred.rename(columns={date_col: 'Fecha'})\n",
    "            \n",
    "            # Formatear fechas\n",
    "            df_pred['Fecha'] = pd.to_datetime(df_pred['Fecha']).dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Agregar columna de material\n",
    "            df_pred['Material'] = material\n",
    "            \n",
    "            dfs_list.append(df_pred)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {material}: {e}\")\n",
    "    \n",
    "    # Concatenar todos los DataFrames\n",
    "    if dfs_list:\n",
    "        df_final = pd.concat(dfs_list, ignore_index=True)\n",
    "        \n",
    "        # Reorganizar columnas: Material, Fecha, luego el resto en orden\n",
    "        other_cols = [col for col in df_final.columns if col not in ['Material', 'Fecha']]\n",
    "        cols = ['Material', 'Fecha'] + other_cols\n",
    "        df_final = df_final[cols]\n",
    "        \n",
    "        # Exportar\n",
    "        df_final.to_excel(nombre_archivo, index=False)\n",
    "        print(f\"Archivo guardado: {nombre_archivo}\")\n",
    "        print(f\"Orden de columnas: {list(df_final.columns)}\")\n",
    "        print(\"Formato de fecha: YYYY-MM-DD\")\n",
    "    else:\n",
    "        print(\"Error: No se pudieron procesar las predicciones\")\n",
    "\n",
    "# Ejecutar\n",
    "exportar_predicciones_consolidado(predicciones_por_material, \"mensual_modificado_test_27.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c118dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03a9e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2DO ENTRENAMIENTO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "5649ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    #\"learning_rate\": \"1E-3\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "35de1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "df473ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 11:14:41] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 11:14:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=955046;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=565503;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-16-14-41-449                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=616357;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=837267;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-16-14-41-449                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 16:14:43 Starting - Starting the training job...\n",
      "2025-05-21 16:15:07 Starting - Preparing the instances for training...\n",
      "2025-05-21 16:15:42 Downloading - Downloading the training image.........\n",
      "2025-05-21 16:17:14 Training - Training image download completed. Training in progress..Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '18', 'early_stopping_patience': '40', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '18', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] Detected entry point for worker worker\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] Using early stopping with patience 40\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] random_seed is None\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 16:17:32 INFO 140328105305920] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] [cardinality=auto] Inferred value of cardinality=[2, 4, 5, 6, 6] from dataset.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Training set statistics:\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Real time series\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] number of time series: 15\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] number of observations: 582\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] mean target length: 38.8\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] min/mean/max target: 1.0/30.99656357388316/350.0\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] mean abs(target): 30.99656357388316\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] contains missing values: no\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Small number of time series. Doing 86 passes over dataset with prob 0.9922480620155039 per epoch.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Test set statistics:\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Real time series\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] number of time series: 15\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] number of observations: 672\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] mean target length: 44.8\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] min/mean/max target: 1.0/30.99702380952381/388.0\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] mean abs(target): 30.99702380952381\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] contains missing values: no\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] nvidia-smi: took 0.030 seconds to run.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] nvidia-smi identified 0 GPUs.\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Number of GPUs being used: 0\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Create Store: local\n",
      "#metrics {\"StartTime\": 1747844253.0371804, \"EndTime\": 1747844253.0848963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 46.84758186340332, \"count\": 1, \"min\": 46.84758186340332, \"max\": 46.84758186340332}}}\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Number of GPUs being used: 0\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] #memory_usage::<model> = 21 mb\n",
      "#metrics {\"StartTime\": 1747844253.0849526, \"EndTime\": 1747844253.1619067, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 124.61495399475098, \"count\": 1, \"min\": 124.61495399475098, \"max\": 124.61495399475098}}}\n",
      "[16:17:33] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 20480 bytes with malloc directly\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Epoch[0] Batch[0] avg_epoch_loss=3.753399\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.7533986568450928\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Epoch[0] Batch[5] avg_epoch_loss=3.480704\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.4807043075561523\n",
      "[05/21/2025 16:17:33 INFO 140328105305920] Epoch[0] Batch [5]#011Speed: 2142.82 samples/sec#011loss=3.480704\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Epoch[0] Batch[10] avg_epoch_loss=3.531558\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.592581605911255\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Epoch[0] Batch [10]#011Speed: 1646.05 samples/sec#011loss=3.592582\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747844253.1619542, \"EndTime\": 1747844254.2148647, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 1052.8380870819092, \"count\": 1, \"min\": 1052.8380870819092, \"max\": 1052.8380870819092}}}\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1284.0146092434939 records/second\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.53155762499029\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_32489641-7d98-4e34-b76f-b67d263fa726-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844254.2149394, \"EndTime\": 1747844254.2264044, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.989189147949219, \"count\": 1, \"min\": 10.989189147949219, \"max\": 10.989189147949219}}}\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Epoch[1] Batch[0] avg_epoch_loss=3.453705\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.453705310821533\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Epoch[1] Batch[5] avg_epoch_loss=3.405561\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.4055606524149575\n",
      "[05/21/2025 16:17:34 INFO 140328105305920] Epoch[1] Batch [5]#011Speed: 1620.66 samples/sec#011loss=3.405561\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Epoch[1] Batch[10] avg_epoch_loss=3.469333\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.5458587646484374\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Epoch[1] Batch [10]#011Speed: 2099.79 samples/sec#011loss=3.545859\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747844254.2264605, \"EndTime\": 1747844255.2667363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1040.226936340332, \"count\": 1, \"min\": 1040.226936340332, \"max\": 1040.226936340332}}}\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1254.4353253482227 records/second\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.469332521611994\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_d957fa88-a937-4bd9-8c90-9985fbaab718-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844255.2667916, \"EndTime\": 1747844255.2766502, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.553909301757812, \"count\": 1, \"min\": 9.553909301757812, \"max\": 9.553909301757812}}}\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Epoch[2] Batch[0] avg_epoch_loss=3.228668\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.228667736053467\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Epoch[2] Batch[5] avg_epoch_loss=3.315588\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.3155884742736816\n",
      "[05/21/2025 16:17:35 INFO 140328105305920] Epoch[2] Batch [5]#011Speed: 1917.09 samples/sec#011loss=3.315588\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Epoch[2] Batch[10] avg_epoch_loss=3.259377\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.191923427581787\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Epoch[2] Batch [10]#011Speed: 2040.38 samples/sec#011loss=3.191923\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747844255.2766993, \"EndTime\": 1747844256.2376146, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.8674049377441, \"count\": 1, \"min\": 960.8674049377441, \"max\": 960.8674049377441}}}\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1396.4686512812764 records/second\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.2593770894137295\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_e749dd0a-a603-49c2-a8b9-0a92a258295a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844256.2377155, \"EndTime\": 1747844256.2486606, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.623931884765625, \"count\": 1, \"min\": 10.623931884765625, \"max\": 10.623931884765625}}}\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Epoch[3] Batch[0] avg_epoch_loss=3.345333\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.3453330993652344\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Epoch[3] Batch[5] avg_epoch_loss=3.349148\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.349148074785868\n",
      "[05/21/2025 16:17:36 INFO 140328105305920] Epoch[3] Batch [5]#011Speed: 2197.29 samples/sec#011loss=3.349148\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] Epoch[3] Batch[10] avg_epoch_loss=3.345339\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=3.3407680988311768\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] Epoch[3] Batch [10]#011Speed: 2115.52 samples/sec#011loss=3.340768\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844256.2487144, \"EndTime\": 1747844257.1680331, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.2698001861572, \"count\": 1, \"min\": 919.2698001861572, \"max\": 919.2698001861572}}}\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1420.5671790578826 records/second\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.345338994806463\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] Epoch[4] Batch[0] avg_epoch_loss=3.389310\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.389310359954834\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] Epoch[4] Batch[5] avg_epoch_loss=3.340915\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.3409146467844644\n",
      "[05/21/2025 16:17:37 INFO 140328105305920] Epoch[4] Batch [5]#011Speed: 2204.75 samples/sec#011loss=3.340915\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] Epoch[4] Batch[10] avg_epoch_loss=3.358957\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.3806087493896486\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] Epoch[4] Batch [10]#011Speed: 2007.03 samples/sec#011loss=3.380609\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844257.168089, \"EndTime\": 1747844258.0983407, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.9900531768799, \"count\": 1, \"min\": 929.9900531768799, \"max\": 929.9900531768799}}}\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1432.1489177134067 records/second\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.3589574206959116\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] Epoch[5] Batch[0] avg_epoch_loss=3.347919\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.347919464111328\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] Epoch[5] Batch[5] avg_epoch_loss=3.294286\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.294285774230957\n",
      "[05/21/2025 16:17:38 INFO 140328105305920] Epoch[5] Batch [5]#011Speed: 2120.79 samples/sec#011loss=3.294286\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] Epoch[5] Batch[10] avg_epoch_loss=3.375697\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.4733904361724854\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] Epoch[5] Batch [10]#011Speed: 2140.90 samples/sec#011loss=3.473390\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747844258.0983953, \"EndTime\": 1747844259.0163932, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.7467823028564, \"count\": 1, \"min\": 917.7467823028564, \"max\": 917.7467823028564}}}\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1410.919454867321 records/second\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.375696984204379\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] Epoch[6] Batch[0] avg_epoch_loss=3.199827\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.199826717376709\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] Epoch[6] Batch[5] avg_epoch_loss=3.307880\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.30787984530131\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] Epoch[6] Batch [5]#011Speed: 2172.12 samples/sec#011loss=3.307880\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] processed a total of 1260 examples\n",
      "#metrics {\"StartTime\": 1747844259.0164587, \"EndTime\": 1747844259.8690226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 852.2608280181885, \"count\": 1, \"min\": 852.2608280181885, \"max\": 852.2608280181885}}}\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1478.2655630072704 records/second\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.2958977699279783\n",
      "[05/21/2025 16:17:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] Epoch[7] Batch[0] avg_epoch_loss=3.167600\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.16759991645813\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] Epoch[7] Batch[5] avg_epoch_loss=3.267885\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.2678849697113037\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] Epoch[7] Batch [5]#011Speed: 2170.09 samples/sec#011loss=3.267885\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] Epoch[7] Batch[10] avg_epoch_loss=3.329810\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.404119873046875\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] Epoch[7] Batch [10]#011Speed: 1947.30 samples/sec#011loss=3.404120\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747844259.86908, \"EndTime\": 1747844260.8129969, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.4936046600342, \"count\": 1, \"min\": 943.4936046600342, \"max\": 943.4936046600342}}}\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1444.5016660126596 records/second\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.3298099257729272\n",
      "[05/21/2025 16:17:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] Epoch[8] Batch[0] avg_epoch_loss=3.164814\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.164813756942749\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] Epoch[8] Batch[5] avg_epoch_loss=3.314466\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.314465800921122\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] Epoch[8] Batch [5]#011Speed: 2220.42 samples/sec#011loss=3.314466\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] Epoch[8] Batch[10] avg_epoch_loss=3.272942\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.2231131076812742\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] Epoch[8] Batch [10]#011Speed: 2134.84 samples/sec#011loss=3.223113\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747844260.813053, \"EndTime\": 1747844261.71966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.360387802124, \"count\": 1, \"min\": 906.360387802124, \"max\": 906.360387802124}}}\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1487.1341108937631 records/second\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.2729418494484643\n",
      "[05/21/2025 16:17:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[9] Batch[0] avg_epoch_loss=3.373947\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.3739466667175293\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[9] Batch[5] avg_epoch_loss=3.263353\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.2633527517318726\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[9] Batch [5]#011Speed: 2128.92 samples/sec#011loss=3.263353\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[9] Batch[10] avg_epoch_loss=3.230842\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.1918297290802\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[9] Batch [10]#011Speed: 2171.15 samples/sec#011loss=3.191830\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747844261.7197149, \"EndTime\": 1747844262.6345532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.588212966919, \"count\": 1, \"min\": 914.588212966919, \"max\": 914.588212966919}}}\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1439.8616956638357 records/second\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.230842286890203\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_ecfb3c07-894c-4587-88b2-31c6a6c8e4a5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844262.6346083, \"EndTime\": 1747844262.6457222, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.839223861694336, \"count\": 1, \"min\": 10.839223861694336, \"max\": 10.839223861694336}}}\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] Epoch[10] Batch[0] avg_epoch_loss=3.329922\n",
      "[05/21/2025 16:17:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.3299219608306885\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] Epoch[10] Batch[5] avg_epoch_loss=3.250695\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.250694910685221\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] Epoch[10] Batch [5]#011Speed: 2206.27 samples/sec#011loss=3.250695\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] Epoch[10] Batch[10] avg_epoch_loss=3.276585\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.3076525688171388\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] Epoch[10] Batch [10]#011Speed: 2103.78 samples/sec#011loss=3.307653\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844262.6457717, \"EndTime\": 1747844263.554626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.8096618652344, \"count\": 1, \"min\": 908.8096618652344, \"max\": 908.8096618652344}}}\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1465.520790919815 records/second\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.276584755290638\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] Epoch[11] Batch[0] avg_epoch_loss=3.217952\n",
      "[05/21/2025 16:17:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.2179524898529053\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] Epoch[11] Batch[5] avg_epoch_loss=3.203618\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.2036184867223105\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] Epoch[11] Batch [5]#011Speed: 2188.44 samples/sec#011loss=3.203618\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] Epoch[11] Batch[10] avg_epoch_loss=3.252336\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=3.3107959747314455\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] Epoch[11] Batch [10]#011Speed: 2119.72 samples/sec#011loss=3.310796\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747844263.5546827, \"EndTime\": 1747844264.4799447, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0068664550781, \"count\": 1, \"min\": 925.0068664550781, \"max\": 925.0068664550781}}}\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1403.10805815822 records/second\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.2523355267264624\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] Epoch[12] Batch[0] avg_epoch_loss=3.270044\n",
      "[05/21/2025 16:17:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.2700438499450684\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Epoch[12] Batch[5] avg_epoch_loss=3.190872\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.1908716758092246\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Epoch[12] Batch [5]#011Speed: 2144.94 samples/sec#011loss=3.190872\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Epoch[12] Batch[10] avg_epoch_loss=3.196439\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=3.203120708465576\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Epoch[12] Batch [10]#011Speed: 2101.90 samples/sec#011loss=3.203121\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] processed a total of 1370 examples\n",
      "#metrics {\"StartTime\": 1747844264.4799998, \"EndTime\": 1747844265.409565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.316520690918, \"count\": 1, \"min\": 929.316520690918, \"max\": 929.316520690918}}}\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1474.0704784767672 records/second\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.196439417925748\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_5c4bace2-86df-4f13-8242-162d7386c8b4-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844265.4096203, \"EndTime\": 1747844265.4200537, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.080575942993164, \"count\": 1, \"min\": 10.080575942993164, \"max\": 10.080575942993164}}}\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] Epoch[13] Batch[0] avg_epoch_loss=3.073098\n",
      "[05/21/2025 16:17:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.0730981826782227\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[13] Batch[5] avg_epoch_loss=3.160310\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.160310427347819\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[13] Batch [5]#011Speed: 2144.62 samples/sec#011loss=3.160310\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[13] Batch[10] avg_epoch_loss=3.163378\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.16705904006958\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[13] Batch [10]#011Speed: 2057.72 samples/sec#011loss=3.167059\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747844265.4201076, \"EndTime\": 1747844266.351987, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.833028793335, \"count\": 1, \"min\": 931.833028793335, \"max\": 931.833028793335}}}\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.4543630666865 records/second\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.163377978584983\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_8605e18c-d459-408d-bf82-76d286e50f60-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844266.352045, \"EndTime\": 1747844266.362412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.054349899291992, \"count\": 1, \"min\": 10.054349899291992, \"max\": 10.054349899291992}}}\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[14] Batch[0] avg_epoch_loss=3.139221\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.139221429824829\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[14] Batch[5] avg_epoch_loss=3.162249\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.1622488101323447\n",
      "[05/21/2025 16:17:46 INFO 140328105305920] Epoch[14] Batch [5]#011Speed: 2160.95 samples/sec#011loss=3.162249\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Epoch[14] Batch[10] avg_epoch_loss=3.142185\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=3.1181085109710693\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Epoch[14] Batch [10]#011Speed: 2036.34 samples/sec#011loss=3.118109\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747844266.3624659, \"EndTime\": 1747844267.2898984, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.3824691772461, \"count\": 1, \"min\": 927.3824691772461, \"max\": 927.3824691772461}}}\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1464.2088912184713 records/second\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.1421850377863105\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_abc21b79-a4e7-4ea9-91d6-18b999f8b01a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844267.289952, \"EndTime\": 1747844267.3002884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.00070571899414, \"count\": 1, \"min\": 10.00070571899414, \"max\": 10.00070571899414}}}\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Epoch[15] Batch[0] avg_epoch_loss=3.169248\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.169248104095459\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Epoch[15] Batch[5] avg_epoch_loss=3.116711\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=3.116711378097534\n",
      "[05/21/2025 16:17:47 INFO 140328105305920] Epoch[15] Batch [5]#011Speed: 2217.56 samples/sec#011loss=3.116711\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] processed a total of 1259 examples\n",
      "#metrics {\"StartTime\": 1747844267.300335, \"EndTime\": 1747844268.1467736, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 846.3881015777588, \"count\": 1, \"min\": 846.3881015777588, \"max\": 846.3881015777588}}}\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1487.3389115045768 records/second\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=15, train loss <loss>=3.1053293466567995\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_d5ceac36-4ee2-406d-ad81-49bb35e6e8d6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844268.1468332, \"EndTime\": 1747844268.1579049, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.759353637695312, \"count\": 1, \"min\": 10.759353637695312, \"max\": 10.759353637695312}}}\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] Epoch[16] Batch[0] avg_epoch_loss=3.217985\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.217984676361084\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] Epoch[16] Batch[5] avg_epoch_loss=3.117103\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=3.11710254351298\n",
      "[05/21/2025 16:17:48 INFO 140328105305920] Epoch[16] Batch [5]#011Speed: 2237.47 samples/sec#011loss=3.117103\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[16] Batch[10] avg_epoch_loss=3.153348\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=3.196842002868652\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[16] Batch [10]#011Speed: 2210.40 samples/sec#011loss=3.196842\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844268.157954, \"EndTime\": 1747844269.0491135, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 891.1130428314209, \"count\": 1, \"min\": 891.1130428314209, \"max\": 891.1130428314209}}}\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1468.821713871122 records/second\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.153347752311013\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[17] Batch[0] avg_epoch_loss=3.112368\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.112367630004883\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[17] Batch[5] avg_epoch_loss=3.113505\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.1135048866271973\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[17] Batch [5]#011Speed: 2242.53 samples/sec#011loss=3.113505\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[17] Batch[10] avg_epoch_loss=3.097730\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.0788010120391847\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Epoch[17] Batch [10]#011Speed: 2062.55 samples/sec#011loss=3.078801\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747844269.0491657, \"EndTime\": 1747844269.9520032, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 902.5955200195312, \"count\": 1, \"min\": 902.5955200195312, \"max\": 902.5955200195312}}}\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1499.9858999802964 records/second\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.0977303981781006\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:49 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_ea097a88-b8e7-4e04-9866-7cd88b4b926e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844269.9520574, \"EndTime\": 1747844269.9624069, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.07390022277832, \"count\": 1, \"min\": 10.07390022277832, \"max\": 10.07390022277832}}}\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Epoch[18] Batch[0] avg_epoch_loss=3.184320\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.1843199729919434\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Epoch[18] Batch[5] avg_epoch_loss=3.148649\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.1486487785975137\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Epoch[18] Batch [5]#011Speed: 2036.66 samples/sec#011loss=3.148649\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Epoch[18] Batch[10] avg_epoch_loss=3.090709\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.0211817264556884\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Epoch[18] Batch [10]#011Speed: 2124.10 samples/sec#011loss=3.021182\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844269.9624584, \"EndTime\": 1747844270.8969254, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.4191551208496, \"count\": 1, \"min\": 934.4191551208496, \"max\": 934.4191551208496}}}\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.8698273462533 records/second\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.0907092094421387\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:50 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_8452d9a9-66d4-4e61-97e4-df1b23365845-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844270.8969786, \"EndTime\": 1747844270.9069178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.594202041625977, \"count\": 1, \"min\": 9.594202041625977, \"max\": 9.594202041625977}}}\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Epoch[19] Batch[0] avg_epoch_loss=3.114054\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.1140542030334473\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Epoch[19] Batch[5] avg_epoch_loss=3.061827\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=3.061826785405477\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Epoch[19] Batch [5]#011Speed: 2014.87 samples/sec#011loss=3.061827\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Epoch[19] Batch[10] avg_epoch_loss=2.947856\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=2.811090612411499\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Epoch[19] Batch [10]#011Speed: 2205.20 samples/sec#011loss=2.811091\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747844270.906967, \"EndTime\": 1747844271.8365998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.5847415924072, \"count\": 1, \"min\": 929.5847415924072, \"max\": 929.5847415924072}}}\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1384.3656011872872 records/second\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.9478557976809414\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:51 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_35c9deb2-fcfd-42bd-89e7-d2f3f0591133-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844271.8366563, \"EndTime\": 1747844271.8474627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.543346405029297, \"count\": 1, \"min\": 10.543346405029297, \"max\": 10.543346405029297}}}\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] Epoch[20] Batch[0] avg_epoch_loss=3.163296\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.1632955074310303\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] Epoch[20] Batch[5] avg_epoch_loss=3.118913\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=3.118913014729818\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] Epoch[20] Batch [5]#011Speed: 2166.64 samples/sec#011loss=3.118913\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747844271.847512, \"EndTime\": 1747844272.700904, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 853.3427715301514, \"count\": 1, \"min\": 853.3427715301514, \"max\": 853.3427715301514}}}\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1484.600708974373 records/second\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.100708508491516\n",
      "[05/21/2025 16:17:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[21] Batch[0] avg_epoch_loss=2.935093\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=2.9350931644439697\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[21] Batch[5] avg_epoch_loss=3.021580\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.0215804179509482\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[21] Batch [5]#011Speed: 2193.26 samples/sec#011loss=3.021580\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[21] Batch[10] avg_epoch_loss=2.987009\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=2.945522499084473\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[21] Batch [10]#011Speed: 1986.14 samples/sec#011loss=2.945522\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747844272.7009604, \"EndTime\": 1747844273.6295998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.3497333526611, \"count\": 1, \"min\": 928.3497333526611, \"max\": 928.3497333526611}}}\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1471.297863500051 records/second\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=21, train loss <loss>=2.987008636648005\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] Epoch[22] Batch[0] avg_epoch_loss=2.996017\n",
      "[05/21/2025 16:17:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.99601674079895\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] Epoch[22] Batch[5] avg_epoch_loss=2.980684\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.980684280395508\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] Epoch[22] Batch [5]#011Speed: 2179.83 samples/sec#011loss=2.980684\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] Epoch[22] Batch[10] avg_epoch_loss=2.983089\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=2.985973596572876\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] Epoch[22] Batch [10]#011Speed: 2107.98 samples/sec#011loss=2.985974\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844273.6296537, \"EndTime\": 1747844274.5464482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.5475368499756, \"count\": 1, \"min\": 916.5475368499756, \"max\": 916.5475368499756}}}\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.7857003330107 records/second\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.9830885150215845\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] Epoch[23] Batch[0] avg_epoch_loss=2.899899\n",
      "[05/21/2025 16:17:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.8998990058898926\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] Epoch[23] Batch[5] avg_epoch_loss=2.992970\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.992969512939453\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] Epoch[23] Batch [5]#011Speed: 2118.09 samples/sec#011loss=2.992970\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] Epoch[23] Batch[10] avg_epoch_loss=3.105073\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=3.2395971775054933\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] Epoch[23] Batch [10]#011Speed: 2162.33 samples/sec#011loss=3.239597\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844274.546503, \"EndTime\": 1747844275.4611733, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.4232273101807, \"count\": 1, \"min\": 914.4232273101807, \"max\": 914.4232273101807}}}\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1448.8066502549739 records/second\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=23, train loss <loss>=3.105072996833108\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] Epoch[24] Batch[0] avg_epoch_loss=2.964596\n",
      "[05/21/2025 16:17:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.9645955562591553\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Epoch[24] Batch[5] avg_epoch_loss=2.960554\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.9605544010798135\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Epoch[24] Batch [5]#011Speed: 2036.40 samples/sec#011loss=2.960554\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Epoch[24] Batch[10] avg_epoch_loss=2.880204\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.7837835788726806\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Epoch[24] Batch [10]#011Speed: 2159.45 samples/sec#011loss=2.783784\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844275.461268, \"EndTime\": 1747844276.3956757, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.0171813964844, \"count\": 1, \"min\": 934.0171813964844, \"max\": 934.0171813964844}}}\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1388.5010139352607 records/second\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.880204027349299\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_dee121b8-9412-4977-9fb5-6e2e8d35b655-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844276.3957314, \"EndTime\": 1747844276.4063368, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.312080383300781, \"count\": 1, \"min\": 10.312080383300781, \"max\": 10.312080383300781}}}\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] Epoch[25] Batch[0] avg_epoch_loss=3.030883\n",
      "[05/21/2025 16:17:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=3.030883312225342\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[25] Batch[5] avg_epoch_loss=3.008580\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=3.008580048878988\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[25] Batch [5]#011Speed: 2171.95 samples/sec#011loss=3.008580\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[25] Batch[10] avg_epoch_loss=2.971188\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=2.9263179302215576\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[25] Batch [10]#011Speed: 2112.26 samples/sec#011loss=2.926318\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844276.4063852, \"EndTime\": 1747844277.3182383, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.8070602416992, \"count\": 1, \"min\": 911.8070602416992, \"max\": 911.8070602416992}}}\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1470.5201560624532 records/second\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.971188176761974\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[26] Batch[0] avg_epoch_loss=3.111129\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=3.111128807067871\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[26] Batch[5] avg_epoch_loss=2.981121\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.981120983759562\n",
      "[05/21/2025 16:17:57 INFO 140328105305920] Epoch[26] Batch [5]#011Speed: 2199.01 samples/sec#011loss=2.981121\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] Epoch[26] Batch[10] avg_epoch_loss=3.003871\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=3.0311717987060547\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] Epoch[26] Batch [10]#011Speed: 1942.88 samples/sec#011loss=3.031172\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] processed a total of 1362 examples\n",
      "#metrics {\"StartTime\": 1747844277.318327, \"EndTime\": 1747844278.255448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.859130859375, \"count\": 1, \"min\": 936.859130859375, \"max\": 936.859130859375}}}\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1453.6036637280642 records/second\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=26, train loss <loss>=3.003871354189786\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] Epoch[27] Batch[0] avg_epoch_loss=2.948818\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.9488184452056885\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] Epoch[27] Batch[5] avg_epoch_loss=2.965740\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.9657403230667114\n",
      "[05/21/2025 16:17:58 INFO 140328105305920] Epoch[27] Batch [5]#011Speed: 2086.11 samples/sec#011loss=2.965740\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] Epoch[27] Batch[10] avg_epoch_loss=2.962515\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.958644247055054\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] Epoch[27] Batch [10]#011Speed: 2006.96 samples/sec#011loss=2.958644\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] processed a total of 1414 examples\n",
      "#metrics {\"StartTime\": 1747844278.2555425, \"EndTime\": 1747844279.2467356, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 990.9274578094482, \"count\": 1, \"min\": 990.9274578094482, \"max\": 990.9274578094482}}}\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1426.8176359426218 records/second\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=27, train loss <loss>=3.021000564098358\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] Epoch[28] Batch[0] avg_epoch_loss=2.988422\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.988421678543091\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] Epoch[28] Batch[5] avg_epoch_loss=2.986384\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.98638379573822\n",
      "[05/21/2025 16:17:59 INFO 140328105305920] Epoch[28] Batch [5]#011Speed: 2186.66 samples/sec#011loss=2.986384\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] Epoch[28] Batch[10] avg_epoch_loss=3.041811\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=3.108324432373047\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] Epoch[28] Batch [10]#011Speed: 2004.06 samples/sec#011loss=3.108324\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844279.246796, \"EndTime\": 1747844280.1759396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.8535118103027, \"count\": 1, \"min\": 928.8535118103027, \"max\": 928.8535118103027}}}\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.9066062014258 records/second\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=28, train loss <loss>=3.0418113578449595\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] Epoch[29] Batch[0] avg_epoch_loss=2.941563\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.941563129425049\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] Epoch[29] Batch[5] avg_epoch_loss=2.964945\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.9649451971054077\n",
      "[05/21/2025 16:18:00 INFO 140328105305920] Epoch[29] Batch [5]#011Speed: 2060.59 samples/sec#011loss=2.964945\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] Epoch[29] Batch[10] avg_epoch_loss=3.016815\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=3.0790579319000244\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] Epoch[29] Batch [10]#011Speed: 2033.88 samples/sec#011loss=3.079058\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844280.1759942, \"EndTime\": 1747844281.1197906, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.5365200042725, \"count\": 1, \"min\": 943.5365200042725, \"max\": 943.5365200042725}}}\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.5809422359312 records/second\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=29, train loss <loss>=3.0168146220120517\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] Epoch[30] Batch[0] avg_epoch_loss=2.934904\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.934903860092163\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] Epoch[30] Batch[5] avg_epoch_loss=2.976976\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.97697647412618\n",
      "[05/21/2025 16:18:01 INFO 140328105305920] Epoch[30] Batch [5]#011Speed: 2182.44 samples/sec#011loss=2.976976\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] Epoch[30] Batch[10] avg_epoch_loss=3.016997\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=3.0650208950042725\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] Epoch[30] Batch [10]#011Speed: 1740.07 samples/sec#011loss=3.065021\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844281.1198483, \"EndTime\": 1747844282.1040366, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 983.9351177215576, \"count\": 1, \"min\": 983.9351177215576, \"max\": 983.9351177215576}}}\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1346.5189856549384 records/second\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=30, train loss <loss>=3.016996665434404\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] Epoch[31] Batch[0] avg_epoch_loss=2.910988\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.910987615585327\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] Epoch[31] Batch[5] avg_epoch_loss=2.948782\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.9487820068995156\n",
      "[05/21/2025 16:18:02 INFO 140328105305920] Epoch[31] Batch [5]#011Speed: 2024.63 samples/sec#011loss=2.948782\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Epoch[31] Batch[10] avg_epoch_loss=2.858777\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=2.7507699489593507\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Epoch[31] Batch [10]#011Speed: 2024.51 samples/sec#011loss=2.750770\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747844282.104092, \"EndTime\": 1747844283.0586572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.277515411377, \"count\": 1, \"min\": 954.277515411377, \"max\": 954.277515411377}}}\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.4188261375398 records/second\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.8587765260176226\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_85b62897-3f8d-4e7b-b1e3-380f4bb1a5d2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844283.058712, \"EndTime\": 1747844283.0696557, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.644197463989258, \"count\": 1, \"min\": 10.644197463989258, \"max\": 10.644197463989258}}}\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Epoch[32] Batch[0] avg_epoch_loss=2.839033\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.8390326499938965\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Epoch[32] Batch[5] avg_epoch_loss=2.938138\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.9381381273269653\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] Epoch[32] Batch [5]#011Speed: 2121.92 samples/sec#011loss=2.938138\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747844283.0697029, \"EndTime\": 1747844283.9271212, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 857.367992401123, \"count\": 1, \"min\": 857.367992401123, \"max\": 857.367992401123}}}\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1491.5964823500233 records/second\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.91433470249176\n",
      "[05/21/2025 16:18:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] Epoch[33] Batch[0] avg_epoch_loss=3.030623\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=3.030623197555542\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] Epoch[33] Batch[5] avg_epoch_loss=2.898388\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.8983875513076782\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] Epoch[33] Batch [5]#011Speed: 2192.53 samples/sec#011loss=2.898388\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] processed a total of 1238 examples\n",
      "#metrics {\"StartTime\": 1747844283.9271946, \"EndTime\": 1747844284.7919815, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.4335269927979, \"count\": 1, \"min\": 864.4335269927979, \"max\": 864.4335269927979}}}\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.9491568331673 records/second\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.867684030532837\n",
      "[05/21/2025 16:18:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] Epoch[34] Batch[0] avg_epoch_loss=2.841973\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.841973066329956\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] Epoch[34] Batch[5] avg_epoch_loss=2.856923\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.8569226264953613\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] Epoch[34] Batch [5]#011Speed: 2144.03 samples/sec#011loss=2.856923\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] Epoch[34] Batch[10] avg_epoch_loss=2.895933\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=2.942746114730835\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] Epoch[34] Batch [10]#011Speed: 1978.23 samples/sec#011loss=2.942746\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747844284.79206, \"EndTime\": 1747844285.7327156, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.3445720672607, \"count\": 1, \"min\": 940.3445720672607, \"max\": 940.3445720672607}}}\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1445.089973917664 records/second\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.8959333029660312\n",
      "[05/21/2025 16:18:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[35] Batch[0] avg_epoch_loss=2.833843\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.8338427543640137\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[35] Batch[5] avg_epoch_loss=2.860663\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.860662857691447\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[35] Batch [5]#011Speed: 2165.84 samples/sec#011loss=2.860663\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[35] Batch[10] avg_epoch_loss=2.873239\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=2.8883305549621583\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[35] Batch [10]#011Speed: 1926.19 samples/sec#011loss=2.888331\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] processed a total of 1394 examples\n",
      "#metrics {\"StartTime\": 1747844285.7327695, \"EndTime\": 1747844286.6718035, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.788890838623, \"count\": 1, \"min\": 938.788890838623, \"max\": 938.788890838623}}}\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1484.763672875889 records/second\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.8732390837235884\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] Epoch[36] Batch[0] avg_epoch_loss=2.771353\n",
      "[05/21/2025 16:18:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.771352767944336\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Epoch[36] Batch[5] avg_epoch_loss=2.798503\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.7985031604766846\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Epoch[36] Batch [5]#011Speed: 2181.99 samples/sec#011loss=2.798503\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Epoch[36] Batch[10] avg_epoch_loss=2.839319\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.888297986984253\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Epoch[36] Batch [10]#011Speed: 2064.69 samples/sec#011loss=2.888298\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844286.671858, \"EndTime\": 1747844287.59631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.2115020751953, \"count\": 1, \"min\": 924.2115020751953, \"max\": 924.2115020751953}}}\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1441.1017763521907 records/second\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.8393189907073975\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_f27338cd-e0b5-4936-9bd7-958f1f0c97a7-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844287.5963647, \"EndTime\": 1747844287.607496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.868549346923828, \"count\": 1, \"min\": 10.868549346923828, \"max\": 10.868549346923828}}}\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] Epoch[37] Batch[0] avg_epoch_loss=2.820853\n",
      "[05/21/2025 16:18:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.8208532333374023\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] Epoch[37] Batch[5] avg_epoch_loss=2.853956\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.8539563020070395\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] Epoch[37] Batch [5]#011Speed: 2125.59 samples/sec#011loss=2.853956\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747844287.607544, \"EndTime\": 1747844288.4722607, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.6693229675293, \"count\": 1, \"min\": 864.6693229675293, \"max\": 864.6693229675293}}}\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.0881199032383 records/second\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.864393162727356\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] Epoch[38] Batch[0] avg_epoch_loss=2.743274\n",
      "[05/21/2025 16:18:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.743273973464966\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Epoch[38] Batch[5] avg_epoch_loss=2.801143\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.801142772038778\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Epoch[38] Batch [5]#011Speed: 2161.15 samples/sec#011loss=2.801143\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Epoch[38] Batch[10] avg_epoch_loss=2.832631\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=2.870417070388794\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Epoch[38] Batch [10]#011Speed: 1936.94 samples/sec#011loss=2.870417\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747844288.47232, \"EndTime\": 1747844289.415446, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.7917003631592, \"count\": 1, \"min\": 942.7917003631592, \"max\": 942.7917003631592}}}\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.6729235319226 records/second\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.832631089470603\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_312f3c90-ab97-4e50-9685-1a38bc752735-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844289.4155016, \"EndTime\": 1747844289.4263535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.589361190795898, \"count\": 1, \"min\": 10.589361190795898, \"max\": 10.589361190795898}}}\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] Epoch[39] Batch[0] avg_epoch_loss=2.722493\n",
      "[05/21/2025 16:18:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.7224926948547363\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[39] Batch[5] avg_epoch_loss=2.769656\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.7696563005447388\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[39] Batch [5]#011Speed: 2114.36 samples/sec#011loss=2.769656\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[39] Batch[10] avg_epoch_loss=2.848568\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=2.9432626247406004\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[39] Batch [10]#011Speed: 1969.16 samples/sec#011loss=2.943263\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747844289.4264016, \"EndTime\": 1747844290.3708978, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.4520473480225, \"count\": 1, \"min\": 944.4520473480225, \"max\": 944.4520473480225}}}\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1401.752524576856 records/second\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.8485682660883125\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[40] Batch[0] avg_epoch_loss=2.939894\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.939893960952759\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[40] Batch[5] avg_epoch_loss=2.848230\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.848229924837748\n",
      "[05/21/2025 16:18:10 INFO 140328105305920] Epoch[40] Batch [5]#011Speed: 2142.29 samples/sec#011loss=2.848230\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] Epoch[40] Batch[10] avg_epoch_loss=2.862678\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=2.8800151348114014\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] Epoch[40] Batch [10]#011Speed: 2106.50 samples/sec#011loss=2.880015\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844290.3709524, \"EndTime\": 1747844291.2942414, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.0482578277588, \"count\": 1, \"min\": 923.0482578277588, \"max\": 923.0482578277588}}}\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.7482329070822 records/second\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.862677747553045\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] Epoch[41] Batch[0] avg_epoch_loss=2.792788\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.792787551879883\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] Epoch[41] Batch[5] avg_epoch_loss=2.884656\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.884656389554342\n",
      "[05/21/2025 16:18:11 INFO 140328105305920] Epoch[41] Batch [5]#011Speed: 1993.05 samples/sec#011loss=2.884656\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747844291.2942986, \"EndTime\": 1747844292.1884685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 893.9125537872314, \"count\": 1, \"min\": 893.9125537872314, \"max\": 893.9125537872314}}}\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.292598972347 records/second\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.877144384384155\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] Epoch[42] Batch[0] avg_epoch_loss=2.643600\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.6435999870300293\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] Epoch[42] Batch[5] avg_epoch_loss=2.825771\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.825770934422811\n",
      "[05/21/2025 16:18:12 INFO 140328105305920] Epoch[42] Batch [5]#011Speed: 2214.89 samples/sec#011loss=2.825771\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Epoch[42] Batch[10] avg_epoch_loss=2.801968\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.7734045028686523\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Epoch[42] Batch [10]#011Speed: 2088.14 samples/sec#011loss=2.773405\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747844292.1885285, \"EndTime\": 1747844293.0989609, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.1457595825195, \"count\": 1, \"min\": 910.1457595825195, \"max\": 910.1457595825195}}}\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.3829561414584 records/second\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.8019680109891025\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_220d0423-291b-4ab7-8a25-e1128972764a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844293.099017, \"EndTime\": 1747844293.1100094, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.73002815246582, \"count\": 1, \"min\": 10.73002815246582, \"max\": 10.73002815246582}}}\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Epoch[43] Batch[0] avg_epoch_loss=2.818613\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.818612813949585\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Epoch[43] Batch[5] avg_epoch_loss=2.813760\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.813759724299113\n",
      "[05/21/2025 16:18:13 INFO 140328105305920] Epoch[43] Batch [5]#011Speed: 2176.38 samples/sec#011loss=2.813760\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[43] Batch[10] avg_epoch_loss=2.745500\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.663588523864746\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[43] Batch [10]#011Speed: 2162.13 samples/sec#011loss=2.663589\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747844293.1100607, \"EndTime\": 1747844294.0208051, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.698652267456, \"count\": 1, \"min\": 910.698652267456, \"max\": 910.698652267456}}}\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.0311518430824 records/second\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.745500087738037\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_80482ca4-146c-441a-bd71-be04ce65fa0d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844294.0208619, \"EndTime\": 1747844294.0318751, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.746479034423828, \"count\": 1, \"min\": 10.746479034423828, \"max\": 10.746479034423828}}}\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[44] Batch[0] avg_epoch_loss=2.871888\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.8718881607055664\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[44] Batch[5] avg_epoch_loss=2.798786\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.7987858057022095\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[44] Batch [5]#011Speed: 2163.97 samples/sec#011loss=2.798786\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[44] Batch[10] avg_epoch_loss=2.790603\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=2.780783987045288\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] Epoch[44] Batch [10]#011Speed: 1997.45 samples/sec#011loss=2.780784\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747844294.0319307, \"EndTime\": 1747844294.9648702, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.8882694244385, \"count\": 1, \"min\": 932.8882694244385, \"max\": 932.8882694244385}}}\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1477.0087576594383 records/second\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.7906031608581543\n",
      "[05/21/2025 16:18:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] Epoch[45] Batch[0] avg_epoch_loss=2.881600\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.8815999031066895\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] Epoch[45] Batch[5] avg_epoch_loss=2.765190\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.7651896874109902\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] Epoch[45] Batch [5]#011Speed: 2157.05 samples/sec#011loss=2.765190\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] Epoch[45] Batch[10] avg_epoch_loss=2.778004\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=2.793380546569824\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] Epoch[45] Batch [10]#011Speed: 2052.61 samples/sec#011loss=2.793381\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] processed a total of 1362 examples\n",
      "#metrics {\"StartTime\": 1747844294.964921, \"EndTime\": 1747844295.8931549, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.9413223266602, \"count\": 1, \"min\": 927.9413223266602, \"max\": 927.9413223266602}}}\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1467.6366353073379 records/second\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.7780037143013696\n",
      "[05/21/2025 16:18:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] Epoch[46] Batch[0] avg_epoch_loss=2.587780\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.5877797603607178\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] Epoch[46] Batch[5] avg_epoch_loss=2.798245\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.798245429992676\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] Epoch[46] Batch [5]#011Speed: 2155.61 samples/sec#011loss=2.798245\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] Epoch[46] Batch[10] avg_epoch_loss=2.762800\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.720265817642212\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] Epoch[46] Batch [10]#011Speed: 2143.42 samples/sec#011loss=2.720266\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747844295.8932104, \"EndTime\": 1747844296.8124318, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.9565181732178, \"count\": 1, \"min\": 918.9565181732178, \"max\": 918.9565181732178}}}\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1393.846528849873 records/second\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.7628001516515557\n",
      "[05/21/2025 16:18:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] Epoch[47] Batch[0] avg_epoch_loss=2.715326\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.7153263092041016\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] Epoch[47] Batch[5] avg_epoch_loss=2.726246\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.726246198018392\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] Epoch[47] Batch [5]#011Speed: 2174.15 samples/sec#011loss=2.726246\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] Epoch[47] Batch[10] avg_epoch_loss=2.786092\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=2.857906150817871\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] Epoch[47] Batch [10]#011Speed: 1988.93 samples/sec#011loss=2.857906\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844296.8124866, \"EndTime\": 1747844297.7466738, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.8908195495605, \"count\": 1, \"min\": 933.8908195495605, \"max\": 933.8908195495605}}}\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.1727041705224 records/second\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.7860916311090644\n",
      "[05/21/2025 16:18:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[48] Batch[0] avg_epoch_loss=2.542259\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.5422587394714355\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[48] Batch[5] avg_epoch_loss=2.726263\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.7262625296910605\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[48] Batch [5]#011Speed: 2247.62 samples/sec#011loss=2.726263\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[48] Batch[10] avg_epoch_loss=2.804776\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=2.89899263381958\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[48] Batch [10]#011Speed: 2110.20 samples/sec#011loss=2.898993\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747844297.7467308, \"EndTime\": 1747844298.655018, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.0173969268799, \"count\": 1, \"min\": 908.0173969268799, \"max\": 908.0173969268799}}}\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1461.2761058271292 records/second\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.8047762133858423\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] Epoch[49] Batch[0] avg_epoch_loss=3.000951\n",
      "[05/21/2025 16:18:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=3.000950813293457\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] Epoch[49] Batch[5] avg_epoch_loss=2.981481\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.9814807176589966\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] Epoch[49] Batch [5]#011Speed: 2222.96 samples/sec#011loss=2.981481\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] Epoch[49] Batch[10] avg_epoch_loss=3.067530\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=3.1707894802093506\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] Epoch[49] Batch [10]#011Speed: 2202.17 samples/sec#011loss=3.170789\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747844298.6550713, \"EndTime\": 1747844299.552472, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.1579074859619, \"count\": 1, \"min\": 897.1579074859619, \"max\": 897.1579074859619}}}\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1446.6518460453085 records/second\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=49, train loss <loss>=3.0675301551818848\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] Epoch[50] Batch[0] avg_epoch_loss=2.960189\n",
      "[05/21/2025 16:18:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.9601891040802\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] Epoch[50] Batch[5] avg_epoch_loss=2.935006\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.935006260871887\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] Epoch[50] Batch [5]#011Speed: 2183.80 samples/sec#011loss=2.935006\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] Epoch[50] Batch[10] avg_epoch_loss=2.964458\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.9998002529144285\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] Epoch[50] Batch [10]#011Speed: 2055.74 samples/sec#011loss=2.999800\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844299.5525298, \"EndTime\": 1747844300.473726, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.9356307983398, \"count\": 1, \"min\": 920.9356307983398, \"max\": 920.9356307983398}}}\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1464.686480170188 records/second\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.9644580754366787\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] Epoch[51] Batch[0] avg_epoch_loss=2.762835\n",
      "[05/21/2025 16:18:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.7628345489501953\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] Epoch[51] Batch[5] avg_epoch_loss=2.862908\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.8629081646601358\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] Epoch[51] Batch [5]#011Speed: 2142.93 samples/sec#011loss=2.862908\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] Epoch[51] Batch[10] avg_epoch_loss=2.883451\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.9081027030944826\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] Epoch[51] Batch [10]#011Speed: 2009.75 samples/sec#011loss=2.908103\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747844300.4737813, \"EndTime\": 1747844301.4066741, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.647705078125, \"count\": 1, \"min\": 932.647705078125, \"max\": 932.647705078125}}}\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1398.0441536133492 records/second\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.883451136675748\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] Epoch[52] Batch[0] avg_epoch_loss=2.789102\n",
      "[05/21/2025 16:18:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.7891016006469727\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[52] Batch[5] avg_epoch_loss=2.781222\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.781221866607666\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[52] Batch [5]#011Speed: 2148.34 samples/sec#011loss=2.781222\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[52] Batch[10] avg_epoch_loss=2.831510\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=2.891856813430786\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[52] Batch [10]#011Speed: 1992.98 samples/sec#011loss=2.891857\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747844301.406731, \"EndTime\": 1747844302.3457391, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.762903213501, \"count\": 1, \"min\": 938.762903213501, \"max\": 938.762903213501}}}\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.2825149004143 records/second\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.831510478799993\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[53] Batch[0] avg_epoch_loss=2.740258\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.74025821685791\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[53] Batch[5] avg_epoch_loss=2.762394\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.762393832206726\n",
      "[05/21/2025 16:18:22 INFO 140328105305920] Epoch[53] Batch [5]#011Speed: 2141.44 samples/sec#011loss=2.762394\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Epoch[53] Batch[10] avg_epoch_loss=2.713519\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.654868459701538\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Epoch[53] Batch [10]#011Speed: 2089.86 samples/sec#011loss=2.654868\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844302.3457956, \"EndTime\": 1747844303.2718155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.7667064666748, \"count\": 1, \"min\": 925.7667064666748, \"max\": 925.7667064666748}}}\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1421.3992479055769 records/second\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.713518662886186\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_7e6014f5-eed0-4edb-b89a-f9502d0a1421-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844303.2718701, \"EndTime\": 1747844303.2828476, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.702133178710938, \"count\": 1, \"min\": 10.702133178710938, \"max\": 10.702133178710938}}}\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Epoch[54] Batch[0] avg_epoch_loss=2.703054\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.703054428100586\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Epoch[54] Batch[5] avg_epoch_loss=2.749809\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.7498091061909995\n",
      "[05/21/2025 16:18:23 INFO 140328105305920] Epoch[54] Batch [5]#011Speed: 2146.14 samples/sec#011loss=2.749809\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] Epoch[54] Batch[10] avg_epoch_loss=2.778501\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=2.812930965423584\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] Epoch[54] Batch [10]#011Speed: 1963.42 samples/sec#011loss=2.812931\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844303.2828963, \"EndTime\": 1747844304.2224438, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.5003318786621, \"count\": 1, \"min\": 939.5003318786621, \"max\": 939.5003318786621}}}\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.740656458518 records/second\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.778500860387629\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] Epoch[55] Batch[0] avg_epoch_loss=2.656221\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.6562211513519287\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] Epoch[55] Batch[5] avg_epoch_loss=2.739138\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.7391379674275718\n",
      "[05/21/2025 16:18:24 INFO 140328105305920] Epoch[55] Batch [5]#011Speed: 2126.49 samples/sec#011loss=2.739138\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Epoch[55] Batch[10] avg_epoch_loss=2.673060\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.5937660694122315\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Epoch[55] Batch [10]#011Speed: 1988.34 samples/sec#011loss=2.593766\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747844304.222502, \"EndTime\": 1747844305.1608891, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.1406307220459, \"count\": 1, \"min\": 938.1406307220459, \"max\": 938.1406307220459}}}\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.7446407384434 records/second\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.6730598319660532\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_d616934f-9625-4e6c-b0c4-641f920266f0-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844305.1609454, \"EndTime\": 1747844305.1715205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.169506072998047, \"count\": 1, \"min\": 10.169506072998047, \"max\": 10.169506072998047}}}\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Epoch[56] Batch[0] avg_epoch_loss=2.649429\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.6494293212890625\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Epoch[56] Batch[5] avg_epoch_loss=2.693852\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.6938523054122925\n",
      "[05/21/2025 16:18:25 INFO 140328105305920] Epoch[56] Batch [5]#011Speed: 2146.51 samples/sec#011loss=2.693852\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747844305.171568, \"EndTime\": 1747844306.0295868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 857.9707145690918, \"count\": 1, \"min\": 857.9707145690918, \"max\": 857.9707145690918}}}\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1484.7469215403676 records/second\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.719949984550476\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] Epoch[57] Batch[0] avg_epoch_loss=2.632661\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.6326608657836914\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] Epoch[57] Batch[5] avg_epoch_loss=2.665387\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.6653868754704795\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] Epoch[57] Batch [5]#011Speed: 2157.19 samples/sec#011loss=2.665387\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] Epoch[57] Batch[10] avg_epoch_loss=2.677641\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=2.69234676361084\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] Epoch[57] Batch [10]#011Speed: 1918.60 samples/sec#011loss=2.692347\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747844306.0296462, \"EndTime\": 1747844306.9783173, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.3165740966797, \"count\": 1, \"min\": 948.3165740966797, \"max\": 948.3165740966797}}}\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.8290434887099 records/second\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.677641370079734\n",
      "[05/21/2025 16:18:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] Epoch[58] Batch[0] avg_epoch_loss=2.789186\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.7891860008239746\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] Epoch[58] Batch[5] avg_epoch_loss=2.714509\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.714509129524231\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] Epoch[58] Batch [5]#011Speed: 2256.23 samples/sec#011loss=2.714509\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] Epoch[58] Batch[10] avg_epoch_loss=2.740179\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.770983362197876\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] Epoch[58] Batch [10]#011Speed: 2080.31 samples/sec#011loss=2.770983\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747844306.978374, \"EndTime\": 1747844307.8877199, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.0604782104492, \"count\": 1, \"min\": 909.0604782104492, \"max\": 909.0604782104492}}}\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.4166669944732 records/second\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.7401792352849785\n",
      "[05/21/2025 16:18:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] Epoch[59] Batch[0] avg_epoch_loss=2.738549\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.738548517227173\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] Epoch[59] Batch[5] avg_epoch_loss=2.681741\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.681740959485372\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] Epoch[59] Batch [5]#011Speed: 2225.02 samples/sec#011loss=2.681741\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] Epoch[59] Batch[10] avg_epoch_loss=2.718385\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=2.762358570098877\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] Epoch[59] Batch [10]#011Speed: 2241.26 samples/sec#011loss=2.762359\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747844307.8877769, \"EndTime\": 1747844308.783738, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 895.6897258758545, \"count\": 1, \"min\": 895.6897258758545, \"max\": 895.6897258758545}}}\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1438.985336687665 records/second\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.718385327946056\n",
      "[05/21/2025 16:18:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Epoch[60] Batch[0] avg_epoch_loss=2.636716\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.636716365814209\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Epoch[60] Batch[5] avg_epoch_loss=2.640205\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.640204668045044\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Epoch[60] Batch [5]#011Speed: 2179.99 samples/sec#011loss=2.640205\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Epoch[60] Batch[10] avg_epoch_loss=2.665488\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.695828151702881\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Epoch[60] Batch [10]#011Speed: 2079.68 samples/sec#011loss=2.695828\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747844308.783792, \"EndTime\": 1747844309.7036903, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.6581840515137, \"count\": 1, \"min\": 919.6581840515137, \"max\": 919.6581840515137}}}\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1446.057529944179 records/second\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.6654880697076972\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:29 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_d780b17a-c384-49bc-b803-2fd8af05b712-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844309.7037504, \"EndTime\": 1747844309.713369, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.301424026489258, \"count\": 1, \"min\": 9.301424026489258, \"max\": 9.301424026489258}}}\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] Epoch[61] Batch[0] avg_epoch_loss=2.587524\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.5875244140625\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] Epoch[61] Batch[5] avg_epoch_loss=2.688253\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.6882527271906533\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] Epoch[61] Batch [5]#011Speed: 2040.54 samples/sec#011loss=2.688253\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] processed a total of 1245 examples\n",
      "#metrics {\"StartTime\": 1747844309.7134233, \"EndTime\": 1747844310.6006336, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 887.1428966522217, \"count\": 1, \"min\": 887.1428966522217, \"max\": 887.1428966522217}}}\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1403.2329958474647 records/second\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.6469605445861815\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_a30b099d-892c-47b7-83fe-0e7429670e2c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844310.6006973, \"EndTime\": 1747844310.6102302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.11569595336914, \"count\": 1, \"min\": 9.11569595336914, \"max\": 9.11569595336914}}}\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] Epoch[62] Batch[0] avg_epoch_loss=2.639351\n",
      "[05/21/2025 16:18:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.639350652694702\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] Epoch[62] Batch[5] avg_epoch_loss=2.715307\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.7153072357177734\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] Epoch[62] Batch [5]#011Speed: 2196.10 samples/sec#011loss=2.715307\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] Epoch[62] Batch[10] avg_epoch_loss=2.759767\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.8131179809570312\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] Epoch[62] Batch [10]#011Speed: 1929.85 samples/sec#011loss=2.813118\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747844310.6102738, \"EndTime\": 1747844311.5577018, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.3822116851807, \"count\": 1, \"min\": 947.3822116851807, \"max\": 947.3822116851807}}}\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.9104432579988 records/second\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.7597666653719815\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] Epoch[63] Batch[0] avg_epoch_loss=2.767029\n",
      "[05/21/2025 16:18:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.767029285430908\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] Epoch[63] Batch[5] avg_epoch_loss=2.673155\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.673155148824056\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] Epoch[63] Batch [5]#011Speed: 2111.77 samples/sec#011loss=2.673155\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] Epoch[63] Batch[10] avg_epoch_loss=2.696899\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.725390625\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] Epoch[63] Batch [10]#011Speed: 2022.46 samples/sec#011loss=2.725391\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747844311.557758, \"EndTime\": 1747844312.4985, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.49072265625, \"count\": 1, \"min\": 940.49072265625, \"max\": 940.49072265625}}}\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1455.496150110214 records/second\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.6968985470858486\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] Epoch[64] Batch[0] avg_epoch_loss=2.802317\n",
      "[05/21/2025 16:18:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.802316665649414\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] Epoch[64] Batch[5] avg_epoch_loss=2.699165\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.6991650660832724\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] Epoch[64] Batch [5]#011Speed: 2130.54 samples/sec#011loss=2.699165\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747844312.4985561, \"EndTime\": 1747844313.3660083, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 867.1646118164062, \"count\": 1, \"min\": 867.1646118164062, \"max\": 867.1646118164062}}}\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1475.9110567644868 records/second\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.6842265367507934\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] Epoch[65] Batch[0] avg_epoch_loss=2.747829\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.7478294372558594\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] Epoch[65] Batch[5] avg_epoch_loss=2.692172\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.6921721696853638\n",
      "[05/21/2025 16:18:33 INFO 140328105305920] Epoch[65] Batch [5]#011Speed: 2152.82 samples/sec#011loss=2.692172\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Epoch[65] Batch[10] avg_epoch_loss=2.597779\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.4845073938369753\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Epoch[65] Batch [10]#011Speed: 2126.77 samples/sec#011loss=2.484507\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747844313.3660707, \"EndTime\": 1747844314.2837496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.259693145752, \"count\": 1, \"min\": 917.259693145752, \"max\": 917.259693145752}}}\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1443.2988997080008 records/second\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.597779089754278\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_26ff6204-3425-43cd-92e8-c18351622c9a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844314.2838042, \"EndTime\": 1747844314.2942386, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.16998291015625, \"count\": 1, \"min\": 10.16998291015625, \"max\": 10.16998291015625}}}\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Epoch[66] Batch[0] avg_epoch_loss=2.742064\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.7420644760131836\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Epoch[66] Batch[5] avg_epoch_loss=2.680289\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.6802891890207925\n",
      "[05/21/2025 16:18:34 INFO 140328105305920] Epoch[66] Batch [5]#011Speed: 2195.00 samples/sec#011loss=2.680289\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] Epoch[66] Batch[10] avg_epoch_loss=2.734270\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.7990467071533205\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] Epoch[66] Batch [10]#011Speed: 2073.28 samples/sec#011loss=2.799047\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844314.2942877, \"EndTime\": 1747844315.2128654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.5318946838379, \"count\": 1, \"min\": 918.5318946838379, \"max\": 918.5318946838379}}}\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1428.2439575886624 records/second\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.7342698790810327\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] Epoch[67] Batch[0] avg_epoch_loss=2.653497\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.6534972190856934\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] Epoch[67] Batch[5] avg_epoch_loss=2.704259\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.704259475072225\n",
      "[05/21/2025 16:18:35 INFO 140328105305920] Epoch[67] Batch [5]#011Speed: 2125.32 samples/sec#011loss=2.704259\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] Epoch[67] Batch[10] avg_epoch_loss=2.703344\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.7022465229034425\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] Epoch[67] Batch [10]#011Speed: 1978.59 samples/sec#011loss=2.702247\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747844315.2129185, \"EndTime\": 1747844316.1542091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.0426616668701, \"count\": 1, \"min\": 941.0426616668701, \"max\": 941.0426616668701}}}\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1454.6447600255058 records/second\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.7033444968136875\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] Epoch[68] Batch[0] avg_epoch_loss=2.595007\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.5950074195861816\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] Epoch[68] Batch[5] avg_epoch_loss=2.645993\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.6459934314092\n",
      "[05/21/2025 16:18:36 INFO 140328105305920] Epoch[68] Batch [5]#011Speed: 2159.51 samples/sec#011loss=2.645993\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Epoch[68] Batch[10] avg_epoch_loss=2.583158\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.5077563524246216\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Epoch[68] Batch [10]#011Speed: 2002.12 samples/sec#011loss=2.507756\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747844316.1542637, \"EndTime\": 1747844317.0920267, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.4833106994629, \"count\": 1, \"min\": 937.4833106994629, \"max\": 937.4833106994629}}}\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1410.0336452856982 records/second\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.583158395507119\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_8f649221-177b-4135-9dc8-e4145cc7e915-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844317.0920823, \"EndTime\": 1747844317.102839, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.469436645507812, \"count\": 1, \"min\": 10.469436645507812, \"max\": 10.469436645507812}}}\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Epoch[69] Batch[0] avg_epoch_loss=2.637610\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.63761043548584\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Epoch[69] Batch[5] avg_epoch_loss=2.672314\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.672313849131266\n",
      "[05/21/2025 16:18:37 INFO 140328105305920] Epoch[69] Batch [5]#011Speed: 2182.69 samples/sec#011loss=2.672314\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[69] Batch[10] avg_epoch_loss=2.698810\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.730605459213257\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[69] Batch [10]#011Speed: 2073.61 samples/sec#011loss=2.730605\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844317.1028888, \"EndTime\": 1747844318.0293224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.3887405395508, \"count\": 1, \"min\": 926.3887405395508, \"max\": 926.3887405395508}}}\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1437.7166144307114 records/second\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.698810035532171\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[70] Batch[0] avg_epoch_loss=2.708440\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.708439826965332\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[70] Batch[5] avg_epoch_loss=2.711126\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.7111255725224814\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[70] Batch [5]#011Speed: 2134.60 samples/sec#011loss=2.711126\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[70] Batch[10] avg_epoch_loss=2.689081\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.6626279830932615\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] Epoch[70] Batch [10]#011Speed: 2125.25 samples/sec#011loss=2.662628\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747844318.0293763, \"EndTime\": 1747844318.9463341, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.6877269744873, \"count\": 1, \"min\": 916.6877269744873, \"max\": 916.6877269744873}}}\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1433.2944943420487 records/second\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.689081213691018\n",
      "[05/21/2025 16:18:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] Epoch[71] Batch[0] avg_epoch_loss=2.640226\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.640226364135742\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] Epoch[71] Batch[5] avg_epoch_loss=2.697364\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.6973640521367392\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] Epoch[71] Batch [5]#011Speed: 2194.95 samples/sec#011loss=2.697364\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] Epoch[71] Batch[10] avg_epoch_loss=2.701304\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.7060321807861327\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] Epoch[71] Batch [10]#011Speed: 2033.88 samples/sec#011loss=2.706032\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747844318.94639, \"EndTime\": 1747844319.8691812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.529935836792, \"count\": 1, \"min\": 922.529935836792, \"max\": 922.529935836792}}}\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1485.9996774953795 records/second\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.7013041106137363\n",
      "[05/21/2025 16:18:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Epoch[72] Batch[0] avg_epoch_loss=2.785212\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.7852115631103516\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Epoch[72] Batch[5] avg_epoch_loss=2.638068\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.638068159421285\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Epoch[72] Batch [5]#011Speed: 2136.09 samples/sec#011loss=2.638068\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Epoch[72] Batch[10] avg_epoch_loss=2.555631\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.4567064523696898\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Epoch[72] Batch [10]#011Speed: 2161.40 samples/sec#011loss=2.456706\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747844319.8692358, \"EndTime\": 1747844320.7891335, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.0182685852051, \"count\": 1, \"min\": 919.0182685852051, \"max\": 919.0182685852051}}}\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1423.118701101084 records/second\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.555631019852378\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:40 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_791974c1-f20b-4315-908a-45f7903f1a5c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844320.7891927, \"EndTime\": 1747844320.7996707, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.125875473022461, \"count\": 1, \"min\": 10.125875473022461, \"max\": 10.125875473022461}}}\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] Epoch[73] Batch[0] avg_epoch_loss=2.587415\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.5874152183532715\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] Epoch[73] Batch[5] avg_epoch_loss=2.663499\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.663499196370443\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] Epoch[73] Batch [5]#011Speed: 2135.34 samples/sec#011loss=2.663499\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] Epoch[73] Batch[10] avg_epoch_loss=2.662399\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=2.661077785491943\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] Epoch[73] Batch [10]#011Speed: 2165.25 samples/sec#011loss=2.661078\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844320.799707, \"EndTime\": 1747844321.7170436, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.2964096069336, \"count\": 1, \"min\": 917.2964096069336, \"max\": 917.2964096069336}}}\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1413.8175633689013 records/second\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.6623985550620337\n",
      "[05/21/2025 16:18:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[74] Batch[0] avg_epoch_loss=2.677128\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.6771275997161865\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[74] Batch[5] avg_epoch_loss=2.648040\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.648040016492208\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[74] Batch [5]#011Speed: 2106.96 samples/sec#011loss=2.648040\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[74] Batch[10] avg_epoch_loss=2.620211\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.5868155479431154\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[74] Batch [10]#011Speed: 2037.65 samples/sec#011loss=2.586816\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747844321.7170982, \"EndTime\": 1747844322.6508062, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.4621429443359, \"count\": 1, \"min\": 933.4621429443359, \"max\": 933.4621429443359}}}\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.5245874174452 records/second\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.620210712606257\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] Epoch[75] Batch[0] avg_epoch_loss=2.576171\n",
      "[05/21/2025 16:18:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.576171398162842\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] Epoch[75] Batch[5] avg_epoch_loss=2.565156\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.565155506134033\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] Epoch[75] Batch [5]#011Speed: 2172.26 samples/sec#011loss=2.565156\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] Epoch[75] Batch[10] avg_epoch_loss=2.598329\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=2.6381362438201905\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] Epoch[75] Batch [10]#011Speed: 2109.52 samples/sec#011loss=2.638136\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747844322.650863, \"EndTime\": 1747844323.5644343, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 913.3241176605225, \"count\": 1, \"min\": 913.3241176605225, \"max\": 913.3241176605225}}}\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1473.6086308506135 records/second\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.59832856871865\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] Epoch[76] Batch[0] avg_epoch_loss=2.667192\n",
      "[05/21/2025 16:18:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.667191505432129\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] Epoch[76] Batch[5] avg_epoch_loss=2.648342\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.648342251777649\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] Epoch[76] Batch [5]#011Speed: 2138.92 samples/sec#011loss=2.648342\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] Epoch[76] Batch[10] avg_epoch_loss=2.653079\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.658762741088867\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] Epoch[76] Batch [10]#011Speed: 2095.11 samples/sec#011loss=2.658763\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747844323.5644875, \"EndTime\": 1747844324.4853055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.5539226531982, \"count\": 1, \"min\": 920.5539226531982, \"max\": 920.5539226531982}}}\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1453.3409622800655 records/second\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.6530788378282026\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] Epoch[77] Batch[0] avg_epoch_loss=2.482671\n",
      "[05/21/2025 16:18:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.4826714992523193\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] Epoch[77] Batch[5] avg_epoch_loss=2.617149\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.617148995399475\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] Epoch[77] Batch [5]#011Speed: 2138.31 samples/sec#011loss=2.617149\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] Epoch[77] Batch[10] avg_epoch_loss=2.634044\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.6543182849884035\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] Epoch[77] Batch [10]#011Speed: 2053.55 samples/sec#011loss=2.654318\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747844324.4853623, \"EndTime\": 1747844325.4153063, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.6698570251465, \"count\": 1, \"min\": 929.6698570251465, \"max\": 929.6698570251465}}}\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.0017909262813 records/second\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.634044127030806\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] Epoch[78] Batch[0] avg_epoch_loss=2.507796\n",
      "[05/21/2025 16:18:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.507796049118042\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[78] Batch[5] avg_epoch_loss=2.581424\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.581424276034037\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[78] Batch [5]#011Speed: 2135.96 samples/sec#011loss=2.581424\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[78] Batch[10] avg_epoch_loss=2.596632\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.6148819446563722\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[78] Batch [10]#011Speed: 2076.17 samples/sec#011loss=2.614882\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844325.4153607, \"EndTime\": 1747844326.3466473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.0281276702881, \"count\": 1, \"min\": 931.0281276702881, \"max\": 931.0281276702881}}}\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1450.95207470739 records/second\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.596632307226008\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[79] Batch[0] avg_epoch_loss=2.659168\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.659168243408203\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[79] Batch[5] avg_epoch_loss=2.565337\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.5653370221455893\n",
      "[05/21/2025 16:18:46 INFO 140328105305920] Epoch[79] Batch [5]#011Speed: 2195.61 samples/sec#011loss=2.565337\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] Epoch[79] Batch[10] avg_epoch_loss=2.604857\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.652281379699707\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] Epoch[79] Batch [10]#011Speed: 2052.05 samples/sec#011loss=2.652281\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844326.3467045, \"EndTime\": 1747844327.266499, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.5408821105957, \"count\": 1, \"min\": 919.5408821105957, \"max\": 919.5408821105957}}}\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1458.21018529657 records/second\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.604857184670188\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] Epoch[80] Batch[0] avg_epoch_loss=2.539536\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.539536237716675\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] Epoch[80] Batch[5] avg_epoch_loss=2.519401\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.5194009145100913\n",
      "[05/21/2025 16:18:47 INFO 140328105305920] Epoch[80] Batch [5]#011Speed: 2184.44 samples/sec#011loss=2.519401\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Epoch[80] Batch[10] avg_epoch_loss=2.542533\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.57029128074646\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Epoch[80] Batch [10]#011Speed: 1948.75 samples/sec#011loss=2.570291\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] processed a total of 1380 examples\n",
      "#metrics {\"StartTime\": 1747844327.2665532, \"EndTime\": 1747844328.20755, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.709114074707, \"count\": 1, \"min\": 940.709114074707, \"max\": 940.709114074707}}}\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1466.8435013531482 records/second\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.542532899162986\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_625c93f5-58de-4bfb-9098-4de2e08c0733-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844328.2076077, \"EndTime\": 1747844328.2182775, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.394096374511719, \"count\": 1, \"min\": 10.394096374511719, \"max\": 10.394096374511719}}}\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Epoch[81] Batch[0] avg_epoch_loss=2.599761\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.5997612476348877\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Epoch[81] Batch[5] avg_epoch_loss=2.617402\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.6174017985661826\n",
      "[05/21/2025 16:18:48 INFO 140328105305920] Epoch[81] Batch [5]#011Speed: 2195.30 samples/sec#011loss=2.617402\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Epoch[81] Batch[10] avg_epoch_loss=2.524622\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.413285565376282\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Epoch[81] Batch [10]#011Speed: 2114.87 samples/sec#011loss=2.413286\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844328.218328, \"EndTime\": 1747844329.1334972, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.12131690979, \"count\": 1, \"min\": 915.12131690979, \"max\": 915.12131690979}}}\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.2836254506803 records/second\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.524621692570773\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_827f84db-51f5-4ce8-bc61-2ef2192583d5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844329.1335526, \"EndTime\": 1747844329.1443543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.52093505859375, \"count\": 1, \"min\": 10.52093505859375, \"max\": 10.52093505859375}}}\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Epoch[82] Batch[0] avg_epoch_loss=2.544739\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.5447394847869873\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Epoch[82] Batch[5] avg_epoch_loss=2.559262\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.5592620372772217\n",
      "[05/21/2025 16:18:49 INFO 140328105305920] Epoch[82] Batch [5]#011Speed: 2063.30 samples/sec#011loss=2.559262\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747844329.1444013, \"EndTime\": 1747844330.008599, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 864.152193069458, \"count\": 1, \"min\": 864.152193069458, \"max\": 864.152193069458}}}\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1478.7596905383798 records/second\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.544045925140381\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Epoch[83] Batch[0] avg_epoch_loss=2.516079\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.5160794258117676\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Epoch[83] Batch[5] avg_epoch_loss=2.562589\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.5625888109207153\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Epoch[83] Batch [5]#011Speed: 2251.95 samples/sec#011loss=2.562589\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Epoch[83] Batch[10] avg_epoch_loss=2.521766\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.472777843475342\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Epoch[83] Batch [10]#011Speed: 1956.67 samples/sec#011loss=2.472778\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] processed a total of 1397 examples\n",
      "#metrics {\"StartTime\": 1747844330.0086575, \"EndTime\": 1747844330.9262424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.2530174255371, \"count\": 1, \"min\": 917.2530174255371, \"max\": 917.2530174255371}}}\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1522.8915985307117 records/second\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.521765643900091\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:50 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_3af60ff6-d845-4fc9-a85a-036313d67334-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844330.9262962, \"EndTime\": 1747844330.9367306, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.13326644897461, \"count\": 1, \"min\": 10.13326644897461, \"max\": 10.13326644897461}}}\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] Epoch[84] Batch[0] avg_epoch_loss=2.593500\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.5934996604919434\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] Epoch[84] Batch[5] avg_epoch_loss=2.568795\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.568795402844747\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] Epoch[84] Batch [5]#011Speed: 2151.02 samples/sec#011loss=2.568795\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] Epoch[84] Batch[10] avg_epoch_loss=2.581604\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.596974420547485\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] Epoch[84] Batch [10]#011Speed: 2109.20 samples/sec#011loss=2.596974\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844330.9367797, \"EndTime\": 1747844331.8757305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.9054775238037, \"count\": 1, \"min\": 938.9054775238037, \"max\": 938.9054775238037}}}\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1394.0540681357738 records/second\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.5816040472550825\n",
      "[05/21/2025 16:18:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] Epoch[85] Batch[0] avg_epoch_loss=2.574815\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.574815273284912\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] Epoch[85] Batch[5] avg_epoch_loss=2.582688\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.5826878945032754\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] Epoch[85] Batch [5]#011Speed: 2204.28 samples/sec#011loss=2.582688\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] Epoch[85] Batch[10] avg_epoch_loss=2.593978\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=2.6075253009796144\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] Epoch[85] Batch [10]#011Speed: 2087.10 samples/sec#011loss=2.607525\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747844331.8757877, \"EndTime\": 1747844332.7881424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.1079444885254, \"count\": 1, \"min\": 912.1079444885254, \"max\": 912.1079444885254}}}\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1498.5874503268678 records/second\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.593977624719793\n",
      "[05/21/2025 16:18:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] Epoch[86] Batch[0] avg_epoch_loss=2.564471\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.564471483230591\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] Epoch[86] Batch[5] avg_epoch_loss=2.505260\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.505259911219279\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] Epoch[86] Batch [5]#011Speed: 2095.10 samples/sec#011loss=2.505260\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] Epoch[86] Batch[10] avg_epoch_loss=2.559611\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.6248323917388916\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] Epoch[86] Batch [10]#011Speed: 2012.56 samples/sec#011loss=2.624832\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747844332.7881992, \"EndTime\": 1747844333.7352378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.786642074585, \"count\": 1, \"min\": 946.786642074585, \"max\": 946.786642074585}}}\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1425.7517645921293 records/second\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.559611038728194\n",
      "[05/21/2025 16:18:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[87] Batch[0] avg_epoch_loss=2.576954\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.576953887939453\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[87] Batch[5] avg_epoch_loss=2.546942\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.546941558519999\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[87] Batch [5]#011Speed: 2147.80 samples/sec#011loss=2.546942\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[87] Batch[10] avg_epoch_loss=2.526176\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.501256513595581\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[87] Batch [10]#011Speed: 2067.62 samples/sec#011loss=2.501257\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844333.7352922, \"EndTime\": 1747844334.6643832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.8334846496582, \"count\": 1, \"min\": 928.8334846496582, \"max\": 928.8334846496582}}}\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.9350323588255 records/second\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.5261756290089\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] Epoch[88] Batch[0] avg_epoch_loss=2.521134\n",
      "[05/21/2025 16:18:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.521134376525879\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] Epoch[88] Batch[5] avg_epoch_loss=2.524491\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.52449099222819\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] Epoch[88] Batch [5]#011Speed: 2009.92 samples/sec#011loss=2.524491\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] Epoch[88] Batch[10] avg_epoch_loss=2.548667\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=2.5776791095733644\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] Epoch[88] Batch [10]#011Speed: 2080.61 samples/sec#011loss=2.577679\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844334.664438, \"EndTime\": 1747844335.6101573, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.4381465911865, \"count\": 1, \"min\": 945.4381465911865, \"max\": 945.4381465911865}}}\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1412.9795710673038 records/second\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.548667409203269\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] Epoch[89] Batch[0] avg_epoch_loss=2.496668\n",
      "[05/21/2025 16:18:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.4966676235198975\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] Epoch[89] Batch[5] avg_epoch_loss=2.523211\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.5232107639312744\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] Epoch[89] Batch [5]#011Speed: 2139.86 samples/sec#011loss=2.523211\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] Epoch[89] Batch[10] avg_epoch_loss=2.580910\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=2.6501489639282227\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] Epoch[89] Batch [10]#011Speed: 2081.06 samples/sec#011loss=2.650149\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844335.6102111, \"EndTime\": 1747844336.5389662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.5123348236084, \"count\": 1, \"min\": 928.5123348236084, \"max\": 928.5123348236084}}}\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1412.883483190494 records/second\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.580909945748069\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] Epoch[90] Batch[0] avg_epoch_loss=2.678149\n",
      "[05/21/2025 16:18:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.6781492233276367\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] Epoch[90] Batch[5] avg_epoch_loss=2.540747\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.5407474438349404\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] Epoch[90] Batch [5]#011Speed: 2015.56 samples/sec#011loss=2.540747\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] Epoch[90] Batch[10] avg_epoch_loss=2.548369\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.5575154781341554\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] Epoch[90] Batch [10]#011Speed: 1968.46 samples/sec#011loss=2.557515\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844336.539024, \"EndTime\": 1747844337.5055056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 966.2370681762695, \"count\": 1, \"min\": 966.2370681762695, \"max\": 966.2370681762695}}}\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1364.9627827611084 records/second\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.548369277607311\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] Epoch[91] Batch[0] avg_epoch_loss=2.544415\n",
      "[05/21/2025 16:18:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.544414520263672\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] Epoch[91] Batch[5] avg_epoch_loss=2.495894\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.4958940744400024\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] Epoch[91] Batch [5]#011Speed: 2216.38 samples/sec#011loss=2.495894\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] Epoch[91] Batch[10] avg_epoch_loss=2.521802\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=2.552891254425049\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] Epoch[91] Batch [10]#011Speed: 2000.24 samples/sec#011loss=2.552891\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747844337.5055654, \"EndTime\": 1747844338.4303374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.518346786499, \"count\": 1, \"min\": 924.518346786499, \"max\": 924.518346786499}}}\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1478.476599223064 records/second\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.5218018835241143\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] Epoch[92] Batch[0] avg_epoch_loss=2.581659\n",
      "[05/21/2025 16:18:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.5816593170166016\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[92] Batch[5] avg_epoch_loss=2.512166\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.5121663014094033\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[92] Batch [5]#011Speed: 2267.61 samples/sec#011loss=2.512166\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[92] Batch[10] avg_epoch_loss=2.505539\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.4975860118865967\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[92] Batch [10]#011Speed: 2107.61 samples/sec#011loss=2.497586\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844338.4303923, \"EndTime\": 1747844339.3350036, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.3686389923096, \"count\": 1, \"min\": 904.3686389923096, \"max\": 904.3686389923096}}}\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1482.6706875435939 records/second\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.505538897080855\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_e45a1a04-2c04-43d9-b97b-53284d69f460-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844339.3350575, \"EndTime\": 1747844339.345525, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.207176208496094, \"count\": 1, \"min\": 10.207176208496094, \"max\": 10.207176208496094}}}\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[93] Batch[0] avg_epoch_loss=2.486224\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.4862236976623535\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[93] Batch[5] avg_epoch_loss=2.548997\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.548997243245443\n",
      "[05/21/2025 16:18:59 INFO 140328105305920] Epoch[93] Batch [5]#011Speed: 2227.42 samples/sec#011loss=2.548997\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Epoch[93] Batch[10] avg_epoch_loss=2.502475\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.446647882461548\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Epoch[93] Batch [10]#011Speed: 1958.03 samples/sec#011loss=2.446648\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747844339.3455737, \"EndTime\": 1747844340.2710476, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.426721572876, \"count\": 1, \"min\": 925.426721572876, \"max\": 925.426721572876}}}\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1478.10331510158 records/second\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.5024748065254907\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_0a2abff6-f741-4722-b207-e69860709141-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844340.2711043, \"EndTime\": 1747844340.2815213, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.152816772460938, \"count\": 1, \"min\": 10.152816772460938, \"max\": 10.152816772460938}}}\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Epoch[94] Batch[0] avg_epoch_loss=2.568638\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.5686376094818115\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Epoch[94] Batch[5] avg_epoch_loss=2.550819\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.5508190790812173\n",
      "[05/21/2025 16:19:00 INFO 140328105305920] Epoch[94] Batch [5]#011Speed: 2128.34 samples/sec#011loss=2.550819\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Epoch[94] Batch[10] avg_epoch_loss=2.488851\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=2.4144886255264284\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Epoch[94] Batch [10]#011Speed: 2040.25 samples/sec#011loss=2.414489\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844340.2815726, \"EndTime\": 1747844341.232095, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.4749774932861, \"count\": 1, \"min\": 950.4749774932861, \"max\": 950.4749774932861}}}\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.1647255760943 records/second\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.4888506911017676\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_45724cd0-2b12-4272-b652-14118951d852-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844341.2321517, \"EndTime\": 1747844341.242488, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.069608688354492, \"count\": 1, \"min\": 10.069608688354492, \"max\": 10.069608688354492}}}\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Epoch[95] Batch[0] avg_epoch_loss=2.615051\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.615050792694092\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Epoch[95] Batch[5] avg_epoch_loss=2.479632\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.4796317418416343\n",
      "[05/21/2025 16:19:01 INFO 140328105305920] Epoch[95] Batch [5]#011Speed: 2098.60 samples/sec#011loss=2.479632\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] Epoch[95] Batch[10] avg_epoch_loss=2.525263\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.580020618438721\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] Epoch[95] Batch [10]#011Speed: 1873.79 samples/sec#011loss=2.580021\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844341.2425356, \"EndTime\": 1747844342.205766, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.1829261779785, \"count\": 1, \"min\": 963.1829261779785, \"max\": 963.1829261779785}}}\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1392.1358771102402 records/second\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.525263049385764\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] Epoch[96] Batch[0] avg_epoch_loss=2.540325\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.5403249263763428\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] Epoch[96] Batch[5] avg_epoch_loss=2.515888\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.515888492266337\n",
      "[05/21/2025 16:19:02 INFO 140328105305920] Epoch[96] Batch [5]#011Speed: 2195.18 samples/sec#011loss=2.515888\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] Epoch[96] Batch[10] avg_epoch_loss=2.545796\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.581685018539429\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] Epoch[96] Batch [10]#011Speed: 2113.40 samples/sec#011loss=2.581685\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747844342.205823, \"EndTime\": 1747844343.1179688, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.8402004241943, \"count\": 1, \"min\": 911.8402004241943, \"max\": 911.8402004241943}}}\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1448.5918695275918 records/second\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.5457960042086514\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] Epoch[97] Batch[0] avg_epoch_loss=2.425649\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.425649404525757\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] Epoch[97] Batch[5] avg_epoch_loss=2.498859\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.4988587697347007\n",
      "[05/21/2025 16:19:03 INFO 140328105305920] Epoch[97] Batch [5]#011Speed: 2203.32 samples/sec#011loss=2.498859\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[97] Batch[10] avg_epoch_loss=2.482701\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.463312101364136\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[97] Batch [10]#011Speed: 2054.44 samples/sec#011loss=2.463312\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747844343.1180232, \"EndTime\": 1747844344.0347826, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.3815975189209, \"count\": 1, \"min\": 916.3815975189209, \"max\": 916.3815975189209}}}\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1480.7178223758988 records/second\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.4827011932026255\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_c097895e-48a0-4481-85c7-279eabca7c8c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844344.0348241, \"EndTime\": 1747844344.0456467, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.603666305541992, \"count\": 1, \"min\": 10.603666305541992, \"max\": 10.603666305541992}}}\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[98] Batch[0] avg_epoch_loss=2.416579\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.416578769683838\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[98] Batch[5] avg_epoch_loss=2.438522\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.43852162361145\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[98] Batch [5]#011Speed: 2185.18 samples/sec#011loss=2.438522\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[98] Batch[10] avg_epoch_loss=2.465466\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=2.497799205780029\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Epoch[98] Batch [10]#011Speed: 2115.02 samples/sec#011loss=2.497799\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747844344.0456958, \"EndTime\": 1747844344.9603317, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.5913124084473, \"count\": 1, \"min\": 914.5913124084473, \"max\": 914.5913124084473}}}\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1443.139305836308 records/second\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.4654659791426226\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:04 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_38048547-ce28-4ca4-b3c4-5b870dc3f122-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844344.9603875, \"EndTime\": 1747844344.971202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.554313659667969, \"count\": 1, \"min\": 10.554313659667969, \"max\": 10.554313659667969}}}\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] Epoch[99] Batch[0] avg_epoch_loss=2.473066\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.4730658531188965\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] Epoch[99] Batch[5] avg_epoch_loss=2.469876\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.469875693321228\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] Epoch[99] Batch [5]#011Speed: 2156.93 samples/sec#011loss=2.469876\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] processed a total of 1269 examples\n",
      "#metrics {\"StartTime\": 1747844344.9712505, \"EndTime\": 1747844345.825837, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 854.5260429382324, \"count\": 1, \"min\": 854.5260429382324, \"max\": 854.5260429382324}}}\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1484.8816883986062 records/second\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.471322846412659\n",
      "[05/21/2025 16:19:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Epoch[100] Batch[0] avg_epoch_loss=2.366273\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.3662731647491455\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Epoch[100] Batch[5] avg_epoch_loss=2.445511\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.4455111026763916\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Epoch[100] Batch [5]#011Speed: 2145.06 samples/sec#011loss=2.445511\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Epoch[100] Batch[10] avg_epoch_loss=2.332029\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.195850133895874\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Epoch[100] Batch [10]#011Speed: 2035.57 samples/sec#011loss=2.195850\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844345.8258963, \"EndTime\": 1747844346.7571185, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.9351444244385, \"count\": 1, \"min\": 930.9351444244385, \"max\": 930.9351444244385}}}\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1385.5799156613887 records/second\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.3320288441397925\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:06 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_29617f75-22dd-4e81-b640-fb20f128afd8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844346.7571747, \"EndTime\": 1747844346.7681153, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.617733001708984, \"count\": 1, \"min\": 10.617733001708984, \"max\": 10.617733001708984}}}\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[101] Batch[0] avg_epoch_loss=2.514674\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.514674425125122\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[101] Batch[5] avg_epoch_loss=2.484517\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.484517296155294\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[101] Batch [5]#011Speed: 2178.92 samples/sec#011loss=2.484517\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[101] Batch[10] avg_epoch_loss=2.504199\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=2.527817153930664\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[101] Batch [10]#011Speed: 2142.91 samples/sec#011loss=2.527817\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747844346.768165, \"EndTime\": 1747844347.6741576, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 905.9481620788574, \"count\": 1, \"min\": 905.9481620788574, \"max\": 905.9481620788574}}}\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.3602376532765 records/second\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.504199049689553\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] Epoch[102] Batch[0] avg_epoch_loss=2.569388\n",
      "[05/21/2025 16:19:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.5693881511688232\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] Epoch[102] Batch[5] avg_epoch_loss=2.572202\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.5722023248672485\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] Epoch[102] Batch [5]#011Speed: 2130.81 samples/sec#011loss=2.572202\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] Epoch[102] Batch[10] avg_epoch_loss=2.454001\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=2.312159562110901\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] Epoch[102] Batch [10]#011Speed: 2141.76 samples/sec#011loss=2.312160\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844347.6742132, \"EndTime\": 1747844348.595684, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.2260246276855, \"count\": 1, \"min\": 921.2260246276855, \"max\": 921.2260246276855}}}\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.0427171913975 records/second\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.4540010690689087\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] Epoch[103] Batch[0] avg_epoch_loss=2.595697\n",
      "[05/21/2025 16:19:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.5956969261169434\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] Epoch[103] Batch[5] avg_epoch_loss=2.464097\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.4640973011652627\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] Epoch[103] Batch [5]#011Speed: 2223.46 samples/sec#011loss=2.464097\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] Epoch[103] Batch[10] avg_epoch_loss=2.531548\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.6124877452850344\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] Epoch[103] Batch [10]#011Speed: 2087.91 samples/sec#011loss=2.612488\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747844348.5957534, \"EndTime\": 1747844349.510564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.5660400390625, \"count\": 1, \"min\": 914.5660400390625, \"max\": 914.5660400390625}}}\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1439.8996034729223 records/second\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.5315475030378862\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] Epoch[104] Batch[0] avg_epoch_loss=2.487704\n",
      "[05/21/2025 16:19:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.487703561782837\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] Epoch[104] Batch[5] avg_epoch_loss=2.455972\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.455971678098043\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] Epoch[104] Batch [5]#011Speed: 2138.44 samples/sec#011loss=2.455972\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] Epoch[104] Batch[10] avg_epoch_loss=2.484526\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=2.518790531158447\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] Epoch[104] Batch [10]#011Speed: 1945.91 samples/sec#011loss=2.518791\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747844349.5106187, \"EndTime\": 1747844350.4584174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.5491046905518, \"count\": 1, \"min\": 947.5491046905518, \"max\": 947.5491046905518}}}\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1382.374275764955 records/second\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.4845257022164087\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] Epoch[105] Batch[0] avg_epoch_loss=2.488034\n",
      "[05/21/2025 16:19:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.4880340099334717\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] Epoch[105] Batch[5] avg_epoch_loss=2.586483\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.5864830017089844\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] Epoch[105] Batch [5]#011Speed: 2137.98 samples/sec#011loss=2.586483\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] Epoch[105] Batch[10] avg_epoch_loss=2.520594\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.44152774810791\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] Epoch[105] Batch [10]#011Speed: 2006.70 samples/sec#011loss=2.441528\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747844350.4584813, \"EndTime\": 1747844351.3958073, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.9912147521973, \"count\": 1, \"min\": 936.9912147521973, \"max\": 936.9912147521973}}}\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.2419539995929 records/second\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.5205942500721323\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] Epoch[106] Batch[0] avg_epoch_loss=2.679627\n",
      "[05/21/2025 16:19:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.679626703262329\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[106] Batch[5] avg_epoch_loss=2.552969\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.5529689391454062\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[106] Batch [5]#011Speed: 2137.83 samples/sec#011loss=2.552969\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[106] Batch[10] avg_epoch_loss=2.601831\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=2.6604661464691164\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[106] Batch [10]#011Speed: 2089.74 samples/sec#011loss=2.660466\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844351.3958657, \"EndTime\": 1747844352.3523421, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.1793804168701, \"count\": 1, \"min\": 956.1793804168701, \"max\": 956.1793804168701}}}\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1385.6147656552112 records/second\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.601831306110729\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[107] Batch[0] avg_epoch_loss=2.481964\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.481964349746704\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[107] Batch[5] avg_epoch_loss=2.499590\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.499589681625366\n",
      "[05/21/2025 16:19:12 INFO 140328105305920] Epoch[107] Batch [5]#011Speed: 2204.46 samples/sec#011loss=2.499590\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] Epoch[107] Batch[10] avg_epoch_loss=2.509140\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.520600986480713\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] Epoch[107] Batch [10]#011Speed: 2103.16 samples/sec#011loss=2.520601\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844352.3523917, \"EndTime\": 1747844353.2666519, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.0136241912842, \"count\": 1, \"min\": 914.0136241912842, \"max\": 914.0136241912842}}}\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.1095289077832 records/second\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.509140274741433\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] Epoch[108] Batch[0] avg_epoch_loss=2.499492\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.4994921684265137\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] Epoch[108] Batch[5] avg_epoch_loss=2.469515\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.4695154428482056\n",
      "[05/21/2025 16:19:13 INFO 140328105305920] Epoch[108] Batch [5]#011Speed: 2243.37 samples/sec#011loss=2.469515\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] Epoch[108] Batch[10] avg_epoch_loss=2.501070\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.538936233520508\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] Epoch[108] Batch [10]#011Speed: 2042.43 samples/sec#011loss=2.538936\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747844353.2667491, \"EndTime\": 1747844354.1831021, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.0678386688232, \"count\": 1, \"min\": 916.0678386688232, \"max\": 916.0678386688232}}}\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1496.4785137204742 records/second\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.501070347699252\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] Epoch[109] Batch[0] avg_epoch_loss=2.484426\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.484426259994507\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] Epoch[109] Batch[5] avg_epoch_loss=2.479495\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.4794954856236777\n",
      "[05/21/2025 16:19:14 INFO 140328105305920] Epoch[109] Batch [5]#011Speed: 2136.85 samples/sec#011loss=2.479495\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] Epoch[109] Batch[10] avg_epoch_loss=2.447394\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.408871793746948\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] Epoch[109] Batch [10]#011Speed: 2134.47 samples/sec#011loss=2.408872\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747844354.1831574, \"EndTime\": 1747844355.1055264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.1246242523193, \"count\": 1, \"min\": 922.1246242523193, \"max\": 922.1246242523193}}}\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1418.3339172662838 records/second\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.4473938074978916\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] Epoch[110] Batch[0] avg_epoch_loss=2.515764\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.515763759613037\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] Epoch[110] Batch[5] avg_epoch_loss=2.444915\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.444915493329366\n",
      "[05/21/2025 16:19:15 INFO 140328105305920] Epoch[110] Batch [5]#011Speed: 2130.40 samples/sec#011loss=2.444915\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[110] Batch[10] avg_epoch_loss=2.473953\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.508798599243164\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[110] Batch [10]#011Speed: 2094.63 samples/sec#011loss=2.508799\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844355.1055825, \"EndTime\": 1747844356.0369165, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.0657978057861, \"count\": 1, \"min\": 931.0657978057861, \"max\": 931.0657978057861}}}\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1402.567138604925 records/second\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.473953268744729\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[111] Batch[0] avg_epoch_loss=2.477202\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.4772024154663086\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[111] Batch[5] avg_epoch_loss=2.517113\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.5171127319335938\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[111] Batch [5]#011Speed: 2163.01 samples/sec#011loss=2.517113\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[111] Batch[10] avg_epoch_loss=2.532923\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=2.5518945693969726\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] Epoch[111] Batch [10]#011Speed: 2036.30 samples/sec#011loss=2.551895\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844356.036973, \"EndTime\": 1747844356.9655929, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.3826351165771, \"count\": 1, \"min\": 928.3826351165771, \"max\": 928.3826351165771}}}\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1438.938759998069 records/second\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.5329226580533115\n",
      "[05/21/2025 16:19:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] Epoch[112] Batch[0] avg_epoch_loss=2.579566\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.579566478729248\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] Epoch[112] Batch[5] avg_epoch_loss=2.501805\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.501805067062378\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] Epoch[112] Batch [5]#011Speed: 2160.23 samples/sec#011loss=2.501805\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] Epoch[112] Batch[10] avg_epoch_loss=2.484142\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.4629465103149415\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] Epoch[112] Batch [10]#011Speed: 2006.72 samples/sec#011loss=2.462947\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] processed a total of 1388 examples\n",
      "#metrics {\"StartTime\": 1747844356.9656465, \"EndTime\": 1747844357.8937457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.8521537780762, \"count\": 1, \"min\": 927.8521537780762, \"max\": 927.8521537780762}}}\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1495.7915360263964 records/second\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.4841420867226343\n",
      "[05/21/2025 16:19:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] Epoch[113] Batch[0] avg_epoch_loss=2.420855\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.4208552837371826\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] Epoch[113] Batch[5] avg_epoch_loss=2.489880\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.489880363146464\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] Epoch[113] Batch [5]#011Speed: 2097.24 samples/sec#011loss=2.489880\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] Epoch[113] Batch[10] avg_epoch_loss=2.467430\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.4404892444610597\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] Epoch[113] Batch [10]#011Speed: 2155.80 samples/sec#011loss=2.440489\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747844357.8938024, \"EndTime\": 1747844358.8173594, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.2959747314453, \"count\": 1, \"min\": 923.2959747314453, \"max\": 923.2959747314453}}}\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1439.2958059452806 records/second\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.467429854653098\n",
      "[05/21/2025 16:19:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] Epoch[114] Batch[0] avg_epoch_loss=2.502264\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.5022644996643066\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] Epoch[114] Batch[5] avg_epoch_loss=2.578713\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.5787134567896524\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] Epoch[114] Batch [5]#011Speed: 2137.48 samples/sec#011loss=2.578713\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] Epoch[114] Batch[10] avg_epoch_loss=2.618420\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=2.6660674571990968\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] Epoch[114] Batch [10]#011Speed: 2205.12 samples/sec#011loss=2.666067\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747844358.817406, \"EndTime\": 1747844359.7289417, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.2064838409424, \"count\": 1, \"min\": 911.2064838409424, \"max\": 911.2064838409424}}}\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.774972888757 records/second\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.618419820612127\n",
      "[05/21/2025 16:19:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[115] Batch[0] avg_epoch_loss=2.581695\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.581695318222046\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[115] Batch[5] avg_epoch_loss=2.511013\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.5110127131144204\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[115] Batch [5]#011Speed: 2057.87 samples/sec#011loss=2.511013\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[115] Batch[10] avg_epoch_loss=2.360514\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=2.1799148082733155\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[115] Batch [10]#011Speed: 2104.54 samples/sec#011loss=2.179915\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747844359.7289958, \"EndTime\": 1747844360.6715782, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.3387050628662, \"count\": 1, \"min\": 942.3387050628662, \"max\": 942.3387050628662}}}\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1359.2658729335524 records/second\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.3605136654593726\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] Epoch[116] Batch[0] avg_epoch_loss=2.427891\n",
      "[05/21/2025 16:19:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.4278910160064697\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] Epoch[116] Batch[5] avg_epoch_loss=2.431253\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.4312525590260825\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] Epoch[116] Batch [5]#011Speed: 2192.01 samples/sec#011loss=2.431253\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] Epoch[116] Batch[10] avg_epoch_loss=2.516590\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=2.6189942359924316\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] Epoch[116] Batch [10]#011Speed: 1960.26 samples/sec#011loss=2.618994\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747844360.6716332, \"EndTime\": 1747844361.6060398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.1399669647217, \"count\": 1, \"min\": 934.1399669647217, \"max\": 934.1399669647217}}}\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.136648433945 records/second\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.5165896849198774\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] Epoch[117] Batch[0] avg_epoch_loss=2.460442\n",
      "[05/21/2025 16:19:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.460441827774048\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] Epoch[117] Batch[5] avg_epoch_loss=2.453490\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.4534895022710166\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] Epoch[117] Batch [5]#011Speed: 2189.03 samples/sec#011loss=2.453490\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] Epoch[117] Batch[10] avg_epoch_loss=2.442530\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.429378843307495\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] Epoch[117] Batch [10]#011Speed: 2037.66 samples/sec#011loss=2.429379\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844361.6060941, \"EndTime\": 1747844362.5311887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.8487949371338, \"count\": 1, \"min\": 924.8487949371338, \"max\": 924.8487949371338}}}\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1440.1099459070715 records/second\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.4425301118330522\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] Epoch[118] Batch[0] avg_epoch_loss=2.521953\n",
      "[05/21/2025 16:19:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.5219528675079346\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] Epoch[118] Batch[5] avg_epoch_loss=2.487997\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.4879966576894126\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] Epoch[118] Batch [5]#011Speed: 2144.68 samples/sec#011loss=2.487997\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] Epoch[118] Batch[10] avg_epoch_loss=2.484834\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.4810391426086427\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] Epoch[118] Batch [10]#011Speed: 2055.71 samples/sec#011loss=2.481039\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] processed a total of 1332 examples\n",
      "#metrics {\"StartTime\": 1747844362.531238, \"EndTime\": 1747844363.4621613, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.6051731109619, \"count\": 1, \"min\": 930.6051731109619, \"max\": 930.6051731109619}}}\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.188066253392 records/second\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.484834150834517\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] Epoch[119] Batch[0] avg_epoch_loss=2.501423\n",
      "[05/21/2025 16:19:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.5014233589172363\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] Epoch[119] Batch[5] avg_epoch_loss=2.359029\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.3590290546417236\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] Epoch[119] Batch [5]#011Speed: 2114.87 samples/sec#011loss=2.359029\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747844363.4622195, \"EndTime\": 1747844364.3291228, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 866.5966987609863, \"count\": 1, \"min\": 866.5966987609863, \"max\": 866.5966987609863}}}\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1454.931343915868 records/second\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.359263563156128\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] Epoch[120] Batch[0] avg_epoch_loss=2.391076\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.39107608795166\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] Epoch[120] Batch[5] avg_epoch_loss=2.422777\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.422776738802592\n",
      "[05/21/2025 16:19:24 INFO 140328105305920] Epoch[120] Batch [5]#011Speed: 2198.38 samples/sec#011loss=2.422777\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] Epoch[120] Batch[10] avg_epoch_loss=2.408092\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=2.3904700756072996\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] Epoch[120] Batch [10]#011Speed: 2022.39 samples/sec#011loss=2.390470\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747844364.329191, \"EndTime\": 1747844365.2576568, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.0266761779785, \"count\": 1, \"min\": 928.0266761779785, \"max\": 928.0266761779785}}}\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1416.8540885627929 records/second\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.408091891895641\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] Epoch[121] Batch[0] avg_epoch_loss=2.414685\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.414684772491455\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] Epoch[121] Batch[5] avg_epoch_loss=2.488867\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.488867481549581\n",
      "[05/21/2025 16:19:25 INFO 140328105305920] Epoch[121] Batch [5]#011Speed: 2149.32 samples/sec#011loss=2.488867\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] Epoch[121] Batch[10] avg_epoch_loss=2.510795\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=2.5371081829071045\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] Epoch[121] Batch [10]#011Speed: 2063.11 samples/sec#011loss=2.537108\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] processed a total of 1366 examples\n",
      "#metrics {\"StartTime\": 1747844365.2577128, \"EndTime\": 1747844366.1901793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.2206974029541, \"count\": 1, \"min\": 932.2206974029541, \"max\": 932.2206974029541}}}\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1465.1803502724156 records/second\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.510795073075728\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] Epoch[122] Batch[0] avg_epoch_loss=2.438099\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.4380991458892822\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] Epoch[122] Batch[5] avg_epoch_loss=2.390530\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.39052951335907\n",
      "[05/21/2025 16:19:26 INFO 140328105305920] Epoch[122] Batch [5]#011Speed: 2140.83 samples/sec#011loss=2.390530\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] Epoch[122] Batch[10] avg_epoch_loss=2.378257\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=2.3635307788848876\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] Epoch[122] Batch [10]#011Speed: 1964.00 samples/sec#011loss=2.363531\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] processed a total of 1409 examples\n",
      "#metrics {\"StartTime\": 1747844366.1902387, \"EndTime\": 1747844367.1933372, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1002.8350353240967, \"count\": 1, \"min\": 1002.8350353240967, \"max\": 1002.8350353240967}}}\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1404.8938137857438 records/second\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.4166356523831687\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] Epoch[123] Batch[0] avg_epoch_loss=2.465710\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.465710401535034\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] Epoch[123] Batch[5] avg_epoch_loss=2.415783\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.415782928466797\n",
      "[05/21/2025 16:19:27 INFO 140328105305920] Epoch[123] Batch [5]#011Speed: 2167.97 samples/sec#011loss=2.415783\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] Epoch[123] Batch[10] avg_epoch_loss=2.387924\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=2.3544943809509276\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] Epoch[123] Batch [10]#011Speed: 2073.64 samples/sec#011loss=2.354494\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747844367.193395, \"EndTime\": 1747844368.1176212, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.9192008972168, \"count\": 1, \"min\": 923.9192008972168, \"max\": 923.9192008972168}}}\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1468.6101318806702 records/second\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 31.0 % of epochs\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.3879244977777656\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] Epoch[124] Batch[0] avg_epoch_loss=2.412093\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.412093162536621\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] Epoch[124] Batch[5] avg_epoch_loss=2.385314\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.385314146677653\n",
      "[05/21/2025 16:19:28 INFO 140328105305920] Epoch[124] Batch [5]#011Speed: 2161.77 samples/sec#011loss=2.385314\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[124] Batch[10] avg_epoch_loss=2.409338\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=2.4381657600402833\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[124] Batch [10]#011Speed: 2191.12 samples/sec#011loss=2.438166\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747844368.1176796, \"EndTime\": 1747844369.023939, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.012773513794, \"count\": 1, \"min\": 906.012773513794, \"max\": 906.012773513794}}}\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.904095816299 records/second\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 31.25 % of epochs\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.4093376072970303\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[125] Batch[0] avg_epoch_loss=2.421747\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.4217472076416016\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[125] Batch[5] avg_epoch_loss=2.365662\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.3656618197758994\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[125] Batch [5]#011Speed: 2254.09 samples/sec#011loss=2.365662\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[125] Batch[10] avg_epoch_loss=2.243230\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=2.096311259269714\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Epoch[125] Batch [10]#011Speed: 2177.57 samples/sec#011loss=2.096311\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747844369.0239944, \"EndTime\": 1747844369.9255493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 901.3078212738037, \"count\": 1, \"min\": 901.3078212738037, \"max\": 901.3078212738037}}}\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1421.1334580186774 records/second\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 31.5 % of epochs\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.2432297468185425\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:29 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_19b92750-1c29-430d-bb51-434f2547cfca-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844369.9256067, \"EndTime\": 1747844369.9359908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.117769241333008, \"count\": 1, \"min\": 10.117769241333008, \"max\": 10.117769241333008}}}\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] Epoch[126] Batch[0] avg_epoch_loss=2.417030\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.4170303344726562\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] Epoch[126] Batch[5] avg_epoch_loss=2.414675\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.4146751165390015\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] Epoch[126] Batch [5]#011Speed: 2133.83 samples/sec#011loss=2.414675\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] Epoch[126] Batch[10] avg_epoch_loss=2.431236\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=2.451109790802002\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] Epoch[126] Batch [10]#011Speed: 2073.56 samples/sec#011loss=2.451110\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747844369.9360435, \"EndTime\": 1747844370.8768215, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.7308101654053, \"count\": 1, \"min\": 940.7308101654053, \"max\": 940.7308101654053}}}\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1421.1119381539127 records/second\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 31.75 % of epochs\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.4312363321130928\n",
      "[05/21/2025 16:19:30 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] Epoch[127] Batch[0] avg_epoch_loss=2.418379\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.418379306793213\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] Epoch[127] Batch[5] avg_epoch_loss=2.377191\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.377190947532654\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] Epoch[127] Batch [5]#011Speed: 2134.78 samples/sec#011loss=2.377191\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] Epoch[127] Batch[10] avg_epoch_loss=2.402442\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=2.4327428340911865\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] Epoch[127] Batch [10]#011Speed: 2090.41 samples/sec#011loss=2.432743\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747844370.8768773, \"EndTime\": 1747844371.804797, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.1972179412842, \"count\": 1, \"min\": 927.1972179412842, \"max\": 927.1972179412842}}}\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.2599416245168 records/second\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 32.0 % of epochs\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.4024418050592597\n",
      "[05/21/2025 16:19:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] Epoch[128] Batch[0] avg_epoch_loss=2.349715\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.349715232849121\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] Epoch[128] Batch[5] avg_epoch_loss=2.406762\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.40676216284434\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] Epoch[128] Batch [5]#011Speed: 2156.42 samples/sec#011loss=2.406762\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] Epoch[128] Batch[10] avg_epoch_loss=2.455539\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=2.5140711307525634\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] Epoch[128] Batch [10]#011Speed: 2124.96 samples/sec#011loss=2.514071\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844371.8048542, \"EndTime\": 1747844372.725425, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.3290939331055, \"count\": 1, \"min\": 920.3290939331055, \"max\": 920.3290939331055}}}\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.9331996746603 records/second\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 32.25 % of epochs\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.455538966438987\n",
      "[05/21/2025 16:19:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[129] Batch[0] avg_epoch_loss=2.328143\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.328143358230591\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[129] Batch[5] avg_epoch_loss=2.427358\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.4273579518000283\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[129] Batch [5]#011Speed: 2212.77 samples/sec#011loss=2.427358\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[129] Batch[10] avg_epoch_loss=2.429665\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=2.4324339866638183\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[129] Batch [10]#011Speed: 2086.24 samples/sec#011loss=2.432434\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844372.725503, \"EndTime\": 1747844373.6418812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.118860244751, \"count\": 1, \"min\": 916.118860244751, \"max\": 916.118860244751}}}\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1436.3669791713019 records/second\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 32.5 % of epochs\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.4296652403744785\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] Epoch[130] Batch[0] avg_epoch_loss=2.547657\n",
      "[05/21/2025 16:19:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.547656774520874\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] Epoch[130] Batch[5] avg_epoch_loss=2.461944\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.4619439442952475\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] Epoch[130] Batch [5]#011Speed: 2193.13 samples/sec#011loss=2.461944\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] Epoch[130] Batch[10] avg_epoch_loss=2.477146\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=2.495387601852417\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] Epoch[130] Batch [10]#011Speed: 2100.79 samples/sec#011loss=2.495388\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844373.6419353, \"EndTime\": 1747844374.5580904, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.9159660339355, \"count\": 1, \"min\": 915.9159660339355, \"max\": 915.9159660339355}}}\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1474.8894722677283 records/second\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 32.75 % of epochs\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.4771456068212334\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] Epoch[131] Batch[0] avg_epoch_loss=2.453865\n",
      "[05/21/2025 16:19:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.4538650512695312\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] Epoch[131] Batch[5] avg_epoch_loss=2.459543\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.459542989730835\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] Epoch[131] Batch [5]#011Speed: 2181.17 samples/sec#011loss=2.459543\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] Epoch[131] Batch[10] avg_epoch_loss=2.429714\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=2.393918180465698\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] Epoch[131] Batch [10]#011Speed: 2182.44 samples/sec#011loss=2.393918\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747844374.5581474, \"EndTime\": 1747844375.4691663, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.771369934082, \"count\": 1, \"min\": 910.771369934082, \"max\": 910.771369934082}}}\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1408.5688037133314 records/second\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 33.0 % of epochs\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.4297135309739546\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] Epoch[132] Batch[0] avg_epoch_loss=2.365893\n",
      "[05/21/2025 16:19:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.3658928871154785\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] Epoch[132] Batch[5] avg_epoch_loss=2.381746\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.381745934486389\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] Epoch[132] Batch [5]#011Speed: 2215.01 samples/sec#011loss=2.381746\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] Epoch[132] Batch[10] avg_epoch_loss=2.411666\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=2.447569465637207\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] Epoch[132] Batch [10]#011Speed: 1995.39 samples/sec#011loss=2.447569\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747844375.4692218, \"EndTime\": 1747844376.4269218, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.4384689331055, \"count\": 1, \"min\": 957.4384689331055, \"max\": 957.4384689331055}}}\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.981642019378 records/second\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 33.25 % of epochs\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.4116657213731245\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] Epoch[133] Batch[0] avg_epoch_loss=2.469029\n",
      "[05/21/2025 16:19:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.4690287113189697\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[133] Batch[5] avg_epoch_loss=2.397215\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.397215207417806\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[133] Batch [5]#011Speed: 2234.74 samples/sec#011loss=2.397215\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[133] Batch[10] avg_epoch_loss=2.508304\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=2.641610527038574\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[133] Batch [10]#011Speed: 2154.76 samples/sec#011loss=2.641611\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747844376.4269767, \"EndTime\": 1747844377.3364787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.8075160980225, \"count\": 1, \"min\": 908.8075160980225, \"max\": 908.8075160980225}}}\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.0209838451226 records/second\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 33.5 % of epochs\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.50830398906361\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[134] Batch[0] avg_epoch_loss=2.650060\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.650059700012207\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[134] Batch[5] avg_epoch_loss=2.730564\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.7305637200673423\n",
      "[05/21/2025 16:19:37 INFO 140328105305920] Epoch[134] Batch [5]#011Speed: 2197.51 samples/sec#011loss=2.730564\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] Epoch[134] Batch[10] avg_epoch_loss=2.793463\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.868942928314209\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] Epoch[134] Batch [10]#011Speed: 2066.22 samples/sec#011loss=2.868943\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747844377.336592, \"EndTime\": 1747844378.275621, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.7617111206055, \"count\": 1, \"min\": 938.7617111206055, \"max\": 938.7617111206055}}}\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.4073423780894 records/second\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 33.75 % of epochs\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.793463360179554\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] Epoch[135] Batch[0] avg_epoch_loss=2.774531\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.774531126022339\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] Epoch[135] Batch[5] avg_epoch_loss=2.711623\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.711622953414917\n",
      "[05/21/2025 16:19:38 INFO 140328105305920] Epoch[135] Batch [5]#011Speed: 2069.68 samples/sec#011loss=2.711623\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] Epoch[135] Batch[10] avg_epoch_loss=2.593354\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=2.451430559158325\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] Epoch[135] Batch [10]#011Speed: 2169.49 samples/sec#011loss=2.451431\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747844378.2756808, \"EndTime\": 1747844379.2010014, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0121116638184, \"count\": 1, \"min\": 925.0121116638184, \"max\": 925.0121116638184}}}\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1421.4707447637884 records/second\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 34.0 % of epochs\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.593353683298284\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] Epoch[136] Batch[0] avg_epoch_loss=2.554748\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.554748058319092\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] Epoch[136] Batch[5] avg_epoch_loss=2.508444\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.508443911870321\n",
      "[05/21/2025 16:19:39 INFO 140328105305920] Epoch[136] Batch [5]#011Speed: 2201.54 samples/sec#011loss=2.508444\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] Epoch[136] Batch[10] avg_epoch_loss=2.484134\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=2.4549629211425783\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] Epoch[136] Batch [10]#011Speed: 2053.47 samples/sec#011loss=2.454963\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747844379.2010598, \"EndTime\": 1747844380.1239307, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.6226806640625, \"count\": 1, \"min\": 922.6226806640625, \"max\": 922.6226806640625}}}\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1468.494796442817 records/second\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 34.25 % of epochs\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.4841343706304375\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] Epoch[137] Batch[0] avg_epoch_loss=2.371437\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.3714370727539062\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] Epoch[137] Batch[5] avg_epoch_loss=2.483833\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.4838332335154214\n",
      "[05/21/2025 16:19:40 INFO 140328105305920] Epoch[137] Batch [5]#011Speed: 2180.20 samples/sec#011loss=2.483833\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[137] Batch[10] avg_epoch_loss=2.466566\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=2.44584584236145\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[137] Batch [10]#011Speed: 2181.58 samples/sec#011loss=2.445846\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] processed a total of 1292 examples\n",
      "#metrics {\"StartTime\": 1747844380.123993, \"EndTime\": 1747844381.0340328, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.7566604614258, \"count\": 1, \"min\": 909.7566604614258, \"max\": 909.7566604614258}}}\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1420.0278678700083 records/second\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 34.5 % of epochs\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.4665662375363437\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[138] Batch[0] avg_epoch_loss=2.572862\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.572862148284912\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[138] Batch[5] avg_epoch_loss=2.456529\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.4565288623174033\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[138] Batch [5]#011Speed: 2124.23 samples/sec#011loss=2.456529\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[138] Batch[10] avg_epoch_loss=2.384054\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.2970836877822878\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] Epoch[138] Batch [10]#011Speed: 2150.05 samples/sec#011loss=2.297084\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747844381.0340903, \"EndTime\": 1747844381.9606528, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.3174533843994, \"count\": 1, \"min\": 926.3174533843994, \"max\": 926.3174533843994}}}\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1384.9281443767788 records/second\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 34.75 % of epochs\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.3840537829832598\n",
      "[05/21/2025 16:19:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] Epoch[139] Batch[0] avg_epoch_loss=2.294175\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.294175386428833\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] Epoch[139] Batch[5] avg_epoch_loss=2.425527\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.4255266586939492\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] Epoch[139] Batch [5]#011Speed: 2169.39 samples/sec#011loss=2.425527\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] Epoch[139] Batch[10] avg_epoch_loss=2.443351\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=2.4647404670715334\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] Epoch[139] Batch [10]#011Speed: 2022.68 samples/sec#011loss=2.464740\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747844381.9607098, \"EndTime\": 1747844382.892108, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.1282634735107, \"count\": 1, \"min\": 931.1282634735107, \"max\": 931.1282634735107}}}\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1442.2158119762064 records/second\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 35.0 % of epochs\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.4433511170473965\n",
      "[05/21/2025 16:19:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] Epoch[140] Batch[0] avg_epoch_loss=2.347186\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.3471856117248535\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] Epoch[140] Batch[5] avg_epoch_loss=2.360451\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.3604511817296348\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] Epoch[140] Batch [5]#011Speed: 2189.74 samples/sec#011loss=2.360451\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747844382.8921585, \"EndTime\": 1747844383.743627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 851.2370586395264, \"count\": 1, \"min\": 851.2370586395264, \"max\": 851.2370586395264}}}\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1495.3102004352052 records/second\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 35.25 % of epochs\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.4053548336029054\n",
      "[05/21/2025 16:19:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] Epoch[141] Batch[0] avg_epoch_loss=2.371131\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.3711307048797607\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] Epoch[141] Batch[5] avg_epoch_loss=2.421040\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.421039859453837\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] Epoch[141] Batch [5]#011Speed: 2110.52 samples/sec#011loss=2.421040\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] Epoch[141] Batch[10] avg_epoch_loss=2.392971\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=2.3592894077301025\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] Epoch[141] Batch [10]#011Speed: 1970.81 samples/sec#011loss=2.359289\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747844383.7436879, \"EndTime\": 1747844384.689682, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 945.6679821014404, \"count\": 1, \"min\": 945.6679821014404, \"max\": 945.6679821014404}}}\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1441.184974844716 records/second\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 35.5 % of epochs\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.392971472306685\n",
      "[05/21/2025 16:19:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[142] Batch[0] avg_epoch_loss=2.446964\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.4469635486602783\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[142] Batch[5] avg_epoch_loss=2.346366\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.3463656504948935\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[142] Batch [5]#011Speed: 2154.14 samples/sec#011loss=2.346366\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[142] Batch[10] avg_epoch_loss=2.423116\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=2.515215349197388\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[142] Batch [10]#011Speed: 2133.13 samples/sec#011loss=2.515215\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747844384.689736, \"EndTime\": 1747844385.6100914, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.1090335845947, \"count\": 1, \"min\": 920.1090335845947, \"max\": 920.1090335845947}}}\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.217852517075 records/second\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 35.75 % of epochs\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.423115513541482\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] Epoch[143] Batch[0] avg_epoch_loss=2.285443\n",
      "[05/21/2025 16:19:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.28544282913208\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] Epoch[143] Batch[5] avg_epoch_loss=2.349302\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.3493016560872397\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] Epoch[143] Batch [5]#011Speed: 2199.19 samples/sec#011loss=2.349302\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] Epoch[143] Batch[10] avg_epoch_loss=2.358295\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=2.369087505340576\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] Epoch[143] Batch [10]#011Speed: 2025.78 samples/sec#011loss=2.369088\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747844385.6101494, \"EndTime\": 1747844386.5410168, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.5815696716309, \"count\": 1, \"min\": 930.5815696716309, \"max\": 930.5815696716309}}}\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1420.4888973827037 records/second\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 36.0 % of epochs\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.3582952239296655\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] Epoch[144] Batch[0] avg_epoch_loss=2.358984\n",
      "[05/21/2025 16:19:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.3589842319488525\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] Epoch[144] Batch[5] avg_epoch_loss=2.312392\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.312392274538676\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] Epoch[144] Batch [5]#011Speed: 2252.80 samples/sec#011loss=2.312392\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] Epoch[144] Batch[10] avg_epoch_loss=2.324947\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=2.3400121212005613\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] Epoch[144] Batch [10]#011Speed: 2011.85 samples/sec#011loss=2.340012\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747844386.541074, \"EndTime\": 1747844387.4583712, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.0527458190918, \"count\": 1, \"min\": 917.0527458190918, \"max\": 917.0527458190918}}}\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1477.4181533267165 records/second\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 36.25 % of epochs\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.3249467502940786\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] Epoch[145] Batch[0] avg_epoch_loss=2.254450\n",
      "[05/21/2025 16:19:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.2544500827789307\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Epoch[145] Batch[5] avg_epoch_loss=2.325000\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.3250003258387246\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Epoch[145] Batch [5]#011Speed: 2166.85 samples/sec#011loss=2.325000\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Epoch[145] Batch[10] avg_epoch_loss=2.219018\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=2.0918401002883913\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Epoch[145] Batch [10]#011Speed: 2096.99 samples/sec#011loss=2.091840\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747844387.4584293, \"EndTime\": 1747844388.385219, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.5437126159668, \"count\": 1, \"min\": 926.5437126159668, \"max\": 926.5437126159668}}}\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1391.0475316657785 records/second\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 36.5 % of epochs\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.219018405134028\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_58058a4e-ff5f-4df2-915b-edd635c6a423-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844388.3852844, \"EndTime\": 1747844388.3954344, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.791135787963867, \"count\": 1, \"min\": 9.791135787963867, \"max\": 9.791135787963867}}}\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] Epoch[146] Batch[0] avg_epoch_loss=2.407546\n",
      "[05/21/2025 16:19:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.407546043395996\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] Epoch[146] Batch[5] avg_epoch_loss=2.369877\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.3698767820994058\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] Epoch[146] Batch [5]#011Speed: 1999.56 samples/sec#011loss=2.369877\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747844388.3954928, \"EndTime\": 1747844389.279679, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 884.0987682342529, \"count\": 1, \"min\": 884.0987682342529, \"max\": 884.0987682342529}}}\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1441.9960707184393 records/second\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 36.75 % of epochs\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.343180537223816\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] Epoch[147] Batch[0] avg_epoch_loss=2.315478\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=2.3154780864715576\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] Epoch[147] Batch[5] avg_epoch_loss=2.337687\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=2.337686816851298\n",
      "[05/21/2025 16:19:49 INFO 140328105305920] Epoch[147] Batch [5]#011Speed: 2150.44 samples/sec#011loss=2.337687\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747844389.2797408, \"EndTime\": 1747844390.138001, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 857.9027652740479, \"count\": 1, \"min\": 857.9027652740479, \"max\": 857.9027652740479}}}\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1491.854273314508 records/second\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 37.0 % of epochs\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.355016088485718\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] Epoch[148] Batch[0] avg_epoch_loss=2.266876\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.266876459121704\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] Epoch[148] Batch[5] avg_epoch_loss=2.318702\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.31870174407959\n",
      "[05/21/2025 16:19:50 INFO 140328105305920] Epoch[148] Batch [5]#011Speed: 2155.68 samples/sec#011loss=2.318702\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[148] Batch[10] avg_epoch_loss=2.435118\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=2.5748181343078613\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[148] Batch [10]#011Speed: 2077.20 samples/sec#011loss=2.574818\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747844390.1380603, \"EndTime\": 1747844391.066178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.8314113616943, \"count\": 1, \"min\": 927.8314113616943, \"max\": 927.8314113616943}}}\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1447.3325530909547 records/second\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 37.25 % of epochs\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.4351182850924404\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[149] Batch[0] avg_epoch_loss=2.403487\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.403486967086792\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[149] Batch[5] avg_epoch_loss=2.398267\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.398266832033793\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[149] Batch [5]#011Speed: 2213.14 samples/sec#011loss=2.398267\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[149] Batch[10] avg_epoch_loss=2.329826\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=2.247696280479431\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] Epoch[149] Batch [10]#011Speed: 2200.67 samples/sec#011loss=2.247696\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747844391.0662334, \"EndTime\": 1747844391.9726436, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.1710834503174, \"count\": 1, \"min\": 906.1710834503174, \"max\": 906.1710834503174}}}\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1416.8201313932675 records/second\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 37.5 % of epochs\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.329825672236356\n",
      "[05/21/2025 16:19:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] Epoch[150] Batch[0] avg_epoch_loss=2.217197\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.2171974182128906\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] Epoch[150] Batch[5] avg_epoch_loss=2.317984\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.317983786265055\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] Epoch[150] Batch [5]#011Speed: 2168.89 samples/sec#011loss=2.317984\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] Epoch[150] Batch[10] avg_epoch_loss=2.377537\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=2.448999834060669\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] Epoch[150] Batch [10]#011Speed: 2046.51 samples/sec#011loss=2.449000\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747844391.9726996, \"EndTime\": 1747844392.9014053, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.4634590148926, \"count\": 1, \"min\": 928.4634590148926, \"max\": 928.4634590148926}}}\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1450.62203567778 records/second\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 37.75 % of epochs\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.3775365352630615\n",
      "[05/21/2025 16:19:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] Epoch[151] Batch[0] avg_epoch_loss=2.441972\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.44197154045105\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] Epoch[151] Batch[5] avg_epoch_loss=2.314077\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.314076542854309\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] Epoch[151] Batch [5]#011Speed: 2141.88 samples/sec#011loss=2.314077\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] Epoch[151] Batch[10] avg_epoch_loss=2.333195\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=2.3561376571655273\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] Epoch[151] Batch [10]#011Speed: 1978.83 samples/sec#011loss=2.356138\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747844392.9014828, \"EndTime\": 1747844393.843166, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.4339065551758, \"count\": 1, \"min\": 941.4339065551758, \"max\": 941.4339065551758}}}\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1439.1706250547606 records/second\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 38.0 % of epochs\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.3331952311775903\n",
      "[05/21/2025 16:19:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] Epoch[152] Batch[0] avg_epoch_loss=2.293791\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.2937912940979004\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] Epoch[152] Batch[5] avg_epoch_loss=2.350782\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.350781520207723\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] Epoch[152] Batch [5]#011Speed: 2168.28 samples/sec#011loss=2.350782\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] Epoch[152] Batch[10] avg_epoch_loss=2.325568\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=2.2953118801116945\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] Epoch[152] Batch [10]#011Speed: 2053.05 samples/sec#011loss=2.295312\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747844393.843221, \"EndTime\": 1747844394.7661674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.6915836334229, \"count\": 1, \"min\": 922.6915836334229, \"max\": 922.6915836334229}}}\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.7392681698614 records/second\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 38.25 % of epochs\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.325568047436801\n",
      "[05/21/2025 16:19:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] Epoch[153] Batch[0] avg_epoch_loss=2.324811\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.324810743331909\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] Epoch[153] Batch[5] avg_epoch_loss=2.302463\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.302462895711263\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] Epoch[153] Batch [5]#011Speed: 2127.35 samples/sec#011loss=2.302463\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] Epoch[153] Batch[10] avg_epoch_loss=2.375377\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=2.4628739833831785\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] Epoch[153] Batch [10]#011Speed: 2121.47 samples/sec#011loss=2.462874\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844394.7662199, \"EndTime\": 1747844395.6919198, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.4100322723389, \"count\": 1, \"min\": 925.4100322723389, \"max\": 925.4100322723389}}}\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1401.413076648621 records/second\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 38.5 % of epochs\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.3753770264712246\n",
      "[05/21/2025 16:19:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[154] Batch[0] avg_epoch_loss=2.229473\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.229473352432251\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[154] Batch[5] avg_epoch_loss=2.354401\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.3544007539749146\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[154] Batch [5]#011Speed: 2189.82 samples/sec#011loss=2.354401\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[154] Batch[10] avg_epoch_loss=2.326115\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=2.292171812057495\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[154] Batch [10]#011Speed: 1955.53 samples/sec#011loss=2.292172\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747844395.6919768, \"EndTime\": 1747844396.6313827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.1193389892578, \"count\": 1, \"min\": 939.1193389892578, \"max\": 939.1193389892578}}}\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1445.8873054377416 records/second\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 38.75 % of epochs\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.3261148712851782\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] Epoch[155] Batch[0] avg_epoch_loss=2.332606\n",
      "[05/21/2025 16:19:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.332606077194214\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] Epoch[155] Batch[5] avg_epoch_loss=2.313935\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.3139353593190513\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] Epoch[155] Batch [5]#011Speed: 2183.25 samples/sec#011loss=2.313935\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] Epoch[155] Batch[10] avg_epoch_loss=2.366865\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=2.430380344390869\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] Epoch[155] Batch [10]#011Speed: 1946.59 samples/sec#011loss=2.430380\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844396.631449, \"EndTime\": 1747844397.573259, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.5557384490967, \"count\": 1, \"min\": 941.5557384490967, \"max\": 941.5557384490967}}}\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.7277776891597 records/second\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 39.0 % of epochs\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.366864897988059\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] Epoch[156] Batch[0] avg_epoch_loss=2.257180\n",
      "[05/21/2025 16:19:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.2571797370910645\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] Epoch[156] Batch[5] avg_epoch_loss=2.301977\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.3019769191741943\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] Epoch[156] Batch [5]#011Speed: 2219.14 samples/sec#011loss=2.301977\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] Epoch[156] Batch[10] avg_epoch_loss=2.288552\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=2.2724430084228517\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] Epoch[156] Batch [10]#011Speed: 2092.72 samples/sec#011loss=2.272443\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844397.5733168, \"EndTime\": 1747844398.4893532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.7545566558838, \"count\": 1, \"min\": 915.7545566558838, \"max\": 915.7545566558838}}}\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1436.9375926933012 records/second\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 39.25 % of epochs\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.2885524142872202\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] Epoch[157] Batch[0] avg_epoch_loss=2.256745\n",
      "[05/21/2025 16:19:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.256744861602783\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] Epoch[157] Batch[5] avg_epoch_loss=2.297895\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.297894597053528\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] Epoch[157] Batch [5]#011Speed: 2165.05 samples/sec#011loss=2.297895\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] Epoch[157] Batch[10] avg_epoch_loss=2.368222\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=2.452614974975586\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] Epoch[157] Batch [10]#011Speed: 2140.56 samples/sec#011loss=2.452615\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747844398.489408, \"EndTime\": 1747844399.4057562, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.0046577453613, \"count\": 1, \"min\": 916.0046577453613, \"max\": 916.0046577453613}}}\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.0723111749376 records/second\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 39.5 % of epochs\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.368222041563554\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] Epoch[158] Batch[0] avg_epoch_loss=2.303841\n",
      "[05/21/2025 16:19:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.3038413524627686\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] Epoch[158] Batch[5] avg_epoch_loss=2.329891\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.3298914432525635\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] Epoch[158] Batch [5]#011Speed: 1943.29 samples/sec#011loss=2.329891\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] Epoch[158] Batch[10] avg_epoch_loss=2.315077\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=2.2972986698150635\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] Epoch[158] Batch [10]#011Speed: 2022.37 samples/sec#011loss=2.297299\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747844399.405815, \"EndTime\": 1747844400.3730314, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 966.963529586792, \"count\": 1, \"min\": 966.963529586792, \"max\": 966.963529586792}}}\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1393.9326337111518 records/second\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 39.75 % of epochs\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.315076546235518\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] Epoch[159] Batch[0] avg_epoch_loss=2.270633\n",
      "[05/21/2025 16:20:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.2706334590911865\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] Epoch[159] Batch[5] avg_epoch_loss=2.261721\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.26172137260437\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] Epoch[159] Batch [5]#011Speed: 2126.55 samples/sec#011loss=2.261721\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747844400.373087, \"EndTime\": 1747844401.3119347, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.5759830474854, \"count\": 1, \"min\": 938.5759830474854, \"max\": 938.5759830474854}}}\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1348.668958477418 records/second\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 40.0 % of epochs\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.2646661043167113\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] Epoch[160] Batch[0] avg_epoch_loss=2.348164\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.3481638431549072\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] Epoch[160] Batch[5] avg_epoch_loss=2.294722\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.2947216828664145\n",
      "[05/21/2025 16:20:01 INFO 140328105305920] Epoch[160] Batch [5]#011Speed: 2083.61 samples/sec#011loss=2.294722\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] Epoch[160] Batch[10] avg_epoch_loss=2.336715\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=2.387107276916504\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] Epoch[160] Batch [10]#011Speed: 1928.41 samples/sec#011loss=2.387107\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747844401.3120098, \"EndTime\": 1747844402.275074, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 962.7559185028076, \"count\": 1, \"min\": 962.7559185028076, \"max\": 962.7559185028076}}}\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1398.9751302223908 records/second\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 40.25 % of epochs\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.3367151347073642\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] Epoch[161] Batch[0] avg_epoch_loss=2.268247\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.268247365951538\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] Epoch[161] Batch[5] avg_epoch_loss=2.298446\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.2984460592269897\n",
      "[05/21/2025 16:20:02 INFO 140328105305920] Epoch[161] Batch [5]#011Speed: 2100.87 samples/sec#011loss=2.298446\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] Epoch[161] Batch[10] avg_epoch_loss=2.327358\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=2.3620516777038576\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] Epoch[161] Batch [10]#011Speed: 2046.85 samples/sec#011loss=2.362052\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747844402.2751353, \"EndTime\": 1747844403.213976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.4911060333252, \"count\": 1, \"min\": 938.4911060333252, \"max\": 938.4911060333252}}}\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.1368771533746 records/second\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 40.5 % of epochs\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.327357703989202\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] Epoch[162] Batch[0] avg_epoch_loss=2.417369\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.4173688888549805\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] Epoch[162] Batch[5] avg_epoch_loss=2.295865\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.295864741007487\n",
      "[05/21/2025 16:20:03 INFO 140328105305920] Epoch[162] Batch [5]#011Speed: 2180.73 samples/sec#011loss=2.295865\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] Epoch[162] Batch[10] avg_epoch_loss=2.248915\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=2.1925751209259032\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] Epoch[162] Batch [10]#011Speed: 2114.07 samples/sec#011loss=2.192575\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747844403.2140713, \"EndTime\": 1747844404.1330788, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.7510013580322, \"count\": 1, \"min\": 918.7510013580322, \"max\": 918.7510013580322}}}\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.071521798585 records/second\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 40.75 % of epochs\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.2489149136976763\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] Epoch[163] Batch[0] avg_epoch_loss=2.490334\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.4903335571289062\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] Epoch[163] Batch[5] avg_epoch_loss=2.364074\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.364073872566223\n",
      "[05/21/2025 16:20:04 INFO 140328105305920] Epoch[163] Batch [5]#011Speed: 2198.75 samples/sec#011loss=2.364074\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[163] Batch[10] avg_epoch_loss=2.368072\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=2.372869110107422\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[163] Batch [10]#011Speed: 2126.06 samples/sec#011loss=2.372869\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844404.1331353, \"EndTime\": 1747844405.0415404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.1623554229736, \"count\": 1, \"min\": 908.1623554229736, \"max\": 908.1623554229736}}}\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1476.472555289347 records/second\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 41.0 % of epochs\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.3680717078122226\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[164] Batch[0] avg_epoch_loss=2.546010\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.5460095405578613\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[164] Batch[5] avg_epoch_loss=2.472324\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.4723244508107505\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[164] Batch [5]#011Speed: 2164.59 samples/sec#011loss=2.472324\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[164] Batch[10] avg_epoch_loss=2.455597\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=2.4355239868164062\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] Epoch[164] Batch [10]#011Speed: 2062.03 samples/sec#011loss=2.435524\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747844405.0415957, \"EndTime\": 1747844405.9799225, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.0800724029541, \"count\": 1, \"min\": 938.0800724029541, \"max\": 938.0800724029541}}}\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1388.8893267905605 records/second\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 41.25 % of epochs\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.4555969671769575\n",
      "[05/21/2025 16:20:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] Epoch[165] Batch[0] avg_epoch_loss=2.422015\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.4220149517059326\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] Epoch[165] Batch[5] avg_epoch_loss=2.470610\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.4706103404363\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] Epoch[165] Batch [5]#011Speed: 2063.80 samples/sec#011loss=2.470610\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] processed a total of 1243 examples\n",
      "#metrics {\"StartTime\": 1747844405.9799762, \"EndTime\": 1747844406.8497722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 869.5247173309326, \"count\": 1, \"min\": 869.5247173309326, \"max\": 869.5247173309326}}}\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.3637298039914 records/second\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 41.5 % of epochs\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.471579337120056\n",
      "[05/21/2025 16:20:06 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] Epoch[166] Batch[0] avg_epoch_loss=2.445377\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.4453771114349365\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] Epoch[166] Batch[5] avg_epoch_loss=2.368198\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.3681981960932412\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] Epoch[166] Batch [5]#011Speed: 2152.76 samples/sec#011loss=2.368198\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] Epoch[166] Batch[10] avg_epoch_loss=2.393544\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=2.423958921432495\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] Epoch[166] Batch [10]#011Speed: 2101.31 samples/sec#011loss=2.423959\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747844406.8498352, \"EndTime\": 1747844407.7766635, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.511287689209, \"count\": 1, \"min\": 926.511287689209, \"max\": 926.511287689209}}}\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1387.8764467995377 records/second\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 41.75 % of epochs\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.393543980338357\n",
      "[05/21/2025 16:20:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] Epoch[167] Batch[0] avg_epoch_loss=2.402444\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=2.4024436473846436\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] Epoch[167] Batch[5] avg_epoch_loss=2.433686\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.4336864153544107\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] Epoch[167] Batch [5]#011Speed: 2198.49 samples/sec#011loss=2.433686\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] Epoch[167] Batch[10] avg_epoch_loss=2.402691\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=2.365496015548706\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] Epoch[167] Batch [10]#011Speed: 2038.39 samples/sec#011loss=2.365496\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747844407.77672, \"EndTime\": 1747844408.7033606, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.393985748291, \"count\": 1, \"min\": 926.393985748291, \"max\": 926.393985748291}}}\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1476.541902332412 records/second\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 42.0 % of epochs\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.4026907790790903\n",
      "[05/21/2025 16:20:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[168] Batch[0] avg_epoch_loss=2.250059\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.250058889389038\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[168] Batch[5] avg_epoch_loss=2.301390\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.301389733950297\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[168] Batch [5]#011Speed: 2162.45 samples/sec#011loss=2.301390\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[168] Batch[10] avg_epoch_loss=2.328149\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=2.3602608680725097\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[168] Batch [10]#011Speed: 2164.56 samples/sec#011loss=2.360261\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844408.7034278, \"EndTime\": 1747844409.619222, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.5449867248535, \"count\": 1, \"min\": 915.5449867248535, \"max\": 915.5449867248535}}}\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.6177238578616 records/second\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 42.25 % of epochs\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.328149340369485\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] Epoch[169] Batch[0] avg_epoch_loss=2.277385\n",
      "[05/21/2025 16:20:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.2773852348327637\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] Epoch[169] Batch[5] avg_epoch_loss=2.311664\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.311663786570231\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] Epoch[169] Batch [5]#011Speed: 2043.26 samples/sec#011loss=2.311664\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] Epoch[169] Batch[10] avg_epoch_loss=2.322823\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.336214208602905\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] Epoch[169] Batch [10]#011Speed: 2060.90 samples/sec#011loss=2.336214\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844409.6192791, \"EndTime\": 1747844410.5623326, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.795991897583, \"count\": 1, \"min\": 942.795991897583, \"max\": 942.795991897583}}}\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.724105512347 records/second\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 42.5 % of epochs\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.322823069312356\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] Epoch[170] Batch[0] avg_epoch_loss=2.279757\n",
      "[05/21/2025 16:20:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.279756784439087\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] Epoch[170] Batch[5] avg_epoch_loss=2.341592\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.341592232386271\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] Epoch[170] Batch [5]#011Speed: 2140.87 samples/sec#011loss=2.341592\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] Epoch[170] Batch[10] avg_epoch_loss=2.362781\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=2.38820858001709\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] Epoch[170] Batch [10]#011Speed: 2138.32 samples/sec#011loss=2.388209\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844410.562388, \"EndTime\": 1747844411.4839475, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.3221073150635, \"count\": 1, \"min\": 921.3221073150635, \"max\": 921.3221073150635}}}\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.418887836908 records/second\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 42.75 % of epochs\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.3627814813093706\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] Epoch[171] Batch[0] avg_epoch_loss=2.455422\n",
      "[05/21/2025 16:20:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.4554216861724854\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Epoch[171] Batch[5] avg_epoch_loss=2.319022\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.319022297859192\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Epoch[171] Batch [5]#011Speed: 2234.25 samples/sec#011loss=2.319022\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Epoch[171] Batch[10] avg_epoch_loss=2.208417\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=2.0756905555725096\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Epoch[171] Batch [10]#011Speed: 1956.61 samples/sec#011loss=2.075691\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844411.484006, \"EndTime\": 1747844412.4186308, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.3786239624023, \"count\": 1, \"min\": 934.3786239624023, \"max\": 934.3786239624023}}}\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1380.4768883464033 records/second\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 43.0 % of epochs\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.2084169604561548\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_c377c09f-74f6-427d-a3d8-1176f9e2b2f7-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844412.418684, \"EndTime\": 1747844412.4296396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.692596435546875, \"count\": 1, \"min\": 10.692596435546875, \"max\": 10.692596435546875}}}\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] Epoch[172] Batch[0] avg_epoch_loss=2.423239\n",
      "[05/21/2025 16:20:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.423238515853882\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[172] Batch[5] avg_epoch_loss=2.288428\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.28842830657959\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[172] Batch [5]#011Speed: 2173.64 samples/sec#011loss=2.288428\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[172] Batch[10] avg_epoch_loss=2.252656\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=2.2097291469573976\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[172] Batch [10]#011Speed: 2157.01 samples/sec#011loss=2.209729\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844412.429689, \"EndTime\": 1747844413.3483365, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.6022281646729, \"count\": 1, \"min\": 918.6022281646729, \"max\": 918.6022281646729}}}\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1442.2815933720142 records/second\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 43.25 % of epochs\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.252655961296775\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[173] Batch[0] avg_epoch_loss=2.274303\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.274303436279297\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[173] Batch[5] avg_epoch_loss=2.435970\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.4359697898228965\n",
      "[05/21/2025 16:20:13 INFO 140328105305920] Epoch[173] Batch [5]#011Speed: 2131.28 samples/sec#011loss=2.435970\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] Epoch[173] Batch[10] avg_epoch_loss=2.412766\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=2.3849222660064697\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] Epoch[173] Batch [10]#011Speed: 1968.69 samples/sec#011loss=2.384922\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747844413.3483922, \"EndTime\": 1747844414.2910674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.4035549163818, \"count\": 1, \"min\": 942.4035549163818, \"max\": 942.4035549163818}}}\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1451.4781698013119 records/second\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 43.5 % of epochs\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.412766369906339\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] Epoch[174] Batch[0] avg_epoch_loss=2.412391\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.412391424179077\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] Epoch[174] Batch[5] avg_epoch_loss=2.328897\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.3288971980412803\n",
      "[05/21/2025 16:20:14 INFO 140328105305920] Epoch[174] Batch [5]#011Speed: 2208.13 samples/sec#011loss=2.328897\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] Epoch[174] Batch[10] avg_epoch_loss=2.325103\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=2.320550060272217\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] Epoch[174] Batch [10]#011Speed: 2099.86 samples/sec#011loss=2.320550\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844414.2911232, \"EndTime\": 1747844415.207856, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.4464473724365, \"count\": 1, \"min\": 916.4464473724365, \"max\": 916.4464473724365}}}\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.8543372539634 records/second\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 43.75 % of epochs\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.3251030445098877\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] Epoch[175] Batch[0] avg_epoch_loss=2.355162\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.3551623821258545\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] Epoch[175] Batch[5] avg_epoch_loss=2.288846\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.288846492767334\n",
      "[05/21/2025 16:20:15 INFO 140328105305920] Epoch[175] Batch [5]#011Speed: 2135.10 samples/sec#011loss=2.288846\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] Epoch[175] Batch[10] avg_epoch_loss=2.267757\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=2.242449426651001\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] Epoch[175] Batch [10]#011Speed: 2037.06 samples/sec#011loss=2.242449\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844415.2079103, \"EndTime\": 1747844416.145288, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.1261596679688, \"count\": 1, \"min\": 937.1261596679688, \"max\": 937.1261596679688}}}\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1383.8974452903838 records/second\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 44.0 % of epochs\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.2677569172599097\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] Epoch[176] Batch[0] avg_epoch_loss=2.343240\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.3432400226593018\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] Epoch[176] Batch[5] avg_epoch_loss=2.339534\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.3395336469014487\n",
      "[05/21/2025 16:20:16 INFO 140328105305920] Epoch[176] Batch [5]#011Speed: 2152.74 samples/sec#011loss=2.339534\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] Epoch[176] Batch[10] avg_epoch_loss=2.473007\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.6331750392913817\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] Epoch[176] Batch [10]#011Speed: 2017.31 samples/sec#011loss=2.633175\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844416.145343, \"EndTime\": 1747844417.0779521, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.3413372039795, \"count\": 1, \"min\": 932.3413372039795, \"max\": 932.3413372039795}}}\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1414.5905905967334 records/second\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 44.25 % of epochs\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.473007007078691\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] Epoch[177] Batch[0] avg_epoch_loss=2.520688\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.520688056945801\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] Epoch[177] Batch[5] avg_epoch_loss=2.420799\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.420799136161804\n",
      "[05/21/2025 16:20:17 INFO 140328105305920] Epoch[177] Batch [5]#011Speed: 2152.58 samples/sec#011loss=2.420799\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[177] Batch[10] avg_epoch_loss=2.454213\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=2.494310140609741\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[177] Batch [10]#011Speed: 2097.58 samples/sec#011loss=2.494310\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747844417.0780098, \"EndTime\": 1747844418.0019827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.7310886383057, \"count\": 1, \"min\": 923.7310886383057, \"max\": 923.7310886383057}}}\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1458.084121317418 records/second\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 44.5 % of epochs\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.4542132290926846\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[178] Batch[0] avg_epoch_loss=2.285871\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.2858712673187256\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[178] Batch[5] avg_epoch_loss=2.399009\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.3990089098612466\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[178] Batch [5]#011Speed: 2196.35 samples/sec#011loss=2.399009\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[178] Batch[10] avg_epoch_loss=2.385001\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=2.368190574645996\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] Epoch[178] Batch [10]#011Speed: 2059.27 samples/sec#011loss=2.368191\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747844418.002038, \"EndTime\": 1747844418.920888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.6029434204102, \"count\": 1, \"min\": 918.6029434204102, \"max\": 918.6029434204102}}}\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1469.4933095265283 records/second\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 44.75 % of epochs\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.3850005756724966\n",
      "[05/21/2025 16:20:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] Epoch[179] Batch[0] avg_epoch_loss=2.387969\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.3879690170288086\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] Epoch[179] Batch[5] avg_epoch_loss=2.327167\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.3271666367848716\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] Epoch[179] Batch [5]#011Speed: 2110.40 samples/sec#011loss=2.327167\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] Epoch[179] Batch[10] avg_epoch_loss=2.285501\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=2.235502338409424\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] Epoch[179] Batch [10]#011Speed: 2098.74 samples/sec#011loss=2.235502\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747844418.9209416, \"EndTime\": 1747844419.8644176, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.2005882263184, \"count\": 1, \"min\": 943.2005882263184, \"max\": 943.2005882263184}}}\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1405.7303712885239 records/second\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 45.0 % of epochs\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.2855010466142134\n",
      "[05/21/2025 16:20:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] Epoch[180] Batch[0] avg_epoch_loss=2.285327\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.285327196121216\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] Epoch[180] Batch[5] avg_epoch_loss=2.257989\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.2579893271128335\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] Epoch[180] Batch [5]#011Speed: 2180.65 samples/sec#011loss=2.257989\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] Epoch[180] Batch[10] avg_epoch_loss=2.232889\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=2.202767753601074\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] Epoch[180] Batch [10]#011Speed: 2046.98 samples/sec#011loss=2.202768\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] processed a total of 1327 examples\n",
      "#metrics {\"StartTime\": 1747844419.8644726, \"EndTime\": 1747844420.7927008, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.912712097168, \"count\": 1, \"min\": 927.912712097168, \"max\": 927.912712097168}}}\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.9591419795145 records/second\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 45.25 % of epochs\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.232888611880216\n",
      "[05/21/2025 16:20:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Epoch[181] Batch[0] avg_epoch_loss=2.269516\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.2695159912109375\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Epoch[181] Batch[5] avg_epoch_loss=2.252482\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.252481738726298\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Epoch[181] Batch [5]#011Speed: 2136.08 samples/sec#011loss=2.252482\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Epoch[181] Batch[10] avg_epoch_loss=2.162564\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=2.0546637535095216\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Epoch[181] Batch [10]#011Speed: 2048.83 samples/sec#011loss=2.054664\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747844420.7927585, \"EndTime\": 1747844421.7297697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.6779327392578, \"count\": 1, \"min\": 936.6779327392578, \"max\": 936.6779327392578}}}\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1389.8950456877494 records/second\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 45.5 % of epochs\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.1625644727186724\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:20:21 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_69947841-16bd-485e-b2cb-db9d973de1c1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844421.729826, \"EndTime\": 1747844421.7406147, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.52403450012207, \"count\": 1, \"min\": 10.52403450012207, \"max\": 10.52403450012207}}}\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] Epoch[182] Batch[0] avg_epoch_loss=2.342083\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.3420827388763428\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] Epoch[182] Batch[5] avg_epoch_loss=2.263306\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.263305902481079\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] Epoch[182] Batch [5]#011Speed: 2153.57 samples/sec#011loss=2.263306\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] processed a total of 1269 examples\n",
      "#metrics {\"StartTime\": 1747844421.740667, \"EndTime\": 1747844422.6060226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 865.3059005737305, \"count\": 1, \"min\": 865.3059005737305, \"max\": 865.3059005737305}}}\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1466.3855182297707 records/second\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 45.75 % of epochs\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.2542507886886596\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] Epoch[183] Batch[0] avg_epoch_loss=2.207478\n",
      "[05/21/2025 16:20:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.2074780464172363\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] Epoch[183] Batch[5] avg_epoch_loss=2.225078\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.225078026453654\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] Epoch[183] Batch [5]#011Speed: 2141.97 samples/sec#011loss=2.225078\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] Epoch[183] Batch[10] avg_epoch_loss=2.203507\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=2.177621006965637\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] Epoch[183] Batch [10]#011Speed: 2105.50 samples/sec#011loss=2.177621\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747844422.6060817, \"EndTime\": 1747844423.5309718, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.5550632476807, \"count\": 1, \"min\": 924.5550632476807, \"max\": 924.5550632476807}}}\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1448.1308847198536 records/second\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 46.0 % of epochs\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.203506653959101\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] Epoch[184] Batch[0] avg_epoch_loss=2.186476\n",
      "[05/21/2025 16:20:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.186475992202759\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] Epoch[184] Batch[5] avg_epoch_loss=2.207302\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.2073023319244385\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] Epoch[184] Batch [5]#011Speed: 2026.23 samples/sec#011loss=2.207302\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] Epoch[184] Batch[10] avg_epoch_loss=2.219013\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=2.2330652713775634\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] Epoch[184] Batch [10]#011Speed: 2034.63 samples/sec#011loss=2.233065\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844423.5310276, \"EndTime\": 1747844424.4793487, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.0772018432617, \"count\": 1, \"min\": 948.0772018432617, \"max\": 948.0772018432617}}}\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1395.332815841584 records/second\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 46.25 % of epochs\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.2190127589485864\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] Epoch[185] Batch[0] avg_epoch_loss=2.237939\n",
      "[05/21/2025 16:20:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.23793888092041\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] Epoch[185] Batch[5] avg_epoch_loss=2.235370\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.2353699604670205\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] Epoch[185] Batch [5]#011Speed: 2079.39 samples/sec#011loss=2.235370\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] Epoch[185] Batch[10] avg_epoch_loss=2.243000\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=2.2521552562713625\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] Epoch[185] Batch [10]#011Speed: 2066.28 samples/sec#011loss=2.252155\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747844424.4794044, \"EndTime\": 1747844425.4211507, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.4966106414795, \"count\": 1, \"min\": 941.4966106414795, \"max\": 941.4966106414795}}}\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1456.0616497652609 records/second\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 46.5 % of epochs\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.242999640378085\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] Epoch[186] Batch[0] avg_epoch_loss=2.120279\n",
      "[05/21/2025 16:20:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.12027907371521\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[186] Batch[5] avg_epoch_loss=2.220194\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.2201935847600303\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[186] Batch [5]#011Speed: 2151.71 samples/sec#011loss=2.220194\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[186] Batch[10] avg_epoch_loss=2.201114\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=2.178218698501587\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[186] Batch [10]#011Speed: 1977.49 samples/sec#011loss=2.178219\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] processed a total of 1396 examples\n",
      "#metrics {\"StartTime\": 1747844425.4212084, \"EndTime\": 1747844426.3611608, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.6605491638184, \"count\": 1, \"min\": 939.6605491638184, \"max\": 939.6605491638184}}}\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1485.5139695816179 records/second\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 46.75 % of epochs\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.2011140910061924\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[187] Batch[0] avg_epoch_loss=2.181596\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.18159556388855\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[187] Batch[5] avg_epoch_loss=2.202896\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.2028964360555015\n",
      "[05/21/2025 16:20:26 INFO 140328105305920] Epoch[187] Batch [5]#011Speed: 2093.34 samples/sec#011loss=2.202896\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] Epoch[187] Batch[10] avg_epoch_loss=2.198268\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=2.192714214324951\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] Epoch[187] Batch [10]#011Speed: 1876.23 samples/sec#011loss=2.192714\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747844426.361216, \"EndTime\": 1747844427.3292959, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 967.808723449707, \"count\": 1, \"min\": 967.808723449707, \"max\": 967.808723449707}}}\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1412.3018371753044 records/second\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 47.0 % of epochs\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.1982681534507056\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] Epoch[188] Batch[0] avg_epoch_loss=2.134347\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.134347438812256\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] Epoch[188] Batch[5] avg_epoch_loss=2.201319\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.2013185818990073\n",
      "[05/21/2025 16:20:27 INFO 140328105305920] Epoch[188] Batch [5]#011Speed: 2173.74 samples/sec#011loss=2.201319\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] Epoch[188] Batch[10] avg_epoch_loss=2.239240\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=2.2847452640533445\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] Epoch[188] Batch [10]#011Speed: 1993.00 samples/sec#011loss=2.284745\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] processed a total of 1350 examples\n",
      "#metrics {\"StartTime\": 1747844427.32935, \"EndTime\": 1747844428.2648692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.7455501556396, \"count\": 1, \"min\": 934.7455501556396, \"max\": 934.7455501556396}}}\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1444.1103319384397 records/second\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 47.25 % of epochs\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.23923980106007\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] Epoch[189] Batch[0] avg_epoch_loss=2.231008\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.2310078144073486\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] Epoch[189] Batch[5] avg_epoch_loss=2.198471\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.1984713474909463\n",
      "[05/21/2025 16:20:28 INFO 140328105305920] Epoch[189] Batch [5]#011Speed: 2206.14 samples/sec#011loss=2.198471\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] Epoch[189] Batch[10] avg_epoch_loss=2.192304\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=2.1849036693572996\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] Epoch[189] Batch [10]#011Speed: 2153.05 samples/sec#011loss=2.184904\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844428.2649262, \"EndTime\": 1747844429.1908998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.6927967071533, \"count\": 1, \"min\": 925.6927967071533, \"max\": 925.6927967071533}}}\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1400.984675734588 records/second\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 47.5 % of epochs\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.1923042210665615\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] Epoch[190] Batch[0] avg_epoch_loss=2.222224\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.222224235534668\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] Epoch[190] Batch[5] avg_epoch_loss=2.192694\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.1926939884821572\n",
      "[05/21/2025 16:20:29 INFO 140328105305920] Epoch[190] Batch [5]#011Speed: 2186.13 samples/sec#011loss=2.192694\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Epoch[190] Batch[10] avg_epoch_loss=2.120107\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=2.0330026865005495\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Epoch[190] Batch [10]#011Speed: 2121.16 samples/sec#011loss=2.033003\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747844429.1909564, \"EndTime\": 1747844430.1104863, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.2402362823486, \"count\": 1, \"min\": 919.2402362823486, \"max\": 919.2402362823486}}}\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1409.7297911865078 records/second\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 47.75 % of epochs\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.1201070330359717\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_f10aef95-1b23-4b6b-ae15-f314e8bd0b9a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844430.1105444, \"EndTime\": 1747844430.1209936, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.189056396484375, \"count\": 1, \"min\": 10.189056396484375, \"max\": 10.189056396484375}}}\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Epoch[191] Batch[0] avg_epoch_loss=2.220549\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.2205488681793213\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Epoch[191] Batch[5] avg_epoch_loss=2.166945\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.166945219039917\n",
      "[05/21/2025 16:20:30 INFO 140328105305920] Epoch[191] Batch [5]#011Speed: 2116.54 samples/sec#011loss=2.166945\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] Epoch[191] Batch[10] avg_epoch_loss=2.239659\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=2.326914930343628\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] Epoch[191] Batch [10]#011Speed: 2005.91 samples/sec#011loss=2.326915\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747844430.1210454, \"EndTime\": 1747844431.0632734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.1792030334473, \"count\": 1, \"min\": 942.1792030334473, \"max\": 942.1792030334473}}}\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1379.6560395998017 records/second\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 48.0 % of epochs\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.2396587241779673\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] Epoch[192] Batch[0] avg_epoch_loss=2.204095\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.204094886779785\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] Epoch[192] Batch[5] avg_epoch_loss=2.289934\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.289934237798055\n",
      "[05/21/2025 16:20:31 INFO 140328105305920] Epoch[192] Batch [5]#011Speed: 2114.91 samples/sec#011loss=2.289934\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[192] Batch[10] avg_epoch_loss=2.290091\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=2.2902793407440187\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[192] Batch [10]#011Speed: 2029.04 samples/sec#011loss=2.290279\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747844431.0633307, \"EndTime\": 1747844432.0119772, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.3954906463623, \"count\": 1, \"min\": 948.3954906463623, \"max\": 948.3954906463623}}}\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1375.8888986085178 records/second\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 48.25 % of epochs\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.290091102773493\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[193] Batch[0] avg_epoch_loss=2.268916\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.268916130065918\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[193] Batch[5] avg_epoch_loss=2.276996\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.2769957780838013\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[193] Batch [5]#011Speed: 2207.21 samples/sec#011loss=2.276996\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[193] Batch[10] avg_epoch_loss=2.300075\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=2.3277692794799805\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] Epoch[193] Batch [10]#011Speed: 2077.67 samples/sec#011loss=2.327769\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747844432.012033, \"EndTime\": 1747844432.9281142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.8389568328857, \"count\": 1, \"min\": 915.8389568328857, \"max\": 915.8389568328857}}}\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.5413621985426 records/second\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 48.5 % of epochs\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.300074642354792\n",
      "[05/21/2025 16:20:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] Epoch[194] Batch[0] avg_epoch_loss=2.224495\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.2244949340820312\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] Epoch[194] Batch[5] avg_epoch_loss=2.224732\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.2247315645217896\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] Epoch[194] Batch [5]#011Speed: 2222.23 samples/sec#011loss=2.224732\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] Epoch[194] Batch[10] avg_epoch_loss=2.236438\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=2.250484800338745\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] Epoch[194] Batch [10]#011Speed: 1968.68 samples/sec#011loss=2.250485\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] processed a total of 1375 examples\n",
      "#metrics {\"StartTime\": 1747844432.9281726, \"EndTime\": 1747844433.8730626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.6396827697754, \"count\": 1, \"min\": 944.6396827697754, \"max\": 944.6396827697754}}}\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1455.443330720493 records/second\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 48.75 % of epochs\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.236437580802224\n",
      "[05/21/2025 16:20:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] Epoch[195] Batch[0] avg_epoch_loss=2.223054\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.2230544090270996\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] Epoch[195] Batch[5] avg_epoch_loss=2.230622\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.2306220531463623\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] Epoch[195] Batch [5]#011Speed: 2103.79 samples/sec#011loss=2.230622\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] Epoch[195] Batch[10] avg_epoch_loss=2.266708\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=2.3100100994110107\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] Epoch[195] Batch [10]#011Speed: 1969.83 samples/sec#011loss=2.310010\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844433.873123, \"EndTime\": 1747844434.8271701, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 953.7491798400879, \"count\": 1, \"min\": 953.7491798400879, \"max\": 953.7491798400879}}}\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1387.034066552369 records/second\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 49.0 % of epochs\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.2667075287212026\n",
      "[05/21/2025 16:20:34 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] Epoch[196] Batch[0] avg_epoch_loss=2.114752\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.1147522926330566\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] Epoch[196] Batch[5] avg_epoch_loss=2.188905\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.1889049212137857\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] Epoch[196] Batch [5]#011Speed: 2096.74 samples/sec#011loss=2.188905\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] Epoch[196] Batch[10] avg_epoch_loss=2.151026\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.105570578575134\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] Epoch[196] Batch [10]#011Speed: 2044.90 samples/sec#011loss=2.105571\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747844434.8272238, \"EndTime\": 1747844435.7681081, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.5581951141357, \"count\": 1, \"min\": 940.5581951141357, \"max\": 940.5581951141357}}}\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1412.8324235463367 records/second\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 49.25 % of epochs\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.1510256745598535\n",
      "[05/21/2025 16:20:35 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] Epoch[197] Batch[0] avg_epoch_loss=2.218790\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.218790292739868\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] Epoch[197] Batch[5] avg_epoch_loss=2.181632\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.181632320086161\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] Epoch[197] Batch [5]#011Speed: 2021.55 samples/sec#011loss=2.181632\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] processed a total of 1274 examples\n",
      "#metrics {\"StartTime\": 1747844435.7681856, \"EndTime\": 1747844436.6559618, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 887.4204158782959, \"count\": 1, \"min\": 887.4204158782959, \"max\": 887.4204158782959}}}\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.4759130248606 records/second\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 49.5 % of epochs\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.1750035524368285\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] Epoch[198] Batch[0] avg_epoch_loss=2.191280\n",
      "[05/21/2025 16:20:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.1912803649902344\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] Epoch[198] Batch[5] avg_epoch_loss=2.165895\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.1658952236175537\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] Epoch[198] Batch [5]#011Speed: 2190.92 samples/sec#011loss=2.165895\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] Epoch[198] Batch[10] avg_epoch_loss=2.164875\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.1636516094207763\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] Epoch[198] Batch [10]#011Speed: 2049.32 samples/sec#011loss=2.163652\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747844436.656024, \"EndTime\": 1747844437.588201, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.8387508392334, \"count\": 1, \"min\": 931.8387508392334, \"max\": 931.8387508392334}}}\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.2039368976834 records/second\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 49.75 % of epochs\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.164875398982655\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] Epoch[199] Batch[0] avg_epoch_loss=2.202812\n",
      "[05/21/2025 16:20:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.202812433242798\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] Epoch[199] Batch[5] avg_epoch_loss=2.171891\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.1718913316726685\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] Epoch[199] Batch [5]#011Speed: 2188.51 samples/sec#011loss=2.171891\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] Epoch[199] Batch[10] avg_epoch_loss=2.191814\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=2.2157201290130617\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] Epoch[199] Batch [10]#011Speed: 2089.56 samples/sec#011loss=2.215720\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844437.588256, \"EndTime\": 1747844438.507479, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.9832210540771, \"count\": 1, \"min\": 918.9832210540771, \"max\": 918.9832210540771}}}\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.1530908797536 records/second\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 50.0 % of epochs\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.191813512281938\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] Epoch[200] Batch[0] avg_epoch_loss=2.205767\n",
      "[05/21/2025 16:20:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.2057671546936035\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] Epoch[200] Batch[5] avg_epoch_loss=2.163594\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.163594365119934\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] Epoch[200] Batch [5]#011Speed: 2232.93 samples/sec#011loss=2.163594\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] Epoch[200] Batch[10] avg_epoch_loss=2.172927\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=2.1841251850128174\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] Epoch[200] Batch [10]#011Speed: 1989.03 samples/sec#011loss=2.184125\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] processed a total of 1392 examples\n",
      "#metrics {\"StartTime\": 1747844438.5075336, \"EndTime\": 1747844439.4294884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.7102527618408, \"count\": 1, \"min\": 921.7102527618408, \"max\": 921.7102527618408}}}\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1510.0969348126848 records/second\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 50.25 % of epochs\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.1729265559803355\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] Epoch[201] Batch[0] avg_epoch_loss=2.219630\n",
      "[05/21/2025 16:20:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.219630241394043\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[201] Batch[5] avg_epoch_loss=2.212164\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.212164044380188\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[201] Batch [5]#011Speed: 2145.07 samples/sec#011loss=2.212164\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[201] Batch[10] avg_epoch_loss=2.208648\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=2.204428195953369\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[201] Batch [10]#011Speed: 1953.88 samples/sec#011loss=2.204428\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] processed a total of 1396 examples\n",
      "#metrics {\"StartTime\": 1747844439.4295444, \"EndTime\": 1747844440.3708005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.9737586975098, \"count\": 1, \"min\": 940.9737586975098, \"max\": 940.9737586975098}}}\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1483.4285847475555 records/second\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 50.5 % of epochs\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.208647749640725\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[202] Batch[0] avg_epoch_loss=2.123602\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.1236023902893066\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[202] Batch[5] avg_epoch_loss=2.190491\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.1904907623926797\n",
      "[05/21/2025 16:20:40 INFO 140328105305920] Epoch[202] Batch [5]#011Speed: 2095.86 samples/sec#011loss=2.190491\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Epoch[202] Batch[10] avg_epoch_loss=2.099372\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=1.9900302648544312\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Epoch[202] Batch [10]#011Speed: 2118.50 samples/sec#011loss=1.990030\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747844440.3708591, \"EndTime\": 1747844441.299555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.4489154815674, \"count\": 1, \"min\": 928.4489154815674, \"max\": 928.4489154815674}}}\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1401.1329931147461 records/second\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 50.75 % of epochs\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.0993723544207485\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_66f623dc-d5d4-4eb5-af66-873445dab848-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844441.2996116, \"EndTime\": 1747844441.3105419, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.640144348144531, \"count\": 1, \"min\": 10.640144348144531, \"max\": 10.640144348144531}}}\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Epoch[203] Batch[0] avg_epoch_loss=2.162575\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.1625752449035645\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Epoch[203] Batch[5] avg_epoch_loss=2.153125\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.1531251668930054\n",
      "[05/21/2025 16:20:41 INFO 140328105305920] Epoch[203] Batch [5]#011Speed: 2141.36 samples/sec#011loss=2.153125\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] Epoch[203] Batch[10] avg_epoch_loss=2.323638\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=2.5282530307769777\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] Epoch[203] Batch [10]#011Speed: 2051.45 samples/sec#011loss=2.528253\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747844441.310592, \"EndTime\": 1747844442.2553658, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.7240829467773, \"count\": 1, \"min\": 944.7240829467773, \"max\": 944.7240829467773}}}\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1418.2657560414298 records/second\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 51.0 % of epochs\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.323637832294811\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] Epoch[204] Batch[0] avg_epoch_loss=2.236738\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.2367379665374756\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] Epoch[204] Batch[5] avg_epoch_loss=2.274503\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.2745028336842856\n",
      "[05/21/2025 16:20:42 INFO 140328105305920] Epoch[204] Batch [5]#011Speed: 2179.95 samples/sec#011loss=2.274503\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] processed a total of 1227 examples\n",
      "#metrics {\"StartTime\": 1747844442.2554297, \"EndTime\": 1747844443.097475, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 841.799259185791, \"count\": 1, \"min\": 841.799259185791, \"max\": 841.799259185791}}}\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.4311748687114 records/second\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 51.25 % of epochs\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.250216019153595\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] Epoch[205] Batch[0] avg_epoch_loss=2.268302\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.2683019638061523\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] Epoch[205] Batch[5] avg_epoch_loss=2.275498\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.275498112042745\n",
      "[05/21/2025 16:20:43 INFO 140328105305920] Epoch[205] Batch [5]#011Speed: 2183.50 samples/sec#011loss=2.275498\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[205] Batch[10] avg_epoch_loss=2.302355\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=2.3345824241638184\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[205] Batch [10]#011Speed: 2067.94 samples/sec#011loss=2.334582\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747844443.0975375, \"EndTime\": 1747844444.0247908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.9585609436035, \"count\": 1, \"min\": 926.9585609436035, \"max\": 926.9585609436035}}}\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1443.3240485650033 records/second\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 51.5 % of epochs\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.3023546175523237\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[206] Batch[0] avg_epoch_loss=2.207852\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.207852363586426\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[206] Batch[5] avg_epoch_loss=2.168553\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.168552796045939\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[206] Batch [5]#011Speed: 1948.61 samples/sec#011loss=2.168553\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[206] Batch[10] avg_epoch_loss=2.198014\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=2.233367586135864\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] Epoch[206] Batch [10]#011Speed: 2130.41 samples/sec#011loss=2.233368\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747844444.0248358, \"EndTime\": 1747844444.9728792, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.8485584259033, \"count\": 1, \"min\": 947.8485584259033, \"max\": 947.8485584259033}}}\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1389.339108100318 records/second\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 51.75 % of epochs\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.1980140642686323\n",
      "[05/21/2025 16:20:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] Epoch[207] Batch[0] avg_epoch_loss=2.198467\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.1984667778015137\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] Epoch[207] Batch[5] avg_epoch_loss=2.197401\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.197401444117228\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] Epoch[207] Batch [5]#011Speed: 2143.90 samples/sec#011loss=2.197401\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] Epoch[207] Batch[10] avg_epoch_loss=2.162070\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=2.119672250747681\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] Epoch[207] Batch [10]#011Speed: 2066.03 samples/sec#011loss=2.119672\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747844444.9729347, \"EndTime\": 1747844445.904755, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.5760135650635, \"count\": 1, \"min\": 931.5760135650635, \"max\": 931.5760135650635}}}\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.4574055639293 records/second\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 52.0 % of epochs\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.1620699925856157\n",
      "[05/21/2025 16:20:45 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] Epoch[208] Batch[0] avg_epoch_loss=2.266285\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.2662854194641113\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] Epoch[208] Batch[5] avg_epoch_loss=2.342024\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.3420235315958657\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] Epoch[208] Batch [5]#011Speed: 2160.93 samples/sec#011loss=2.342024\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] Epoch[208] Batch[10] avg_epoch_loss=2.364377\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.391201877593994\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] Epoch[208] Batch [10]#011Speed: 1977.63 samples/sec#011loss=2.391202\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] processed a total of 1413 examples\n",
      "#metrics {\"StartTime\": 1747844445.9048107, \"EndTime\": 1747844446.9070728, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1002.0110607147217, \"count\": 1, \"min\": 1002.0110607147217, \"max\": 1002.0110607147217}}}\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1410.034234519736 records/second\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 52.25 % of epochs\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.3148432870705924\n",
      "[05/21/2025 16:20:46 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] Epoch[209] Batch[0] avg_epoch_loss=2.381964\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.3819644451141357\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] Epoch[209] Batch[5] avg_epoch_loss=2.314153\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.3141531944274902\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] Epoch[209] Batch [5]#011Speed: 2166.86 samples/sec#011loss=2.314153\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] Epoch[209] Batch[10] avg_epoch_loss=2.426307\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=2.560890769958496\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] Epoch[209] Batch [10]#011Speed: 2109.81 samples/sec#011loss=2.560891\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747844446.907135, \"EndTime\": 1747844447.8301382, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.7101802825928, \"count\": 1, \"min\": 922.7101802825928, \"max\": 922.7101802825928}}}\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1398.999322570594 records/second\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 52.5 % of epochs\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.426306637850675\n",
      "[05/21/2025 16:20:47 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] Epoch[210] Batch[0] avg_epoch_loss=2.178801\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.1788012981414795\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] Epoch[210] Batch[5] avg_epoch_loss=2.283313\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.283312519391378\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] Epoch[210] Batch [5]#011Speed: 2130.17 samples/sec#011loss=2.283313\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747844447.8301947, \"EndTime\": 1747844448.6934836, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 863.039493560791, \"count\": 1, \"min\": 863.039493560791, \"max\": 863.039493560791}}}\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1467.9078636434074 records/second\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 52.75 % of epochs\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.2861845970153807\n",
      "[05/21/2025 16:20:48 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[211] Batch[0] avg_epoch_loss=2.290043\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.2900431156158447\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[211] Batch[5] avg_epoch_loss=2.203702\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.203702211380005\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[211] Batch [5]#011Speed: 2244.81 samples/sec#011loss=2.203702\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[211] Batch[10] avg_epoch_loss=2.198770\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=2.1928505897521973\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[211] Batch [10]#011Speed: 2072.20 samples/sec#011loss=2.192851\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] processed a total of 1383 examples\n",
      "#metrics {\"StartTime\": 1747844448.6935458, \"EndTime\": 1747844449.600697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.8546295166016, \"count\": 1, \"min\": 906.8546295166016, \"max\": 906.8546295166016}}}\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1524.9123697315254 records/second\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 53.0 % of epochs\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.1987696560946377\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] Epoch[212] Batch[0] avg_epoch_loss=2.145395\n",
      "[05/21/2025 16:20:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.145394802093506\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] Epoch[212] Batch[5] avg_epoch_loss=2.177683\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.1776832739512124\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] Epoch[212] Batch [5]#011Speed: 2132.52 samples/sec#011loss=2.177683\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] Epoch[212] Batch[10] avg_epoch_loss=2.185011\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.19380521774292\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] Epoch[212] Batch [10]#011Speed: 2122.56 samples/sec#011loss=2.193805\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844449.600752, \"EndTime\": 1747844450.5245595, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.5687255859375, \"count\": 1, \"min\": 923.5687255859375, \"max\": 923.5687255859375}}}\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1404.1549698326762 records/second\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 53.25 % of epochs\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.1850114302201704\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] Epoch[213] Batch[0] avg_epoch_loss=2.319232\n",
      "[05/21/2025 16:20:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.319232225418091\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] Epoch[213] Batch[5] avg_epoch_loss=2.362285\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.3622852166493735\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] Epoch[213] Batch [5]#011Speed: 2130.41 samples/sec#011loss=2.362285\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] Epoch[213] Batch[10] avg_epoch_loss=2.378485\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=2.3979246616363525\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] Epoch[213] Batch [10]#011Speed: 2001.42 samples/sec#011loss=2.397925\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747844450.5246496, \"EndTime\": 1747844451.4655364, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.6254291534424, \"count\": 1, \"min\": 940.6254291534424, \"max\": 940.6254291534424}}}\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1437.197644807059 records/second\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 53.5 % of epochs\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.3784849643707275\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] Epoch[214] Batch[0] avg_epoch_loss=2.207564\n",
      "[05/21/2025 16:20:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.207563638687134\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] Epoch[214] Batch[5] avg_epoch_loss=2.261972\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.261971910794576\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] Epoch[214] Batch [5]#011Speed: 2110.87 samples/sec#011loss=2.261972\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] Epoch[214] Batch[10] avg_epoch_loss=2.369025\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=2.497488260269165\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] Epoch[214] Batch [10]#011Speed: 2140.17 samples/sec#011loss=2.497488\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747844451.4655974, \"EndTime\": 1747844452.415094, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 949.1779804229736, \"count\": 1, \"min\": 949.1779804229736, \"max\": 949.1779804229736}}}\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1354.7173698685185 records/second\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 53.75 % of epochs\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.369024796919389\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] Epoch[215] Batch[0] avg_epoch_loss=2.233238\n",
      "[05/21/2025 16:20:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.2332379817962646\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[215] Batch[5] avg_epoch_loss=2.310457\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.3104573090871177\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[215] Batch [5]#011Speed: 2067.96 samples/sec#011loss=2.310457\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[215] Batch[10] avg_epoch_loss=2.424845\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=2.5621108531951906\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[215] Batch [10]#011Speed: 2073.62 samples/sec#011loss=2.562111\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844452.4151592, \"EndTime\": 1747844453.3490922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.6338043212891, \"count\": 1, \"min\": 933.6338043212891, \"max\": 933.6338043212891}}}\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1446.9077855907358 records/second\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 54.0 % of epochs\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.4248452836816963\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[216] Batch[0] avg_epoch_loss=2.276415\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.2764153480529785\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[216] Batch[5] avg_epoch_loss=2.332436\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.3324364026387534\n",
      "[05/21/2025 16:20:53 INFO 140328105305920] Epoch[216] Batch [5]#011Speed: 2231.26 samples/sec#011loss=2.332436\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] Epoch[216] Batch[10] avg_epoch_loss=2.317406\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=2.2993701934814452\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] Epoch[216] Batch [10]#011Speed: 2047.32 samples/sec#011loss=2.299370\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747844453.3491461, \"EndTime\": 1747844454.2671657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.7813529968262, \"count\": 1, \"min\": 917.7813529968262, \"max\": 917.7813529968262}}}\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1466.4385309881538 records/second\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 54.25 % of epochs\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.3174063075672495\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] Epoch[217] Batch[0] avg_epoch_loss=2.252441\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.252440929412842\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] Epoch[217] Batch[5] avg_epoch_loss=2.250445\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.250444849332174\n",
      "[05/21/2025 16:20:54 INFO 140328105305920] Epoch[217] Batch [5]#011Speed: 2190.83 samples/sec#011loss=2.250445\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] Epoch[217] Batch[10] avg_epoch_loss=2.360031\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=2.49153413772583\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] Epoch[217] Batch [10]#011Speed: 2172.79 samples/sec#011loss=2.491534\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747844454.2672248, \"EndTime\": 1747844455.1754255, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.9287052154541, \"count\": 1, \"min\": 907.9287052154541, \"max\": 907.9287052154541}}}\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1414.0623974503487 records/second\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 54.5 % of epochs\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.3600308895111084\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] Epoch[218] Batch[0] avg_epoch_loss=2.160618\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=2.160618305206299\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] Epoch[218] Batch[5] avg_epoch_loss=2.197252\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.197251637776693\n",
      "[05/21/2025 16:20:55 INFO 140328105305920] Epoch[218] Batch [5]#011Speed: 2120.74 samples/sec#011loss=2.197252\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747844455.1754842, \"EndTime\": 1747844456.0429168, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 867.1820163726807, \"count\": 1, \"min\": 867.1820163726807, \"max\": 867.1820163726807}}}\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1471.280229117974 records/second\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 54.75 % of epochs\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.1921730756759645\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] Epoch[219] Batch[0] avg_epoch_loss=2.148972\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.1489717960357666\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] Epoch[219] Batch[5] avg_epoch_loss=2.206292\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.2062920729319253\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] Epoch[219] Batch [5]#011Speed: 2113.06 samples/sec#011loss=2.206292\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] Epoch[219] Batch[10] avg_epoch_loss=2.208831\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=2.211878776550293\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] Epoch[219] Batch [10]#011Speed: 2081.01 samples/sec#011loss=2.211879\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747844456.042977, \"EndTime\": 1747844456.9769843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.6154460906982, \"count\": 1, \"min\": 933.6154460906982, \"max\": 933.6154460906982}}}\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.8652953118653 records/second\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 55.0 % of epochs\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.208831483667547\n",
      "[05/21/2025 16:20:56 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] Epoch[220] Batch[0] avg_epoch_loss=2.114685\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.11468505859375\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] Epoch[220] Batch[5] avg_epoch_loss=2.170950\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.170950253804525\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] Epoch[220] Batch [5]#011Speed: 2093.23 samples/sec#011loss=2.170950\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] Epoch[220] Batch[10] avg_epoch_loss=2.118172\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=2.054839086532593\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] Epoch[220] Batch [10]#011Speed: 2087.84 samples/sec#011loss=2.054839\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747844456.9770854, \"EndTime\": 1747844457.9101918, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.8317642211914, \"count\": 1, \"min\": 932.8317642211914, \"max\": 932.8317642211914}}}\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.218338334716 records/second\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 55.25 % of epochs\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.118172450499101\n",
      "[05/21/2025 16:20:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] Epoch[221] Batch[0] avg_epoch_loss=2.186387\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.186386823654175\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] Epoch[221] Batch[5] avg_epoch_loss=2.131918\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.131918430328369\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] Epoch[221] Batch [5]#011Speed: 2189.56 samples/sec#011loss=2.131918\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] Epoch[221] Batch[10] avg_epoch_loss=2.191399\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=2.2627758026123046\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] Epoch[221] Batch [10]#011Speed: 2091.18 samples/sec#011loss=2.262776\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747844457.9102457, \"EndTime\": 1747844458.828832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.3139801025391, \"count\": 1, \"min\": 918.3139801025391, \"max\": 918.3139801025391}}}\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1459.0633218052367 records/second\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 55.5 % of epochs\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.1913990540937944\n",
      "[05/21/2025 16:20:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] Epoch[222] Batch[0] avg_epoch_loss=2.418191\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=2.418191432952881\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] Epoch[222] Batch[5] avg_epoch_loss=2.225063\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.2250633239746094\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] Epoch[222] Batch [5]#011Speed: 2206.48 samples/sec#011loss=2.225063\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] processed a total of 1262 examples\n",
      "#metrics {\"StartTime\": 1747844458.8288877, \"EndTime\": 1747844459.682305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 853.1687259674072, \"count\": 1, \"min\": 853.1687259674072, \"max\": 853.1687259674072}}}\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1479.035350968348 records/second\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 55.75 % of epochs\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.2138325452804564\n",
      "[05/21/2025 16:20:59 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[223] Batch[0] avg_epoch_loss=2.189793\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.189793109893799\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[223] Batch[5] avg_epoch_loss=2.205834\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.2058343092600503\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[223] Batch [5]#011Speed: 2132.65 samples/sec#011loss=2.205834\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[223] Batch[10] avg_epoch_loss=2.254772\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=2.3134968757629393\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[223] Batch [10]#011Speed: 2106.22 samples/sec#011loss=2.313497\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844459.6823657, \"EndTime\": 1747844460.6087496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.0504245758057, \"count\": 1, \"min\": 926.0504245758057, \"max\": 926.0504245758057}}}\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1423.1185627361313 records/second\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 56.0 % of epochs\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.2547718394886362\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] Epoch[224] Batch[0] avg_epoch_loss=2.044531\n",
      "[05/21/2025 16:21:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.0445306301116943\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] Epoch[224] Batch[5] avg_epoch_loss=2.183264\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.183264136314392\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] Epoch[224] Batch [5]#011Speed: 2108.31 samples/sec#011loss=2.183264\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] Epoch[224] Batch[10] avg_epoch_loss=2.148940\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=2.1077516317367553\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] Epoch[224] Batch [10]#011Speed: 1767.97 samples/sec#011loss=2.107752\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844460.6088068, \"EndTime\": 1747844461.5949411, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 985.8365058898926, \"count\": 1, \"min\": 985.8365058898926, \"max\": 985.8365058898926}}}\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1368.269210269982 records/second\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 56.25 % of epochs\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.1489402705972847\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] Epoch[225] Batch[0] avg_epoch_loss=2.169954\n",
      "[05/21/2025 16:21:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.1699540615081787\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Epoch[225] Batch[5] avg_epoch_loss=2.141982\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.141981840133667\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Epoch[225] Batch [5]#011Speed: 2122.66 samples/sec#011loss=2.141982\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Epoch[225] Batch[10] avg_epoch_loss=2.098197\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=2.0456557750701903\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Epoch[225] Batch [10]#011Speed: 2169.47 samples/sec#011loss=2.045656\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747844461.5949917, \"EndTime\": 1747844462.5309029, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.6434345245361, \"count\": 1, \"min\": 935.6434345245361, \"max\": 935.6434345245361}}}\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1404.258411564047 records/second\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 56.5 % of epochs\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.098197265104814\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_09a95c9d-8e4c-4b62-818d-fea88424c140-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844462.5309565, \"EndTime\": 1747844462.5412636, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.048389434814453, \"count\": 1, \"min\": 10.048389434814453, \"max\": 10.048389434814453}}}\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] Epoch[226] Batch[0] avg_epoch_loss=2.265798\n",
      "[05/21/2025 16:21:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=2.2657980918884277\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] Epoch[226] Batch[5] avg_epoch_loss=2.173375\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.173375368118286\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] Epoch[226] Batch [5]#011Speed: 2195.65 samples/sec#011loss=2.173375\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] Epoch[226] Batch[10] avg_epoch_loss=2.137421\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=2.0942755222320555\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] Epoch[226] Batch [10]#011Speed: 1956.09 samples/sec#011loss=2.094276\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844462.5413113, \"EndTime\": 1747844463.477142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.786247253418, \"count\": 1, \"min\": 935.786247253418, \"max\": 935.786247253418}}}\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.479706219289 records/second\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 56.75 % of epochs\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.137420892715454\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] Epoch[227] Batch[0] avg_epoch_loss=2.098751\n",
      "[05/21/2025 16:21:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.0987510681152344\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[227] Batch[5] avg_epoch_loss=2.136324\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.136324087778727\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[227] Batch [5]#011Speed: 2214.62 samples/sec#011loss=2.136324\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[227] Batch[10] avg_epoch_loss=2.154931\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=2.177258586883545\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[227] Batch [10]#011Speed: 2200.96 samples/sec#011loss=2.177259\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] processed a total of 1286 examples\n",
      "#metrics {\"StartTime\": 1747844463.4772446, \"EndTime\": 1747844464.3816047, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.0439128875732, \"count\": 1, \"min\": 904.0439128875732, \"max\": 904.0439128875732}}}\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1422.3637322065265 records/second\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 57.0 % of epochs\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.154930678280917\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[228] Batch[0] avg_epoch_loss=2.085278\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.085278272628784\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[228] Batch[5] avg_epoch_loss=2.106476\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.106476346651713\n",
      "[05/21/2025 16:21:04 INFO 140328105305920] Epoch[228] Batch [5]#011Speed: 2181.96 samples/sec#011loss=2.106476\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] Epoch[228] Batch[10] avg_epoch_loss=2.189946\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=2.290109968185425\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] Epoch[228] Batch [10]#011Speed: 2124.50 samples/sec#011loss=2.290110\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747844464.3816605, \"EndTime\": 1747844465.2940657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.1639728546143, \"count\": 1, \"min\": 912.1639728546143, \"max\": 912.1639728546143}}}\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1441.5043157499128 records/second\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 57.25 % of epochs\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.189946174621582\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] Epoch[229] Batch[0] avg_epoch_loss=2.103817\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.1038174629211426\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] Epoch[229] Batch[5] avg_epoch_loss=2.172805\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.172805349032084\n",
      "[05/21/2025 16:21:05 INFO 140328105305920] Epoch[229] Batch [5]#011Speed: 2077.63 samples/sec#011loss=2.172805\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] processed a total of 1262 examples\n",
      "#metrics {\"StartTime\": 1747844465.294117, \"EndTime\": 1747844466.1914606, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 896.9743251800537, \"count\": 1, \"min\": 896.9743251800537, \"max\": 896.9743251800537}}}\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.7929056673177 records/second\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 57.5 % of epochs\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.171135401725769\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] Epoch[230] Batch[0] avg_epoch_loss=2.082486\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.0824859142303467\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] Epoch[230] Batch[5] avg_epoch_loss=2.126018\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.126018206278483\n",
      "[05/21/2025 16:21:06 INFO 140328105305920] Epoch[230] Batch [5]#011Speed: 2106.85 samples/sec#011loss=2.126018\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747844466.1915288, \"EndTime\": 1747844467.055914, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 863.9934062957764, \"count\": 1, \"min\": 863.9934062957764, \"max\": 863.9934062957764}}}\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1481.3321398890362 records/second\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 57.75 % of epochs\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.1157091856002808\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] Epoch[231] Batch[0] avg_epoch_loss=2.044520\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.044520378112793\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] Epoch[231] Batch[5] avg_epoch_loss=2.102587\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.1025867064793906\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] Epoch[231] Batch [5]#011Speed: 2226.60 samples/sec#011loss=2.102587\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] Epoch[231] Batch[10] avg_epoch_loss=2.130683\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=2.164398717880249\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] Epoch[231] Batch [10]#011Speed: 2122.58 samples/sec#011loss=2.164399\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844467.0559762, \"EndTime\": 1747844467.9650147, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.7293148040771, \"count\": 1, \"min\": 908.7293148040771, \"max\": 908.7293148040771}}}\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1437.0381723686796 records/second\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 58.0 % of epochs\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.1306830752979624\n",
      "[05/21/2025 16:21:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] Epoch[232] Batch[0] avg_epoch_loss=2.166233\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.1662330627441406\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] Epoch[232] Batch[5] avg_epoch_loss=2.150295\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.1502949396769204\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] Epoch[232] Batch [5]#011Speed: 2222.41 samples/sec#011loss=2.150295\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] Epoch[232] Batch[10] avg_epoch_loss=2.147755\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=2.144706916809082\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] Epoch[232] Batch [10]#011Speed: 1954.23 samples/sec#011loss=2.144707\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844467.9650722, \"EndTime\": 1747844468.9008226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.4674816131592, \"count\": 1, \"min\": 935.4674816131592, \"max\": 935.4674816131592}}}\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1414.0866764709556 records/second\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 58.25 % of epochs\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.1477549292824487\n",
      "[05/21/2025 16:21:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] Epoch[233] Batch[0] avg_epoch_loss=2.144544\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.1445443630218506\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] Epoch[233] Batch[5] avg_epoch_loss=2.103925\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.103924552599589\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] Epoch[233] Batch [5]#011Speed: 2204.68 samples/sec#011loss=2.103925\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] Epoch[233] Batch[10] avg_epoch_loss=2.183500\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=2.2789910793304444\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] Epoch[233] Batch [10]#011Speed: 2101.52 samples/sec#011loss=2.278991\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844468.9009125, \"EndTime\": 1747844469.8167875, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.6019687652588, \"count\": 1, \"min\": 915.6019687652588, \"max\": 915.6019687652588}}}\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.5265272518645 records/second\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 58.5 % of epochs\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.1835002465681597\n",
      "[05/21/2025 16:21:09 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] Epoch[234] Batch[0] avg_epoch_loss=2.084017\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.084017038345337\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] Epoch[234] Batch[5] avg_epoch_loss=2.102297\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.1022969484329224\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] Epoch[234] Batch [5]#011Speed: 2203.14 samples/sec#011loss=2.102297\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] Epoch[234] Batch[10] avg_epoch_loss=2.141853\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=2.189320755004883\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] Epoch[234] Batch [10]#011Speed: 1952.78 samples/sec#011loss=2.189321\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] processed a total of 1381 examples\n",
      "#metrics {\"StartTime\": 1747844469.8168447, \"EndTime\": 1747844470.7503269, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.211088180542, \"count\": 1, \"min\": 933.211088180542, \"max\": 933.211088180542}}}\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1479.6975643875307 records/second\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 58.75 % of epochs\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.1418532241474497\n",
      "[05/21/2025 16:21:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Epoch[235] Batch[0] avg_epoch_loss=2.213713\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.2137134075164795\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Epoch[235] Batch[5] avg_epoch_loss=2.103458\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.103458285331726\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Epoch[235] Batch [5]#011Speed: 2186.33 samples/sec#011loss=2.103458\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Epoch[235] Batch[10] avg_epoch_loss=2.025390\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=1.9317082643508912\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Epoch[235] Batch [10]#011Speed: 2141.58 samples/sec#011loss=1.931708\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747844470.7503862, \"EndTime\": 1747844471.6665583, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.9243106842041, \"count\": 1, \"min\": 915.9243106842041, \"max\": 915.9243106842041}}}\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1421.3794235392686 records/second\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 59.0 % of epochs\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.0253900939768013\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:21:11 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_abb907f2-359c-4c6a-835a-688fabbb27fb-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844471.6666174, \"EndTime\": 1747844471.6774325, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.513782501220703, \"count\": 1, \"min\": 10.513782501220703, \"max\": 10.513782501220703}}}\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[236] Batch[0] avg_epoch_loss=2.208539\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.2085392475128174\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[236] Batch[5] avg_epoch_loss=2.106447\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.1064474980036416\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[236] Batch [5]#011Speed: 2203.89 samples/sec#011loss=2.106447\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[236] Batch[10] avg_epoch_loss=2.112650\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=2.1200929641723634\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[236] Batch [10]#011Speed: 2169.01 samples/sec#011loss=2.120093\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844471.6774986, \"EndTime\": 1747844472.5872593, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.710168838501, \"count\": 1, \"min\": 909.710168838501, \"max\": 909.710168838501}}}\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.9025067119503 records/second\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 59.25 % of epochs\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.112649982625788\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] Epoch[237] Batch[0] avg_epoch_loss=2.101073\n",
      "[05/21/2025 16:21:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.1010725498199463\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] Epoch[237] Batch[5] avg_epoch_loss=2.115961\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.115960677464803\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] Epoch[237] Batch [5]#011Speed: 2194.22 samples/sec#011loss=2.115961\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] Epoch[237] Batch[10] avg_epoch_loss=2.073710\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=2.023009729385376\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] Epoch[237] Batch [10]#011Speed: 1964.36 samples/sec#011loss=2.023010\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747844472.5873165, \"EndTime\": 1747844473.5306098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.0415630340576, \"count\": 1, \"min\": 943.0415630340576, \"max\": 943.0415630340576}}}\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1414.4469966772438 records/second\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 59.5 % of epochs\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.073710246519609\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] Epoch[238] Batch[0] avg_epoch_loss=2.228057\n",
      "[05/21/2025 16:21:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.2280569076538086\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] Epoch[238] Batch[5] avg_epoch_loss=2.225373\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.225372592608134\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] Epoch[238] Batch [5]#011Speed: 2097.72 samples/sec#011loss=2.225373\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] Epoch[238] Batch[10] avg_epoch_loss=2.182702\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=2.131497287750244\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] Epoch[238] Batch [10]#011Speed: 2025.74 samples/sec#011loss=2.131497\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844473.5306642, \"EndTime\": 1747844474.4792476, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.251485824585, \"count\": 1, \"min\": 948.251485824585, \"max\": 948.251485824585}}}\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.6053907938362 records/second\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 59.75 % of epochs\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.182701999490911\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] Epoch[239] Batch[0] avg_epoch_loss=2.250238\n",
      "[05/21/2025 16:21:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.2502377033233643\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] Epoch[239] Batch[5] avg_epoch_loss=2.156253\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.156252900759379\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] Epoch[239] Batch [5]#011Speed: 2161.59 samples/sec#011loss=2.156253\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] Epoch[239] Batch[10] avg_epoch_loss=2.205487\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=2.2645677089691163\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] Epoch[239] Batch [10]#011Speed: 2120.90 samples/sec#011loss=2.264568\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747844474.4793, \"EndTime\": 1747844475.4018378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.290563583374, \"count\": 1, \"min\": 922.290563583374, \"max\": 922.290563583374}}}\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1402.9027154759954 records/second\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 60.0 % of epochs\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.2054869044910776\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] Epoch[240] Batch[0] avg_epoch_loss=2.111235\n",
      "[05/21/2025 16:21:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.111234664916992\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[240] Batch[5] avg_epoch_loss=2.135606\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.1356064875920615\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[240] Batch [5]#011Speed: 2050.54 samples/sec#011loss=2.135606\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[240] Batch[10] avg_epoch_loss=2.105627\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=2.0696524143218995\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[240] Batch [10]#011Speed: 2154.33 samples/sec#011loss=2.069652\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747844475.401893, \"EndTime\": 1747844476.341685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.549446105957, \"count\": 1, \"min\": 939.549446105957, \"max\": 939.549446105957}}}\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1382.4526925395676 records/second\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 60.25 % of epochs\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.1056273633783515\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[241] Batch[0] avg_epoch_loss=2.112519\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.1125192642211914\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[241] Batch[5] avg_epoch_loss=2.163996\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.163995623588562\n",
      "[05/21/2025 16:21:16 INFO 140328105305920] Epoch[241] Batch [5]#011Speed: 2069.89 samples/sec#011loss=2.163996\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] Epoch[241] Batch[10] avg_epoch_loss=2.197976\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.2387518882751465\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] Epoch[241] Batch [10]#011Speed: 2027.85 samples/sec#011loss=2.238752\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747844476.3417408, \"EndTime\": 1747844477.2863777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.8629150390625, \"count\": 1, \"min\": 943.8629150390625, \"max\": 943.8629150390625}}}\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.858177986372 records/second\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 60.5 % of epochs\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.197975743900646\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] Epoch[242] Batch[0] avg_epoch_loss=2.273446\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.2734458446502686\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] Epoch[242] Batch[5] avg_epoch_loss=2.164304\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.164304176966349\n",
      "[05/21/2025 16:21:17 INFO 140328105305920] Epoch[242] Batch [5]#011Speed: 2216.79 samples/sec#011loss=2.164304\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] Epoch[242] Batch[10] avg_epoch_loss=2.147145\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=2.1265542984008787\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] Epoch[242] Batch [10]#011Speed: 2048.28 samples/sec#011loss=2.126554\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747844477.2864327, \"EndTime\": 1747844478.2032852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.6061878204346, \"count\": 1, \"min\": 916.6061878204346, \"max\": 916.6061878204346}}}\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1473.7801053765554 records/second\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 60.75 % of epochs\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.147145141254772\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] Epoch[243] Batch[0] avg_epoch_loss=2.202285\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=2.202284574508667\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] Epoch[243] Batch[5] avg_epoch_loss=2.195996\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.195995807647705\n",
      "[05/21/2025 16:21:18 INFO 140328105305920] Epoch[243] Batch [5]#011Speed: 2046.45 samples/sec#011loss=2.195996\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] Epoch[243] Batch[10] avg_epoch_loss=2.176829\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=2.1538279056549072\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] Epoch[243] Batch [10]#011Speed: 2100.16 samples/sec#011loss=2.153828\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747844478.2033424, \"EndTime\": 1747844479.140913, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.3178482055664, \"count\": 1, \"min\": 937.3178482055664, \"max\": 937.3178482055664}}}\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.1484936733007 records/second\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 61.0 % of epochs\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.1768285794691606\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] Epoch[244] Batch[0] avg_epoch_loss=2.095212\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.0952117443084717\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] Epoch[244] Batch[5] avg_epoch_loss=2.106763\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.1067630449930825\n",
      "[05/21/2025 16:21:19 INFO 140328105305920] Epoch[244] Batch [5]#011Speed: 2203.99 samples/sec#011loss=2.106763\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] Epoch[244] Batch[10] avg_epoch_loss=2.078181\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=2.043881869316101\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] Epoch[244] Batch [10]#011Speed: 2021.96 samples/sec#011loss=2.043882\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] processed a total of 1372 examples\n",
      "#metrics {\"StartTime\": 1747844479.140969, \"EndTime\": 1747844480.0646374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.274040222168, \"count\": 1, \"min\": 923.274040222168, \"max\": 923.274040222168}}}\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1485.8797902421654 records/second\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 61.25 % of epochs\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.0781806924126367\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] Epoch[245] Batch[0] avg_epoch_loss=2.081185\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.0811853408813477\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] Epoch[245] Batch[5] avg_epoch_loss=2.075188\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.075188239415487\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] Epoch[245] Batch [5]#011Speed: 2235.23 samples/sec#011loss=2.075188\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] processed a total of 1254 examples\n",
      "#metrics {\"StartTime\": 1747844480.0646927, \"EndTime\": 1747844480.9215238, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 856.5425872802734, \"count\": 1, \"min\": 856.5425872802734, \"max\": 856.5425872802734}}}\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1463.864736762711 records/second\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 61.5 % of epochs\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.056214988231659\n",
      "[05/21/2025 16:21:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Epoch[246] Batch[0] avg_epoch_loss=2.074374\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.074374198913574\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Epoch[246] Batch[5] avg_epoch_loss=2.028003\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.028002997239431\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Epoch[246] Batch [5]#011Speed: 2152.30 samples/sec#011loss=2.028003\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Epoch[246] Batch[10] avg_epoch_loss=1.987982\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=1.939957046508789\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Epoch[246] Batch [10]#011Speed: 2073.40 samples/sec#011loss=1.939957\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747844480.9215868, \"EndTime\": 1747844481.8533163, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.4291477203369, \"count\": 1, \"min\": 931.4291477203369, \"max\": 931.4291477203369}}}\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1394.5021793891976 records/second\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 61.75 % of epochs\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=246, train loss <loss>=1.9879821105436846\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:21:21 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_668d5524-9324-4d89-9d9e-93fbb8a6c4fd-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844481.8533747, \"EndTime\": 1747844481.8646479, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.983705520629883, \"count\": 1, \"min\": 10.983705520629883, \"max\": 10.983705520629883}}}\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] Epoch[247] Batch[0] avg_epoch_loss=2.075244\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.0752439498901367\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] Epoch[247] Batch[5] avg_epoch_loss=2.054706\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.054705778757731\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] Epoch[247] Batch [5]#011Speed: 2228.90 samples/sec#011loss=2.054706\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] Epoch[247] Batch[10] avg_epoch_loss=2.119027\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=2.1962114334106446\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] Epoch[247] Batch [10]#011Speed: 1966.76 samples/sec#011loss=2.196211\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747844481.8646975, \"EndTime\": 1747844482.794408, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 929.6655654907227, \"count\": 1, \"min\": 929.6655654907227, \"max\": 929.6655654907227}}}\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1416.5124094565483 records/second\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 62.0 % of epochs\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=247, train loss <loss>=2.119026530872692\n",
      "[05/21/2025 16:21:22 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] Epoch[248] Batch[0] avg_epoch_loss=2.074578\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.074578046798706\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] Epoch[248] Batch[5] avg_epoch_loss=2.124177\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.1241767406463623\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] Epoch[248] Batch [5]#011Speed: 2146.38 samples/sec#011loss=2.124177\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] Epoch[248] Batch[10] avg_epoch_loss=2.093256\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=2.056151032447815\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] Epoch[248] Batch [10]#011Speed: 2080.58 samples/sec#011loss=2.056151\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747844482.7944655, \"EndTime\": 1747844483.719626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.8561859130859, \"count\": 1, \"min\": 924.8561859130859, \"max\": 924.8561859130859}}}\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1445.49489817092 records/second\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 62.25 % of epochs\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.093255964192477\n",
      "[05/21/2025 16:21:23 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[249] Batch[0] avg_epoch_loss=2.094382\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.094381809234619\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[249] Batch[5] avg_epoch_loss=2.125469\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.125468691190084\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[249] Batch [5]#011Speed: 2145.19 samples/sec#011loss=2.125469\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[249] Batch[10] avg_epoch_loss=2.126042\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=2.1267292499542236\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[249] Batch [10]#011Speed: 2144.66 samples/sec#011loss=2.126729\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844483.7196834, \"EndTime\": 1747844484.6393871, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.4116592407227, \"count\": 1, \"min\": 919.4116592407227, \"max\": 919.4116592407227}}}\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1410.5424555466216 records/second\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 62.5 % of epochs\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.126041672446511\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] Epoch[250] Batch[0] avg_epoch_loss=2.372456\n",
      "[05/21/2025 16:21:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.3724563121795654\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] Epoch[250] Batch[5] avg_epoch_loss=2.379787\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.379786570866903\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] Epoch[250] Batch [5]#011Speed: 2183.25 samples/sec#011loss=2.379787\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] Epoch[250] Batch[10] avg_epoch_loss=2.323853\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=2.256733274459839\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] Epoch[250] Batch [10]#011Speed: 2196.12 samples/sec#011loss=2.256733\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747844484.6394434, \"EndTime\": 1747844485.5505795, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 910.8943939208984, \"count\": 1, \"min\": 910.8943939208984, \"max\": 910.8943939208984}}}\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.1548021841813 records/second\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 62.75 % of epochs\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.3238532543182373\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] Epoch[251] Batch[0] avg_epoch_loss=2.296105\n",
      "[05/21/2025 16:21:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.296104669570923\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] Epoch[251] Batch[5] avg_epoch_loss=2.409397\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.4093971252441406\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] Epoch[251] Batch [5]#011Speed: 2129.88 samples/sec#011loss=2.409397\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] Epoch[251] Batch[10] avg_epoch_loss=2.381258\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=2.3474917888641356\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] Epoch[251] Batch [10]#011Speed: 2071.69 samples/sec#011loss=2.347492\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747844485.5506375, \"EndTime\": 1747844486.4904478, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.5720958709717, \"count\": 1, \"min\": 939.5720958709717, \"max\": 939.5720958709717}}}\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1398.3851253425353 records/second\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 63.0 % of epochs\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.381258335980502\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] Epoch[252] Batch[0] avg_epoch_loss=2.316093\n",
      "[05/21/2025 16:21:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=2.3160932064056396\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] Epoch[252] Batch[5] avg_epoch_loss=2.290615\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.2906148036321006\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] Epoch[252] Batch [5]#011Speed: 2105.96 samples/sec#011loss=2.290615\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] processed a total of 1221 examples\n",
      "#metrics {\"StartTime\": 1747844486.4905045, \"EndTime\": 1747844487.3534336, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 862.689733505249, \"count\": 1, \"min\": 862.689733505249, \"max\": 862.689733505249}}}\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1415.161700666042 records/second\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 63.25 % of epochs\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.217351162433624\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] Epoch[253] Batch[0] avg_epoch_loss=2.228507\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=2.2285070419311523\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] Epoch[253] Batch[5] avg_epoch_loss=2.166979\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.166979352633158\n",
      "[05/21/2025 16:21:27 INFO 140328105305920] Epoch[253] Batch [5]#011Speed: 2074.42 samples/sec#011loss=2.166979\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] Epoch[253] Batch[10] avg_epoch_loss=2.205465\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=2.2516479015350344\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] Epoch[253] Batch [10]#011Speed: 2024.07 samples/sec#011loss=2.251648\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] processed a total of 1396 examples\n",
      "#metrics {\"StartTime\": 1747844487.3535128, \"EndTime\": 1747844488.2928777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.0690326690674, \"count\": 1, \"min\": 939.0690326690674, \"max\": 939.0690326690674}}}\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1486.448099267673 records/second\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 63.5 % of epochs\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.2054650566794654\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] Epoch[254] Batch[0] avg_epoch_loss=2.081606\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.081605911254883\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] Epoch[254] Batch[5] avg_epoch_loss=2.093350\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.0933500130971274\n",
      "[05/21/2025 16:21:28 INFO 140328105305920] Epoch[254] Batch [5]#011Speed: 2190.14 samples/sec#011loss=2.093350\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747844488.292932, \"EndTime\": 1747844489.1420693, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 848.8447666168213, \"count\": 1, \"min\": 848.8447666168213, \"max\": 848.8447666168213}}}\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1505.4136921545676 records/second\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 63.75 % of epochs\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.0905584692955017\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] Epoch[255] Batch[0] avg_epoch_loss=2.142189\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=2.142188549041748\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] Epoch[255] Batch[5] avg_epoch_loss=2.085126\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.0851258039474487\n",
      "[05/21/2025 16:21:29 INFO 140328105305920] Epoch[255] Batch [5]#011Speed: 2210.57 samples/sec#011loss=2.085126\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[255] Batch[10] avg_epoch_loss=2.189808\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=2.315425682067871\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[255] Batch [10]#011Speed: 2111.71 samples/sec#011loss=2.315426\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] processed a total of 1348 examples\n",
      "#metrics {\"StartTime\": 1747844489.1421306, \"EndTime\": 1747844490.0518398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.4223976135254, \"count\": 1, \"min\": 909.4223976135254, \"max\": 909.4223976135254}}}\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1482.1207968750778 records/second\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 64.0 % of epochs\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.189807566729459\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[256] Batch[0] avg_epoch_loss=2.146406\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.1464059352874756\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[256] Batch[5] avg_epoch_loss=2.163758\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.163757880528768\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[256] Batch [5]#011Speed: 2186.03 samples/sec#011loss=2.163758\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[256] Batch[10] avg_epoch_loss=2.152655\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=2.139331007003784\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] Epoch[256] Batch [10]#011Speed: 2069.08 samples/sec#011loss=2.139331\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844490.0518959, \"EndTime\": 1747844490.972747, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.5772876739502, \"count\": 1, \"min\": 920.5772876739502, \"max\": 920.5772876739502}}}\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1451.1328531089248 records/second\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 64.25 % of epochs\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.15265475619923\n",
      "[05/21/2025 16:21:30 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] Epoch[257] Batch[0] avg_epoch_loss=2.096661\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.09666109085083\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] Epoch[257] Batch[5] avg_epoch_loss=2.094128\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.094128211339315\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] Epoch[257] Batch [5]#011Speed: 2181.00 samples/sec#011loss=2.094128\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] Epoch[257] Batch[10] avg_epoch_loss=2.056489\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=2.011322855949402\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] Epoch[257] Batch [10]#011Speed: 2133.00 samples/sec#011loss=2.011323\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747844490.9728017, \"EndTime\": 1747844491.8909464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.8953170776367, \"count\": 1, \"min\": 917.8953170776367, \"max\": 917.8953170776367}}}\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1409.6204963954542 records/second\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 64.5 % of epochs\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.056489413434809\n",
      "[05/21/2025 16:21:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] Epoch[258] Batch[0] avg_epoch_loss=2.142484\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.142483711242676\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] Epoch[258] Batch[5] avg_epoch_loss=2.125413\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.1254132191340127\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] Epoch[258] Batch [5]#011Speed: 2229.09 samples/sec#011loss=2.125413\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] Epoch[258] Batch[10] avg_epoch_loss=2.031918\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=1.9197229862213134\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] Epoch[258] Batch [10]#011Speed: 2056.81 samples/sec#011loss=1.919723\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844491.891001, \"EndTime\": 1747844492.809504, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.255090713501, \"count\": 1, \"min\": 918.255090713501, \"max\": 918.255090713501}}}\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.1923813539236 records/second\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 64.75 % of epochs\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.0319176587191494\n",
      "[05/21/2025 16:21:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] Epoch[259] Batch[0] avg_epoch_loss=2.065534\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.0655341148376465\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] Epoch[259] Batch[5] avg_epoch_loss=2.056187\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.056187470753988\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] Epoch[259] Batch [5]#011Speed: 2175.58 samples/sec#011loss=2.056187\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] Epoch[259] Batch[10] avg_epoch_loss=2.056605\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=2.057106637954712\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] Epoch[259] Batch [10]#011Speed: 2160.29 samples/sec#011loss=2.057107\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747844492.809563, \"EndTime\": 1747844493.7247088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.8881435394287, \"count\": 1, \"min\": 914.8881435394287, \"max\": 914.8881435394287}}}\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1402.2351765519186 records/second\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 65.0 % of epochs\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.056605274027044\n",
      "[05/21/2025 16:21:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[260] Batch[0] avg_epoch_loss=2.146675\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=2.146674633026123\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[260] Batch[5] avg_epoch_loss=2.227282\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.227282484372457\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[260] Batch [5]#011Speed: 2148.48 samples/sec#011loss=2.227282\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[260] Batch[10] avg_epoch_loss=2.242275\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=260, batch=10 train loss <loss>=2.260265064239502\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[260] Batch [10]#011Speed: 2109.64 samples/sec#011loss=2.260265\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844493.7247622, \"EndTime\": 1747844494.6476424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.6412773132324, \"count\": 1, \"min\": 922.6412773132324, \"max\": 922.6412773132324}}}\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1433.7944708212376 records/second\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 65.25 % of epochs\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.2422745661302046\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] Epoch[261] Batch[0] avg_epoch_loss=2.091267\n",
      "[05/21/2025 16:21:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.091266632080078\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] Epoch[261] Batch[5] avg_epoch_loss=2.150998\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.150997757911682\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] Epoch[261] Batch [5]#011Speed: 2211.41 samples/sec#011loss=2.150998\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] Epoch[261] Batch[10] avg_epoch_loss=2.092135\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=2.021500062942505\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] Epoch[261] Batch [10]#011Speed: 2094.69 samples/sec#011loss=2.021500\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747844494.6476994, \"EndTime\": 1747844495.5666869, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.7374114990234, \"count\": 1, \"min\": 918.7374114990234, \"max\": 918.7374114990234}}}\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1448.592753894705 records/second\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 65.5 % of epochs\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=261, train loss <loss>=2.0921351692893286\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] Epoch[262] Batch[0] avg_epoch_loss=2.094076\n",
      "[05/21/2025 16:21:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.094076156616211\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] Epoch[262] Batch[5] avg_epoch_loss=2.173132\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.1731321016947427\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] Epoch[262] Batch [5]#011Speed: 2134.19 samples/sec#011loss=2.173132\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] Epoch[262] Batch[10] avg_epoch_loss=2.203665\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=2.240303468704224\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] Epoch[262] Batch [10]#011Speed: 2022.95 samples/sec#011loss=2.240303\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844495.5667436, \"EndTime\": 1747844496.5047197, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.7350807189941, \"count\": 1, \"min\": 937.7350807189941, \"max\": 937.7350807189941}}}\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.460478527676 records/second\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 65.75 % of epochs\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.203664541244507\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] Epoch[263] Batch[0] avg_epoch_loss=2.182294\n",
      "[05/21/2025 16:21:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.1822938919067383\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] Epoch[263] Batch[5] avg_epoch_loss=2.225466\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.2254664500554404\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] Epoch[263] Batch [5]#011Speed: 1983.36 samples/sec#011loss=2.225466\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] Epoch[263] Batch[10] avg_epoch_loss=2.191238\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=263, batch=10 train loss <loss>=2.1501638412475588\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] Epoch[263] Batch [10]#011Speed: 2034.28 samples/sec#011loss=2.150164\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] processed a total of 1368 examples\n",
      "#metrics {\"StartTime\": 1747844496.5047731, \"EndTime\": 1747844497.46129, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 956.2332630157471, \"count\": 1, \"min\": 956.2332630157471, \"max\": 956.2332630157471}}}\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1430.486302348315 records/second\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 66.0 % of epochs\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=263, train loss <loss>=2.1912379915064033\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] Epoch[264] Batch[0] avg_epoch_loss=2.172250\n",
      "[05/21/2025 16:21:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.1722500324249268\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[264] Batch[5] avg_epoch_loss=2.117030\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.1170299450556436\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[264] Batch [5]#011Speed: 2138.26 samples/sec#011loss=2.117030\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[264] Batch[10] avg_epoch_loss=2.169096\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=2.2315754652023316\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[264] Batch [10]#011Speed: 2140.87 samples/sec#011loss=2.231575\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747844497.461346, \"EndTime\": 1747844498.3798273, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.1814193725586, \"count\": 1, \"min\": 918.1814193725586, \"max\": 918.1814193725586}}}\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1448.382343853775 records/second\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 66.25 % of epochs\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.1690960905768653\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[265] Batch[0] avg_epoch_loss=2.111740\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.1117403507232666\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[265] Batch[5] avg_epoch_loss=2.069481\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.069481094678243\n",
      "[05/21/2025 16:21:38 INFO 140328105305920] Epoch[265] Batch [5]#011Speed: 2166.23 samples/sec#011loss=2.069481\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] Epoch[265] Batch[10] avg_epoch_loss=2.090607\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=2.1159587860107423\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] Epoch[265] Batch [10]#011Speed: 2049.65 samples/sec#011loss=2.115959\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747844498.3798835, \"EndTime\": 1747844499.3068752, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.7237186431885, \"count\": 1, \"min\": 926.7237186431885, \"max\": 926.7237186431885}}}\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1463.086770733409 records/second\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 66.5 % of epochs\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.0906073180111973\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] Epoch[266] Batch[0] avg_epoch_loss=2.046064\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.0460641384124756\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] Epoch[266] Batch[5] avg_epoch_loss=2.055419\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.055418531099955\n",
      "[05/21/2025 16:21:39 INFO 140328105305920] Epoch[266] Batch [5]#011Speed: 2204.83 samples/sec#011loss=2.055419\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] Epoch[266] Batch[10] avg_epoch_loss=2.050448\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=2.044483518600464\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] Epoch[266] Batch [10]#011Speed: 2052.39 samples/sec#011loss=2.044484\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747844499.3069305, \"EndTime\": 1747844500.2312229, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.0367412567139, \"count\": 1, \"min\": 924.0367412567139, \"max\": 924.0367412567139}}}\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1440.2892188935098 records/second\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 66.75 % of epochs\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.0504480708729136\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] Epoch[267] Batch[0] avg_epoch_loss=2.075765\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.0757651329040527\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] Epoch[267] Batch[5] avg_epoch_loss=2.011019\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.0110191305478415\n",
      "[05/21/2025 16:21:40 INFO 140328105305920] Epoch[267] Batch [5]#011Speed: 2145.20 samples/sec#011loss=2.011019\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] Epoch[267] Batch[10] avg_epoch_loss=2.057787\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=2.113909292221069\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] Epoch[267] Batch [10]#011Speed: 1966.30 samples/sec#011loss=2.113909\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747844500.231279, \"EndTime\": 1747844501.17951, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 947.9801654815674, \"count\": 1, \"min\": 947.9801654815674, \"max\": 947.9801654815674}}}\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1401.8000885205006 records/second\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 67.0 % of epochs\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.057787385853854\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] Epoch[268] Batch[0] avg_epoch_loss=2.007273\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.0072731971740723\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] Epoch[268] Batch[5] avg_epoch_loss=2.023583\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.023582677046458\n",
      "[05/21/2025 16:21:41 INFO 140328105305920] Epoch[268] Batch [5]#011Speed: 2160.88 samples/sec#011loss=2.023583\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] processed a total of 1250 examples\n",
      "#metrics {\"StartTime\": 1747844501.179569, \"EndTime\": 1747844502.040682, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 860.8617782592773, \"count\": 1, \"min\": 860.8617782592773, \"max\": 860.8617782592773}}}\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1451.8769185609392 records/second\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 67.25 % of epochs\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.042870056629181\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] Epoch[269] Batch[0] avg_epoch_loss=1.988962\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=1.9889622926712036\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] Epoch[269] Batch[5] avg_epoch_loss=2.039282\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=2.0392818450927734\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] Epoch[269] Batch [5]#011Speed: 2145.87 samples/sec#011loss=2.039282\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] Epoch[269] Batch[10] avg_epoch_loss=2.028661\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=269, batch=10 train loss <loss>=2.0159154891967774\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] Epoch[269] Batch [10]#011Speed: 2219.38 samples/sec#011loss=2.015915\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747844502.0407443, \"EndTime\": 1747844502.9539, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.8751754760742, \"count\": 1, \"min\": 912.8751754760742, \"max\": 912.8751754760742}}}\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1407.5143364743567 records/second\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 67.5 % of epochs\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=269, train loss <loss>=2.028660774230957\n",
      "[05/21/2025 16:21:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] Epoch[270] Batch[0] avg_epoch_loss=2.063635\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=2.0636346340179443\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] Epoch[270] Batch[5] avg_epoch_loss=2.068144\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=2.0681439638137817\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] Epoch[270] Batch [5]#011Speed: 2236.00 samples/sec#011loss=2.068144\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] Epoch[270] Batch[10] avg_epoch_loss=2.095536\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=2.128405809402466\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] Epoch[270] Batch [10]#011Speed: 2040.54 samples/sec#011loss=2.128406\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747844502.953955, \"EndTime\": 1747844503.8727028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.5035228729248, \"count\": 1, \"min\": 918.5035228729248, \"max\": 918.5035228729248}}}\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1453.3194907019044 records/second\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 67.75 % of epochs\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=270, train loss <loss>=2.095535711808638\n",
      "[05/21/2025 16:21:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] Epoch[271] Batch[0] avg_epoch_loss=2.081211\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=2.0812106132507324\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] Epoch[271] Batch[5] avg_epoch_loss=2.050624\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=2.050623973210653\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] Epoch[271] Batch [5]#011Speed: 2203.10 samples/sec#011loss=2.050624\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] Epoch[271] Batch[10] avg_epoch_loss=2.047355\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=271, batch=10 train loss <loss>=2.0434326410293577\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] Epoch[271] Batch [10]#011Speed: 2057.72 samples/sec#011loss=2.043433\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747844503.8727589, \"EndTime\": 1747844504.7900245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.0253276824951, \"count\": 1, \"min\": 917.0253276824951, \"max\": 917.0253276824951}}}\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1482.9153694333352 records/second\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 68.0 % of epochs\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=271, train loss <loss>=2.0473551858555186\n",
      "[05/21/2025 16:21:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] Epoch[272] Batch[0] avg_epoch_loss=2.062631\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=2.062631368637085\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] Epoch[272] Batch[5] avg_epoch_loss=2.049751\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=2.0497512022654214\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] Epoch[272] Batch [5]#011Speed: 2175.81 samples/sec#011loss=2.049751\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] Epoch[272] Batch[10] avg_epoch_loss=2.061618\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=2.075857639312744\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] Epoch[272] Batch [10]#011Speed: 2016.70 samples/sec#011loss=2.075858\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] processed a total of 1365 examples\n",
      "#metrics {\"StartTime\": 1747844504.7900841, \"EndTime\": 1747844505.725321, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.9985122680664, \"count\": 1, \"min\": 934.9985122680664, \"max\": 934.9985122680664}}}\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1459.7643459237843 records/second\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 68.25 % of epochs\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=272, train loss <loss>=2.061617764559659\n",
      "[05/21/2025 16:21:45 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[273] Batch[0] avg_epoch_loss=2.013784\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=2.013784408569336\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[273] Batch[5] avg_epoch_loss=2.027751\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=2.0277512470881143\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[273] Batch [5]#011Speed: 2226.49 samples/sec#011loss=2.027751\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[273] Batch[10] avg_epoch_loss=1.997438\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=273, batch=10 train loss <loss>=1.9610623359680175\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[273] Batch [10]#011Speed: 2124.11 samples/sec#011loss=1.961062\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] processed a total of 1303 examples\n",
      "#metrics {\"StartTime\": 1747844505.725378, \"EndTime\": 1747844506.635154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.5268249511719, \"count\": 1, \"min\": 909.5268249511719, \"max\": 909.5268249511719}}}\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1432.4729895248092 records/second\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 68.5 % of epochs\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=273, train loss <loss>=1.9974381056698887\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] Epoch[274] Batch[0] avg_epoch_loss=1.934196\n",
      "[05/21/2025 16:21:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=1.9341957569122314\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] Epoch[274] Batch[5] avg_epoch_loss=2.043501\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=2.0435009002685547\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] Epoch[274] Batch [5]#011Speed: 2154.11 samples/sec#011loss=2.043501\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] Epoch[274] Batch[10] avg_epoch_loss=2.043374\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=274, batch=10 train loss <loss>=2.0432215452194216\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] Epoch[274] Batch [10]#011Speed: 2101.18 samples/sec#011loss=2.043222\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747844506.635214, \"EndTime\": 1747844507.559697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.2210388183594, \"count\": 1, \"min\": 924.2210388183594, \"max\": 924.2210388183594}}}\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.5944147865976 records/second\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 68.75 % of epochs\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=274, train loss <loss>=2.0433739207007666\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] Epoch[275] Batch[0] avg_epoch_loss=2.001681\n",
      "[05/21/2025 16:21:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=2.001681089401245\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] Epoch[275] Batch[5] avg_epoch_loss=2.102991\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=2.102990984916687\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] Epoch[275] Batch [5]#011Speed: 2112.42 samples/sec#011loss=2.102991\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] processed a total of 1272 examples\n",
      "#metrics {\"StartTime\": 1747844507.5597517, \"EndTime\": 1747844508.4212089, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 861.2117767333984, \"count\": 1, \"min\": 861.2117767333984, \"max\": 861.2117767333984}}}\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1476.8173220251435 records/second\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 69.0 % of epochs\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=275, train loss <loss>=2.091800808906555\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] Epoch[276] Batch[0] avg_epoch_loss=2.097358\n",
      "[05/21/2025 16:21:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=2.097357749938965\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[276] Batch[5] avg_epoch_loss=2.061634\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=2.0616343021392822\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[276] Batch [5]#011Speed: 2242.67 samples/sec#011loss=2.061634\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[276] Batch[10] avg_epoch_loss=2.119225\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=2.1883330583572387\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[276] Batch [10]#011Speed: 2028.87 samples/sec#011loss=2.188333\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] processed a total of 1382 examples\n",
      "#metrics {\"StartTime\": 1747844508.4212794, \"EndTime\": 1747844509.338387, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.8002605438232, \"count\": 1, \"min\": 916.8002605438232, \"max\": 916.8002605438232}}}\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1507.2853622017883 records/second\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 69.25 % of epochs\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=276, train loss <loss>=2.119224645874717\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[277] Batch[0] avg_epoch_loss=2.048753\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=2.048752784729004\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[277] Batch[5] avg_epoch_loss=2.033185\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=2.0331848859786987\n",
      "[05/21/2025 16:21:49 INFO 140328105305920] Epoch[277] Batch [5]#011Speed: 2155.88 samples/sec#011loss=2.033185\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] processed a total of 1275 examples\n",
      "#metrics {\"StartTime\": 1747844509.33844, \"EndTime\": 1747844510.1943762, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 855.663537979126, \"count\": 1, \"min\": 855.663537979126, \"max\": 855.663537979126}}}\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1489.912258584341 records/second\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 69.5 % of epochs\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=277, train loss <loss>=2.0188499689102173\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] Epoch[278] Batch[0] avg_epoch_loss=1.969388\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=1.9693877696990967\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] Epoch[278] Batch[5] avg_epoch_loss=2.031577\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=2.031576673189799\n",
      "[05/21/2025 16:21:50 INFO 140328105305920] Epoch[278] Batch [5]#011Speed: 2142.57 samples/sec#011loss=2.031577\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Epoch[278] Batch[10] avg_epoch_loss=1.956911\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=1.8673123836517334\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Epoch[278] Batch [10]#011Speed: 2121.15 samples/sec#011loss=1.867312\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844510.1944368, \"EndTime\": 1747844511.1165407, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.771764755249, \"count\": 1, \"min\": 921.771764755249, \"max\": 921.771764755249}}}\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1399.3499005701988 records/second\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 69.75 % of epochs\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=278, train loss <loss>=1.9569110870361328\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_65dd1f25-8463-4a5b-bbd3-1f348e9e4723-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844511.1165977, \"EndTime\": 1747844511.1273384, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.480403900146484, \"count\": 1, \"min\": 10.480403900146484, \"max\": 10.480403900146484}}}\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Epoch[279] Batch[0] avg_epoch_loss=2.061907\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=2.0619072914123535\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Epoch[279] Batch[5] avg_epoch_loss=2.049469\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=2.049468755722046\n",
      "[05/21/2025 16:21:51 INFO 140328105305920] Epoch[279] Batch [5]#011Speed: 2161.30 samples/sec#011loss=2.049469\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[279] Batch[10] avg_epoch_loss=2.038807\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=2.026011848449707\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[279] Batch [10]#011Speed: 2030.85 samples/sec#011loss=2.026012\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747844511.1273825, \"EndTime\": 1747844512.0636399, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.2053871154785, \"count\": 1, \"min\": 936.2053871154785, \"max\": 936.2053871154785}}}\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1380.974965279776 records/second\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 70.0 % of epochs\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=279, train loss <loss>=2.03880652514371\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[280] Batch[0] avg_epoch_loss=2.087935\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=2.087934732437134\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[280] Batch[5] avg_epoch_loss=2.069880\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=2.0698802868525186\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[280] Batch [5]#011Speed: 2179.53 samples/sec#011loss=2.069880\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[280] Batch[10] avg_epoch_loss=2.072417\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=2.075461220741272\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] Epoch[280] Batch [10]#011Speed: 2181.11 samples/sec#011loss=2.075461\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844512.0636952, \"EndTime\": 1747844512.9912941, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.3598194122314, \"count\": 1, \"min\": 927.3598194122314, \"max\": 927.3598194122314}}}\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1390.869888108879 records/second\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 70.25 % of epochs\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=280, train loss <loss>=2.07241707498377\n",
      "[05/21/2025 16:21:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] Epoch[281] Batch[0] avg_epoch_loss=2.209831\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=2.2098305225372314\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] Epoch[281] Batch[5] avg_epoch_loss=2.065507\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=2.0655071139335632\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] Epoch[281] Batch [5]#011Speed: 2201.85 samples/sec#011loss=2.065507\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] Epoch[281] Batch[10] avg_epoch_loss=1.974826\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=281, batch=10 train loss <loss>=1.8660086512565612\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] Epoch[281] Batch [10]#011Speed: 2166.90 samples/sec#011loss=1.866009\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747844512.991385, \"EndTime\": 1747844513.9006913, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.0206623077393, \"count\": 1, \"min\": 909.0206623077393, \"max\": 909.0206623077393}}}\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1426.6774142789106 records/second\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 70.5 % of epochs\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=281, train loss <loss>=1.974825994534926\n",
      "[05/21/2025 16:21:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] Epoch[282] Batch[0] avg_epoch_loss=2.123526\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=2.123525857925415\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] Epoch[282] Batch[5] avg_epoch_loss=2.077568\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=2.077568451563517\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] Epoch[282] Batch [5]#011Speed: 2204.18 samples/sec#011loss=2.077568\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] Epoch[282] Batch[10] avg_epoch_loss=2.054749\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=282, batch=10 train loss <loss>=2.027366304397583\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] Epoch[282] Batch [10]#011Speed: 2033.97 samples/sec#011loss=2.027366\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844513.9007478, \"EndTime\": 1747844514.833737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.7487945556641, \"count\": 1, \"min\": 932.7487945556641, \"max\": 932.7487945556641}}}\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1418.2596302650907 records/second\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 70.75 % of epochs\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=282, train loss <loss>=2.05474929376082\n",
      "[05/21/2025 16:21:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] Epoch[283] Batch[0] avg_epoch_loss=2.091890\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=2.0918898582458496\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] Epoch[283] Batch[5] avg_epoch_loss=2.097097\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=2.097096562385559\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] Epoch[283] Batch [5]#011Speed: 2161.13 samples/sec#011loss=2.097097\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] Epoch[283] Batch[10] avg_epoch_loss=2.130858\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=283, batch=10 train loss <loss>=2.171372413635254\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] Epoch[283] Batch [10]#011Speed: 1945.73 samples/sec#011loss=2.171372\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747844514.833795, \"EndTime\": 1747844515.7835844, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 949.5463371276855, \"count\": 1, \"min\": 949.5463371276855, \"max\": 949.5463371276855}}}\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.295098039462 records/second\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 71.0 % of epochs\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=283, train loss <loss>=2.130858312953602\n",
      "[05/21/2025 16:21:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] Epoch[284] Batch[0] avg_epoch_loss=2.001824\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=2.001824140548706\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] Epoch[284] Batch[5] avg_epoch_loss=2.029810\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=2.0298101902008057\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] Epoch[284] Batch [5]#011Speed: 2190.98 samples/sec#011loss=2.029810\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] Epoch[284] Batch[10] avg_epoch_loss=2.029354\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=284, batch=10 train loss <loss>=2.02880597114563\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] Epoch[284] Batch [10]#011Speed: 2032.96 samples/sec#011loss=2.028806\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747844515.7836401, \"EndTime\": 1747844516.7045734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.6669330596924, \"count\": 1, \"min\": 920.6669330596924, \"max\": 920.6669330596924}}}\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.7095675122666 records/second\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 71.25 % of epochs\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=284, train loss <loss>=2.0293537269939077\n",
      "[05/21/2025 16:21:56 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[285] Batch[0] avg_epoch_loss=2.079565\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=2.0795648097991943\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[285] Batch[5] avg_epoch_loss=2.094036\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=2.094035506248474\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[285] Batch [5]#011Speed: 2108.82 samples/sec#011loss=2.094036\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[285] Batch[10] avg_epoch_loss=2.096006\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=2.098370981216431\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[285] Batch [10]#011Speed: 2050.70 samples/sec#011loss=2.098371\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747844516.7046316, \"EndTime\": 1747844517.6455595, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.6795501708984, \"count\": 1, \"min\": 940.6795501708984, \"max\": 940.6795501708984}}}\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1361.6531075038497 records/second\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 71.5 % of epochs\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=285, train loss <loss>=2.0960061766884546\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] Epoch[286] Batch[0] avg_epoch_loss=2.030232\n",
      "[05/21/2025 16:21:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=2.0302324295043945\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] Epoch[286] Batch[5] avg_epoch_loss=2.023871\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=2.023870607217153\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] Epoch[286] Batch [5]#011Speed: 2211.70 samples/sec#011loss=2.023871\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] Epoch[286] Batch[10] avg_epoch_loss=2.054100\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=286, batch=10 train loss <loss>=2.0903759479522703\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] Epoch[286] Batch [10]#011Speed: 2142.79 samples/sec#011loss=2.090376\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747844517.645618, \"EndTime\": 1747844518.5569959, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 911.0972881317139, \"count\": 1, \"min\": 911.0972881317139, \"max\": 911.0972881317139}}}\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1431.1127736368721 records/second\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 71.75 % of epochs\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=286, train loss <loss>=2.0541003075512974\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] Epoch[287] Batch[0] avg_epoch_loss=2.272309\n",
      "[05/21/2025 16:21:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=2.2723093032836914\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] Epoch[287] Batch[5] avg_epoch_loss=2.287042\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=2.2870421012242637\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] Epoch[287] Batch [5]#011Speed: 2162.70 samples/sec#011loss=2.287042\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] Epoch[287] Batch[10] avg_epoch_loss=2.326892\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=2.3747119903564453\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] Epoch[287] Batch [10]#011Speed: 2088.24 samples/sec#011loss=2.374712\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747844518.5570514, \"EndTime\": 1747844519.4828715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.574541091919, \"count\": 1, \"min\": 925.574541091919, \"max\": 925.574541091919}}}\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.5271182158099 records/second\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 72.0 % of epochs\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=287, train loss <loss>=2.3268920508298008\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] Epoch[288] Batch[0] avg_epoch_loss=2.255603\n",
      "[05/21/2025 16:21:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=2.255603313446045\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] Epoch[288] Batch[5] avg_epoch_loss=2.209161\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=2.2091609636942544\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] Epoch[288] Batch [5]#011Speed: 2168.05 samples/sec#011loss=2.209161\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] processed a total of 1271 examples\n",
      "#metrics {\"StartTime\": 1747844519.4829292, \"EndTime\": 1747844520.3461144, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 862.940788269043, \"count\": 1, \"min\": 862.940788269043, \"max\": 862.940788269043}}}\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.7125915514125 records/second\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 72.25 % of epochs\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=288, train loss <loss>=2.1523969173431396\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] Epoch[289] Batch[0] avg_epoch_loss=2.105288\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=2.10528826713562\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] Epoch[289] Batch[5] avg_epoch_loss=2.049546\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=2.0495463609695435\n",
      "[05/21/2025 16:22:00 INFO 140328105305920] Epoch[289] Batch [5]#011Speed: 2121.58 samples/sec#011loss=2.049546\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] Epoch[289] Batch[10] avg_epoch_loss=2.002361\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=289, batch=10 train loss <loss>=1.9457375526428222\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] Epoch[289] Batch [10]#011Speed: 2071.42 samples/sec#011loss=1.945738\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747844520.3461761, \"EndTime\": 1747844521.287912, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.4143562316895, \"count\": 1, \"min\": 941.4143562316895, \"max\": 941.4143562316895}}}\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1378.6480220291694 records/second\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 72.5 % of epochs\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=289, train loss <loss>=2.002360539002852\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] Epoch[290] Batch[0] avg_epoch_loss=2.005005\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=2.005004644393921\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] Epoch[290] Batch[5] avg_epoch_loss=2.052449\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=2.052448829015096\n",
      "[05/21/2025 16:22:01 INFO 140328105305920] Epoch[290] Batch [5]#011Speed: 2085.88 samples/sec#011loss=2.052449\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] Epoch[290] Batch[10] avg_epoch_loss=2.076067\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=290, batch=10 train loss <loss>=2.1044090747833253\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] Epoch[290] Batch [10]#011Speed: 2037.08 samples/sec#011loss=2.104409\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747844521.2879705, \"EndTime\": 1747844522.2581716, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 969.9516296386719, \"count\": 1, \"min\": 969.9516296386719, \"max\": 969.9516296386719}}}\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1358.7114165484245 records/second\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 72.75 % of epochs\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=290, train loss <loss>=2.0760671225461094\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] Epoch[291] Batch[0] avg_epoch_loss=2.174697\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=2.174697160720825\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] Epoch[291] Batch[5] avg_epoch_loss=2.043999\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=2.043999433517456\n",
      "[05/21/2025 16:22:02 INFO 140328105305920] Epoch[291] Batch [5]#011Speed: 2211.62 samples/sec#011loss=2.043999\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] Epoch[291] Batch[10] avg_epoch_loss=2.030773\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=291, batch=10 train loss <loss>=2.014902353286743\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] Epoch[291] Batch [10]#011Speed: 2147.93 samples/sec#011loss=2.014902\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] processed a total of 1337 examples\n",
      "#metrics {\"StartTime\": 1747844522.2582288, \"EndTime\": 1747844523.165221, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.7420959472656, \"count\": 1, \"min\": 906.7420959472656, \"max\": 906.7420959472656}}}\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1474.3681829212278 records/second\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 73.0 % of epochs\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=291, train loss <loss>=2.030773487958041\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] Epoch[292] Batch[0] avg_epoch_loss=1.956750\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=1.9567500352859497\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] Epoch[292] Batch[5] avg_epoch_loss=1.971801\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=1.9718005855878193\n",
      "[05/21/2025 16:22:03 INFO 140328105305920] Epoch[292] Batch [5]#011Speed: 2139.09 samples/sec#011loss=1.971801\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] processed a total of 1269 examples\n",
      "#metrics {\"StartTime\": 1747844523.1652792, \"EndTime\": 1747844524.0216346, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 856.069803237915, \"count\": 1, \"min\": 856.069803237915, \"max\": 856.069803237915}}}\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1482.1852716351575 records/second\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 73.25 % of epochs\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=292, train loss <loss>=1.9699634552001952\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] Epoch[293] Batch[0] avg_epoch_loss=2.018970\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=2.018970489501953\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] Epoch[293] Batch[5] avg_epoch_loss=1.989670\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=1.9896697004636128\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] Epoch[293] Batch [5]#011Speed: 2194.38 samples/sec#011loss=1.989670\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] Epoch[293] Batch[10] avg_epoch_loss=2.028575\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=293, batch=10 train loss <loss>=2.0752606868743895\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] Epoch[293] Batch [10]#011Speed: 2097.82 samples/sec#011loss=2.075261\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747844524.0216937, \"EndTime\": 1747844524.9609344, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.9538764953613, \"count\": 1, \"min\": 938.9538764953613, \"max\": 938.9538764953613}}}\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.8595134487493 records/second\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 73.5 % of epochs\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=293, train loss <loss>=2.0285746942866933\n",
      "[05/21/2025 16:22:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] Epoch[294] Batch[0] avg_epoch_loss=2.025587\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=2.0255866050720215\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] Epoch[294] Batch[5] avg_epoch_loss=2.026751\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=2.0267507632573447\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] Epoch[294] Batch [5]#011Speed: 2166.26 samples/sec#011loss=2.026751\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] Epoch[294] Batch[10] avg_epoch_loss=2.043778\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=294, batch=10 train loss <loss>=2.0642106533050537\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] Epoch[294] Batch [10]#011Speed: 2101.87 samples/sec#011loss=2.064211\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747844524.960993, \"EndTime\": 1747844525.887616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.3420104980469, \"count\": 1, \"min\": 926.3420104980469, \"max\": 926.3420104980469}}}\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1404.318401655703 records/second\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 73.75 % of epochs\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=294, train loss <loss>=2.0437779860063032\n",
      "[05/21/2025 16:22:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] Epoch[295] Batch[0] avg_epoch_loss=1.979458\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=295, batch=0 train loss <loss>=1.979457974433899\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] Epoch[295] Batch[5] avg_epoch_loss=2.060963\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=295, batch=5 train loss <loss>=2.060962696870168\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] Epoch[295] Batch [5]#011Speed: 2169.36 samples/sec#011loss=2.060963\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] Epoch[295] Batch[10] avg_epoch_loss=2.109374\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=295, batch=10 train loss <loss>=2.1674670696258547\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] Epoch[295] Batch [10]#011Speed: 2174.13 samples/sec#011loss=2.167467\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747844525.8876739, \"EndTime\": 1747844526.8001351, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.168025970459, \"count\": 1, \"min\": 912.168025970459, \"max\": 912.168025970459}}}\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1415.1762588630702 records/second\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 74.0 % of epochs\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=295, train loss <loss>=2.10937377539548\n",
      "[05/21/2025 16:22:06 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] Epoch[296] Batch[0] avg_epoch_loss=2.145722\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=296, batch=0 train loss <loss>=2.1457221508026123\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] Epoch[296] Batch[5] avg_epoch_loss=2.133498\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=296, batch=5 train loss <loss>=2.133498469988505\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] Epoch[296] Batch [5]#011Speed: 2137.30 samples/sec#011loss=2.133498\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] Epoch[296] Batch[10] avg_epoch_loss=2.123422\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=296, batch=10 train loss <loss>=2.111329364776611\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] Epoch[296] Batch [10]#011Speed: 1976.66 samples/sec#011loss=2.111329\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747844526.8001943, \"EndTime\": 1747844527.7443001, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.8066482543945, \"count\": 1, \"min\": 943.8066482543945, \"max\": 943.8066482543945}}}\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1441.9029767353513 records/second\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 74.25 % of epochs\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=296, train loss <loss>=2.1234216039830986\n",
      "[05/21/2025 16:22:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[297] Batch[0] avg_epoch_loss=2.233529\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=297, batch=0 train loss <loss>=2.2335288524627686\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[297] Batch[5] avg_epoch_loss=2.200092\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=297, batch=5 train loss <loss>=2.2000917196273804\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[297] Batch [5]#011Speed: 2167.71 samples/sec#011loss=2.200092\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[297] Batch[10] avg_epoch_loss=2.163770\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=297, batch=10 train loss <loss>=2.1201844692230223\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[297] Batch [10]#011Speed: 2148.91 samples/sec#011loss=2.120184\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844527.7443562, \"EndTime\": 1747844528.6606796, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.0811901092529, \"count\": 1, \"min\": 916.0811901092529, \"max\": 916.0811901092529}}}\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1444.06472374677 records/second\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 74.5 % of epochs\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=297, train loss <loss>=2.163770242170854\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] Epoch[298] Batch[0] avg_epoch_loss=2.063551\n",
      "[05/21/2025 16:22:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=298, batch=0 train loss <loss>=2.0635509490966797\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] Epoch[298] Batch[5] avg_epoch_loss=2.046894\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=298, batch=5 train loss <loss>=2.046894371509552\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] Epoch[298] Batch [5]#011Speed: 2193.75 samples/sec#011loss=2.046894\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] Epoch[298] Batch[10] avg_epoch_loss=2.025295\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=298, batch=10 train loss <loss>=1.9993764877319335\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] Epoch[298] Batch [10]#011Speed: 2017.14 samples/sec#011loss=1.999376\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747844528.660735, \"EndTime\": 1747844529.5834246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.4421977996826, \"count\": 1, \"min\": 922.4421977996826, \"max\": 922.4421977996826}}}\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1469.8014871998168 records/second\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 74.75 % of epochs\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=298, train loss <loss>=2.0252953334288164\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] Epoch[299] Batch[0] avg_epoch_loss=2.083143\n",
      "[05/21/2025 16:22:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=299, batch=0 train loss <loss>=2.0831429958343506\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] Epoch[299] Batch[5] avg_epoch_loss=2.059275\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=299, batch=5 train loss <loss>=2.0592748721440635\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] Epoch[299] Batch [5]#011Speed: 2201.29 samples/sec#011loss=2.059275\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] Epoch[299] Batch[10] avg_epoch_loss=2.024920\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=299, batch=10 train loss <loss>=1.983694863319397\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] Epoch[299] Batch [10]#011Speed: 2003.55 samples/sec#011loss=1.983695\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844529.5835195, \"EndTime\": 1747844530.5163586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 932.5780868530273, \"count\": 1, \"min\": 932.5780868530273, \"max\": 932.5780868530273}}}\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.7293447948916 records/second\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 75.0 % of epochs\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=299, train loss <loss>=2.0249203226783057\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] Epoch[300] Batch[0] avg_epoch_loss=2.047976\n",
      "[05/21/2025 16:22:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=300, batch=0 train loss <loss>=2.047976493835449\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] Epoch[300] Batch[5] avg_epoch_loss=2.041773\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=300, batch=5 train loss <loss>=2.0417732993761697\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] Epoch[300] Batch [5]#011Speed: 2150.86 samples/sec#011loss=2.041773\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] Epoch[300] Batch[10] avg_epoch_loss=2.055168\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=300, batch=10 train loss <loss>=2.0712414741516114\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] Epoch[300] Batch [10]#011Speed: 2038.49 samples/sec#011loss=2.071241\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747844530.516414, \"EndTime\": 1747844531.4482005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.541919708252, \"count\": 1, \"min\": 931.541919708252, \"max\": 931.541919708252}}}\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1443.7082006196235 records/second\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 75.25 % of epochs\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=300, train loss <loss>=2.0551679242740977\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] Epoch[301] Batch[0] avg_epoch_loss=1.944075\n",
      "[05/21/2025 16:22:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=301, batch=0 train loss <loss>=1.9440745115280151\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[301] Batch[5] avg_epoch_loss=1.928944\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=301, batch=5 train loss <loss>=1.9289435942967732\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[301] Batch [5]#011Speed: 2126.38 samples/sec#011loss=1.928944\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[301] Batch[10] avg_epoch_loss=1.971324\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=301, batch=10 train loss <loss>=2.0221798419952393\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[301] Batch [10]#011Speed: 2069.68 samples/sec#011loss=2.022180\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] processed a total of 1358 examples\n",
      "#metrics {\"StartTime\": 1747844531.4482589, \"EndTime\": 1747844532.3792346, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.7222366333008, \"count\": 1, \"min\": 930.7222366333008, \"max\": 930.7222366333008}}}\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1458.9544898366398 records/second\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 75.5 % of epochs\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=301, train loss <loss>=1.971323706886985\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[302] Batch[0] avg_epoch_loss=1.976236\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=302, batch=0 train loss <loss>=1.9762358665466309\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[302] Batch[5] avg_epoch_loss=1.983432\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=302, batch=5 train loss <loss>=1.9834323525428772\n",
      "[05/21/2025 16:22:12 INFO 140328105305920] Epoch[302] Batch [5]#011Speed: 2245.66 samples/sec#011loss=1.983432\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] processed a total of 1256 examples\n",
      "#metrics {\"StartTime\": 1747844532.379289, \"EndTime\": 1747844533.2214305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 841.893196105957, \"count\": 1, \"min\": 841.893196105957, \"max\": 841.893196105957}}}\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1491.6856025275754 records/second\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 75.75 % of epochs\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=302, train loss <loss>=2.00654559135437\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] Epoch[303] Batch[0] avg_epoch_loss=1.954631\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=303, batch=0 train loss <loss>=1.954630970954895\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] Epoch[303] Batch[5] avg_epoch_loss=1.975633\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=303, batch=5 train loss <loss>=1.9756327867507935\n",
      "[05/21/2025 16:22:13 INFO 140328105305920] Epoch[303] Batch [5]#011Speed: 2229.87 samples/sec#011loss=1.975633\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Epoch[303] Batch[10] avg_epoch_loss=1.954375\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=303, batch=10 train loss <loss>=1.9288663864135742\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Epoch[303] Batch [10]#011Speed: 2128.71 samples/sec#011loss=1.928866\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844533.221508, \"EndTime\": 1747844534.1283586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.5582752227783, \"count\": 1, \"min\": 906.5582752227783, \"max\": 906.5582752227783}}}\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1473.5695663012802 records/second\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 76.0 % of epochs\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=303, train loss <loss>=1.9543753320520574\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_e9b93e35-329d-4a77-9316-6b9f78f24356-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844534.1284142, \"EndTime\": 1747844534.1393514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.672330856323242, \"count\": 1, \"min\": 10.672330856323242, \"max\": 10.672330856323242}}}\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Epoch[304] Batch[0] avg_epoch_loss=1.897976\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=304, batch=0 train loss <loss>=1.8979763984680176\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Epoch[304] Batch[5] avg_epoch_loss=2.024638\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=304, batch=5 train loss <loss>=2.0246376593907676\n",
      "[05/21/2025 16:22:14 INFO 140328105305920] Epoch[304] Batch [5]#011Speed: 2186.74 samples/sec#011loss=2.024638\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[304] Batch[10] avg_epoch_loss=2.074674\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=304, batch=10 train loss <loss>=2.1347182273864744\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[304] Batch [10]#011Speed: 2107.12 samples/sec#011loss=2.134718\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747844534.1394017, \"EndTime\": 1747844535.0618217, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.36328125, \"count\": 1, \"min\": 922.36328125, \"max\": 922.36328125}}}\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1399.540261637449 records/second\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 76.25 % of epochs\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=304, train loss <loss>=2.074674281206998\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[305] Batch[0] avg_epoch_loss=2.171135\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=305, batch=0 train loss <loss>=2.171135425567627\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[305] Batch[5] avg_epoch_loss=2.119835\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=305, batch=5 train loss <loss>=2.119835158189138\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[305] Batch [5]#011Speed: 2164.84 samples/sec#011loss=2.119835\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[305] Batch[10] avg_epoch_loss=2.142076\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=305, batch=10 train loss <loss>=2.1687654495239257\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] Epoch[305] Batch [10]#011Speed: 2017.76 samples/sec#011loss=2.168765\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] processed a total of 1331 examples\n",
      "#metrics {\"StartTime\": 1747844535.061877, \"EndTime\": 1747844535.9936774, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.5555095672607, \"count\": 1, \"min\": 931.5555095672607, \"max\": 931.5555095672607}}}\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1428.662839407378 records/second\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 76.5 % of epochs\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=305, train loss <loss>=2.1420761997049507\n",
      "[05/21/2025 16:22:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] Epoch[306] Batch[0] avg_epoch_loss=2.242744\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=306, batch=0 train loss <loss>=2.242743730545044\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] Epoch[306] Batch[5] avg_epoch_loss=2.232954\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=306, batch=5 train loss <loss>=2.2329540650049844\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] Epoch[306] Batch [5]#011Speed: 2166.67 samples/sec#011loss=2.232954\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] Epoch[306] Batch[10] avg_epoch_loss=2.106814\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=306, batch=10 train loss <loss>=1.955445647239685\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] Epoch[306] Batch [10]#011Speed: 2054.74 samples/sec#011loss=1.955446\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844535.9937336, \"EndTime\": 1747844536.9229136, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.9026260375977, \"count\": 1, \"min\": 928.9026260375977, \"max\": 928.9026260375977}}}\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1416.5989290759173 records/second\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 76.75 % of epochs\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=306, train loss <loss>=2.1068138751116665\n",
      "[05/21/2025 16:22:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] Epoch[307] Batch[0] avg_epoch_loss=2.151961\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=307, batch=0 train loss <loss>=2.151960849761963\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] Epoch[307] Batch[5] avg_epoch_loss=2.075274\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=307, batch=5 train loss <loss>=2.075273950894674\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] Epoch[307] Batch [5]#011Speed: 2024.54 samples/sec#011loss=2.075274\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] Epoch[307] Batch[10] avg_epoch_loss=2.038361\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=307, batch=10 train loss <loss>=1.9940653324127198\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] Epoch[307] Batch [10]#011Speed: 2105.99 samples/sec#011loss=1.994065\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844536.9229693, \"EndTime\": 1747844537.866043, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.8248405456543, \"count\": 1, \"min\": 942.8248405456543, \"max\": 942.8248405456543}}}\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1405.2250288190523 records/second\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 77.0 % of epochs\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=307, train loss <loss>=2.0383609424937856\n",
      "[05/21/2025 16:22:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] Epoch[308] Batch[0] avg_epoch_loss=1.949635\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=308, batch=0 train loss <loss>=1.9496345520019531\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] Epoch[308] Batch[5] avg_epoch_loss=1.973885\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=308, batch=5 train loss <loss>=1.9738854765892029\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] Epoch[308] Batch [5]#011Speed: 2130.10 samples/sec#011loss=1.973885\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] Epoch[308] Batch[10] avg_epoch_loss=2.003941\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=308, batch=10 train loss <loss>=2.0400076627731325\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] Epoch[308] Batch [10]#011Speed: 2190.94 samples/sec#011loss=2.040008\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747844537.866099, \"EndTime\": 1747844538.7836885, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.341947555542, \"count\": 1, \"min\": 917.341947555542, \"max\": 917.341947555542}}}\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1396.2984624068533 records/second\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 77.25 % of epochs\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=308, train loss <loss>=2.0039410157637163\n",
      "[05/21/2025 16:22:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] Epoch[309] Batch[0] avg_epoch_loss=2.095531\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=309, batch=0 train loss <loss>=2.095531463623047\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] Epoch[309] Batch[5] avg_epoch_loss=2.018467\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=309, batch=5 train loss <loss>=2.018466889858246\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] Epoch[309] Batch [5]#011Speed: 2178.33 samples/sec#011loss=2.018467\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] Epoch[309] Batch[10] avg_epoch_loss=2.004142\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=309, batch=10 train loss <loss>=1.9869529485702515\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] Epoch[309] Batch [10]#011Speed: 2132.95 samples/sec#011loss=1.986953\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747844538.783744, \"EndTime\": 1747844539.703094, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.1067218780518, \"count\": 1, \"min\": 919.1067218780518, \"max\": 919.1067218780518}}}\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1400.1433450338995 records/second\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 77.5 % of epochs\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=309, train loss <loss>=2.0041423710909756\n",
      "[05/21/2025 16:22:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[310] Batch[0] avg_epoch_loss=2.020170\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=310, batch=0 train loss <loss>=2.020169973373413\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[310] Batch[5] avg_epoch_loss=2.008619\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=310, batch=5 train loss <loss>=2.0086193482081094\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[310] Batch [5]#011Speed: 2178.75 samples/sec#011loss=2.008619\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[310] Batch[10] avg_epoch_loss=2.003822\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=310, batch=10 train loss <loss>=1.9980658054351808\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[310] Batch [10]#011Speed: 2172.18 samples/sec#011loss=1.998066\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747844539.7031498, \"EndTime\": 1747844540.6168122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 913.4204387664795, \"count\": 1, \"min\": 913.4204387664795, \"max\": 913.4204387664795}}}\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1415.4280112623828 records/second\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 77.75 % of epochs\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=310, train loss <loss>=2.0038222833113237\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] Epoch[311] Batch[0] avg_epoch_loss=1.999156\n",
      "[05/21/2025 16:22:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=311, batch=0 train loss <loss>=1.9991559982299805\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] Epoch[311] Batch[5] avg_epoch_loss=2.016928\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=311, batch=5 train loss <loss>=2.016928215821584\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] Epoch[311] Batch [5]#011Speed: 2189.49 samples/sec#011loss=2.016928\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] processed a total of 1272 examples\n",
      "#metrics {\"StartTime\": 1747844540.6168685, \"EndTime\": 1747844541.475684, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 857.9583168029785, \"count\": 1, \"min\": 857.9583168029785, \"max\": 857.9583168029785}}}\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1482.435438265787 records/second\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 78.0 % of epochs\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=311, train loss <loss>=2.0079071640968325\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] Epoch[312] Batch[0] avg_epoch_loss=1.948977\n",
      "[05/21/2025 16:22:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=312, batch=0 train loss <loss>=1.9489766359329224\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Epoch[312] Batch[5] avg_epoch_loss=1.974265\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=312, batch=5 train loss <loss>=1.9742645819981892\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Epoch[312] Batch [5]#011Speed: 2155.26 samples/sec#011loss=1.974265\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Epoch[312] Batch[10] avg_epoch_loss=1.931766\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=312, batch=10 train loss <loss>=1.8807667732238769\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Epoch[312] Batch [10]#011Speed: 2034.13 samples/sec#011loss=1.880767\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844541.475743, \"EndTime\": 1747844542.411455, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.4171752929688, \"count\": 1, \"min\": 935.4171752929688, \"max\": 935.4171752929688}}}\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1428.1130871008816 records/second\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 78.25 % of epochs\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=312, train loss <loss>=1.9317655780098655\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_f02184d7-5102-4f09-a7a3-36227fae0c4a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844542.4115117, \"EndTime\": 1747844542.422408, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.606527328491211, \"count\": 1, \"min\": 10.606527328491211, \"max\": 10.606527328491211}}}\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] Epoch[313] Batch[0] avg_epoch_loss=1.989179\n",
      "[05/21/2025 16:22:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=313, batch=0 train loss <loss>=1.989179015159607\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[313] Batch[5] avg_epoch_loss=1.938090\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=313, batch=5 train loss <loss>=1.938089907169342\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[313] Batch [5]#011Speed: 2134.85 samples/sec#011loss=1.938090\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[313] Batch[10] avg_epoch_loss=1.985537\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=313, batch=10 train loss <loss>=2.0424734115600587\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[313] Batch [10]#011Speed: 1959.54 samples/sec#011loss=2.042473\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747844542.4224563, \"EndTime\": 1747844543.374657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.1543979644775, \"count\": 1, \"min\": 952.1543979644775, \"max\": 952.1543979644775}}}\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1409.3096506968861 records/second\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 78.5 % of epochs\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=313, train loss <loss>=1.9855369546196677\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[314] Batch[0] avg_epoch_loss=1.951363\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=314, batch=0 train loss <loss>=1.9513630867004395\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[314] Batch[5] avg_epoch_loss=1.971190\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=314, batch=5 train loss <loss>=1.971190094947815\n",
      "[05/21/2025 16:22:23 INFO 140328105305920] Epoch[314] Batch [5]#011Speed: 2255.12 samples/sec#011loss=1.971190\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Epoch[314] Batch[10] avg_epoch_loss=1.873032\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=314, batch=10 train loss <loss>=1.7552432775497437\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Epoch[314] Batch [10]#011Speed: 2120.32 samples/sec#011loss=1.755243\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844543.374714, \"EndTime\": 1747844544.2794363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 904.350757598877, \"count\": 1, \"min\": 904.350757598877, \"max\": 904.350757598877}}}\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1450.6203502360222 records/second\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 78.75 % of epochs\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=314, train loss <loss>=1.8730324506759644\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_9df92fe5-5c10-46fa-a112-0e1e474613c7-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844544.2794962, \"EndTime\": 1747844544.2903469, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.56528091430664, \"count\": 1, \"min\": 10.56528091430664, \"max\": 10.56528091430664}}}\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Epoch[315] Batch[0] avg_epoch_loss=1.946999\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=315, batch=0 train loss <loss>=1.946998953819275\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Epoch[315] Batch[5] avg_epoch_loss=1.974433\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=315, batch=5 train loss <loss>=1.974432607491811\n",
      "[05/21/2025 16:22:24 INFO 140328105305920] Epoch[315] Batch [5]#011Speed: 2249.34 samples/sec#011loss=1.974433\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] Epoch[315] Batch[10] avg_epoch_loss=1.966270\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=315, batch=10 train loss <loss>=1.9564749956130982\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] Epoch[315] Batch [10]#011Speed: 2052.10 samples/sec#011loss=1.956475\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747844544.2903965, \"EndTime\": 1747844545.2030013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.5573635101318, \"count\": 1, \"min\": 912.5573635101318, \"max\": 912.5573635101318}}}\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1486.896949098523 records/second\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 79.0 % of epochs\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=315, train loss <loss>=1.9662700566378506\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] Epoch[316] Batch[0] avg_epoch_loss=1.991629\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=316, batch=0 train loss <loss>=1.991628646850586\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] Epoch[316] Batch[5] avg_epoch_loss=1.980418\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=316, batch=5 train loss <loss>=1.9804184238115947\n",
      "[05/21/2025 16:22:25 INFO 140328105305920] Epoch[316] Batch [5]#011Speed: 2064.68 samples/sec#011loss=1.980418\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] Epoch[316] Batch[10] avg_epoch_loss=2.034246\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=316, batch=10 train loss <loss>=2.0988384246826173\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] Epoch[316] Batch [10]#011Speed: 1961.23 samples/sec#011loss=2.098838\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] processed a total of 1336 examples\n",
      "#metrics {\"StartTime\": 1747844545.203057, \"EndTime\": 1747844546.1582046, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.9038410186768, \"count\": 1, \"min\": 954.9038410186768, \"max\": 954.9038410186768}}}\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1398.974296086455 records/second\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 79.25 % of epochs\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=316, train loss <loss>=2.0342456969347866\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] Epoch[317] Batch[0] avg_epoch_loss=1.891972\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=317, batch=0 train loss <loss>=1.8919724225997925\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] Epoch[317] Batch[5] avg_epoch_loss=1.940321\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=317, batch=5 train loss <loss>=1.9403212865193684\n",
      "[05/21/2025 16:22:26 INFO 140328105305920] Epoch[317] Batch [5]#011Speed: 2156.09 samples/sec#011loss=1.940321\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] Epoch[317] Batch[10] avg_epoch_loss=1.949080\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=317, batch=10 train loss <loss>=1.9595906496047975\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] Epoch[317] Batch [10]#011Speed: 1947.26 samples/sec#011loss=1.959591\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] processed a total of 1383 examples\n",
      "#metrics {\"StartTime\": 1747844546.1582592, \"EndTime\": 1747844547.1016502, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.1524276733398, \"count\": 1, \"min\": 943.1524276733398, \"max\": 943.1524276733398}}}\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1466.2281080859739 records/second\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 79.5 % of epochs\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=317, train loss <loss>=1.9490800879218362\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] Epoch[318] Batch[0] avg_epoch_loss=2.026574\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=318, batch=0 train loss <loss>=2.0265743732452393\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] Epoch[318] Batch[5] avg_epoch_loss=2.023883\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=318, batch=5 train loss <loss>=2.02388334274292\n",
      "[05/21/2025 16:22:27 INFO 140328105305920] Epoch[318] Batch [5]#011Speed: 2163.53 samples/sec#011loss=2.023883\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[318] Batch[10] avg_epoch_loss=1.996456\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=318, batch=10 train loss <loss>=1.9635438203811646\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[318] Batch [10]#011Speed: 2180.88 samples/sec#011loss=1.963544\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844547.1017065, \"EndTime\": 1747844548.0189257, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.9256687164307, \"count\": 1, \"min\": 916.9256687164307, \"max\": 916.9256687164307}}}\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.745365579712 records/second\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 79.75 % of epochs\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=318, train loss <loss>=1.9964562871239402\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[319] Batch[0] avg_epoch_loss=2.347011\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=319, batch=0 train loss <loss>=2.347011089324951\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[319] Batch[5] avg_epoch_loss=2.366764\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=319, batch=5 train loss <loss>=2.366764227549235\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[319] Batch [5]#011Speed: 2085.16 samples/sec#011loss=2.366764\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[319] Batch[10] avg_epoch_loss=2.370226\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=319, batch=10 train loss <loss>=2.3743792533874513\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] Epoch[319] Batch [10]#011Speed: 2133.99 samples/sec#011loss=2.374379\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844548.018982, \"EndTime\": 1747844548.947572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.3418655395508, \"count\": 1, \"min\": 928.3418655395508, \"max\": 928.3418655395508}}}\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.1505794678603 records/second\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 80.0 % of epochs\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=319, train loss <loss>=2.370225602930242\n",
      "[05/21/2025 16:22:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] Epoch[320] Batch[0] avg_epoch_loss=2.181647\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=320, batch=0 train loss <loss>=2.181647300720215\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] Epoch[320] Batch[5] avg_epoch_loss=2.224921\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=320, batch=5 train loss <loss>=2.224920948346456\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] Epoch[320] Batch [5]#011Speed: 2277.04 samples/sec#011loss=2.224921\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] Epoch[320] Batch[10] avg_epoch_loss=2.280628\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=320, batch=10 train loss <loss>=2.3474770069122313\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] Epoch[320] Batch [10]#011Speed: 2082.69 samples/sec#011loss=2.347477\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747844548.947627, \"EndTime\": 1747844549.855101, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.1717262268066, \"count\": 1, \"min\": 907.1717262268066, \"max\": 907.1717262268066}}}\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1475.875993446009 records/second\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 80.25 % of epochs\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=320, train loss <loss>=2.2806282476945356\n",
      "[05/21/2025 16:22:29 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] Epoch[321] Batch[0] avg_epoch_loss=2.167392\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=321, batch=0 train loss <loss>=2.1673924922943115\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] Epoch[321] Batch[5] avg_epoch_loss=2.095479\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=321, batch=5 train loss <loss>=2.0954786936442056\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] Epoch[321] Batch [5]#011Speed: 2202.23 samples/sec#011loss=2.095479\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] Epoch[321] Batch[10] avg_epoch_loss=2.119892\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=321, batch=10 train loss <loss>=2.1491881370544434\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] Epoch[321] Batch [10]#011Speed: 1923.19 samples/sec#011loss=2.149188\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844549.8551586, \"EndTime\": 1747844550.7983115, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.8999423980713, \"count\": 1, \"min\": 942.8999423980713, \"max\": 942.8999423980713}}}\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1422.0819547123251 records/second\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 80.5 % of epochs\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=321, train loss <loss>=2.1198920770124956\n",
      "[05/21/2025 16:22:30 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] Epoch[322] Batch[0] avg_epoch_loss=2.159278\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=322, batch=0 train loss <loss>=2.1592776775360107\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] Epoch[322] Batch[5] avg_epoch_loss=2.120059\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=322, batch=5 train loss <loss>=2.1200589338938394\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] Epoch[322] Batch [5]#011Speed: 2160.72 samples/sec#011loss=2.120059\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] Epoch[322] Batch[10] avg_epoch_loss=2.044299\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=322, batch=10 train loss <loss>=1.9533878803253173\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] Epoch[322] Batch [10]#011Speed: 2076.19 samples/sec#011loss=1.953388\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747844550.7983673, \"EndTime\": 1747844551.724291, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.6727695465088, \"count\": 1, \"min\": 925.6727695465088, \"max\": 925.6727695465088}}}\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1439.891677843776 records/second\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 80.75 % of epochs\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=322, train loss <loss>=2.044299364089966\n",
      "[05/21/2025 16:22:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[323] Batch[0] avg_epoch_loss=2.091526\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=323, batch=0 train loss <loss>=2.0915257930755615\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[323] Batch[5] avg_epoch_loss=2.026023\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=323, batch=5 train loss <loss>=2.0260226130485535\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[323] Batch [5]#011Speed: 2051.66 samples/sec#011loss=2.026023\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[323] Batch[10] avg_epoch_loss=1.957690\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=323, batch=10 train loss <loss>=1.875690793991089\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[323] Batch [10]#011Speed: 2089.09 samples/sec#011loss=1.875691\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747844551.7243493, \"EndTime\": 1747844552.6682699, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.0503845214844, \"count\": 1, \"min\": 943.0503845214844, \"max\": 943.0503845214844}}}\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1391.1041079448446 records/second\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 81.0 % of epochs\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=323, train loss <loss>=1.9576899680224331\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] Epoch[324] Batch[0] avg_epoch_loss=1.897087\n",
      "[05/21/2025 16:22:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=324, batch=0 train loss <loss>=1.8970872163772583\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] Epoch[324] Batch[5] avg_epoch_loss=1.982966\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=324, batch=5 train loss <loss>=1.9829662442207336\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] Epoch[324] Batch [5]#011Speed: 2166.63 samples/sec#011loss=1.982966\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] Epoch[324] Batch[10] avg_epoch_loss=2.032220\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=324, batch=10 train loss <loss>=2.0913240909576416\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] Epoch[324] Batch [10]#011Speed: 2077.79 samples/sec#011loss=2.091324\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] processed a total of 1352 examples\n",
      "#metrics {\"StartTime\": 1747844552.668325, \"EndTime\": 1747844553.5907888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.1782684326172, \"count\": 1, \"min\": 922.1782684326172, \"max\": 922.1782684326172}}}\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1465.9560132979686 records/second\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 81.25 % of epochs\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=324, train loss <loss>=2.032219810919328\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] Epoch[325] Batch[0] avg_epoch_loss=1.987223\n",
      "[05/21/2025 16:22:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=325, batch=0 train loss <loss>=1.9872232675552368\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] Epoch[325] Batch[5] avg_epoch_loss=1.959030\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=325, batch=5 train loss <loss>=1.9590296546618144\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] Epoch[325] Batch [5]#011Speed: 2211.56 samples/sec#011loss=1.959030\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] processed a total of 1237 examples\n",
      "#metrics {\"StartTime\": 1747844553.5908473, \"EndTime\": 1747844554.439337, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 848.2027053833008, \"count\": 1, \"min\": 848.2027053833008, \"max\": 848.2027053833008}}}\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1458.2212286558579 records/second\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] #progress_metric: host=algo-1, completed 81.5 % of epochs\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=325, train loss <loss>=1.9542640686035155\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] Epoch[326] Batch[0] avg_epoch_loss=1.902865\n",
      "[05/21/2025 16:22:34 INFO 140328105305920] #quality_metric: host=algo-1, epoch=326, batch=0 train loss <loss>=1.9028648138046265\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[326] Batch[5] avg_epoch_loss=1.951081\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=326, batch=5 train loss <loss>=1.951081116994222\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[326] Batch [5]#011Speed: 2229.40 samples/sec#011loss=1.951081\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[326] Batch[10] avg_epoch_loss=1.886111\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=326, batch=10 train loss <loss>=1.8081474304199219\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[326] Batch [10]#011Speed: 2047.07 samples/sec#011loss=1.808147\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747844554.4393966, \"EndTime\": 1747844555.3630896, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.8725433349609, \"count\": 1, \"min\": 922.8725433349609, \"max\": 922.8725433349609}}}\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.7652092868025 records/second\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #progress_metric: host=algo-1, completed 81.75 % of epochs\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=326, train loss <loss>=1.8861112594604492\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[327] Batch[0] avg_epoch_loss=2.087726\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=327, batch=0 train loss <loss>=2.08772611618042\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[327] Batch[5] avg_epoch_loss=1.981912\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] #quality_metric: host=algo-1, epoch=327, batch=5 train loss <loss>=1.9819121956825256\n",
      "[05/21/2025 16:22:35 INFO 140328105305920] Epoch[327] Batch [5]#011Speed: 2159.59 samples/sec#011loss=1.981912\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] Epoch[327] Batch[10] avg_epoch_loss=1.980093\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=327, batch=10 train loss <loss>=1.977909517288208\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] Epoch[327] Batch [10]#011Speed: 2060.34 samples/sec#011loss=1.977910\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] processed a total of 1353 examples\n",
      "#metrics {\"StartTime\": 1747844555.3631475, \"EndTime\": 1747844556.294245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.8521747589111, \"count\": 1, \"min\": 930.8521747589111, \"max\": 930.8521747589111}}}\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1453.3739428586648 records/second\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #progress_metric: host=algo-1, completed 82.0 % of epochs\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=327, train loss <loss>=1.9800927964123813\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] Epoch[328] Batch[0] avg_epoch_loss=2.135504\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=328, batch=0 train loss <loss>=2.1355042457580566\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] Epoch[328] Batch[5] avg_epoch_loss=2.115267\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] #quality_metric: host=algo-1, epoch=328, batch=5 train loss <loss>=2.115267197291056\n",
      "[05/21/2025 16:22:36 INFO 140328105305920] Epoch[328] Batch [5]#011Speed: 2117.49 samples/sec#011loss=2.115267\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] Epoch[328] Batch[10] avg_epoch_loss=2.101479\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=328, batch=10 train loss <loss>=2.0849330186843873\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] Epoch[328] Batch [10]#011Speed: 2123.21 samples/sec#011loss=2.084933\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747844556.2943027, \"EndTime\": 1747844557.217654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.1090545654297, \"count\": 1, \"min\": 923.1090545654297, \"max\": 923.1090545654297}}}\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.8180187895225 records/second\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #progress_metric: host=algo-1, completed 82.25 % of epochs\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=328, train loss <loss>=2.101478934288025\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] Epoch[329] Batch[0] avg_epoch_loss=2.181826\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=329, batch=0 train loss <loss>=2.181825876235962\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] Epoch[329] Batch[5] avg_epoch_loss=2.160175\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] #quality_metric: host=algo-1, epoch=329, batch=5 train loss <loss>=2.1601752440134683\n",
      "[05/21/2025 16:22:37 INFO 140328105305920] Epoch[329] Batch [5]#011Speed: 2176.89 samples/sec#011loss=2.160175\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] Epoch[329] Batch[10] avg_epoch_loss=2.195544\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=329, batch=10 train loss <loss>=2.2379855155944823\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] Epoch[329] Batch [10]#011Speed: 2121.96 samples/sec#011loss=2.237986\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844557.2177124, \"EndTime\": 1747844558.135081, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.1204566955566, \"count\": 1, \"min\": 917.1204566955566, \"max\": 917.1204566955566}}}\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.7950911780586 records/second\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #progress_metric: host=algo-1, completed 82.5 % of epochs\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=329, train loss <loss>=2.195543549277566\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] Epoch[330] Batch[0] avg_epoch_loss=2.020260\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=330, batch=0 train loss <loss>=2.0202596187591553\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] Epoch[330] Batch[5] avg_epoch_loss=2.100488\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] #quality_metric: host=algo-1, epoch=330, batch=5 train loss <loss>=2.100488265355428\n",
      "[05/21/2025 16:22:38 INFO 140328105305920] Epoch[330] Batch [5]#011Speed: 2133.19 samples/sec#011loss=2.100488\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] Epoch[330] Batch[10] avg_epoch_loss=2.037305\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=330, batch=10 train loss <loss>=1.9614856004714967\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] Epoch[330] Batch [10]#011Speed: 2023.49 samples/sec#011loss=1.961486\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747844558.1351368, \"EndTime\": 1747844559.1037602, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 968.3494567871094, \"count\": 1, \"min\": 968.3494567871094, \"max\": 968.3494567871094}}}\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1411.5584660687368 records/second\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #progress_metric: host=algo-1, completed 82.75 % of epochs\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=330, train loss <loss>=2.037305235862732\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] Epoch[331] Batch[0] avg_epoch_loss=2.068285\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=331, batch=0 train loss <loss>=2.0682852268218994\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] Epoch[331] Batch[5] avg_epoch_loss=2.012760\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] #quality_metric: host=algo-1, epoch=331, batch=5 train loss <loss>=2.012760043144226\n",
      "[05/21/2025 16:22:39 INFO 140328105305920] Epoch[331] Batch [5]#011Speed: 2113.59 samples/sec#011loss=2.012760\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[331] Batch[10] avg_epoch_loss=1.999939\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=331, batch=10 train loss <loss>=1.9845544338226317\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[331] Batch [10]#011Speed: 2118.85 samples/sec#011loss=1.984554\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747844559.103815, \"EndTime\": 1747844560.0303965, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 926.2869358062744, \"count\": 1, \"min\": 926.2869358062744, \"max\": 926.2869358062744}}}\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1393.6142767799006 records/second\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 83.0 % of epochs\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=331, train loss <loss>=1.9999393116344104\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[332] Batch[0] avg_epoch_loss=1.925253\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=332, batch=0 train loss <loss>=1.9252533912658691\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[332] Batch[5] avg_epoch_loss=1.997668\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=332, batch=5 train loss <loss>=1.997667908668518\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[332] Batch [5]#011Speed: 2130.50 samples/sec#011loss=1.997668\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[332] Batch[10] avg_epoch_loss=1.966203\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=332, batch=10 train loss <loss>=1.9284443616867066\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] Epoch[332] Batch [10]#011Speed: 2125.11 samples/sec#011loss=1.928444\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] processed a total of 1290 examples\n",
      "#metrics {\"StartTime\": 1747844560.0304494, \"EndTime\": 1747844560.956516, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.8229732513428, \"count\": 1, \"min\": 925.8229732513428, \"max\": 925.8229732513428}}}\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1393.229350696904 records/second\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #progress_metric: host=algo-1, completed 83.25 % of epochs\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] #quality_metric: host=algo-1, epoch=332, train loss <loss>=1.9662026600404219\n",
      "[05/21/2025 16:22:40 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] Epoch[333] Batch[0] avg_epoch_loss=1.883147\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=333, batch=0 train loss <loss>=1.8831466436386108\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] Epoch[333] Batch[5] avg_epoch_loss=1.934529\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=333, batch=5 train loss <loss>=1.9345289468765259\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] Epoch[333] Batch [5]#011Speed: 2196.75 samples/sec#011loss=1.934529\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] Epoch[333] Batch[10] avg_epoch_loss=1.892304\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=333, batch=10 train loss <loss>=1.8416346073150636\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] Epoch[333] Batch [10]#011Speed: 2139.35 samples/sec#011loss=1.841635\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] processed a total of 1285 examples\n",
      "#metrics {\"StartTime\": 1747844560.9565718, \"EndTime\": 1747844561.8730876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.2371158599854, \"count\": 1, \"min\": 916.2371158599854, \"max\": 916.2371158599854}}}\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1402.3436502332088 records/second\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #progress_metric: host=algo-1, completed 83.5 % of epochs\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] #quality_metric: host=algo-1, epoch=333, train loss <loss>=1.892304247075861\n",
      "[05/21/2025 16:22:41 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] Epoch[334] Batch[0] avg_epoch_loss=1.939021\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=334, batch=0 train loss <loss>=1.9390212297439575\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] Epoch[334] Batch[5] avg_epoch_loss=1.984599\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=334, batch=5 train loss <loss>=1.9845987558364868\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] Epoch[334] Batch [5]#011Speed: 2116.73 samples/sec#011loss=1.984599\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] Epoch[334] Batch[10] avg_epoch_loss=1.969920\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=334, batch=10 train loss <loss>=1.9523045778274537\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] Epoch[334] Batch [10]#011Speed: 2155.68 samples/sec#011loss=1.952305\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747844561.873146, \"EndTime\": 1747844562.7984486, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0564575195312, \"count\": 1, \"min\": 925.0564575195312, \"max\": 925.0564575195312}}}\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1386.8208482419436 records/second\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #progress_metric: host=algo-1, completed 83.75 % of epochs\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] #quality_metric: host=algo-1, epoch=334, train loss <loss>=1.969919584014199\n",
      "[05/21/2025 16:22:42 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] Epoch[335] Batch[0] avg_epoch_loss=1.901392\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=335, batch=0 train loss <loss>=1.9013919830322266\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] Epoch[335] Batch[5] avg_epoch_loss=1.957714\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=335, batch=5 train loss <loss>=1.9577135642369587\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] Epoch[335] Batch [5]#011Speed: 2178.01 samples/sec#011loss=1.957714\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] Epoch[335] Batch[10] avg_epoch_loss=1.916576\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=335, batch=10 train loss <loss>=1.867211675643921\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] Epoch[335] Batch [10]#011Speed: 2187.86 samples/sec#011loss=1.867212\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844562.7985, \"EndTime\": 1747844563.7062461, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 907.5021743774414, \"count\": 1, \"min\": 907.5021743774414, \"max\": 907.5021743774414}}}\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1442.2915752593926 records/second\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #progress_metric: host=algo-1, completed 84.0 % of epochs\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] #quality_metric: host=algo-1, epoch=335, train loss <loss>=1.9165763421492144\n",
      "[05/21/2025 16:22:43 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[336] Batch[0] avg_epoch_loss=1.946753\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=336, batch=0 train loss <loss>=1.9467525482177734\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[336] Batch[5] avg_epoch_loss=1.934292\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=336, batch=5 train loss <loss>=1.9342920184135437\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[336] Batch [5]#011Speed: 2175.28 samples/sec#011loss=1.934292\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[336] Batch[10] avg_epoch_loss=1.923450\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=336, batch=10 train loss <loss>=1.9104394674301148\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[336] Batch [10]#011Speed: 2172.54 samples/sec#011loss=1.910439\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747844563.706301, \"EndTime\": 1747844564.6212766, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 914.689302444458, \"count\": 1, \"min\": 914.689302444458, \"max\": 914.689302444458}}}\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1401.443882666589 records/second\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #progress_metric: host=algo-1, completed 84.25 % of epochs\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=336, train loss <loss>=1.9234499497847124\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] Epoch[337] Batch[0] avg_epoch_loss=1.890816\n",
      "[05/21/2025 16:22:44 INFO 140328105305920] #quality_metric: host=algo-1, epoch=337, batch=0 train loss <loss>=1.8908156156539917\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] Epoch[337] Batch[5] avg_epoch_loss=1.950219\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=337, batch=5 train loss <loss>=1.9502187768618267\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] Epoch[337] Batch [5]#011Speed: 2131.19 samples/sec#011loss=1.950219\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] Epoch[337] Batch[10] avg_epoch_loss=1.966249\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=337, batch=10 train loss <loss>=1.9854860782623291\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] Epoch[337] Batch [10]#011Speed: 1970.77 samples/sec#011loss=1.985486\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] processed a total of 1338 examples\n",
      "#metrics {\"StartTime\": 1747844564.6213305, \"EndTime\": 1747844565.5676954, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.1073875427246, \"count\": 1, \"min\": 946.1073875427246, \"max\": 946.1073875427246}}}\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1414.099968578237 records/second\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #progress_metric: host=algo-1, completed 84.5 % of epochs\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=337, train loss <loss>=1.9662493684075095\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] Epoch[338] Batch[0] avg_epoch_loss=1.830634\n",
      "[05/21/2025 16:22:45 INFO 140328105305920] #quality_metric: host=algo-1, epoch=338, batch=0 train loss <loss>=1.8306337594985962\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Epoch[338] Batch[5] avg_epoch_loss=1.918262\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=338, batch=5 train loss <loss>=1.9182615677515666\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Epoch[338] Batch [5]#011Speed: 2206.55 samples/sec#011loss=1.918262\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Epoch[338] Batch[10] avg_epoch_loss=1.857293\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=338, batch=10 train loss <loss>=1.7841316223144532\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Epoch[338] Batch [10]#011Speed: 2093.32 samples/sec#011loss=1.784132\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747844565.5677466, \"EndTime\": 1747844566.4874063, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.3406105041504, \"count\": 1, \"min\": 919.3406105041504, \"max\": 919.3406105041504}}}\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1422.5991136354974 records/second\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #progress_metric: host=algo-1, completed 84.75 % of epochs\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=338, train loss <loss>=1.8572934107346968\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_2da286c3-01cb-474e-a953-ef3afd2f7c89-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844566.4874752, \"EndTime\": 1747844566.49809, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.282278060913086, \"count\": 1, \"min\": 10.282278060913086, \"max\": 10.282278060913086}}}\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] Epoch[339] Batch[0] avg_epoch_loss=2.045336\n",
      "[05/21/2025 16:22:46 INFO 140328105305920] #quality_metric: host=algo-1, epoch=339, batch=0 train loss <loss>=2.0453362464904785\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] Epoch[339] Batch[5] avg_epoch_loss=2.040904\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=339, batch=5 train loss <loss>=2.040903707345327\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] Epoch[339] Batch [5]#011Speed: 2098.18 samples/sec#011loss=2.040904\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] processed a total of 1276 examples\n",
      "#metrics {\"StartTime\": 1747844566.4981372, \"EndTime\": 1747844567.3773854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 879.1966438293457, \"count\": 1, \"min\": 879.1966438293457, \"max\": 879.1966438293457}}}\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1451.1505921404228 records/second\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] #progress_metric: host=algo-1, completed 85.0 % of epochs\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=339, train loss <loss>=2.017747735977173\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] Epoch[340] Batch[0] avg_epoch_loss=1.942451\n",
      "[05/21/2025 16:22:47 INFO 140328105305920] #quality_metric: host=algo-1, epoch=340, batch=0 train loss <loss>=1.9424514770507812\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] Epoch[340] Batch[5] avg_epoch_loss=1.943193\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=340, batch=5 train loss <loss>=1.9431930979092915\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] Epoch[340] Batch [5]#011Speed: 2017.46 samples/sec#011loss=1.943193\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] processed a total of 1238 examples\n",
      "#metrics {\"StartTime\": 1747844567.3774617, \"EndTime\": 1747844568.2650363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 887.1505260467529, \"count\": 1, \"min\": 887.1505260467529, \"max\": 887.1505260467529}}}\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1395.3403327664241 records/second\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #progress_metric: host=algo-1, completed 85.25 % of epochs\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=340, train loss <loss>=1.9766751885414124\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] Epoch[341] Batch[0] avg_epoch_loss=1.898194\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=341, batch=0 train loss <loss>=1.8981939554214478\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] Epoch[341] Batch[5] avg_epoch_loss=1.937606\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] #quality_metric: host=algo-1, epoch=341, batch=5 train loss <loss>=1.9376058181126912\n",
      "[05/21/2025 16:22:48 INFO 140328105305920] Epoch[341] Batch [5]#011Speed: 2110.53 samples/sec#011loss=1.937606\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] Epoch[341] Batch[10] avg_epoch_loss=1.953986\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=341, batch=10 train loss <loss>=1.9736428260803223\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] Epoch[341] Batch [10]#011Speed: 1984.65 samples/sec#011loss=1.973643\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747844568.2650907, \"EndTime\": 1747844569.20618, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.7081604003906, \"count\": 1, \"min\": 940.7081604003906, \"max\": 940.7081604003906}}}\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1464.6875752648716 records/second\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #progress_metric: host=algo-1, completed 85.5 % of epochs\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=341, train loss <loss>=1.9539862762797962\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] Epoch[342] Batch[0] avg_epoch_loss=1.960180\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=342, batch=0 train loss <loss>=1.9601795673370361\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] Epoch[342] Batch[5] avg_epoch_loss=1.911338\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] #quality_metric: host=algo-1, epoch=342, batch=5 train loss <loss>=1.9113381505012512\n",
      "[05/21/2025 16:22:49 INFO 140328105305920] Epoch[342] Batch [5]#011Speed: 2086.22 samples/sec#011loss=1.911338\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] Epoch[342] Batch[10] avg_epoch_loss=1.906371\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=342, batch=10 train loss <loss>=1.9004103660583496\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] Epoch[342] Batch [10]#011Speed: 1982.55 samples/sec#011loss=1.900410\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747844569.206239, \"EndTime\": 1747844570.151264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.7231292724609, \"count\": 1, \"min\": 944.7231292724609, \"max\": 944.7231292724609}}}\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1451.0804096260404 records/second\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #progress_metric: host=algo-1, completed 85.75 % of epochs\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=342, train loss <loss>=1.9063709757544778\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] Epoch[343] Batch[0] avg_epoch_loss=1.867126\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=343, batch=0 train loss <loss>=1.867126226425171\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] Epoch[343] Batch[5] avg_epoch_loss=1.952001\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] #quality_metric: host=algo-1, epoch=343, batch=5 train loss <loss>=1.9520011742909749\n",
      "[05/21/2025 16:22:50 INFO 140328105305920] Epoch[343] Batch [5]#011Speed: 2110.37 samples/sec#011loss=1.952001\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747844570.1513247, \"EndTime\": 1747844571.020203, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 868.5636520385742, \"count\": 1, \"min\": 868.5636520385742, \"max\": 868.5636520385742}}}\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.4064160599387 records/second\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 86.0 % of epochs\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=343, train loss <loss>=1.9415612936019897\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] Epoch[344] Batch[0] avg_epoch_loss=1.878242\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=344, batch=0 train loss <loss>=1.8782421350479126\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] Epoch[344] Batch[5] avg_epoch_loss=1.928460\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=344, batch=5 train loss <loss>=1.9284604787826538\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] Epoch[344] Batch [5]#011Speed: 2111.31 samples/sec#011loss=1.928460\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] Epoch[344] Batch[10] avg_epoch_loss=1.950319\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=344, batch=10 train loss <loss>=1.9765501976013184\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] Epoch[344] Batch [10]#011Speed: 2037.53 samples/sec#011loss=1.976550\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747844571.0202715, \"EndTime\": 1747844571.96086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.2077198028564, \"count\": 1, \"min\": 940.2077198028564, \"max\": 940.2077198028564}}}\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1427.2127874073249 records/second\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #progress_metric: host=algo-1, completed 86.25 % of epochs\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] #quality_metric: host=algo-1, epoch=344, train loss <loss>=1.9503194418820469\n",
      "[05/21/2025 16:22:51 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] Epoch[345] Batch[0] avg_epoch_loss=1.881248\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=345, batch=0 train loss <loss>=1.8812483549118042\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] Epoch[345] Batch[5] avg_epoch_loss=1.928709\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=345, batch=5 train loss <loss>=1.9287087122599285\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] Epoch[345] Batch [5]#011Speed: 2146.66 samples/sec#011loss=1.928709\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] Epoch[345] Batch[10] avg_epoch_loss=1.887068\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=345, batch=10 train loss <loss>=1.837098240852356\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] Epoch[345] Batch [10]#011Speed: 2085.24 samples/sec#011loss=1.837098\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844571.9609158, \"EndTime\": 1747844572.9036353, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.4736499786377, \"count\": 1, \"min\": 942.4736499786377, \"max\": 942.4736499786377}}}\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1385.5917526628527 records/second\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #progress_metric: host=algo-1, completed 86.5 % of epochs\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] #quality_metric: host=algo-1, epoch=345, train loss <loss>=1.88706758889285\n",
      "[05/21/2025 16:22:52 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] Epoch[346] Batch[0] avg_epoch_loss=1.964410\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=346, batch=0 train loss <loss>=1.964409589767456\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] Epoch[346] Batch[5] avg_epoch_loss=2.004757\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=346, batch=5 train loss <loss>=2.004756987094879\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] Epoch[346] Batch [5]#011Speed: 2157.31 samples/sec#011loss=2.004757\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] Epoch[346] Batch[10] avg_epoch_loss=1.977614\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=346, batch=10 train loss <loss>=1.9450418949127197\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] Epoch[346] Batch [10]#011Speed: 2111.34 samples/sec#011loss=1.945042\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747844572.9036922, \"EndTime\": 1747844573.8238196, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.8799133300781, \"count\": 1, \"min\": 919.8799133300781, \"max\": 919.8799133300781}}}\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1444.6220025459959 records/second\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #progress_metric: host=algo-1, completed 86.75 % of epochs\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] #quality_metric: host=algo-1, epoch=346, train loss <loss>=1.9776137633757158\n",
      "[05/21/2025 16:22:53 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] Epoch[347] Batch[0] avg_epoch_loss=1.958619\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=347, batch=0 train loss <loss>=1.9586193561553955\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] Epoch[347] Batch[5] avg_epoch_loss=1.987577\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=347, batch=5 train loss <loss>=1.9875773191452026\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] Epoch[347] Batch [5]#011Speed: 2143.78 samples/sec#011loss=1.987577\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] Epoch[347] Batch[10] avg_epoch_loss=1.964913\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=347, batch=10 train loss <loss>=1.9377164125442505\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] Epoch[347] Batch [10]#011Speed: 2137.32 samples/sec#011loss=1.937716\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747844573.8238757, \"EndTime\": 1747844574.7438056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.666051864624, \"count\": 1, \"min\": 919.666051864624, \"max\": 919.666051864624}}}\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1449.3061645591572 records/second\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #progress_metric: host=algo-1, completed 87.0 % of epochs\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] #quality_metric: host=algo-1, epoch=347, train loss <loss>=1.9649132706902244\n",
      "[05/21/2025 16:22:54 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[348] Batch[0] avg_epoch_loss=1.981183\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=348, batch=0 train loss <loss>=1.9811831712722778\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[348] Batch[5] avg_epoch_loss=1.988753\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=348, batch=5 train loss <loss>=1.988753080368042\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[348] Batch [5]#011Speed: 2203.55 samples/sec#011loss=1.988753\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[348] Batch[10] avg_epoch_loss=2.008597\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=348, batch=10 train loss <loss>=2.032410192489624\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[348] Batch [10]#011Speed: 2093.91 samples/sec#011loss=2.032410\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747844574.743862, \"EndTime\": 1747844575.6606205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.5079593658447, \"count\": 1, \"min\": 916.5079593658447, \"max\": 916.5079593658447}}}\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.753869460086 records/second\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #progress_metric: host=algo-1, completed 87.25 % of epochs\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=348, train loss <loss>=2.0085972222414883\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] Epoch[349] Batch[0] avg_epoch_loss=1.892482\n",
      "[05/21/2025 16:22:55 INFO 140328105305920] #quality_metric: host=algo-1, epoch=349, batch=0 train loss <loss>=1.8924821615219116\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Epoch[349] Batch[5] avg_epoch_loss=1.957979\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=349, batch=5 train loss <loss>=1.957979142665863\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Epoch[349] Batch [5]#011Speed: 2207.48 samples/sec#011loss=1.957979\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Epoch[349] Batch[10] avg_epoch_loss=1.855209\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=349, batch=10 train loss <loss>=1.7318843126296997\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Epoch[349] Batch [10]#011Speed: 2111.63 samples/sec#011loss=1.731884\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] processed a total of 1295 examples\n",
      "#metrics {\"StartTime\": 1747844575.6606772, \"EndTime\": 1747844576.581631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.7141399383545, \"count\": 1, \"min\": 920.7141399383545, \"max\": 920.7141399383545}}}\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1406.3912586416716 records/second\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #progress_metric: host=algo-1, completed 87.5 % of epochs\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=349, train loss <loss>=1.855208765376698\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] best epoch loss so far\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/state_486bfebe-1e6d-48df-89bb-542d9321fd20-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844576.581686, \"EndTime\": 1747844576.5925927, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.646343231201172, \"count\": 1, \"min\": 10.646343231201172, \"max\": 10.646343231201172}}}\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] Epoch[350] Batch[0] avg_epoch_loss=2.013490\n",
      "[05/21/2025 16:22:56 INFO 140328105305920] #quality_metric: host=algo-1, epoch=350, batch=0 train loss <loss>=2.0134904384613037\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] Epoch[350] Batch[5] avg_epoch_loss=1.937004\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=350, batch=5 train loss <loss>=1.937003533045451\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] Epoch[350] Batch [5]#011Speed: 2104.56 samples/sec#011loss=1.937004\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] Epoch[350] Batch[10] avg_epoch_loss=1.952326\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=350, batch=10 train loss <loss>=1.9707127571105958\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] Epoch[350] Batch [10]#011Speed: 2064.14 samples/sec#011loss=1.970713\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747844576.5926404, \"EndTime\": 1747844577.5282218, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.5344772338867, \"count\": 1, \"min\": 935.5344772338867, \"max\": 935.5344772338867}}}\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1419.3813657062333 records/second\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #progress_metric: host=algo-1, completed 87.75 % of epochs\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=350, train loss <loss>=1.9523259076205166\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] Epoch[351] Batch[0] avg_epoch_loss=1.905909\n",
      "[05/21/2025 16:22:57 INFO 140328105305920] #quality_metric: host=algo-1, epoch=351, batch=0 train loss <loss>=1.9059085845947266\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] Epoch[351] Batch[5] avg_epoch_loss=1.883299\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=351, batch=5 train loss <loss>=1.8832994898160298\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] Epoch[351] Batch [5]#011Speed: 2190.22 samples/sec#011loss=1.883299\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] Epoch[351] Batch[10] avg_epoch_loss=1.961825\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=351, batch=10 train loss <loss>=2.0560564279556273\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] Epoch[351] Batch [10]#011Speed: 2070.40 samples/sec#011loss=2.056056\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747844577.528278, \"EndTime\": 1747844578.4460626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.4978733062744, \"count\": 1, \"min\": 917.4978733062744, \"max\": 917.4978733062744}}}\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1423.307461855099 records/second\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #progress_metric: host=algo-1, completed 88.0 % of epochs\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=351, train loss <loss>=1.9618253707885742\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] Epoch[352] Batch[0] avg_epoch_loss=1.902905\n",
      "[05/21/2025 16:22:58 INFO 140328105305920] #quality_metric: host=algo-1, epoch=352, batch=0 train loss <loss>=1.902904987335205\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] Epoch[352] Batch[5] avg_epoch_loss=1.909955\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=352, batch=5 train loss <loss>=1.9099551439285278\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] Epoch[352] Batch [5]#011Speed: 2074.71 samples/sec#011loss=1.909955\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] Epoch[352] Batch[10] avg_epoch_loss=1.922973\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=352, batch=10 train loss <loss>=1.9385939359664917\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] Epoch[352] Batch [10]#011Speed: 2044.01 samples/sec#011loss=1.938594\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747844578.4461184, \"EndTime\": 1747844579.3873055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.9317970275879, \"count\": 1, \"min\": 940.9317970275879, \"max\": 940.9317970275879}}}\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1392.1148850996985 records/second\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #progress_metric: host=algo-1, completed 88.25 % of epochs\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=352, train loss <loss>=1.9229727766730569\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] Epoch[353] Batch[0] avg_epoch_loss=1.955073\n",
      "[05/21/2025 16:22:59 INFO 140328105305920] #quality_metric: host=algo-1, epoch=353, batch=0 train loss <loss>=1.9550726413726807\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[353] Batch[5] avg_epoch_loss=1.926557\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=353, batch=5 train loss <loss>=1.9265571633974712\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[353] Batch [5]#011Speed: 2150.30 samples/sec#011loss=1.926557\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[353] Batch[10] avg_epoch_loss=1.987137\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=353, batch=10 train loss <loss>=2.0598335027694703\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[353] Batch [10]#011Speed: 2113.49 samples/sec#011loss=2.059834\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747844579.387361, \"EndTime\": 1747844580.3122797, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.6659278869629, \"count\": 1, \"min\": 924.6659278869629, \"max\": 924.6659278869629}}}\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1391.7273590030431 records/second\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #progress_metric: host=algo-1, completed 88.5 % of epochs\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=353, train loss <loss>=1.9871373176574707\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[354] Batch[0] avg_epoch_loss=1.997734\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=354, batch=0 train loss <loss>=1.9977338314056396\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[354] Batch[5] avg_epoch_loss=1.935116\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] #quality_metric: host=algo-1, epoch=354, batch=5 train loss <loss>=1.9351160724957783\n",
      "[05/21/2025 16:23:00 INFO 140328105305920] Epoch[354] Batch [5]#011Speed: 2076.65 samples/sec#011loss=1.935116\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] Epoch[354] Batch[10] avg_epoch_loss=1.978463\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=354, batch=10 train loss <loss>=2.030479907989502\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] Epoch[354] Batch [10]#011Speed: 2058.25 samples/sec#011loss=2.030480\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] processed a total of 1310 examples\n",
      "#metrics {\"StartTime\": 1747844580.3123374, \"EndTime\": 1747844581.2531357, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.5124187469482, \"count\": 1, \"min\": 940.5124187469482, \"max\": 940.5124187469482}}}\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1392.7362863513808 records/second\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #progress_metric: host=algo-1, completed 88.75 % of epochs\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=354, train loss <loss>=1.978463270447471\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] Epoch[355] Batch[0] avg_epoch_loss=1.894016\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=355, batch=0 train loss <loss>=1.8940162658691406\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] Epoch[355] Batch[5] avg_epoch_loss=1.957568\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] #quality_metric: host=algo-1, epoch=355, batch=5 train loss <loss>=1.9575678706169128\n",
      "[05/21/2025 16:23:01 INFO 140328105305920] Epoch[355] Batch [5]#011Speed: 1786.76 samples/sec#011loss=1.957568\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] Epoch[355] Batch[10] avg_epoch_loss=1.998796\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=355, batch=10 train loss <loss>=2.0482698917388915\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] Epoch[355] Batch [10]#011Speed: 1953.32 samples/sec#011loss=2.048270\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] processed a total of 1302 examples\n",
      "#metrics {\"StartTime\": 1747844581.253189, \"EndTime\": 1747844582.266266, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1012.8347873687744, \"count\": 1, \"min\": 1012.8347873687744, \"max\": 1012.8347873687744}}}\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1285.3889161533687 records/second\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #progress_metric: host=algo-1, completed 89.0 % of epochs\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=355, train loss <loss>=1.9987960620359941\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] Epoch[356] Batch[0] avg_epoch_loss=1.942045\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=356, batch=0 train loss <loss>=1.9420450925827026\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] Epoch[356] Batch[5] avg_epoch_loss=1.959397\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] #quality_metric: host=algo-1, epoch=356, batch=5 train loss <loss>=1.9593968987464905\n",
      "[05/21/2025 16:23:02 INFO 140328105305920] Epoch[356] Batch [5]#011Speed: 2206.91 samples/sec#011loss=1.959397\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] Epoch[356] Batch[10] avg_epoch_loss=2.074807\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=356, batch=10 train loss <loss>=2.213299512863159\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] Epoch[356] Batch [10]#011Speed: 2013.22 samples/sec#011loss=2.213300\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] processed a total of 1341 examples\n",
      "#metrics {\"StartTime\": 1747844582.2663257, \"EndTime\": 1747844583.2044992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.9241466522217, \"count\": 1, \"min\": 937.9241466522217, \"max\": 937.9241466522217}}}\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1429.6306776647089 records/second\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #progress_metric: host=algo-1, completed 89.25 % of epochs\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=356, train loss <loss>=2.0748071778904307\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] Epoch[357] Batch[0] avg_epoch_loss=1.874987\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=357, batch=0 train loss <loss>=1.8749868869781494\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] Epoch[357] Batch[5] avg_epoch_loss=1.923519\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] #quality_metric: host=algo-1, epoch=357, batch=5 train loss <loss>=1.9235188563664753\n",
      "[05/21/2025 16:23:03 INFO 140328105305920] Epoch[357] Batch [5]#011Speed: 2007.30 samples/sec#011loss=1.923519\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] processed a total of 1228 examples\n",
      "#metrics {\"StartTime\": 1747844583.204552, \"EndTime\": 1747844584.0819535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 877.1514892578125, \"count\": 1, \"min\": 877.1514892578125, \"max\": 877.1514892578125}}}\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1399.7967440477582 records/second\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 89.5 % of epochs\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=357, train loss <loss>=1.9079267859458924\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] Epoch[358] Batch[0] avg_epoch_loss=1.922627\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=358, batch=0 train loss <loss>=1.9226268529891968\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] Epoch[358] Batch[5] avg_epoch_loss=1.940480\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=358, batch=5 train loss <loss>=1.940480371316274\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] Epoch[358] Batch [5]#011Speed: 2134.65 samples/sec#011loss=1.940480\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] processed a total of 1280 examples\n",
      "#metrics {\"StartTime\": 1747844584.0820324, \"EndTime\": 1747844584.951548, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 869.1158294677734, \"count\": 1, \"min\": 869.1158294677734, \"max\": 869.1158294677734}}}\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1472.6043770729764 records/second\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #progress_metric: host=algo-1, completed 89.75 % of epochs\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] #quality_metric: host=algo-1, epoch=358, train loss <loss>=1.9196133971214295\n",
      "[05/21/2025 16:23:04 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] Epoch[359] Batch[0] avg_epoch_loss=1.867336\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=359, batch=0 train loss <loss>=1.8673360347747803\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] Epoch[359] Batch[5] avg_epoch_loss=1.919697\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=359, batch=5 train loss <loss>=1.9196965893109639\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] Epoch[359] Batch [5]#011Speed: 2097.69 samples/sec#011loss=1.919697\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] processed a total of 1253 examples\n",
      "#metrics {\"StartTime\": 1747844584.9516065, \"EndTime\": 1747844585.835968, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 884.0134143829346, \"count\": 1, \"min\": 884.0134143829346, \"max\": 884.0134143829346}}}\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1417.2502352212427 records/second\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] #progress_metric: host=algo-1, completed 90.0 % of epochs\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] #quality_metric: host=algo-1, epoch=359, train loss <loss>=1.9233336806297303\n",
      "[05/21/2025 16:23:05 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] Epoch[360] Batch[0] avg_epoch_loss=1.924537\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=360, batch=0 train loss <loss>=1.9245374202728271\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] Epoch[360] Batch[5] avg_epoch_loss=1.921983\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=360, batch=5 train loss <loss>=1.9219831625620525\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] Epoch[360] Batch [5]#011Speed: 2181.51 samples/sec#011loss=1.921983\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] Epoch[360] Batch[10] avg_epoch_loss=1.910325\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=360, batch=10 train loss <loss>=1.896335482597351\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] Epoch[360] Batch [10]#011Speed: 1956.76 samples/sec#011loss=1.896335\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747844585.8360302, \"EndTime\": 1747844586.7746053, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.2884502410889, \"count\": 1, \"min\": 938.2884502410889, \"max\": 938.2884502410889}}}\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1409.891278288332 records/second\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #progress_metric: host=algo-1, completed 90.25 % of epochs\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] #quality_metric: host=algo-1, epoch=360, train loss <loss>=1.910325126214461\n",
      "[05/21/2025 16:23:06 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] Epoch[361] Batch[0] avg_epoch_loss=2.007339\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=361, batch=0 train loss <loss>=2.0073392391204834\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] Epoch[361] Batch[5] avg_epoch_loss=2.037901\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=361, batch=5 train loss <loss>=2.0379007856051126\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] Epoch[361] Batch [5]#011Speed: 2139.08 samples/sec#011loss=2.037901\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] Epoch[361] Batch[10] avg_epoch_loss=1.994515\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=361, batch=10 train loss <loss>=1.9424513339996339\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] Epoch[361] Batch [10]#011Speed: 2090.70 samples/sec#011loss=1.942451\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844586.7746596, \"EndTime\": 1747844587.6999543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.053596496582, \"count\": 1, \"min\": 925.053596496582, \"max\": 925.053596496582}}}\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1425.7328796583572 records/second\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #progress_metric: host=algo-1, completed 90.5 % of epochs\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] #quality_metric: host=algo-1, epoch=361, train loss <loss>=1.9945146712389858\n",
      "[05/21/2025 16:23:07 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[362] Batch[0] avg_epoch_loss=1.944668\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=362, batch=0 train loss <loss>=1.944668173789978\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[362] Batch[5] avg_epoch_loss=1.972118\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=362, batch=5 train loss <loss>=1.9721180200576782\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[362] Batch [5]#011Speed: 2134.07 samples/sec#011loss=1.972118\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[362] Batch[10] avg_epoch_loss=1.918621\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=362, batch=10 train loss <loss>=1.8544236660003661\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[362] Batch [10]#011Speed: 2132.58 samples/sec#011loss=1.854424\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747844587.7000115, \"EndTime\": 1747844588.6209083, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.6557273864746, \"count\": 1, \"min\": 920.6557273864746, \"max\": 920.6557273864746}}}\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1412.9962616430387 records/second\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #progress_metric: host=algo-1, completed 90.75 % of epochs\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=362, train loss <loss>=1.9186205863952637\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] Epoch[363] Batch[0] avg_epoch_loss=1.920631\n",
      "[05/21/2025 16:23:08 INFO 140328105305920] #quality_metric: host=algo-1, epoch=363, batch=0 train loss <loss>=1.920630693435669\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] Epoch[363] Batch[5] avg_epoch_loss=1.992560\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=363, batch=5 train loss <loss>=1.992559512456258\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] Epoch[363] Batch [5]#011Speed: 2130.50 samples/sec#011loss=1.992560\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] Epoch[363] Batch[10] avg_epoch_loss=1.951916\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=363, batch=10 train loss <loss>=1.9031442880630494\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] Epoch[363] Batch [10]#011Speed: 2068.88 samples/sec#011loss=1.903144\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747844588.6209645, \"EndTime\": 1747844589.5520096, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.7975769042969, \"count\": 1, \"min\": 930.7975769042969, \"max\": 930.7975769042969}}}\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.4540921205428 records/second\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #progress_metric: host=algo-1, completed 91.0 % of epochs\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=363, train loss <loss>=1.9519162286411633\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] Epoch[364] Batch[0] avg_epoch_loss=2.008521\n",
      "[05/21/2025 16:23:09 INFO 140328105305920] #quality_metric: host=algo-1, epoch=364, batch=0 train loss <loss>=2.008521318435669\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] Epoch[364] Batch[5] avg_epoch_loss=1.907350\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=364, batch=5 train loss <loss>=1.907349705696106\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] Epoch[364] Batch [5]#011Speed: 2143.43 samples/sec#011loss=1.907350\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] Epoch[364] Batch[10] avg_epoch_loss=1.910223\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=364, batch=10 train loss <loss>=1.9136698961257934\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] Epoch[364] Batch [10]#011Speed: 2160.74 samples/sec#011loss=1.913670\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] processed a total of 1305 examples\n",
      "#metrics {\"StartTime\": 1747844589.552066, \"EndTime\": 1747844590.4681785, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.825605392456, \"count\": 1, \"min\": 915.825605392456, \"max\": 915.825605392456}}}\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1424.8098766871824 records/second\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #progress_metric: host=algo-1, completed 91.25 % of epochs\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=364, train loss <loss>=1.910222519527782\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] Epoch[365] Batch[0] avg_epoch_loss=1.839038\n",
      "[05/21/2025 16:23:10 INFO 140328105305920] #quality_metric: host=algo-1, epoch=365, batch=0 train loss <loss>=1.8390377759933472\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] Epoch[365] Batch[5] avg_epoch_loss=1.855465\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=365, batch=5 train loss <loss>=1.8554645776748657\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] Epoch[365] Batch [5]#011Speed: 2131.68 samples/sec#011loss=1.855465\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] processed a total of 1265 examples\n",
      "#metrics {\"StartTime\": 1747844590.468234, \"EndTime\": 1747844591.35762, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 889.1313076019287, \"count\": 1, \"min\": 889.1313076019287, \"max\": 889.1313076019287}}}\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1422.5908887381456 records/second\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #progress_metric: host=algo-1, completed 91.5 % of epochs\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=365, train loss <loss>=1.8646503806114196\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] Epoch[366] Batch[0] avg_epoch_loss=1.907968\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=366, batch=0 train loss <loss>=1.9079681634902954\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] Epoch[366] Batch[5] avg_epoch_loss=1.883509\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] #quality_metric: host=algo-1, epoch=366, batch=5 train loss <loss>=1.8835090001424153\n",
      "[05/21/2025 16:23:11 INFO 140328105305920] Epoch[366] Batch [5]#011Speed: 2154.85 samples/sec#011loss=1.883509\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] Epoch[366] Batch[10] avg_epoch_loss=1.914761\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=366, batch=10 train loss <loss>=1.952262854576111\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] Epoch[366] Batch [10]#011Speed: 2017.10 samples/sec#011loss=1.952263\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] processed a total of 1329 examples\n",
      "#metrics {\"StartTime\": 1747844591.3576825, \"EndTime\": 1747844592.2911985, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.2253932952881, \"count\": 1, \"min\": 933.2253932952881, \"max\": 933.2253932952881}}}\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1423.9633943597642 records/second\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #progress_metric: host=algo-1, completed 91.75 % of epochs\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=366, train loss <loss>=1.9147607521577314\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] Epoch[367] Batch[0] avg_epoch_loss=1.893311\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=367, batch=0 train loss <loss>=1.8933113813400269\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] Epoch[367] Batch[5] avg_epoch_loss=1.958928\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] #quality_metric: host=algo-1, epoch=367, batch=5 train loss <loss>=1.9589282274246216\n",
      "[05/21/2025 16:23:12 INFO 140328105305920] Epoch[367] Batch [5]#011Speed: 2270.07 samples/sec#011loss=1.958928\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] Epoch[367] Batch[10] avg_epoch_loss=1.929331\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=367, batch=10 train loss <loss>=1.8938146591186524\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] Epoch[367] Batch [10]#011Speed: 2010.22 samples/sec#011loss=1.893815\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] processed a total of 1387 examples\n",
      "#metrics {\"StartTime\": 1747844592.2912555, \"EndTime\": 1747844593.2042212, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 912.7039909362793, \"count\": 1, \"min\": 912.7039909362793, \"max\": 912.7039909362793}}}\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1519.4931717485783 records/second\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #progress_metric: host=algo-1, completed 92.0 % of epochs\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=367, train loss <loss>=1.9293311509219082\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] Epoch[368] Batch[0] avg_epoch_loss=1.835091\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=368, batch=0 train loss <loss>=1.8350906372070312\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] Epoch[368] Batch[5] avg_epoch_loss=1.859682\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] #quality_metric: host=algo-1, epoch=368, batch=5 train loss <loss>=1.8596824208895366\n",
      "[05/21/2025 16:23:13 INFO 140328105305920] Epoch[368] Batch [5]#011Speed: 2174.05 samples/sec#011loss=1.859682\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] Epoch[368] Batch[10] avg_epoch_loss=1.859569\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=368, batch=10 train loss <loss>=1.8594321250915526\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] Epoch[368] Batch [10]#011Speed: 2018.89 samples/sec#011loss=1.859432\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] processed a total of 1362 examples\n",
      "#metrics {\"StartTime\": 1747844593.2042866, \"EndTime\": 1747844594.130634, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.978422164917, \"count\": 1, \"min\": 925.978422164917, \"max\": 925.978422164917}}}\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1470.7406602244894 records/second\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 92.25 % of epochs\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=368, train loss <loss>=1.8595686500722712\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] Epoch[369] Batch[0] avg_epoch_loss=1.902289\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=369, batch=0 train loss <loss>=1.902288556098938\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] Epoch[369] Batch[5] avg_epoch_loss=1.890440\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=369, batch=5 train loss <loss>=1.890439788500468\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] Epoch[369] Batch [5]#011Speed: 2213.47 samples/sec#011loss=1.890440\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] processed a total of 1271 examples\n",
      "#metrics {\"StartTime\": 1747844594.130692, \"EndTime\": 1747844594.9748816, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 843.8458442687988, \"count\": 1, \"min\": 843.8458442687988, \"max\": 843.8458442687988}}}\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1506.0175847434284 records/second\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #progress_metric: host=algo-1, completed 92.5 % of epochs\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] #quality_metric: host=algo-1, epoch=369, train loss <loss>=1.8732738256454469\n",
      "[05/21/2025 16:23:14 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] Epoch[370] Batch[0] avg_epoch_loss=1.903133\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=370, batch=0 train loss <loss>=1.9031330347061157\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] Epoch[370] Batch[5] avg_epoch_loss=1.897915\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=370, batch=5 train loss <loss>=1.8979148467381795\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] Epoch[370] Batch [5]#011Speed: 2173.26 samples/sec#011loss=1.897915\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] Epoch[370] Batch[10] avg_epoch_loss=1.877309\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=370, batch=10 train loss <loss>=1.8525811433792114\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] Epoch[370] Batch [10]#011Speed: 2091.30 samples/sec#011loss=1.852581\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] processed a total of 1319 examples\n",
      "#metrics {\"StartTime\": 1747844594.9749484, \"EndTime\": 1747844595.8953245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.9841022491455, \"count\": 1, \"min\": 919.9841022491455, \"max\": 919.9841022491455}}}\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1433.5848219954196 records/second\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #progress_metric: host=algo-1, completed 92.75 % of epochs\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] #quality_metric: host=algo-1, epoch=370, train loss <loss>=1.8773086179386487\n",
      "[05/21/2025 16:23:15 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] Epoch[371] Batch[0] avg_epoch_loss=1.916072\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=371, batch=0 train loss <loss>=1.9160717725753784\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] Epoch[371] Batch[5] avg_epoch_loss=1.950581\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=371, batch=5 train loss <loss>=1.9505807757377625\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] Epoch[371] Batch [5]#011Speed: 2174.32 samples/sec#011loss=1.950581\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] Epoch[371] Batch[10] avg_epoch_loss=1.995080\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=371, batch=10 train loss <loss>=2.048479962348938\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] Epoch[371] Batch [10]#011Speed: 2061.74 samples/sec#011loss=2.048480\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747844595.89538, \"EndTime\": 1747844596.8176947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.9658374786377, \"count\": 1, \"min\": 921.9658374786377, \"max\": 921.9658374786377}}}\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1469.549644033932 records/second\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #progress_metric: host=algo-1, completed 93.0 % of epochs\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] #quality_metric: host=algo-1, epoch=371, train loss <loss>=1.9950804060155696\n",
      "[05/21/2025 16:23:16 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] Epoch[372] Batch[0] avg_epoch_loss=1.963281\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=372, batch=0 train loss <loss>=1.9632809162139893\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] Epoch[372] Batch[5] avg_epoch_loss=1.943607\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=372, batch=5 train loss <loss>=1.9436069528261821\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] Epoch[372] Batch [5]#011Speed: 2146.20 samples/sec#011loss=1.943607\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] Epoch[372] Batch[10] avg_epoch_loss=1.940135\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=372, batch=10 train loss <loss>=1.9359686136245728\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] Epoch[372] Batch [10]#011Speed: 2126.77 samples/sec#011loss=1.935969\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747844596.8177514, \"EndTime\": 1747844597.7363105, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.3087348937988, \"count\": 1, \"min\": 918.3087348937988, \"max\": 918.3087348937988}}}\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1457.9820385055314 records/second\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #progress_metric: host=algo-1, completed 93.25 % of epochs\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] #quality_metric: host=algo-1, epoch=372, train loss <loss>=1.9401349804618142\n",
      "[05/21/2025 16:23:17 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] Epoch[373] Batch[0] avg_epoch_loss=1.951711\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=373, batch=0 train loss <loss>=1.9517111778259277\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] Epoch[373] Batch[5] avg_epoch_loss=1.911455\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=373, batch=5 train loss <loss>=1.9114554127057393\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] Epoch[373] Batch [5]#011Speed: 2110.19 samples/sec#011loss=1.911455\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] Epoch[373] Batch[10] avg_epoch_loss=1.895978\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=373, batch=10 train loss <loss>=1.8774057626724243\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] Epoch[373] Batch [10]#011Speed: 1939.56 samples/sec#011loss=1.877406\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] processed a total of 1371 examples\n",
      "#metrics {\"StartTime\": 1747844597.7363665, \"EndTime\": 1747844598.6854649, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.8351345062256, \"count\": 1, \"min\": 948.8351345062256, \"max\": 948.8351345062256}}}\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1444.7760658833413 records/second\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #progress_metric: host=algo-1, completed 93.5 % of epochs\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] #quality_metric: host=algo-1, epoch=373, train loss <loss>=1.8959782990542324\n",
      "[05/21/2025 16:23:18 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] Epoch[374] Batch[0] avg_epoch_loss=2.003289\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=374, batch=0 train loss <loss>=2.003288745880127\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] Epoch[374] Batch[5] avg_epoch_loss=1.889786\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=374, batch=5 train loss <loss>=1.8897858063379924\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] Epoch[374] Batch [5]#011Speed: 2145.50 samples/sec#011loss=1.889786\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] processed a total of 1223 examples\n",
      "#metrics {\"StartTime\": 1747844598.6855204, \"EndTime\": 1747844599.5379586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 852.1826267242432, \"count\": 1, \"min\": 852.1826267242432, \"max\": 852.1826267242432}}}\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1434.9802073288804 records/second\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #progress_metric: host=algo-1, completed 93.75 % of epochs\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=374, train loss <loss>=1.9514550805091857\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] Epoch[375] Batch[0] avg_epoch_loss=1.924773\n",
      "[05/21/2025 16:23:19 INFO 140328105305920] #quality_metric: host=algo-1, epoch=375, batch=0 train loss <loss>=1.9247729778289795\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] Epoch[375] Batch[5] avg_epoch_loss=1.881832\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=375, batch=5 train loss <loss>=1.881832202275594\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] Epoch[375] Batch [5]#011Speed: 2215.47 samples/sec#011loss=1.881832\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] Epoch[375] Batch[10] avg_epoch_loss=2.010984\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=375, batch=10 train loss <loss>=2.165965962409973\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] Epoch[375] Batch [10]#011Speed: 2038.47 samples/sec#011loss=2.165966\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] processed a total of 1324 examples\n",
      "#metrics {\"StartTime\": 1747844599.538022, \"EndTime\": 1747844600.465318, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.0005226135254, \"count\": 1, \"min\": 927.0005226135254, \"max\": 927.0005226135254}}}\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1428.1360557093724 records/second\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #progress_metric: host=algo-1, completed 94.0 % of epochs\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=375, train loss <loss>=2.0109839114275845\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] Epoch[376] Batch[0] avg_epoch_loss=1.854953\n",
      "[05/21/2025 16:23:20 INFO 140328105305920] #quality_metric: host=algo-1, epoch=376, batch=0 train loss <loss>=1.854953408241272\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] Epoch[376] Batch[5] avg_epoch_loss=1.898125\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=376, batch=5 train loss <loss>=1.8981253504753113\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] Epoch[376] Batch [5]#011Speed: 2096.11 samples/sec#011loss=1.898125\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] Epoch[376] Batch[10] avg_epoch_loss=1.945986\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=376, batch=10 train loss <loss>=2.003418970108032\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] Epoch[376] Batch [10]#011Speed: 2015.18 samples/sec#011loss=2.003419\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747844600.4653733, \"EndTime\": 1747844601.4256256, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 959.9812030792236, \"count\": 1, \"min\": 959.9812030792236, \"max\": 959.9812030792236}}}\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1385.3237184246952 records/second\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #progress_metric: host=algo-1, completed 94.25 % of epochs\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=376, train loss <loss>=1.9459860866720027\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] Epoch[377] Batch[0] avg_epoch_loss=1.836383\n",
      "[05/21/2025 16:23:21 INFO 140328105305920] #quality_metric: host=algo-1, epoch=377, batch=0 train loss <loss>=1.8363831043243408\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[377] Batch[5] avg_epoch_loss=1.877891\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=377, batch=5 train loss <loss>=1.877890944480896\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[377] Batch [5]#011Speed: 2149.22 samples/sec#011loss=1.877891\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[377] Batch[10] avg_epoch_loss=1.887889\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=377, batch=10 train loss <loss>=1.8998858451843261\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[377] Batch [10]#011Speed: 2066.69 samples/sec#011loss=1.899886\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747844601.425681, \"EndTime\": 1747844602.3498924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.9637851715088, \"count\": 1, \"min\": 923.9637851715088, \"max\": 923.9637851715088}}}\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1433.9230765658212 records/second\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #progress_metric: host=algo-1, completed 94.5 % of epochs\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=377, train loss <loss>=1.8878886266188188\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[378] Batch[0] avg_epoch_loss=1.884837\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=378, batch=0 train loss <loss>=1.8848369121551514\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[378] Batch[5] avg_epoch_loss=1.884732\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] #quality_metric: host=algo-1, epoch=378, batch=5 train loss <loss>=1.884732445081075\n",
      "[05/21/2025 16:23:22 INFO 140328105305920] Epoch[378] Batch [5]#011Speed: 2171.27 samples/sec#011loss=1.884732\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] Epoch[378] Batch[10] avg_epoch_loss=1.964028\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=378, batch=10 train loss <loss>=2.059181976318359\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] Epoch[378] Batch [10]#011Speed: 2059.20 samples/sec#011loss=2.059182\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] processed a total of 1328 examples\n",
      "#metrics {\"StartTime\": 1747844602.3499405, \"EndTime\": 1747844603.2742178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.0500926971436, \"count\": 1, \"min\": 924.0500926971436, \"max\": 924.0500926971436}}}\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1437.022866834499 records/second\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #progress_metric: host=algo-1, completed 94.75 % of epochs\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=378, train loss <loss>=1.9640276865525679\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] Epoch[379] Batch[0] avg_epoch_loss=1.893410\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=379, batch=0 train loss <loss>=1.8934097290039062\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] Epoch[379] Batch[5] avg_epoch_loss=1.872226\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] #quality_metric: host=algo-1, epoch=379, batch=5 train loss <loss>=1.8722260197003682\n",
      "[05/21/2025 16:23:23 INFO 140328105305920] Epoch[379] Batch [5]#011Speed: 2187.85 samples/sec#011loss=1.872226\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] Epoch[379] Batch[10] avg_epoch_loss=1.872603\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=379, batch=10 train loss <loss>=1.8730555295944213\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] Epoch[379] Batch [10]#011Speed: 2037.06 samples/sec#011loss=1.873056\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747844603.274273, \"EndTime\": 1747844604.1984198, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.839807510376, \"count\": 1, \"min\": 923.839807510376, \"max\": 923.839807510376}}}\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1471.9533454872467 records/second\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #progress_metric: host=algo-1, completed 95.0 % of epochs\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=379, train loss <loss>=1.8726030696522107\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] Epoch[380] Batch[0] avg_epoch_loss=1.785311\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=380, batch=0 train loss <loss>=1.7853105068206787\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] Epoch[380] Batch[5] avg_epoch_loss=1.864872\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] #quality_metric: host=algo-1, epoch=380, batch=5 train loss <loss>=1.8648719390233357\n",
      "[05/21/2025 16:23:24 INFO 140328105305920] Epoch[380] Batch [5]#011Speed: 2182.84 samples/sec#011loss=1.864872\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] Epoch[380] Batch[10] avg_epoch_loss=1.911317\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=380, batch=10 train loss <loss>=1.96705162525177\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] Epoch[380] Batch [10]#011Speed: 2038.79 samples/sec#011loss=1.967052\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] processed a total of 1357 examples\n",
      "#metrics {\"StartTime\": 1747844604.1984937, \"EndTime\": 1747844605.12228, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.4843254089355, \"count\": 1, \"min\": 923.4843254089355, \"max\": 923.4843254089355}}}\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1469.2603059398002 records/second\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #progress_metric: host=algo-1, completed 95.25 % of epochs\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=380, train loss <loss>=1.9113172509453513\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] Epoch[381] Batch[0] avg_epoch_loss=1.769135\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=381, batch=0 train loss <loss>=1.7691346406936646\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] Epoch[381] Batch[5] avg_epoch_loss=1.848879\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] #quality_metric: host=algo-1, epoch=381, batch=5 train loss <loss>=1.8488789598147075\n",
      "[05/21/2025 16:23:25 INFO 140328105305920] Epoch[381] Batch [5]#011Speed: 2149.88 samples/sec#011loss=1.848879\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] Epoch[381] Batch[10] avg_epoch_loss=1.861372\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=381, batch=10 train loss <loss>=1.8763646841049195\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] Epoch[381] Batch [10]#011Speed: 1970.28 samples/sec#011loss=1.876365\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] processed a total of 1283 examples\n",
      "#metrics {\"StartTime\": 1747844605.1223617, \"EndTime\": 1747844606.0735276, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.9167671203613, \"count\": 1, \"min\": 950.9167671203613, \"max\": 950.9167671203613}}}\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1349.1055627214803 records/second\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #progress_metric: host=algo-1, completed 95.5 % of epochs\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=381, train loss <loss>=1.861372470855713\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] Epoch[382] Batch[0] avg_epoch_loss=1.868259\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=382, batch=0 train loss <loss>=1.8682594299316406\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] Epoch[382] Batch[5] avg_epoch_loss=1.885089\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] #quality_metric: host=algo-1, epoch=382, batch=5 train loss <loss>=1.8850894570350647\n",
      "[05/21/2025 16:23:26 INFO 140328105305920] Epoch[382] Batch [5]#011Speed: 2131.39 samples/sec#011loss=1.885089\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[382] Batch[10] avg_epoch_loss=2.109103\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=382, batch=10 train loss <loss>=2.3779193639755247\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[382] Batch [10]#011Speed: 2061.57 samples/sec#011loss=2.377919\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747844606.073584, \"EndTime\": 1747844607.0093565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.5216026306152, \"count\": 1, \"min\": 935.5216026306152, \"max\": 935.5216026306152}}}\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1435.43401863405 records/second\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 95.75 % of epochs\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=382, train loss <loss>=2.10910305109891\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[383] Batch[0] avg_epoch_loss=1.888615\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=383, batch=0 train loss <loss>=1.8886146545410156\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[383] Batch[5] avg_epoch_loss=1.926276\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=383, batch=5 train loss <loss>=1.9262755115826924\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[383] Batch [5]#011Speed: 2195.54 samples/sec#011loss=1.926276\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[383] Batch[10] avg_epoch_loss=1.939533\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=383, batch=10 train loss <loss>=1.9554420232772827\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] Epoch[383] Batch [10]#011Speed: 2151.50 samples/sec#011loss=1.955442\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] processed a total of 1339 examples\n",
      "#metrics {\"StartTime\": 1747844607.0094128, \"EndTime\": 1747844607.9166248, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 906.933069229126, \"count\": 1, \"min\": 906.933069229126, \"max\": 906.933069229126}}}\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1476.265881592194 records/second\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #progress_metric: host=algo-1, completed 96.0 % of epochs\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] #quality_metric: host=algo-1, epoch=383, train loss <loss>=1.9395330168984153\n",
      "[05/21/2025 16:23:27 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] Epoch[384] Batch[0] avg_epoch_loss=1.878735\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=384, batch=0 train loss <loss>=1.8787345886230469\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] Epoch[384] Batch[5] avg_epoch_loss=1.938076\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=384, batch=5 train loss <loss>=1.9380757212638855\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] Epoch[384] Batch [5]#011Speed: 2166.20 samples/sec#011loss=1.938076\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] processed a total of 1244 examples\n",
      "#metrics {\"StartTime\": 1747844607.9166822, \"EndTime\": 1747844608.7731326, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 856.2033176422119, \"count\": 1, \"min\": 856.2033176422119, \"max\": 856.2033176422119}}}\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1452.7742257386221 records/second\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] #progress_metric: host=algo-1, completed 96.25 % of epochs\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] #quality_metric: host=algo-1, epoch=384, train loss <loss>=1.9202686548233032\n",
      "[05/21/2025 16:23:28 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] Epoch[385] Batch[0] avg_epoch_loss=1.877258\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=385, batch=0 train loss <loss>=1.87725830078125\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] Epoch[385] Batch[5] avg_epoch_loss=1.914976\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=385, batch=5 train loss <loss>=1.9149755835533142\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] Epoch[385] Batch [5]#011Speed: 2093.34 samples/sec#011loss=1.914976\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] Epoch[385] Batch[10] avg_epoch_loss=1.978058\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=385, batch=10 train loss <loss>=2.053757667541504\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] Epoch[385] Batch [10]#011Speed: 2148.41 samples/sec#011loss=2.053758\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] processed a total of 1349 examples\n",
      "#metrics {\"StartTime\": 1747844608.7731926, \"EndTime\": 1747844609.6942565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 920.720100402832, \"count\": 1, \"min\": 920.720100402832, \"max\": 920.720100402832}}}\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1465.0243857600894 records/second\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #progress_metric: host=algo-1, completed 96.5 % of epochs\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] #quality_metric: host=algo-1, epoch=385, train loss <loss>=1.9780583490024914\n",
      "[05/21/2025 16:23:29 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] Epoch[386] Batch[0] avg_epoch_loss=1.879024\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=386, batch=0 train loss <loss>=1.8790241479873657\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] Epoch[386] Batch[5] avg_epoch_loss=1.923937\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=386, batch=5 train loss <loss>=1.9239368438720703\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] Epoch[386] Batch [5]#011Speed: 2158.50 samples/sec#011loss=1.923937\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747844609.694312, \"EndTime\": 1747844610.5415418, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 846.9538688659668, \"count\": 1, \"min\": 846.9538688659668, \"max\": 846.9538688659668}}}\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1509.9578457074758 records/second\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #progress_metric: host=algo-1, completed 96.75 % of epochs\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=386, train loss <loss>=1.9054224967956543\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] Epoch[387] Batch[0] avg_epoch_loss=1.898412\n",
      "[05/21/2025 16:23:30 INFO 140328105305920] #quality_metric: host=algo-1, epoch=387, batch=0 train loss <loss>=1.8984123468399048\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] Epoch[387] Batch[5] avg_epoch_loss=1.870563\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=387, batch=5 train loss <loss>=1.8705626328786213\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] Epoch[387] Batch [5]#011Speed: 2171.51 samples/sec#011loss=1.870563\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] Epoch[387] Batch[10] avg_epoch_loss=1.885858\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=387, batch=10 train loss <loss>=1.9042129039764404\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] Epoch[387] Batch [10]#011Speed: 2050.43 samples/sec#011loss=1.904213\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747844610.5416026, \"EndTime\": 1747844611.475029, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.1073760986328, \"count\": 1, \"min\": 933.1073760986328, \"max\": 933.1073760986328}}}\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1400.5724274555312 records/second\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #progress_metric: host=algo-1, completed 97.0 % of epochs\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=387, train loss <loss>=1.8858582106503574\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] Epoch[388] Batch[0] avg_epoch_loss=2.079593\n",
      "[05/21/2025 16:23:31 INFO 140328105305920] #quality_metric: host=algo-1, epoch=388, batch=0 train loss <loss>=2.079592704772949\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] Epoch[388] Batch[5] avg_epoch_loss=1.954362\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=388, batch=5 train loss <loss>=1.9543617566426594\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] Epoch[388] Batch [5]#011Speed: 2126.54 samples/sec#011loss=1.954362\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] Epoch[388] Batch[10] avg_epoch_loss=1.934951\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=388, batch=10 train loss <loss>=1.9116574287414552\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] Epoch[388] Batch [10]#011Speed: 2173.43 samples/sec#011loss=1.911657\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747844611.4750843, \"EndTime\": 1747844612.3908424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 915.5206680297852, \"count\": 1, \"min\": 915.5206680297852, \"max\": 915.5206680297852}}}\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1418.7372802818102 records/second\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #progress_metric: host=algo-1, completed 97.25 % of epochs\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=388, train loss <loss>=1.9349506985057483\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] Epoch[389] Batch[0] avg_epoch_loss=1.900690\n",
      "[05/21/2025 16:23:32 INFO 140328105305920] #quality_metric: host=algo-1, epoch=389, batch=0 train loss <loss>=1.9006900787353516\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Epoch[389] Batch[5] avg_epoch_loss=1.916535\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=389, batch=5 train loss <loss>=1.9165347814559937\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Epoch[389] Batch [5]#011Speed: 2146.97 samples/sec#011loss=1.916535\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Epoch[389] Batch[10] avg_epoch_loss=1.855850\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=389, batch=10 train loss <loss>=1.7830280542373658\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Epoch[389] Batch [10]#011Speed: 2117.18 samples/sec#011loss=1.783028\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747844612.3908968, \"EndTime\": 1747844613.3109858, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.8422431945801, \"count\": 1, \"min\": 919.8422431945801, \"max\": 919.8422431945801}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #throughput_metric: host=algo-1, train throughput=1422.9384393494288 records/second\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 97.5 % of epochs\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, epoch=389, train loss <loss>=1.8558499054475264\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] loss did not improve\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Loading parameters from best epoch (349)\n",
      "#metrics {\"StartTime\": 1747844613.3110428, \"EndTime\": 1747844613.3164725, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 5.159139633178711, \"count\": 1, \"min\": 5.159139633178711, \"max\": 5.159139633178711}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] stopping training now\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Final loss: 1.855208765376698 (occurred at epoch 349)\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, train final_loss <loss>=1.855208765376698\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Worker algo-1 finished training.\n",
      "[05/21/2025 16:23:33 WARNING 140328105305920] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747844613.3165226, \"EndTime\": 1747844613.369023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 52.09207534790039, \"count\": 1, \"min\": 52.09207534790039, \"max\": 52.09207534790039}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747844613.3690696, \"EndTime\": 1747844613.391722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 74.81861114501953, \"count\": 1, \"min\": 74.81861114501953, \"max\": 74.81861114501953}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747844613.391761, \"EndTime\": 1747844613.3955586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 3.7746429443359375, \"count\": 1, \"min\": 3.7746429443359375, \"max\": 3.7746429443359375}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Successfully serialized the model for prediction.\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] Evaluating model accuracy on testset using 100 samples\n",
      "#metrics {\"StartTime\": 1747844613.3955932, \"EndTime\": 1747844613.397247, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}}}\n",
      "#metrics {\"StartTime\": 1747844613.3972874, \"EndTime\": 1747844613.5749, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 177.66714096069336, \"count\": 1, \"min\": 177.66714096069336, \"max\": 177.66714096069336}}}\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, RMSE): 30.268762624880054\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, mean_absolute_QuantileLoss): 1398.5490469826593\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, mean_wQuantileLoss): 0.5012720598504156\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.1]): 0.21033582273777243\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.2]): 0.3290987657389761\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.3]): 0.4287174626832367\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.4]): 0.5116063667625511\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.5]): 0.5733221108768148\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.6]): 0.6165097236633301\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.7]): 0.6345287654220417\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.8]): 0.6268949049946229\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #test_score (algo-1, wQuantileLoss[0.9]): 0.580434615774394\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, test RMSE <loss>=30.268762624880054\n",
      "[05/21/2025 16:23:33 INFO 140328105305920] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.5012720598504156\n",
      "#metrics {\"StartTime\": 1747844613.5749729, \"EndTime\": 1747844613.5850916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 3.976583480834961, \"count\": 1, \"min\": 3.976583480834961, \"max\": 3.976583480834961}, \"totaltime\": {\"sum\": 360693.0537223816, \"count\": 1, \"min\": 360693.0537223816, \"max\": 360693.0537223816}}}\n",
      "\n",
      "2025-05-21 16:23:49 Uploading - Uploading generated training model\n",
      "2025-05-21 16:23:49 Completed - Training job completed\n",
      "Training seconds: 501\n",
      "Billable seconds: 501\n",
      "CPU times: total: 15.5 s\n",
      "Wall time: 9min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "30028f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-21 16:23:49 Starting - Preparing the instances for training\n",
      "2025-05-21 16:23:49 Downloading - Downloading the training image\n",
      "2025-05-21 16:23:49 Training - Training image download completed. Training in progress.\n",
      "2025-05-21 16:23:49 Uploading - Uploading generated training model\n",
      "2025-05-21 16:23:49 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-21-16-14-41-449',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "0a66a95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 11:27:16] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-16-27-15-927 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 11:27:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-16-27-15-927 \u001b]8;id=890145;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=635645;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-16-27-15-927                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=975649;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=110072;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-16-27-15-927                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 11:27:17] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-16-27-15-927                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 11:27:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=559989;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=975198;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-16-27-15-927                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "9b524d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>Tipo_Producto</th>\n",
       "      <th>segmento_producto</th>\n",
       "      <th>supergrupo_producto</th>\n",
       "      <th>grupo_producto</th>\n",
       "      <th>subgrupo_producto</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-01</th>\n",
       "      <td>20001016001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               material  Tipo_Producto  segmento_producto  \\\n",
       "2021-08-01  20001016001              0                  0   \n",
       "\n",
       "            supergrupo_producto  grupo_producto  subgrupo_producto  cantidad  \\\n",
       "2021-08-01                    0               0                  0      25.0   \n",
       "\n",
       "            month  quarter  \n",
       "2021-08-01      8        3  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[6].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "c6ad49f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>-0.145210</td>\n",
       "      <td>5.119237</td>\n",
       "      <td>9.403378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>-7.877854</td>\n",
       "      <td>-1.599877</td>\n",
       "      <td>3.847554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>-1.344202</td>\n",
       "      <td>3.692548</td>\n",
       "      <td>9.995129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>-4.450853</td>\n",
       "      <td>0.291701</td>\n",
       "      <td>4.337483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>-0.706475</td>\n",
       "      <td>6.791806</td>\n",
       "      <td>12.815763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>-3.520440</td>\n",
       "      <td>3.702541</td>\n",
       "      <td>13.981384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0.1       0.5        0.9\n",
       "2024-11-01 -0.145210  5.119237   9.403378\n",
       "2024-12-01 -7.877854 -1.599877   3.847554\n",
       "2025-01-01 -1.344202  3.692548   9.995129\n",
       "2025-02-01 -4.450853  0.291701   4.337483\n",
       "2025-03-01 -0.706475  6.791806  12.815763\n",
       "2025-04-01 -3.520440  3.702541  13.981384"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=6\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "4d2af07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    14.0\n",
       "2024-12-01    73.0\n",
       "2025-01-01    26.0\n",
       "2025-02-01    12.0\n",
       "2025-03-01    23.0\n",
       "2025-04-01    29.0\n",
       "Freq: MS, Name: cantidad, dtype: float64"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[6].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d0707",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3ER ENTRENAMIENTO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "06c4235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_cantidad_a_entero(lista_dataframes):\n",
    "    \"\"\"\n",
    "    Convierte los valores de la columna 'cantidad' de cada dataframe a enteros,\n",
    "    redondeando al entero más cercano.\n",
    "    \n",
    "    Args:\n",
    "        lista_dataframes: Lista de dataframes con una columna 'cantidad'\n",
    "    \n",
    "    Returns:\n",
    "        Una nueva lista de dataframes con los valores de 'cantidad' convertidos a enteros\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Lista que almacenará los dataframes modificados\n",
    "    lista_modificada = []\n",
    "    \n",
    "    for i, df in enumerate(lista_dataframes):\n",
    "        # Crear una copia para no modificar el original\n",
    "        df_modificado = df.copy()\n",
    "        \n",
    "        # Verificar que exista la columna 'cantidad'\n",
    "        if 'cantidad' not in df_modificado.columns:\n",
    "            print(f\"Advertencia: Dataframe {i} no tiene la columna 'cantidad'. Se añadirá sin cambios.\")\n",
    "            lista_modificada.append(df_modificado)\n",
    "            continue\n",
    "        \n",
    "        # Convertir a entero redondeando al entero más cercano\n",
    "        try:\n",
    "            # Primero verificar si hay valores nulos y manejarlos\n",
    "            if df_modificado['cantidad'].isna().any():\n",
    "                # Mantener los valores nulos como son\n",
    "                mask = df_modificado['cantidad'].notna()\n",
    "                df_modificado.loc[mask, 'cantidad'] = np.round(df_modificado.loc[mask, 'cantidad']).astype(int)\n",
    "            else:\n",
    "                # Si no hay valores nulos, convertir directamente\n",
    "                df_modificado['cantidad'] = np.round(df_modificado['cantidad']).astype(int)\n",
    "                \n",
    "            lista_modificada.append(df_modificado)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al convertir valores en Dataframe {i}: {e}. Se añadirá sin cambios.\")\n",
    "            lista_modificada.append(df_modificado)\n",
    "    \n",
    "    return lista_modificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "79c82cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = convertir_cantidad_a_entero(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ee08550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores_target = extraer_vectores_cantidad(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "742a13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_test(start, vectores_target, vectores_cat, vectores_dynamic):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios con la estructura requerida para entrenamiento,\n",
    "    donde start son las fechas de inicio de cada serie (un valor por dataframe).\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie (como enteros)\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string, mantiene enteros como enteros\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else int(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic\n",
    "        if len(target_data) != len(month_vector) or len(target_data) != len(quarter_vector):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes - target: {len(target_data)}, \"\n",
    "                  f\"month: {len(month_vector)}, quarter: {len(quarter_vector)}\")\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector, quarter_vector]  # Usar valores originales sin normalizar\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "b2a5428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = crear_diccionarios_test(start,vectores_target,vectores_cat,vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "923ba370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_diccionarios_entrenamiento(start, vectores_target, vectores_cat, vectores_dynamic, puntos_a_excluir=6):\n",
    "    \"\"\"\n",
    "    Crea una lista de diccionarios excluyendo los últimos 'puntos_a_excluir' valores de \n",
    "    target y dynamic_feat para cada serie.\n",
    "    \n",
    "    Args:\n",
    "        start: Lista de strings con las fechas de inicio (un valor por dataframe)\n",
    "        vectores_target: Lista de vectores con los valores de 'cantidad' para cada serie\n",
    "        vectores_cat: Lista de vectores con las características categóricas\n",
    "        vectores_dynamic: Lista de tuplas (month_vector, quarter_vector) con características dinámicas\n",
    "        puntos_a_excluir: Número de puntos a excluir del final de las series (default=6)\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura {start, target, cat, dynamic_feat}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def convert_nans_to_string(values_list):\n",
    "        \"\"\"Convierte valores NaN en la lista a 'NaN' como string, mantiene enteros como enteros\"\"\"\n",
    "        return ['NaN' if (isinstance(x, float) and np.isnan(x)) else int(x) for x in values_list]\n",
    "    \n",
    "    diccionarios = []\n",
    "    \n",
    "    # Verificar que tengamos el mismo número de series en todas las listas\n",
    "    num_series = len(start)\n",
    "    if not (num_series == len(vectores_target) == len(vectores_cat) == len(vectores_dynamic)):\n",
    "        print(f\"Error: Las listas tienen diferentes longitudes - start: {len(start)}, target: {len(vectores_target)}, \" \n",
    "              f\"cat: {len(vectores_cat)}, dynamic: {len(vectores_dynamic)}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        # Verificar que haya datos para esta serie\n",
    "        if not vectores_target[i]:\n",
    "            print(f\"Advertencia: Serie {i} no tiene valores target. Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtener los datos para esta serie\n",
    "        fecha_inicio = start[i]\n",
    "        target_data = vectores_target[i]\n",
    "        cat_data = vectores_cat[i]\n",
    "        month_vector, quarter_vector = vectores_dynamic[i]\n",
    "        \n",
    "        # Verificar que hay suficientes puntos para excluir\n",
    "        if len(target_data) <= puntos_a_excluir:\n",
    "            print(f\"Advertencia: Serie {i} tiene menos puntos ({len(target_data)}) que los requeridos a excluir ({puntos_a_excluir}). Se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        # Excluir los últimos 'puntos_a_excluir' valores\n",
    "        target_data_recortado = target_data[:-puntos_a_excluir]\n",
    "        month_vector_recortado = month_vector[:-puntos_a_excluir]\n",
    "        quarter_vector_recortado = quarter_vector[:-puntos_a_excluir]\n",
    "        \n",
    "        # Verificar longitudes de vectors target y dynamic después del recorte\n",
    "        if len(target_data_recortado) != len(month_vector_recortado) or len(target_data_recortado) != len(quarter_vector_recortado):\n",
    "            print(f\"Advertencia: Serie {i} tiene longitudes inconsistentes después del recorte - target: {len(target_data_recortado)}, \"\n",
    "                  f\"month: {len(month_vector_recortado)}, quarter: {len(quarter_vector_recortado)}\")\n",
    "            # Ajustar a la longitud mínima\n",
    "            min_len = min(len(target_data_recortado), len(month_vector_recortado), len(quarter_vector_recortado))\n",
    "            target_data_recortado = target_data_recortado[:min_len]\n",
    "            month_vector_recortado = month_vector_recortado[:min_len]\n",
    "            quarter_vector_recortado = quarter_vector_recortado[:min_len]\n",
    "        \n",
    "        # Crear el diccionario\n",
    "        diccionario = {\n",
    "            \"start\": fecha_inicio,\n",
    "            \"target\": convert_nans_to_string(target_data_recortado),\n",
    "            \"cat\": cat_data,\n",
    "            \"dynamic_feat\": [month_vector_recortado, quarter_vector_recortado]\n",
    "        }\n",
    "        \n",
    "        diccionarios.append(diccionario)\n",
    "    \n",
    "    return diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a1a7be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = crear_diccionarios_entrenamiento(start,vectores_target, vectores_cat, vectores_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb2cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"data_json/mensual_modificado_int_27/train.json\", train)\n",
    "write_dicts_to_file(\"data_json/mensual_modificado_int_27/test.json\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "fbab8abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket S3 'forecasting-mensual-15-v4' creado exitosamente en la región por defecto\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"forecasting-mensual-15-v4\"\n",
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "af4e7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = bucket_name  # replace with an existing bucket if needed\n",
    "s3_bucket_prefix = (\n",
    "        \"lilipink\"  \n",
    "    )\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "if default_bucket_prefix:\n",
    "    s3_prefix = f\"{default_bucket_prefix}/{s3_bucket_prefix}\"\n",
    "else:\n",
    "    s3_prefix = s3_bucket_prefix\n",
    "\n",
    "role = \"arn:aws:iam::844598627082:role/service-role/AmazonSageMaker-ExecutionRole-20250513T105052\"  # IAM role to use by SageMaker\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file to s3://forecasting-mensual-15-v4/lilipink/data/train/train.json\n",
      "Uploading file to s3://forecasting-mensual-15-v4/lilipink/data/test/test.json\n"
     ]
    }
   ],
   "source": [
    "local_file = 'data_json/mensual_modificado_int_27/'\n",
    "copy_to_s3(local_file + 'train.json', s3_data_path + \"/train/train.json\",override=True)\n",
    "copy_to_s3(local_file + 'test.json', s3_data_path + \"/test/test.json\",override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "0e84683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"learning_rate\": \"1E-1\",\n",
    "    \"likelihood\":\"negative-binomial\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "42976f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "42949922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 17:50:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 17:50:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=946621;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=358654;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-50-26-760                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=190197;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=393617;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-50-26-760                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 22:50:28 Starting - Starting the training job...\n",
      "2025-05-21 22:50:44 Starting - Preparing the instances for training...\n",
      "2025-05-21 22:51:22 Downloading - Downloading the training image.........\n",
      "2025-05-21 22:53:08 Training - Training image download completed. Training in progress...Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/21/2025 22:53:25 INFO 140039678244672] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/21/2025 22:53:25 INFO 140039678244672] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '18', 'early_stopping_patience': '40', 'epochs': '400', 'learning_rate': '1E-1', 'likelihood': 'negative-binomial', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/21/2025 22:53:25 INFO 140039678244672] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '1E-1', 'likelihood': 'negative-binomial', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '18', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/21/2025 22:53:25 INFO 140039678244672] Detected entry point for worker worker\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Using early stopping with patience 40\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] random_seed is None\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] [cardinality=auto] Inferred value of cardinality=[2, 4, 5, 6, 6] from dataset.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Training set statistics:\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Integer time series\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] number of time series: 15\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] number of observations: 582\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] mean target length: 38.8\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] min/mean/max target: 1.0/30.99656357388316/350.0\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] mean abs(target): 30.99656357388316\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] contains missing values: no\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Small number of time series. Doing 86 passes over dataset with prob 0.9922480620155039 per epoch.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Test set statistics:\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Integer time series\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] number of time series: 15\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] number of observations: 672\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] mean target length: 44.8\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] min/mean/max target: 1.0/30.99702380952381/388.0\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] mean abs(target): 30.99702380952381\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] contains missing values: no\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] nvidia-smi: took 0.032 seconds to run.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] nvidia-smi identified 0 GPUs.\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Number of GPUs being used: 0\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Create Store: local\n",
      "#metrics {\"StartTime\": 1747868006.096881, \"EndTime\": 1747868006.1429086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 45.05038261413574, \"count\": 1, \"min\": 45.05038261413574, \"max\": 45.05038261413574}}}\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Number of GPUs being used: 0\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] #memory_usage::<model> = 21 mb\n",
      "#metrics {\"StartTime\": 1747868006.1429837, \"EndTime\": 1747868006.2202697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 123.26431274414062, \"count\": 1, \"min\": 123.26431274414062, \"max\": 123.26431274414062}}}\n",
      "[22:53:26] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 20480 bytes with malloc directly\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Epoch[0] Batch[0] avg_epoch_loss=3.779001\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.779000997543335\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Epoch[0] Batch[5] avg_epoch_loss=5.264504\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=5.264503558476766\n",
      "[05/21/2025 22:53:26 INFO 140039678244672] Epoch[0] Batch [5]#011Speed: 1909.94 samples/sec#011loss=5.264504\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Epoch[0] Batch[10] avg_epoch_loss=4.471682\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.52029709815979\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Epoch[0] Batch [10]#011Speed: 2139.90 samples/sec#011loss=3.520297\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] processed a total of 1293 examples\n",
      "#metrics {\"StartTime\": 1747868006.2203236, \"EndTime\": 1747868007.2365031, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 1016.1144733428955, \"count\": 1, \"min\": 1016.1144733428955, \"max\": 1016.1144733428955}}}\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1272.3412720421284 records/second\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=0, train loss <loss>=4.471682440150868\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_74c6775b-aedf-425c-a4da-f4df50251b26-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868007.2365966, \"EndTime\": 1747868007.2476692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.730266571044922, \"count\": 1, \"min\": 10.730266571044922, \"max\": 10.730266571044922}}}\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Epoch[1] Batch[0] avg_epoch_loss=3.569272\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.569272041320801\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Epoch[1] Batch[5] avg_epoch_loss=3.422921\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.4229212601979575\n",
      "[05/21/2025 22:53:27 INFO 140039678244672] Epoch[1] Batch [5]#011Speed: 2256.27 samples/sec#011loss=3.422921\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Epoch[1] Batch[10] avg_epoch_loss=3.350217\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.262971019744873\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Epoch[1] Batch [10]#011Speed: 1984.93 samples/sec#011loss=3.262971\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747868007.247718, \"EndTime\": 1747868008.1904504, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.6822662353516, \"count\": 1, \"min\": 942.6822662353516, \"max\": 942.6822662353516}}}\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1423.4706492865394 records/second\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.350216605446555\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_570a2efb-7f2c-4a7b-b523-405090c021a7-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868008.1905065, \"EndTime\": 1747868008.201092, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.301828384399414, \"count\": 1, \"min\": 10.301828384399414, \"max\": 10.301828384399414}}}\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Epoch[2] Batch[0] avg_epoch_loss=3.332011\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.3320109844207764\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Epoch[2] Batch[5] avg_epoch_loss=3.262753\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.2627533674240112\n",
      "[05/21/2025 22:53:28 INFO 140039678244672] Epoch[2] Batch [5]#011Speed: 2155.45 samples/sec#011loss=3.262753\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Epoch[2] Batch[10] avg_epoch_loss=3.349782\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.454216241836548\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Epoch[2] Batch [10]#011Speed: 2145.74 samples/sec#011loss=3.454216\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747868008.201145, \"EndTime\": 1747868009.1295812, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.363561630249, \"count\": 1, \"min\": 928.363561630249, \"max\": 928.363561630249}}}\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1404.4875872191858 records/second\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.349781946702437\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_07f39d6d-21d7-45a3-b653-b06cc42f095b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868009.1296413, \"EndTime\": 1747868009.140705, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.78033447265625, \"count\": 1, \"min\": 10.78033447265625, \"max\": 10.78033447265625}}}\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Epoch[3] Batch[0] avg_epoch_loss=3.283588\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.283587694168091\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Epoch[3] Batch[5] avg_epoch_loss=3.228552\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.228552063306173\n",
      "[05/21/2025 22:53:29 INFO 140039678244672] Epoch[3] Batch [5]#011Speed: 2189.57 samples/sec#011loss=3.228552\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] processed a total of 1263 examples\n",
      "#metrics {\"StartTime\": 1747868009.1407561, \"EndTime\": 1747868010.0060468, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 865.2379512786865, \"count\": 1, \"min\": 865.2379512786865, \"max\": 865.2379512786865}}}\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1459.5608240582876 records/second\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.2851897716522216\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_cf1c6d30-667c-4ead-95fa-0d0182c7845c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868010.006107, \"EndTime\": 1747868010.0165246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.102033615112305, \"count\": 1, \"min\": 10.102033615112305, \"max\": 10.102033615112305}}}\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Epoch[4] Batch[0] avg_epoch_loss=3.385940\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.3859400749206543\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Epoch[4] Batch[5] avg_epoch_loss=3.255168\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.2551676432291665\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Epoch[4] Batch [5]#011Speed: 2103.05 samples/sec#011loss=3.255168\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Epoch[4] Batch[10] avg_epoch_loss=3.252001\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.2482015609741213\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Epoch[4] Batch [10]#011Speed: 1894.34 samples/sec#011loss=3.248202\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747868010.0166, \"EndTime\": 1747868010.9749227, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.2741260528564, \"count\": 1, \"min\": 958.2741260528564, \"max\": 958.2741260528564}}}\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1373.179584700367 records/second\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.252001242204146\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:30 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_96101552-9336-4237-9380-394fdbe6da7f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868010.97498, \"EndTime\": 1747868010.9860091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.747909545898438, \"count\": 1, \"min\": 10.747909545898438, \"max\": 10.747909545898438}}}\n",
      "[05/21/2025 22:53:31 INFO 140039678244672] Epoch[5] Batch[0] avg_epoch_loss=3.321702\n",
      "[05/21/2025 22:53:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.321702003479004\n",
      "[05/21/2025 22:53:31 INFO 140039678244672] Epoch[5] Batch[5] avg_epoch_loss=3.220100\n",
      "[05/21/2025 22:53:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.2201004028320312\n",
      "[05/21/2025 22:53:31 INFO 140039678244672] Epoch[5] Batch [5]#011Speed: 1717.77 samples/sec#011loss=3.220100\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Epoch[5] Batch[10] avg_epoch_loss=3.215730\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.2104866027832033\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Epoch[5] Batch [10]#011Speed: 1582.12 samples/sec#011loss=3.210487\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747868010.9860685, \"EndTime\": 1747868012.1244254, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1138.303518295288, \"count\": 1, \"min\": 1138.303518295288, \"max\": 1138.303518295288}}}\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1186.7659328403925 records/second\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.2157304937189277\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_a11992b5-e6e0-4911-a5ca-11cbaffed477-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868012.124481, \"EndTime\": 1747868012.1358838, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.926961898803711, \"count\": 1, \"min\": 10.926961898803711, \"max\": 10.926961898803711}}}\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Epoch[6] Batch[0] avg_epoch_loss=3.216772\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.2167723178863525\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Epoch[6] Batch[5] avg_epoch_loss=3.177713\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.177712599436442\n",
      "[05/21/2025 22:53:32 INFO 140039678244672] Epoch[6] Batch [5]#011Speed: 2001.09 samples/sec#011loss=3.177713\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] Epoch[6] Batch[10] avg_epoch_loss=3.226506\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.2850578308105467\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] Epoch[6] Batch [10]#011Speed: 1804.29 samples/sec#011loss=3.285058\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] processed a total of 1320 examples\n",
      "#metrics {\"StartTime\": 1747868012.1359446, \"EndTime\": 1747868013.1517174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1015.7225131988525, \"count\": 1, \"min\": 1015.7225131988525, \"max\": 1015.7225131988525}}}\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1299.4595553727959 records/second\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.2265058864246714\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] Epoch[7] Batch[0] avg_epoch_loss=3.302910\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.302910327911377\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] Epoch[7] Batch[5] avg_epoch_loss=3.181818\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.1818178494771323\n",
      "[05/21/2025 22:53:33 INFO 140039678244672] Epoch[7] Batch [5]#011Speed: 1907.73 samples/sec#011loss=3.181818\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Epoch[7] Batch[10] avg_epoch_loss=3.213976\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.252566337585449\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Epoch[7] Batch [10]#011Speed: 1902.80 samples/sec#011loss=3.252566\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747868013.151774, \"EndTime\": 1747868014.1544473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1002.4209022521973, \"count\": 1, \"min\": 1002.4209022521973, \"max\": 1002.4209022521973}}}\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1300.741868479194 records/second\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.213976253162731\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_57fc8cbf-fb66-4d00-b710-b133433fbbfb-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868014.1545033, \"EndTime\": 1747868014.1649113, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.143041610717773, \"count\": 1, \"min\": 10.143041610717773, \"max\": 10.143041610717773}}}\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Epoch[8] Batch[0] avg_epoch_loss=3.185846\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.1858460903167725\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Epoch[8] Batch[5] avg_epoch_loss=3.168270\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.168270150820414\n",
      "[05/21/2025 22:53:34 INFO 140039678244672] Epoch[8] Batch [5]#011Speed: 2062.20 samples/sec#011loss=3.168270\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Epoch[8] Batch[10] avg_epoch_loss=3.119979\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.06202917098999\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Epoch[8] Batch [10]#011Speed: 2055.94 samples/sec#011loss=3.062029\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747868014.1649594, \"EndTime\": 1747868015.1067848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.7765140533447, \"count\": 1, \"min\": 941.7765140533447, \"max\": 941.7765140533447}}}\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1434.395830142766 records/second\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.1199787963520396\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_ee59c9c8-1de6-4494-9de0-f038017eca53-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868015.1068408, \"EndTime\": 1747868015.1169887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.88149642944336, \"count\": 1, \"min\": 9.88149642944336, \"max\": 9.88149642944336}}}\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Epoch[9] Batch[0] avg_epoch_loss=2.961764\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.961763620376587\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Epoch[9] Batch[5] avg_epoch_loss=3.052943\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.0529428720474243\n",
      "[05/21/2025 22:53:35 INFO 140039678244672] Epoch[9] Batch [5]#011Speed: 1967.29 samples/sec#011loss=3.052943\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Epoch[9] Batch[10] avg_epoch_loss=3.093267\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.1416563987731934\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Epoch[9] Batch [10]#011Speed: 1758.01 samples/sec#011loss=3.141656\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747868015.117038, \"EndTime\": 1747868016.118444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1001.3566017150879, \"count\": 1, \"min\": 1001.3566017150879, \"max\": 1001.3566017150879}}}\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1358.0388542794299 records/second\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.0932672023773193\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_ad64e5f1-1b1c-4d5b-97e0-59a37c36a4cd-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868016.1185024, \"EndTime\": 1747868016.1291142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.330438613891602, \"count\": 1, \"min\": 10.330438613891602, \"max\": 10.330438613891602}}}\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Epoch[10] Batch[0] avg_epoch_loss=2.949334\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.949333667755127\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Epoch[10] Batch[5] avg_epoch_loss=3.025159\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.0251588026682534\n",
      "[05/21/2025 22:53:36 INFO 140039678244672] Epoch[10] Batch [5]#011Speed: 2049.61 samples/sec#011loss=3.025159\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] processed a total of 1266 examples\n",
      "#metrics {\"StartTime\": 1747868016.1291978, \"EndTime\": 1747868017.0187862, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 889.5320892333984, \"count\": 1, \"min\": 889.5320892333984, \"max\": 889.5320892333984}}}\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1423.05004590753 records/second\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.0312586069107055\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_de96c00c-2335-49ed-8883-5221a813ac9f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868017.018862, \"EndTime\": 1747868017.0293543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.179519653320312, \"count\": 1, \"min\": 10.179519653320312, \"max\": 10.179519653320312}}}\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Epoch[11] Batch[0] avg_epoch_loss=2.934703\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.9347033500671387\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Epoch[11] Batch[5] avg_epoch_loss=3.015705\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.015704870223999\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Epoch[11] Batch [5]#011Speed: 2150.27 samples/sec#011loss=3.015705\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Epoch[11] Batch[10] avg_epoch_loss=3.098903\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=3.1987398624420167\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] Epoch[11] Batch [10]#011Speed: 2085.55 samples/sec#011loss=3.198740\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] processed a total of 1323 examples\n",
      "#metrics {\"StartTime\": 1747868017.0294023, \"EndTime\": 1747868017.9524827, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 923.0301380157471, \"count\": 1, \"min\": 923.0301380157471, \"max\": 923.0301380157471}}}\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1433.1771617893407 records/second\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.0989025939594614\n",
      "[05/21/2025 22:53:37 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] Epoch[12] Batch[0] avg_epoch_loss=3.088809\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.08880877494812\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] Epoch[12] Batch[5] avg_epoch_loss=2.964589\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.9645885626475015\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] Epoch[12] Batch [5]#011Speed: 2108.02 samples/sec#011loss=2.964589\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] Epoch[12] Batch[10] avg_epoch_loss=2.968965\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=2.9742156982421877\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] Epoch[12] Batch [10]#011Speed: 1976.67 samples/sec#011loss=2.974216\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] processed a total of 1410 examples\n",
      "#metrics {\"StartTime\": 1747868017.9525464, \"EndTime\": 1747868018.9512777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 997.7879524230957, \"count\": 1, \"min\": 997.7879524230957, \"max\": 997.7879524230957}}}\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1412.9972640653584 records/second\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.0685986280441284\n",
      "[05/21/2025 22:53:38 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] Epoch[13] Batch[0] avg_epoch_loss=3.053341\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.0533409118652344\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] Epoch[13] Batch[5] avg_epoch_loss=2.995858\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.99585751692454\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] Epoch[13] Batch [5]#011Speed: 2112.58 samples/sec#011loss=2.995858\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] Epoch[13] Batch[10] avg_epoch_loss=3.045060\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.1041040420532227\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] Epoch[13] Batch [10]#011Speed: 2045.01 samples/sec#011loss=3.104104\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] processed a total of 1356 examples\n",
      "#metrics {\"StartTime\": 1747868018.9513392, \"EndTime\": 1747868019.878963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.2928237915039, \"count\": 1, \"min\": 927.2928237915039, \"max\": 927.2928237915039}}}\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1462.1911708221778 records/second\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.045060482892123\n",
      "[05/21/2025 22:53:39 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Epoch[14] Batch[0] avg_epoch_loss=2.993405\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=2.993405342102051\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Epoch[14] Batch[5] avg_epoch_loss=2.984151\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.984151323636373\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Epoch[14] Batch [5]#011Speed: 2179.12 samples/sec#011loss=2.984151\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Epoch[14] Batch[10] avg_epoch_loss=2.960331\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=2.9317463874816894\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Epoch[14] Batch [10]#011Speed: 1964.21 samples/sec#011loss=2.931746\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] processed a total of 1393 examples\n",
      "#metrics {\"StartTime\": 1747868019.8790188, \"EndTime\": 1747868020.8193023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.0391578674316, \"count\": 1, \"min\": 940.0391578674316, \"max\": 940.0391578674316}}}\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1481.7122382033813 records/second\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.9603308981115166\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:40 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_22677cf5-d72d-45a0-a746-f6db127a96d5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868020.8193638, \"EndTime\": 1747868020.8300414, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.349512100219727, \"count\": 1, \"min\": 10.349512100219727, \"max\": 10.349512100219727}}}\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Epoch[15] Batch[0] avg_epoch_loss=3.071212\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.07121205329895\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Epoch[15] Batch[5] avg_epoch_loss=2.924342\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.924341837565104\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Epoch[15] Batch [5]#011Speed: 2115.20 samples/sec#011loss=2.924342\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Epoch[15] Batch[10] avg_epoch_loss=2.955516\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=2.9929253101348876\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Epoch[15] Batch [10]#011Speed: 1996.59 samples/sec#011loss=2.992925\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747868020.830094, \"EndTime\": 1747868021.7888644, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.7209224700928, \"count\": 1, \"min\": 958.7209224700928, \"max\": 958.7209224700928}}}\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1417.3853529911867 records/second\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.955516143278642\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:41 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_4d54c1a5-c0a3-44e7-9ff8-1905aeb25df8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868021.7889237, \"EndTime\": 1747868021.799998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.765552520751953, \"count\": 1, \"min\": 10.765552520751953, \"max\": 10.765552520751953}}}\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] Epoch[16] Batch[0] avg_epoch_loss=3.018320\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.018320322036743\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] Epoch[16] Batch[5] avg_epoch_loss=2.998804\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.9988038142522178\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] Epoch[16] Batch [5]#011Speed: 2199.16 samples/sec#011loss=2.998804\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] Epoch[16] Batch[10] avg_epoch_loss=3.023663\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=3.0534934997558594\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] Epoch[16] Batch [10]#011Speed: 2034.98 samples/sec#011loss=3.053493\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] processed a total of 1306 examples\n",
      "#metrics {\"StartTime\": 1747868021.8000505, \"EndTime\": 1747868022.7423878, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.284345626831, \"count\": 1, \"min\": 942.284345626831, \"max\": 942.284345626831}}}\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1385.873248038618 records/second\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.0236627622084185\n",
      "[05/21/2025 22:53:42 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Epoch[17] Batch[0] avg_epoch_loss=2.846042\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=2.8460421562194824\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Epoch[17] Batch[5] avg_epoch_loss=2.887623\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=2.887623111406962\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Epoch[17] Batch [5]#011Speed: 2183.57 samples/sec#011loss=2.887623\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Epoch[17] Batch[10] avg_epoch_loss=2.942488\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.008326005935669\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Epoch[17] Batch [10]#011Speed: 2105.11 samples/sec#011loss=3.008326\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747868022.742441, \"EndTime\": 1747868023.6619241, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 919.2352294921875, \"count\": 1, \"min\": 919.2352294921875, \"max\": 919.2352294921875}}}\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1415.174802744461 records/second\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=17, train loss <loss>=2.9424880634654653\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:43 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_4ba5886e-00f8-4b36-9ce5-0d9984633e34-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868023.661983, \"EndTime\": 1747868023.6728594, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.542869567871094, \"count\": 1, \"min\": 10.542869567871094, \"max\": 10.542869567871094}}}\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[18] Batch[0] avg_epoch_loss=3.106320\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.1063196659088135\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[18] Batch[5] avg_epoch_loss=3.039408\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.0394084453582764\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[18] Batch [5]#011Speed: 2181.38 samples/sec#011loss=3.039408\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[18] Batch[10] avg_epoch_loss=3.038717\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.0378865718841555\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[18] Batch [10]#011Speed: 1966.46 samples/sec#011loss=3.037887\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] processed a total of 1379 examples\n",
      "#metrics {\"StartTime\": 1747868023.6729088, \"EndTime\": 1747868024.621821, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 948.8644599914551, \"count\": 1, \"min\": 948.8644599914551, \"max\": 948.8644599914551}}}\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1453.1868448160635 records/second\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.038716684688221\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] Epoch[19] Batch[0] avg_epoch_loss=3.115020\n",
      "[05/21/2025 22:53:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.115020275115967\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] Epoch[19] Batch[5] avg_epoch_loss=2.990650\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=2.9906504154205322\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] Epoch[19] Batch [5]#011Speed: 2157.45 samples/sec#011loss=2.990650\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] processed a total of 1200 examples\n",
      "#metrics {\"StartTime\": 1747868024.621877, \"EndTime\": 1747868025.463793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 841.6633605957031, \"count\": 1, \"min\": 841.6633605957031, \"max\": 841.6633605957031}}}\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1425.5906816496545 records/second\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.867463302612305\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_53d667d9-5e33-40c2-911b-cced8c583015-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868025.463857, \"EndTime\": 1747868025.474305, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.091304779052734, \"count\": 1, \"min\": 10.091304779052734, \"max\": 10.091304779052734}}}\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] Epoch[20] Batch[0] avg_epoch_loss=3.145285\n",
      "[05/21/2025 22:53:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.145284652709961\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] Epoch[20] Batch[5] avg_epoch_loss=2.968836\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=2.9688358306884766\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] Epoch[20] Batch [5]#011Speed: 2111.86 samples/sec#011loss=2.968836\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] Epoch[20] Batch[10] avg_epoch_loss=3.030304\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=3.1040658950805664\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] Epoch[20] Batch [10]#011Speed: 2018.36 samples/sec#011loss=3.104066\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747868025.4743543, \"EndTime\": 1747868026.40973, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.3268146514893, \"count\": 1, \"min\": 935.3268146514893, \"max\": 935.3268146514893}}}\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1387.6193550771459 records/second\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.03030404177579\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] Epoch[21] Batch[0] avg_epoch_loss=3.070351\n",
      "[05/21/2025 22:53:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.0703511238098145\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[21] Batch[5] avg_epoch_loss=3.077614\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.0776140292485556\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[21] Batch [5]#011Speed: 2235.40 samples/sec#011loss=3.077614\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[21] Batch[10] avg_epoch_loss=3.056501\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=3.031165361404419\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[21] Batch [10]#011Speed: 2078.73 samples/sec#011loss=3.031165\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747868026.4097893, \"EndTime\": 1747868027.3185596, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 908.5204601287842, \"count\": 1, \"min\": 908.5204601287842, \"max\": 908.5204601287842}}}\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1482.477448987196 records/second\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=21, train loss <loss>=3.0565009984103115\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[22] Batch[0] avg_epoch_loss=2.863285\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.8632845878601074\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[22] Batch[5] avg_epoch_loss=2.942289\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.9422885179519653\n",
      "[05/21/2025 22:53:47 INFO 140039678244672] Epoch[22] Batch [5]#011Speed: 2149.55 samples/sec#011loss=2.942289\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] Epoch[22] Batch[10] avg_epoch_loss=2.940520\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=2.938397026062012\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] Epoch[22] Batch [10]#011Speed: 1904.23 samples/sec#011loss=2.938397\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] processed a total of 1391 examples\n",
      "#metrics {\"StartTime\": 1747868027.3186235, \"EndTime\": 1747868028.282409, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 963.4485244750977, \"count\": 1, \"min\": 963.4485244750977, \"max\": 963.4485244750977}}}\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1443.5940926795884 records/second\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.9405196580019863\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] Epoch[23] Batch[0] avg_epoch_loss=2.807034\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.8070342540740967\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] Epoch[23] Batch[5] avg_epoch_loss=2.845057\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.8450570901234946\n",
      "[05/21/2025 22:53:48 INFO 140039678244672] Epoch[23] Batch [5]#011Speed: 2143.77 samples/sec#011loss=2.845057\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] processed a total of 1257 examples\n",
      "#metrics {\"StartTime\": 1747868028.2824953, \"EndTime\": 1747868029.1607444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 877.9096603393555, \"count\": 1, \"min\": 877.9096603393555, \"max\": 877.9096603393555}}}\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1431.6616696564006 records/second\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.8797963142395018\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] Epoch[24] Batch[0] avg_epoch_loss=2.908964\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.908964157104492\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] Epoch[24] Batch[5] avg_epoch_loss=2.880745\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.8807448546091714\n",
      "[05/21/2025 22:53:49 INFO 140039678244672] Epoch[24] Batch [5]#011Speed: 2184.26 samples/sec#011loss=2.880745\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Epoch[24] Batch[10] avg_epoch_loss=2.844024\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.7999584674835205\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Epoch[24] Batch [10]#011Speed: 2129.90 samples/sec#011loss=2.799958\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747868029.1608036, \"EndTime\": 1747868030.0825734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.400785446167, \"count\": 1, \"min\": 921.400785446167, \"max\": 921.400785446167}}}\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1404.2337327333923 records/second\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.8440237695520576\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_8f113bc4-2d11-422d-9803-f9dc7c4c3e6f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868030.0826392, \"EndTime\": 1747868030.092664, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.677886962890625, \"count\": 1, \"min\": 9.677886962890625, \"max\": 9.677886962890625}}}\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Epoch[25] Batch[0] avg_epoch_loss=2.908136\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.9081361293792725\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Epoch[25] Batch[5] avg_epoch_loss=2.868694\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.868693550427755\n",
      "[05/21/2025 22:53:50 INFO 140039678244672] Epoch[25] Batch [5]#011Speed: 2132.32 samples/sec#011loss=2.868694\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[25] Batch[10] avg_epoch_loss=2.899229\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=2.935872268676758\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[25] Batch [10]#011Speed: 2033.66 samples/sec#011loss=2.935872\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] processed a total of 1291 examples\n",
      "#metrics {\"StartTime\": 1747868030.0927207, \"EndTime\": 1747868031.0198338, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.06298828125, \"count\": 1, \"min\": 927.06298828125, \"max\": 927.06298828125}}}\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1392.4377464961133 records/second\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.899229331450029\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[26] Batch[0] avg_epoch_loss=2.954578\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.954577922821045\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[26] Batch[5] avg_epoch_loss=2.953744\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.9537444512049356\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[26] Batch [5]#011Speed: 2122.78 samples/sec#011loss=2.953744\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[26] Batch[10] avg_epoch_loss=2.983640\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=3.019514036178589\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] Epoch[26] Batch [10]#011Speed: 2057.14 samples/sec#011loss=3.019514\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747868031.0198936, \"EndTime\": 1747868031.9571366, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 936.9893074035645, \"count\": 1, \"min\": 936.9893074035645, \"max\": 936.9893074035645}}}\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1387.2699563663193 records/second\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.983639717102051\n",
      "[05/21/2025 22:53:51 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] Epoch[27] Batch[0] avg_epoch_loss=3.124765\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=3.124764919281006\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] Epoch[27] Batch[5] avg_epoch_loss=3.007196\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=3.007195750872294\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] Epoch[27] Batch [5]#011Speed: 2169.66 samples/sec#011loss=3.007196\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] Epoch[27] Batch[10] avg_epoch_loss=2.962127\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.908044767379761\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] Epoch[27] Batch [10]#011Speed: 2121.29 samples/sec#011loss=2.908045\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] processed a total of 1360 examples\n",
      "#metrics {\"StartTime\": 1747868031.957213, \"EndTime\": 1747868032.8668697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 909.3954563140869, \"count\": 1, \"min\": 909.3954563140869, \"max\": 909.3954563140869}}}\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1495.3582618543296 records/second\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.9621271220120517\n",
      "[05/21/2025 22:53:52 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] Epoch[28] Batch[0] avg_epoch_loss=2.849691\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.849691390991211\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] Epoch[28] Batch[5] avg_epoch_loss=2.861701\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.8617008129755654\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] Epoch[28] Batch [5]#011Speed: 2131.63 samples/sec#011loss=2.861701\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] Epoch[28] Batch[10] avg_epoch_loss=2.863094\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=2.8647647380828856\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] Epoch[28] Batch [10]#011Speed: 1759.54 samples/sec#011loss=2.864765\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747868032.8669264, \"EndTime\": 1747868033.8524303, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 985.2585792541504, \"count\": 1, \"min\": 985.2585792541504, \"max\": 985.2585792541504}}}\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1335.5726499738557 records/second\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.8630935062061655\n",
      "[05/21/2025 22:53:53 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] Epoch[29] Batch[0] avg_epoch_loss=2.853114\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.853114128112793\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] Epoch[29] Batch[5] avg_epoch_loss=2.804688\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.8046875\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] Epoch[29] Batch [5]#011Speed: 2047.60 samples/sec#011loss=2.804688\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] Epoch[29] Batch[10] avg_epoch_loss=2.885855\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=2.98325572013855\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] Epoch[29] Batch [10]#011Speed: 2119.05 samples/sec#011loss=2.983256\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747868033.8524897, \"EndTime\": 1747868034.8048515, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.0378112792969, \"count\": 1, \"min\": 952.0378112792969, \"max\": 952.0378112792969}}}\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1374.8210994023534 records/second\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.88585487279025\n",
      "[05/21/2025 22:53:54 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] Epoch[30] Batch[0] avg_epoch_loss=3.112880\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=3.1128804683685303\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] Epoch[30] Batch[5] avg_epoch_loss=2.986420\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.986419677734375\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] Epoch[30] Batch [5]#011Speed: 2147.34 samples/sec#011loss=2.986420\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] Epoch[30] Batch[10] avg_epoch_loss=2.950110\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=2.906538486480713\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] Epoch[30] Batch [10]#011Speed: 2040.73 samples/sec#011loss=2.906538\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] processed a total of 1359 examples\n",
      "#metrics {\"StartTime\": 1747868034.804911, \"EndTime\": 1747868035.7423317, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.1659755706787, \"count\": 1, \"min\": 937.1659755706787, \"max\": 937.1659755706787}}}\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1449.9879260503653 records/second\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.9501100453463467\n",
      "[05/21/2025 22:53:55 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] Epoch[31] Batch[0] avg_epoch_loss=2.980428\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.9804279804229736\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] Epoch[31] Batch[5] avg_epoch_loss=2.991928\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.9919283787409463\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] Epoch[31] Batch [5]#011Speed: 2078.54 samples/sec#011loss=2.991928\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] Epoch[31] Batch[10] avg_epoch_loss=2.937093\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=2.8712912082672117\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] Epoch[31] Batch [10]#011Speed: 2022.03 samples/sec#011loss=2.871291\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] processed a total of 1315 examples\n",
      "#metrics {\"StartTime\": 1747868035.742387, \"EndTime\": 1747868036.686113, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.4278011322021, \"count\": 1, \"min\": 943.4278011322021, \"max\": 943.4278011322021}}}\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1393.7254945562552 records/second\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.9370933012528853\n",
      "[05/21/2025 22:53:56 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[32] Batch[0] avg_epoch_loss=2.950505\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.950505256652832\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[32] Batch[5] avg_epoch_loss=2.875283\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.875282963116964\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[32] Batch [5]#011Speed: 2176.80 samples/sec#011loss=2.875283\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[32] Batch[10] avg_epoch_loss=2.872476\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=2.8691084384918213\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[32] Batch [10]#011Speed: 2040.16 samples/sec#011loss=2.869108\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747868036.6861691, \"EndTime\": 1747868037.6114874, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0693321228027, \"count\": 1, \"min\": 925.0693321228027, \"max\": 925.0693321228027}}}\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1423.547928112084 records/second\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.8724763610146264\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] Epoch[33] Batch[0] avg_epoch_loss=2.786280\n",
      "[05/21/2025 22:53:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.786280393600464\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Epoch[33] Batch[5] avg_epoch_loss=2.836293\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.83629310131073\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Epoch[33] Batch [5]#011Speed: 2153.83 samples/sec#011loss=2.836293\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Epoch[33] Batch[10] avg_epoch_loss=2.763503\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=2.6761550426483156\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Epoch[33] Batch [10]#011Speed: 2101.85 samples/sec#011loss=2.676155\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747868037.6115432, \"EndTime\": 1747868038.5297117, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 917.8721904754639, \"count\": 1, \"min\": 917.8721904754639, \"max\": 917.8721904754639}}}\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1416.1919140944283 records/second\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.763503074645996\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_ef94eb6d-0c4d-46be-a492-b4c1805ff196-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868038.5297666, \"EndTime\": 1747868038.539642, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.61160659790039, \"count\": 1, \"min\": 9.61160659790039, \"max\": 9.61160659790039}}}\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] Epoch[34] Batch[0] avg_epoch_loss=3.011615\n",
      "[05/21/2025 22:53:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=3.011615037918091\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] Epoch[34] Batch[5] avg_epoch_loss=2.879901\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.8799006938934326\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] Epoch[34] Batch [5]#011Speed: 2215.31 samples/sec#011loss=2.879901\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] processed a total of 1279 examples\n",
      "#metrics {\"StartTime\": 1747868038.5396912, \"EndTime\": 1747868039.4234111, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 883.6703300476074, \"count\": 1, \"min\": 883.6703300476074, \"max\": 883.6703300476074}}}\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1447.2204557551572 records/second\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.893144679069519\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] Epoch[35] Batch[0] avg_epoch_loss=2.980130\n",
      "[05/21/2025 22:53:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.980130195617676\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] Epoch[35] Batch[5] avg_epoch_loss=2.836271\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.8362707694371543\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] Epoch[35] Batch [5]#011Speed: 2153.97 samples/sec#011loss=2.836271\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] processed a total of 1264 examples\n",
      "#metrics {\"StartTime\": 1747868039.4234748, \"EndTime\": 1747868040.295035, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 871.2091445922852, \"count\": 1, \"min\": 871.2091445922852, \"max\": 871.2091445922852}}}\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1450.691978069969 records/second\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.8173850059509276\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] Epoch[36] Batch[0] avg_epoch_loss=2.751853\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.7518534660339355\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] Epoch[36] Batch[5] avg_epoch_loss=2.759395\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.759395440419515\n",
      "[05/21/2025 22:54:00 INFO 140039678244672] Epoch[36] Batch [5]#011Speed: 2075.84 samples/sec#011loss=2.759395\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] Epoch[36] Batch[10] avg_epoch_loss=2.871870\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=3.0068397521972656\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] Epoch[36] Batch [10]#011Speed: 2023.17 samples/sec#011loss=3.006840\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747868040.2951035, \"EndTime\": 1747868041.2600992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 964.6739959716797, \"count\": 1, \"min\": 964.6739959716797, \"max\": 964.6739959716797}}}\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1345.398607896429 records/second\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.8718701275912197\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] Epoch[37] Batch[0] avg_epoch_loss=2.987023\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.987023115158081\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] Epoch[37] Batch[5] avg_epoch_loss=2.894200\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.8942000468571982\n",
      "[05/21/2025 22:54:01 INFO 140039678244672] Epoch[37] Batch [5]#011Speed: 1981.27 samples/sec#011loss=2.894200\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] Epoch[37] Batch[10] avg_epoch_loss=2.877102\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=2.8565841197967528\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] Epoch[37] Batch [10]#011Speed: 2094.52 samples/sec#011loss=2.856584\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] processed a total of 1288 examples\n",
      "#metrics {\"StartTime\": 1747868041.2601624, \"EndTime\": 1747868042.2113814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.9263038635254, \"count\": 1, \"min\": 950.9263038635254, \"max\": 950.9263038635254}}}\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1354.345867315678 records/second\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.8771018981933594\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] Epoch[38] Batch[0] avg_epoch_loss=2.799570\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.799570322036743\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] Epoch[38] Batch[5] avg_epoch_loss=2.851625\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.8516250054041543\n",
      "[05/21/2025 22:54:02 INFO 140039678244672] Epoch[38] Batch [5]#011Speed: 2161.41 samples/sec#011loss=2.851625\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] Epoch[38] Batch[10] avg_epoch_loss=2.833903\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=2.8126355171203614\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] Epoch[38] Batch [10]#011Speed: 1980.87 samples/sec#011loss=2.812636\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] processed a total of 1355 examples\n",
      "#metrics {\"StartTime\": 1747868042.211437, \"EndTime\": 1747868043.1451406, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 933.3789348602295, \"count\": 1, \"min\": 933.3789348602295, \"max\": 933.3789348602295}}}\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1451.5531256648578 records/second\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.833902510729703\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] Epoch[39] Batch[0] avg_epoch_loss=2.782075\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.7820751667022705\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] Epoch[39] Batch[5] avg_epoch_loss=2.756799\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.756799300511678\n",
      "[05/21/2025 22:54:03 INFO 140039678244672] Epoch[39] Batch [5]#011Speed: 2132.30 samples/sec#011loss=2.756799\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Epoch[39] Batch[10] avg_epoch_loss=2.707347\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=2.6480039596557616\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Epoch[39] Batch [10]#011Speed: 2093.35 samples/sec#011loss=2.648004\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747868043.145215, \"EndTime\": 1747868044.0641434, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 918.6022281646729, \"count\": 1, \"min\": 918.6022281646729, \"max\": 918.6022281646729}}}\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1462.9527364455857 records/second\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.707346872849898\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_5e941c5f-f69a-434e-a30d-e3bbd154c09e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868044.064202, \"EndTime\": 1747868044.0752387, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.760068893432617, \"count\": 1, \"min\": 10.760068893432617, \"max\": 10.760068893432617}}}\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Epoch[40] Batch[0] avg_epoch_loss=2.823097\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.823096990585327\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Epoch[40] Batch[5] avg_epoch_loss=2.759601\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.7596009969711304\n",
      "[05/21/2025 22:54:04 INFO 140039678244672] Epoch[40] Batch [5]#011Speed: 2176.31 samples/sec#011loss=2.759601\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[40] Batch[10] avg_epoch_loss=2.804478\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=2.858330249786377\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[40] Batch [10]#011Speed: 2166.30 samples/sec#011loss=2.858330\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] processed a total of 1299 examples\n",
      "#metrics {\"StartTime\": 1747868044.075292, \"EndTime\": 1747868045.0059552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.5994510650635, \"count\": 1, \"min\": 930.5994510650635, \"max\": 930.5994510650635}}}\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1395.741073217218 records/second\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.8044779300689697\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[41] Batch[0] avg_epoch_loss=2.794183\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.7941832542419434\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[41] Batch[5] avg_epoch_loss=2.871680\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.871680418650309\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[41] Batch [5]#011Speed: 2064.08 samples/sec#011loss=2.871680\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[41] Batch[10] avg_epoch_loss=2.775428\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=2.6599258899688722\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] Epoch[41] Batch [10]#011Speed: 2046.30 samples/sec#011loss=2.659926\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] processed a total of 1318 examples\n",
      "#metrics {\"StartTime\": 1747868045.006015, \"EndTime\": 1747868045.965257, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.9815139770508, \"count\": 1, \"min\": 958.9815139770508, \"max\": 958.9815139770508}}}\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1374.2422086148229 records/second\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.775428360158747\n",
      "[05/21/2025 22:54:05 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] Epoch[42] Batch[0] avg_epoch_loss=2.724887\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.7248873710632324\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] Epoch[42] Batch[5] avg_epoch_loss=2.733680\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.7336795330047607\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] Epoch[42] Batch [5]#011Speed: 2132.31 samples/sec#011loss=2.733680\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] Epoch[42] Batch[10] avg_epoch_loss=2.768361\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.8099795818328857\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] Epoch[42] Batch [10]#011Speed: 2077.20 samples/sec#011loss=2.809980\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] processed a total of 1325 examples\n",
      "#metrics {\"StartTime\": 1747868045.9653215, \"EndTime\": 1747868046.9160864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.465202331543, \"count\": 1, \"min\": 950.465202331543, \"max\": 950.465202331543}}}\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1393.9167776333336 records/second\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.768361373381181\n",
      "[05/21/2025 22:54:06 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] Epoch[43] Batch[0] avg_epoch_loss=2.900434\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.9004335403442383\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] Epoch[43] Batch[5] avg_epoch_loss=2.837516\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.837515950202942\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] Epoch[43] Batch [5]#011Speed: 2100.42 samples/sec#011loss=2.837516\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] Epoch[43] Batch[10] avg_epoch_loss=2.775376\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.700806999206543\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] Epoch[43] Batch [10]#011Speed: 2111.19 samples/sec#011loss=2.700807\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] processed a total of 1346 examples\n",
      "#metrics {\"StartTime\": 1747868046.9161499, \"EndTime\": 1747868047.8612869, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.8320865631104, \"count\": 1, \"min\": 944.8320865631104, \"max\": 944.8320865631104}}}\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1424.4652285426284 records/second\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.7753755179318516\n",
      "[05/21/2025 22:54:07 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] Epoch[44] Batch[0] avg_epoch_loss=3.101784\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=3.1017837524414062\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] Epoch[44] Batch[5] avg_epoch_loss=2.849811\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.8498111168543496\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] Epoch[44] Batch [5]#011Speed: 1967.42 samples/sec#011loss=2.849811\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] Epoch[44] Batch[10] avg_epoch_loss=2.844781\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=2.8387439250946045\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] Epoch[44] Batch [10]#011Speed: 2041.50 samples/sec#011loss=2.838744\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747868047.8613443, \"EndTime\": 1747868048.8423269, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 980.7147979736328, \"count\": 1, \"min\": 980.7147979736328, \"max\": 980.7147979736328}}}\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1338.6993126767684 records/second\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.8447805751453745\n",
      "[05/21/2025 22:54:08 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Epoch[45] Batch[0] avg_epoch_loss=2.803029\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.8030290603637695\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Epoch[45] Batch[5] avg_epoch_loss=2.758190\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.758190075556437\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Epoch[45] Batch [5]#011Speed: 2099.34 samples/sec#011loss=2.758190\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Epoch[45] Batch[10] avg_epoch_loss=2.662842\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=2.5484238386154177\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Epoch[45] Batch [10]#011Speed: 2146.93 samples/sec#011loss=2.548424\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747868048.842386, \"EndTime\": 1747868049.7842681, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 941.6167736053467, \"count\": 1, \"min\": 941.6167736053467, \"max\": 941.6167736053467}}}\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1368.794893100754 records/second\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.662841786037792\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:54:09 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_039d76d8-54db-4e82-a027-6d479b569763-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868049.784327, \"EndTime\": 1747868049.795143, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.514974594116211, \"count\": 1, \"min\": 10.514974594116211, \"max\": 10.514974594116211}}}\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] Epoch[46] Batch[0] avg_epoch_loss=2.868196\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.8681955337524414\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] Epoch[46] Batch[5] avg_epoch_loss=2.832919\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.832919160525004\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] Epoch[46] Batch [5]#011Speed: 2145.95 samples/sec#011loss=2.832919\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] Epoch[46] Batch[10] avg_epoch_loss=2.815736\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.795116138458252\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] Epoch[46] Batch [10]#011Speed: 2083.56 samples/sec#011loss=2.795116\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747868049.7952003, \"EndTime\": 1747868050.7359757, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.7215118408203, \"count\": 1, \"min\": 940.7215118408203, \"max\": 940.7215118408203}}}\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1409.4192033767388 records/second\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.8157359686764805\n",
      "[05/21/2025 22:54:10 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] Epoch[47] Batch[0] avg_epoch_loss=2.761642\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.7616419792175293\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] Epoch[47] Batch[5] avg_epoch_loss=2.733175\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.733175357182821\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] Epoch[47] Batch [5]#011Speed: 2091.96 samples/sec#011loss=2.733175\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] Epoch[47] Batch[10] avg_epoch_loss=2.767752\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=2.809243011474609\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] Epoch[47] Batch [10]#011Speed: 2006.49 samples/sec#011loss=2.809243\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747868050.7360377, \"EndTime\": 1747868051.7020588, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 965.742826461792, \"count\": 1, \"min\": 965.742826461792, \"max\": 965.742826461792}}}\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1398.7594715796454 records/second\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.7677515636790884\n",
      "[05/21/2025 22:54:11 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[48] Batch[0] avg_epoch_loss=2.710209\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.710209369659424\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[48] Batch[5] avg_epoch_loss=2.710558\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.7105578184127808\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[48] Batch [5]#011Speed: 2125.94 samples/sec#011loss=2.710558\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[48] Batch[10] avg_epoch_loss=2.614180\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=2.4985273838043214\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[48] Batch [10]#011Speed: 2007.02 samples/sec#011loss=2.498527\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747868051.7021356, \"EndTime\": 1747868052.6429226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.4549598693848, \"count\": 1, \"min\": 940.4549598693848, \"max\": 940.4549598693848}}}\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1390.67624211302 records/second\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.6141803481362085\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_e499476b-b91c-42c8-a53b-dc7532ce5051-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868052.6429858, \"EndTime\": 1747868052.6529496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.622335433959961, \"count\": 1, \"min\": 9.622335433959961, \"max\": 9.622335433959961}}}\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] Epoch[49] Batch[0] avg_epoch_loss=3.172111\n",
      "[05/21/2025 22:54:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=3.1721107959747314\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] Epoch[49] Batch[5] avg_epoch_loss=3.146817\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=3.1468174854914346\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] Epoch[49] Batch [5]#011Speed: 2106.01 samples/sec#011loss=3.146817\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] Epoch[49] Batch[10] avg_epoch_loss=3.058615\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=2.952771520614624\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] Epoch[49] Batch [10]#011Speed: 1941.44 samples/sec#011loss=2.952772\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] processed a total of 1367 examples\n",
      "#metrics {\"StartTime\": 1747868052.653008, \"EndTime\": 1747868053.6075034, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.442024230957, \"count\": 1, \"min\": 954.442024230957, \"max\": 954.442024230957}}}\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1432.1159197881104 records/second\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=49, train loss <loss>=3.0586147741837935\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] Epoch[50] Batch[0] avg_epoch_loss=2.884904\n",
      "[05/21/2025 22:54:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.884903907775879\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] Epoch[50] Batch[5] avg_epoch_loss=2.852137\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.8521373669306436\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] Epoch[50] Batch [5]#011Speed: 2069.33 samples/sec#011loss=2.852137\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] Epoch[50] Batch[10] avg_epoch_loss=2.849579\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.846509885787964\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] Epoch[50] Batch [10]#011Speed: 2041.65 samples/sec#011loss=2.846510\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747868053.6075609, \"EndTime\": 1747868054.5485847, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 940.6495094299316, \"count\": 1, \"min\": 940.6495094299316, \"max\": 940.6495094299316}}}\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1405.2865072602683 records/second\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.8495794209566983\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] Epoch[51] Batch[0] avg_epoch_loss=2.891051\n",
      "[05/21/2025 22:54:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.8910510540008545\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] Epoch[51] Batch[5] avg_epoch_loss=2.839245\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.839244802792867\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] Epoch[51] Batch [5]#011Speed: 1972.75 samples/sec#011loss=2.839245\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] Epoch[51] Batch[10] avg_epoch_loss=2.871868\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.9110167980194093\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] Epoch[51] Batch [10]#011Speed: 1675.00 samples/sec#011loss=2.911017\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] processed a total of 1402 examples\n",
      "#metrics {\"StartTime\": 1747868054.5486424, \"EndTime\": 1747868055.5874686, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1038.573980331421, \"count\": 1, \"min\": 1038.573980331421, \"max\": 1038.573980331421}}}\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1349.755008718849 records/second\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.87186843698675\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] Epoch[52] Batch[0] avg_epoch_loss=2.772520\n",
      "[05/21/2025 22:54:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.7725203037261963\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] Epoch[52] Batch[5] avg_epoch_loss=2.865179\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.865179419517517\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] Epoch[52] Batch [5]#011Speed: 2121.00 samples/sec#011loss=2.865179\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] processed a total of 1261 examples\n",
      "#metrics {\"StartTime\": 1747868055.5875697, \"EndTime\": 1747868056.4559233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 867.4368858337402, \"count\": 1, \"min\": 867.4368858337402, \"max\": 867.4368858337402}}}\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1453.5258932325662 records/second\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.8412468671798705\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] Epoch[53] Batch[0] avg_epoch_loss=2.777425\n",
      "[05/21/2025 22:54:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.7774252891540527\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] Epoch[53] Batch[5] avg_epoch_loss=2.773443\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.773443023363749\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] Epoch[53] Batch [5]#011Speed: 2111.76 samples/sec#011loss=2.773443\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] Epoch[53] Batch[10] avg_epoch_loss=2.709117\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.6319268226623533\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] Epoch[53] Batch [10]#011Speed: 2010.30 samples/sec#011loss=2.631927\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] processed a total of 1308 examples\n",
      "#metrics {\"StartTime\": 1747868056.4559968, \"EndTime\": 1747868057.3996894, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.2554244995117, \"count\": 1, \"min\": 943.2554244995117, \"max\": 943.2554244995117}}}\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1386.5600933311969 records/second\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.7091174775903877\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] Epoch[54] Batch[0] avg_epoch_loss=2.797012\n",
      "[05/21/2025 22:54:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.797011613845825\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[54] Batch[5] avg_epoch_loss=2.757059\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.75705885887146\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[54] Batch [5]#011Speed: 2143.84 samples/sec#011loss=2.757059\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[54] Batch[10] avg_epoch_loss=2.849418\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=2.9602492332458494\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[54] Batch [10]#011Speed: 2025.21 samples/sec#011loss=2.960249\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747868057.399748, \"EndTime\": 1747868058.3421905, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 942.1372413635254, \"count\": 1, \"min\": 942.1372413635254, \"max\": 942.1372413635254}}}\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1360.592011999915 records/second\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.849418119950728\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[55] Batch[0] avg_epoch_loss=2.898941\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.8989412784576416\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[55] Batch[5] avg_epoch_loss=2.896953\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.8969526290893555\n",
      "[05/21/2025 22:54:18 INFO 140039678244672] Epoch[55] Batch [5]#011Speed: 2184.13 samples/sec#011loss=2.896953\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] Epoch[55] Batch[10] avg_epoch_loss=2.820202\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.7281020641326905\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] Epoch[55] Batch [10]#011Speed: 2012.60 samples/sec#011loss=2.728102\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] processed a total of 1363 examples\n",
      "#metrics {\"StartTime\": 1747868058.3422587, \"EndTime\": 1747868059.2730694, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 930.4728507995605, \"count\": 1, \"min\": 930.4728507995605, \"max\": 930.4728507995605}}}\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1464.7111223615807 records/second\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.8202023722908716\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] Epoch[56] Batch[0] avg_epoch_loss=2.816246\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.8162460327148438\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] Epoch[56] Batch[5] avg_epoch_loss=2.851778\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.8517781496047974\n",
      "[05/21/2025 22:54:19 INFO 140039678244672] Epoch[56] Batch [5]#011Speed: 2137.36 samples/sec#011loss=2.851778\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] Epoch[56] Batch[10] avg_epoch_loss=2.771863\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=2.67596492767334\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] Epoch[56] Batch [10]#011Speed: 2077.14 samples/sec#011loss=2.675965\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747868059.2731285, \"EndTime\": 1747868060.2046514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.1025142669678, \"count\": 1, \"min\": 931.1025142669678, \"max\": 931.1025142669678}}}\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1411.0958002652021 records/second\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.7718630487268623\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] Epoch[57] Batch[0] avg_epoch_loss=2.708515\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.7085154056549072\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] Epoch[57] Batch[5] avg_epoch_loss=2.799202\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.799202005068461\n",
      "[05/21/2025 22:54:20 INFO 140039678244672] Epoch[57] Batch [5]#011Speed: 2113.82 samples/sec#011loss=2.799202\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] Epoch[57] Batch[10] avg_epoch_loss=2.637991\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=2.4445388078689576\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] Epoch[57] Batch [10]#011Speed: 2021.61 samples/sec#011loss=2.444539\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747868060.2047117, \"EndTime\": 1747868061.1694884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 964.5133018493652, \"count\": 1, \"min\": 964.5133018493652, \"max\": 964.5133018493652}}}\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1329.042278446722 records/second\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.6379914608868686\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] Epoch[58] Batch[0] avg_epoch_loss=2.815988\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.8159875869750977\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] Epoch[58] Batch[5] avg_epoch_loss=2.831392\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.83139177163442\n",
      "[05/21/2025 22:54:21 INFO 140039678244672] Epoch[58] Batch [5]#011Speed: 2117.03 samples/sec#011loss=2.831392\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] Epoch[58] Batch[10] avg_epoch_loss=2.757602\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.669053626060486\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] Epoch[58] Batch [10]#011Speed: 2052.13 samples/sec#011loss=2.669054\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] processed a total of 1344 examples\n",
      "#metrics {\"StartTime\": 1747868061.169551, \"EndTime\": 1747868062.1041443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.3376159667969, \"count\": 1, \"min\": 934.3376159667969, \"max\": 934.3376159667969}}}\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1438.3204399815781 records/second\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.7576017054644497\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] Epoch[59] Batch[0] avg_epoch_loss=2.769587\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.769587278366089\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] Epoch[59] Batch[5] avg_epoch_loss=2.749524\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.7495243549346924\n",
      "[05/21/2025 22:54:22 INFO 140039678244672] Epoch[59] Batch [5]#011Speed: 2099.44 samples/sec#011loss=2.749524\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] Epoch[59] Batch[10] avg_epoch_loss=2.668847\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=2.5720332145690916\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] Epoch[59] Batch [10]#011Speed: 2108.80 samples/sec#011loss=2.572033\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] processed a total of 1309 examples\n",
      "#metrics {\"StartTime\": 1747868062.1042023, \"EndTime\": 1747868063.0424862, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 937.9897117614746, \"count\": 1, \"min\": 937.9897117614746, \"max\": 937.9897117614746}}}\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1395.4131996802696 records/second\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.6688465638594194\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] Epoch[60] Batch[0] avg_epoch_loss=2.959544\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.9595444202423096\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] Epoch[60] Batch[5] avg_epoch_loss=2.811174\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.8111735582351685\n",
      "[05/21/2025 22:54:23 INFO 140039678244672] Epoch[60] Batch [5]#011Speed: 2000.38 samples/sec#011loss=2.811174\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] Epoch[60] Batch[10] avg_epoch_loss=2.668546\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.497391963005066\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] Epoch[60] Batch [10]#011Speed: 1858.55 samples/sec#011loss=2.497392\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747868063.0425436, \"EndTime\": 1747868064.0239594, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 981.1632633209229, \"count\": 1, \"min\": 981.1632633209229, \"max\": 981.1632633209229}}}\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1339.1046361323254 records/second\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.6685455604033037\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] Epoch[61] Batch[0] avg_epoch_loss=2.799644\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.7996444702148438\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] Epoch[61] Batch[5] avg_epoch_loss=2.868217\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.8682172695795694\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] Epoch[61] Batch [5]#011Speed: 1821.07 samples/sec#011loss=2.868217\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] processed a total of 1248 examples\n",
      "#metrics {\"StartTime\": 1747868064.0240204, \"EndTime\": 1747868064.9456122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 921.339750289917, \"count\": 1, \"min\": 921.339750289917, \"max\": 921.339750289917}}}\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1354.4142390065733 records/second\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.8896899938583376\n",
      "[05/21/2025 22:54:24 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] Epoch[62] Batch[0] avg_epoch_loss=2.830926\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.8309261798858643\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] Epoch[62] Batch[5] avg_epoch_loss=2.835928\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.8359278440475464\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] Epoch[62] Batch [5]#011Speed: 1852.21 samples/sec#011loss=2.835928\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] Epoch[62] Batch[10] avg_epoch_loss=2.857639\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.883692407608032\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] Epoch[62] Batch [10]#011Speed: 1946.31 samples/sec#011loss=2.883692\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] processed a total of 1333 examples\n",
      "#metrics {\"StartTime\": 1747868064.9456742, \"EndTime\": 1747868065.9416502, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 995.6896305084229, \"count\": 1, \"min\": 995.6896305084229, \"max\": 995.6896305084229}}}\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1338.6061639489956 records/second\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.8576390093023125\n",
      "[05/21/2025 22:54:25 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] Epoch[63] Batch[0] avg_epoch_loss=2.655268\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.6552681922912598\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] Epoch[63] Batch[5] avg_epoch_loss=2.785733\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.785733461380005\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] Epoch[63] Batch [5]#011Speed: 2059.08 samples/sec#011loss=2.785733\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] Epoch[63] Batch[10] avg_epoch_loss=2.854958\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.938027572631836\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] Epoch[63] Batch [10]#011Speed: 2104.24 samples/sec#011loss=2.938028\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] processed a total of 1284 examples\n",
      "#metrics {\"StartTime\": 1747868065.9417436, \"EndTime\": 1747868066.8812675, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.2566680908203, \"count\": 1, \"min\": 939.2566680908203, \"max\": 939.2566680908203}}}\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1366.9097446406622 records/second\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.8549580574035645\n",
      "[05/21/2025 22:54:26 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] Epoch[64] Batch[0] avg_epoch_loss=2.933094\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.933093786239624\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] Epoch[64] Batch[5] avg_epoch_loss=2.911959\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.9119585752487183\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] Epoch[64] Batch [5]#011Speed: 2074.33 samples/sec#011loss=2.911959\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] Epoch[64] Batch[10] avg_epoch_loss=2.944036\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=2.982528638839722\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] Epoch[64] Batch [10]#011Speed: 1998.34 samples/sec#011loss=2.982529\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747868066.8813267, \"EndTime\": 1747868067.8258197, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.2322254180908, \"count\": 1, \"min\": 944.2322254180908, \"max\": 944.2322254180908}}}\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1412.6599911734022 records/second\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.9440358768809927\n",
      "[05/21/2025 22:54:27 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] Epoch[65] Batch[0] avg_epoch_loss=2.745537\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.7455368041992188\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] Epoch[65] Batch[5] avg_epoch_loss=2.786935\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.7869345347086587\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] Epoch[65] Batch [5]#011Speed: 1858.94 samples/sec#011loss=2.786935\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] Epoch[65] Batch[10] avg_epoch_loss=2.799670\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.8149528026580812\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] Epoch[65] Batch [10]#011Speed: 1915.69 samples/sec#011loss=2.814953\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] processed a total of 1321 examples\n",
      "#metrics {\"StartTime\": 1747868067.825878, \"EndTime\": 1747868068.8297899, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1003.6561489105225, \"count\": 1, \"min\": 1003.6561489105225, \"max\": 1003.6561489105225}}}\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1316.0733975375326 records/second\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.799670111049305\n",
      "[05/21/2025 22:54:28 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] Epoch[66] Batch[0] avg_epoch_loss=2.897692\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.8976919651031494\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] Epoch[66] Batch[5] avg_epoch_loss=2.682137\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.682137211163839\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] Epoch[66] Batch [5]#011Speed: 2139.00 samples/sec#011loss=2.682137\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] Epoch[66] Batch[10] avg_epoch_loss=2.671645\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.659054231643677\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] Epoch[66] Batch [10]#011Speed: 1988.05 samples/sec#011loss=2.659054\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] processed a total of 1392 examples\n",
      "#metrics {\"StartTime\": 1747868068.8298488, \"EndTime\": 1747868069.7648025, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 934.6797466278076, \"count\": 1, \"min\": 934.6797466278076, \"max\": 934.6797466278076}}}\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1489.1229008772568 records/second\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.6716449477455835\n",
      "[05/21/2025 22:54:29 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] Epoch[67] Batch[0] avg_epoch_loss=2.698026\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.698026180267334\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] Epoch[67] Batch[5] avg_epoch_loss=2.708687\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.7086872657140098\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] Epoch[67] Batch [5]#011Speed: 2154.38 samples/sec#011loss=2.708687\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] Epoch[67] Batch[10] avg_epoch_loss=2.743172\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.7845537662506104\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] Epoch[67] Batch [10]#011Speed: 2045.97 samples/sec#011loss=2.784554\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747868069.764868, \"EndTime\": 1747868070.6902134, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 925.0130653381348, \"count\": 1, \"min\": 925.0130653381348, \"max\": 925.0130653381348}}}\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1437.6578217146102 records/second\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.743172038685192\n",
      "[05/21/2025 22:54:30 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] Epoch[68] Batch[0] avg_epoch_loss=2.956230\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.9562296867370605\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] Epoch[68] Batch[5] avg_epoch_loss=2.859456\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.8594560623168945\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] Epoch[68] Batch [5]#011Speed: 2015.89 samples/sec#011loss=2.859456\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] processed a total of 1237 examples\n",
      "#metrics {\"StartTime\": 1747868070.6902707, \"EndTime\": 1747868071.5741842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 883.6619853973389, \"count\": 1, \"min\": 883.6619853973389, \"max\": 883.6619853973389}}}\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1399.7073570267366 records/second\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.8462641954422\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] Epoch[69] Batch[0] avg_epoch_loss=2.767323\n",
      "[05/21/2025 22:54:31 INFO 140039678244672] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.7673230171203613\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Epoch[69] Batch[5] avg_epoch_loss=2.702632\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.7026323080062866\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Epoch[69] Batch [5]#011Speed: 2082.18 samples/sec#011loss=2.702632\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Epoch[69] Batch[10] avg_epoch_loss=2.612857\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.5051260948181153\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Epoch[69] Batch [10]#011Speed: 2166.61 samples/sec#011loss=2.505126\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] processed a total of 1282 examples\n",
      "#metrics {\"StartTime\": 1747868071.5742471, \"EndTime\": 1747868072.4969347, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 922.3544597625732, \"count\": 1, \"min\": 922.3544597625732, \"max\": 922.3544597625732}}}\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1389.791133981236 records/second\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.6128567565571177\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_29cac851-26ca-4a74-bd1d-05dd602d928e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868072.4969926, \"EndTime\": 1747868072.5070033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.718894958496094, \"count\": 1, \"min\": 9.718894958496094, \"max\": 9.718894958496094}}}\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] Epoch[70] Batch[0] avg_epoch_loss=2.805671\n",
      "[05/21/2025 22:54:32 INFO 140039678244672] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.805671453475952\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] Epoch[70] Batch[5] avg_epoch_loss=2.789068\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.78906778494517\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] Epoch[70] Batch [5]#011Speed: 1981.75 samples/sec#011loss=2.789068\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] Epoch[70] Batch[10] avg_epoch_loss=2.708494\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.6118055820465087\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] Epoch[70] Batch [10]#011Speed: 1984.50 samples/sec#011loss=2.611806\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] processed a total of 1330 examples\n",
      "#metrics {\"StartTime\": 1747868072.5070555, \"EndTime\": 1747868073.4677398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 960.6325626373291, \"count\": 1, \"min\": 960.6325626373291, \"max\": 960.6325626373291}}}\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1384.3793238399633 records/second\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.7084940563548696\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] Epoch[71] Batch[0] avg_epoch_loss=2.772291\n",
      "[05/21/2025 22:54:33 INFO 140039678244672] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.772291421890259\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] Epoch[71] Batch[5] avg_epoch_loss=2.754039\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.7540394067764282\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] Epoch[71] Batch [5]#011Speed: 2159.21 samples/sec#011loss=2.754039\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] Epoch[71] Batch[10] avg_epoch_loss=2.729872\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.7008718967437746\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] Epoch[71] Batch [10]#011Speed: 2155.54 samples/sec#011loss=2.700872\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] processed a total of 1287 examples\n",
      "#metrics {\"StartTime\": 1747868073.4677982, \"EndTime\": 1747868074.393007, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 924.9234199523926, \"count\": 1, \"min\": 924.9234199523926, \"max\": 924.9234199523926}}}\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1391.2807784061972 records/second\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.7298723567615855\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] Epoch[72] Batch[0] avg_epoch_loss=2.686310\n",
      "[05/21/2025 22:54:34 INFO 140039678244672] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.686309814453125\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[72] Batch[5] avg_epoch_loss=2.826659\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.8266592820485434\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[72] Batch [5]#011Speed: 2159.62 samples/sec#011loss=2.826659\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[72] Batch[10] avg_epoch_loss=2.683611\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.5119534015655516\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[72] Batch [10]#011Speed: 2129.60 samples/sec#011loss=2.511953\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747868074.3931012, \"EndTime\": 1747868075.3485284, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.1308155059814, \"count\": 1, \"min\": 955.1308155059814, \"max\": 955.1308155059814}}}\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1358.849971333946 records/second\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.6836111545562744\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[73] Batch[0] avg_epoch_loss=2.810009\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.8100087642669678\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[73] Batch[5] avg_epoch_loss=2.786824\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.786824027697245\n",
      "[05/21/2025 22:54:35 INFO 140039678244672] Epoch[73] Batch [5]#011Speed: 2126.59 samples/sec#011loss=2.786824\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] processed a total of 1245 examples\n",
      "#metrics {\"StartTime\": 1747868075.348589, \"EndTime\": 1747868076.2372653, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 888.4060382843018, \"count\": 1, \"min\": 888.4060382843018, \"max\": 888.4060382843018}}}\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1401.2316886774631 records/second\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.7368746757507325\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] Epoch[74] Batch[0] avg_epoch_loss=2.705509\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.7055094242095947\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] Epoch[74] Batch[5] avg_epoch_loss=2.703939\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.7039392789204917\n",
      "[05/21/2025 22:54:36 INFO 140039678244672] Epoch[74] Batch [5]#011Speed: 1997.28 samples/sec#011loss=2.703939\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] Epoch[74] Batch[10] avg_epoch_loss=2.616593\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.5117779970169067\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] Epoch[74] Batch [10]#011Speed: 1957.18 samples/sec#011loss=2.511778\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] processed a total of 1312 examples\n",
      "#metrics {\"StartTime\": 1747868076.2373316, \"EndTime\": 1747868077.2255068, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 987.858772277832, \"count\": 1, \"min\": 987.858772277832, \"max\": 987.858772277832}}}\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1328.0176961977356 records/second\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.6165932416915894\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] Epoch[75] Batch[0] avg_epoch_loss=2.742567\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.742567300796509\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] Epoch[75] Batch[5] avg_epoch_loss=2.754796\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.7547960678736367\n",
      "[05/21/2025 22:54:37 INFO 140039678244672] Epoch[75] Batch [5]#011Speed: 2046.06 samples/sec#011loss=2.754796\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] Epoch[75] Batch[10] avg_epoch_loss=2.764327\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=2.775764560699463\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] Epoch[75] Batch [10]#011Speed: 1993.86 samples/sec#011loss=2.775765\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] processed a total of 1335 examples\n",
      "#metrics {\"StartTime\": 1747868077.2255597, \"EndTime\": 1747868078.198915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.1101989746094, \"count\": 1, \"min\": 973.1101989746094, \"max\": 973.1101989746094}}}\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1371.737934508125 records/second\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.764327200976285\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] Epoch[76] Batch[0] avg_epoch_loss=2.830038\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.830037832260132\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] Epoch[76] Batch[5] avg_epoch_loss=2.738950\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.738949775695801\n",
      "[05/21/2025 22:54:38 INFO 140039678244672] Epoch[76] Batch [5]#011Speed: 2025.09 samples/sec#011loss=2.738950\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] Epoch[76] Batch[10] avg_epoch_loss=2.690033\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.631333017349243\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] Epoch[76] Batch [10]#011Speed: 2085.71 samples/sec#011loss=2.631333\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] processed a total of 1326 examples\n",
      "#metrics {\"StartTime\": 1747868078.1989884, \"EndTime\": 1747868079.1607916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.4124298095703, \"count\": 1, \"min\": 961.4124298095703, \"max\": 961.4124298095703}}}\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1379.090819463028 records/second\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.6900330673564565\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] Epoch[77] Batch[0] avg_epoch_loss=2.960603\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.9606025218963623\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] Epoch[77] Batch[5] avg_epoch_loss=2.828712\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.8287116289138794\n",
      "[05/21/2025 22:54:39 INFO 140039678244672] Epoch[77] Batch [5]#011Speed: 1866.49 samples/sec#011loss=2.828712\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] Epoch[77] Batch[10] avg_epoch_loss=2.728350\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.60791494846344\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] Epoch[77] Batch [10]#011Speed: 1833.56 samples/sec#011loss=2.607915\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] processed a total of 1304 examples\n",
      "#metrics {\"StartTime\": 1747868079.160851, \"EndTime\": 1747868080.173708, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1012.5844478607178, \"count\": 1, \"min\": 1012.5844478607178, \"max\": 1012.5844478607178}}}\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1287.6852827994242 records/second\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.7283495014364068\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] Epoch[78] Batch[0] avg_epoch_loss=2.657533\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.6575334072113037\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] Epoch[78] Batch[5] avg_epoch_loss=2.730625\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.7306245962778726\n",
      "[05/21/2025 22:54:40 INFO 140039678244672] Epoch[78] Batch [5]#011Speed: 1866.04 samples/sec#011loss=2.730625\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] Epoch[78] Batch[10] avg_epoch_loss=2.630934\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.511305332183838\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] Epoch[78] Batch [10]#011Speed: 1740.39 samples/sec#011loss=2.511305\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] processed a total of 1300 examples\n",
      "#metrics {\"StartTime\": 1747868080.173766, \"EndTime\": 1747868081.2188659, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1044.7311401367188, \"count\": 1, \"min\": 1044.7311401367188, \"max\": 1044.7311401367188}}}\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1244.2339406488525 records/second\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.6309340216896753\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] Epoch[79] Batch[0] avg_epoch_loss=2.793998\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.7939984798431396\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] Epoch[79] Batch[5] avg_epoch_loss=2.759306\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.7593063910802207\n",
      "[05/21/2025 22:54:41 INFO 140039678244672] Epoch[79] Batch [5]#011Speed: 1810.35 samples/sec#011loss=2.759306\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] Epoch[79] Batch[10] avg_epoch_loss=2.827669\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.9097039222717287\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] Epoch[79] Batch [10]#011Speed: 1817.42 samples/sec#011loss=2.909704\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] processed a total of 1314 examples\n",
      "#metrics {\"StartTime\": 1747868081.2189245, \"EndTime\": 1747868082.2559922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1036.8094444274902, \"count\": 1, \"min\": 1036.8094444274902, \"max\": 1036.8094444274902}}}\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1267.2446596432235 records/second\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.8276689052581787\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] Epoch[80] Batch[0] avg_epoch_loss=2.773407\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.773406744003296\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] Epoch[80] Batch[5] avg_epoch_loss=2.733800\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.7338000535964966\n",
      "[05/21/2025 22:54:42 INFO 140039678244672] Epoch[80] Batch [5]#011Speed: 1844.89 samples/sec#011loss=2.733800\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] Epoch[80] Batch[10] avg_epoch_loss=2.657774\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.5665430068969726\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] Epoch[80] Batch [10]#011Speed: 1720.86 samples/sec#011loss=2.566543\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] processed a total of 1361 examples\n",
      "#metrics {\"StartTime\": 1747868082.2560494, \"EndTime\": 1747868083.2999132, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1043.6105728149414, \"count\": 1, \"min\": 1043.6105728149414, \"max\": 1043.6105728149414}}}\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1304.01846133322 records/second\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.6577741232785312\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] Epoch[81] Batch[0] avg_epoch_loss=2.692976\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.6929757595062256\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] Epoch[81] Batch[5] avg_epoch_loss=2.634967\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.63496732711792\n",
      "[05/21/2025 22:54:43 INFO 140039678244672] Epoch[81] Batch [5]#011Speed: 1983.67 samples/sec#011loss=2.634967\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] Epoch[81] Batch[10] avg_epoch_loss=2.654137\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.677140951156616\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] Epoch[81] Batch [10]#011Speed: 1989.24 samples/sec#011loss=2.677141\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747868083.299972, \"EndTime\": 1747868084.2732759, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 972.9986190795898, \"count\": 1, \"min\": 972.9986190795898, \"max\": 972.9986190795898}}}\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1416.114487745059 records/second\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.6541371562264184\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] Epoch[82] Batch[0] avg_epoch_loss=2.537997\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.5379974842071533\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] Epoch[82] Batch[5] avg_epoch_loss=2.619919\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.619919180870056\n",
      "[05/21/2025 22:54:44 INFO 140039678244672] Epoch[82] Batch [5]#011Speed: 2090.42 samples/sec#011loss=2.619919\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Epoch[82] Batch[10] avg_epoch_loss=2.515828\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=2.3909193754196165\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Epoch[82] Batch [10]#011Speed: 2121.49 samples/sec#011loss=2.390919\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] processed a total of 1289 examples\n",
      "#metrics {\"StartTime\": 1747868084.2733338, \"EndTime\": 1747868085.201013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 927.4308681488037, \"count\": 1, \"min\": 927.4308681488037, \"max\": 927.4308681488037}}}\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1389.737035489017 records/second\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.5158283602107656\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] best epoch loss so far\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/state_9988aea7-4a55-481c-bfb8-bb3000f40940-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868085.2010689, \"EndTime\": 1747868085.2109895, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.57942008972168, \"count\": 1, \"min\": 9.57942008972168, \"max\": 9.57942008972168}}}\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Epoch[83] Batch[0] avg_epoch_loss=2.776438\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.7764382362365723\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Epoch[83] Batch[5] avg_epoch_loss=2.704990\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.7049895524978638\n",
      "[05/21/2025 22:54:45 INFO 140039678244672] Epoch[83] Batch [5]#011Speed: 2028.01 samples/sec#011loss=2.704990\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] processed a total of 1258 examples\n",
      "#metrics {\"StartTime\": 1747868085.2110431, \"EndTime\": 1747868086.106716, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 895.6217765808105, \"count\": 1, \"min\": 895.6217765808105, \"max\": 895.6217765808105}}}\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1404.462723315409 records/second\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.6733351707458497\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] Epoch[84] Batch[0] avg_epoch_loss=2.745158\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.7451584339141846\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] Epoch[84] Batch[5] avg_epoch_loss=2.684010\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.6840099096298218\n",
      "[05/21/2025 22:54:46 INFO 140039678244672] Epoch[84] Batch [5]#011Speed: 2110.88 samples/sec#011loss=2.684010\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] Epoch[84] Batch[10] avg_epoch_loss=2.781234\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.8979032039642334\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] Epoch[84] Batch [10]#011Speed: 2009.59 samples/sec#011loss=2.897903\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747868086.1067805, \"EndTime\": 1747868087.046054, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.9801025390625, \"count\": 1, \"min\": 938.9801025390625, \"max\": 938.9801025390625}}}\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1402.4567228522899 records/second\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.7812341343272817\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] Epoch[85] Batch[0] avg_epoch_loss=2.769842\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.7698419094085693\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] Epoch[85] Batch[5] avg_epoch_loss=2.683764\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.6837642192840576\n",
      "[05/21/2025 22:54:47 INFO 140039678244672] Epoch[85] Batch [5]#011Speed: 2023.01 samples/sec#011loss=2.683764\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[85] Batch[10] avg_epoch_loss=2.694137\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=2.7065850734710692\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[85] Batch [10]#011Speed: 1992.74 samples/sec#011loss=2.706585\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] processed a total of 1347 examples\n",
      "#metrics {\"StartTime\": 1747868087.0461118, \"EndTime\": 1747868088.0009742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 954.620361328125, \"count\": 1, \"min\": 954.620361328125, \"max\": 954.620361328125}}}\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1410.8548889478784 records/second\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.6941373348236084\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[86] Batch[0] avg_epoch_loss=2.655053\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.6550533771514893\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[86] Batch[5] avg_epoch_loss=2.642568\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.642568031946818\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[86] Batch [5]#011Speed: 2066.41 samples/sec#011loss=2.642568\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[86] Batch[10] avg_epoch_loss=2.618320\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.589222621917725\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] Epoch[86] Batch [10]#011Speed: 1900.53 samples/sec#011loss=2.589223\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] processed a total of 1376 examples\n",
      "#metrics {\"StartTime\": 1747868088.001066, \"EndTime\": 1747868088.9602587, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 958.8954448699951, \"count\": 1, \"min\": 958.8954448699951, \"max\": 958.8954448699951}}}\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1434.8374116272958 records/second\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.61832011829723\n",
      "[05/21/2025 22:54:48 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] Epoch[87] Batch[0] avg_epoch_loss=2.766579\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.7665786743164062\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] Epoch[87] Batch[5] avg_epoch_loss=2.666480\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.666479547818502\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] Epoch[87] Batch [5]#011Speed: 2120.71 samples/sec#011loss=2.666480\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] Epoch[87] Batch[10] avg_epoch_loss=2.664140\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.66133337020874\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] Epoch[87] Batch [10]#011Speed: 2054.49 samples/sec#011loss=2.661333\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] processed a total of 1340 examples\n",
      "#metrics {\"StartTime\": 1747868088.960329, \"EndTime\": 1747868089.888624, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 928.009033203125, \"count\": 1, \"min\": 928.009033203125, \"max\": 928.009033203125}}}\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1443.8205206919097 records/second\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.664140376177701\n",
      "[05/21/2025 22:54:49 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] Epoch[88] Batch[0] avg_epoch_loss=2.738768\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.738767623901367\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] Epoch[88] Batch[5] avg_epoch_loss=2.653844\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.653844396273295\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] Epoch[88] Batch [5]#011Speed: 2178.75 samples/sec#011loss=2.653844\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] processed a total of 1230 examples\n",
      "#metrics {\"StartTime\": 1747868089.8886814, \"EndTime\": 1747868090.7526479, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 863.7175559997559, \"count\": 1, \"min\": 863.7175559997559, \"max\": 863.7175559997559}}}\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1423.9213886272184 records/second\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.673880457878113\n",
      "[05/21/2025 22:54:50 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] Epoch[89] Batch[0] avg_epoch_loss=2.685548\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.6855475902557373\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] Epoch[89] Batch[5] avg_epoch_loss=2.621079\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.6210792462031045\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] Epoch[89] Batch [5]#011Speed: 2040.75 samples/sec#011loss=2.621079\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] Epoch[89] Batch[10] avg_epoch_loss=2.532300\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=2.4257658958435058\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] Epoch[89] Batch [10]#011Speed: 1949.75 samples/sec#011loss=2.425766\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] processed a total of 1345 examples\n",
      "#metrics {\"StartTime\": 1747868090.7527115, \"EndTime\": 1747868091.7325234, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 979.5064926147461, \"count\": 1, \"min\": 979.5064926147461, \"max\": 979.5064926147461}}}\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1373.0051137169842 records/second\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.532300450585105\n",
      "[05/21/2025 22:54:51 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] Epoch[90] Batch[0] avg_epoch_loss=2.511914\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.5119142532348633\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] Epoch[90] Batch[5] avg_epoch_loss=2.552367\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.5523672898610434\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] Epoch[90] Batch [5]#011Speed: 1997.47 samples/sec#011loss=2.552367\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] Epoch[90] Batch[10] avg_epoch_loss=2.634405\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.7328495025634765\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] Epoch[90] Batch [10]#011Speed: 1847.70 samples/sec#011loss=2.732850\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] processed a total of 1374 examples\n",
      "#metrics {\"StartTime\": 1747868091.7325926, \"EndTime\": 1747868092.7115884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 978.7130355834961, \"count\": 1, \"min\": 978.7130355834961, \"max\": 978.7130355834961}}}\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1403.755518893788 records/second\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.6344046592712402\n",
      "[05/21/2025 22:54:52 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] Epoch[91] Batch[0] avg_epoch_loss=2.660592\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.6605916023254395\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] Epoch[91] Batch[5] avg_epoch_loss=2.696772\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.696772495905558\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] Epoch[91] Batch [5]#011Speed: 2069.67 samples/sec#011loss=2.696772\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] processed a total of 1240 examples\n",
      "#metrics {\"StartTime\": 1747868092.711648, \"EndTime\": 1747868093.6031268, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 891.0551071166992, \"count\": 1, \"min\": 891.0551071166992, \"max\": 891.0551071166992}}}\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1391.4187828028078 records/second\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.637514042854309\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] Epoch[92] Batch[0] avg_epoch_loss=2.746128\n",
      "[05/21/2025 22:54:53 INFO 140039678244672] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.7461283206939697\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] Epoch[92] Batch[5] avg_epoch_loss=2.701899\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.7018993695576987\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] Epoch[92] Batch [5]#011Speed: 2175.06 samples/sec#011loss=2.701899\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] Epoch[92] Batch[10] avg_epoch_loss=2.686649\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.668349266052246\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] Epoch[92] Batch [10]#011Speed: 1916.04 samples/sec#011loss=2.668349\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747868093.6032138, \"EndTime\": 1747868094.5678968, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 964.3692970275879, \"count\": 1, \"min\": 964.3692970275879, \"max\": 964.3692970275879}}}\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1391.4564892048058 records/second\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.6866493225097656\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] Epoch[93] Batch[0] avg_epoch_loss=2.699401\n",
      "[05/21/2025 22:54:54 INFO 140039678244672] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.6994011402130127\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] Epoch[93] Batch[5] avg_epoch_loss=2.599568\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.599567691485087\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] Epoch[93] Batch [5]#011Speed: 2085.31 samples/sec#011loss=2.599568\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] Epoch[93] Batch[10] avg_epoch_loss=2.594279\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.5879316329956055\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] Epoch[93] Batch [10]#011Speed: 2059.90 samples/sec#011loss=2.587932\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747868094.5679564, \"EndTime\": 1747868095.540287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 972.0666408538818, \"count\": 1, \"min\": 972.0666408538818, \"max\": 972.0666408538818}}}\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1372.2066755756746 records/second\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.594278573989868\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] Epoch[94] Batch[0] avg_epoch_loss=2.523899\n",
      "[05/21/2025 22:54:55 INFO 140039678244672] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.5238993167877197\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] Epoch[94] Batch[5] avg_epoch_loss=2.728736\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.72873584429423\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] Epoch[94] Batch [5]#011Speed: 2044.46 samples/sec#011loss=2.728736\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] processed a total of 1244 examples\n",
      "#metrics {\"StartTime\": 1747868095.540348, \"EndTime\": 1747868096.4461486, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 905.5004119873047, \"count\": 1, \"min\": 905.5004119873047, \"max\": 905.5004119873047}}}\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1373.6805904464734 records/second\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.7114044427871704\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] Epoch[95] Batch[0] avg_epoch_loss=2.640889\n",
      "[05/21/2025 22:54:56 INFO 140039678244672] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.6408886909484863\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] Epoch[95] Batch[5] avg_epoch_loss=2.743198\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.7431979179382324\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] Epoch[95] Batch [5]#011Speed: 2095.43 samples/sec#011loss=2.743198\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] Epoch[95] Batch[10] avg_epoch_loss=2.779997\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.824154996871948\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] Epoch[95] Batch [10]#011Speed: 2021.89 samples/sec#011loss=2.824155\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] processed a total of 1343 examples\n",
      "#metrics {\"StartTime\": 1747868096.446213, \"EndTime\": 1747868097.4061382, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 959.6130847930908, \"count\": 1, \"min\": 959.6130847930908, \"max\": 959.6130847930908}}}\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1399.3864487118972 records/second\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.7799965901808306\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] Epoch[96] Batch[0] avg_epoch_loss=2.770406\n",
      "[05/21/2025 22:54:57 INFO 140039678244672] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.7704055309295654\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] Epoch[96] Batch[5] avg_epoch_loss=2.719531\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.7195308208465576\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] Epoch[96] Batch [5]#011Speed: 1895.15 samples/sec#011loss=2.719531\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] Epoch[96] Batch[10] avg_epoch_loss=2.728376\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.7389899253845216\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] Epoch[96] Batch [10]#011Speed: 1996.90 samples/sec#011loss=2.738990\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] processed a total of 1379 examples\n",
      "#metrics {\"StartTime\": 1747868097.4061992, \"EndTime\": 1747868098.3827183, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 976.207971572876, \"count\": 1, \"min\": 976.207971572876, \"max\": 976.207971572876}}}\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1412.4818806700366 records/second\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.728375868363814\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] Epoch[97] Batch[0] avg_epoch_loss=2.632780\n",
      "[05/21/2025 22:54:58 INFO 140039678244672] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.632780075073242\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[97] Batch[5] avg_epoch_loss=2.638247\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.6382468938827515\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[97] Batch [5]#011Speed: 2001.07 samples/sec#011loss=2.638247\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[97] Batch[10] avg_epoch_loss=2.652910\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.670504856109619\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[97] Batch [10]#011Speed: 2026.65 samples/sec#011loss=2.670505\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] processed a total of 1317 examples\n",
      "#metrics {\"StartTime\": 1747868098.3827782, \"EndTime\": 1747868099.3407185, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 957.1113586425781, \"count\": 1, \"min\": 957.1113586425781, \"max\": 957.1113586425781}}}\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1375.8934176087707 records/second\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.652909603985873\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[98] Batch[0] avg_epoch_loss=2.516323\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.5163233280181885\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[98] Batch[5] avg_epoch_loss=2.633808\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.6338077783584595\n",
      "[05/21/2025 22:54:59 INFO 140039678244672] Epoch[98] Batch [5]#011Speed: 2022.45 samples/sec#011loss=2.633808\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] Epoch[98] Batch[10] avg_epoch_loss=2.712326\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=2.806547927856445\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] Epoch[98] Batch [10]#011Speed: 2074.09 samples/sec#011loss=2.806548\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] processed a total of 1294 examples\n",
      "#metrics {\"StartTime\": 1747868099.3407729, \"EndTime\": 1747868100.28715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 946.0678100585938, \"count\": 1, \"min\": 946.0678100585938, \"max\": 946.0678100585938}}}\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1367.635680800388 records/second\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.712326028130271\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] Epoch[99] Batch[0] avg_epoch_loss=2.733343\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.7333426475524902\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] Epoch[99] Batch[5] avg_epoch_loss=2.710128\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.7101282278696694\n",
      "[05/21/2025 22:55:00 INFO 140039678244672] Epoch[99] Batch [5]#011Speed: 2025.33 samples/sec#011loss=2.710128\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] processed a total of 1251 examples\n",
      "#metrics {\"StartTime\": 1747868100.2872062, \"EndTime\": 1747868101.1849966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.451639175415, \"count\": 1, \"min\": 897.451639175415, \"max\": 897.451639175415}}}\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1393.7970148143622 records/second\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.646059823036194\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] Epoch[100] Batch[0] avg_epoch_loss=2.655790\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.655789852142334\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] Epoch[100] Batch[5] avg_epoch_loss=2.629428\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.6294278701146445\n",
      "[05/21/2025 22:55:01 INFO 140039678244672] Epoch[100] Batch [5]#011Speed: 2006.76 samples/sec#011loss=2.629428\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] Epoch[100] Batch[10] avg_epoch_loss=2.766549\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.9310939788818358\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] Epoch[100] Batch [10]#011Speed: 1799.16 samples/sec#011loss=2.931094\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] processed a total of 1297 examples\n",
      "#metrics {\"StartTime\": 1747868101.185061, \"EndTime\": 1747868102.1789312, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 993.5402870178223, \"count\": 1, \"min\": 993.5402870178223, \"max\": 993.5402870178223}}}\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1305.3205821716647 records/second\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.766548828645186\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] Epoch[101] Batch[0] avg_epoch_loss=3.951824\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=3.951824188232422\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] Epoch[101] Batch[5] avg_epoch_loss=3.365800\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=3.3658004999160767\n",
      "[05/21/2025 22:55:02 INFO 140039678244672] Epoch[101] Batch [5]#011Speed: 2095.29 samples/sec#011loss=3.365800\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] Epoch[101] Batch[10] avg_epoch_loss=3.355721\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=3.3436246871948243\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] Epoch[101] Batch [10]#011Speed: 1943.21 samples/sec#011loss=3.343625\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] processed a total of 1364 examples\n",
      "#metrics {\"StartTime\": 1747868102.1789882, \"EndTime\": 1747868103.1309986, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 951.7612457275391, \"count\": 1, \"min\": 951.7612457275391, \"max\": 951.7612457275391}}}\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1433.0047340752221 records/second\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=101, train loss <loss>=3.3557205850427803\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] Epoch[102] Batch[0] avg_epoch_loss=3.288331\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=3.288330554962158\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] Epoch[102] Batch[5] avg_epoch_loss=3.013932\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=3.0139323075612388\n",
      "[05/21/2025 22:55:03 INFO 140039678244672] Epoch[102] Batch [5]#011Speed: 1996.02 samples/sec#011loss=3.013932\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] Epoch[102] Batch[10] avg_epoch_loss=3.066422\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=3.1294085502624513\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] Epoch[102] Batch [10]#011Speed: 1990.62 samples/sec#011loss=3.129409\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747868103.1310563, \"EndTime\": 1747868104.0968542, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 965.5489921569824, \"count\": 1, \"min\": 965.5489921569824, \"max\": 965.5489921569824}}}\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1342.1196185645358 records/second\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=102, train loss <loss>=3.0664215087890625\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] Epoch[103] Batch[0] avg_epoch_loss=3.001844\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=3.0018436908721924\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] Epoch[103] Batch[5] avg_epoch_loss=2.933886\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.933886090914408\n",
      "[05/21/2025 22:55:04 INFO 140039678244672] Epoch[103] Batch [5]#011Speed: 1995.92 samples/sec#011loss=2.933886\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] Epoch[103] Batch[10] avg_epoch_loss=2.798127\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.6352166652679445\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] Epoch[103] Batch [10]#011Speed: 1984.37 samples/sec#011loss=2.635217\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] processed a total of 1301 examples\n",
      "#metrics {\"StartTime\": 1747868104.0969136, \"EndTime\": 1747868105.0831618, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 985.9631061553955, \"count\": 1, \"min\": 985.9631061553955, \"max\": 985.9631061553955}}}\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1319.3867151467907 records/second\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.7981272610751065\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] Epoch[104] Batch[0] avg_epoch_loss=2.926480\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.926480293273926\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] Epoch[104] Batch[5] avg_epoch_loss=2.855701\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.855700929959615\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] Epoch[104] Batch [5]#011Speed: 1951.87 samples/sec#011loss=2.855701\n",
      "[05/21/2025 22:55:05 INFO 140039678244672] processed a total of 1267 examples\n",
      "#metrics {\"StartTime\": 1747868105.083218, \"EndTime\": 1747868106.0000443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 916.5623188018799, \"count\": 1, \"min\": 916.5623188018799, \"max\": 916.5623188018799}}}\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1382.1942808155757 records/second\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.882403254508972\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] Epoch[105] Batch[0] avg_epoch_loss=2.678195\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.6781952381134033\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] Epoch[105] Batch[5] avg_epoch_loss=2.798267\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.798267443974813\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] Epoch[105] Batch [5]#011Speed: 1927.69 samples/sec#011loss=2.798267\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] Epoch[105] Batch[10] avg_epoch_loss=2.798478\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.79873104095459\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] Epoch[105] Batch [10]#011Speed: 1998.23 samples/sec#011loss=2.798731\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] processed a total of 1354 examples\n",
      "#metrics {\"StartTime\": 1747868106.0001101, \"EndTime\": 1747868106.9737744, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 973.2863903045654, \"count\": 1, \"min\": 973.2863903045654, \"max\": 973.2863903045654}}}\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1391.0389511840795 records/second\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.7984781698747114\n",
      "[05/21/2025 22:55:06 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] Epoch[106] Batch[0] avg_epoch_loss=2.817352\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.817352294921875\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] Epoch[106] Batch[5] avg_epoch_loss=2.793050\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.7930497328440347\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] Epoch[106] Batch [5]#011Speed: 2120.13 samples/sec#011loss=2.793050\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] Epoch[106] Batch[10] avg_epoch_loss=2.784385\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=2.7739876747131347\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] Epoch[106] Batch [10]#011Speed: 1921.12 samples/sec#011loss=2.773988\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] processed a total of 1414 examples\n",
      "#metrics {\"StartTime\": 1747868106.973832, \"EndTime\": 1747868107.9892282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1015.1159763336182, \"count\": 1, \"min\": 1015.1159763336182, \"max\": 1015.1159763336182}}}\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1392.814417315508 records/second\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.675286680459976\n",
      "[05/21/2025 22:55:07 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] Epoch[107] Batch[0] avg_epoch_loss=2.787293\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.7872931957244873\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] Epoch[107] Batch[5] avg_epoch_loss=2.786016\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.786016265551249\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] Epoch[107] Batch [5]#011Speed: 1994.11 samples/sec#011loss=2.786016\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] Epoch[107] Batch[10] avg_epoch_loss=2.751252\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.709535551071167\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] Epoch[107] Batch [10]#011Speed: 1721.41 samples/sec#011loss=2.709536\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] processed a total of 1364 examples\n",
      "#metrics {\"StartTime\": 1747868107.9892924, \"EndTime\": 1747868108.997727, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1008.1026554107666, \"count\": 1, \"min\": 1008.1026554107666, \"max\": 1008.1026554107666}}}\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1352.9216201202796 records/second\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.751252304423939\n",
      "[05/21/2025 22:55:08 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] Epoch[108] Batch[0] avg_epoch_loss=2.717089\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.7170891761779785\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] Epoch[108] Batch[5] avg_epoch_loss=2.764505\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.7645047108332315\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] Epoch[108] Batch [5]#011Speed: 1894.25 samples/sec#011loss=2.764505\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] Epoch[108] Batch[10] avg_epoch_loss=2.727584\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.68327956199646\n",
      "[05/21/2025 22:55:09 INFO 140039678244672] Epoch[108] Batch [10]#011Speed: 1914.41 samples/sec#011loss=2.683280\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] processed a total of 1351 examples\n",
      "#metrics {\"StartTime\": 1747868108.9977841, \"EndTime\": 1747868110.000153, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1002.1054744720459, \"count\": 1, \"min\": 1002.1054744720459, \"max\": 1002.1054744720459}}}\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1348.0489060746247 records/second\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.727584188634699\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] Epoch[109] Batch[0] avg_epoch_loss=2.709381\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.709380865097046\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] Epoch[109] Batch[5] avg_epoch_loss=2.665857\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.665856957435608\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] Epoch[109] Batch [5]#011Speed: 2074.24 samples/sec#011loss=2.665857\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] Epoch[109] Batch[10] avg_epoch_loss=2.683119\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.7038345336914062\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] Epoch[109] Batch [10]#011Speed: 1938.86 samples/sec#011loss=2.703835\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] processed a total of 1378 examples\n",
      "#metrics {\"StartTime\": 1747868110.0002103, \"EndTime\": 1747868110.9562175, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.7368755340576, \"count\": 1, \"min\": 955.7368755340576, \"max\": 955.7368755340576}}}\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1441.6878032694797 records/second\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.6831194920973345\n",
      "[05/21/2025 22:55:10 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] Epoch[110] Batch[0] avg_epoch_loss=2.644939\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.6449389457702637\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] Epoch[110] Batch[5] avg_epoch_loss=2.718509\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.718508799870809\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] Epoch[110] Batch [5]#011Speed: 2032.88 samples/sec#011loss=2.718509\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] Epoch[110] Batch[10] avg_epoch_loss=2.766152\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.8233241558074953\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] Epoch[110] Batch [10]#011Speed: 2054.18 samples/sec#011loss=2.823324\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] processed a total of 1281 examples\n",
      "#metrics {\"StartTime\": 1747868110.956275, \"EndTime\": 1747868111.9071922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 950.5953788757324, \"count\": 1, \"min\": 950.5953788757324, \"max\": 950.5953788757324}}}\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1347.453491329045 records/second\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.7661521434783936\n",
      "[05/21/2025 22:55:11 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] Epoch[111] Batch[0] avg_epoch_loss=3.144874\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=3.144874095916748\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] Epoch[111] Batch[5] avg_epoch_loss=2.871602\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.8716015021006265\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] Epoch[111] Batch [5]#011Speed: 2108.83 samples/sec#011loss=2.871602\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] Epoch[111] Batch[10] avg_epoch_loss=2.871455\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=2.871278190612793\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] Epoch[111] Batch [10]#011Speed: 1817.31 samples/sec#011loss=2.871278\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] processed a total of 1364 examples\n",
      "#metrics {\"StartTime\": 1747868111.9072504, \"EndTime\": 1747868112.8778353, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 970.3290462493896, \"count\": 1, \"min\": 970.3290462493896, \"max\": 970.3290462493896}}}\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1405.5906031083998 records/second\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.8714545423334297\n",
      "[05/21/2025 22:55:12 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] Epoch[112] Batch[0] avg_epoch_loss=2.719615\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.7196147441864014\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] Epoch[112] Batch[5] avg_epoch_loss=2.750521\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.7505205074946084\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] Epoch[112] Batch [5]#011Speed: 2138.24 samples/sec#011loss=2.750521\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] Epoch[112] Batch[10] avg_epoch_loss=2.786705\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.8301273345947267\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] Epoch[112] Batch [10]#011Speed: 2013.03 samples/sec#011loss=2.830127\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] processed a total of 1313 examples\n",
      "#metrics {\"StartTime\": 1747868112.877891, \"EndTime\": 1747868113.8166494, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 938.4865760803223, \"count\": 1, \"min\": 938.4865760803223, \"max\": 938.4865760803223}}}\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1398.9352251608727 records/second\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.786705428903753\n",
      "[05/21/2025 22:55:13 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] Epoch[113] Batch[0] avg_epoch_loss=3.176594\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=3.1765942573547363\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] Epoch[113] Batch[5] avg_epoch_loss=3.020604\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=3.020604411760966\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] Epoch[113] Batch [5]#011Speed: 2122.97 samples/sec#011loss=3.020604\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] Epoch[113] Batch[10] avg_epoch_loss=2.884847\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.7219380378723144\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] Epoch[113] Batch [10]#011Speed: 1997.74 samples/sec#011loss=2.721938\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] processed a total of 1307 examples\n",
      "#metrics {\"StartTime\": 1747868113.8167067, \"EndTime\": 1747868114.7603123, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 943.3615207672119, \"count\": 1, \"min\": 943.3615207672119, \"max\": 943.3615207672119}}}\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1385.3491257344722 records/second\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.884846969084306\n",
      "[05/21/2025 22:55:14 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] Epoch[114] Batch[0] avg_epoch_loss=3.017334\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=3.017334222793579\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] Epoch[114] Batch[5] avg_epoch_loss=3.035681\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=3.0356813271840415\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] Epoch[114] Batch [5]#011Speed: 2160.25 samples/sec#011loss=3.035681\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] processed a total of 1278 examples\n",
      "#metrics {\"StartTime\": 1747868114.7603693, \"EndTime\": 1747868115.6205723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 859.9410057067871, \"count\": 1, \"min\": 859.9410057067871, \"max\": 859.9410057067871}}}\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1485.9877823623797 records/second\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.941991376876831\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] Epoch[115] Batch[0] avg_epoch_loss=2.881479\n",
      "[05/21/2025 22:55:15 INFO 140039678244672] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.8814785480499268\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] Epoch[115] Batch[5] avg_epoch_loss=2.808885\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.8088845014572144\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] Epoch[115] Batch [5]#011Speed: 2026.80 samples/sec#011loss=2.808885\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] Epoch[115] Batch[10] avg_epoch_loss=2.796095\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=2.780747079849243\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] Epoch[115] Batch [10]#011Speed: 1940.88 samples/sec#011loss=2.780747\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] processed a total of 1334 examples\n",
      "#metrics {\"StartTime\": 1747868115.6206362, \"EndTime\": 1747868116.5820916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 961.1544609069824, \"count\": 1, \"min\": 961.1544609069824, \"max\": 961.1544609069824}}}\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1387.7917261324544 records/second\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.796094764362682\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] Epoch[116] Batch[0] avg_epoch_loss=2.803929\n",
      "[05/21/2025 22:55:16 INFO 140039678244672] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.803929328918457\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] Epoch[116] Batch[5] avg_epoch_loss=2.794242\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.7942424615224204\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] Epoch[116] Batch [5]#011Speed: 2100.98 samples/sec#011loss=2.794242\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] Epoch[116] Batch[10] avg_epoch_loss=2.838817\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=2.892307090759277\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] Epoch[116] Batch [10]#011Speed: 1983.86 samples/sec#011loss=2.892307\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] processed a total of 1322 examples\n",
      "#metrics {\"StartTime\": 1747868116.582149, \"EndTime\": 1747868117.5267673, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 944.3464279174805, \"count\": 1, \"min\": 944.3464279174805, \"max\": 944.3464279174805}}}\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1399.7841802752275 records/second\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.8388172929937188\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] Epoch[117] Batch[0] avg_epoch_loss=2.645959\n",
      "[05/21/2025 22:55:17 INFO 140039678244672] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.645958662033081\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] Epoch[117] Batch[5] avg_epoch_loss=2.756181\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.756180683771769\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] Epoch[117] Batch [5]#011Speed: 2122.09 samples/sec#011loss=2.756181\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] Epoch[117] Batch[10] avg_epoch_loss=2.783390\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.8160403251647947\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] Epoch[117] Batch [10]#011Speed: 1982.98 samples/sec#011loss=2.816040\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] processed a total of 1369 examples\n",
      "#metrics {\"StartTime\": 1747868117.5268245, \"EndTime\": 1747868118.4670541, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 939.9833679199219, \"count\": 1, \"min\": 939.9833679199219, \"max\": 939.9833679199219}}}\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1456.2798369230964 records/second\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.78338961167769\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] loss did not improve\n",
      "\n",
      "2025-05-21 22:55:24 Uploading - Uploading generated training model[05/21/2025 22:55:18 INFO 140039678244672] Epoch[118] Batch[0] avg_epoch_loss=2.818308\n",
      "[05/21/2025 22:55:18 INFO 140039678244672] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.8183083534240723\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] Epoch[118] Batch[5] avg_epoch_loss=2.659153\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.659152865409851\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] Epoch[118] Batch [5]#011Speed: 2046.90 samples/sec#011loss=2.659153\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] Epoch[118] Batch[10] avg_epoch_loss=2.641338\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.619959592819214\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] Epoch[118] Batch [10]#011Speed: 2015.52 samples/sec#011loss=2.619960\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] processed a total of 1316 examples\n",
      "#metrics {\"StartTime\": 1747868118.4671097, \"EndTime\": 1747868119.4202003, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 952.7978897094727, \"count\": 1, \"min\": 952.7978897094727, \"max\": 952.7978897094727}}}\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1381.072651568965 records/second\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.641337741505016\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] Epoch[119] Batch[0] avg_epoch_loss=2.735101\n",
      "[05/21/2025 22:55:19 INFO 140039678244672] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.735100746154785\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[119] Batch[5] avg_epoch_loss=2.698972\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.69897198677063\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[119] Batch [5]#011Speed: 2134.16 samples/sec#011loss=2.698972\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[119] Batch[10] avg_epoch_loss=2.553305\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=2.3785037279129027\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[119] Batch [10]#011Speed: 2068.00 samples/sec#011loss=2.378504\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] processed a total of 1298 examples\n",
      "#metrics {\"StartTime\": 1747868119.420257, \"EndTime\": 1747868120.3524597, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 931.6122531890869, \"count\": 1, \"min\": 931.6122531890869, \"max\": 931.6122531890869}}}\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1393.1558803968348 records/second\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.553304596380754\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[120] Batch[0] avg_epoch_loss=2.741342\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.7413418292999268\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[120] Batch[5] avg_epoch_loss=2.689299\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.6892987489700317\n",
      "[05/21/2025 22:55:20 INFO 140039678244672] Epoch[120] Batch [5]#011Speed: 2009.75 samples/sec#011loss=2.689299\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] processed a total of 1273 examples\n",
      "#metrics {\"StartTime\": 1747868120.3525167, \"EndTime\": 1747868121.2500675, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 897.2265720367432, \"count\": 1, \"min\": 897.2265720367432, \"max\": 897.2265720367432}}}\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1418.6760363841775 records/second\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.6485931158065794\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] Epoch[121] Batch[0] avg_epoch_loss=2.723799\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.723799228668213\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] Epoch[121] Batch[5] avg_epoch_loss=2.658221\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.658221483230591\n",
      "[05/21/2025 22:55:21 INFO 140039678244672] Epoch[121] Batch [5]#011Speed: 2091.90 samples/sec#011loss=2.658221\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] Epoch[121] Batch[10] avg_epoch_loss=2.702426\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=2.755470561981201\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] Epoch[121] Batch [10]#011Speed: 1950.74 samples/sec#011loss=2.755471\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] processed a total of 1342 examples\n",
      "#metrics {\"StartTime\": 1747868121.2501256, \"EndTime\": 1747868122.2060935, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 955.0905227661133, \"count\": 1, \"min\": 955.0905227661133, \"max\": 955.0905227661133}}}\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1404.955113369742 records/second\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.7024256099354136\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] Epoch[122] Batch[0] avg_epoch_loss=2.863546\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.863546371459961\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] Epoch[122] Batch[5] avg_epoch_loss=2.821329\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.8213289976119995\n",
      "[05/21/2025 22:55:22 INFO 140039678244672] Epoch[122] Batch [5]#011Speed: 2100.40 samples/sec#011loss=2.821329\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Epoch[122] Batch[10] avg_epoch_loss=2.989230\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=3.190711736679077\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Epoch[122] Batch [10]#011Speed: 2068.36 samples/sec#011loss=3.190712\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] processed a total of 1296 examples\n",
      "#metrics {\"StartTime\": 1747868122.206159, \"EndTime\": 1747868123.1417396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 935.2045059204102, \"count\": 1, \"min\": 935.2045059204102, \"max\": 935.2045059204102}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #throughput_metric: host=algo-1, train throughput=1385.66527262781 records/second\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.9892302426424893\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] loss did not improve\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Loading parameters from best epoch (82)\n",
      "#metrics {\"StartTime\": 1747868123.141797, \"EndTime\": 1747868123.1470907, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 4.97126579284668, \"count\": 1, \"min\": 4.97126579284668, \"max\": 4.97126579284668}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] stopping training now\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Final loss: 2.5158283602107656 (occurred at epoch 82)\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #quality_metric: host=algo-1, train final_loss <loss>=2.5158283602107656\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Worker algo-1 finished training.\n",
      "[05/21/2025 22:55:23 WARNING 140039678244672] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747868123.1471436, \"EndTime\": 1747868123.1964884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 48.979759216308594, \"count\": 1, \"min\": 48.979759216308594, \"max\": 48.979759216308594}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747868123.1965415, \"EndTime\": 1747868123.221122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 73.63533973693848, \"count\": 1, \"min\": 73.63533973693848, \"max\": 73.63533973693848}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747868123.2211618, \"EndTime\": 1747868123.2257152, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 4.5146942138671875, \"count\": 1, \"min\": 4.5146942138671875, \"max\": 4.5146942138671875}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Successfully serialized the model for prediction.\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #memory_usage::<batchbuffer> = 2.080078125 mb\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] Evaluating model accuracy on testset using 100 samples\n",
      "#metrics {\"StartTime\": 1747868123.2257519, \"EndTime\": 1747868123.2273743, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}}}\n",
      "#metrics {\"StartTime\": 1747868123.2274091, \"EndTime\": 1747868123.4119763, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 184.62276458740234, \"count\": 1, \"min\": 184.62276458740234, \"max\": 184.62276458740234}}}\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, RMSE): 39.07367798834659\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, mean_absolute_QuantileLoss): 1628.8888888888887\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, mean_wQuantileLoss): 0.583831142970928\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.1]): 0.22086021505376346\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.2]): 0.3720430107526882\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.3]): 0.49899641577060944\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.4]): 0.6005734767025089\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.5]): 0.6835125448028674\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.6]): 0.7416487455197132\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.7]): 0.7602150537634409\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.8]): 0.7449462365591398\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #test_score (algo-1, wQuantileLoss[0.9]): 0.63168458781362\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #quality_metric: host=algo-1, test RMSE <loss>=39.07367798834659\n",
      "[05/21/2025 22:55:23 INFO 140039678244672] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.583831142970928\n",
      "#metrics {\"StartTime\": 1747868123.4120512, \"EndTime\": 1747868123.422676, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 4.419565200805664, \"count\": 1, \"min\": 4.419565200805664, \"max\": 4.419565200805664}, \"totaltime\": {\"sum\": 117487.07842826843, \"count\": 1, \"min\": 117487.07842826843, \"max\": 117487.07842826843}}}\n",
      "\n",
      "2025-05-21 22:55:38 Completed - Training job completed\n",
      "Training seconds: 271\n",
      "Billable seconds: 271\n",
      "CPU times: total: 9.92 s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "ddb84337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-21 22:55:38 Starting - Preparing the instances for training\n",
      "2025-05-21 22:55:38 Downloading - Downloading the training image\n",
      "2025-05-21 22:55:38 Training - Training image download completed. Training in progress.\n",
      "2025-05-21 22:55:38 Uploading - Uploading generated training model\n",
      "2025-05-21 22:55:38 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-21-22-50-26-760',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ce6db267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 17:57:50] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-57-50-381 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 17:57:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-57-50-381 \u001b]8;id=222346;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=403041;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 17:57:51] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-57-50-381                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 17:57:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=238830;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=813013;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-57-50-381                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-21-22-57-50-381                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=503750;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=857256;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-21-22-57-50-381                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "c6c75c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_list = convertir_a_series(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "4410c5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0.1   0.5   0.9\n",
       "2024-11-01   4.0   9.0  17.0\n",
       "2024-12-01  12.0  26.0  40.0\n",
       "2025-01-01   8.0  16.0  24.0\n",
       "2025-02-01   8.0  14.0  19.0\n",
       "2025-03-01   2.0   5.0  16.0\n",
       "2025-04-01   3.0   8.0  18.0"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=2\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "bd0d8d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    30\n",
       "2024-12-01    36\n",
       "2025-01-01     6\n",
       "2025-02-01    11\n",
       "2025-03-01     4\n",
       "2025-04-01    18\n",
       "Freq: MS, Name: cantidad, dtype: int32"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[i].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e8268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "ea59b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"likelihood\": \"student-T\",\n",
    "    \"learning_rate\": \"0.001\",\n",
    "}\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "4d7f6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    #\"likelihood\": CategoricalParameter([\"gaussian\", \"negative-binomial\", \"student-T\"]),\n",
    "    \"mini_batch_size\": IntegerParameter(32,512),\n",
    "    \"num_cells\": IntegerParameter(30, 200),  # Rango amplio\n",
    "    #\"learning_rate\": ContinuousParameter(0.0001, 0.1),\n",
    "    #\"num_layers\": IntegerParameter(1, 4),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "e5e74383",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"test:RMSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "9e9fe4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=10,\n",
    "    strategy=\"Bayesian\",\n",
    "    objective_type=\"Minimize\",\n",
    "    max_parallel_jobs=2,\n",
    "    early_stopping_type=\"Auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "1d3d50b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 18:18:47] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating hyperparameter tuning job with name:                          <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#3383\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3383</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250521</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1818</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 18:18:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating hyperparameter tuning job with name:                          \u001b]8;id=517022;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=312894;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#3383\u001b\\\u001b[2m3383\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         forecasting-deepar-\u001b[1;36m250521\u001b[0m-\u001b[1;36m1818\u001b[0m                                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\"train\": \"{}/train/\".format(s3_data_path) , \"test\": \"{}/test/\".format(s3_data_path)}, include_cls_metadata=False)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "dea29667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-22 00:37:35 Starting - Found matching resource for reuse\n",
      "2025-05-22 00:37:35 Downloading - Downloading the training image\n",
      "2025-05-22 00:37:35 Training - Training image download completed. Training in progress.\n",
      "2025-05-22 00:37:35 Uploading - Uploading generated training model\n",
      "2025-05-22 00:37:35 Completed - Resource released due to keep alive period expiry\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('forecasting-deepar-250521-1818-009-87cebbdc',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ccf324ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 21:58:37] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-02-58-36-412   <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 21:58:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: forecasting-deepar-\u001b[1;36m2025\u001b[0m-05-22-02-58-36-412   \u001b]8;id=476931;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=454284;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 21:58:38] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-02-58-36-412                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 21:58:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=808770;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=504010;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         forecasting-deepar-\u001b[1;36m2025\u001b[0m-05-22-02-58-36-412                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name forecasting-deepar-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-02-58-36-412 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name forecasting-deepar-\u001b[1;36m2025\u001b[0m-05-22-02-58-36-412 \u001b]8;id=479013;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=82651;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "f8f09a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>Tipo_Producto</th>\n",
       "      <th>segmento_producto</th>\n",
       "      <th>supergrupo_producto</th>\n",
       "      <th>grupo_producto</th>\n",
       "      <th>subgrupo_producto</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>20000337001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               material  Tipo_Producto  segmento_producto  \\\n",
       "2024-11-01  20000337001              0                  0   \n",
       "2024-12-01  20000337001              0                  0   \n",
       "2025-01-01  20000337001              0                  0   \n",
       "2025-02-01  20000337001              0                  0   \n",
       "2025-03-01  20000337001              0                  0   \n",
       "2025-04-01  20000337001              0                  0   \n",
       "\n",
       "            supergrupo_producto  grupo_producto  subgrupo_producto  cantidad  \\\n",
       "2024-11-01                    0               0                  0        33   \n",
       "2024-12-01                    0               0                  0        44   \n",
       "2025-01-01                    0               0                  0        17   \n",
       "2025-02-01                    0               0                  0        10   \n",
       "2025-03-01                    0               0                  0        14   \n",
       "2025-04-01                    0               0                  0         4   \n",
       "\n",
       "            month  quarter  \n",
       "2024-11-01     11        4  \n",
       "2024-12-01     12        4  \n",
       "2025-01-01      1        1  \n",
       "2025-02-01      2        1  \n",
       "2025-03-01      3        1  \n",
       "2025-04-01      4        2  "
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[0].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "7946e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "materiales = [df['material'].unique()[0] for df in timeseries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "6dae477c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000337001"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "materiales[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "8a685d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>10.772312</td>\n",
       "      <td>13.156721</td>\n",
       "      <td>15.081972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>17.859997</td>\n",
       "      <td>20.791840</td>\n",
       "      <td>23.978069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>7.654194</td>\n",
       "      <td>13.237596</td>\n",
       "      <td>17.679573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>-2.515227</td>\n",
       "      <td>14.570486</td>\n",
       "      <td>43.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>-14.742406</td>\n",
       "      <td>2.468850</td>\n",
       "      <td>19.240965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>-15.199956</td>\n",
       "      <td>-0.681237</td>\n",
       "      <td>19.299246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01  10.772312  13.156721  15.081972\n",
       "2024-12-01  17.859997  20.791840  23.978069\n",
       "2025-01-01   7.654194  13.237596  17.679573\n",
       "2025-02-01  -2.515227  14.570486  43.232300\n",
       "2025-03-01 -14.742406   2.468850  19.240965\n",
       "2025-04-01 -15.199956  -0.681237  19.299246"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=0\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "b6991007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    33\n",
       "2024-12-01    44\n",
       "2025-01-01    17\n",
       "2025-02-01    10\n",
       "2025-03-01    14\n",
       "2025-04-01     4\n",
       "Freq: MS, Name: cantidad, dtype: int32"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[i].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "e87945f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_predicciones_por_material(materiales, timeseries_list, vectores_cat, dynamic_list, predictor, horizon_pred=6):\n",
    "    \"\"\"\n",
    "    Genera predicciones para cada material y las devuelve en un diccionario.\n",
    "    \n",
    "    Args:\n",
    "        materiales: Lista con los nombres de materiales\n",
    "        timeseries_list: Lista de series temporales\n",
    "        vectores_cat: Lista de vectores categóricos\n",
    "        dynamic_list: Lista de features dinámicas\n",
    "        predictor: Modelo predictor entrenado\n",
    "        horizon_pred: Horizonte de predicción (default: 6)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con materiales como keys y dataframes de predicciones como values\n",
    "    \"\"\"\n",
    "    predicciones_dict = {}\n",
    "    \n",
    "    for i in range(len(materiales)):\n",
    "        material = materiales[i]\n",
    "        \n",
    "        # Generar predicción para el índice i\n",
    "        prediccion = predictor.predict(\n",
    "            ts = timeseries_list[i][:-horizon_pred], \n",
    "            cat=vectores_cat[i],\n",
    "            dynamic_feat=dynamic_list[i],\n",
    "            quantiles=[0.1, 0.5, 0.9],\n",
    "        )\n",
    "        \n",
    "        # Guardar en el diccionario\n",
    "        predicciones_dict[material] = prediccion\n",
    "        \n",
    "    return predicciones_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "bb403277",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_por_material = generar_predicciones_por_material(\n",
    "    materiales=materiales,\n",
    "    timeseries_list=timeseries_list,\n",
    "    vectores_cat=vectores_cat,\n",
    "    dynamic_list=dynamic_list,\n",
    "    predictor=predictor,\n",
    "    horizon_pred=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "ae35c96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([20000337001, 20000400003, 20000815002, 20000815003, 20000837001, 20000837002, 20001016001, 20001374001, 20003147001, 20003257001, 20003257002, 20003257004, 20008046001, 25109225001, 25109232001])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_por_material.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "4cf5c956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>11.174452</td>\n",
       "      <td>13.033033</td>\n",
       "      <td>15.327240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>17.000874</td>\n",
       "      <td>20.702934</td>\n",
       "      <td>24.452698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>7.063230</td>\n",
       "      <td>12.199194</td>\n",
       "      <td>17.474936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>-5.257400</td>\n",
       "      <td>16.376047</td>\n",
       "      <td>34.438889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>-14.730208</td>\n",
       "      <td>1.734847</td>\n",
       "      <td>24.478224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>-19.101561</td>\n",
       "      <td>1.368773</td>\n",
       "      <td>17.366959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01  11.174452  13.033033  15.327240\n",
       "2024-12-01  17.000874  20.702934  24.452698\n",
       "2025-01-01   7.063230  12.199194  17.474936\n",
       "2025-02-01  -5.257400  16.376047  34.438889\n",
       "2025-03-01 -14.730208   1.734847  24.478224\n",
       "2025-04-01 -19.101561   1.368773  17.366959"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_por_material[20000337001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "994789f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado: mensual_modificado_test.xlsx\n",
      "Orden de columnas: ['Material', 'Fecha', '0.1', '0.5', '0.9']\n",
      "Formato de fecha: YYYY-MM-DD\n"
     ]
    }
   ],
   "source": [
    "def exportar_predicciones_consolidado(predicciones_dict, nombre_archivo=\"mensual_modificado_test.xlsx\"):\n",
    "    \"\"\"\n",
    "    Exporta todas las predicciones con Material y Fecha como primeras dos columnas.\n",
    "    \"\"\"\n",
    "    \n",
    "    dfs_list = []\n",
    "    \n",
    "    for material, prediccion in predicciones_dict.items():\n",
    "        try:\n",
    "            # Convertir a DataFrame\n",
    "            if hasattr(prediccion, 'to_dataframe'):\n",
    "                df_pred = prediccion.to_dataframe()\n",
    "            elif hasattr(prediccion, 'to_pandas'):\n",
    "                df_pred = prediccion.to_pandas()\n",
    "            else:\n",
    "                df_pred = prediccion\n",
    "            \n",
    "            # Resetear índice y renombrar a 'Fecha'\n",
    "            df_pred = df_pred.reset_index()\n",
    "            date_col = df_pred.columns[0]\n",
    "            df_pred = df_pred.rename(columns={date_col: 'Fecha'})\n",
    "            \n",
    "            # Formatear fechas\n",
    "            df_pred['Fecha'] = pd.to_datetime(df_pred['Fecha']).dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Agregar columna de material\n",
    "            df_pred['Material'] = material\n",
    "            \n",
    "            dfs_list.append(df_pred)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {material}: {e}\")\n",
    "    \n",
    "    # Concatenar todos los DataFrames\n",
    "    if dfs_list:\n",
    "        df_final = pd.concat(dfs_list, ignore_index=True)\n",
    "        \n",
    "        # Reorganizar columnas: Material, Fecha, luego el resto en orden\n",
    "        other_cols = [col for col in df_final.columns if col not in ['Material', 'Fecha']]\n",
    "        cols = ['Material', 'Fecha'] + other_cols\n",
    "        df_final = df_final[cols]\n",
    "        \n",
    "        # Exportar\n",
    "        df_final.to_excel(nombre_archivo, index=False)\n",
    "        print(f\"Archivo guardado: {nombre_archivo}\")\n",
    "        print(f\"Orden de columnas: {list(df_final.columns)}\")\n",
    "        print(\"Formato de fecha: YYYY-MM-DD\")\n",
    "    else:\n",
    "        print(\"Error: No se pudieron procesar las predicciones\")\n",
    "\n",
    "# Ejecutar\n",
    "exportar_predicciones_consolidado(predicciones_por_material, \"mensual_modificado_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000caab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### ENTRENAMIENTO CON TODA LA DATA CON HYPERPARÁMETROS OPTIMIZADOS #####################\n",
    "#DATA TEST (COMPLETA) --> PARA TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "8504224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.2xlarge\",\n",
    "   # use_spot_instances=True,\n",
    "   # max_run=1800,  # max training time in seconds\n",
    "   # max_wait=1800,  # seconds to wait for spot instance\n",
    "    base_job_name=\"lilipink-forecasting\",\n",
    "    output_path=s3_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "318d25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq= \"M\"\n",
    "context_length = 18\n",
    "prediction_length = 6\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"learning_rate\": \"1E-3\",\n",
    "    \"likelihood\":\"student-T\",\n",
    "    \"mini_batch_size\": \"449\",\n",
    "    \"num_cells\": \"56\",  # Rango amplio\n",
    "    #\"learning_rate\": \"0.001\",\n",
    "    \"num_layers\": \"2\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "e3b6549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "888e4f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 22:48:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 22:48:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=842486;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=413242;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 22:48:30] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-03-48-30-015                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 22:48:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=168109;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=613742;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-03-48-30-015                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-22 03:48:32 Starting - Starting the training job...\n",
      "2025-05-22 03:49:08 Downloading - Downloading input data...\n",
      "2025-05-22 03:49:23 Downloading - Downloading the training image.........\n",
      "2025-05-22 03:51:19 Training - Training image download completed. Training in progress....Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Running custom environment configuration script\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '18', 'early_stopping_patience': '40', 'epochs': '400', 'learning_rate': '1E-3', 'likelihood': 'student-T', 'mini_batch_size': '449', 'num_cells': '56', 'num_layers': '2', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '1E-3', 'likelihood': 'student-T', 'mini_batch_size': '449', 'num_cells': '56', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '18', 'epochs': '400', 'prediction_length': '6', 'time_freq': 'M'}\n",
      "Process 7 is a worker.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Detected entry point for worker worker\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Using early stopping with patience 40\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] random_seed is None\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/test.json` and will be used for training.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/test.json` and will be used for training.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] [cardinality=auto] Inferred value of cardinality=[2, 4, 5, 6, 6] from dataset.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Training set statistics:\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Integer time series\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] number of time series: 15\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] number of observations: 672\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] mean target length: 44.8\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] min/mean/max target: 1.0/30.99702380952381/388.0\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] mean abs(target): 30.99702380952381\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] contains missing values: no\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Small number of time series. Doing 300 passes over dataset with prob 0.9977777777777778 per epoch.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] No test channel found not running evaluations\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] #memory_usage::<batchbuffer> = 2.1889572143554688 mb\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] nvidia-smi: took 0.106 seconds to run.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] nvidia-smi identified 0 GPUs.\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Number of GPUs being used: 0\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Create Store: local\n",
      "#metrics {\"StartTime\": 1747885899.4719648, \"EndTime\": 1747885899.520339, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 47.48106002807617, \"count\": 1, \"min\": 47.48106002807617, \"max\": 47.48106002807617}}}\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] Number of GPUs being used: 0\n",
      "[05/22/2025 03:51:39 INFO 140041726678848] #memory_usage::<model> = 102 mb\n",
      "#metrics {\"StartTime\": 1747885899.5204067, \"EndTime\": 1747885899.597773, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 125.68855285644531, \"count\": 1, \"min\": 125.68855285644531, \"max\": 125.68855285644531}}}\n",
      "[03:51:40] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 100576 bytes with malloc directly\n",
      "[05/22/2025 03:51:40 INFO 140041726678848] Epoch[0] Batch[0] avg_epoch_loss=3.674480\n",
      "[05/22/2025 03:51:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.674479801033547\n",
      "[05/22/2025 03:51:41 INFO 140041726678848] Epoch[0] Batch[5] avg_epoch_loss=3.655242\n",
      "[05/22/2025 03:51:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.655241855091755\n",
      "[05/22/2025 03:51:41 INFO 140041726678848] Epoch[0] Batch [5]#011Speed: 2217.95 samples/sec#011loss=3.655242\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] Epoch[0] Batch[10] avg_epoch_loss=3.592270\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.5167035143200165\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] Epoch[0] Batch [10]#011Speed: 1977.04 samples/sec#011loss=3.516704\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] processed a total of 4614 examples\n",
      "#metrics {\"StartTime\": 1747885899.5978258, \"EndTime\": 1747885902.2660196, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 2668.1220531463623, \"count\": 1, \"min\": 2668.1220531463623, \"max\": 2668.1220531463623}}}\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1729.241452002058 records/second\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] #progress_metric: host=algo-1, completed 0.25 % of epochs\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.5922698820136922\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_5a5c4cca-daec-4fee-8b9c-e84ba25542b5-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885902.2660825, \"EndTime\": 1747885902.2770402, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.645151138305664, \"count\": 1, \"min\": 10.645151138305664, \"max\": 10.645151138305664}}}\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] Epoch[1] Batch[0] avg_epoch_loss=3.650374\n",
      "[05/22/2025 03:51:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.6503737689657574\n",
      "[05/22/2025 03:51:43 INFO 140041726678848] Epoch[1] Batch[5] avg_epoch_loss=3.553188\n",
      "[05/22/2025 03:51:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.5531879020073545\n",
      "[05/22/2025 03:51:43 INFO 140041726678848] Epoch[1] Batch [5]#011Speed: 1786.02 samples/sec#011loss=3.553188\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] Epoch[1] Batch[10] avg_epoch_loss=3.484337\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.4017167055261694\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] Epoch[1] Batch [10]#011Speed: 1990.47 samples/sec#011loss=3.401717\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] processed a total of 4666 examples\n",
      "#metrics {\"StartTime\": 1747885902.2770839, \"EndTime\": 1747885905.0903966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2813.264846801758, \"count\": 1, \"min\": 2813.264846801758, \"max\": 2813.264846801758}}}\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1658.5208620373176 records/second\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] #progress_metric: host=algo-1, completed 0.5 % of epochs\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.48433735815227\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_b5d4b7d1-798d-45a5-8a32-32c76a8e16a9-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885905.090455, \"EndTime\": 1747885905.1021864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.363506317138672, \"count\": 1, \"min\": 11.363506317138672, \"max\": 11.363506317138672}}}\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] Epoch[2] Batch[0] avg_epoch_loss=3.532750\n",
      "[05/22/2025 03:51:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.532750458919126\n",
      "[05/22/2025 03:51:46 INFO 140041726678848] Epoch[2] Batch[5] avg_epoch_loss=3.463854\n",
      "[05/22/2025 03:51:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.4638541376670378\n",
      "[05/22/2025 03:51:46 INFO 140041726678848] Epoch[2] Batch [5]#011Speed: 2257.32 samples/sec#011loss=3.463854\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] Epoch[2] Batch[10] avg_epoch_loss=3.383008\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.285991602432489\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] Epoch[2] Batch [10]#011Speed: 2044.67 samples/sec#011loss=3.285992\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] processed a total of 4589 examples\n",
      "#metrics {\"StartTime\": 1747885905.102238, \"EndTime\": 1747885907.6247246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.4356651306152, \"count\": 1, \"min\": 2522.4356651306152, \"max\": 2522.4356651306152}}}\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1819.2140339031173 records/second\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] #progress_metric: host=algo-1, completed 0.75 % of epochs\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.3830075307422427\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:51:47 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_7277c9da-459d-4cd9-9389-d324ad214921-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885907.624779, \"EndTime\": 1747885907.6346512, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.490251541137695, \"count\": 1, \"min\": 9.490251541137695, \"max\": 9.490251541137695}}}\n",
      "[05/22/2025 03:51:48 INFO 140041726678848] Epoch[3] Batch[0] avg_epoch_loss=3.366224\n",
      "[05/22/2025 03:51:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.366224259204482\n",
      "[05/22/2025 03:51:49 INFO 140041726678848] Epoch[3] Batch[5] avg_epoch_loss=3.442951\n",
      "[05/22/2025 03:51:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.442950706793453\n",
      "[05/22/2025 03:51:49 INFO 140041726678848] Epoch[3] Batch [5]#011Speed: 2291.17 samples/sec#011loss=3.442951\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] Epoch[3] Batch[10] avg_epoch_loss=3.433691\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=3.4225801259743873\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] Epoch[3] Batch [10]#011Speed: 2006.64 samples/sec#011loss=3.422580\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] processed a total of 4562 examples\n",
      "#metrics {\"StartTime\": 1747885907.6347108, \"EndTime\": 1747885910.1574924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.728681564331, \"count\": 1, \"min\": 2522.728681564331, \"max\": 2522.728681564331}}}\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1808.2968014707237 records/second\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] #progress_metric: host=algo-1, completed 1.0 % of epochs\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.433691351875696\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] Epoch[4] Batch[0] avg_epoch_loss=3.413021\n",
      "[05/22/2025 03:51:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.4130206883351892\n",
      "[05/22/2025 03:51:51 INFO 140041726678848] Epoch[4] Batch[5] avg_epoch_loss=3.426347\n",
      "[05/22/2025 03:51:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.4263467427616927\n",
      "[05/22/2025 03:51:51 INFO 140041726678848] Epoch[4] Batch [5]#011Speed: 2274.81 samples/sec#011loss=3.426347\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] Epoch[4] Batch[10] avg_epoch_loss=3.329502\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.213288264285217\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] Epoch[4] Batch [10]#011Speed: 2000.97 samples/sec#011loss=3.213288\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] processed a total of 4733 examples\n",
      "#metrics {\"StartTime\": 1747885910.1575532, \"EndTime\": 1747885912.6887782, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2530.925750732422, \"count\": 1, \"min\": 2530.925750732422, \"max\": 2530.925750732422}}}\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1870.0025915999456 records/second\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] #progress_metric: host=algo-1, completed 1.25 % of epochs\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.3295019798178402\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:51:52 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_c588414d-c887-485a-acd1-3cfd61b77d26-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885912.6888385, \"EndTime\": 1747885912.6991992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.085582733154297, \"count\": 1, \"min\": 10.085582733154297, \"max\": 10.085582733154297}}}\n",
      "[05/22/2025 03:51:53 INFO 140041726678848] Epoch[5] Batch[0] avg_epoch_loss=3.472590\n",
      "[05/22/2025 03:51:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.472589913349109\n",
      "[05/22/2025 03:51:54 INFO 140041726678848] Epoch[5] Batch[5] avg_epoch_loss=3.436483\n",
      "[05/22/2025 03:51:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.4364830192673534\n",
      "[05/22/2025 03:51:54 INFO 140041726678848] Epoch[5] Batch [5]#011Speed: 2294.40 samples/sec#011loss=3.436483\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] Epoch[5] Batch[10] avg_epoch_loss=3.385087\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.32341254219446\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] Epoch[5] Batch [10]#011Speed: 2027.05 samples/sec#011loss=3.323413\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] processed a total of 4711 examples\n",
      "#metrics {\"StartTime\": 1747885912.6992507, \"EndTime\": 1747885915.2127838, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2513.4832859039307, \"count\": 1, \"min\": 2513.4832859039307, \"max\": 2513.4832859039307}}}\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1874.1953571770373 records/second\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] #progress_metric: host=algo-1, completed 1.5 % of epochs\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.3850873478705834\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] Epoch[6] Batch[0] avg_epoch_loss=3.393776\n",
      "[05/22/2025 03:51:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.3937759909173164\n",
      "[05/22/2025 03:51:56 INFO 140041726678848] Epoch[6] Batch[5] avg_epoch_loss=3.388423\n",
      "[05/22/2025 03:51:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.3884229313114793\n",
      "[05/22/2025 03:51:56 INFO 140041726678848] Epoch[6] Batch [5]#011Speed: 2293.32 samples/sec#011loss=3.388423\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] Epoch[6] Batch[10] avg_epoch_loss=3.404573\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.4239522071617485\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] Epoch[6] Batch [10]#011Speed: 2013.73 samples/sec#011loss=3.423952\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] processed a total of 4653 examples\n",
      "#metrics {\"StartTime\": 1747885915.2128837, \"EndTime\": 1747885917.758852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2545.6950664520264, \"count\": 1, \"min\": 2545.6950664520264, \"max\": 2545.6950664520264}}}\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1827.7308090618887 records/second\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] #progress_metric: host=algo-1, completed 1.75 % of epochs\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.4045726021525105\n",
      "[05/22/2025 03:51:57 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:51:58 INFO 140041726678848] Epoch[7] Batch[0] avg_epoch_loss=3.318570\n",
      "[05/22/2025 03:51:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.3185698035565143\n",
      "[05/22/2025 03:51:59 INFO 140041726678848] Epoch[7] Batch[5] avg_epoch_loss=3.369144\n",
      "[05/22/2025 03:51:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.3691442499536004\n",
      "[05/22/2025 03:51:59 INFO 140041726678848] Epoch[7] Batch [5]#011Speed: 2306.82 samples/sec#011loss=3.369144\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] Epoch[7] Batch[10] avg_epoch_loss=3.282125\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.1777028922779786\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] Epoch[7] Batch [10]#011Speed: 2015.70 samples/sec#011loss=3.177703\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] processed a total of 4676 examples\n",
      "#metrics {\"StartTime\": 1747885917.7589107, \"EndTime\": 1747885920.264536, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2505.356550216675, \"count\": 1, \"min\": 2505.356550216675, \"max\": 2505.356550216675}}}\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1866.3393819180415 records/second\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] #progress_metric: host=algo-1, completed 2.0 % of epochs\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.282125451010136\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_cf1f2cd9-d599-4a11-91f0-0dd52a663962-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885920.2645917, \"EndTime\": 1747885920.2753098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.443687438964844, \"count\": 1, \"min\": 10.443687438964844, \"max\": 10.443687438964844}}}\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] Epoch[8] Batch[0] avg_epoch_loss=3.324413\n",
      "[05/22/2025 03:52:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.3244125943937917\n",
      "[05/22/2025 03:52:01 INFO 140041726678848] Epoch[8] Batch[5] avg_epoch_loss=3.299807\n",
      "[05/22/2025 03:52:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.2998072702794405\n",
      "[05/22/2025 03:52:01 INFO 140041726678848] Epoch[8] Batch [5]#011Speed: 2200.58 samples/sec#011loss=3.299807\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] Epoch[8] Batch[10] avg_epoch_loss=3.348431\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.406779605721047\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] Epoch[8] Batch [10]#011Speed: 2025.23 samples/sec#011loss=3.406780\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] processed a total of 4660 examples\n",
      "#metrics {\"StartTime\": 1747885920.2753785, \"EndTime\": 1747885922.8368292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2561.398983001709, \"count\": 1, \"min\": 2561.398983001709, \"max\": 2561.398983001709}}}\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1819.2561356923943 records/second\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 2.25 % of epochs\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.348431059116534\n",
      "[05/22/2025 03:52:02 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:03 INFO 140041726678848] Epoch[9] Batch[0] avg_epoch_loss=3.329106\n",
      "[05/22/2025 03:52:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.3291059124443207\n",
      "[05/22/2025 03:52:04 INFO 140041726678848] Epoch[9] Batch[5] avg_epoch_loss=3.315991\n",
      "[05/22/2025 03:52:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.315990558445852\n",
      "[05/22/2025 03:52:04 INFO 140041726678848] Epoch[9] Batch [5]#011Speed: 2248.52 samples/sec#011loss=3.315991\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] Epoch[9] Batch[10] avg_epoch_loss=3.397756\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.495875165297884\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] Epoch[9] Batch [10]#011Speed: 2008.75 samples/sec#011loss=3.495875\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] processed a total of 4600 examples\n",
      "#metrics {\"StartTime\": 1747885922.8368883, \"EndTime\": 1747885925.3739715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2536.8082523345947, \"count\": 1, \"min\": 2536.8082523345947, \"max\": 2536.8082523345947}}}\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1813.2393228372239 records/second\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] #progress_metric: host=algo-1, completed 2.5 % of epochs\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.3977562888331394\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] Epoch[10] Batch[0] avg_epoch_loss=3.196760\n",
      "[05/22/2025 03:52:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.196760215844237\n",
      "[05/22/2025 03:52:06 INFO 140041726678848] Epoch[10] Batch[5] avg_epoch_loss=3.326190\n",
      "[05/22/2025 03:52:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.326189909144163\n",
      "[05/22/2025 03:52:06 INFO 140041726678848] Epoch[10] Batch [5]#011Speed: 2209.69 samples/sec#011loss=3.326190\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] Epoch[10] Batch[10] avg_epoch_loss=3.291234\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.2492865003827953\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] Epoch[10] Batch [10]#011Speed: 1964.42 samples/sec#011loss=3.249287\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] processed a total of 4582 examples\n",
      "#metrics {\"StartTime\": 1747885925.374032, \"EndTime\": 1747885927.994217, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2619.926691055298, \"count\": 1, \"min\": 2619.926691055298, \"max\": 2619.926691055298}}}\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1748.8469218710459 records/second\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 2.75 % of epochs\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.291233814252632\n",
      "[05/22/2025 03:52:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:08 INFO 140041726678848] Epoch[11] Batch[0] avg_epoch_loss=3.175697\n",
      "[05/22/2025 03:52:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.175696697957266\n",
      "[05/22/2025 03:52:09 INFO 140041726678848] Epoch[11] Batch[5] avg_epoch_loss=3.268217\n",
      "[05/22/2025 03:52:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.2682174308793845\n",
      "[05/22/2025 03:52:09 INFO 140041726678848] Epoch[11] Batch [5]#011Speed: 2223.79 samples/sec#011loss=3.268217\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] Epoch[11] Batch[10] avg_epoch_loss=3.400359\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=3.558929565701559\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] Epoch[11] Batch [10]#011Speed: 2061.41 samples/sec#011loss=3.558930\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] processed a total of 4626 examples\n",
      "#metrics {\"StartTime\": 1747885927.9942756, \"EndTime\": 1747885930.527696, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2533.1645011901855, \"count\": 1, \"min\": 2533.1645011901855, \"max\": 2533.1645011901855}}}\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1826.1188208958245 records/second\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 3.0 % of epochs\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.4003593103440095\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] Epoch[12] Batch[0] avg_epoch_loss=3.298322\n",
      "[05/22/2025 03:52:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.298322172101197\n",
      "[05/22/2025 03:52:11 INFO 140041726678848] Epoch[12] Batch[5] avg_epoch_loss=3.281908\n",
      "[05/22/2025 03:52:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.281907883766588\n",
      "[05/22/2025 03:52:11 INFO 140041726678848] Epoch[12] Batch [5]#011Speed: 2273.86 samples/sec#011loss=3.281908\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] Epoch[12] Batch[10] avg_epoch_loss=3.246372\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=3.203728989768931\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] Epoch[12] Batch [10]#011Speed: 1979.71 samples/sec#011loss=3.203729\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] processed a total of 4642 examples\n",
      "#metrics {\"StartTime\": 1747885930.527748, \"EndTime\": 1747885933.083429, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2555.4513931274414, \"count\": 1, \"min\": 2555.4513931274414, \"max\": 2555.4513931274414}}}\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1816.4451010736734 records/second\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] #progress_metric: host=algo-1, completed 3.25 % of epochs\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.2463720228585617\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_ca4ad5c7-bfa2-4ac6-a978-1441251f7d69-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885933.0834901, \"EndTime\": 1747885933.0938268, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.057687759399414, \"count\": 1, \"min\": 10.057687759399414, \"max\": 10.057687759399414}}}\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] Epoch[13] Batch[0] avg_epoch_loss=3.147404\n",
      "[05/22/2025 03:52:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.147403844480791\n",
      "[05/22/2025 03:52:14 INFO 140041726678848] Epoch[13] Batch[5] avg_epoch_loss=3.229156\n",
      "[05/22/2025 03:52:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.229155565246265\n",
      "[05/22/2025 03:52:14 INFO 140041726678848] Epoch[13] Batch [5]#011Speed: 2251.94 samples/sec#011loss=3.229156\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] Epoch[13] Batch[10] avg_epoch_loss=3.315482\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.419074125226197\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] Epoch[13] Batch [10]#011Speed: 2047.55 samples/sec#011loss=3.419074\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] processed a total of 4545 examples\n",
      "#metrics {\"StartTime\": 1747885933.0938761, \"EndTime\": 1747885935.6113665, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2517.4381732940674, \"count\": 1, \"min\": 2517.4381732940674, \"max\": 2517.4381732940674}}}\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1805.3420005909493 records/second\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 3.5 % of epochs\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.315482183418961\n",
      "[05/22/2025 03:52:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:16 INFO 140041726678848] Epoch[14] Batch[0] avg_epoch_loss=3.228868\n",
      "[05/22/2025 03:52:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.228867698618458\n",
      "[05/22/2025 03:52:17 INFO 140041726678848] Epoch[14] Batch[5] avg_epoch_loss=3.275035\n",
      "[05/22/2025 03:52:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.2750349717398617\n",
      "[05/22/2025 03:52:17 INFO 140041726678848] Epoch[14] Batch [5]#011Speed: 2239.24 samples/sec#011loss=3.275035\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] Epoch[14] Batch[10] avg_epoch_loss=3.324063\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=3.382897650160078\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] Epoch[14] Batch [10]#011Speed: 2023.80 samples/sec#011loss=3.382898\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] processed a total of 4617 examples\n",
      "#metrics {\"StartTime\": 1747885935.6114283, \"EndTime\": 1747885938.1513963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2539.705753326416, \"count\": 1, \"min\": 2539.705753326416, \"max\": 2539.705753326416}}}\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1817.862284770083 records/second\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] #progress_metric: host=algo-1, completed 3.75 % of epochs\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.3240634619308693\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] Epoch[15] Batch[0] avg_epoch_loss=3.262094\n",
      "[05/22/2025 03:52:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.2620942045691814\n",
      "[05/22/2025 03:52:19 INFO 140041726678848] Epoch[15] Batch[5] avg_epoch_loss=3.274038\n",
      "[05/22/2025 03:52:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=3.274038109499698\n",
      "[05/22/2025 03:52:19 INFO 140041726678848] Epoch[15] Batch [5]#011Speed: 2227.93 samples/sec#011loss=3.274038\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] Epoch[15] Batch[10] avg_epoch_loss=3.192752\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=3.095208101336303\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] Epoch[15] Batch [10]#011Speed: 2023.95 samples/sec#011loss=3.095208\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] processed a total of 4648 examples\n",
      "#metrics {\"StartTime\": 1747885938.1514587, \"EndTime\": 1747885940.695989, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2544.2426204681396, \"count\": 1, \"min\": 2544.2426204681396, \"max\": 2544.2426204681396}}}\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1826.8071422219512 records/second\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 4.0 % of epochs\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=15, train loss <loss>=3.1927517421527005\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:20 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_5dc35adb-fe9a-4cf7-a9bc-3c44fef5dc1f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885940.6960487, \"EndTime\": 1747885940.7071753, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.849237442016602, \"count\": 1, \"min\": 10.849237442016602, \"max\": 10.849237442016602}}}\n",
      "[05/22/2025 03:52:21 INFO 140041726678848] Epoch[16] Batch[0] avg_epoch_loss=3.339991\n",
      "[05/22/2025 03:52:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.339990832492344\n",
      "[05/22/2025 03:52:22 INFO 140041726678848] Epoch[16] Batch[5] avg_epoch_loss=3.257571\n",
      "[05/22/2025 03:52:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=3.2575712593378805\n",
      "[05/22/2025 03:52:22 INFO 140041726678848] Epoch[16] Batch [5]#011Speed: 2277.57 samples/sec#011loss=3.257571\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] Epoch[16] Batch[10] avg_epoch_loss=3.268604\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=3.281844148019905\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] Epoch[16] Batch [10]#011Speed: 1936.48 samples/sec#011loss=3.281844\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] processed a total of 4550 examples\n",
      "#metrics {\"StartTime\": 1747885940.7072263, \"EndTime\": 1747885943.2799032, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2572.624683380127, \"count\": 1, \"min\": 2572.624683380127, \"max\": 2572.624683380127}}}\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1768.5614459363205 records/second\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 4.25 % of epochs\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.2686043905569826\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] Epoch[17] Batch[0] avg_epoch_loss=3.266548\n",
      "[05/22/2025 03:52:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.266548003810551\n",
      "[05/22/2025 03:52:24 INFO 140041726678848] Epoch[17] Batch[5] avg_epoch_loss=3.209086\n",
      "[05/22/2025 03:52:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.2090861908842565\n",
      "[05/22/2025 03:52:24 INFO 140041726678848] Epoch[17] Batch [5]#011Speed: 2285.73 samples/sec#011loss=3.209086\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] Epoch[17] Batch[10] avg_epoch_loss=3.201363\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.1920962599178733\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] Epoch[17] Batch [10]#011Speed: 1998.48 samples/sec#011loss=3.192096\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] processed a total of 4697 examples\n",
      "#metrics {\"StartTime\": 1747885943.279964, \"EndTime\": 1747885945.8080451, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2527.827739715576, \"count\": 1, \"min\": 2527.827739715576, \"max\": 2527.827739715576}}}\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1858.053154988714 records/second\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 4.5 % of epochs\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.201363494990446\n",
      "[05/22/2025 03:52:25 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:26 INFO 140041726678848] Epoch[18] Batch[0] avg_epoch_loss=3.191032\n",
      "[05/22/2025 03:52:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.191032154788419\n",
      "[05/22/2025 03:52:27 INFO 140041726678848] Epoch[18] Batch[5] avg_epoch_loss=3.190338\n",
      "[05/22/2025 03:52:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.190338066797745\n",
      "[05/22/2025 03:52:27 INFO 140041726678848] Epoch[18] Batch [5]#011Speed: 2211.23 samples/sec#011loss=3.190338\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] Epoch[18] Batch[10] avg_epoch_loss=3.224782\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.2661152387249444\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] Epoch[18] Batch [10]#011Speed: 2041.62 samples/sec#011loss=3.266115\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] processed a total of 4579 examples\n",
      "#metrics {\"StartTime\": 1747885945.808105, \"EndTime\": 1747885948.349201, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2540.8434867858887, \"count\": 1, \"min\": 2540.8434867858887, \"max\": 2540.8434867858887}}}\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1802.0945378825425 records/second\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 4.75 % of epochs\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.224782235855563\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] Epoch[19] Batch[0] avg_epoch_loss=3.207947\n",
      "[05/22/2025 03:52:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.20794718515103\n",
      "[05/22/2025 03:52:29 INFO 140041726678848] Epoch[19] Batch[5] avg_epoch_loss=3.198905\n",
      "[05/22/2025 03:52:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=3.1989050555777885\n",
      "[05/22/2025 03:52:29 INFO 140041726678848] Epoch[19] Batch [5]#011Speed: 2283.07 samples/sec#011loss=3.198905\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] Epoch[19] Batch[10] avg_epoch_loss=3.169087\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=3.133305729311665\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] Epoch[19] Batch [10]#011Speed: 2061.26 samples/sec#011loss=3.133306\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] processed a total of 4548 examples\n",
      "#metrics {\"StartTime\": 1747885948.3492622, \"EndTime\": 1747885950.852879, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2503.3621788024902, \"count\": 1, \"min\": 2503.3621788024902, \"max\": 2503.3621788024902}}}\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1816.6655151537718 records/second\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 5.0 % of epochs\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=19, train loss <loss>=3.1690871800022777\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:30 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_f7a44def-3042-4797-b10b-25cb04e4f8c2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885950.852978, \"EndTime\": 1747885950.86375, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.483503341674805, \"count\": 1, \"min\": 10.483503341674805, \"max\": 10.483503341674805}}}\n",
      "[05/22/2025 03:52:31 INFO 140041726678848] Epoch[20] Batch[0] avg_epoch_loss=3.197749\n",
      "[05/22/2025 03:52:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.1977490125626393\n",
      "[05/22/2025 03:52:32 INFO 140041726678848] Epoch[20] Batch[5] avg_epoch_loss=3.152172\n",
      "[05/22/2025 03:52:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=3.1521717006397316\n",
      "[05/22/2025 03:52:32 INFO 140041726678848] Epoch[20] Batch [5]#011Speed: 2208.46 samples/sec#011loss=3.152172\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] Epoch[20] Batch[10] avg_epoch_loss=3.136058\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=3.1167204791028675\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] Epoch[20] Batch [10]#011Speed: 1986.83 samples/sec#011loss=3.116720\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] processed a total of 4703 examples\n",
      "#metrics {\"StartTime\": 1747885950.8638005, \"EndTime\": 1747885953.4342048, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2570.354223251343, \"count\": 1, \"min\": 2570.354223251343, \"max\": 2570.354223251343}}}\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1829.647634291074 records/second\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 5.25 % of epochs\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.1360575090320664\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_a914f27a-a483-4cea-a2a2-2ea57cad1280-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885953.4342637, \"EndTime\": 1747885953.4447055, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.167598724365234, \"count\": 1, \"min\": 10.167598724365234, \"max\": 10.167598724365234}}}\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] Epoch[21] Batch[0] avg_epoch_loss=3.104306\n",
      "[05/22/2025 03:52:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.1043059555087695\n",
      "[05/22/2025 03:52:34 INFO 140041726678848] Epoch[21] Batch[5] avg_epoch_loss=3.129884\n",
      "[05/22/2025 03:52:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.1298836281145603\n",
      "[05/22/2025 03:52:34 INFO 140041726678848] Epoch[21] Batch [5]#011Speed: 2194.13 samples/sec#011loss=3.129884\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] Epoch[21] Batch[10] avg_epoch_loss=3.182809\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=3.246319620858853\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] Epoch[21] Batch [10]#011Speed: 1950.34 samples/sec#011loss=3.246320\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] processed a total of 4632 examples\n",
      "#metrics {\"StartTime\": 1747885953.4447608, \"EndTime\": 1747885956.0586467, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2613.8336658477783, \"count\": 1, \"min\": 2613.8336658477783, \"max\": 2613.8336658477783}}}\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1772.051351867557 records/second\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 5.5 % of epochs\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=21, train loss <loss>=3.182809079361966\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] Epoch[22] Batch[0] avg_epoch_loss=3.193355\n",
      "[05/22/2025 03:52:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=3.1933550250556793\n",
      "[05/22/2025 03:52:37 INFO 140041726678848] Epoch[22] Batch[5] avg_epoch_loss=3.136931\n",
      "[05/22/2025 03:52:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=3.1369308097856345\n",
      "[05/22/2025 03:52:37 INFO 140041726678848] Epoch[22] Batch [5]#011Speed: 2264.19 samples/sec#011loss=3.136931\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] Epoch[22] Batch[10] avg_epoch_loss=3.150773\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=3.167384389354816\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] Epoch[22] Batch [10]#011Speed: 1977.88 samples/sec#011loss=3.167384\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] processed a total of 4659 examples\n",
      "#metrics {\"StartTime\": 1747885956.058705, \"EndTime\": 1747885958.6235404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2564.5241737365723, \"count\": 1, \"min\": 2564.5241737365723, \"max\": 2564.5241737365723}}}\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1816.6484551211768 records/second\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 5.75 % of epochs\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=22, train loss <loss>=3.1507733459534446\n",
      "[05/22/2025 03:52:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:39 INFO 140041726678848] Epoch[23] Batch[0] avg_epoch_loss=3.130802\n",
      "[05/22/2025 03:52:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=3.130802281980791\n",
      "[05/22/2025 03:52:40 INFO 140041726678848] Epoch[23] Batch[5] avg_epoch_loss=3.124068\n",
      "[05/22/2025 03:52:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=3.1240676619339274\n",
      "[05/22/2025 03:52:40 INFO 140041726678848] Epoch[23] Batch [5]#011Speed: 2204.35 samples/sec#011loss=3.124068\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] Epoch[23] Batch[10] avg_epoch_loss=3.069765\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=3.00460218671701\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] Epoch[23] Batch [10]#011Speed: 2027.86 samples/sec#011loss=3.004602\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] processed a total of 4571 examples\n",
      "#metrics {\"StartTime\": 1747885958.6236012, \"EndTime\": 1747885961.1842616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2560.4023933410645, \"count\": 1, \"min\": 2560.4023933410645, \"max\": 2560.4023933410645}}}\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1785.2050839733863 records/second\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 6.0 % of epochs\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=23, train loss <loss>=3.069765173198965\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_5c3e08b1-aacb-45f0-965a-03aae38e8428-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885961.184322, \"EndTime\": 1747885961.195462, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.859966278076172, \"count\": 1, \"min\": 10.859966278076172, \"max\": 10.859966278076172}}}\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] Epoch[24] Batch[0] avg_epoch_loss=3.027233\n",
      "[05/22/2025 03:52:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=3.0272325545483016\n",
      "[05/22/2025 03:52:42 INFO 140041726678848] Epoch[24] Batch[5] avg_epoch_loss=3.104290\n",
      "[05/22/2025 03:52:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=3.104289960401007\n",
      "[05/22/2025 03:52:42 INFO 140041726678848] Epoch[24] Batch [5]#011Speed: 2271.75 samples/sec#011loss=3.104290\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] Epoch[24] Batch[10] avg_epoch_loss=2.960121\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.7871180205143373\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] Epoch[24] Batch [10]#011Speed: 1970.47 samples/sec#011loss=2.787118\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] processed a total of 4588 examples\n",
      "#metrics {\"StartTime\": 1747885961.1955144, \"EndTime\": 1747885963.7644222, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2568.854570388794, \"count\": 1, \"min\": 2568.854570388794, \"max\": 2568.854570388794}}}\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1785.9501809665744 records/second\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] #progress_metric: host=algo-1, completed 6.25 % of epochs\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.960120896816157\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:52:43 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_54c9ef4e-99fb-4849-9af7-9e5b955f7094-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885963.7644815, \"EndTime\": 1747885963.7753017, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.550260543823242, \"count\": 1, \"min\": 10.550260543823242, \"max\": 10.550260543823242}}}\n",
      "[05/22/2025 03:52:44 INFO 140041726678848] Epoch[25] Batch[0] avg_epoch_loss=3.090392\n",
      "[05/22/2025 03:52:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=3.0903915711128898\n",
      "[05/22/2025 03:52:45 INFO 140041726678848] Epoch[25] Batch[5] avg_epoch_loss=3.087562\n",
      "[05/22/2025 03:52:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=3.087561932332266\n",
      "[05/22/2025 03:52:45 INFO 140041726678848] Epoch[25] Batch [5]#011Speed: 2197.74 samples/sec#011loss=3.087562\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] Epoch[25] Batch[10] avg_epoch_loss=3.204268\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=3.3443148946443486\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] Epoch[25] Batch [10]#011Speed: 1987.88 samples/sec#011loss=3.344315\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] processed a total of 4575 examples\n",
      "#metrics {\"StartTime\": 1747885963.7753763, \"EndTime\": 1747885966.3844414, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2609.0140342712402, \"count\": 1, \"min\": 2609.0140342712402, \"max\": 2609.0140342712402}}}\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1753.4786220972799 records/second\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 6.5 % of epochs\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=25, train loss <loss>=3.2042678242923035\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] Epoch[26] Batch[0] avg_epoch_loss=3.023362\n",
      "[05/22/2025 03:52:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=3.0233621915889475\n",
      "[05/22/2025 03:52:47 INFO 140041726678848] Epoch[26] Batch[5] avg_epoch_loss=3.064099\n",
      "[05/22/2025 03:52:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=3.064098831097462\n",
      "[05/22/2025 03:52:47 INFO 140041726678848] Epoch[26] Batch [5]#011Speed: 2228.66 samples/sec#011loss=3.064099\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] Epoch[26] Batch[10] avg_epoch_loss=3.073204\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=3.08412977188892\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] Epoch[26] Batch [10]#011Speed: 1914.86 samples/sec#011loss=3.084130\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] processed a total of 4663 examples\n",
      "#metrics {\"StartTime\": 1747885966.3844988, \"EndTime\": 1747885968.993293, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2608.5407733917236, \"count\": 1, \"min\": 2608.5407733917236, \"max\": 2608.5407733917236}}}\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1787.5290127399799 records/second\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] #progress_metric: host=algo-1, completed 6.75 % of epochs\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=26, train loss <loss>=3.0732038041844882\n",
      "[05/22/2025 03:52:48 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:49 INFO 140041726678848] Epoch[27] Batch[0] avg_epoch_loss=3.081393\n",
      "[05/22/2025 03:52:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=3.0813928956709353\n",
      "[05/22/2025 03:52:50 INFO 140041726678848] Epoch[27] Batch[5] avg_epoch_loss=3.083502\n",
      "[05/22/2025 03:52:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=3.083502074923441\n",
      "[05/22/2025 03:52:50 INFO 140041726678848] Epoch[27] Batch [5]#011Speed: 2214.18 samples/sec#011loss=3.083502\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] processed a total of 4487 examples\n",
      "#metrics {\"StartTime\": 1747885968.9933524, \"EndTime\": 1747885971.4261658, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2432.528257369995, \"count\": 1, \"min\": 2432.528257369995, \"max\": 2432.528257369995}}}\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1844.5123823978724 records/second\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 7.0 % of epochs\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=27, train loss <loss>=3.059638661000139\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] Epoch[28] Batch[0] avg_epoch_loss=3.102289\n",
      "[05/22/2025 03:52:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=3.102288940701559\n",
      "[05/22/2025 03:52:52 INFO 140041726678848] Epoch[28] Batch[5] avg_epoch_loss=3.038419\n",
      "[05/22/2025 03:52:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=3.0384192972954946\n",
      "[05/22/2025 03:52:52 INFO 140041726678848] Epoch[28] Batch [5]#011Speed: 2242.82 samples/sec#011loss=3.038419\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] Epoch[28] Batch[10] avg_epoch_loss=3.069780\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=3.107413120737055\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] Epoch[28] Batch [10]#011Speed: 2031.01 samples/sec#011loss=3.107413\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] processed a total of 4619 examples\n",
      "#metrics {\"StartTime\": 1747885971.4262288, \"EndTime\": 1747885973.9661572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2539.6368503570557, \"count\": 1, \"min\": 2539.6368503570557, \"max\": 2539.6368503570557}}}\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1818.7040407947159 records/second\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] #progress_metric: host=algo-1, completed 7.25 % of epochs\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=28, train loss <loss>=3.0697801261325672\n",
      "[05/22/2025 03:52:53 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:54 INFO 140041726678848] Epoch[29] Batch[0] avg_epoch_loss=3.076329\n",
      "[05/22/2025 03:52:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=3.076329288610106\n",
      "[05/22/2025 03:52:55 INFO 140041726678848] Epoch[29] Batch[5] avg_epoch_loss=3.081015\n",
      "[05/22/2025 03:52:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=3.0810145411388734\n",
      "[05/22/2025 03:52:55 INFO 140041726678848] Epoch[29] Batch [5]#011Speed: 2256.90 samples/sec#011loss=3.081015\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] Epoch[29] Batch[10] avg_epoch_loss=3.045516\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=3.002916746415646\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] Epoch[29] Batch [10]#011Speed: 2056.75 samples/sec#011loss=3.002917\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] processed a total of 4499 examples\n",
      "#metrics {\"StartTime\": 1747885973.9662151, \"EndTime\": 1747885976.4885888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.115707397461, \"count\": 1, \"min\": 2522.115707397461, \"max\": 2522.115707397461}}}\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1783.7581098803787 records/second\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 7.5 % of epochs\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=29, train loss <loss>=3.045515543537406\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] Epoch[30] Batch[0] avg_epoch_loss=3.056129\n",
      "[05/22/2025 03:52:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=3.056129234670796\n",
      "[05/22/2025 03:52:57 INFO 140041726678848] Epoch[30] Batch[5] avg_epoch_loss=3.041557\n",
      "[05/22/2025 03:52:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=3.041557329003689\n",
      "[05/22/2025 03:52:57 INFO 140041726678848] Epoch[30] Batch [5]#011Speed: 2252.79 samples/sec#011loss=3.041557\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] Epoch[30] Batch[10] avg_epoch_loss=3.009194\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=2.9703570869292872\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] Epoch[30] Batch [10]#011Speed: 2050.49 samples/sec#011loss=2.970357\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] processed a total of 4573 examples\n",
      "#metrics {\"StartTime\": 1747885976.4886484, \"EndTime\": 1747885979.0051377, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2516.242027282715, \"count\": 1, \"min\": 2516.242027282715, \"max\": 2516.242027282715}}}\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1817.331613581993 records/second\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 7.75 % of epochs\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=30, train loss <loss>=3.0091935826062337\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] Epoch[31] Batch[0] avg_epoch_loss=3.036905\n",
      "[05/22/2025 03:52:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=3.0369049276169267\n",
      "[05/22/2025 03:53:00 INFO 140041726678848] Epoch[31] Batch[5] avg_epoch_loss=3.082184\n",
      "[05/22/2025 03:53:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=3.082183543363145\n",
      "[05/22/2025 03:53:00 INFO 140041726678848] Epoch[31] Batch [5]#011Speed: 2243.00 samples/sec#011loss=3.082184\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] processed a total of 4375 examples\n",
      "#metrics {\"StartTime\": 1747885979.0051963, \"EndTime\": 1747885981.3997245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2394.2604064941406, \"count\": 1, \"min\": 2394.2604064941406, \"max\": 2394.2604064941406}}}\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1827.2134727678667 records/second\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] #progress_metric: host=algo-1, completed 8.0 % of epochs\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=31, train loss <loss>=3.039898831169961\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] Epoch[32] Batch[0] avg_epoch_loss=3.008687\n",
      "[05/22/2025 03:53:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=3.0086873825515035\n",
      "[05/22/2025 03:53:02 INFO 140041726678848] Epoch[32] Batch[5] avg_epoch_loss=3.009034\n",
      "[05/22/2025 03:53:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=3.00903361093228\n",
      "[05/22/2025 03:53:02 INFO 140041726678848] Epoch[32] Batch [5]#011Speed: 2201.88 samples/sec#011loss=3.009034\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] Epoch[32] Batch[10] avg_epoch_loss=3.048549\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=3.0959673297431793\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] Epoch[32] Batch [10]#011Speed: 1974.44 samples/sec#011loss=3.095967\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] processed a total of 4654 examples\n",
      "#metrics {\"StartTime\": 1747885981.399789, \"EndTime\": 1747885984.0165718, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2616.455554962158, \"count\": 1, \"min\": 2616.455554962158, \"max\": 2616.455554962158}}}\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1778.682265380543 records/second\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 8.25 % of epochs\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=32, train loss <loss>=3.048548937664507\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] Epoch[33] Batch[0] avg_epoch_loss=2.882610\n",
      "[05/22/2025 03:53:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.882610227589087\n",
      "[05/22/2025 03:53:05 INFO 140041726678848] Epoch[33] Batch[5] avg_epoch_loss=2.980484\n",
      "[05/22/2025 03:53:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.9804843373004823\n",
      "[05/22/2025 03:53:05 INFO 140041726678848] Epoch[33] Batch [5]#011Speed: 2261.18 samples/sec#011loss=2.980484\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] Epoch[33] Batch[10] avg_epoch_loss=3.022661\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=3.073273561473413\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] Epoch[33] Batch [10]#011Speed: 1977.53 samples/sec#011loss=3.073274\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] processed a total of 4688 examples\n",
      "#metrics {\"StartTime\": 1747885984.0166316, \"EndTime\": 1747885986.5761867, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2559.3008995056152, \"count\": 1, \"min\": 2559.3008995056152, \"max\": 2559.3008995056152}}}\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1831.6887966534405 records/second\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] #progress_metric: host=algo-1, completed 8.5 % of epochs\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=33, train loss <loss>=3.022661257379087\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] Epoch[34] Batch[0] avg_epoch_loss=3.013511\n",
      "[05/22/2025 03:53:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=3.0135114708031736\n",
      "[05/22/2025 03:53:07 INFO 140041726678848] Epoch[34] Batch[5] avg_epoch_loss=3.034111\n",
      "[05/22/2025 03:53:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=3.0341113118127088\n",
      "[05/22/2025 03:53:07 INFO 140041726678848] Epoch[34] Batch [5]#011Speed: 2236.76 samples/sec#011loss=3.034111\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] Epoch[34] Batch[10] avg_epoch_loss=3.062200\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=3.0959070286400334\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] Epoch[34] Batch [10]#011Speed: 1947.87 samples/sec#011loss=3.095907\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] processed a total of 4744 examples\n",
      "#metrics {\"StartTime\": 1747885986.5762463, \"EndTime\": 1747885989.1512783, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2574.7807025909424, \"count\": 1, \"min\": 2574.7807025909424, \"max\": 2574.7807025909424}}}\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1842.4116042298715 records/second\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] #progress_metric: host=algo-1, completed 8.75 % of epochs\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=34, train loss <loss>=3.062200274006947\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] Epoch[35] Batch[0] avg_epoch_loss=2.996250\n",
      "[05/22/2025 03:53:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.9962503479955456\n",
      "[05/22/2025 03:53:10 INFO 140041726678848] Epoch[35] Batch[5] avg_epoch_loss=2.985260\n",
      "[05/22/2025 03:53:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.985259760550065\n",
      "[05/22/2025 03:53:10 INFO 140041726678848] Epoch[35] Batch [5]#011Speed: 2234.92 samples/sec#011loss=2.985260\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] Epoch[35] Batch[10] avg_epoch_loss=3.026529\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=3.0760530671457404\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] Epoch[35] Batch [10]#011Speed: 1977.57 samples/sec#011loss=3.076053\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] processed a total of 4567 examples\n",
      "#metrics {\"StartTime\": 1747885989.151356, \"EndTime\": 1747885991.7204378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2568.8130855560303, \"count\": 1, \"min\": 2568.8130855560303, \"max\": 2568.8130855560303}}}\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1777.8036542478767 records/second\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] #progress_metric: host=algo-1, completed 9.0 % of epochs\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=35, train loss <loss>=3.026529445366281\n",
      "[05/22/2025 03:53:11 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:12 INFO 140041726678848] Epoch[36] Batch[0] avg_epoch_loss=2.924002\n",
      "[05/22/2025 03:53:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.9240023946443485\n",
      "[05/22/2025 03:53:13 INFO 140041726678848] Epoch[36] Batch[5] avg_epoch_loss=2.955042\n",
      "[05/22/2025 03:53:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.9550418301520742\n",
      "[05/22/2025 03:53:13 INFO 140041726678848] Epoch[36] Batch [5]#011Speed: 2233.12 samples/sec#011loss=2.955042\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] Epoch[36] Batch[10] avg_epoch_loss=2.966493\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.9802342880011135\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] Epoch[36] Batch [10]#011Speed: 1971.19 samples/sec#011loss=2.980234\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] processed a total of 4619 examples\n",
      "#metrics {\"StartTime\": 1747885991.7204974, \"EndTime\": 1747885994.3029332, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2582.1194648742676, \"count\": 1, \"min\": 2582.1194648742676, \"max\": 2582.1194648742676}}}\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.7767945945648 records/second\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] #progress_metric: host=algo-1, completed 9.25 % of epochs\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.966492947356183\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] Epoch[37] Batch[0] avg_epoch_loss=2.998889\n",
      "[05/22/2025 03:53:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.9988885892260577\n",
      "[05/22/2025 03:53:15 INFO 140041726678848] Epoch[37] Batch[5] avg_epoch_loss=2.953542\n",
      "[05/22/2025 03:53:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.953542368095188\n",
      "[05/22/2025 03:53:15 INFO 140041726678848] Epoch[37] Batch [5]#011Speed: 2265.76 samples/sec#011loss=2.953542\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] Epoch[37] Batch[10] avg_epoch_loss=2.929969\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=2.9016814709771714\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] Epoch[37] Batch [10]#011Speed: 1946.55 samples/sec#011loss=2.901681\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] processed a total of 4669 examples\n",
      "#metrics {\"StartTime\": 1747885994.3029912, \"EndTime\": 1747885996.882844, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2579.5962810516357, \"count\": 1, \"min\": 2579.5962810516357, \"max\": 2579.5962810516357}}}\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1809.9124245585062 records/second\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] #progress_metric: host=algo-1, completed 9.5 % of epochs\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.9299692330415446\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:16 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_1772fb02-2d96-4c41-afab-8184651db75a-0000.params\"\n",
      "#metrics {\"StartTime\": 1747885996.8829033, \"EndTime\": 1747885996.8937898, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.57291030883789, \"count\": 1, \"min\": 10.57291030883789, \"max\": 10.57291030883789}}}\n",
      "[05/22/2025 03:53:17 INFO 140041726678848] Epoch[38] Batch[0] avg_epoch_loss=2.943506\n",
      "[05/22/2025 03:53:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.9435061856208242\n",
      "[05/22/2025 03:53:18 INFO 140041726678848] Epoch[38] Batch[5] avg_epoch_loss=2.929111\n",
      "[05/22/2025 03:53:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.9291106792583057\n",
      "[05/22/2025 03:53:18 INFO 140041726678848] Epoch[38] Batch [5]#011Speed: 2289.82 samples/sec#011loss=2.929111\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] Epoch[38] Batch[10] avg_epoch_loss=2.981355\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=3.044047536191537\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] Epoch[38] Batch [10]#011Speed: 1987.29 samples/sec#011loss=3.044048\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] processed a total of 4654 examples\n",
      "#metrics {\"StartTime\": 1747885996.8938417, \"EndTime\": 1747885999.4359734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.0680046081543, \"count\": 1, \"min\": 2542.0680046081543, \"max\": 2542.0680046081543}}}\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1830.7253996891377 records/second\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] #progress_metric: host=algo-1, completed 9.75 % of epochs\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.981354705137047\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] Epoch[39] Batch[0] avg_epoch_loss=2.903089\n",
      "[05/22/2025 03:53:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.9030892217079622\n",
      "[05/22/2025 03:53:20 INFO 140041726678848] Epoch[39] Batch[5] avg_epoch_loss=2.915301\n",
      "[05/22/2025 03:53:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.915300738838043\n",
      "[05/22/2025 03:53:20 INFO 140041726678848] Epoch[39] Batch [5]#011Speed: 2271.35 samples/sec#011loss=2.915301\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] Epoch[39] Batch[10] avg_epoch_loss=3.009228\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=3.1219408472821546\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] Epoch[39] Batch [10]#011Speed: 1945.84 samples/sec#011loss=3.121941\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] processed a total of 4638 examples\n",
      "#metrics {\"StartTime\": 1747885999.436026, \"EndTime\": 1747886001.9984713, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2562.199831008911, \"count\": 1, \"min\": 2562.199831008911, \"max\": 2562.199831008911}}}\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.1021188408904 records/second\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] #progress_metric: host=algo-1, completed 10.0 % of epochs\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=39, train loss <loss>=3.009228060858094\n",
      "[05/22/2025 03:53:21 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:22 INFO 140041726678848] Epoch[40] Batch[0] avg_epoch_loss=2.927527\n",
      "[05/22/2025 03:53:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.927526937030206\n",
      "[05/22/2025 03:53:23 INFO 140041726678848] Epoch[40] Batch[5] avg_epoch_loss=2.941609\n",
      "[05/22/2025 03:53:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.941609428649313\n",
      "[05/22/2025 03:53:23 INFO 140041726678848] Epoch[40] Batch [5]#011Speed: 2249.47 samples/sec#011loss=2.941609\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] Epoch[40] Batch[10] avg_epoch_loss=3.041634\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=3.161664321321687\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] Epoch[40] Batch [10]#011Speed: 1940.79 samples/sec#011loss=3.161664\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] processed a total of 4661 examples\n",
      "#metrics {\"StartTime\": 1747886001.9985304, \"EndTime\": 1747886004.5864933, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2587.7158641815186, \"count\": 1, \"min\": 2587.7158641815186, \"max\": 2587.7158641815186}}}\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1801.1439766228527 records/second\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] #progress_metric: host=algo-1, completed 10.25 % of epochs\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=40, train loss <loss>=3.041634379864029\n",
      "[05/22/2025 03:53:24 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:25 INFO 140041726678848] Epoch[41] Batch[0] avg_epoch_loss=2.892891\n",
      "[05/22/2025 03:53:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.892890777248051\n",
      "[05/22/2025 03:53:26 INFO 140041726678848] Epoch[41] Batch[5] avg_epoch_loss=2.978307\n",
      "[05/22/2025 03:53:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.978306510489166\n",
      "[05/22/2025 03:53:26 INFO 140041726678848] Epoch[41] Batch [5]#011Speed: 2203.35 samples/sec#011loss=2.978307\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] Epoch[41] Batch[10] avg_epoch_loss=2.995107\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=3.0152684676886135\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] Epoch[41] Batch [10]#011Speed: 1963.67 samples/sec#011loss=3.015268\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] processed a total of 4577 examples\n",
      "#metrics {\"StartTime\": 1747886004.5865507, \"EndTime\": 1747886007.181191, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2594.3856239318848, \"count\": 1, \"min\": 2594.3856239318848, \"max\": 2594.3856239318848}}}\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1764.1325672747216 records/second\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] #progress_metric: host=algo-1, completed 10.5 % of epochs\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.995107400125278\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] Epoch[42] Batch[0] avg_epoch_loss=2.883955\n",
      "[05/22/2025 03:53:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.883954632255707\n",
      "[05/22/2025 03:53:28 INFO 140041726678848] Epoch[42] Batch[5] avg_epoch_loss=2.974679\n",
      "[05/22/2025 03:53:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.9746792912925715\n",
      "[05/22/2025 03:53:28 INFO 140041726678848] Epoch[42] Batch [5]#011Speed: 2252.00 samples/sec#011loss=2.974679\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] Epoch[42] Batch[10] avg_epoch_loss=2.929455\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.8751851716923023\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] Epoch[42] Batch [10]#011Speed: 2023.94 samples/sec#011loss=2.875185\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] processed a total of 4530 examples\n",
      "#metrics {\"StartTime\": 1747886007.1812522, \"EndTime\": 1747886009.7231703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2541.6507720947266, \"count\": 1, \"min\": 2541.6507720947266, \"max\": 2541.6507720947266}}}\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1782.2460419540118 records/second\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] #progress_metric: host=algo-1, completed 10.75 % of epochs\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.9294546914742674\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:29 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_13e342f6-1912-4474-b4c5-5dfc8c9c385e-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886009.7232282, \"EndTime\": 1747886009.7340448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.50257682800293, \"count\": 1, \"min\": 10.50257682800293, \"max\": 10.50257682800293}}}\n",
      "[05/22/2025 03:53:30 INFO 140041726678848] Epoch[43] Batch[0] avg_epoch_loss=3.002949\n",
      "[05/22/2025 03:53:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=3.002948718506403\n",
      "[05/22/2025 03:53:31 INFO 140041726678848] Epoch[43] Batch[5] avg_epoch_loss=2.959776\n",
      "[05/22/2025 03:53:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.95977583830677\n",
      "[05/22/2025 03:53:31 INFO 140041726678848] Epoch[43] Batch [5]#011Speed: 2220.60 samples/sec#011loss=2.959776\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] Epoch[43] Batch[10] avg_epoch_loss=2.925211\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.883732404475223\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] Epoch[43] Batch [10]#011Speed: 1978.11 samples/sec#011loss=2.883732\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] processed a total of 4616 examples\n",
      "#metrics {\"StartTime\": 1747886009.7341492, \"EndTime\": 1747886012.3109787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2576.779842376709, \"count\": 1, \"min\": 2576.779842376709, \"max\": 2576.779842376709}}}\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1791.319508128194 records/second\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] #progress_metric: host=algo-1, completed 11.0 % of epochs\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.925210641110612\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_412913f9-d839-44af-9094-f095b7c767ac-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886012.3110435, \"EndTime\": 1747886012.3219361, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.527849197387695, \"count\": 1, \"min\": 10.527849197387695, \"max\": 10.527849197387695}}}\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] Epoch[44] Batch[0] avg_epoch_loss=2.914469\n",
      "[05/22/2025 03:53:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.9144689479224666\n",
      "[05/22/2025 03:53:33 INFO 140041726678848] Epoch[44] Batch[5] avg_epoch_loss=2.891656\n",
      "[05/22/2025 03:53:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.891656118051689\n",
      "[05/22/2025 03:53:33 INFO 140041726678848] Epoch[44] Batch [5]#011Speed: 2231.81 samples/sec#011loss=2.891656\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] Epoch[44] Batch[10] avg_epoch_loss=2.898864\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=2.907513930696687\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] Epoch[44] Batch [10]#011Speed: 2037.37 samples/sec#011loss=2.907514\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] processed a total of 4566 examples\n",
      "#metrics {\"StartTime\": 1747886012.321993, \"EndTime\": 1747886014.860677, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2538.634777069092, \"count\": 1, \"min\": 2538.634777069092, \"max\": 2538.634777069092}}}\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1798.5450689217796 records/second\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] #progress_metric: host=algo-1, completed 11.25 % of epochs\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.898864214708506\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:34 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_e2f1d34f-4d93-471a-b2bb-ed9f7711b55d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886014.8607347, \"EndTime\": 1747886014.871525, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.51950454711914, \"count\": 1, \"min\": 10.51950454711914, \"max\": 10.51950454711914}}}\n",
      "[05/22/2025 03:53:35 INFO 140041726678848] Epoch[45] Batch[0] avg_epoch_loss=2.989974\n",
      "[05/22/2025 03:53:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.9899744658268372\n",
      "[05/22/2025 03:53:36 INFO 140041726678848] Epoch[45] Batch[5] avg_epoch_loss=2.953714\n",
      "[05/22/2025 03:53:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.9537144174554566\n",
      "[05/22/2025 03:53:36 INFO 140041726678848] Epoch[45] Batch [5]#011Speed: 2243.03 samples/sec#011loss=2.953714\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] Epoch[45] Batch[10] avg_epoch_loss=3.043436\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=3.1511028740082128\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] Epoch[45] Batch [10]#011Speed: 1991.25 samples/sec#011loss=3.151103\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] processed a total of 4672 examples\n",
      "#metrics {\"StartTime\": 1747886014.8715758, \"EndTime\": 1747886017.4351819, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2563.5547637939453, \"count\": 1, \"min\": 2563.5547637939453, \"max\": 2563.5547637939453}}}\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1822.4071535554574 records/second\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] #progress_metric: host=algo-1, completed 11.5 % of epochs\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=45, train loss <loss>=3.0434364431612546\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] Epoch[46] Batch[0] avg_epoch_loss=2.995776\n",
      "[05/22/2025 03:53:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.995776475936108\n",
      "[05/22/2025 03:53:38 INFO 140041726678848] Epoch[46] Batch[5] avg_epoch_loss=2.997587\n",
      "[05/22/2025 03:53:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.9975871855715246\n",
      "[05/22/2025 03:53:38 INFO 140041726678848] Epoch[46] Batch [5]#011Speed: 2296.26 samples/sec#011loss=2.997587\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] Epoch[46] Batch[10] avg_epoch_loss=2.994035\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.9897730090304844\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] Epoch[46] Batch [10]#011Speed: 2024.73 samples/sec#011loss=2.989773\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] processed a total of 4583 examples\n",
      "#metrics {\"StartTime\": 1747886017.4352427, \"EndTime\": 1747886019.9572418, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2521.7161178588867, \"count\": 1, \"min\": 2521.7161178588867, \"max\": 2521.7161178588867}}}\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1817.3497339989276 records/second\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] #progress_metric: host=algo-1, completed 11.75 % of epochs\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.994035287143779\n",
      "[05/22/2025 03:53:39 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:40 INFO 140041726678848] Epoch[47] Batch[0] avg_epoch_loss=2.903438\n",
      "[05/22/2025 03:53:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.9034377609966593\n",
      "[05/22/2025 03:53:41 INFO 140041726678848] Epoch[47] Batch[5] avg_epoch_loss=2.934909\n",
      "[05/22/2025 03:53:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.9349089737901353\n",
      "[05/22/2025 03:53:41 INFO 140041726678848] Epoch[47] Batch [5]#011Speed: 2258.37 samples/sec#011loss=2.934909\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] Epoch[47] Batch[10] avg_epoch_loss=3.087479\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=3.270563274290089\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] Epoch[47] Batch [10]#011Speed: 2008.94 samples/sec#011loss=3.270563\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] processed a total of 4661 examples\n",
      "#metrics {\"StartTime\": 1747886019.957302, \"EndTime\": 1747886022.4989843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2541.429281234741, \"count\": 1, \"min\": 2541.429281234741, \"max\": 2541.429281234741}}}\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1833.9449041219 records/second\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] #progress_metric: host=algo-1, completed 12.0 % of epochs\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=47, train loss <loss>=3.0874791103810235\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] Epoch[48] Batch[0] avg_epoch_loss=2.939310\n",
      "[05/22/2025 03:53:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.9393103924519766\n",
      "[05/22/2025 03:53:43 INFO 140041726678848] Epoch[48] Batch[5] avg_epoch_loss=2.882280\n",
      "[05/22/2025 03:53:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.882280447435273\n",
      "[05/22/2025 03:53:43 INFO 140041726678848] Epoch[48] Batch [5]#011Speed: 2287.24 samples/sec#011loss=2.882280\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] Epoch[48] Batch[10] avg_epoch_loss=2.874060\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=2.864196152039254\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] Epoch[48] Batch [10]#011Speed: 2027.00 samples/sec#011loss=2.864196\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] processed a total of 4608 examples\n",
      "#metrics {\"StartTime\": 1747886022.4990432, \"EndTime\": 1747886025.0119205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2512.591600418091, \"count\": 1, \"min\": 2512.591600418091, \"max\": 2512.591600418091}}}\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1833.899993879837 records/second\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] #progress_metric: host=algo-1, completed 12.25 % of epochs\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.874060313164355\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_a7b2b896-0f57-423d-a2c6-b2e754f5179b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886025.011979, \"EndTime\": 1747886025.0223646, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.068655014038086, \"count\": 1, \"min\": 10.068655014038086, \"max\": 10.068655014038086}}}\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] Epoch[49] Batch[0] avg_epoch_loss=2.887537\n",
      "[05/22/2025 03:53:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.8875368114038142\n",
      "[05/22/2025 03:53:46 INFO 140041726678848] Epoch[49] Batch[5] avg_epoch_loss=2.914137\n",
      "[05/22/2025 03:53:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.914137174044172\n",
      "[05/22/2025 03:53:46 INFO 140041726678848] Epoch[49] Batch [5]#011Speed: 2214.87 samples/sec#011loss=2.914137\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] Epoch[49] Batch[10] avg_epoch_loss=2.898782\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=2.8803567389337417\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] Epoch[49] Batch [10]#011Speed: 2011.03 samples/sec#011loss=2.880357\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] processed a total of 4646 examples\n",
      "#metrics {\"StartTime\": 1747886025.0224133, \"EndTime\": 1747886027.581076, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2558.6118698120117, \"count\": 1, \"min\": 2558.6118698120117, \"max\": 2558.6118698120117}}}\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1815.7649125216608 records/second\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] #progress_metric: host=algo-1, completed 12.5 % of epochs\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.898782430812158\n",
      "[05/22/2025 03:53:47 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:48 INFO 140041726678848] Epoch[50] Batch[0] avg_epoch_loss=2.855810\n",
      "[05/22/2025 03:53:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.855809676886136\n",
      "[05/22/2025 03:53:48 INFO 140041726678848] Epoch[50] Batch[5] avg_epoch_loss=2.850577\n",
      "[05/22/2025 03:53:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.8505765579325586\n",
      "[05/22/2025 03:53:48 INFO 140041726678848] Epoch[50] Batch [5]#011Speed: 2284.48 samples/sec#011loss=2.850577\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] Epoch[50] Batch[10] avg_epoch_loss=2.882357\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.9204940558010857\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] Epoch[50] Batch [10]#011Speed: 2013.34 samples/sec#011loss=2.920494\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] processed a total of 4514 examples\n",
      "#metrics {\"StartTime\": 1747886027.5811362, \"EndTime\": 1747886030.1050978, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2523.707628250122, \"count\": 1, \"min\": 2523.707628250122, \"max\": 2523.707628250122}}}\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.5772536506815 records/second\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] #progress_metric: host=algo-1, completed 12.75 % of epochs\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.882357238781889\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] Epoch[51] Batch[0] avg_epoch_loss=2.860143\n",
      "[05/22/2025 03:53:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.860142765172606\n",
      "[05/22/2025 03:53:51 INFO 140041726678848] Epoch[51] Batch[5] avg_epoch_loss=2.858774\n",
      "[05/22/2025 03:53:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.8587738014453414\n",
      "[05/22/2025 03:53:51 INFO 140041726678848] Epoch[51] Batch [5]#011Speed: 2248.08 samples/sec#011loss=2.858774\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] Epoch[51] Batch[10] avg_epoch_loss=2.868537\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.8802529927616924\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] Epoch[51] Batch [10]#011Speed: 2047.19 samples/sec#011loss=2.880253\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] processed a total of 4522 examples\n",
      "#metrics {\"StartTime\": 1747886030.1051555, \"EndTime\": 1747886032.6250334, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2519.5765495300293, \"count\": 1, \"min\": 2519.5765495300293, \"max\": 2519.5765495300293}}}\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.6870969814493 records/second\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] #progress_metric: host=algo-1, completed 13.0 % of epochs\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.8685370702255013\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:52 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_1501dc37-2f14-446a-9cac-abb4d112fc69-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886032.6250904, \"EndTime\": 1747886032.6356413, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.288715362548828, \"count\": 1, \"min\": 10.288715362548828, \"max\": 10.288715362548828}}}\n",
      "[05/22/2025 03:53:53 INFO 140041726678848] Epoch[52] Batch[0] avg_epoch_loss=2.866098\n",
      "[05/22/2025 03:53:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.8660975670761415\n",
      "[05/22/2025 03:53:54 INFO 140041726678848] Epoch[52] Batch[5] avg_epoch_loss=2.886904\n",
      "[05/22/2025 03:53:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.88690357732171\n",
      "[05/22/2025 03:53:54 INFO 140041726678848] Epoch[52] Batch [5]#011Speed: 2240.23 samples/sec#011loss=2.886904\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] Epoch[52] Batch[10] avg_epoch_loss=2.800819\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=2.697516508038697\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] Epoch[52] Batch [10]#011Speed: 1990.73 samples/sec#011loss=2.697517\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] processed a total of 4595 examples\n",
      "#metrics {\"StartTime\": 1747886032.6356883, \"EndTime\": 1747886035.1836524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2547.9159355163574, \"count\": 1, \"min\": 2547.9159355163574, \"max\": 2547.9159355163574}}}\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1803.3616280161057 records/second\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] #progress_metric: host=algo-1, completed 13.25 % of epochs\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.8008185458294315\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_fcfb1c77-f0e0-4419-a8a7-ff8385365256-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886035.1837275, \"EndTime\": 1747886035.1945777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.575056076049805, \"count\": 1, \"min\": 10.575056076049805, \"max\": 10.575056076049805}}}\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] Epoch[53] Batch[0] avg_epoch_loss=2.796311\n",
      "[05/22/2025 03:53:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.7963108665959076\n",
      "[05/22/2025 03:53:56 INFO 140041726678848] Epoch[53] Batch[5] avg_epoch_loss=2.775311\n",
      "[05/22/2025 03:53:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.7753109666446267\n",
      "[05/22/2025 03:53:56 INFO 140041726678848] Epoch[53] Batch [5]#011Speed: 2211.47 samples/sec#011loss=2.775311\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] Epoch[53] Batch[10] avg_epoch_loss=2.808736\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.848846286017539\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] Epoch[53] Batch [10]#011Speed: 2029.50 samples/sec#011loss=2.848846\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] processed a total of 4574 examples\n",
      "#metrics {\"StartTime\": 1747886035.1946235, \"EndTime\": 1747886037.743362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.6695766448975, \"count\": 1, \"min\": 2548.6695766448975, \"max\": 2548.6695766448975}}}\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.580575300464 records/second\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] #progress_metric: host=algo-1, completed 13.5 % of epochs\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.8087361118141323\n",
      "[05/22/2025 03:53:57 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:53:58 INFO 140041726678848] Epoch[54] Batch[0] avg_epoch_loss=3.023384\n",
      "[05/22/2025 03:53:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=3.023384213182071\n",
      "[05/22/2025 03:53:59 INFO 140041726678848] Epoch[54] Batch[5] avg_epoch_loss=2.911436\n",
      "[05/22/2025 03:53:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.91143599455677\n",
      "[05/22/2025 03:53:59 INFO 140041726678848] Epoch[54] Batch [5]#011Speed: 2272.41 samples/sec#011loss=2.911436\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] processed a total of 4490 examples\n",
      "#metrics {\"StartTime\": 1747886037.74343, \"EndTime\": 1747886040.1262162, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2382.446765899658, \"count\": 1, \"min\": 2382.446765899658, \"max\": 2382.446765899658}}}\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1884.5401903750924 records/second\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] #progress_metric: host=algo-1, completed 13.75 % of epochs\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.911467350405415\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] Epoch[55] Batch[0] avg_epoch_loss=2.747521\n",
      "[05/22/2025 03:54:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.7475205317371936\n",
      "[05/22/2025 03:54:01 INFO 140041726678848] Epoch[55] Batch[5] avg_epoch_loss=2.774154\n",
      "[05/22/2025 03:54:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.7741539267672373\n",
      "[05/22/2025 03:54:01 INFO 140041726678848] Epoch[55] Batch [5]#011Speed: 2226.26 samples/sec#011loss=2.774154\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] Epoch[55] Batch[10] avg_epoch_loss=2.805759\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.8436849683324055\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] Epoch[55] Batch [10]#011Speed: 1876.01 samples/sec#011loss=2.843685\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] processed a total of 4699 examples\n",
      "#metrics {\"StartTime\": 1747886040.1262822, \"EndTime\": 1747886042.75458, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2628.0009746551514, \"count\": 1, \"min\": 2628.0009746551514, \"max\": 2628.0009746551514}}}\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1787.9834456010913 records/second\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 14.0 % of epochs\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.8057589456604957\n",
      "[05/22/2025 03:54:02 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:03 INFO 140041726678848] Epoch[56] Batch[0] avg_epoch_loss=2.784593\n",
      "[05/22/2025 03:54:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.7845926603389475\n",
      "[05/22/2025 03:54:04 INFO 140041726678848] Epoch[56] Batch[5] avg_epoch_loss=2.846169\n",
      "[05/22/2025 03:54:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.8461687956019164\n",
      "[05/22/2025 03:54:04 INFO 140041726678848] Epoch[56] Batch [5]#011Speed: 2295.63 samples/sec#011loss=2.846169\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] Epoch[56] Batch[10] avg_epoch_loss=2.833201\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=2.8176407098239142\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] Epoch[56] Batch [10]#011Speed: 1980.11 samples/sec#011loss=2.817641\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] processed a total of 4611 examples\n",
      "#metrics {\"StartTime\": 1747886042.7546525, \"EndTime\": 1747886045.3032367, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.325777053833, \"count\": 1, \"min\": 2548.325777053833, \"max\": 2548.325777053833}}}\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1809.3603126629914 records/second\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] #progress_metric: host=algo-1, completed 14.25 % of epochs\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.8332014838846424\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] Epoch[57] Batch[0] avg_epoch_loss=2.775035\n",
      "[05/22/2025 03:54:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.7750350170517817\n",
      "[05/22/2025 03:54:06 INFO 140041726678848] Epoch[57] Batch[5] avg_epoch_loss=2.752183\n",
      "[05/22/2025 03:54:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.7521829923701975\n",
      "[05/22/2025 03:54:06 INFO 140041726678848] Epoch[57] Batch [5]#011Speed: 2256.01 samples/sec#011loss=2.752183\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] Epoch[57] Batch[10] avg_epoch_loss=2.900909\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=3.0793799045622214\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] Epoch[57] Batch [10]#011Speed: 2031.19 samples/sec#011loss=3.079380\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] processed a total of 4592 examples\n",
      "#metrics {\"StartTime\": 1747886045.3032968, \"EndTime\": 1747886047.8330033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2529.3829441070557, \"count\": 1, \"min\": 2529.3829441070557, \"max\": 2529.3829441070557}}}\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1815.4000878092056 records/second\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 14.5 % of epochs\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.9009088615483902\n",
      "[05/22/2025 03:54:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:08 INFO 140041726678848] Epoch[58] Batch[0] avg_epoch_loss=2.866679\n",
      "[05/22/2025 03:54:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.8666788283859965\n",
      "[05/22/2025 03:54:09 INFO 140041726678848] Epoch[58] Batch[5] avg_epoch_loss=2.816774\n",
      "[05/22/2025 03:54:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.81677413747854\n",
      "[05/22/2025 03:54:09 INFO 140041726678848] Epoch[58] Batch [5]#011Speed: 2249.24 samples/sec#011loss=2.816774\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] Epoch[58] Batch[10] avg_epoch_loss=2.855458\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.901879284695156\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] Epoch[58] Batch [10]#011Speed: 2019.35 samples/sec#011loss=2.901879\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] processed a total of 4622 examples\n",
      "#metrics {\"StartTime\": 1747886047.8330626, \"EndTime\": 1747886050.3799453, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2546.627998352051, \"count\": 1, \"min\": 2546.627998352051, \"max\": 2546.627998352051}}}\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1814.883777849926 records/second\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 14.75 % of epochs\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.855458295304275\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] Epoch[59] Batch[0] avg_epoch_loss=2.697822\n",
      "[05/22/2025 03:54:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.697821602258491\n",
      "[05/22/2025 03:54:11 INFO 140041726678848] Epoch[59] Batch[5] avg_epoch_loss=2.758002\n",
      "[05/22/2025 03:54:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.758002085073311\n",
      "[05/22/2025 03:54:11 INFO 140041726678848] Epoch[59] Batch [5]#011Speed: 2211.49 samples/sec#011loss=2.758002\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] Epoch[59] Batch[10] avg_epoch_loss=2.782318\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=2.811497718454204\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] Epoch[59] Batch [10]#011Speed: 2003.49 samples/sec#011loss=2.811498\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] processed a total of 4641 examples\n",
      "#metrics {\"StartTime\": 1747886050.3800075, \"EndTime\": 1747886052.9473019, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2567.020893096924, \"count\": 1, \"min\": 2567.020893096924, \"max\": 2567.020893096924}}}\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1807.8423062499198 records/second\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 15.0 % of epochs\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.782318282064626\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:12 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_b7c5894d-c138-4b05-9b59-93493bbf2771-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886052.947395, \"EndTime\": 1747886052.9584403, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.604381561279297, \"count\": 1, \"min\": 10.604381561279297, \"max\": 10.604381561279297}}}\n",
      "[05/22/2025 03:54:13 INFO 140041726678848] Epoch[60] Batch[0] avg_epoch_loss=2.821534\n",
      "[05/22/2025 03:54:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.8215342906110803\n",
      "[05/22/2025 03:54:14 INFO 140041726678848] Epoch[60] Batch[5] avg_epoch_loss=2.883717\n",
      "[05/22/2025 03:54:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.883716563427988\n",
      "[05/22/2025 03:54:14 INFO 140041726678848] Epoch[60] Batch [5]#011Speed: 2238.09 samples/sec#011loss=2.883717\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] Epoch[60] Batch[10] avg_epoch_loss=3.001099\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=3.1419579316884745\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] Epoch[60] Batch [10]#011Speed: 1902.53 samples/sec#011loss=3.141958\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] processed a total of 4635 examples\n",
      "#metrics {\"StartTime\": 1747886052.958493, \"EndTime\": 1747886055.5636926, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2605.147123336792, \"count\": 1, \"min\": 2605.147123336792, \"max\": 2605.147123336792}}}\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1779.1120234981975 records/second\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 15.25 % of epochs\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=60, train loss <loss>=3.001099003546391\n",
      "[05/22/2025 03:54:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:16 INFO 140041726678848] Epoch[61] Batch[0] avg_epoch_loss=2.850000\n",
      "[05/22/2025 03:54:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.849999510631264\n",
      "[05/22/2025 03:54:17 INFO 140041726678848] Epoch[61] Batch[5] avg_epoch_loss=2.873962\n",
      "[05/22/2025 03:54:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.8739615867291897\n",
      "[05/22/2025 03:54:17 INFO 140041726678848] Epoch[61] Batch [5]#011Speed: 2196.05 samples/sec#011loss=2.873962\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] Epoch[61] Batch[10] avg_epoch_loss=2.878943\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=2.8849205917664253\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] Epoch[61] Batch [10]#011Speed: 1956.62 samples/sec#011loss=2.884921\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] processed a total of 4549 examples\n",
      "#metrics {\"StartTime\": 1747886055.56375, \"EndTime\": 1747886058.1734676, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2609.4272136688232, \"count\": 1, \"min\": 2609.4272136688232, \"max\": 2609.4272136688232}}}\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1743.235366468033 records/second\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] #progress_metric: host=algo-1, completed 15.5 % of epochs\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.878942952655206\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] Epoch[62] Batch[0] avg_epoch_loss=2.822592\n",
      "[05/22/2025 03:54:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.8225924145670938\n",
      "[05/22/2025 03:54:19 INFO 140041726678848] Epoch[62] Batch[5] avg_epoch_loss=2.868327\n",
      "[05/22/2025 03:54:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.8683265963570665\n",
      "[05/22/2025 03:54:19 INFO 140041726678848] Epoch[62] Batch [5]#011Speed: 2245.31 samples/sec#011loss=2.868327\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] Epoch[62] Batch[10] avg_epoch_loss=2.846341\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.81995836015799\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] Epoch[62] Batch [10]#011Speed: 2030.44 samples/sec#011loss=2.819958\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] processed a total of 4574 examples\n",
      "#metrics {\"StartTime\": 1747886058.1735287, \"EndTime\": 1747886060.711471, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2537.6787185668945, \"count\": 1, \"min\": 2537.6787185668945, \"max\": 2537.6787185668945}}}\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1802.3716363740218 records/second\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 15.75 % of epochs\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.8463410344483955\n",
      "[05/22/2025 03:54:20 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:21 INFO 140041726678848] Epoch[63] Batch[0] avg_epoch_loss=2.834434\n",
      "[05/22/2025 03:54:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.8344335067511137\n",
      "[05/22/2025 03:54:22 INFO 140041726678848] Epoch[63] Batch[5] avg_epoch_loss=2.807329\n",
      "[05/22/2025 03:54:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.8073285505695527\n",
      "[05/22/2025 03:54:22 INFO 140041726678848] Epoch[63] Batch [5]#011Speed: 2271.95 samples/sec#011loss=2.807329\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] Epoch[63] Batch[10] avg_epoch_loss=2.835425\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.869140733748608\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] Epoch[63] Batch [10]#011Speed: 1955.84 samples/sec#011loss=2.869141\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] processed a total of 4675 examples\n",
      "#metrics {\"StartTime\": 1747886060.7115319, \"EndTime\": 1747886063.2743902, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2562.595844268799, \"count\": 1, \"min\": 2562.595844268799, \"max\": 2562.595844268799}}}\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1824.261926602944 records/second\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 16.0 % of epochs\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.8354249974691235\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] Epoch[64] Batch[0] avg_epoch_loss=2.858397\n",
      "[05/22/2025 03:54:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.8583968062708798\n",
      "[05/22/2025 03:54:24 INFO 140041726678848] Epoch[64] Batch[5] avg_epoch_loss=2.878937\n",
      "[05/22/2025 03:54:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.878936608986405\n",
      "[05/22/2025 03:54:24 INFO 140041726678848] Epoch[64] Batch [5]#011Speed: 2249.39 samples/sec#011loss=2.878937\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] Epoch[64] Batch[10] avg_epoch_loss=2.847566\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=2.809921788001114\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] Epoch[64] Batch [10]#011Speed: 2004.66 samples/sec#011loss=2.809922\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] processed a total of 4627 examples\n",
      "#metrics {\"StartTime\": 1747886063.2744477, \"EndTime\": 1747886065.8165417, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2541.7869091033936, \"count\": 1, \"min\": 2541.7869091033936, \"max\": 2541.7869091033936}}}\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1820.310234102595 records/second\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 16.25 % of epochs\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.8475662358112723\n",
      "[05/22/2025 03:54:25 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:26 INFO 140041726678848] Epoch[65] Batch[0] avg_epoch_loss=2.704420\n",
      "[05/22/2025 03:54:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.7044199240499722\n",
      "[05/22/2025 03:54:27 INFO 140041726678848] Epoch[65] Batch[5] avg_epoch_loss=2.756668\n",
      "[05/22/2025 03:54:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.7566681927721324\n",
      "[05/22/2025 03:54:27 INFO 140041726678848] Epoch[65] Batch [5]#011Speed: 2172.94 samples/sec#011loss=2.756668\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] Epoch[65] Batch[10] avg_epoch_loss=2.779680\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.807293660391147\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] Epoch[65] Batch [10]#011Speed: 2030.20 samples/sec#011loss=2.807294\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] processed a total of 4662 examples\n",
      "#metrics {\"StartTime\": 1747886065.8166013, \"EndTime\": 1747886068.3882685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2571.4099407196045, \"count\": 1, \"min\": 2571.4099407196045, \"max\": 2571.4099407196045}}}\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1812.9532938777527 records/second\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 16.5 % of epochs\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.779679768962594\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_563ade2d-115c-4291-973c-3dab17f8883d-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886068.3883264, \"EndTime\": 1747886068.3992443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.64300537109375, \"count\": 1, \"min\": 10.64300537109375, \"max\": 10.64300537109375}}}\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] Epoch[66] Batch[0] avg_epoch_loss=2.794592\n",
      "[05/22/2025 03:54:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.794591551103146\n",
      "[05/22/2025 03:54:29 INFO 140041726678848] Epoch[66] Batch[5] avg_epoch_loss=2.812195\n",
      "[05/22/2025 03:54:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.81219482421875\n",
      "[05/22/2025 03:54:29 INFO 140041726678848] Epoch[66] Batch [5]#011Speed: 2263.03 samples/sec#011loss=2.812195\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] Epoch[66] Batch[10] avg_epoch_loss=2.690994\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.5455540306584075\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] Epoch[66] Batch [10]#011Speed: 2058.13 samples/sec#011loss=2.545554\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] processed a total of 4549 examples\n",
      "#metrics {\"StartTime\": 1747886068.3992963, \"EndTime\": 1747886070.908662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2509.298086166382, \"count\": 1, \"min\": 2509.298086166382, \"max\": 2509.298086166382}}}\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1812.7834945291718 records/second\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 16.75 % of epochs\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.6909944635095036\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:30 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_ec7e6c70-0f88-4ec5-b345-efa0f539e916-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886070.9087214, \"EndTime\": 1747886070.919626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.606050491333008, \"count\": 1, \"min\": 10.606050491333008, \"max\": 10.606050491333008}}}\n",
      "[05/22/2025 03:54:31 INFO 140041726678848] Epoch[67] Batch[0] avg_epoch_loss=2.736314\n",
      "[05/22/2025 03:54:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.7363137158094375\n",
      "[05/22/2025 03:54:32 INFO 140041726678848] Epoch[67] Batch[5] avg_epoch_loss=2.723590\n",
      "[05/22/2025 03:54:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.7235904005428733\n",
      "[05/22/2025 03:54:32 INFO 140041726678848] Epoch[67] Batch [5]#011Speed: 2218.88 samples/sec#011loss=2.723590\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] Epoch[67] Batch[10] avg_epoch_loss=2.691595\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.6531994927964924\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] Epoch[67] Batch [10]#011Speed: 2059.85 samples/sec#011loss=2.653199\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] processed a total of 4574 examples\n",
      "#metrics {\"StartTime\": 1747886070.919677, \"EndTime\": 1747886073.4497144, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2529.9878120422363, \"count\": 1, \"min\": 2529.9878120422363, \"max\": 2529.9878120422363}}}\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1807.8521750110724 records/second\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 17.0 % of epochs\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.691594533385427\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] Epoch[68] Batch[0] avg_epoch_loss=2.742240\n",
      "[05/22/2025 03:54:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.7422399712033685\n",
      "[05/22/2025 03:54:34 INFO 140041726678848] Epoch[68] Batch[5] avg_epoch_loss=2.762723\n",
      "[05/22/2025 03:54:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.7627234058904047\n",
      "[05/22/2025 03:54:34 INFO 140041726678848] Epoch[68] Batch [5]#011Speed: 2288.50 samples/sec#011loss=2.762723\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] Epoch[68] Batch[10] avg_epoch_loss=2.672682\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.5646319620858855\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] Epoch[68] Batch [10]#011Speed: 2039.50 samples/sec#011loss=2.564632\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] processed a total of 4566 examples\n",
      "#metrics {\"StartTime\": 1747886073.4497733, \"EndTime\": 1747886075.9561276, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2506.101131439209, \"count\": 1, \"min\": 2506.101131439209, \"max\": 2506.101131439209}}}\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1821.8972774557812 records/second\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] #progress_metric: host=algo-1, completed 17.25 % of epochs\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.672681840524714\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:35 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_a221d3fa-6142-47fe-84e9-63001371419c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886075.9561806, \"EndTime\": 1747886075.967235, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.761737823486328, \"count\": 1, \"min\": 10.761737823486328, \"max\": 10.761737823486328}}}\n",
      "[05/22/2025 03:54:36 INFO 140041726678848] Epoch[69] Batch[0] avg_epoch_loss=2.674850\n",
      "[05/22/2025 03:54:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.674850090043847\n",
      "[05/22/2025 03:54:37 INFO 140041726678848] Epoch[69] Batch[5] avg_epoch_loss=2.775347\n",
      "[05/22/2025 03:54:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.775347080244873\n",
      "[05/22/2025 03:54:37 INFO 140041726678848] Epoch[69] Batch [5]#011Speed: 2253.45 samples/sec#011loss=2.775347\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] Epoch[69] Batch[10] avg_epoch_loss=2.755324\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.7312964900299277\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] Epoch[69] Batch [10]#011Speed: 2038.90 samples/sec#011loss=2.731296\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] processed a total of 4705 examples\n",
      "#metrics {\"StartTime\": 1747886075.9672842, \"EndTime\": 1747886078.4946735, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2527.340888977051, \"count\": 1, \"min\": 2527.340888977051, \"max\": 2527.340888977051}}}\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1861.5770418016682 records/second\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 17.5 % of epochs\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.7553240846926252\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] Epoch[70] Batch[0] avg_epoch_loss=2.721877\n",
      "[05/22/2025 03:54:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.721876522480512\n",
      "[05/22/2025 03:54:39 INFO 140041726678848] Epoch[70] Batch[5] avg_epoch_loss=2.742227\n",
      "[05/22/2025 03:54:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.7422270573061667\n",
      "[05/22/2025 03:54:39 INFO 140041726678848] Epoch[70] Batch [5]#011Speed: 2245.86 samples/sec#011loss=2.742227\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] Epoch[70] Batch[10] avg_epoch_loss=2.839006\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.955140764198218\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] Epoch[70] Batch [10]#011Speed: 2018.40 samples/sec#011loss=2.955141\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] processed a total of 4565 examples\n",
      "#metrics {\"StartTime\": 1747886078.4947329, \"EndTime\": 1747886081.0270789, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2532.0777893066406, \"count\": 1, \"min\": 2532.0777893066406, \"max\": 2532.0777893066406}}}\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1802.793361177598 records/second\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 17.75 % of epochs\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.839006014984372\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] Epoch[71] Batch[0] avg_epoch_loss=2.675203\n",
      "[05/22/2025 03:54:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.6752029792768655\n",
      "[05/22/2025 03:54:42 INFO 140041726678848] Epoch[71] Batch[5] avg_epoch_loss=2.730294\n",
      "[05/22/2025 03:54:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.7302942991079715\n",
      "[05/22/2025 03:54:42 INFO 140041726678848] Epoch[71] Batch [5]#011Speed: 2215.91 samples/sec#011loss=2.730294\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] Epoch[71] Batch[10] avg_epoch_loss=2.759830\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.7952723717636414\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] Epoch[71] Batch [10]#011Speed: 2057.75 samples/sec#011loss=2.795272\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] processed a total of 4565 examples\n",
      "#metrics {\"StartTime\": 1747886081.027151, \"EndTime\": 1747886083.5985346, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2571.0301399230957, \"count\": 1, \"min\": 2571.0301399230957, \"max\": 2571.0301399230957}}}\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1775.4814358450892 records/second\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] #progress_metric: host=algo-1, completed 18.0 % of epochs\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.7598297866787305\n",
      "[05/22/2025 03:54:43 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:44 INFO 140041726678848] Epoch[72] Batch[0] avg_epoch_loss=2.884513\n",
      "[05/22/2025 03:54:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.884513328229399\n",
      "[05/22/2025 03:54:45 INFO 140041726678848] Epoch[72] Batch[5] avg_epoch_loss=2.849905\n",
      "[05/22/2025 03:54:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.8499050805899686\n",
      "[05/22/2025 03:54:45 INFO 140041726678848] Epoch[72] Batch [5]#011Speed: 2271.45 samples/sec#011loss=2.849905\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] Epoch[72] Batch[10] avg_epoch_loss=2.790944\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.720189994693068\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] Epoch[72] Batch [10]#011Speed: 1984.86 samples/sec#011loss=2.720190\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] processed a total of 4656 examples\n",
      "#metrics {\"StartTime\": 1747886083.598609, \"EndTime\": 1747886086.1357348, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2536.8733406066895, \"count\": 1, \"min\": 2536.8733406066895, \"max\": 2536.8733406066895}}}\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1835.2640392391513 records/second\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 18.25 % of epochs\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.790943677909559\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] Epoch[73] Batch[0] avg_epoch_loss=2.775353\n",
      "[05/22/2025 03:54:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.775353106730234\n",
      "[05/22/2025 03:54:47 INFO 140041726678848] Epoch[73] Batch[5] avg_epoch_loss=2.763383\n",
      "[05/22/2025 03:54:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.7633825130788328\n",
      "[05/22/2025 03:54:47 INFO 140041726678848] Epoch[73] Batch [5]#011Speed: 2259.66 samples/sec#011loss=2.763383\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] Epoch[73] Batch[10] avg_epoch_loss=2.724225\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=2.677235001391982\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] Epoch[73] Batch [10]#011Speed: 2026.09 samples/sec#011loss=2.677235\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] processed a total of 4657 examples\n",
      "#metrics {\"StartTime\": 1747886086.1357968, \"EndTime\": 1747886088.6637383, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2527.6200771331787, \"count\": 1, \"min\": 2527.6200771331787, \"max\": 2527.6200771331787}}}\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1842.3810104024976 records/second\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] #progress_metric: host=algo-1, completed 18.5 % of epochs\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.7242245532211733\n",
      "[05/22/2025 03:54:48 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:49 INFO 140041726678848] Epoch[74] Batch[0] avg_epoch_loss=2.716284\n",
      "[05/22/2025 03:54:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.716283581570156\n",
      "[05/22/2025 03:54:50 INFO 140041726678848] Epoch[74] Batch[5] avg_epoch_loss=2.729015\n",
      "[05/22/2025 03:54:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.7290147811108016\n",
      "[05/22/2025 03:54:50 INFO 140041726678848] Epoch[74] Batch [5]#011Speed: 2282.69 samples/sec#011loss=2.729015\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] Epoch[74] Batch[10] avg_epoch_loss=2.788058\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.858910371572244\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] Epoch[74] Batch [10]#011Speed: 1992.97 samples/sec#011loss=2.858910\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] processed a total of 4698 examples\n",
      "#metrics {\"StartTime\": 1747886088.6637979, \"EndTime\": 1747886091.201589, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2537.5359058380127, \"count\": 1, \"min\": 2537.5359058380127, \"max\": 2537.5359058380127}}}\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1851.3435801169442 records/second\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 18.75 % of epochs\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.788058231320548\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] Epoch[75] Batch[0] avg_epoch_loss=2.689610\n",
      "[05/22/2025 03:54:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.689610266738586\n",
      "[05/22/2025 03:54:52 INFO 140041726678848] Epoch[75] Batch[5] avg_epoch_loss=2.687048\n",
      "[05/22/2025 03:54:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.687048330781366\n",
      "[05/22/2025 03:54:52 INFO 140041726678848] Epoch[75] Batch [5]#011Speed: 2274.86 samples/sec#011loss=2.687048\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] Epoch[75] Batch[10] avg_epoch_loss=2.687383\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=2.687785492283199\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] Epoch[75] Batch [10]#011Speed: 1994.65 samples/sec#011loss=2.687785\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] processed a total of 4711 examples\n",
      "#metrics {\"StartTime\": 1747886091.2016432, \"EndTime\": 1747886093.738722, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2536.8268489837646, \"count\": 1, \"min\": 2536.8268489837646, \"max\": 2536.8268489837646}}}\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1856.9813596697325 records/second\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] #progress_metric: host=algo-1, completed 19.0 % of epochs\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.68738340419129\n",
      "[05/22/2025 03:54:53 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:54:54 INFO 140041726678848] Epoch[76] Batch[0] avg_epoch_loss=2.632513\n",
      "[05/22/2025 03:54:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.632512897584911\n",
      "[05/22/2025 03:54:55 INFO 140041726678848] Epoch[76] Batch[5] avg_epoch_loss=2.675116\n",
      "[05/22/2025 03:54:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.675116206950051\n",
      "[05/22/2025 03:54:55 INFO 140041726678848] Epoch[76] Batch [5]#011Speed: 2252.73 samples/sec#011loss=2.675116\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] Epoch[76] Batch[10] avg_epoch_loss=2.644913\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.608668868100988\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] Epoch[76] Batch [10]#011Speed: 2001.63 samples/sec#011loss=2.608669\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] processed a total of 4581 examples\n",
      "#metrics {\"StartTime\": 1747886093.7387812, \"EndTime\": 1747886096.2843888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2545.34649848938, \"count\": 1, \"min\": 2545.34649848938, \"max\": 2545.34649848938}}}\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1799.6622513336993 records/second\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 19.25 % of epochs\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.644912871109568\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_42414ee0-5a3e-493b-bfef-509b7bb6c430-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886096.2844918, \"EndTime\": 1747886096.2956398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.850906372070312, \"count\": 1, \"min\": 10.850906372070312, \"max\": 10.850906372070312}}}\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] Epoch[77] Batch[0] avg_epoch_loss=2.706676\n",
      "[05/22/2025 03:54:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.7066756420517817\n",
      "[05/22/2025 03:54:57 INFO 140041726678848] Epoch[77] Batch[5] avg_epoch_loss=2.655692\n",
      "[05/22/2025 03:54:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.6556921649527885\n",
      "[05/22/2025 03:54:57 INFO 140041726678848] Epoch[77] Batch [5]#011Speed: 2227.04 samples/sec#011loss=2.655692\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] Epoch[77] Batch[10] avg_epoch_loss=2.584938\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.5000325158337975\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] Epoch[77] Batch [10]#011Speed: 1977.33 samples/sec#011loss=2.500033\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] processed a total of 4626 examples\n",
      "#metrics {\"StartTime\": 1747886096.2956924, \"EndTime\": 1747886098.8710036, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2575.2577781677246, \"count\": 1, \"min\": 2575.2577781677246, \"max\": 2575.2577781677246}}}\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.2654927358215 records/second\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] #progress_metric: host=algo-1, completed 19.5 % of epochs\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.5849377789896106\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:54:58 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_18acd0a5-6113-448e-a05a-e538c4bf2000-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886098.8710616, \"EndTime\": 1747886098.882204, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.851621627807617, \"count\": 1, \"min\": 10.851621627807617, \"max\": 10.851621627807617}}}\n",
      "[05/22/2025 03:54:59 INFO 140041726678848] Epoch[78] Batch[0] avg_epoch_loss=2.711300\n",
      "[05/22/2025 03:54:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.711299904736219\n",
      "[05/22/2025 03:55:00 INFO 140041726678848] Epoch[78] Batch[5] avg_epoch_loss=2.670223\n",
      "[05/22/2025 03:55:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.670223108644209\n",
      "[05/22/2025 03:55:00 INFO 140041726678848] Epoch[78] Batch [5]#011Speed: 2178.87 samples/sec#011loss=2.670223\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] Epoch[78] Batch[10] avg_epoch_loss=2.679940\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.6915991700306234\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] Epoch[78] Batch [10]#011Speed: 1964.67 samples/sec#011loss=2.691599\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] processed a total of 4631 examples\n",
      "#metrics {\"StartTime\": 1747886098.882255, \"EndTime\": 1747886101.496359, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2614.0520572662354, \"count\": 1, \"min\": 2614.0520572662354, \"max\": 2614.0520572662354}}}\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1771.519967312676 records/second\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] #progress_metric: host=algo-1, completed 19.75 % of epochs\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.6799395001834885\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] Epoch[79] Batch[0] avg_epoch_loss=2.655106\n",
      "[05/22/2025 03:55:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.6551062365151727\n",
      "[05/22/2025 03:55:02 INFO 140041726678848] Epoch[79] Batch[5] avg_epoch_loss=2.627417\n",
      "[05/22/2025 03:55:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.627416575317836\n",
      "[05/22/2025 03:55:02 INFO 140041726678848] Epoch[79] Batch [5]#011Speed: 2294.22 samples/sec#011loss=2.627417\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] Epoch[79] Batch[10] avg_epoch_loss=2.605323\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.5788100074819043\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] Epoch[79] Batch [10]#011Speed: 2033.45 samples/sec#011loss=2.578810\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] processed a total of 4683 examples\n",
      "#metrics {\"StartTime\": 1747886101.4964185, \"EndTime\": 1747886104.0201046, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2523.4334468841553, \"count\": 1, \"min\": 2523.4334468841553, \"max\": 2523.4334468841553}}}\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1855.743822107924 records/second\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.605322680846958\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] Epoch[80] Batch[0] avg_epoch_loss=2.655098\n",
      "[05/22/2025 03:55:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.655098352241091\n",
      "[05/22/2025 03:55:05 INFO 140041726678848] Epoch[80] Batch[5] avg_epoch_loss=2.630104\n",
      "[05/22/2025 03:55:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.6301040252934764\n",
      "[05/22/2025 03:55:05 INFO 140041726678848] Epoch[80] Batch [5]#011Speed: 2283.17 samples/sec#011loss=2.630104\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] Epoch[80] Batch[10] avg_epoch_loss=2.641123\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.65434488751044\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] Epoch[80] Batch [10]#011Speed: 2033.19 samples/sec#011loss=2.654345\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] processed a total of 4555 examples\n",
      "#metrics {\"StartTime\": 1747886104.0201616, \"EndTime\": 1747886106.5349042, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2514.4400596618652, \"count\": 1, \"min\": 2514.4400596618652, \"max\": 2514.4400596618652}}}\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1811.47142353939 records/second\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] #progress_metric: host=algo-1, completed 20.25 % of epochs\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.64112259902846\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] Epoch[81] Batch[0] avg_epoch_loss=2.615154\n",
      "[05/22/2025 03:55:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.6151544447731068\n",
      "[05/22/2025 03:55:07 INFO 140041726678848] Epoch[81] Batch[5] avg_epoch_loss=2.673076\n",
      "[05/22/2025 03:55:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.673076037751717\n",
      "[05/22/2025 03:55:07 INFO 140041726678848] Epoch[81] Batch [5]#011Speed: 2237.50 samples/sec#011loss=2.673076\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] Epoch[81] Batch[10] avg_epoch_loss=2.668208\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.662366184837834\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] Epoch[81] Batch [10]#011Speed: 2002.30 samples/sec#011loss=2.662366\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] processed a total of 4612 examples\n",
      "#metrics {\"StartTime\": 1747886106.5349672, \"EndTime\": 1747886109.0863225, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2551.0947704315186, \"count\": 1, \"min\": 2551.0947704315186, \"max\": 2551.0947704315186}}}\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1807.771050101948 records/second\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] #progress_metric: host=algo-1, completed 20.5 % of epochs\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.668207922790861\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] Epoch[82] Batch[0] avg_epoch_loss=2.653652\n",
      "[05/22/2025 03:55:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.6536517238829345\n",
      "[05/22/2025 03:55:10 INFO 140041726678848] Epoch[82] Batch[5] avg_epoch_loss=2.714064\n",
      "[05/22/2025 03:55:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.714064384975872\n",
      "[05/22/2025 03:55:10 INFO 140041726678848] Epoch[82] Batch [5]#011Speed: 2275.50 samples/sec#011loss=2.714064\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] Epoch[82] Batch[10] avg_epoch_loss=2.715445\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=2.717102295465618\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] Epoch[82] Batch [10]#011Speed: 1966.01 samples/sec#011loss=2.717102\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] processed a total of 4798 examples\n",
      "#metrics {\"StartTime\": 1747886109.0864089, \"EndTime\": 1747886111.6433535, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2556.6418170928955, \"count\": 1, \"min\": 2556.6418170928955, \"max\": 2556.6418170928955}}}\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1876.6016353928799 records/second\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] #progress_metric: host=algo-1, completed 20.75 % of epochs\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.7154452533803024\n",
      "[05/22/2025 03:55:11 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:12 INFO 140041726678848] Epoch[83] Batch[0] avg_epoch_loss=2.640444\n",
      "[05/22/2025 03:55:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.6404442054391706\n",
      "[05/22/2025 03:55:13 INFO 140041726678848] Epoch[83] Batch[5] avg_epoch_loss=2.690635\n",
      "[05/22/2025 03:55:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.6906353583049136\n",
      "[05/22/2025 03:55:13 INFO 140041726678848] Epoch[83] Batch [5]#011Speed: 2218.21 samples/sec#011loss=2.690635\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] Epoch[83] Batch[10] avg_epoch_loss=2.760798\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.8449928878410358\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] Epoch[83] Batch [10]#011Speed: 1977.19 samples/sec#011loss=2.844993\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] processed a total of 4612 examples\n",
      "#metrics {\"StartTime\": 1747886111.6434164, \"EndTime\": 1747886114.229359, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2585.1457118988037, \"count\": 1, \"min\": 2585.1457118988037, \"max\": 2585.1457118988037}}}\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1783.979142044972 records/second\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] #progress_metric: host=algo-1, completed 21.0 % of epochs\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.7607978717304236\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] Epoch[84] Batch[0] avg_epoch_loss=2.836983\n",
      "[05/22/2025 03:55:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.8369833897376115\n",
      "[05/22/2025 03:55:15 INFO 140041726678848] Epoch[84] Batch[5] avg_epoch_loss=2.837342\n",
      "[05/22/2025 03:55:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.8373420788963903\n",
      "[05/22/2025 03:55:15 INFO 140041726678848] Epoch[84] Batch [5]#011Speed: 2247.70 samples/sec#011loss=2.837342\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] Epoch[84] Batch[10] avg_epoch_loss=2.814960\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.7881024129141148\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] Epoch[84] Batch [10]#011Speed: 1884.08 samples/sec#011loss=2.788102\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] processed a total of 4719 examples\n",
      "#metrics {\"StartTime\": 1747886114.229418, \"EndTime\": 1747886116.8589542, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2629.284143447876, \"count\": 1, \"min\": 2629.284143447876, \"max\": 2629.284143447876}}}\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.7258601239837 records/second\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] #progress_metric: host=algo-1, completed 21.25 % of epochs\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.8149604125408105\n",
      "[05/22/2025 03:55:16 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:17 INFO 140041726678848] Epoch[85] Batch[0] avg_epoch_loss=2.761566\n",
      "[05/22/2025 03:55:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.761565958205735\n",
      "[05/22/2025 03:55:18 INFO 140041726678848] Epoch[85] Batch[5] avg_epoch_loss=2.847027\n",
      "[05/22/2025 03:55:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.847026912743017\n",
      "[05/22/2025 03:55:18 INFO 140041726678848] Epoch[85] Batch [5]#011Speed: 2276.53 samples/sec#011loss=2.847027\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] Epoch[85] Batch[10] avg_epoch_loss=2.769125\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=2.6756436286365535\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] Epoch[85] Batch [10]#011Speed: 2058.18 samples/sec#011loss=2.675644\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] processed a total of 4576 examples\n",
      "#metrics {\"StartTime\": 1747886116.8590124, \"EndTime\": 1747886119.37398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2514.6710872650146, \"count\": 1, \"min\": 2514.6710872650146, \"max\": 2514.6710872650146}}}\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1819.658631675262 records/second\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] #progress_metric: host=algo-1, completed 21.5 % of epochs\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.769125419967352\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] Epoch[86] Batch[0] avg_epoch_loss=2.663274\n",
      "[05/22/2025 03:55:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.6632735288488307\n",
      "[05/22/2025 03:55:20 INFO 140041726678848] Epoch[86] Batch[5] avg_epoch_loss=2.727740\n",
      "[05/22/2025 03:55:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.727739658369873\n",
      "[05/22/2025 03:55:20 INFO 140041726678848] Epoch[86] Batch [5]#011Speed: 2242.75 samples/sec#011loss=2.727740\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] Epoch[86] Batch[10] avg_epoch_loss=2.631984\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.517077555157294\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] Epoch[86] Batch [10]#011Speed: 1972.73 samples/sec#011loss=2.517078\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] processed a total of 4686 examples\n",
      "#metrics {\"StartTime\": 1747886119.374038, \"EndTime\": 1747886121.940569, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2566.2741661071777, \"count\": 1, \"min\": 2566.2741661071777, \"max\": 2566.2741661071777}}}\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1825.9317728248109 records/second\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] #progress_metric: host=algo-1, completed 21.75 % of epochs\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.63198415690961\n",
      "[05/22/2025 03:55:21 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:22 INFO 140041726678848] Epoch[87] Batch[0] avg_epoch_loss=2.656132\n",
      "[05/22/2025 03:55:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.656132007760301\n",
      "[05/22/2025 03:55:23 INFO 140041726678848] Epoch[87] Batch[5] avg_epoch_loss=2.648318\n",
      "[05/22/2025 03:55:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.6483178312192606\n",
      "[05/22/2025 03:55:23 INFO 140041726678848] Epoch[87] Batch [5]#011Speed: 2269.18 samples/sec#011loss=2.648318\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] Epoch[87] Batch[10] avg_epoch_loss=2.733702\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.836162555244293\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] Epoch[87] Batch [10]#011Speed: 2050.89 samples/sec#011loss=2.836163\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] processed a total of 4566 examples\n",
      "#metrics {\"StartTime\": 1747886121.9406278, \"EndTime\": 1747886124.463808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.927761077881, \"count\": 1, \"min\": 2522.927761077881, \"max\": 2522.927761077881}}}\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1809.7403769147445 records/second\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] #progress_metric: host=algo-1, completed 22.0 % of epochs\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.7337017966851844\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] Epoch[88] Batch[0] avg_epoch_loss=2.612507\n",
      "[05/22/2025 03:55:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.612507231782433\n",
      "[05/22/2025 03:55:25 INFO 140041726678848] Epoch[88] Batch[5] avg_epoch_loss=2.688510\n",
      "[05/22/2025 03:55:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.6885095495777653\n",
      "[05/22/2025 03:55:25 INFO 140041726678848] Epoch[88] Batch [5]#011Speed: 2277.69 samples/sec#011loss=2.688510\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] Epoch[88] Batch[10] avg_epoch_loss=2.773952\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=2.876481917281459\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] Epoch[88] Batch [10]#011Speed: 2032.95 samples/sec#011loss=2.876482\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] processed a total of 4562 examples\n",
      "#metrics {\"StartTime\": 1747886124.4638677, \"EndTime\": 1747886126.9928362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2528.7156105041504, \"count\": 1, \"min\": 2528.7156105041504, \"max\": 2528.7156105041504}}}\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1804.0146467652985 records/second\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] #progress_metric: host=algo-1, completed 22.25 % of epochs\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.773951534897626\n",
      "[05/22/2025 03:55:26 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:27 INFO 140041726678848] Epoch[89] Batch[0] avg_epoch_loss=2.643766\n",
      "[05/22/2025 03:55:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.6437662035425946\n",
      "[05/22/2025 03:55:28 INFO 140041726678848] Epoch[89] Batch[5] avg_epoch_loss=2.642149\n",
      "[05/22/2025 03:55:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.6421486133102494\n",
      "[05/22/2025 03:55:28 INFO 140041726678848] Epoch[89] Batch [5]#011Speed: 2247.54 samples/sec#011loss=2.642149\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] processed a total of 4456 examples\n",
      "#metrics {\"StartTime\": 1747886126.9928968, \"EndTime\": 1747886129.3795164, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2386.364221572876, \"count\": 1, \"min\": 2386.364221572876, \"max\": 2386.364221572876}}}\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1867.1999934462542 records/second\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] #progress_metric: host=algo-1, completed 22.5 % of epochs\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.6759632679826697\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] Epoch[90] Batch[0] avg_epoch_loss=2.630460\n",
      "[05/22/2025 03:55:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.6304599957370547\n",
      "[05/22/2025 03:55:30 INFO 140041726678848] Epoch[90] Batch[5] avg_epoch_loss=2.596529\n",
      "[05/22/2025 03:55:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.5965294331732554\n",
      "[05/22/2025 03:55:30 INFO 140041726678848] Epoch[90] Batch [5]#011Speed: 2282.39 samples/sec#011loss=2.596529\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] Epoch[90] Batch[10] avg_epoch_loss=2.569989\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.5381394418151446\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] Epoch[90] Batch [10]#011Speed: 1933.47 samples/sec#011loss=2.538139\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] processed a total of 4623 examples\n",
      "#metrics {\"StartTime\": 1747886129.3795805, \"EndTime\": 1747886131.949862, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2569.9799060821533, \"count\": 1, \"min\": 2569.9799060821533, \"max\": 2569.9799060821533}}}\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1798.784505248315 records/second\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] #progress_metric: host=algo-1, completed 22.75 % of epochs\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.569988528010478\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:55:31 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_67fed88c-162e-4f54-b4a4-4cdccd2bc970-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886131.9499228, \"EndTime\": 1747886131.9603155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.045528411865234, \"count\": 1, \"min\": 10.045528411865234, \"max\": 10.045528411865234}}}\n",
      "[05/22/2025 03:55:32 INFO 140041726678848] Epoch[91] Batch[0] avg_epoch_loss=2.626037\n",
      "[05/22/2025 03:55:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.62603691797745\n",
      "[05/22/2025 03:55:33 INFO 140041726678848] Epoch[91] Batch[5] avg_epoch_loss=2.617285\n",
      "[05/22/2025 03:55:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.6172848753160958\n",
      "[05/22/2025 03:55:33 INFO 140041726678848] Epoch[91] Batch [5]#011Speed: 2288.89 samples/sec#011loss=2.617285\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] Epoch[91] Batch[10] avg_epoch_loss=2.524127\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=2.4123367683393653\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] Epoch[91] Batch [10]#011Speed: 2028.32 samples/sec#011loss=2.412337\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] processed a total of 4557 examples\n",
      "#metrics {\"StartTime\": 1747886131.9603674, \"EndTime\": 1747886134.4832273, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.80855178833, \"count\": 1, \"min\": 2522.80855178833, \"max\": 2522.80855178833}}}\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1806.254802746865 records/second\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] #progress_metric: host=algo-1, completed 23.0 % of epochs\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.5241266448721276\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_5971f7c6-d790-42ff-ba7d-6abaf6255816-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886134.4832897, \"EndTime\": 1747886134.4938457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.254144668579102, \"count\": 1, \"min\": 10.254144668579102, \"max\": 10.254144668579102}}}\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] Epoch[92] Batch[0] avg_epoch_loss=2.696514\n",
      "[05/22/2025 03:55:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.696514172118597\n",
      "[05/22/2025 03:55:35 INFO 140041726678848] Epoch[92] Batch[5] avg_epoch_loss=2.673122\n",
      "[05/22/2025 03:55:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.673121621543244\n",
      "[05/22/2025 03:55:35 INFO 140041726678848] Epoch[92] Batch [5]#011Speed: 2279.31 samples/sec#011loss=2.673122\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] Epoch[92] Batch[10] avg_epoch_loss=2.630438\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.5792169991474108\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] Epoch[92] Batch [10]#011Speed: 2004.81 samples/sec#011loss=2.579217\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] processed a total of 4576 examples\n",
      "#metrics {\"StartTime\": 1747886134.4939005, \"EndTime\": 1747886137.0587711, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2564.818859100342, \"count\": 1, \"min\": 2564.818859100342, \"max\": 2564.818859100342}}}\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1784.0820532536331 records/second\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] #progress_metric: host=algo-1, completed 23.25 % of epochs\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.630437702272411\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] Epoch[93] Batch[0] avg_epoch_loss=2.553278\n",
      "[05/22/2025 03:55:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.553278389911609\n",
      "[05/22/2025 03:55:38 INFO 140041726678848] Epoch[93] Batch[5] avg_epoch_loss=2.581497\n",
      "[05/22/2025 03:55:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.5814971130869524\n",
      "[05/22/2025 03:55:38 INFO 140041726678848] Epoch[93] Batch [5]#011Speed: 2211.61 samples/sec#011loss=2.581497\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] Epoch[93] Batch[10] avg_epoch_loss=2.651433\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.7353555861984966\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] Epoch[93] Batch [10]#011Speed: 2017.35 samples/sec#011loss=2.735356\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] processed a total of 4496 examples\n",
      "#metrics {\"StartTime\": 1747886137.0588288, \"EndTime\": 1747886139.6169517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2557.8346252441406, \"count\": 1, \"min\": 2557.8346252441406, \"max\": 2557.8346252441406}}}\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1757.6764895368538 records/second\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] #progress_metric: host=algo-1, completed 23.5 % of epochs\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.651432782683109\n",
      "[05/22/2025 03:55:39 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:40 INFO 140041726678848] Epoch[94] Batch[0] avg_epoch_loss=2.538933\n",
      "[05/22/2025 03:55:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.5389333610279787\n",
      "[05/22/2025 03:55:41 INFO 140041726678848] Epoch[94] Batch[5] avg_epoch_loss=2.668659\n",
      "[05/22/2025 03:55:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.668659394284753\n",
      "[05/22/2025 03:55:41 INFO 140041726678848] Epoch[94] Batch [5]#011Speed: 2253.89 samples/sec#011loss=2.668659\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] Epoch[94] Batch[10] avg_epoch_loss=2.625105\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=2.572839654527422\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] Epoch[94] Batch [10]#011Speed: 1974.81 samples/sec#011loss=2.572840\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] processed a total of 4731 examples\n",
      "#metrics {\"StartTime\": 1747886139.6170115, \"EndTime\": 1747886142.194225, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2576.932430267334, \"count\": 1, \"min\": 2576.932430267334, \"max\": 2576.932430267334}}}\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1835.8387306071588 records/second\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] #progress_metric: host=algo-1, completed 23.75 % of epochs\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.62510496712233\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] Epoch[95] Batch[0] avg_epoch_loss=2.516796\n",
      "[05/22/2025 03:55:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.516796222508352\n",
      "[05/22/2025 03:55:43 INFO 140041726678848] Epoch[95] Batch[5] avg_epoch_loss=2.545486\n",
      "[05/22/2025 03:55:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.5454855099729725\n",
      "[05/22/2025 03:55:43 INFO 140041726678848] Epoch[95] Batch [5]#011Speed: 2273.72 samples/sec#011loss=2.545486\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] Epoch[95] Batch[10] avg_epoch_loss=2.475183\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.39081949688544\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] Epoch[95] Batch [10]#011Speed: 1952.51 samples/sec#011loss=2.390819\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] processed a total of 4712 examples\n",
      "#metrics {\"StartTime\": 1747886142.1942863, \"EndTime\": 1747886144.7577274, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2563.1911754608154, \"count\": 1, \"min\": 2563.1911754608154, \"max\": 2563.1911754608154}}}\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1838.272547917857 records/second\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] #progress_metric: host=algo-1, completed 24.0 % of epochs\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.4751827767513666\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:55:44 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_84a266c7-b892-4f1a-ad81-0cee33b2a6e9-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886144.7577858, \"EndTime\": 1747886144.76834, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.285377502441406, \"count\": 1, \"min\": 10.285377502441406, \"max\": 10.285377502441406}}}\n",
      "[05/22/2025 03:55:45 INFO 140041726678848] Epoch[96] Batch[0] avg_epoch_loss=2.550665\n",
      "[05/22/2025 03:55:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.550664888989421\n",
      "[05/22/2025 03:55:46 INFO 140041726678848] Epoch[96] Batch[5] avg_epoch_loss=2.603125\n",
      "[05/22/2025 03:55:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.603124583130336\n",
      "[05/22/2025 03:55:46 INFO 140041726678848] Epoch[96] Batch [5]#011Speed: 2254.99 samples/sec#011loss=2.603125\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] Epoch[96] Batch[10] avg_epoch_loss=2.708689\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.8353666241822104\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] Epoch[96] Batch [10]#011Speed: 1989.27 samples/sec#011loss=2.835367\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] processed a total of 4539 examples\n",
      "#metrics {\"StartTime\": 1747886144.7683938, \"EndTime\": 1747886147.3274841, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2559.0388774871826, \"count\": 1, \"min\": 2559.0388774871826, \"max\": 2559.0388774871826}}}\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.65380206571 records/second\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] #progress_metric: host=algo-1, completed 24.25 % of epochs\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.7086891472448245\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] Epoch[97] Batch[0] avg_epoch_loss=2.555862\n",
      "[05/22/2025 03:55:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.5558617130950725\n",
      "[05/22/2025 03:55:48 INFO 140041726678848] Epoch[97] Batch[5] avg_epoch_loss=2.637614\n",
      "[05/22/2025 03:55:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.6376136604201466\n",
      "[05/22/2025 03:55:48 INFO 140041726678848] Epoch[97] Batch [5]#011Speed: 2241.05 samples/sec#011loss=2.637614\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] Epoch[97] Batch[10] avg_epoch_loss=2.746071\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.876219670013224\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] Epoch[97] Batch [10]#011Speed: 2019.66 samples/sec#011loss=2.876220\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] processed a total of 4573 examples\n",
      "#metrics {\"StartTime\": 1747886147.327542, \"EndTime\": 1747886149.869888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.093276977539, \"count\": 1, \"min\": 2542.093276977539, \"max\": 2542.093276977539}}}\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1798.8512810162786 records/second\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 24.5 % of epochs\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.746070937507909\n",
      "[05/22/2025 03:55:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:50 INFO 140041726678848] Epoch[98] Batch[0] avg_epoch_loss=2.577486\n",
      "[05/22/2025 03:55:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.577485558184855\n",
      "[05/22/2025 03:55:51 INFO 140041726678848] Epoch[98] Batch[5] avg_epoch_loss=2.572655\n",
      "[05/22/2025 03:55:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.572654945016704\n",
      "[05/22/2025 03:55:51 INFO 140041726678848] Epoch[98] Batch [5]#011Speed: 2227.15 samples/sec#011loss=2.572655\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] Epoch[98] Batch[10] avg_epoch_loss=2.620349\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=2.677581256959911\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] Epoch[98] Batch [10]#011Speed: 2049.68 samples/sec#011loss=2.677581\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] processed a total of 4549 examples\n",
      "#metrics {\"StartTime\": 1747886149.8699455, \"EndTime\": 1747886152.4022264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2532.028913497925, \"count\": 1, \"min\": 2532.028913497925, \"max\": 2532.028913497925}}}\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.5225688991131 records/second\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] #progress_metric: host=algo-1, completed 24.75 % of epochs\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.620348723172707\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] Epoch[99] Batch[0] avg_epoch_loss=2.536207\n",
      "[05/22/2025 03:55:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.5362070334249722\n",
      "[05/22/2025 03:55:53 INFO 140041726678848] Epoch[99] Batch[5] avg_epoch_loss=2.641748\n",
      "[05/22/2025 03:55:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.641747920001624\n",
      "[05/22/2025 03:55:53 INFO 140041726678848] Epoch[99] Batch [5]#011Speed: 2246.06 samples/sec#011loss=2.641748\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] Epoch[99] Batch[10] avg_epoch_loss=2.549816\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=2.4394977391164394\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] Epoch[99] Batch [10]#011Speed: 2056.15 samples/sec#011loss=2.439498\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] processed a total of 4573 examples\n",
      "#metrics {\"StartTime\": 1747886152.4022844, \"EndTime\": 1747886154.9300654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2527.526617050171, \"count\": 1, \"min\": 2527.526617050171, \"max\": 2527.526617050171}}}\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1809.2155269235684 records/second\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 25.0 % of epochs\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.5498160195992674\n",
      "[05/22/2025 03:55:54 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:55 INFO 140041726678848] Epoch[100] Batch[0] avg_epoch_loss=2.585198\n",
      "[05/22/2025 03:55:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.5851982813369987\n",
      "[05/22/2025 03:55:56 INFO 140041726678848] Epoch[100] Batch[5] avg_epoch_loss=2.659792\n",
      "[05/22/2025 03:55:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.6597923499704206\n",
      "[05/22/2025 03:55:56 INFO 140041726678848] Epoch[100] Batch [5]#011Speed: 2266.37 samples/sec#011loss=2.659792\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] Epoch[100] Batch[10] avg_epoch_loss=2.659833\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.6598807897758907\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] Epoch[100] Batch [10]#011Speed: 2037.16 samples/sec#011loss=2.659881\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] processed a total of 4523 examples\n",
      "#metrics {\"StartTime\": 1747886154.9301248, \"EndTime\": 1747886157.4597118, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2529.332399368286, \"count\": 1, \"min\": 2529.332399368286, \"max\": 2529.332399368286}}}\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.1588942370001 records/second\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] #progress_metric: host=algo-1, completed 25.25 % of epochs\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.659832549881998\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] Epoch[101] Batch[0] avg_epoch_loss=2.735483\n",
      "[05/22/2025 03:55:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.7354826045726615\n",
      "[05/22/2025 03:55:58 INFO 140041726678848] Epoch[101] Batch[5] avg_epoch_loss=2.662055\n",
      "[05/22/2025 03:55:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.6620551366317513\n",
      "[05/22/2025 03:55:58 INFO 140041726678848] Epoch[101] Batch [5]#011Speed: 2236.10 samples/sec#011loss=2.662055\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] Epoch[101] Batch[10] avg_epoch_loss=2.697508\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=2.740050535478146\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] Epoch[101] Batch [10]#011Speed: 2046.71 samples/sec#011loss=2.740051\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] processed a total of 4581 examples\n",
      "#metrics {\"StartTime\": 1747886157.4597704, \"EndTime\": 1747886159.986422, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2526.40438079834, \"count\": 1, \"min\": 2526.40438079834, \"max\": 2526.40438079834}}}\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1813.1878271545406 records/second\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 25.5 % of epochs\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.69750759065284\n",
      "[05/22/2025 03:55:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:00 INFO 140041726678848] Epoch[102] Batch[0] avg_epoch_loss=2.665199\n",
      "[05/22/2025 03:56:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.665198922953786\n",
      "[05/22/2025 03:56:01 INFO 140041726678848] Epoch[102] Batch[5] avg_epoch_loss=2.607296\n",
      "[05/22/2025 03:56:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.607295998486219\n",
      "[05/22/2025 03:56:01 INFO 140041726678848] Epoch[102] Batch [5]#011Speed: 2155.03 samples/sec#011loss=2.607296\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] Epoch[102] Batch[10] avg_epoch_loss=2.585783\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=2.559966429304705\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] Epoch[102] Batch [10]#011Speed: 2064.69 samples/sec#011loss=2.559966\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] processed a total of 4524 examples\n",
      "#metrics {\"StartTime\": 1747886159.9864817, \"EndTime\": 1747886162.555866, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2569.1404342651367, \"count\": 1, \"min\": 2569.1404342651367, \"max\": 2569.1404342651367}}}\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1760.8399397742694 records/second\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 25.75 % of epochs\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.5857825579491673\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] Epoch[103] Batch[0] avg_epoch_loss=2.561838\n",
      "[05/22/2025 03:56:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.5618379928486914\n",
      "[05/22/2025 03:56:03 INFO 140041726678848] Epoch[103] Batch[5] avg_epoch_loss=2.574823\n",
      "[05/22/2025 03:56:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.574823392260579\n",
      "[05/22/2025 03:56:03 INFO 140041726678848] Epoch[103] Batch [5]#011Speed: 2281.90 samples/sec#011loss=2.574823\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] Epoch[103] Batch[10] avg_epoch_loss=2.591838\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.6122556962520878\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] Epoch[103] Batch [10]#011Speed: 2020.68 samples/sec#011loss=2.612256\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] processed a total of 4631 examples\n",
      "#metrics {\"StartTime\": 1747886162.5559251, \"EndTime\": 1747886165.073232, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2517.056941986084, \"count\": 1, \"min\": 2517.056941986084, \"max\": 2517.056941986084}}}\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1839.7816095546766 records/second\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] #progress_metric: host=algo-1, completed 26.0 % of epochs\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.591838075893083\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] Epoch[104] Batch[0] avg_epoch_loss=2.562786\n",
      "[05/22/2025 03:56:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.562786008839087\n",
      "[05/22/2025 03:56:06 INFO 140041726678848] Epoch[104] Batch[5] avg_epoch_loss=2.619773\n",
      "[05/22/2025 03:56:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.6197728169079437\n",
      "[05/22/2025 03:56:06 INFO 140041726678848] Epoch[104] Batch [5]#011Speed: 2259.02 samples/sec#011loss=2.619773\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] Epoch[104] Batch[10] avg_epoch_loss=2.657153\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=2.702008858661609\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] Epoch[104] Batch [10]#011Speed: 2014.77 samples/sec#011loss=2.702009\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] processed a total of 4599 examples\n",
      "#metrics {\"StartTime\": 1747886165.0732944, \"EndTime\": 1747886167.6260107, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2552.45041847229, \"count\": 1, \"min\": 2552.45041847229, \"max\": 2552.45041847229}}}\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1801.7375585086352 records/second\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 26.25 % of epochs\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.6571528358868823\n",
      "[05/22/2025 03:56:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:08 INFO 140041726678848] Epoch[105] Batch[0] avg_epoch_loss=2.473209\n",
      "[05/22/2025 03:56:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.4732092366717704\n",
      "[05/22/2025 03:56:09 INFO 140041726678848] Epoch[105] Batch[5] avg_epoch_loss=2.493332\n",
      "[05/22/2025 03:56:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.4933322150351476\n",
      "[05/22/2025 03:56:09 INFO 140041726678848] Epoch[105] Batch [5]#011Speed: 2273.29 samples/sec#011loss=2.493332\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] Epoch[105] Batch[10] avg_epoch_loss=2.466043\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.433295099135231\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] Epoch[105] Batch [10]#011Speed: 2030.35 samples/sec#011loss=2.433295\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] processed a total of 4655 examples\n",
      "#metrics {\"StartTime\": 1747886167.62607, \"EndTime\": 1747886170.1514232, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2525.0749588012695, \"count\": 1, \"min\": 2525.0749588012695, \"max\": 2525.0749588012695}}}\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1843.4460973004534 records/second\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 26.5 % of epochs\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.466042616898822\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_979c1879-04b8-4a37-bcef-69605095dd8b-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886170.1514823, \"EndTime\": 1747886170.1623468, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.590791702270508, \"count\": 1, \"min\": 10.590791702270508, \"max\": 10.590791702270508}}}\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] Epoch[106] Batch[0] avg_epoch_loss=2.502928\n",
      "[05/22/2025 03:56:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.5029280562708798\n",
      "[05/22/2025 03:56:11 INFO 140041726678848] Epoch[106] Batch[5] avg_epoch_loss=2.507579\n",
      "[05/22/2025 03:56:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.5075789170523617\n",
      "[05/22/2025 03:56:11 INFO 140041726678848] Epoch[106] Batch [5]#011Speed: 2286.19 samples/sec#011loss=2.507579\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] processed a total of 4423 examples\n",
      "#metrics {\"StartTime\": 1747886170.1623986, \"EndTime\": 1747886172.5082233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2345.7727432250977, \"count\": 1, \"min\": 2345.7727432250977, \"max\": 2345.7727432250977}}}\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1885.4421658805156 records/second\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 26.75 % of epochs\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.591900784294961\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] Epoch[107] Batch[0] avg_epoch_loss=2.499576\n",
      "[05/22/2025 03:56:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.4995764241717704\n",
      "[05/22/2025 03:56:13 INFO 140041726678848] Epoch[107] Batch[5] avg_epoch_loss=2.572090\n",
      "[05/22/2025 03:56:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.5720897241265313\n",
      "[05/22/2025 03:56:13 INFO 140041726678848] Epoch[107] Batch [5]#011Speed: 2303.20 samples/sec#011loss=2.572090\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] Epoch[107] Batch[10] avg_epoch_loss=2.640798\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.723248223047745\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] Epoch[107] Batch [10]#011Speed: 2027.31 samples/sec#011loss=2.723248\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] processed a total of 4610 examples\n",
      "#metrics {\"StartTime\": 1747886172.5082896, \"EndTime\": 1747886175.0209548, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2512.373447418213, \"count\": 1, \"min\": 2512.373447418213, \"max\": 2512.373447418213}}}\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1834.8552612350327 records/second\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 27.0 % of epochs\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.640798132727083\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] Epoch[108] Batch[0] avg_epoch_loss=2.453504\n",
      "[05/22/2025 03:56:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.453503717027422\n",
      "[05/22/2025 03:56:16 INFO 140041726678848] Epoch[108] Batch[5] avg_epoch_loss=2.487790\n",
      "[05/22/2025 03:56:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.4877902953467195\n",
      "[05/22/2025 03:56:16 INFO 140041726678848] Epoch[108] Batch [5]#011Speed: 2279.01 samples/sec#011loss=2.487790\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] Epoch[108] Batch[10] avg_epoch_loss=2.538301\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.598914743266286\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] Epoch[108] Batch [10]#011Speed: 2020.77 samples/sec#011loss=2.598915\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] processed a total of 4559 examples\n",
      "#metrics {\"StartTime\": 1747886175.0210133, \"EndTime\": 1747886177.5501454, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2528.848171234131, \"count\": 1, \"min\": 2528.848171234131, \"max\": 2528.848171234131}}}\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1802.704753640912 records/second\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] #progress_metric: host=algo-1, completed 27.25 % of epochs\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.5383014080374315\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] Epoch[109] Batch[0] avg_epoch_loss=2.523732\n",
      "[05/22/2025 03:56:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.5237319368562083\n",
      "[05/22/2025 03:56:18 INFO 140041726678848] Epoch[109] Batch[5] avg_epoch_loss=2.633583\n",
      "[05/22/2025 03:56:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.6335831651354864\n",
      "[05/22/2025 03:56:18 INFO 140041726678848] Epoch[109] Batch [5]#011Speed: 2276.25 samples/sec#011loss=2.633583\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] Epoch[109] Batch[10] avg_epoch_loss=2.580657\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.5171459580317372\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] Epoch[109] Batch [10]#011Speed: 1988.33 samples/sec#011loss=2.517146\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] processed a total of 4698 examples\n",
      "#metrics {\"StartTime\": 1747886177.5502186, \"EndTime\": 1747886180.0852327, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.688711166382, \"count\": 1, \"min\": 2534.688711166382, \"max\": 2534.688711166382}}}\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1853.417359865744 records/second\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 27.5 % of epochs\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.5806571619065095\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] Epoch[110] Batch[0] avg_epoch_loss=2.562974\n",
      "[05/22/2025 03:56:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.5629738720594375\n",
      "[05/22/2025 03:56:21 INFO 140041726678848] Epoch[110] Batch[5] avg_epoch_loss=2.539652\n",
      "[05/22/2025 03:56:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.5396518721435366\n",
      "[05/22/2025 03:56:21 INFO 140041726678848] Epoch[110] Batch [5]#011Speed: 2255.52 samples/sec#011loss=2.539652\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] Epoch[110] Batch[10] avg_epoch_loss=2.603760\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.680689618422884\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] Epoch[110] Batch [10]#011Speed: 2048.62 samples/sec#011loss=2.680690\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] processed a total of 4498 examples\n",
      "#metrics {\"StartTime\": 1747886180.085293, \"EndTime\": 1747886182.6352928, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2549.748182296753, \"count\": 1, \"min\": 2549.748182296753, \"max\": 2549.748182296753}}}\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1764.011653747304 records/second\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] #progress_metric: host=algo-1, completed 27.75 % of epochs\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.6037599386341492\n",
      "[05/22/2025 03:56:22 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:23 INFO 140041726678848] Epoch[111] Batch[0] avg_epoch_loss=2.510902\n",
      "[05/22/2025 03:56:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.510901504210746\n",
      "[05/22/2025 03:56:24 INFO 140041726678848] Epoch[111] Batch[5] avg_epoch_loss=2.483952\n",
      "[05/22/2025 03:56:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.4839522850982507\n",
      "[05/22/2025 03:56:24 INFO 140041726678848] Epoch[111] Batch [5]#011Speed: 2176.90 samples/sec#011loss=2.483952\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] Epoch[111] Batch[10] avg_epoch_loss=2.530718\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=2.5868364703681794\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] Epoch[111] Batch [10]#011Speed: 1963.84 samples/sec#011loss=2.586836\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] processed a total of 4587 examples\n",
      "#metrics {\"StartTime\": 1747886182.635387, \"EndTime\": 1747886185.2369795, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2601.3197898864746, \"count\": 1, \"min\": 2601.3197898864746, \"max\": 2601.3197898864746}}}\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1763.272975426707 records/second\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 28.0 % of epochs\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.530717823857309\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] Epoch[112] Batch[0] avg_epoch_loss=2.536052\n",
      "[05/22/2025 03:56:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.536052066658547\n",
      "[05/22/2025 03:56:26 INFO 140041726678848] Epoch[112] Batch[5] avg_epoch_loss=2.483650\n",
      "[05/22/2025 03:56:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.4836496467845213\n",
      "[05/22/2025 03:56:26 INFO 140041726678848] Epoch[112] Batch [5]#011Speed: 2230.76 samples/sec#011loss=2.483650\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] Epoch[112] Batch[10] avg_epoch_loss=2.466578\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.446092635326768\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] Epoch[112] Batch [10]#011Speed: 1990.65 samples/sec#011loss=2.446093\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] processed a total of 4691 examples\n",
      "#metrics {\"StartTime\": 1747886185.2370431, \"EndTime\": 1747886187.7984703, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2561.0876083374023, \"count\": 1, \"min\": 2561.0876083374023, \"max\": 2561.0876083374023}}}\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1831.5698776429467 records/second\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] #progress_metric: host=algo-1, completed 28.25 % of epochs\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.466578277940088\n",
      "[05/22/2025 03:56:27 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:28 INFO 140041726678848] Epoch[113] Batch[0] avg_epoch_loss=2.476687\n",
      "[05/22/2025 03:56:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.4766870171561806\n",
      "[05/22/2025 03:56:29 INFO 140041726678848] Epoch[113] Batch[5] avg_epoch_loss=2.463489\n",
      "[05/22/2025 03:56:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.463489195463298\n",
      "[05/22/2025 03:56:29 INFO 140041726678848] Epoch[113] Batch [5]#011Speed: 2302.36 samples/sec#011loss=2.463489\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] Epoch[113] Batch[10] avg_epoch_loss=2.550477\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.654862259013085\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] Epoch[113] Batch [10]#011Speed: 2002.63 samples/sec#011loss=2.654862\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] processed a total of 4603 examples\n",
      "#metrics {\"StartTime\": 1747886187.7985437, \"EndTime\": 1747886190.3182106, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2519.4151401519775, \"count\": 1, \"min\": 2519.4151401519775, \"max\": 2519.4151401519775}}}\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1826.9480503491866 records/second\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 28.5 % of epochs\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.550476951622292\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] Epoch[114] Batch[0] avg_epoch_loss=2.484623\n",
      "[05/22/2025 03:56:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.484622946826281\n",
      "[05/22/2025 03:56:31 INFO 140041726678848] Epoch[114] Batch[5] avg_epoch_loss=2.544760\n",
      "[05/22/2025 03:56:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.5447603380051733\n",
      "[05/22/2025 03:56:31 INFO 140041726678848] Epoch[114] Batch [5]#011Speed: 2244.70 samples/sec#011loss=2.544760\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] Epoch[114] Batch[10] avg_epoch_loss=2.573477\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=2.6079373977763085\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] Epoch[114] Batch [10]#011Speed: 2021.21 samples/sec#011loss=2.607937\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] processed a total of 4637 examples\n",
      "#metrics {\"StartTime\": 1747886190.3182693, \"EndTime\": 1747886192.8698146, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2551.262140274048, \"count\": 1, \"min\": 2551.262140274048, \"max\": 2551.262140274048}}}\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1817.470798218655 records/second\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] #progress_metric: host=algo-1, completed 28.75 % of epochs\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.5734771833556893\n",
      "[05/22/2025 03:56:32 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:33 INFO 140041726678848] Epoch[115] Batch[0] avg_epoch_loss=2.458391\n",
      "[05/22/2025 03:56:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.4583908794717426\n",
      "[05/22/2025 03:56:34 INFO 140041726678848] Epoch[115] Batch[5] avg_epoch_loss=2.440297\n",
      "[05/22/2025 03:56:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.4402970595101383\n",
      "[05/22/2025 03:56:34 INFO 140041726678848] Epoch[115] Batch [5]#011Speed: 2209.68 samples/sec#011loss=2.440297\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] processed a total of 4427 examples\n",
      "#metrics {\"StartTime\": 1747886192.869872, \"EndTime\": 1747886195.2582653, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2388.144016265869, \"count\": 1, \"min\": 2388.144016265869, \"max\": 2388.144016265869}}}\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1853.6688121213247 records/second\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] #progress_metric: host=algo-1, completed 29.0 % of epochs\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.454100692511136\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_1d64495a-e395-4cef-9f40-849854f19aad-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886195.258328, \"EndTime\": 1747886195.269224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.536909103393555, \"count\": 1, \"min\": 10.536909103393555, \"max\": 10.536909103393555}}}\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] Epoch[116] Batch[0] avg_epoch_loss=2.429065\n",
      "[05/22/2025 03:56:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.429064642347578\n",
      "[05/22/2025 03:56:36 INFO 140041726678848] Epoch[116] Batch[5] avg_epoch_loss=2.534806\n",
      "[05/22/2025 03:56:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.5348058529225828\n",
      "[05/22/2025 03:56:36 INFO 140041726678848] Epoch[116] Batch [5]#011Speed: 2219.71 samples/sec#011loss=2.534806\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] Epoch[116] Batch[10] avg_epoch_loss=2.586175\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=2.647816926068346\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] Epoch[116] Batch [10]#011Speed: 1950.62 samples/sec#011loss=2.647817\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] processed a total of 4649 examples\n",
      "#metrics {\"StartTime\": 1747886195.269273, \"EndTime\": 1747886197.8729696, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2603.6462783813477, \"count\": 1, \"min\": 2603.6462783813477, \"max\": 2603.6462783813477}}}\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1785.5137854259447 records/second\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] #progress_metric: host=algo-1, completed 29.25 % of epochs\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.5861745225342934\n",
      "[05/22/2025 03:56:37 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:38 INFO 140041726678848] Epoch[117] Batch[0] avg_epoch_loss=2.487937\n",
      "[05/22/2025 03:56:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.4879373325271437\n",
      "[05/22/2025 03:56:39 INFO 140041726678848] Epoch[117] Batch[5] avg_epoch_loss=2.437657\n",
      "[05/22/2025 03:56:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.4376569604909055\n",
      "[05/22/2025 03:56:39 INFO 140041726678848] Epoch[117] Batch [5]#011Speed: 2298.43 samples/sec#011loss=2.437657\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] Epoch[117] Batch[10] avg_epoch_loss=2.488544\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.549608450636832\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] Epoch[117] Batch [10]#011Speed: 2037.97 samples/sec#011loss=2.549608\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] processed a total of 4529 examples\n",
      "#metrics {\"StartTime\": 1747886197.8730288, \"EndTime\": 1747886200.3970602, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2523.7767696380615, \"count\": 1, \"min\": 2523.7767696380615, \"max\": 2523.7767696380615}}}\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.4661016372754 records/second\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] #progress_metric: host=algo-1, completed 29.5 % of epochs\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.4885440014663267\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] Epoch[118] Batch[0] avg_epoch_loss=2.584655\n",
      "[05/22/2025 03:56:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.5846545382969097\n",
      "[05/22/2025 03:56:41 INFO 140041726678848] Epoch[118] Batch[5] avg_epoch_loss=2.585593\n",
      "[05/22/2025 03:56:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.5855929481602637\n",
      "[05/22/2025 03:56:41 INFO 140041726678848] Epoch[118] Batch [5]#011Speed: 2223.26 samples/sec#011loss=2.585593\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] Epoch[118] Batch[10] avg_epoch_loss=2.592738\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.601312758821687\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] Epoch[118] Batch [10]#011Speed: 2045.97 samples/sec#011loss=2.601313\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] processed a total of 4567 examples\n",
      "#metrics {\"StartTime\": 1747886200.397123, \"EndTime\": 1747886202.9331446, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2535.6481075286865, \"count\": 1, \"min\": 2535.6481075286865, \"max\": 2535.6481075286865}}}\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1801.0517222850244 records/second\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] #progress_metric: host=algo-1, completed 29.75 % of epochs\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.5927383166427287\n",
      "[05/22/2025 03:56:42 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:43 INFO 140041726678848] Epoch[119] Batch[0] avg_epoch_loss=2.511971\n",
      "[05/22/2025 03:56:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.511970774899081\n",
      "[05/22/2025 03:56:44 INFO 140041726678848] Epoch[119] Batch[5] avg_epoch_loss=2.503728\n",
      "[05/22/2025 03:56:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.5037278116590107\n",
      "[05/22/2025 03:56:44 INFO 140041726678848] Epoch[119] Batch [5]#011Speed: 2276.87 samples/sec#011loss=2.503728\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] Epoch[119] Batch[10] avg_epoch_loss=2.436321\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=2.3554318842218818\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] Epoch[119] Batch [10]#011Speed: 1943.16 samples/sec#011loss=2.355432\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] processed a total of 4692 examples\n",
      "#metrics {\"StartTime\": 1747886202.9332054, \"EndTime\": 1747886205.4992363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2565.7734870910645, \"count\": 1, \"min\": 2565.7734870910645, \"max\": 2565.7734870910645}}}\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1828.6252764238634 records/second\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] #progress_metric: host=algo-1, completed 30.0 % of epochs\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.4363205719148615\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_6d7fa614-1138-4c93-b0d9-c2ee125fe6cf-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886205.4992967, \"EndTime\": 1747886205.510397, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.796546936035156, \"count\": 1, \"min\": 10.796546936035156, \"max\": 10.796546936035156}}}\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] Epoch[120] Batch[0] avg_epoch_loss=2.433695\n",
      "[05/22/2025 03:56:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.4336948862054566\n",
      "[05/22/2025 03:56:46 INFO 140041726678848] Epoch[120] Batch[5] avg_epoch_loss=2.409278\n",
      "[05/22/2025 03:56:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.409277742494896\n",
      "[05/22/2025 03:56:46 INFO 140041726678848] Epoch[120] Batch [5]#011Speed: 2247.59 samples/sec#011loss=2.409278\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] Epoch[120] Batch[10] avg_epoch_loss=2.507548\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=2.6254733283163976\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] Epoch[120] Batch [10]#011Speed: 2002.91 samples/sec#011loss=2.625473\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] processed a total of 4562 examples\n",
      "#metrics {\"StartTime\": 1747886205.51045, \"EndTime\": 1747886208.062288, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2551.786184310913, \"count\": 1, \"min\": 2551.786184310913, \"max\": 2551.786184310913}}}\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1787.707543964142 records/second\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] #progress_metric: host=algo-1, completed 30.25 % of epochs\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.507548463322851\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] Epoch[121] Batch[0] avg_epoch_loss=2.527487\n",
      "[05/22/2025 03:56:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.5274867544195434\n",
      "[05/22/2025 03:56:49 INFO 140041726678848] Epoch[121] Batch[5] avg_epoch_loss=2.570689\n",
      "[05/22/2025 03:56:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.5706890873671817\n",
      "[05/22/2025 03:56:49 INFO 140041726678848] Epoch[121] Batch [5]#011Speed: 2264.53 samples/sec#011loss=2.570689\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] Epoch[121] Batch[10] avg_epoch_loss=2.618911\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=2.676778094115395\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] Epoch[121] Batch [10]#011Speed: 2013.33 samples/sec#011loss=2.676778\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] processed a total of 4651 examples\n",
      "#metrics {\"StartTime\": 1747886208.0623457, \"EndTime\": 1747886210.6030602, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2540.4176712036133, \"count\": 1, \"min\": 2540.4176712036133, \"max\": 2540.4176712036133}}}\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1830.7360202048412 records/second\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] #progress_metric: host=algo-1, completed 30.5 % of epochs\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.6189113631618244\n",
      "[05/22/2025 03:56:50 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:51 INFO 140041726678848] Epoch[122] Batch[0] avg_epoch_loss=2.461295\n",
      "[05/22/2025 03:56:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.4612947391773385\n",
      "[05/22/2025 03:56:52 INFO 140041726678848] Epoch[122] Batch[5] avg_epoch_loss=2.554026\n",
      "[05/22/2025 03:56:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.554025945967892\n",
      "[05/22/2025 03:56:52 INFO 140041726678848] Epoch[122] Batch [5]#011Speed: 2272.52 samples/sec#011loss=2.554026\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] Epoch[122] Batch[10] avg_epoch_loss=2.461090\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=2.349566908668569\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] Epoch[122] Batch [10]#011Speed: 1960.92 samples/sec#011loss=2.349567\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] processed a total of 4656 examples\n",
      "#metrics {\"StartTime\": 1747886210.6031215, \"EndTime\": 1747886213.1597424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2556.335210800171, \"count\": 1, \"min\": 2556.335210800171, \"max\": 2556.335210800171}}}\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1821.2962279831386 records/second\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] #progress_metric: host=algo-1, completed 30.75 % of epochs\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.461090019922745\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] Epoch[123] Batch[0] avg_epoch_loss=2.547620\n",
      "[05/22/2025 03:56:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.547619656093402\n",
      "[05/22/2025 03:56:54 INFO 140041726678848] Epoch[123] Batch[5] avg_epoch_loss=2.487128\n",
      "[05/22/2025 03:56:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.487128061635811\n",
      "[05/22/2025 03:56:54 INFO 140041726678848] Epoch[123] Batch [5]#011Speed: 2272.43 samples/sec#011loss=2.487128\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] Epoch[123] Batch[10] avg_epoch_loss=2.392380\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=2.278681548188683\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] Epoch[123] Batch [10]#011Speed: 2030.41 samples/sec#011loss=2.278682\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] processed a total of 4640 examples\n",
      "#metrics {\"StartTime\": 1747886213.1598005, \"EndTime\": 1747886215.6825814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.489070892334, \"count\": 1, \"min\": 2522.489070892334, \"max\": 2522.489070892334}}}\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1839.3886388261526 records/second\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] #progress_metric: host=algo-1, completed 31.0 % of epochs\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.392379646432571\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:56:55 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_d55dd34f-a2ba-4263-8295-b32d96eb93b4-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886215.6826413, \"EndTime\": 1747886215.6930084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.099172592163086, \"count\": 1, \"min\": 10.099172592163086, \"max\": 10.099172592163086}}}\n",
      "[05/22/2025 03:56:56 INFO 140041726678848] Epoch[124] Batch[0] avg_epoch_loss=2.396659\n",
      "[05/22/2025 03:56:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.3966589165158685\n",
      "[05/22/2025 03:56:57 INFO 140041726678848] Epoch[124] Batch[5] avg_epoch_loss=2.402287\n",
      "[05/22/2025 03:56:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.4022870194761508\n",
      "[05/22/2025 03:56:57 INFO 140041726678848] Epoch[124] Batch [5]#011Speed: 2286.43 samples/sec#011loss=2.402287\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] Epoch[124] Batch[10] avg_epoch_loss=2.417422\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=2.435583523280902\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] Epoch[124] Batch [10]#011Speed: 1975.01 samples/sec#011loss=2.435584\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] processed a total of 4703 examples\n",
      "#metrics {\"StartTime\": 1747886215.6930633, \"EndTime\": 1747886218.231984, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2538.867950439453, \"count\": 1, \"min\": 2538.867950439453, \"max\": 2538.867950439453}}}\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1852.3369061696856 records/second\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] #progress_metric: host=algo-1, completed 31.25 % of epochs\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.417421793932856\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] Epoch[125] Batch[0] avg_epoch_loss=2.538808\n",
      "[05/22/2025 03:56:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.5388080282572383\n",
      "[05/22/2025 03:56:59 INFO 140041726678848] Epoch[125] Batch[5] avg_epoch_loss=2.510003\n",
      "[05/22/2025 03:56:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.510003286020439\n",
      "[05/22/2025 03:56:59 INFO 140041726678848] Epoch[125] Batch [5]#011Speed: 2255.99 samples/sec#011loss=2.510003\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] Epoch[125] Batch[10] avg_epoch_loss=2.424945\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=2.32287584062674\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] Epoch[125] Batch [10]#011Speed: 1993.37 samples/sec#011loss=2.322876\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] processed a total of 4541 examples\n",
      "#metrics {\"StartTime\": 1747886218.2320428, \"EndTime\": 1747886220.7745323, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.234182357788, \"count\": 1, \"min\": 2542.234182357788, \"max\": 2542.234182357788}}}\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.1597895658253 records/second\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] #progress_metric: host=algo-1, completed 31.5 % of epochs\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.42494535629603\n",
      "[05/22/2025 03:57:00 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:01 INFO 140041726678848] Epoch[126] Batch[0] avg_epoch_loss=2.523755\n",
      "[05/22/2025 03:57:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.523754774063892\n",
      "[05/22/2025 03:57:02 INFO 140041726678848] Epoch[126] Batch[5] avg_epoch_loss=2.553108\n",
      "[05/22/2025 03:57:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.553108379587741\n",
      "[05/22/2025 03:57:02 INFO 140041726678848] Epoch[126] Batch [5]#011Speed: 2250.13 samples/sec#011loss=2.553108\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] Epoch[126] Batch[10] avg_epoch_loss=2.633953\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=2.7309656767643373\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] Epoch[126] Batch [10]#011Speed: 1996.94 samples/sec#011loss=2.730966\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] processed a total of 4697 examples\n",
      "#metrics {\"StartTime\": 1747886220.7745943, \"EndTime\": 1747886223.3219438, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2546.9894409179688, \"count\": 1, \"min\": 2546.9894409179688, \"max\": 2546.9894409179688}}}\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1844.0723990913607 records/second\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] #progress_metric: host=algo-1, completed 31.75 % of epochs\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.633952605577103\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] Epoch[127] Batch[0] avg_epoch_loss=2.491777\n",
      "[05/22/2025 03:57:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.4917772458762526\n",
      "[05/22/2025 03:57:04 INFO 140041726678848] Epoch[127] Batch[5] avg_epoch_loss=2.564333\n",
      "[05/22/2025 03:57:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.56433304841198\n",
      "[05/22/2025 03:57:04 INFO 140041726678848] Epoch[127] Batch [5]#011Speed: 2250.40 samples/sec#011loss=2.564333\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] Epoch[127] Batch[10] avg_epoch_loss=2.556149\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=2.5463283207474943\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] Epoch[127] Batch [10]#011Speed: 1967.62 samples/sec#011loss=2.546328\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] processed a total of 4641 examples\n",
      "#metrics {\"StartTime\": 1747886223.322001, \"EndTime\": 1747886225.891034, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2568.7124729156494, \"count\": 1, \"min\": 2568.7124729156494, \"max\": 2568.7124729156494}}}\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1806.6845410496198 records/second\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] #progress_metric: host=algo-1, completed 32.0 % of epochs\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.5561490812917596\n",
      "[05/22/2025 03:57:05 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:06 INFO 140041726678848] Epoch[128] Batch[0] avg_epoch_loss=2.480115\n",
      "[05/22/2025 03:57:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.480114501409382\n",
      "[05/22/2025 03:57:07 INFO 140041726678848] Epoch[128] Batch[5] avg_epoch_loss=2.437706\n",
      "[05/22/2025 03:57:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.4377057161168336\n",
      "[05/22/2025 03:57:07 INFO 140041726678848] Epoch[128] Batch [5]#011Speed: 2235.92 samples/sec#011loss=2.437706\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] Epoch[128] Batch[10] avg_epoch_loss=2.448918\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=2.4623724922570993\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] Epoch[128] Batch [10]#011Speed: 2026.77 samples/sec#011loss=2.462372\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] processed a total of 4566 examples\n",
      "#metrics {\"StartTime\": 1747886225.8910868, \"EndTime\": 1747886228.4419117, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2550.5359172821045, \"count\": 1, \"min\": 2550.5359172821045, \"max\": 2550.5359172821045}}}\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1790.1107597374094 records/second\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] #progress_metric: host=algo-1, completed 32.25 % of epochs\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.4489178870896815\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] Epoch[129] Batch[0] avg_epoch_loss=2.372604\n",
      "[05/22/2025 03:57:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.372603996293847\n",
      "[05/22/2025 03:57:09 INFO 140041726678848] Epoch[129] Batch[5] avg_epoch_loss=2.485529\n",
      "[05/22/2025 03:57:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.485529411786029\n",
      "[05/22/2025 03:57:09 INFO 140041726678848] Epoch[129] Batch [5]#011Speed: 2259.08 samples/sec#011loss=2.485529\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] Epoch[129] Batch[10] avg_epoch_loss=2.404272\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=2.30676296718402\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] Epoch[129] Batch [10]#011Speed: 1994.43 samples/sec#011loss=2.306763\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] processed a total of 4556 examples\n",
      "#metrics {\"StartTime\": 1747886228.4420247, \"EndTime\": 1747886230.9896383, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2547.307014465332, \"count\": 1, \"min\": 2547.307014465332, \"max\": 2547.307014465332}}}\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.4925703978715 records/second\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 32.5 % of epochs\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.4042719369669343\n",
      "[05/22/2025 03:57:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:11 INFO 140041726678848] Epoch[130] Batch[0] avg_epoch_loss=2.411401\n",
      "[05/22/2025 03:57:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.411401149690284\n",
      "[05/22/2025 03:57:12 INFO 140041726678848] Epoch[130] Batch[5] avg_epoch_loss=2.371448\n",
      "[05/22/2025 03:57:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.371448225150218\n",
      "[05/22/2025 03:57:12 INFO 140041726678848] Epoch[130] Batch [5]#011Speed: 2188.08 samples/sec#011loss=2.371448\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] Epoch[130] Batch[10] avg_epoch_loss=2.331212\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=2.282928018208867\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] Epoch[130] Batch [10]#011Speed: 2026.38 samples/sec#011loss=2.282928\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] processed a total of 4578 examples\n",
      "#metrics {\"StartTime\": 1747886230.9896991, \"EndTime\": 1747886233.559296, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2569.29874420166, \"count\": 1, \"min\": 2569.29874420166, \"max\": 2569.29874420166}}}\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1781.729949589395 records/second\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] #progress_metric: host=algo-1, completed 32.75 % of epochs\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.331211767449604\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:57:13 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_ca454f7c-5452-4c0c-ba6a-8e0214c8ecfd-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886233.5593812, \"EndTime\": 1747886233.5703459, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.68568229675293, \"count\": 1, \"min\": 10.68568229675293, \"max\": 10.68568229675293}}}\n",
      "[05/22/2025 03:57:14 INFO 140041726678848] Epoch[131] Batch[0] avg_epoch_loss=2.377934\n",
      "[05/22/2025 03:57:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.3779343093158407\n",
      "[05/22/2025 03:57:14 INFO 140041726678848] Epoch[131] Batch[5] avg_epoch_loss=2.347467\n",
      "[05/22/2025 03:57:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.347467072733969\n",
      "[05/22/2025 03:57:14 INFO 140041726678848] Epoch[131] Batch [5]#011Speed: 2274.15 samples/sec#011loss=2.347467\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] Epoch[131] Batch[10] avg_epoch_loss=2.490040\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=2.661126885700863\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] Epoch[131] Batch [10]#011Speed: 2022.83 samples/sec#011loss=2.661127\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] processed a total of 4643 examples\n",
      "#metrics {\"StartTime\": 1747886233.5703962, \"EndTime\": 1747886236.1004183, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2529.9718379974365, \"count\": 1, \"min\": 2529.9718379974365, \"max\": 2529.9718379974365}}}\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1835.1336145599564 records/second\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] #progress_metric: host=algo-1, completed 33.0 % of epochs\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.490039714991648\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] Epoch[132] Batch[0] avg_epoch_loss=2.416108\n",
      "[05/22/2025 03:57:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.416107517573775\n",
      "[05/22/2025 03:57:17 INFO 140041726678848] Epoch[132] Batch[5] avg_epoch_loss=2.501582\n",
      "[05/22/2025 03:57:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.5015819750632193\n",
      "[05/22/2025 03:57:17 INFO 140041726678848] Epoch[132] Batch [5]#011Speed: 2276.88 samples/sec#011loss=2.501582\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] Epoch[132] Batch[10] avg_epoch_loss=2.562521\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=2.635648881194321\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] Epoch[132] Batch [10]#011Speed: 2023.46 samples/sec#011loss=2.635649\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] processed a total of 4613 examples\n",
      "#metrics {\"StartTime\": 1747886236.1004786, \"EndTime\": 1747886238.623259, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.5281715393066, \"count\": 1, \"min\": 2522.5281715393066, \"max\": 2522.5281715393066}}}\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1828.644856998929 records/second\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] #progress_metric: host=algo-1, completed 33.25 % of epochs\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.5625214778500833\n",
      "[05/22/2025 03:57:18 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:19 INFO 140041726678848] Epoch[133] Batch[0] avg_epoch_loss=2.387518\n",
      "[05/22/2025 03:57:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.387517508525891\n",
      "[05/22/2025 03:57:20 INFO 140041726678848] Epoch[133] Batch[5] avg_epoch_loss=2.530757\n",
      "[05/22/2025 03:57:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.5307571875579993\n",
      "[05/22/2025 03:57:20 INFO 140041726678848] Epoch[133] Batch [5]#011Speed: 2264.20 samples/sec#011loss=2.530757\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] processed a total of 4484 examples\n",
      "#metrics {\"StartTime\": 1747886238.6233346, \"EndTime\": 1747886241.020033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2396.365165710449, \"count\": 1, \"min\": 2396.365165710449, \"max\": 2396.365165710449}}}\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1871.092779533848 records/second\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] #progress_metric: host=algo-1, completed 33.5 % of epochs\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.474232778570434\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] Epoch[134] Batch[0] avg_epoch_loss=2.363325\n",
      "[05/22/2025 03:57:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.3633252931862474\n",
      "[05/22/2025 03:57:22 INFO 140041726678848] Epoch[134] Batch[5] avg_epoch_loss=2.367450\n",
      "[05/22/2025 03:57:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.367450173200283\n",
      "[05/22/2025 03:57:22 INFO 140041726678848] Epoch[134] Batch [5]#011Speed: 2273.13 samples/sec#011loss=2.367450\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] Epoch[134] Batch[10] avg_epoch_loss=2.404033\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.4479319820956293\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] Epoch[134] Batch [10]#011Speed: 1978.68 samples/sec#011loss=2.447932\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] processed a total of 4593 examples\n",
      "#metrics {\"StartTime\": 1747886241.0200965, \"EndTime\": 1747886243.575521, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2555.13072013855, \"count\": 1, \"min\": 2555.13072013855, \"max\": 2555.13072013855}}}\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1797.498476490479 records/second\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 33.75 % of epochs\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.4040328136072584\n",
      "[05/22/2025 03:57:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:24 INFO 140041726678848] Epoch[135] Batch[0] avg_epoch_loss=2.397218\n",
      "[05/22/2025 03:57:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.3972178843610803\n",
      "[05/22/2025 03:57:25 INFO 140041726678848] Epoch[135] Batch[5] avg_epoch_loss=2.399963\n",
      "[05/22/2025 03:57:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.3999625632916897\n",
      "[05/22/2025 03:57:25 INFO 140041726678848] Epoch[135] Batch [5]#011Speed: 2238.76 samples/sec#011loss=2.399963\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] Epoch[135] Batch[10] avg_epoch_loss=2.468971\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=2.551781030327812\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] Epoch[135] Batch [10]#011Speed: 1999.98 samples/sec#011loss=2.551781\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] processed a total of 4642 examples\n",
      "#metrics {\"StartTime\": 1747886243.5755801, \"EndTime\": 1747886246.1329813, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2557.1515560150146, \"count\": 1, \"min\": 2557.1515560150146, \"max\": 2557.1515560150146}}}\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1815.2388049084086 records/second\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] #progress_metric: host=algo-1, completed 34.0 % of epochs\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.468970957399018\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] Epoch[136] Batch[0] avg_epoch_loss=2.368310\n",
      "[05/22/2025 03:57:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.368310057506264\n",
      "[05/22/2025 03:57:27 INFO 140041726678848] Epoch[136] Batch[5] avg_epoch_loss=2.379589\n",
      "[05/22/2025 03:57:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.3795887834510716\n",
      "[05/22/2025 03:57:27 INFO 140041726678848] Epoch[136] Batch [5]#011Speed: 2263.84 samples/sec#011loss=2.379589\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] Epoch[136] Batch[10] avg_epoch_loss=2.448466\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=2.5311197191675947\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] Epoch[136] Batch [10]#011Speed: 2040.98 samples/sec#011loss=2.531120\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] processed a total of 4532 examples\n",
      "#metrics {\"StartTime\": 1747886246.133041, \"EndTime\": 1747886248.6618524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2528.557538986206, \"count\": 1, \"min\": 2528.557538986206, \"max\": 2528.557538986206}}}\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1792.2613362363652 records/second\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 34.25 % of epochs\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.448466481504037\n",
      "[05/22/2025 03:57:28 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:29 INFO 140041726678848] Epoch[137] Batch[0] avg_epoch_loss=2.352606\n",
      "[05/22/2025 03:57:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.352605671022411\n",
      "[05/22/2025 03:57:30 INFO 140041726678848] Epoch[137] Batch[5] avg_epoch_loss=2.391588\n",
      "[05/22/2025 03:57:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.391587697052478\n",
      "[05/22/2025 03:57:30 INFO 140041726678848] Epoch[137] Batch [5]#011Speed: 2259.78 samples/sec#011loss=2.391588\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] Epoch[137] Batch[10] avg_epoch_loss=2.467626\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=2.5588724726823497\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] Epoch[137] Batch [10]#011Speed: 2033.34 samples/sec#011loss=2.558872\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] processed a total of 4567 examples\n",
      "#metrics {\"StartTime\": 1747886248.6619153, \"EndTime\": 1747886251.2275693, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2565.350294113159, \"count\": 1, \"min\": 2565.350294113159, \"max\": 2565.350294113159}}}\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1780.1804779430283 records/second\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] #progress_metric: host=algo-1, completed 34.5 % of epochs\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.4676262314296924\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] Epoch[138] Batch[0] avg_epoch_loss=2.417905\n",
      "[05/22/2025 03:57:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.4179051320643095\n",
      "[05/22/2025 03:57:32 INFO 140041726678848] Epoch[138] Batch[5] avg_epoch_loss=2.399348\n",
      "[05/22/2025 03:57:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.399347544601429\n",
      "[05/22/2025 03:57:32 INFO 140041726678848] Epoch[138] Batch [5]#011Speed: 2266.25 samples/sec#011loss=2.399348\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] Epoch[138] Batch[10] avg_epoch_loss=2.458058\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.528509861323775\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] Epoch[138] Batch [10]#011Speed: 2019.44 samples/sec#011loss=2.528510\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] processed a total of 4554 examples\n",
      "#metrics {\"StartTime\": 1747886251.22766, \"EndTime\": 1747886253.7700741, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.1266555786133, \"count\": 1, \"min\": 2542.1266555786133, \"max\": 2542.1266555786133}}}\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1791.3513341965195 records/second\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 34.75 % of epochs\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.458057688566132\n",
      "[05/22/2025 03:57:33 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:34 INFO 140041726678848] Epoch[139] Batch[0] avg_epoch_loss=2.353017\n",
      "[05/22/2025 03:57:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.3530170126322383\n",
      "[05/22/2025 03:57:35 INFO 140041726678848] Epoch[139] Batch[5] avg_epoch_loss=2.426891\n",
      "[05/22/2025 03:57:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.426891120168662\n",
      "[05/22/2025 03:57:35 INFO 140041726678848] Epoch[139] Batch [5]#011Speed: 2097.57 samples/sec#011loss=2.426891\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] Epoch[139] Batch[10] avg_epoch_loss=2.556661\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=2.712385270218541\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] Epoch[139] Batch [10]#011Speed: 1981.80 samples/sec#011loss=2.712385\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] processed a total of 4624 examples\n",
      "#metrics {\"StartTime\": 1747886253.7701344, \"EndTime\": 1747886256.4016125, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2631.2265396118164, \"count\": 1, \"min\": 2631.2265396118164, \"max\": 2631.2265396118164}}}\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1757.2959431024424 records/second\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 35.0 % of epochs\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.5566611883731523\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] Epoch[140] Batch[0] avg_epoch_loss=2.624928\n",
      "[05/22/2025 03:57:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.6249284977902283\n",
      "[05/22/2025 03:57:37 INFO 140041726678848] Epoch[140] Batch[5] avg_epoch_loss=2.600696\n",
      "[05/22/2025 03:57:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.600695547034498\n",
      "[05/22/2025 03:57:37 INFO 140041726678848] Epoch[140] Batch [5]#011Speed: 2295.47 samples/sec#011loss=2.600696\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] Epoch[140] Batch[10] avg_epoch_loss=2.551340\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=2.4921131159521157\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] Epoch[140] Batch [10]#011Speed: 2013.76 samples/sec#011loss=2.492113\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] processed a total of 4579 examples\n",
      "#metrics {\"StartTime\": 1747886256.401672, \"EndTime\": 1747886258.9224718, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2520.5440521240234, \"count\": 1, \"min\": 2520.5440521240234, \"max\": 2520.5440521240234}}}\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1816.6077059121867 records/second\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 35.25 % of epochs\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.551339896542506\n",
      "[05/22/2025 03:57:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:39 INFO 140041726678848] Epoch[141] Batch[0] avg_epoch_loss=2.535085\n",
      "[05/22/2025 03:57:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.5350847477902283\n",
      "[05/22/2025 03:57:40 INFO 140041726678848] Epoch[141] Batch[5] avg_epoch_loss=2.478133\n",
      "[05/22/2025 03:57:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.4781330111474573\n",
      "[05/22/2025 03:57:40 INFO 140041726678848] Epoch[141] Batch [5]#011Speed: 2270.23 samples/sec#011loss=2.478133\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] Epoch[141] Batch[10] avg_epoch_loss=2.591714\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=2.7280109227101894\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] Epoch[141] Batch [10]#011Speed: 1979.16 samples/sec#011loss=2.728011\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] processed a total of 4693 examples\n",
      "#metrics {\"StartTime\": 1747886258.9225323, \"EndTime\": 1747886261.4932172, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2570.424795150757, \"count\": 1, \"min\": 2570.424795150757, \"max\": 2570.424795150757}}}\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1825.6983196117517 records/second\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 35.5 % of epochs\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.5917138800396082\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] Epoch[142] Batch[0] avg_epoch_loss=2.428561\n",
      "[05/22/2025 03:57:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.4285614081639757\n",
      "[05/22/2025 03:57:42 INFO 140041726678848] Epoch[142] Batch[5] avg_epoch_loss=2.417518\n",
      "[05/22/2025 03:57:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.417517669836326\n",
      "[05/22/2025 03:57:42 INFO 140041726678848] Epoch[142] Batch [5]#011Speed: 2252.30 samples/sec#011loss=2.417518\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] Epoch[142] Batch[10] avg_epoch_loss=2.330217\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=2.2254564722821546\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] Epoch[142] Batch [10]#011Speed: 2023.12 samples/sec#011loss=2.225456\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] processed a total of 4599 examples\n",
      "#metrics {\"StartTime\": 1747886261.493285, \"EndTime\": 1747886264.033086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2539.4515991210938, \"count\": 1, \"min\": 2539.4515991210938, \"max\": 2539.4515991210938}}}\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.9580226523672 records/second\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] #progress_metric: host=algo-1, completed 35.75 % of epochs\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.330217125493521\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_775fae88-f743-4072-b1be-7f406890834f-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886264.0331464, \"EndTime\": 1747886264.0442657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.84446907043457, \"count\": 1, \"min\": 10.84446907043457, \"max\": 10.84446907043457}}}\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] Epoch[143] Batch[0] avg_epoch_loss=2.336717\n",
      "[05/22/2025 03:57:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.3367166837764475\n",
      "[05/22/2025 03:57:45 INFO 140041726678848] Epoch[143] Batch[5] avg_epoch_loss=2.456225\n",
      "[05/22/2025 03:57:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.456225332190748\n",
      "[05/22/2025 03:57:45 INFO 140041726678848] Epoch[143] Batch [5]#011Speed: 2288.60 samples/sec#011loss=2.456225\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] Epoch[143] Batch[10] avg_epoch_loss=2.446751\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=2.435381495554357\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] Epoch[143] Batch [10]#011Speed: 1976.81 samples/sec#011loss=2.435381\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] processed a total of 4674 examples\n",
      "#metrics {\"StartTime\": 1747886264.0443192, \"EndTime\": 1747886266.5875294, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2543.1575775146484, \"count\": 1, \"min\": 2543.1575775146484, \"max\": 2543.1575775146484}}}\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1837.809342031944 records/second\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 36.0 % of epochs\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.4467508609923883\n",
      "[05/22/2025 03:57:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:47 INFO 140041726678848] Epoch[144] Batch[0] avg_epoch_loss=2.324071\n",
      "[05/22/2025 03:57:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.3240705800215755\n",
      "[05/22/2025 03:57:47 INFO 140041726678848] Epoch[144] Batch[5] avg_epoch_loss=2.345777\n",
      "[05/22/2025 03:57:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.3457773006130522\n",
      "[05/22/2025 03:57:47 INFO 140041726678848] Epoch[144] Batch [5]#011Speed: 2283.99 samples/sec#011loss=2.345777\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] Epoch[144] Batch[10] avg_epoch_loss=2.389159\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=2.441217571165089\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] Epoch[144] Batch [10]#011Speed: 2024.83 samples/sec#011loss=2.441218\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] processed a total of 4569 examples\n",
      "#metrics {\"StartTime\": 1747886266.5875902, \"EndTime\": 1747886269.103412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2515.566349029541, \"count\": 1, \"min\": 2515.566349029541, \"max\": 2515.566349029541}}}\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1816.2286518836202 records/second\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 36.25 % of epochs\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.389159241773069\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] Epoch[145] Batch[0] avg_epoch_loss=2.390622\n",
      "[05/22/2025 03:57:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.3906220094132795\n",
      "[05/22/2025 03:57:50 INFO 140041726678848] Epoch[145] Batch[5] avg_epoch_loss=2.466208\n",
      "[05/22/2025 03:57:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.4662078653518233\n",
      "[05/22/2025 03:57:50 INFO 140041726678848] Epoch[145] Batch [5]#011Speed: 2243.78 samples/sec#011loss=2.466208\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] processed a total of 4459 examples\n",
      "#metrics {\"StartTime\": 1747886269.1034713, \"EndTime\": 1747886271.5460577, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2442.326307296753, \"count\": 1, \"min\": 2442.326307296753, \"max\": 2442.326307296753}}}\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1825.6472587863368 records/second\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 36.5 % of epochs\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.428204277735245\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] Epoch[146] Batch[0] avg_epoch_loss=2.395186\n",
      "[05/22/2025 03:57:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.3951856447487474\n",
      "[05/22/2025 03:57:53 INFO 140041726678848] Epoch[146] Batch[5] avg_epoch_loss=2.339390\n",
      "[05/22/2025 03:57:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.3393896339376856\n",
      "[05/22/2025 03:57:53 INFO 140041726678848] Epoch[146] Batch [5]#011Speed: 2154.28 samples/sec#011loss=2.339390\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] Epoch[146] Batch[10] avg_epoch_loss=2.303116\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=2.2595867335398108\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] Epoch[146] Batch [10]#011Speed: 2008.35 samples/sec#011loss=2.259587\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] processed a total of 4530 examples\n",
      "#metrics {\"StartTime\": 1747886271.546122, \"EndTime\": 1747886274.1423612, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2595.909357070923, \"count\": 1, \"min\": 2595.909357070923, \"max\": 2595.909357070923}}}\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1744.995210037843 records/second\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 36.75 % of epochs\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.303115588302288\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_d3c5f3f3-a30b-4ec3-a341-4cfe2e5f33ca-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886274.1424205, \"EndTime\": 1747886274.1528268, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.142326354980469, \"count\": 1, \"min\": 10.142326354980469, \"max\": 10.142326354980469}}}\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] Epoch[147] Batch[0] avg_epoch_loss=2.320619\n",
      "[05/22/2025 03:57:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=2.32061944294613\n",
      "[05/22/2025 03:57:55 INFO 140041726678848] Epoch[147] Batch[5] avg_epoch_loss=2.341309\n",
      "[05/22/2025 03:57:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=2.34130877499768\n",
      "[05/22/2025 03:57:55 INFO 140041726678848] Epoch[147] Batch [5]#011Speed: 2250.12 samples/sec#011loss=2.341309\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] Epoch[147] Batch[10] avg_epoch_loss=2.366586\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=2.396917683828647\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] Epoch[147] Batch [10]#011Speed: 2008.33 samples/sec#011loss=2.396918\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] processed a total of 4520 examples\n",
      "#metrics {\"StartTime\": 1747886274.1528757, \"EndTime\": 1747886276.7015643, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.6385822296143, \"count\": 1, \"min\": 2548.6385822296143, \"max\": 2548.6385822296143}}}\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.4310032519638 records/second\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 37.0 % of epochs\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.366585551739029\n",
      "[05/22/2025 03:57:56 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:57 INFO 140041726678848] Epoch[148] Batch[0] avg_epoch_loss=2.343230\n",
      "[05/22/2025 03:57:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.343229909782155\n",
      "[05/22/2025 03:57:58 INFO 140041726678848] Epoch[148] Batch[5] avg_epoch_loss=2.318303\n",
      "[05/22/2025 03:57:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.3183031429072707\n",
      "[05/22/2025 03:57:58 INFO 140041726678848] Epoch[148] Batch [5]#011Speed: 2311.23 samples/sec#011loss=2.318303\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] Epoch[148] Batch[10] avg_epoch_loss=2.343569\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=2.37388834454169\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] Epoch[148] Batch [10]#011Speed: 2011.51 samples/sec#011loss=2.373888\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] processed a total of 4643 examples\n",
      "#metrics {\"StartTime\": 1747886276.7016296, \"EndTime\": 1747886279.2156496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2513.7391090393066, \"count\": 1, \"min\": 2513.7391090393066, \"max\": 2513.7391090393066}}}\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1846.9835831825096 records/second\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 37.25 % of epochs\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.3435691436501886\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] Epoch[149] Batch[0] avg_epoch_loss=2.447253\n",
      "[05/22/2025 03:57:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.447253390781598\n",
      "[05/22/2025 03:58:00 INFO 140041726678848] Epoch[149] Batch[5] avg_epoch_loss=2.408223\n",
      "[05/22/2025 03:58:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.408222563813683\n",
      "[05/22/2025 03:58:00 INFO 140041726678848] Epoch[149] Batch [5]#011Speed: 2283.34 samples/sec#011loss=2.408223\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] Epoch[149] Batch[10] avg_epoch_loss=2.573564\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=2.771972710624304\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] Epoch[149] Batch [10]#011Speed: 1823.93 samples/sec#011loss=2.771973\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] processed a total of 4668 examples\n",
      "#metrics {\"StartTime\": 1747886279.215712, \"EndTime\": 1747886281.8676622, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2651.6966819763184, \"count\": 1, \"min\": 2651.6966819763184, \"max\": 2651.6966819763184}}}\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1760.3244080318004 records/second\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] #progress_metric: host=algo-1, completed 37.5 % of epochs\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.5735635396366927\n",
      "[05/22/2025 03:58:01 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:02 INFO 140041726678848] Epoch[150] Batch[0] avg_epoch_loss=2.587040\n",
      "[05/22/2025 03:58:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.5870404827568207\n",
      "[05/22/2025 03:58:03 INFO 140041726678848] Epoch[150] Batch[5] avg_epoch_loss=2.572142\n",
      "[05/22/2025 03:58:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.5721424672014197\n",
      "[05/22/2025 03:58:03 INFO 140041726678848] Epoch[150] Batch [5]#011Speed: 2258.10 samples/sec#011loss=2.572142\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] Epoch[150] Batch[10] avg_epoch_loss=2.486849\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=2.3844961459493317\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] Epoch[150] Batch [10]#011Speed: 2033.27 samples/sec#011loss=2.384496\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] processed a total of 4581 examples\n",
      "#metrics {\"StartTime\": 1747886281.8677213, \"EndTime\": 1747886284.398283, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2530.311346054077, \"count\": 1, \"min\": 2530.311346054077, \"max\": 2530.311346054077}}}\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.3959174639674 records/second\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 37.75 % of epochs\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.486848684814107\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] Epoch[151] Batch[0] avg_epoch_loss=2.567582\n",
      "[05/22/2025 03:58:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.5675820943241927\n",
      "[05/22/2025 03:58:05 INFO 140041726678848] Epoch[151] Batch[5] avg_epoch_loss=2.437797\n",
      "[05/22/2025 03:58:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.4377966571402885\n",
      "[05/22/2025 03:58:05 INFO 140041726678848] Epoch[151] Batch [5]#011Speed: 2214.16 samples/sec#011loss=2.437797\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] Epoch[151] Batch[10] avg_epoch_loss=2.400330\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=2.3553695440823357\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] Epoch[151] Batch [10]#011Speed: 2010.81 samples/sec#011loss=2.355370\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] processed a total of 4603 examples\n",
      "#metrics {\"StartTime\": 1747886284.3983335, \"EndTime\": 1747886286.9595098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2560.8856678009033, \"count\": 1, \"min\": 2560.8856678009033, \"max\": 2560.8856678009033}}}\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1797.3353407184675 records/second\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] #progress_metric: host=algo-1, completed 38.0 % of epochs\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.400329787568492\n",
      "[05/22/2025 03:58:06 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:07 INFO 140041726678848] Epoch[152] Batch[0] avg_epoch_loss=2.450338\n",
      "[05/22/2025 03:58:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.4503383169195434\n",
      "[05/22/2025 03:58:08 INFO 140041726678848] Epoch[152] Batch[5] avg_epoch_loss=2.529229\n",
      "[05/22/2025 03:58:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.529229314927269\n",
      "[05/22/2025 03:58:08 INFO 140041726678848] Epoch[152] Batch [5]#011Speed: 2270.72 samples/sec#011loss=2.529229\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] Epoch[152] Batch[10] avg_epoch_loss=2.557858\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=2.5922127840513642\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] Epoch[152] Batch [10]#011Speed: 2056.17 samples/sec#011loss=2.592213\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] processed a total of 4588 examples\n",
      "#metrics {\"StartTime\": 1747886286.9596076, \"EndTime\": 1747886289.4816575, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2521.7843055725098, \"count\": 1, \"min\": 2521.7843055725098, \"max\": 2521.7843055725098}}}\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1819.2825614892286 records/second\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] #progress_metric: host=algo-1, completed 38.25 % of epochs\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.5578581645291303\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] Epoch[153] Batch[0] avg_epoch_loss=2.480253\n",
      "[05/22/2025 03:58:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.4802526121415647\n",
      "[05/22/2025 03:58:10 INFO 140041726678848] Epoch[153] Batch[5] avg_epoch_loss=2.563698\n",
      "[05/22/2025 03:58:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.563697503421956\n",
      "[05/22/2025 03:58:10 INFO 140041726678848] Epoch[153] Batch [5]#011Speed: 2254.94 samples/sec#011loss=2.563698\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] Epoch[153] Batch[10] avg_epoch_loss=2.595509\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=2.6336824344898386\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] Epoch[153] Batch [10]#011Speed: 1922.22 samples/sec#011loss=2.633682\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] processed a total of 4662 examples\n",
      "#metrics {\"StartTime\": 1747886289.481717, \"EndTime\": 1747886292.0953975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2613.4214401245117, \"count\": 1, \"min\": 2613.4214401245117, \"max\": 2613.4214401245117}}}\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1783.7927587512038 records/second\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 38.5 % of epochs\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.595508835725539\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] Epoch[154] Batch[0] avg_epoch_loss=2.464652\n",
      "[05/22/2025 03:58:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.4646523524498885\n",
      "[05/22/2025 03:58:13 INFO 140041726678848] Epoch[154] Batch[5] avg_epoch_loss=2.567210\n",
      "[05/22/2025 03:58:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.5672102647086117\n",
      "[05/22/2025 03:58:13 INFO 140041726678848] Epoch[154] Batch [5]#011Speed: 2207.96 samples/sec#011loss=2.567210\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] Epoch[154] Batch[10] avg_epoch_loss=2.555399\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=2.5412254010648665\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] Epoch[154] Batch [10]#011Speed: 2024.77 samples/sec#011loss=2.541225\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] processed a total of 4611 examples\n",
      "#metrics {\"StartTime\": 1747886292.095479, \"EndTime\": 1747886294.6544938, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2558.729410171509, \"count\": 1, \"min\": 2558.729410171509, \"max\": 2558.729410171509}}}\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1802.0034864317724 records/second\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] #progress_metric: host=algo-1, completed 38.75 % of epochs\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.555398963052364\n",
      "[05/22/2025 03:58:14 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:15 INFO 140041726678848] Epoch[155] Batch[0] avg_epoch_loss=2.532463\n",
      "[05/22/2025 03:58:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.5324633625939588\n",
      "[05/22/2025 03:58:16 INFO 140041726678848] Epoch[155] Batch[5] avg_epoch_loss=2.494310\n",
      "[05/22/2025 03:58:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.494310363452348\n",
      "[05/22/2025 03:58:16 INFO 140041726678848] Epoch[155] Batch [5]#011Speed: 2252.34 samples/sec#011loss=2.494310\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] Epoch[155] Batch[10] avg_epoch_loss=2.487012\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=2.478252942737333\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] Epoch[155] Batch [10]#011Speed: 1994.78 samples/sec#011loss=2.478253\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] processed a total of 4654 examples\n",
      "#metrics {\"StartTime\": 1747886294.6545558, \"EndTime\": 1747886297.2318747, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2576.9991874694824, \"count\": 1, \"min\": 2576.9991874694824, \"max\": 2576.9991874694824}}}\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1805.9135215297858 records/second\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] #progress_metric: host=algo-1, completed 39.0 % of epochs\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.487011535854614\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] Epoch[156] Batch[0] avg_epoch_loss=2.333759\n",
      "[05/22/2025 03:58:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.333758721638363\n",
      "[05/22/2025 03:58:18 INFO 140041726678848] Epoch[156] Batch[5] avg_epoch_loss=2.464123\n",
      "[05/22/2025 03:58:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.464123381095722\n",
      "[05/22/2025 03:58:18 INFO 140041726678848] Epoch[156] Batch [5]#011Speed: 2181.08 samples/sec#011loss=2.464123\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] Epoch[156] Batch[10] avg_epoch_loss=2.477163\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=2.49281128201559\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] Epoch[156] Batch [10]#011Speed: 1969.48 samples/sec#011loss=2.492811\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] processed a total of 4557 examples\n",
      "#metrics {\"StartTime\": 1747886297.2319357, \"EndTime\": 1747886299.8302572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2598.0615615844727, \"count\": 1, \"min\": 2598.0615615844727, \"max\": 2598.0615615844727}}}\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1753.94142028428 records/second\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] #progress_metric: host=algo-1, completed 39.25 % of epochs\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.4771633360592986\n",
      "[05/22/2025 03:58:19 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:20 INFO 140041726678848] Epoch[157] Batch[0] avg_epoch_loss=2.282409\n",
      "[05/22/2025 03:58:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.2824087164184297\n",
      "[05/22/2025 03:58:21 INFO 140041726678848] Epoch[157] Batch[5] avg_epoch_loss=2.314213\n",
      "[05/22/2025 03:58:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.3142127226084006\n",
      "[05/22/2025 03:58:21 INFO 140041726678848] Epoch[157] Batch [5]#011Speed: 2274.23 samples/sec#011loss=2.314213\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] Epoch[157] Batch[10] avg_epoch_loss=2.338036\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=2.366624454081988\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] Epoch[157] Batch [10]#011Speed: 1946.40 samples/sec#011loss=2.366624\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] processed a total of 4687 examples\n",
      "#metrics {\"StartTime\": 1747886299.8303158, \"EndTime\": 1747886302.406239, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2575.6731033325195, \"count\": 1, \"min\": 2575.6731033325195, \"max\": 2575.6731033325195}}}\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1819.6588745694687 records/second\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] #progress_metric: host=algo-1, completed 39.5 % of epochs\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.3380362369145766\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] Epoch[158] Batch[0] avg_epoch_loss=2.301254\n",
      "[05/22/2025 03:58:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.3012540345733576\n",
      "[05/22/2025 03:58:23 INFO 140041726678848] Epoch[158] Batch[5] avg_epoch_loss=2.337236\n",
      "[05/22/2025 03:58:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.3372363208750926\n",
      "[05/22/2025 03:58:23 INFO 140041726678848] Epoch[158] Batch [5]#011Speed: 2279.19 samples/sec#011loss=2.337236\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] Epoch[158] Batch[10] avg_epoch_loss=2.438829\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=2.5607402300250555\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] Epoch[158] Batch [10]#011Speed: 1981.07 samples/sec#011loss=2.560740\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] processed a total of 4684 examples\n",
      "#metrics {\"StartTime\": 1747886302.4062974, \"EndTime\": 1747886304.9634526, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2556.90598487854, \"count\": 1, \"min\": 2556.90598487854, \"max\": 2556.90598487854}}}\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1831.8386775932327 records/second\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] #progress_metric: host=algo-1, completed 39.75 % of epochs\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.4388290068523486\n",
      "[05/22/2025 03:58:24 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:25 INFO 140041726678848] Epoch[159] Batch[0] avg_epoch_loss=2.285080\n",
      "[05/22/2025 03:58:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.2850798541028676\n",
      "[05/22/2025 03:58:26 INFO 140041726678848] Epoch[159] Batch[5] avg_epoch_loss=2.343099\n",
      "[05/22/2025 03:58:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.3430992755167734\n",
      "[05/22/2025 03:58:26 INFO 140041726678848] Epoch[159] Batch [5]#011Speed: 2276.18 samples/sec#011loss=2.343099\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] Epoch[159] Batch[10] avg_epoch_loss=2.327259\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=2.3082502403344236\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] Epoch[159] Batch [10]#011Speed: 2025.73 samples/sec#011loss=2.308250\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] processed a total of 4652 examples\n",
      "#metrics {\"StartTime\": 1747886304.9635134, \"EndTime\": 1747886307.4868953, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2523.0298042297363, \"count\": 1, \"min\": 2523.0298042297363, \"max\": 2523.0298042297363}}}\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1843.7276338001418 records/second\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] #progress_metric: host=algo-1, completed 40.0 % of epochs\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.327258804979342\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] Epoch[160] Batch[0] avg_epoch_loss=2.298074\n",
      "[05/22/2025 03:58:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.2980744971464366\n",
      "[05/22/2025 03:58:28 INFO 140041726678848] Epoch[160] Batch[5] avg_epoch_loss=2.414221\n",
      "[05/22/2025 03:58:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.414220593288906\n",
      "[05/22/2025 03:58:28 INFO 140041726678848] Epoch[160] Batch [5]#011Speed: 2304.70 samples/sec#011loss=2.414221\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] Epoch[160] Batch[10] avg_epoch_loss=2.380640\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=2.340343612976754\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] Epoch[160] Batch [10]#011Speed: 2037.44 samples/sec#011loss=2.340344\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] processed a total of 4603 examples\n",
      "#metrics {\"StartTime\": 1747886307.486985, \"EndTime\": 1747886310.002331, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2515.0749683380127, \"count\": 1, \"min\": 2515.0749683380127, \"max\": 2515.0749683380127}}}\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1830.1013315416276 records/second\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 40.25 % of epochs\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.380640147692473\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] Epoch[161] Batch[0] avg_epoch_loss=2.320380\n",
      "[05/22/2025 03:58:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.320379924136971\n",
      "[05/22/2025 03:58:31 INFO 140041726678848] Epoch[161] Batch[5] avg_epoch_loss=2.396386\n",
      "[05/22/2025 03:58:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.396385640326304\n",
      "[05/22/2025 03:58:31 INFO 140041726678848] Epoch[161] Batch [5]#011Speed: 2228.81 samples/sec#011loss=2.396386\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] Epoch[161] Batch[10] avg_epoch_loss=2.329386\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=2.248985511422954\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] Epoch[161] Batch [10]#011Speed: 2053.88 samples/sec#011loss=2.248986\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] processed a total of 4492 examples\n",
      "#metrics {\"StartTime\": 1747886310.0023904, \"EndTime\": 1747886312.535879, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2533.1883430480957, \"count\": 1, \"min\": 2533.1883430480957, \"max\": 2533.1883430480957}}}\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.1984689035924 records/second\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] #progress_metric: host=algo-1, completed 40.5 % of epochs\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.329385581733872\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] Epoch[162] Batch[0] avg_epoch_loss=2.289526\n",
      "[05/22/2025 03:58:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.2895260409416758\n",
      "[05/22/2025 03:58:33 INFO 140041726678848] Epoch[162] Batch[5] avg_epoch_loss=2.296795\n",
      "[05/22/2025 03:58:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.296794684621787\n",
      "[05/22/2025 03:58:33 INFO 140041726678848] Epoch[162] Batch [5]#011Speed: 2262.11 samples/sec#011loss=2.296795\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] processed a total of 4458 examples\n",
      "#metrics {\"StartTime\": 1747886312.5359378, \"EndTime\": 1747886314.9081178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2371.882915496826, \"count\": 1, \"min\": 2371.882915496826, \"max\": 2371.882915496826}}}\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1879.4442294323856 records/second\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] #progress_metric: host=algo-1, completed 40.75 % of epochs\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.2968481798745475\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:58:34 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_2a342124-fb1b-41e3-9aa1-3abae1e8db9c-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886314.9081817, \"EndTime\": 1747886314.91954, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.00778579711914, \"count\": 1, \"min\": 11.00778579711914, \"max\": 11.00778579711914}}}\n",
      "[05/22/2025 03:58:35 INFO 140041726678848] Epoch[163] Batch[0] avg_epoch_loss=2.264567\n",
      "[05/22/2025 03:58:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.2645672838512665\n",
      "[05/22/2025 03:58:36 INFO 140041726678848] Epoch[163] Batch[5] avg_epoch_loss=2.263344\n",
      "[05/22/2025 03:58:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.2633438166991464\n",
      "[05/22/2025 03:58:36 INFO 140041726678848] Epoch[163] Batch [5]#011Speed: 2264.00 samples/sec#011loss=2.263344\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] Epoch[163] Batch[10] avg_epoch_loss=2.171475\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=2.061232861219376\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] Epoch[163] Batch [10]#011Speed: 2034.03 samples/sec#011loss=2.061233\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] processed a total of 4589 examples\n",
      "#metrics {\"StartTime\": 1747886314.9195852, \"EndTime\": 1747886317.4448187, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2525.1853466033936, \"count\": 1, \"min\": 2525.1853466033936, \"max\": 2525.1853466033936}}}\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1817.2280040068847 records/second\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] #progress_metric: host=algo-1, completed 41.0 % of epochs\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.171475200571978\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_0c747134-0291-4237-805a-d6075a1f67e2-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886317.4448788, \"EndTime\": 1747886317.4557412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.581254959106445, \"count\": 1, \"min\": 10.581254959106445, \"max\": 10.581254959106445}}}\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] Epoch[164] Batch[0] avg_epoch_loss=2.216451\n",
      "[05/22/2025 03:58:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.2164509184907435\n",
      "[05/22/2025 03:58:38 INFO 140041726678848] Epoch[164] Batch[5] avg_epoch_loss=2.362040\n",
      "[05/22/2025 03:58:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.3620404283825165\n",
      "[05/22/2025 03:58:38 INFO 140041726678848] Epoch[164] Batch [5]#011Speed: 2262.37 samples/sec#011loss=2.362040\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] Epoch[164] Batch[10] avg_epoch_loss=2.249069\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=2.1135033962190284\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] Epoch[164] Batch [10]#011Speed: 2073.81 samples/sec#011loss=2.113503\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] processed a total of 4519 examples\n",
      "#metrics {\"StartTime\": 1747886317.455793, \"EndTime\": 1747886319.9663115, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2510.4668140411377, \"count\": 1, \"min\": 2510.4668140411377, \"max\": 2510.4668140411377}}}\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1800.0000357073905 records/second\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] #progress_metric: host=algo-1, completed 41.25 % of epochs\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.2490690501263857\n",
      "[05/22/2025 03:58:39 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:40 INFO 140041726678848] Epoch[165] Batch[0] avg_epoch_loss=2.270510\n",
      "[05/22/2025 03:58:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.2705098515364\n",
      "[05/22/2025 03:58:41 INFO 140041726678848] Epoch[165] Batch[5] avg_epoch_loss=2.242770\n",
      "[05/22/2025 03:58:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.2427703019151353\n",
      "[05/22/2025 03:58:41 INFO 140041726678848] Epoch[165] Batch [5]#011Speed: 2209.96 samples/sec#011loss=2.242770\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] Epoch[165] Batch[10] avg_epoch_loss=2.384433\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=2.5544279170726614\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] Epoch[165] Batch [10]#011Speed: 2013.24 samples/sec#011loss=2.554428\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] processed a total of 4544 examples\n",
      "#metrics {\"StartTime\": 1747886319.9663708, \"EndTime\": 1747886322.5261884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2559.5641136169434, \"count\": 1, \"min\": 2559.5641136169434, \"max\": 2559.5641136169434}}}\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1775.2414247522206 records/second\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] #progress_metric: host=algo-1, completed 41.5 % of epochs\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.3844328542594653\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] Epoch[166] Batch[0] avg_epoch_loss=2.283518\n",
      "[05/22/2025 03:58:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.2835184959632517\n",
      "[05/22/2025 03:58:43 INFO 140041726678848] Epoch[166] Batch[5] avg_epoch_loss=2.238686\n",
      "[05/22/2025 03:58:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.2386856588860664\n",
      "[05/22/2025 03:58:43 INFO 140041726678848] Epoch[166] Batch [5]#011Speed: 2198.77 samples/sec#011loss=2.238686\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] Epoch[166] Batch[10] avg_epoch_loss=2.239009\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=2.2393965757238306\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] Epoch[166] Batch [10]#011Speed: 1999.94 samples/sec#011loss=2.239397\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] processed a total of 4532 examples\n",
      "#metrics {\"StartTime\": 1747886322.5262465, \"EndTime\": 1747886325.0980093, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2571.5060234069824, \"count\": 1, \"min\": 2571.5060234069824, \"max\": 2571.5060234069824}}}\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1762.333028587428 records/second\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] #progress_metric: host=algo-1, completed 41.75 % of epochs\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.239008802903232\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] Epoch[167] Batch[0] avg_epoch_loss=2.234433\n",
      "[05/22/2025 03:58:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=2.2344331805052895\n",
      "[05/22/2025 03:58:46 INFO 140041726678848] Epoch[167] Batch[5] avg_epoch_loss=2.361281\n",
      "[05/22/2025 03:58:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.361280502172072\n",
      "[05/22/2025 03:58:46 INFO 140041726678848] Epoch[167] Batch [5]#011Speed: 2249.98 samples/sec#011loss=2.361281\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] Epoch[167] Batch[10] avg_epoch_loss=2.447581\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=2.551142621624443\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] Epoch[167] Batch [10]#011Speed: 1940.09 samples/sec#011loss=2.551143\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] processed a total of 4647 examples\n",
      "#metrics {\"StartTime\": 1747886325.0980668, \"EndTime\": 1747886327.6963975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2598.102569580078, \"count\": 1, \"min\": 2598.102569580078, \"max\": 2598.102569580078}}}\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.5548861922264 records/second\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] #progress_metric: host=algo-1, completed 42.0 % of epochs\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.4475814655595136\n",
      "[05/22/2025 03:58:47 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:48 INFO 140041726678848] Epoch[168] Batch[0] avg_epoch_loss=2.229743\n",
      "[05/22/2025 03:58:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.229742581169961\n",
      "[05/22/2025 03:58:49 INFO 140041726678848] Epoch[168] Batch[5] avg_epoch_loss=2.246868\n",
      "[05/22/2025 03:58:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.2468677455616066\n",
      "[05/22/2025 03:58:49 INFO 140041726678848] Epoch[168] Batch [5]#011Speed: 2291.37 samples/sec#011loss=2.246868\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] Epoch[168] Batch[10] avg_epoch_loss=2.168423\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=2.074290143461164\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] Epoch[168] Batch [10]#011Speed: 1982.24 samples/sec#011loss=2.074290\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] processed a total of 4673 examples\n",
      "#metrics {\"StartTime\": 1747886327.6964555, \"EndTime\": 1747886330.245658, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.898696899414, \"count\": 1, \"min\": 2548.898696899414, \"max\": 2548.898696899414}}}\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1833.2785617804668 records/second\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] #progress_metric: host=algo-1, completed 42.25 % of epochs\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.1684233809704963\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_778e7b9b-cc95-4fcb-a964-75b27fc30727-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886330.2457159, \"EndTime\": 1747886330.2566876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.700702667236328, \"count\": 1, \"min\": 10.700702667236328, \"max\": 10.700702667236328}}}\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] Epoch[169] Batch[0] avg_epoch_loss=2.231558\n",
      "[05/22/2025 03:58:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.2315584110523385\n",
      "[05/22/2025 03:58:51 INFO 140041726678848] Epoch[169] Batch[5] avg_epoch_loss=2.244715\n",
      "[05/22/2025 03:58:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.244714500466894\n",
      "[05/22/2025 03:58:51 INFO 140041726678848] Epoch[169] Batch [5]#011Speed: 1914.27 samples/sec#011loss=2.244715\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] Epoch[169] Batch[10] avg_epoch_loss=2.302724\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.3723364747181237\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] Epoch[169] Batch [10]#011Speed: 1847.37 samples/sec#011loss=2.372336\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] processed a total of 4573 examples\n",
      "#metrics {\"StartTime\": 1747886330.2567382, \"EndTime\": 1747886333.12975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2872.9591369628906, \"count\": 1, \"min\": 2872.9591369628906, \"max\": 2872.9591369628906}}}\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1591.6888180274896 records/second\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] #progress_metric: host=algo-1, completed 42.5 % of epochs\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.3027244887629075\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] Epoch[170] Batch[0] avg_epoch_loss=2.339475\n",
      "[05/22/2025 03:58:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.3394748203472995\n",
      "[05/22/2025 03:58:54 INFO 140041726678848] Epoch[170] Batch[5] avg_epoch_loss=2.329258\n",
      "[05/22/2025 03:58:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.3292576620644256\n",
      "[05/22/2025 03:58:54 INFO 140041726678848] Epoch[170] Batch [5]#011Speed: 2213.10 samples/sec#011loss=2.329258\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] Epoch[170] Batch[10] avg_epoch_loss=2.495568\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=2.695140949070852\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] Epoch[170] Batch [10]#011Speed: 1979.30 samples/sec#011loss=2.695141\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] processed a total of 4515 examples\n",
      "#metrics {\"StartTime\": 1747886333.129811, \"EndTime\": 1747886335.7121813, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2582.1142196655273, \"count\": 1, \"min\": 2582.1142196655273, \"max\": 2582.1142196655273}}}\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1748.5062446972909 records/second\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] #progress_metric: host=algo-1, completed 42.75 % of epochs\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.4955682470673466\n",
      "[05/22/2025 03:58:55 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:56 INFO 140041726678848] Epoch[171] Batch[0] avg_epoch_loss=2.556953\n",
      "[05/22/2025 03:58:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.556953277248051\n",
      "[05/22/2025 03:58:57 INFO 140041726678848] Epoch[171] Batch[5] avg_epoch_loss=2.687788\n",
      "[05/22/2025 03:58:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.6877883197470074\n",
      "[05/22/2025 03:58:57 INFO 140041726678848] Epoch[171] Batch [5]#011Speed: 2171.50 samples/sec#011loss=2.687788\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] Epoch[171] Batch[10] avg_epoch_loss=2.730209\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=2.7811144448601057\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] Epoch[171] Batch [10]#011Speed: 2000.24 samples/sec#011loss=2.781114\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] processed a total of 4604 examples\n",
      "#metrics {\"StartTime\": 1747886335.7122428, \"EndTime\": 1747886338.3041625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2591.6671752929688, \"count\": 1, \"min\": 2591.6671752929688, \"max\": 2591.6671752929688}}}\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1776.4040064397554 records/second\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] #progress_metric: host=algo-1, completed 43.0 % of epochs\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.7302092857075064\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] Epoch[172] Batch[0] avg_epoch_loss=2.470966\n",
      "[05/22/2025 03:58:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.4709660247598833\n",
      "[05/22/2025 03:58:59 INFO 140041726678848] Epoch[172] Batch[5] avg_epoch_loss=2.506643\n",
      "[05/22/2025 03:58:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.5066425915373283\n",
      "[05/22/2025 03:58:59 INFO 140041726678848] Epoch[172] Batch [5]#011Speed: 2243.85 samples/sec#011loss=2.506643\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] Epoch[172] Batch[10] avg_epoch_loss=2.555645\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=2.614446817580735\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] Epoch[172] Batch [10]#011Speed: 1998.42 samples/sec#011loss=2.614447\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] processed a total of 4556 examples\n",
      "#metrics {\"StartTime\": 1747886338.304222, \"EndTime\": 1747886340.863406, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2558.9303970336914, \"count\": 1, \"min\": 2558.9303970336914, \"max\": 2558.9303970336914}}}\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1780.3708426217966 records/second\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] #progress_metric: host=algo-1, completed 43.25 % of epochs\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.5556445124661495\n",
      "[05/22/2025 03:59:00 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:01 INFO 140041726678848] Epoch[173] Batch[0] avg_epoch_loss=2.372348\n",
      "[05/22/2025 03:59:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.3723476214504453\n",
      "[05/22/2025 03:59:02 INFO 140041726678848] Epoch[173] Batch[5] avg_epoch_loss=2.366395\n",
      "[05/22/2025 03:59:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.3663948132713903\n",
      "[05/22/2025 03:59:02 INFO 140041726678848] Epoch[173] Batch [5]#011Speed: 2183.44 samples/sec#011loss=2.366395\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] Epoch[173] Batch[10] avg_epoch_loss=2.372409\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=2.37962496955039\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] Epoch[173] Batch [10]#011Speed: 1997.76 samples/sec#011loss=2.379625\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] processed a total of 4637 examples\n",
      "#metrics {\"StartTime\": 1747886340.8634653, \"EndTime\": 1747886343.459238, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2595.5135822296143, \"count\": 1, \"min\": 2595.5135822296143, \"max\": 2595.5135822296143}}}\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.4842399546824 records/second\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] #progress_metric: host=algo-1, completed 43.5 % of epochs\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.3724085206709353\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] Epoch[174] Batch[0] avg_epoch_loss=2.285979\n",
      "[05/22/2025 03:59:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.285978933219655\n",
      "[05/22/2025 03:59:04 INFO 140041726678848] Epoch[174] Batch[5] avg_epoch_loss=2.402644\n",
      "[05/22/2025 03:59:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.402643828190249\n",
      "[05/22/2025 03:59:04 INFO 140041726678848] Epoch[174] Batch [5]#011Speed: 2289.26 samples/sec#011loss=2.402644\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] Epoch[174] Batch[10] avg_epoch_loss=2.407380\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=2.41306329060238\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] Epoch[174] Batch [10]#011Speed: 1883.66 samples/sec#011loss=2.413063\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] processed a total of 4639 examples\n",
      "#metrics {\"StartTime\": 1747886343.459297, \"EndTime\": 1747886346.057465, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2597.874402999878, \"count\": 1, \"min\": 2597.874402999878, \"max\": 2597.874402999878}}}\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1785.6308234464937 records/second\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] #progress_metric: host=algo-1, completed 43.75 % of epochs\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.4073799474684905\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] Epoch[175] Batch[0] avg_epoch_loss=2.222388\n",
      "[05/22/2025 03:59:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.222388320616996\n",
      "[05/22/2025 03:59:07 INFO 140041726678848] Epoch[175] Batch[5] avg_epoch_loss=2.250364\n",
      "[05/22/2025 03:59:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.2503640133093796\n",
      "[05/22/2025 03:59:07 INFO 140041726678848] Epoch[175] Batch [5]#011Speed: 2201.42 samples/sec#011loss=2.250364\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] Epoch[175] Batch[10] avg_epoch_loss=2.242074\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=2.2321258884761277\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] Epoch[175] Batch [10]#011Speed: 2022.06 samples/sec#011loss=2.232126\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] processed a total of 4560 examples\n",
      "#metrics {\"StartTime\": 1747886346.0575244, \"EndTime\": 1747886348.6248124, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2567.04044342041, \"count\": 1, \"min\": 2567.04044342041, \"max\": 2567.04044342041}}}\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1776.3043076481283 records/second\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] #progress_metric: host=algo-1, completed 44.0 % of epochs\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.2420739565669923\n",
      "[05/22/2025 03:59:08 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:09 INFO 140041726678848] Epoch[176] Batch[0] avg_epoch_loss=2.277927\n",
      "[05/22/2025 03:59:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.2779270503462556\n",
      "[05/22/2025 03:59:10 INFO 140041726678848] Epoch[176] Batch[5] avg_epoch_loss=2.283462\n",
      "[05/22/2025 03:59:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.2834620146549622\n",
      "[05/22/2025 03:59:10 INFO 140041726678848] Epoch[176] Batch [5]#011Speed: 2278.15 samples/sec#011loss=2.283462\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] Epoch[176] Batch[10] avg_epoch_loss=2.170469\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.0348773098204345\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] Epoch[176] Batch [10]#011Speed: 1957.38 samples/sec#011loss=2.034877\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] processed a total of 4578 examples\n",
      "#metrics {\"StartTime\": 1747886348.6248717, \"EndTime\": 1747886351.1881056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2562.983274459839, \"count\": 1, \"min\": 2562.983274459839, \"max\": 2562.983274459839}}}\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.1389049995548 records/second\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] #progress_metric: host=algo-1, completed 44.25 % of epochs\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.170468967002904\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] Epoch[177] Batch[0] avg_epoch_loss=2.244805\n",
      "[05/22/2025 03:59:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.244804535251949\n",
      "[05/22/2025 03:59:12 INFO 140041726678848] Epoch[177] Batch[5] avg_epoch_loss=2.233703\n",
      "[05/22/2025 03:59:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.23370306953821\n",
      "[05/22/2025 03:59:12 INFO 140041726678848] Epoch[177] Batch [5]#011Speed: 2269.97 samples/sec#011loss=2.233703\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] Epoch[177] Batch[10] avg_epoch_loss=2.186035\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=2.1288337690527563\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] Epoch[177] Batch [10]#011Speed: 1969.83 samples/sec#011loss=2.128834\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] processed a total of 4597 examples\n",
      "#metrics {\"StartTime\": 1747886351.188164, \"EndTime\": 1747886353.7476494, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2559.2312812805176, \"count\": 1, \"min\": 2559.2312812805176, \"max\": 2559.2312812805176}}}\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.180254329798 records/second\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] #progress_metric: host=algo-1, completed 44.5 % of epochs\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.1860352056811854\n",
      "[05/22/2025 03:59:13 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:14 INFO 140041726678848] Epoch[178] Batch[0] avg_epoch_loss=2.234104\n",
      "[05/22/2025 03:59:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.2341040800302756\n",
      "[05/22/2025 03:59:15 INFO 140041726678848] Epoch[178] Batch[5] avg_epoch_loss=2.229940\n",
      "[05/22/2025 03:59:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.2299396200541133\n",
      "[05/22/2025 03:59:15 INFO 140041726678848] Epoch[178] Batch [5]#011Speed: 2246.61 samples/sec#011loss=2.229940\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] Epoch[178] Batch[10] avg_epoch_loss=2.213441\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=2.1936434263641424\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] Epoch[178] Batch [10]#011Speed: 2039.32 samples/sec#011loss=2.193643\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] processed a total of 4559 examples\n",
      "#metrics {\"StartTime\": 1747886353.7477086, \"EndTime\": 1747886356.282644, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.627914428711, \"count\": 1, \"min\": 2534.627914428711, \"max\": 2534.627914428711}}}\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1798.622655677182 records/second\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] #progress_metric: host=algo-1, completed 44.75 % of epochs\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.2134413501950356\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] Epoch[179] Batch[0] avg_epoch_loss=2.545320\n",
      "[05/22/2025 03:59:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.5453204386483854\n",
      "[05/22/2025 03:59:17 INFO 140041726678848] Epoch[179] Batch[5] avg_epoch_loss=2.455989\n",
      "[05/22/2025 03:59:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.4559891664636693\n",
      "[05/22/2025 03:59:17 INFO 140041726678848] Epoch[179] Batch [5]#011Speed: 2256.23 samples/sec#011loss=2.455989\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] Epoch[179] Batch[10] avg_epoch_loss=2.366473\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=2.2590531313074194\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] Epoch[179] Batch [10]#011Speed: 2022.23 samples/sec#011loss=2.259053\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] processed a total of 4566 examples\n",
      "#metrics {\"StartTime\": 1747886356.2827027, \"EndTime\": 1747886358.8360631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2553.0338287353516, \"count\": 1, \"min\": 2553.0338287353516, \"max\": 2553.0338287353516}}}\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.384281276754 records/second\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] #progress_metric: host=algo-1, completed 45.0 % of epochs\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.366472786847192\n",
      "[05/22/2025 03:59:18 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:19 INFO 140041726678848] Epoch[180] Batch[0] avg_epoch_loss=2.372282\n",
      "[05/22/2025 03:59:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.3722815566710747\n",
      "[05/22/2025 03:59:20 INFO 140041726678848] Epoch[180] Batch[5] avg_epoch_loss=2.339374\n",
      "[05/22/2025 03:59:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.339374250540843\n",
      "[05/22/2025 03:59:20 INFO 140041726678848] Epoch[180] Batch [5]#011Speed: 2299.24 samples/sec#011loss=2.339374\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] Epoch[180] Batch[10] avg_epoch_loss=2.441980\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=2.565106649759883\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] Epoch[180] Batch [10]#011Speed: 1974.37 samples/sec#011loss=2.565107\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] processed a total of 4675 examples\n",
      "#metrics {\"StartTime\": 1747886358.8361342, \"EndTime\": 1747886361.382065, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2545.5691814422607, \"count\": 1, \"min\": 2545.5691814422607, \"max\": 2545.5691814422607}}}\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1836.4559767933602 records/second\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] #progress_metric: host=algo-1, completed 45.25 % of epochs\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.4419798865494977\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] Epoch[181] Batch[0] avg_epoch_loss=2.280211\n",
      "[05/22/2025 03:59:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.2802113148576697\n",
      "[05/22/2025 03:59:22 INFO 140041726678848] Epoch[181] Batch[5] avg_epoch_loss=2.293684\n",
      "[05/22/2025 03:59:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.2936840892811574\n",
      "[05/22/2025 03:59:22 INFO 140041726678848] Epoch[181] Batch [5]#011Speed: 2258.00 samples/sec#011loss=2.293684\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] Epoch[181] Batch[10] avg_epoch_loss=2.310346\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=2.3303398557123467\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] Epoch[181] Batch [10]#011Speed: 2003.03 samples/sec#011loss=2.330340\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] processed a total of 4611 examples\n",
      "#metrics {\"StartTime\": 1747886361.3821287, \"EndTime\": 1747886363.9253066, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.8404808044434, \"count\": 1, \"min\": 2542.8404808044434, \"max\": 2542.8404808044434}}}\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1813.26528384259 records/second\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 45.5 % of epochs\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.3103458012953344\n",
      "[05/22/2025 03:59:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:24 INFO 140041726678848] Epoch[182] Batch[0] avg_epoch_loss=2.236033\n",
      "[05/22/2025 03:59:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.2360334162722717\n",
      "[05/22/2025 03:59:25 INFO 140041726678848] Epoch[182] Batch[5] avg_epoch_loss=2.378952\n",
      "[05/22/2025 03:59:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.3789519244153676\n",
      "[05/22/2025 03:59:25 INFO 140041726678848] Epoch[182] Batch [5]#011Speed: 2280.04 samples/sec#011loss=2.378952\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] Epoch[182] Batch[10] avg_epoch_loss=2.363945\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=2.345936744197174\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] Epoch[182] Batch [10]#011Speed: 1956.23 samples/sec#011loss=2.345937\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] processed a total of 4570 examples\n",
      "#metrics {\"StartTime\": 1747886363.9253645, \"EndTime\": 1747886366.487058, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2561.4497661590576, \"count\": 1, \"min\": 2561.4497661590576, \"max\": 2561.4497661590576}}}\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1784.0840866387916 records/second\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] #progress_metric: host=algo-1, completed 45.75 % of epochs\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.363945024316189\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] Epoch[183] Batch[0] avg_epoch_loss=2.172942\n",
      "[05/22/2025 03:59:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.1729415519731345\n",
      "[05/22/2025 03:59:27 INFO 140041726678848] Epoch[183] Batch[5] avg_epoch_loss=2.342495\n",
      "[05/22/2025 03:59:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.342494837159834\n",
      "[05/22/2025 03:59:27 INFO 140041726678848] Epoch[183] Batch [5]#011Speed: 2244.87 samples/sec#011loss=2.342495\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] Epoch[183] Batch[10] avg_epoch_loss=2.423071\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=2.519762395166342\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] Epoch[183] Batch [10]#011Speed: 1948.45 samples/sec#011loss=2.519762\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] processed a total of 4718 examples\n",
      "#metrics {\"StartTime\": 1747886366.4871192, \"EndTime\": 1747886369.0640068, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2576.5748023986816, \"count\": 1, \"min\": 2576.5748023986816, \"max\": 2576.5748023986816}}}\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1831.0494422573454 records/second\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] #progress_metric: host=algo-1, completed 46.0 % of epochs\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.423070999890065\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] Epoch[184] Batch[0] avg_epoch_loss=2.293916\n",
      "[05/22/2025 03:59:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.293915678504315\n",
      "[05/22/2025 03:59:30 INFO 140041726678848] Epoch[184] Batch[5] avg_epoch_loss=2.269663\n",
      "[05/22/2025 03:59:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.2696630850312616\n",
      "[05/22/2025 03:59:30 INFO 140041726678848] Epoch[184] Batch [5]#011Speed: 2294.24 samples/sec#011loss=2.269663\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] Epoch[184] Batch[10] avg_epoch_loss=2.376049\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=2.503711861863168\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] Epoch[184] Batch [10]#011Speed: 2028.17 samples/sec#011loss=2.503712\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] processed a total of 4593 examples\n",
      "#metrics {\"StartTime\": 1747886369.0640678, \"EndTime\": 1747886371.5775938, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2513.227939605713, \"count\": 1, \"min\": 2513.227939605713, \"max\": 2513.227939605713}}}\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1827.4671119372133 records/second\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] #progress_metric: host=algo-1, completed 46.25 % of epochs\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.376048892682128\n",
      "[05/22/2025 03:59:31 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:32 INFO 140041726678848] Epoch[185] Batch[0] avg_epoch_loss=2.201363\n",
      "[05/22/2025 03:59:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.201362592871311\n",
      "[05/22/2025 03:59:32 INFO 140041726678848] Epoch[185] Batch[5] avg_epoch_loss=2.284149\n",
      "[05/22/2025 03:59:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.284148716802675\n",
      "[05/22/2025 03:59:32 INFO 140041726678848] Epoch[185] Batch [5]#011Speed: 2269.11 samples/sec#011loss=2.284149\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] Epoch[185] Batch[10] avg_epoch_loss=2.309568\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=2.3400710074036053\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] Epoch[185] Batch [10]#011Speed: 2035.69 samples/sec#011loss=2.340071\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] processed a total of 4571 examples\n",
      "#metrics {\"StartTime\": 1747886371.577653, \"EndTime\": 1747886374.1022065, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2524.296283721924, \"count\": 1, \"min\": 2524.296283721924, \"max\": 2524.296283721924}}}\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.7380785750863 records/second\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] #progress_metric: host=algo-1, completed 46.5 % of epochs\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.309567939803098\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] Epoch[186] Batch[0] avg_epoch_loss=2.269843\n",
      "[05/22/2025 03:59:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.2698434944407713\n",
      "[05/22/2025 03:59:35 INFO 140041726678848] Epoch[186] Batch[5] avg_epoch_loss=2.350050\n",
      "[05/22/2025 03:59:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.350049965454192\n",
      "[05/22/2025 03:59:35 INFO 140041726678848] Epoch[186] Batch [5]#011Speed: 2284.14 samples/sec#011loss=2.350050\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] Epoch[186] Batch[10] avg_epoch_loss=2.208368\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=2.038350223804635\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] Epoch[186] Batch [10]#011Speed: 2019.31 samples/sec#011loss=2.038350\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] processed a total of 4517 examples\n",
      "#metrics {\"StartTime\": 1747886374.102266, \"EndTime\": 1747886376.631215, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2528.6638736724854, \"count\": 1, \"min\": 2528.6638736724854, \"max\": 2528.6638736724854}}}\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.257904630124 records/second\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 46.75 % of epochs\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.2083682647043936\n",
      "[05/22/2025 03:59:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:37 INFO 140041726678848] Epoch[187] Batch[0] avg_epoch_loss=2.324329\n",
      "[05/22/2025 03:59:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.324329401708658\n",
      "[05/22/2025 03:59:38 INFO 140041726678848] Epoch[187] Batch[5] avg_epoch_loss=2.275759\n",
      "[05/22/2025 03:59:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.2757586484143\n",
      "[05/22/2025 03:59:38 INFO 140041726678848] Epoch[187] Batch [5]#011Speed: 2296.70 samples/sec#011loss=2.275759\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] Epoch[187] Batch[10] avg_epoch_loss=2.295521\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=2.3192351547275196\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] Epoch[187] Batch [10]#011Speed: 1994.37 samples/sec#011loss=2.319235\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] processed a total of 4707 examples\n",
      "#metrics {\"StartTime\": 1747886376.631274, \"EndTime\": 1747886379.1610084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2529.4506549835205, \"count\": 1, \"min\": 2529.4506549835205, \"max\": 2529.4506549835205}}}\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1860.817152410724 records/second\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] #progress_metric: host=algo-1, completed 47.0 % of epochs\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.2955206967384907\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] Epoch[188] Batch[0] avg_epoch_loss=2.287865\n",
      "[05/22/2025 03:59:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.2878646340826836\n",
      "[05/22/2025 03:59:40 INFO 140041726678848] Epoch[188] Batch[5] avg_epoch_loss=2.251654\n",
      "[05/22/2025 03:59:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.251654360855431\n",
      "[05/22/2025 03:59:40 INFO 140041726678848] Epoch[188] Batch [5]#011Speed: 2230.87 samples/sec#011loss=2.251654\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] Epoch[188] Batch[10] avg_epoch_loss=2.367824\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=2.507227269365952\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] Epoch[188] Batch [10]#011Speed: 2032.65 samples/sec#011loss=2.507227\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] processed a total of 4518 examples\n",
      "#metrics {\"StartTime\": 1747886379.161063, \"EndTime\": 1747886381.7015934, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2540.1759147644043, \"count\": 1, \"min\": 2540.1759147644043, \"max\": 2540.1759147644043}}}\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1778.5547082150008 records/second\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 47.25 % of epochs\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.36782386472385\n",
      "[05/22/2025 03:59:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:42 INFO 140041726678848] Epoch[189] Batch[0] avg_epoch_loss=2.371622\n",
      "[05/22/2025 03:59:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.3716217244919267\n",
      "[05/22/2025 03:59:43 INFO 140041726678848] Epoch[189] Batch[5] avg_epoch_loss=2.310413\n",
      "[05/22/2025 03:59:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.310412525157178\n",
      "[05/22/2025 03:59:43 INFO 140041726678848] Epoch[189] Batch [5]#011Speed: 2302.14 samples/sec#011loss=2.310413\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] Epoch[189] Batch[10] avg_epoch_loss=2.365160\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=2.4308564387875835\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] Epoch[189] Batch [10]#011Speed: 2037.14 samples/sec#011loss=2.430856\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] processed a total of 4557 examples\n",
      "#metrics {\"StartTime\": 1747886381.701653, \"EndTime\": 1747886384.2382195, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2536.3128185272217, \"count\": 1, \"min\": 2536.3128185272217, \"max\": 2536.3128185272217}}}\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.6408518998992 records/second\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] #progress_metric: host=algo-1, completed 47.5 % of epochs\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.365159758625544\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] Epoch[190] Batch[0] avg_epoch_loss=2.187367\n",
      "[05/22/2025 03:59:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.187366647019418\n",
      "[05/22/2025 03:59:45 INFO 140041726678848] Epoch[190] Batch[5] avg_epoch_loss=2.318740\n",
      "[05/22/2025 03:59:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.3187395193529023\n",
      "[05/22/2025 03:59:45 INFO 140041726678848] Epoch[190] Batch [5]#011Speed: 2270.43 samples/sec#011loss=2.318740\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] Epoch[190] Batch[10] avg_epoch_loss=2.362071\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=2.414069514285217\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] Epoch[190] Batch [10]#011Speed: 2020.33 samples/sec#011loss=2.414070\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] processed a total of 4621 examples\n",
      "#metrics {\"StartTime\": 1747886384.238278, \"EndTime\": 1747886386.7630951, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2524.4200229644775, \"count\": 1, \"min\": 2524.4200229644775, \"max\": 2524.4200229644775}}}\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1830.454640102148 records/second\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 47.75 % of epochs\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.362071335231227\n",
      "[05/22/2025 03:59:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:47 INFO 140041726678848] Epoch[191] Batch[0] avg_epoch_loss=2.277672\n",
      "[05/22/2025 03:59:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.277672034860454\n",
      "[05/22/2025 03:59:48 INFO 140041726678848] Epoch[191] Batch[5] avg_epoch_loss=2.265384\n",
      "[05/22/2025 03:59:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.2653839632415207\n",
      "[05/22/2025 03:59:48 INFO 140041726678848] Epoch[191] Batch [5]#011Speed: 2202.02 samples/sec#011loss=2.265384\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] Epoch[191] Batch[10] avg_epoch_loss=2.300354\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=2.3423182973882932\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] Epoch[191] Batch [10]#011Speed: 2016.04 samples/sec#011loss=2.342318\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] processed a total of 4561 examples\n",
      "#metrics {\"StartTime\": 1747886386.7631555, \"EndTime\": 1747886389.3347597, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2571.2385177612305, \"count\": 1, \"min\": 2571.2385177612305, \"max\": 2571.2385177612305}}}\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.7913201686092 records/second\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 48.0 % of epochs\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.3003541151264173\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] Epoch[192] Batch[0] avg_epoch_loss=2.517767\n",
      "[05/22/2025 03:59:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.517767075706431\n",
      "[05/22/2025 03:59:50 INFO 140041726678848] Epoch[192] Batch[5] avg_epoch_loss=2.413924\n",
      "[05/22/2025 03:59:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.4139241173962973\n",
      "[05/22/2025 03:59:50 INFO 140041726678848] Epoch[192] Batch [5]#011Speed: 2271.50 samples/sec#011loss=2.413924\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] Epoch[192] Batch[10] avg_epoch_loss=2.307745\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=2.180328980851545\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] Epoch[192] Batch [10]#011Speed: 1980.77 samples/sec#011loss=2.180329\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] processed a total of 4600 examples\n",
      "#metrics {\"StartTime\": 1747886389.3348207, \"EndTime\": 1747886391.8849556, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2549.8735904693604, \"count\": 1, \"min\": 2549.8735904693604, \"max\": 2549.8735904693604}}}\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1803.9480827031043 records/second\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 48.25 % of epochs\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.3077445098759553\n",
      "[05/22/2025 03:59:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:52 INFO 140041726678848] Epoch[193] Batch[0] avg_epoch_loss=2.406749\n",
      "[05/22/2025 03:59:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.4067491561108016\n",
      "[05/22/2025 03:59:53 INFO 140041726678848] Epoch[193] Batch[5] avg_epoch_loss=2.291080\n",
      "[05/22/2025 03:59:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.2910802397979304\n",
      "[05/22/2025 03:59:53 INFO 140041726678848] Epoch[193] Batch [5]#011Speed: 2280.95 samples/sec#011loss=2.291080\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] Epoch[193] Batch[10] avg_epoch_loss=2.363149\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=2.44963229376914\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] Epoch[193] Batch [10]#011Speed: 1985.95 samples/sec#011loss=2.449632\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] processed a total of 4610 examples\n",
      "#metrics {\"StartTime\": 1747886391.885017, \"EndTime\": 1747886394.4333308, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.0029582977295, \"count\": 1, \"min\": 2548.0029582977295, \"max\": 2548.0029582977295}}}\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1809.198275662028 records/second\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 48.5 % of epochs\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.3631493552393894\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] Epoch[194] Batch[0] avg_epoch_loss=2.276865\n",
      "[05/22/2025 03:59:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.2768653920604818\n",
      "[05/22/2025 03:59:55 INFO 140041726678848] Epoch[194] Batch[5] avg_epoch_loss=2.208675\n",
      "[05/22/2025 03:59:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.2086747813065495\n",
      "[05/22/2025 03:59:55 INFO 140041726678848] Epoch[194] Batch [5]#011Speed: 2259.18 samples/sec#011loss=2.208675\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] Epoch[194] Batch[10] avg_epoch_loss=2.285407\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=2.3774866184837835\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] Epoch[194] Batch [10]#011Speed: 1963.96 samples/sec#011loss=2.377487\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] processed a total of 4657 examples\n",
      "#metrics {\"StartTime\": 1747886394.4333882, \"EndTime\": 1747886396.9981093, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2564.4659996032715, \"count\": 1, \"min\": 2564.4659996032715, \"max\": 2564.4659996032715}}}\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1815.9101389668779 records/second\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 48.75 % of epochs\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.2854074345689286\n",
      "[05/22/2025 03:59:56 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:57 INFO 140041726678848] Epoch[195] Batch[0] avg_epoch_loss=2.260371\n",
      "[05/22/2025 03:59:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.2603709469393793\n",
      "[05/22/2025 03:59:58 INFO 140041726678848] Epoch[195] Batch[5] avg_epoch_loss=2.224154\n",
      "[05/22/2025 03:59:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.2241542620754453\n",
      "[05/22/2025 03:59:58 INFO 140041726678848] Epoch[195] Batch [5]#011Speed: 2256.98 samples/sec#011loss=2.224154\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] Epoch[195] Batch[10] avg_epoch_loss=2.260843\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=2.3048688111167177\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] Epoch[195] Batch [10]#011Speed: 2057.90 samples/sec#011loss=2.304869\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] processed a total of 4495 examples\n",
      "#metrics {\"StartTime\": 1747886396.9981678, \"EndTime\": 1747886399.5207427, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.3217010498047, \"count\": 1, \"min\": 2522.3217010498047, \"max\": 2522.3217010498047}}}\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1782.027158116352 records/second\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 49.0 % of epochs\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.260842693457842\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] Epoch[196] Batch[0] avg_epoch_loss=2.168927\n",
      "[05/22/2025 03:59:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.168927097108157\n",
      "[05/22/2025 04:00:01 INFO 140041726678848] Epoch[196] Batch[5] avg_epoch_loss=2.175385\n",
      "[05/22/2025 04:00:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.175384657420135\n",
      "[05/22/2025 04:00:01 INFO 140041726678848] Epoch[196] Batch [5]#011Speed: 2163.01 samples/sec#011loss=2.175385\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] Epoch[196] Batch[10] avg_epoch_loss=2.220020\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.273583495006264\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] Epoch[196] Batch [10]#011Speed: 1875.75 samples/sec#011loss=2.273583\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] processed a total of 4598 examples\n",
      "#metrics {\"StartTime\": 1747886399.5208018, \"EndTime\": 1747886402.2153697, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2694.283962249756, \"count\": 1, \"min\": 2694.283962249756, \"max\": 2694.283962249756}}}\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1706.4851154921223 records/second\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 49.25 % of epochs\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.220020492686557\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] Epoch[197] Batch[0] avg_epoch_loss=2.188937\n",
      "[05/22/2025 04:00:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.1889368409834353\n",
      "[05/22/2025 04:00:03 INFO 140041726678848] Epoch[197] Batch[5] avg_epoch_loss=2.321206\n",
      "[05/22/2025 04:00:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.3212061869983063\n",
      "[05/22/2025 04:00:03 INFO 140041726678848] Epoch[197] Batch [5]#011Speed: 2290.00 samples/sec#011loss=2.321206\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] Epoch[197] Batch[10] avg_epoch_loss=2.388140\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=2.4684603208953924\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] Epoch[197] Batch [10]#011Speed: 2023.85 samples/sec#011loss=2.468460\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] processed a total of 4595 examples\n",
      "#metrics {\"StartTime\": 1747886402.215484, \"EndTime\": 1747886404.751713, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2535.9318256378174, \"count\": 1, \"min\": 2535.9318256378174, \"max\": 2535.9318256378174}}}\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1811.8972651697345 records/second\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 49.5 % of epochs\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.3881398842242545\n",
      "[05/22/2025 04:00:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:05 INFO 140041726678848] Epoch[198] Batch[0] avg_epoch_loss=2.200172\n",
      "[05/22/2025 04:00:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.200171659677756\n",
      "[05/22/2025 04:00:06 INFO 140041726678848] Epoch[198] Batch[5] avg_epoch_loss=2.304919\n",
      "[05/22/2025 04:00:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.304919270470838\n",
      "[05/22/2025 04:00:06 INFO 140041726678848] Epoch[198] Batch [5]#011Speed: 2230.90 samples/sec#011loss=2.304919\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] Epoch[198] Batch[10] avg_epoch_loss=2.265377\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.217925794299833\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] Epoch[198] Batch [10]#011Speed: 1926.31 samples/sec#011loss=2.217926\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] processed a total of 4617 examples\n",
      "#metrics {\"StartTime\": 1747886404.751771, \"EndTime\": 1747886407.3575091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2605.487108230591, \"count\": 1, \"min\": 2605.487108230591, \"max\": 2605.487108230591}}}\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1771.9691747608128 records/second\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 49.75 % of epochs\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.265376781302199\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] Epoch[199] Batch[0] avg_epoch_loss=2.155877\n",
      "[05/22/2025 04:00:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.1558765844672187\n",
      "[05/22/2025 04:00:08 INFO 140041726678848] Epoch[199] Batch[5] avg_epoch_loss=2.294075\n",
      "[05/22/2025 04:00:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.2940747233435412\n",
      "[05/22/2025 04:00:08 INFO 140041726678848] Epoch[199] Batch [5]#011Speed: 2267.54 samples/sec#011loss=2.294075\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] Epoch[199] Batch[10] avg_epoch_loss=2.258406\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=2.2156038212085885\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] Epoch[199] Batch [10]#011Speed: 1977.09 samples/sec#011loss=2.215604\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] processed a total of 4733 examples\n",
      "#metrics {\"StartTime\": 1747886407.3575685, \"EndTime\": 1747886409.9153626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2557.5242042541504, \"count\": 1, \"min\": 2557.5242042541504, \"max\": 2557.5242042541504}}}\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1850.538688955565 records/second\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] #progress_metric: host=algo-1, completed 50.0 % of epochs\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.2584061314640174\n",
      "[05/22/2025 04:00:09 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:10 INFO 140041726678848] Epoch[200] Batch[0] avg_epoch_loss=2.123245\n",
      "[05/22/2025 04:00:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.1232445255950725\n",
      "[05/22/2025 04:00:11 INFO 140041726678848] Epoch[200] Batch[5] avg_epoch_loss=2.149097\n",
      "[05/22/2025 04:00:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.149096924371868\n",
      "[05/22/2025 04:00:11 INFO 140041726678848] Epoch[200] Batch [5]#011Speed: 2244.03 samples/sec#011loss=2.149097\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] Epoch[200] Batch[10] avg_epoch_loss=2.389941\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=2.6789533925215756\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] Epoch[200] Batch [10]#011Speed: 1961.77 samples/sec#011loss=2.678953\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] processed a total of 4585 examples\n",
      "#metrics {\"StartTime\": 1747886409.9154255, \"EndTime\": 1747886412.493204, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2577.517509460449, \"count\": 1, \"min\": 2577.517509460449, \"max\": 2577.517509460449}}}\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1778.7849856727905 records/second\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 50.25 % of epochs\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.3899407735308262\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] Epoch[201] Batch[0] avg_epoch_loss=2.208269\n",
      "[05/22/2025 04:00:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.2082688091592426\n",
      "[05/22/2025 04:00:14 INFO 140041726678848] Epoch[201] Batch[5] avg_epoch_loss=2.160618\n",
      "[05/22/2025 04:00:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.1606181144006356\n",
      "[05/22/2025 04:00:14 INFO 140041726678848] Epoch[201] Batch [5]#011Speed: 1925.47 samples/sec#011loss=2.160618\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] Epoch[201] Batch[10] avg_epoch_loss=2.194865\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=2.235961615003828\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] Epoch[201] Batch [10]#011Speed: 1932.39 samples/sec#011loss=2.235962\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] processed a total of 4595 examples\n",
      "#metrics {\"StartTime\": 1747886412.4932623, \"EndTime\": 1747886415.2945287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2801.0175228118896, \"count\": 1, \"min\": 2801.0175228118896, \"max\": 2801.0175228118896}}}\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1640.424731933738 records/second\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 50.5 % of epochs\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.1948651601293596\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] Epoch[202] Batch[0] avg_epoch_loss=2.134483\n",
      "[05/22/2025 04:00:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.1344828786191536\n",
      "[05/22/2025 04:00:16 INFO 140041726678848] Epoch[202] Batch[5] avg_epoch_loss=2.148250\n",
      "[05/22/2025 04:00:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.148249568811769\n",
      "[05/22/2025 04:00:16 INFO 140041726678848] Epoch[202] Batch [5]#011Speed: 2214.69 samples/sec#011loss=2.148250\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] Epoch[202] Batch[10] avg_epoch_loss=2.239648\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=2.3493254867587696\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] Epoch[202] Batch [10]#011Speed: 1961.79 samples/sec#011loss=2.349325\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] processed a total of 4636 examples\n",
      "#metrics {\"StartTime\": 1747886415.2945886, \"EndTime\": 1747886417.8760211, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2581.1798572540283, \"count\": 1, \"min\": 2581.1798572540283, \"max\": 2581.1798572540283}}}\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.0183060037618 records/second\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] #progress_metric: host=algo-1, completed 50.75 % of epochs\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.239647713333133\n",
      "[05/22/2025 04:00:17 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:18 INFO 140041726678848] Epoch[203] Batch[0] avg_epoch_loss=2.182985\n",
      "[05/22/2025 04:00:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.1829846218593403\n",
      "[05/22/2025 04:00:19 INFO 140041726678848] Epoch[203] Batch[5] avg_epoch_loss=2.187489\n",
      "[05/22/2025 04:00:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.187488807955758\n",
      "[05/22/2025 04:00:19 INFO 140041726678848] Epoch[203] Batch [5]#011Speed: 2170.20 samples/sec#011loss=2.187489\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] Epoch[203] Batch[10] avg_epoch_loss=2.301119\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=2.43747477032294\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] Epoch[203] Batch [10]#011Speed: 2019.33 samples/sec#011loss=2.437475\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] processed a total of 4538 examples\n",
      "#metrics {\"StartTime\": 1747886417.8760798, \"EndTime\": 1747886420.4609072, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2584.571599960327, \"count\": 1, \"min\": 2584.571599960327, \"max\": 2584.571599960327}}}\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1755.7449234796452 records/second\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 51.0 % of epochs\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.3011187908499315\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] Epoch[204] Batch[0] avg_epoch_loss=2.285132\n",
      "[05/22/2025 04:00:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.285131781563196\n",
      "[05/22/2025 04:00:21 INFO 140041726678848] Epoch[204] Batch[5] avg_epoch_loss=2.211808\n",
      "[05/22/2025 04:00:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.2118075794879823\n",
      "[05/22/2025 04:00:21 INFO 140041726678848] Epoch[204] Batch [5]#011Speed: 2083.51 samples/sec#011loss=2.211808\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] Epoch[204] Batch[10] avg_epoch_loss=2.229709\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=2.2511911235036193\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] Epoch[204] Batch [10]#011Speed: 1957.78 samples/sec#011loss=2.251191\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] processed a total of 4564 examples\n",
      "#metrics {\"StartTime\": 1747886420.4609663, \"EndTime\": 1747886423.1341832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2672.9588508605957, \"count\": 1, \"min\": 2672.9588508605957, \"max\": 2672.9588508605957}}}\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1707.4152115551356 records/second\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 51.25 % of epochs\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.229709190404181\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] Epoch[205] Batch[0] avg_epoch_loss=2.117304\n",
      "[05/22/2025 04:00:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.117303589139059\n",
      "[05/22/2025 04:00:24 INFO 140041726678848] Epoch[205] Batch[5] avg_epoch_loss=2.144824\n",
      "[05/22/2025 04:00:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.144823806411528\n",
      "[05/22/2025 04:00:24 INFO 140041726678848] Epoch[205] Batch [5]#011Speed: 2180.04 samples/sec#011loss=2.144824\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] processed a total of 4446 examples\n",
      "#metrics {\"StartTime\": 1747886423.1342425, \"EndTime\": 1747886425.6484616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2513.9424800872803, \"count\": 1, \"min\": 2513.9424800872803, \"max\": 2513.9424800872803}}}\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1768.468454562775 records/second\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 51.5 % of epochs\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.1600739137101543\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 04:00:25 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_1255de04-c69c-4d81-a68d-863f9a45eee6-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886425.6485293, \"EndTime\": 1747886425.6592808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.41269302368164, \"count\": 1, \"min\": 10.41269302368164, \"max\": 10.41269302368164}}}\n",
      "[05/22/2025 04:00:26 INFO 140041726678848] Epoch[206] Batch[0] avg_epoch_loss=2.084883\n",
      "[05/22/2025 04:00:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.084882502566467\n",
      "[05/22/2025 04:00:27 INFO 140041726678848] Epoch[206] Batch[5] avg_epoch_loss=2.119127\n",
      "[05/22/2025 04:00:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.119127076735918\n",
      "[05/22/2025 04:00:27 INFO 140041726678848] Epoch[206] Batch [5]#011Speed: 2087.71 samples/sec#011loss=2.119127\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] Epoch[206] Batch[10] avg_epoch_loss=2.196408\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=2.2891458286208937\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] Epoch[206] Batch [10]#011Speed: 1896.44 samples/sec#011loss=2.289146\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] processed a total of 4663 examples\n",
      "#metrics {\"StartTime\": 1747886425.6593513, \"EndTime\": 1747886428.363004, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2703.6006450653076, \"count\": 1, \"min\": 2703.6006450653076, \"max\": 2703.6006450653076}}}\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1724.6790286932112 records/second\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 51.75 % of epochs\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.196408327592725\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] Epoch[207] Batch[0] avg_epoch_loss=2.245833\n",
      "[05/22/2025 04:00:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.2458328892765174\n",
      "[05/22/2025 04:00:29 INFO 140041726678848] Epoch[207] Batch[5] avg_epoch_loss=2.242056\n",
      "[05/22/2025 04:00:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.2420559141842986\n",
      "[05/22/2025 04:00:29 INFO 140041726678848] Epoch[207] Batch [5]#011Speed: 2211.45 samples/sec#011loss=2.242056\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] Epoch[207] Batch[10] avg_epoch_loss=2.296378\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=2.3615640007307905\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] Epoch[207] Batch [10]#011Speed: 1881.77 samples/sec#011loss=2.361564\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] processed a total of 4644 examples\n",
      "#metrics {\"StartTime\": 1747886428.3630662, \"EndTime\": 1747886431.0418293, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2678.447484970093, \"count\": 1, \"min\": 2678.447484970093, \"max\": 2678.447484970093}}}\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1733.784824037067 records/second\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] #progress_metric: host=algo-1, completed 52.0 % of epochs\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.2963777717054312\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] Epoch[208] Batch[0] avg_epoch_loss=2.714060\n",
      "[05/22/2025 04:00:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.7140602162792318\n",
      "[05/22/2025 04:00:32 INFO 140041726678848] Epoch[208] Batch[5] avg_epoch_loss=2.625315\n",
      "[05/22/2025 04:00:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.6253147819082914\n",
      "[05/22/2025 04:00:32 INFO 140041726678848] Epoch[208] Batch [5]#011Speed: 1983.01 samples/sec#011loss=2.625315\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] Epoch[208] Batch[10] avg_epoch_loss=2.656569\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.6940730377401167\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] Epoch[208] Batch [10]#011Speed: 1944.97 samples/sec#011loss=2.694073\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] processed a total of 4638 examples\n",
      "#metrics {\"StartTime\": 1747886431.041887, \"EndTime\": 1747886433.773564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2731.4085960388184, \"count\": 1, \"min\": 2731.4085960388184, \"max\": 2731.4085960388184}}}\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1697.9698353718732 records/second\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 52.25 % of epochs\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.6565685345591215\n",
      "[05/22/2025 04:00:33 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:34 INFO 140041726678848] Epoch[209] Batch[0] avg_epoch_loss=2.457250\n",
      "[05/22/2025 04:00:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.457249562830596\n",
      "[05/22/2025 04:00:35 INFO 140041726678848] Epoch[209] Batch[5] avg_epoch_loss=2.487341\n",
      "[05/22/2025 04:00:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.4873410729717658\n",
      "[05/22/2025 04:00:35 INFO 140041726678848] Epoch[209] Batch [5]#011Speed: 2189.90 samples/sec#011loss=2.487341\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] Epoch[209] Batch[10] avg_epoch_loss=2.486852\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=2.4862661654805818\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] Epoch[209] Batch [10]#011Speed: 1890.22 samples/sec#011loss=2.486266\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] processed a total of 4630 examples\n",
      "#metrics {\"StartTime\": 1747886433.7736242, \"EndTime\": 1747886436.4367118, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2662.8310680389404, \"count\": 1, \"min\": 2662.8310680389404, \"max\": 2662.8310680389404}}}\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1738.6925533288363 records/second\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 52.5 % of epochs\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.486852478657591\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] Epoch[210] Batch[0] avg_epoch_loss=2.316521\n",
      "[05/22/2025 04:00:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.3165209797814588\n",
      "[05/22/2025 04:00:37 INFO 140041726678848] Epoch[210] Batch[5] avg_epoch_loss=2.402508\n",
      "[05/22/2025 04:00:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.402508345549427\n",
      "[05/22/2025 04:00:37 INFO 140041726678848] Epoch[210] Batch [5]#011Speed: 2258.83 samples/sec#011loss=2.402508\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] Epoch[210] Batch[10] avg_epoch_loss=2.249408\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=2.065687693572522\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] Epoch[210] Batch [10]#011Speed: 1983.98 samples/sec#011loss=2.065688\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] processed a total of 4669 examples\n",
      "#metrics {\"StartTime\": 1747886436.4367733, \"EndTime\": 1747886438.99474, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2557.6629638671875, \"count\": 1, \"min\": 2557.6629638671875, \"max\": 2557.6629638671875}}}\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1825.4296259190205 records/second\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 52.75 % of epochs\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.2494080491962887\n",
      "[05/22/2025 04:00:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:39 INFO 140041726678848] Epoch[211] Batch[0] avg_epoch_loss=2.212450\n",
      "[05/22/2025 04:00:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.2124503290732878\n",
      "[05/22/2025 04:00:40 INFO 140041726678848] Epoch[211] Batch[5] avg_epoch_loss=2.336691\n",
      "[05/22/2025 04:00:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.336690561454563\n",
      "[05/22/2025 04:00:40 INFO 140041726678848] Epoch[211] Batch [5]#011Speed: 2243.36 samples/sec#011loss=2.336691\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] Epoch[211] Batch[10] avg_epoch_loss=2.320057\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=2.300096623138224\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] Epoch[211] Batch [10]#011Speed: 1988.36 samples/sec#011loss=2.300097\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] processed a total of 4591 examples\n",
      "#metrics {\"StartTime\": 1747886438.9948018, \"EndTime\": 1747886441.5633945, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2568.2778358459473, \"count\": 1, \"min\": 2568.2778358459473, \"max\": 2568.2778358459473}}}\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1787.5114818725303 records/second\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 53.0 % of epochs\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.3200569531289545\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] Epoch[212] Batch[0] avg_epoch_loss=2.224287\n",
      "[05/22/2025 04:00:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.224286799441467\n",
      "[05/22/2025 04:00:42 INFO 140041726678848] Epoch[212] Batch[5] avg_epoch_loss=2.329386\n",
      "[05/22/2025 04:00:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.3293857815182464\n",
      "[05/22/2025 04:00:42 INFO 140041726678848] Epoch[212] Batch [5]#011Speed: 2323.27 samples/sec#011loss=2.329386\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] Epoch[212] Batch[10] avg_epoch_loss=2.189077\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.0207061427738724\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] Epoch[212] Batch [10]#011Speed: 1973.25 samples/sec#011loss=2.020706\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] processed a total of 4666 examples\n",
      "#metrics {\"StartTime\": 1747886441.5634615, \"EndTime\": 1747886444.0960112, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2532.2811603546143, \"count\": 1, \"min\": 2532.2811603546143, \"max\": 2532.2811603546143}}}\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1842.5432109714545 records/second\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] #progress_metric: host=algo-1, completed 53.25 % of epochs\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.1890768548162582\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] Epoch[213] Batch[0] avg_epoch_loss=2.134836\n",
      "[05/22/2025 04:00:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.1348359037879314\n",
      "[05/22/2025 04:00:45 INFO 140041726678848] Epoch[213] Batch[5] avg_epoch_loss=2.278937\n",
      "[05/22/2025 04:00:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.278937483506461\n",
      "[05/22/2025 04:00:45 INFO 140041726678848] Epoch[213] Batch [5]#011Speed: 2256.64 samples/sec#011loss=2.278937\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] Epoch[213] Batch[10] avg_epoch_loss=2.193085\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=2.0900625793864838\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] Epoch[213] Batch [10]#011Speed: 1955.27 samples/sec#011loss=2.090063\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] processed a total of 4572 examples\n",
      "#metrics {\"StartTime\": 1747886444.0960722, \"EndTime\": 1747886446.679581, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2583.2598209381104, \"count\": 1, \"min\": 2583.2598209381104, \"max\": 2583.2598209381104}}}\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1769.7973592155522 records/second\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 53.5 % of epochs\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.193085254361017\n",
      "[05/22/2025 04:00:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:47 INFO 140041726678848] Epoch[214] Batch[0] avg_epoch_loss=2.211963\n",
      "[05/22/2025 04:00:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.211962727502088\n",
      "[05/22/2025 04:00:48 INFO 140041726678848] Epoch[214] Batch[5] avg_epoch_loss=2.163665\n",
      "[05/22/2025 04:00:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.1636649105578947\n",
      "[05/22/2025 04:00:48 INFO 140041726678848] Epoch[214] Batch [5]#011Speed: 2268.52 samples/sec#011loss=2.163665\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] Epoch[214] Batch[10] avg_epoch_loss=2.298415\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=2.4601156867692096\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] Epoch[214] Batch [10]#011Speed: 1984.30 samples/sec#011loss=2.460116\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] processed a total of 4681 examples\n",
      "#metrics {\"StartTime\": 1747886446.6796398, \"EndTime\": 1747886449.2274728, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2547.576427459717, \"count\": 1, \"min\": 2547.576427459717, \"max\": 2547.576427459717}}}\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1837.3684699424455 records/second\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 53.75 % of epochs\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.29841526338122\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] Epoch[215] Batch[0] avg_epoch_loss=2.176040\n",
      "[05/22/2025 04:00:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.176039527944042\n",
      "[05/22/2025 04:00:50 INFO 140041726678848] Epoch[215] Batch[5] avg_epoch_loss=2.159852\n",
      "[05/22/2025 04:00:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.1598520257690703\n",
      "[05/22/2025 04:00:50 INFO 140041726678848] Epoch[215] Batch [5]#011Speed: 2228.89 samples/sec#011loss=2.159852\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] Epoch[215] Batch[10] avg_epoch_loss=2.251827\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=2.3621967001322384\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] Epoch[215] Batch [10]#011Speed: 1789.90 samples/sec#011loss=2.362197\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] processed a total of 4603 examples\n",
      "#metrics {\"StartTime\": 1747886449.2275324, \"EndTime\": 1747886451.9218652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2694.0762996673584, \"count\": 1, \"min\": 2694.0762996673584, \"max\": 2694.0762996673584}}}\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1708.5089082564057 records/second\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 54.0 % of epochs\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.2518268777523285\n",
      "[05/22/2025 04:00:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:52 INFO 140041726678848] Epoch[216] Batch[0] avg_epoch_loss=2.284958\n",
      "[05/22/2025 04:00:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.2849583275334076\n",
      "[05/22/2025 04:00:53 INFO 140041726678848] Epoch[216] Batch[5] avg_epoch_loss=2.270037\n",
      "[05/22/2025 04:00:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.270036727123643\n",
      "[05/22/2025 04:00:53 INFO 140041726678848] Epoch[216] Batch [5]#011Speed: 2242.17 samples/sec#011loss=2.270037\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] Epoch[216] Batch[10] avg_epoch_loss=2.354499\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=2.455854807558463\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] Epoch[216] Batch [10]#011Speed: 1983.43 samples/sec#011loss=2.455855\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] processed a total of 4585 examples\n",
      "#metrics {\"StartTime\": 1747886451.9219236, \"EndTime\": 1747886454.4853122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2563.138723373413, \"count\": 1, \"min\": 2563.138723373413, \"max\": 2563.138723373413}}}\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1788.755859813005 records/second\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 54.25 % of epochs\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.354499490957652\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] Epoch[217] Batch[0] avg_epoch_loss=2.205379\n",
      "[05/22/2025 04:00:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.2053789508369293\n",
      "[05/22/2025 04:00:55 INFO 140041726678848] Epoch[217] Batch[5] avg_epoch_loss=2.322139\n",
      "[05/22/2025 04:00:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.3221387969358993\n",
      "[05/22/2025 04:00:55 INFO 140041726678848] Epoch[217] Batch [5]#011Speed: 2188.81 samples/sec#011loss=2.322139\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] Epoch[217] Batch[10] avg_epoch_loss=2.392472\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=2.4768708294908826\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] Epoch[217] Batch [10]#011Speed: 1882.93 samples/sec#011loss=2.476871\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] processed a total of 4634 examples\n",
      "#metrics {\"StartTime\": 1747886454.4853785, \"EndTime\": 1747886457.1508, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2665.0757789611816, \"count\": 1, \"min\": 2665.0757789611816, \"max\": 2665.0757789611816}}}\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1738.7285339127304 records/second\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] #progress_metric: host=algo-1, completed 54.5 % of epochs\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.3924715390063462\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] Epoch[218] Batch[0] avg_epoch_loss=2.227486\n",
      "[05/22/2025 04:00:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=2.2274863194251115\n",
      "[05/22/2025 04:00:58 INFO 140041726678848] Epoch[218] Batch[5] avg_epoch_loss=2.212915\n",
      "[05/22/2025 04:00:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.212915093436804\n",
      "[05/22/2025 04:00:58 INFO 140041726678848] Epoch[218] Batch [5]#011Speed: 2135.71 samples/sec#011loss=2.212915\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] Epoch[218] Batch[10] avg_epoch_loss=2.326052\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=2.461816351875696\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] Epoch[218] Batch [10]#011Speed: 2014.71 samples/sec#011loss=2.461816\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] processed a total of 4637 examples\n",
      "#metrics {\"StartTime\": 1747886457.150859, \"EndTime\": 1747886459.746267, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2595.1435565948486, \"count\": 1, \"min\": 2595.1435565948486, \"max\": 2595.1435565948486}}}\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.7397759633234 records/second\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 54.75 % of epochs\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.326052029090846\n",
      "[05/22/2025 04:00:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:00 INFO 140041726678848] Epoch[219] Batch[0] avg_epoch_loss=2.116261\n",
      "[05/22/2025 04:01:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.116260554052408\n",
      "[05/22/2025 04:01:01 INFO 140041726678848] Epoch[219] Batch[5] avg_epoch_loss=2.157392\n",
      "[05/22/2025 04:01:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.1573919736639873\n",
      "[05/22/2025 04:01:01 INFO 140041726678848] Epoch[219] Batch [5]#011Speed: 2255.20 samples/sec#011loss=2.157392\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] Epoch[219] Batch[10] avg_epoch_loss=2.115708\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=2.065687095455178\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] Epoch[219] Batch [10]#011Speed: 1897.61 samples/sec#011loss=2.065687\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] processed a total of 4640 examples\n",
      "#metrics {\"StartTime\": 1747886459.746324, \"EndTime\": 1747886462.3549511, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2608.3762645721436, \"count\": 1, \"min\": 2608.3762645721436, \"max\": 2608.3762645721436}}}\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1778.817795846037 records/second\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 55.0 % of epochs\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.1157079381145283\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_8db9697e-a48f-4d27-a5c0-1b5b2e80a1e8-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886462.35502, \"EndTime\": 1747886462.3654473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.1470947265625, \"count\": 1, \"min\": 10.1470947265625, \"max\": 10.1470947265625}}}\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] Epoch[220] Batch[0] avg_epoch_loss=2.083635\n",
      "[05/22/2025 04:01:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.0836347482252227\n",
      "[05/22/2025 04:01:03 INFO 140041726678848] Epoch[220] Batch[5] avg_epoch_loss=2.082737\n",
      "[05/22/2025 04:01:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.0827373229935158\n",
      "[05/22/2025 04:01:03 INFO 140041726678848] Epoch[220] Batch [5]#011Speed: 2271.96 samples/sec#011loss=2.082737\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] Epoch[220] Batch[10] avg_epoch_loss=2.233614\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=2.4146657829029787\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] Epoch[220] Batch [10]#011Speed: 1949.77 samples/sec#011loss=2.414666\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] processed a total of 4695 examples\n",
      "#metrics {\"StartTime\": 1747886462.3654969, \"EndTime\": 1747886464.958857, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2593.3079719543457, \"count\": 1, \"min\": 2593.3079719543457, \"max\": 2593.3079719543457}}}\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.3671010988376 records/second\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 55.25 % of epochs\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.2336138956796354\n",
      "[05/22/2025 04:01:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:05 INFO 140041726678848] Epoch[221] Batch[0] avg_epoch_loss=2.080468\n",
      "[05/22/2025 04:01:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.080467580952464\n",
      "[05/22/2025 04:01:06 INFO 140041726678848] Epoch[221] Batch[5] avg_epoch_loss=2.103714\n",
      "[05/22/2025 04:01:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.1037141591775126\n",
      "[05/22/2025 04:01:06 INFO 140041726678848] Epoch[221] Batch [5]#011Speed: 2250.06 samples/sec#011loss=2.103714\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] Epoch[221] Batch[10] avg_epoch_loss=2.229253\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=2.379899016042595\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] Epoch[221] Batch [10]#011Speed: 1988.05 samples/sec#011loss=2.379899\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] processed a total of 4623 examples\n",
      "#metrics {\"StartTime\": 1747886464.9589171, \"EndTime\": 1747886467.517596, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2558.408498764038, \"count\": 1, \"min\": 2558.408498764038, \"max\": 2558.408498764038}}}\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1806.9211105767354 records/second\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 55.5 % of epochs\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.2292527304798226\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] Epoch[222] Batch[0] avg_epoch_loss=2.158919\n",
      "[05/22/2025 04:01:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=2.1589188267765174\n",
      "[05/22/2025 04:01:08 INFO 140041726678848] Epoch[222] Batch[5] avg_epoch_loss=2.221422\n",
      "[05/22/2025 04:01:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.2214218400191976\n",
      "[05/22/2025 04:01:08 INFO 140041726678848] Epoch[222] Batch [5]#011Speed: 2236.02 samples/sec#011loss=2.221422\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] Epoch[222] Batch[10] avg_epoch_loss=2.306232\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=2.408003489742831\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] Epoch[222] Batch [10]#011Speed: 2020.56 samples/sec#011loss=2.408003\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] processed a total of 4582 examples\n",
      "#metrics {\"StartTime\": 1747886467.5176537, \"EndTime\": 1747886470.0577748, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2539.8690700531006, \"count\": 1, \"min\": 2539.8690700531006, \"max\": 2539.8690700531006}}}\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1803.9670064500808 records/second\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 55.75 % of epochs\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.3062316808026675\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] Epoch[223] Batch[0] avg_epoch_loss=2.085795\n",
      "[05/22/2025 04:01:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.0857953111950165\n",
      "[05/22/2025 04:01:11 INFO 140041726678848] Epoch[223] Batch[5] avg_epoch_loss=2.094368\n",
      "[05/22/2025 04:01:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.094367669437581\n",
      "[05/22/2025 04:01:11 INFO 140041726678848] Epoch[223] Batch [5]#011Speed: 2159.98 samples/sec#011loss=2.094368\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] Epoch[223] Batch[10] avg_epoch_loss=2.007080\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=1.9023352132342706\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] Epoch[223] Batch [10]#011Speed: 1960.22 samples/sec#011loss=1.902335\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] processed a total of 4596 examples\n",
      "#metrics {\"StartTime\": 1747886470.057836, \"EndTime\": 1747886472.6857393, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2627.6421546936035, \"count\": 1, \"min\": 2627.6421546936035, \"max\": 2627.6421546936035}}}\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1749.035199419463 records/second\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 56.0 % of epochs\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.0070801893451673\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 04:01:12 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_6aac2aba-0b10-4463-9968-71beb7bdd322-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886472.6858013, \"EndTime\": 1747886472.696488, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.410308837890625, \"count\": 1, \"min\": 10.410308837890625, \"max\": 10.410308837890625}}}\n",
      "[05/22/2025 04:01:13 INFO 140041726678848] Epoch[224] Batch[0] avg_epoch_loss=2.034826\n",
      "[05/22/2025 04:01:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.034825518295866\n",
      "[05/22/2025 04:01:14 INFO 140041726678848] Epoch[224] Batch[5] avg_epoch_loss=2.065635\n",
      "[05/22/2025 04:01:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.065635154401274\n",
      "[05/22/2025 04:01:14 INFO 140041726678848] Epoch[224] Batch [5]#011Speed: 2131.56 samples/sec#011loss=2.065635\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] Epoch[224] Batch[10] avg_epoch_loss=2.061352\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=2.0562112583083936\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] Epoch[224] Batch [10]#011Speed: 1932.15 samples/sec#011loss=2.056211\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] processed a total of 4673 examples\n",
      "#metrics {\"StartTime\": 1747886472.6965468, \"EndTime\": 1747886475.3464608, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2649.860620498657, \"count\": 1, \"min\": 2649.860620498657, \"max\": 2649.860620498657}}}\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1763.4320189155244 records/second\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 56.25 % of epochs\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.0613515652681462\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] Epoch[225] Batch[0] avg_epoch_loss=2.257361\n",
      "[05/22/2025 04:01:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.257361057340966\n",
      "[05/22/2025 04:01:16 INFO 140041726678848] Epoch[225] Batch[5] avg_epoch_loss=2.175206\n",
      "[05/22/2025 04:01:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.1752058339278255\n",
      "[05/22/2025 04:01:16 INFO 140041726678848] Epoch[225] Batch [5]#011Speed: 2234.59 samples/sec#011loss=2.175206\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] Epoch[225] Batch[10] avg_epoch_loss=2.146901\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=2.112935021619223\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] Epoch[225] Batch [10]#011Speed: 1887.71 samples/sec#011loss=2.112935\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] processed a total of 4647 examples\n",
      "#metrics {\"StartTime\": 1747886475.3465195, \"EndTime\": 1747886477.968272, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2621.485471725464, \"count\": 1, \"min\": 2621.485471725464, \"max\": 2621.485471725464}}}\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1772.6002274349398 records/second\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] #progress_metric: host=algo-1, completed 56.5 % of epochs\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.146900919242097\n",
      "[05/22/2025 04:01:17 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:18 INFO 140041726678848] Epoch[226] Batch[0] avg_epoch_loss=2.118643\n",
      "[05/22/2025 04:01:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=2.118642556375278\n",
      "[05/22/2025 04:01:19 INFO 140041726678848] Epoch[226] Batch[5] avg_epoch_loss=2.144430\n",
      "[05/22/2025 04:01:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.1444296380193832\n",
      "[05/22/2025 04:01:19 INFO 140041726678848] Epoch[226] Batch [5]#011Speed: 2201.72 samples/sec#011loss=2.144430\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] Epoch[226] Batch[10] avg_epoch_loss=2.108791\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=2.0660238898942094\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] Epoch[226] Batch [10]#011Speed: 1889.48 samples/sec#011loss=2.066024\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] processed a total of 4637 examples\n",
      "#metrics {\"StartTime\": 1747886477.968333, \"EndTime\": 1747886480.6086378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2640.0232315063477, \"count\": 1, \"min\": 2640.0232315063477, \"max\": 2640.0232315063477}}}\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1756.3335282107132 records/second\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 56.75 % of epochs\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.10879066159885\n",
      "[05/22/2025 04:01:20 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:21 INFO 140041726678848] Epoch[227] Batch[0] avg_epoch_loss=2.112046\n",
      "[05/22/2025 04:01:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.1120462736201975\n",
      "[05/22/2025 04:01:22 INFO 140041726678848] Epoch[227] Batch[5] avg_epoch_loss=2.263053\n",
      "[05/22/2025 04:01:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.2630532766680584\n",
      "[05/22/2025 04:01:22 INFO 140041726678848] Epoch[227] Batch [5]#011Speed: 2220.82 samples/sec#011loss=2.263053\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] Epoch[227] Batch[10] avg_epoch_loss=2.204515\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=2.1342695138502226\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] Epoch[227] Batch [10]#011Speed: 2008.20 samples/sec#011loss=2.134270\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] processed a total of 4550 examples\n",
      "#metrics {\"StartTime\": 1747886480.608744, \"EndTime\": 1747886483.1792855, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2570.265769958496, \"count\": 1, \"min\": 2570.265769958496, \"max\": 2570.265769958496}}}\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1770.1708953228233 records/second\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 57.0 % of epochs\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.2045152026599513\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] Epoch[228] Batch[0] avg_epoch_loss=2.189061\n",
      "[05/22/2025 04:01:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.189061494075376\n",
      "[05/22/2025 04:01:24 INFO 140041726678848] Epoch[228] Batch[5] avg_epoch_loss=2.118567\n",
      "[05/22/2025 04:01:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.118567089372506\n",
      "[05/22/2025 04:01:24 INFO 140041726678848] Epoch[228] Batch [5]#011Speed: 2263.85 samples/sec#011loss=2.118567\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] Epoch[228] Batch[10] avg_epoch_loss=2.148370\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=2.1841340402717844\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] Epoch[228] Batch [10]#011Speed: 1942.37 samples/sec#011loss=2.184134\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] processed a total of 4578 examples\n",
      "#metrics {\"StartTime\": 1747886483.179365, \"EndTime\": 1747886485.7564592, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2576.829671859741, \"count\": 1, \"min\": 2576.829671859741, \"max\": 2576.829671859741}}}\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1776.5399053678982 records/second\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 57.25 % of epochs\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.148370248872178\n",
      "[05/22/2025 04:01:25 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:26 INFO 140041726678848] Epoch[229] Batch[0] avg_epoch_loss=2.077095\n",
      "[05/22/2025 04:01:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.077095422553591\n",
      "[05/22/2025 04:01:27 INFO 140041726678848] Epoch[229] Batch[5] avg_epoch_loss=2.231610\n",
      "[05/22/2025 04:01:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.2316096588338667\n",
      "[05/22/2025 04:01:27 INFO 140041726678848] Epoch[229] Batch [5]#011Speed: 2187.79 samples/sec#011loss=2.231610\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] Epoch[229] Batch[10] avg_epoch_loss=2.082081\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=229, batch=10 train loss <loss>=1.9026468595576977\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] Epoch[229] Batch [10]#011Speed: 1949.20 samples/sec#011loss=1.902647\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] processed a total of 4582 examples\n",
      "#metrics {\"StartTime\": 1747886485.7565207, \"EndTime\": 1747886488.373291, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2616.516351699829, \"count\": 1, \"min\": 2616.516351699829, \"max\": 2616.516351699829}}}\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1751.1230846764734 records/second\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 57.5 % of epochs\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.0820811137083353\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] Epoch[230] Batch[0] avg_epoch_loss=2.196012\n",
      "[05/22/2025 04:01:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.1960118894853147\n",
      "[05/22/2025 04:01:29 INFO 140041726678848] Epoch[230] Batch[5] avg_epoch_loss=2.336289\n",
      "[05/22/2025 04:01:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.336288825971778\n",
      "[05/22/2025 04:01:29 INFO 140041726678848] Epoch[230] Batch [5]#011Speed: 2183.98 samples/sec#011loss=2.336289\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] Epoch[230] Batch[10] avg_epoch_loss=2.303253\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=2.263609779544822\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] Epoch[230] Batch [10]#011Speed: 2003.18 samples/sec#011loss=2.263610\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] processed a total of 4553 examples\n",
      "#metrics {\"StartTime\": 1747886488.3733535, \"EndTime\": 1747886490.9785604, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2604.9487590789795, \"count\": 1, \"min\": 2604.9487590789795, \"max\": 2604.9487590789795}}}\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1747.7424662809858 records/second\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 57.75 % of epochs\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.3032528957777068\n",
      "[05/22/2025 04:01:30 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:31 INFO 140041726678848] Epoch[231] Batch[0] avg_epoch_loss=2.200574\n",
      "[05/22/2025 04:01:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.200573621720142\n",
      "[05/22/2025 04:01:32 INFO 140041726678848] Epoch[231] Batch[5] avg_epoch_loss=2.262668\n",
      "[05/22/2025 04:01:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.2626676042609155\n",
      "[05/22/2025 04:01:32 INFO 140041726678848] Epoch[231] Batch [5]#011Speed: 2190.39 samples/sec#011loss=2.262668\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] Epoch[231] Batch[10] avg_epoch_loss=2.287491\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=2.317279854755359\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] Epoch[231] Batch [10]#011Speed: 1997.78 samples/sec#011loss=2.317280\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] processed a total of 4578 examples\n",
      "#metrics {\"StartTime\": 1747886490.978659, \"EndTime\": 1747886493.5668733, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2587.9077911376953, \"count\": 1, \"min\": 2587.9077911376953, \"max\": 2587.9077911376953}}}\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1768.9338249227972 records/second\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 58.0 % of epochs\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.2874913544856628\n",
      "[05/22/2025 04:01:33 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:34 INFO 140041726678848] Epoch[232] Batch[0] avg_epoch_loss=2.100642\n",
      "[05/22/2025 04:01:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.1006418070973694\n",
      "[05/22/2025 04:01:35 INFO 140041726678848] Epoch[232] Batch[5] avg_epoch_loss=2.099899\n",
      "[05/22/2025 04:01:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.0998988502009674\n",
      "[05/22/2025 04:01:35 INFO 140041726678848] Epoch[232] Batch [5]#011Speed: 2198.77 samples/sec#011loss=2.099899\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] Epoch[232] Batch[10] avg_epoch_loss=2.212571\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=2.347777586259396\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] Epoch[232] Batch [10]#011Speed: 1915.84 samples/sec#011loss=2.347778\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] processed a total of 4595 examples\n",
      "#metrics {\"StartTime\": 1747886493.5669374, \"EndTime\": 1747886496.1948814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2627.6352405548096, \"count\": 1, \"min\": 2627.6352405548096, \"max\": 2627.6352405548096}}}\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1748.6663842475073 records/second\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 58.25 % of epochs\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.2125710029547987\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] Epoch[233] Batch[0] avg_epoch_loss=2.159025\n",
      "[05/22/2025 04:01:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.1590248566693346\n",
      "[05/22/2025 04:01:37 INFO 140041726678848] Epoch[233] Batch[5] avg_epoch_loss=2.208072\n",
      "[05/22/2025 04:01:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.2080718382429705\n",
      "[05/22/2025 04:01:37 INFO 140041726678848] Epoch[233] Batch [5]#011Speed: 2206.31 samples/sec#011loss=2.208072\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] Epoch[233] Batch[10] avg_epoch_loss=2.276382\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=2.3583533883891286\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] Epoch[233] Batch [10]#011Speed: 1918.26 samples/sec#011loss=2.358353\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] processed a total of 4653 examples\n",
      "#metrics {\"StartTime\": 1747886496.194935, \"EndTime\": 1747886498.813966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2618.6625957489014, \"count\": 1, \"min\": 2618.6625957489014, \"max\": 2618.6625957489014}}}\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1776.79957989222 records/second\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 58.5 % of epochs\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.2763816337639513\n",
      "[05/22/2025 04:01:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:39 INFO 140041726678848] Epoch[234] Batch[0] avg_epoch_loss=2.104518\n",
      "[05/22/2025 04:01:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.104518151230164\n",
      "[05/22/2025 04:01:40 INFO 140041726678848] Epoch[234] Batch[5] avg_epoch_loss=2.119217\n",
      "[05/22/2025 04:01:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.1192167037136924\n",
      "[05/22/2025 04:01:40 INFO 140041726678848] Epoch[234] Batch [5]#011Speed: 2203.94 samples/sec#011loss=2.119217\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] Epoch[234] Batch[10] avg_epoch_loss=2.117005\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=2.1143518800459353\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] Epoch[234] Batch [10]#011Speed: 1979.55 samples/sec#011loss=2.114352\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] processed a total of 4619 examples\n",
      "#metrics {\"StartTime\": 1747886498.814027, \"EndTime\": 1747886501.3995097, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2585.222005844116, \"count\": 1, \"min\": 2585.222005844116, \"max\": 2585.222005844116}}}\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1786.630807936376 records/second\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 58.75 % of epochs\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.1170054202283484\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] Epoch[235] Batch[0] avg_epoch_loss=2.038940\n",
      "[05/22/2025 04:01:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.03893988594446\n",
      "[05/22/2025 04:01:42 INFO 140041726678848] Epoch[235] Batch[5] avg_epoch_loss=2.192833\n",
      "[05/22/2025 04:01:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.192832601273954\n",
      "[05/22/2025 04:01:42 INFO 140041726678848] Epoch[235] Batch [5]#011Speed: 2240.18 samples/sec#011loss=2.192833\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] Epoch[235] Batch[10] avg_epoch_loss=2.142968\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=2.083129937186804\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] Epoch[235] Batch [10]#011Speed: 2004.65 samples/sec#011loss=2.083130\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] processed a total of 4543 examples\n",
      "#metrics {\"StartTime\": 1747886501.3995721, \"EndTime\": 1747886503.9472654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2547.4350452423096, \"count\": 1, \"min\": 2547.4350452423096, \"max\": 2547.4350452423096}}}\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1783.2885115431122 records/second\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] #progress_metric: host=algo-1, completed 59.0 % of epochs\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.1429677539616128\n",
      "[05/22/2025 04:01:43 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:44 INFO 140041726678848] Epoch[236] Batch[0] avg_epoch_loss=2.041728\n",
      "[05/22/2025 04:01:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.0417275205752365\n",
      "[05/22/2025 04:01:45 INFO 140041726678848] Epoch[236] Batch[5] avg_epoch_loss=2.193585\n",
      "[05/22/2025 04:01:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.1935848924258767\n",
      "[05/22/2025 04:01:45 INFO 140041726678848] Epoch[236] Batch [5]#011Speed: 2263.51 samples/sec#011loss=2.193585\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] Epoch[236] Batch[10] avg_epoch_loss=2.132820\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=2.0599017238829345\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] Epoch[236] Batch [10]#011Speed: 1963.14 samples/sec#011loss=2.059902\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] processed a total of 4636 examples\n",
      "#metrics {\"StartTime\": 1747886503.947326, \"EndTime\": 1747886506.5123656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2564.751386642456, \"count\": 1, \"min\": 2564.751386642456, \"max\": 2564.751386642456}}}\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1807.5187578193795 records/second\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 59.25 % of epochs\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.1328198158154485\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] Epoch[237] Batch[0] avg_epoch_loss=2.140355\n",
      "[05/22/2025 04:01:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.140354895644836\n",
      "[05/22/2025 04:01:48 INFO 140041726678848] Epoch[237] Batch[5] avg_epoch_loss=2.267091\n",
      "[05/22/2025 04:01:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.2670913390433602\n",
      "[05/22/2025 04:01:48 INFO 140041726678848] Epoch[237] Batch [5]#011Speed: 2133.51 samples/sec#011loss=2.267091\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] Epoch[237] Batch[10] avg_epoch_loss=2.323060\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=2.390222249530206\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] Epoch[237] Batch [10]#011Speed: 1937.16 samples/sec#011loss=2.390222\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] processed a total of 4593 examples\n",
      "#metrics {\"StartTime\": 1747886506.5124266, \"EndTime\": 1747886509.1633828, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2650.653839111328, \"count\": 1, \"min\": 2650.653839111328, \"max\": 2650.653839111328}}}\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1732.7203235896716 records/second\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 59.5 % of epochs\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.323059934719199\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] Epoch[238] Batch[0] avg_epoch_loss=2.065501\n",
      "[05/22/2025 04:01:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.0655010537740117\n",
      "[05/22/2025 04:01:50 INFO 140041726678848] Epoch[238] Batch[5] avg_epoch_loss=2.115808\n",
      "[05/22/2025 04:01:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.115808250466894\n",
      "[05/22/2025 04:01:50 INFO 140041726678848] Epoch[238] Batch [5]#011Speed: 2240.50 samples/sec#011loss=2.115808\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] Epoch[238] Batch[10] avg_epoch_loss=2.094523\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=2.0689811723534937\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] Epoch[238] Batch [10]#011Speed: 1883.96 samples/sec#011loss=2.068981\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] processed a total of 4692 examples\n",
      "#metrics {\"StartTime\": 1747886509.1634462, \"EndTime\": 1747886511.7833178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2619.6019649505615, \"count\": 1, \"min\": 2619.6019649505615, \"max\": 2619.6019649505615}}}\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1791.0342117767364 records/second\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 59.75 % of epochs\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.094523214960803\n",
      "[05/22/2025 04:01:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:52 INFO 140041726678848] Epoch[239] Batch[0] avg_epoch_loss=2.113983\n",
      "[05/22/2025 04:01:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.113983222264755\n",
      "[05/22/2025 04:01:53 INFO 140041726678848] Epoch[239] Batch[5] avg_epoch_loss=2.070707\n",
      "[05/22/2025 04:01:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.0707073027590246\n",
      "[05/22/2025 04:01:53 INFO 140041726678848] Epoch[239] Batch [5]#011Speed: 2185.46 samples/sec#011loss=2.070707\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] Epoch[239] Batch[10] avg_epoch_loss=2.037869\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=1.9984634365430123\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] Epoch[239] Batch [10]#011Speed: 2023.20 samples/sec#011loss=1.998463\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] processed a total of 4578 examples\n",
      "#metrics {\"StartTime\": 1747886511.783401, \"EndTime\": 1747886514.3596292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2575.921058654785, \"count\": 1, \"min\": 2575.921058654785, \"max\": 2575.921058654785}}}\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1777.1696535710455 records/second\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 60.0 % of epochs\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.0378691817517463\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] Epoch[240] Batch[0] avg_epoch_loss=2.055154\n",
      "[05/22/2025 04:01:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.0551544393356767\n",
      "[05/22/2025 04:01:55 INFO 140041726678848] Epoch[240] Batch[5] avg_epoch_loss=2.055715\n",
      "[05/22/2025 04:01:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.0557154915292086\n",
      "[05/22/2025 04:01:55 INFO 140041726678848] Epoch[240] Batch [5]#011Speed: 2248.54 samples/sec#011loss=2.055715\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] Epoch[240] Batch[10] avg_epoch_loss=2.011285\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=1.9579677658250974\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] Epoch[240] Batch [10]#011Speed: 2022.26 samples/sec#011loss=1.957968\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] processed a total of 4561 examples\n",
      "#metrics {\"StartTime\": 1747886514.3596864, \"EndTime\": 1747886516.8942142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.2800617218018, \"count\": 1, \"min\": 2534.2800617218018, \"max\": 2534.2800617218018}}}\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1799.628878470666 records/second\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 60.25 % of epochs\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.0112847071182487\n",
      "[05/22/2025 04:01:56 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:57 INFO 140041726678848] Epoch[241] Batch[0] avg_epoch_loss=2.066881\n",
      "[05/22/2025 04:01:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.066880937673998\n",
      "[05/22/2025 04:01:58 INFO 140041726678848] Epoch[241] Batch[5] avg_epoch_loss=2.090462\n",
      "[05/22/2025 04:01:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.0904616006852614\n",
      "[05/22/2025 04:01:58 INFO 140041726678848] Epoch[241] Batch [5]#011Speed: 2269.82 samples/sec#011loss=2.090462\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] Epoch[241] Batch[10] avg_epoch_loss=2.118577\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.1523162094150194\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] Epoch[241] Batch [10]#011Speed: 2009.92 samples/sec#011loss=2.152316\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] processed a total of 4553 examples\n",
      "#metrics {\"StartTime\": 1747886516.8943157, \"EndTime\": 1747886519.4513495, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2556.7238330841064, \"count\": 1, \"min\": 2556.7238330841064, \"max\": 2556.7238330841064}}}\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1780.7170541536927 records/second\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] #progress_metric: host=algo-1, completed 60.5 % of epochs\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.1185773319260606\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] Epoch[242] Batch[0] avg_epoch_loss=2.079402\n",
      "[05/22/2025 04:01:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.0794017086581293\n",
      "[05/22/2025 04:02:00 INFO 140041726678848] Epoch[242] Batch[5] avg_epoch_loss=2.234388\n",
      "[05/22/2025 04:02:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.2343884349842824\n",
      "[05/22/2025 04:02:00 INFO 140041726678848] Epoch[242] Batch [5]#011Speed: 2199.07 samples/sec#011loss=2.234388\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] Epoch[242] Batch[10] avg_epoch_loss=2.222084\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=2.2073176666463667\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] Epoch[242] Batch [10]#011Speed: 1758.62 samples/sec#011loss=2.207318\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] processed a total of 4631 examples\n",
      "#metrics {\"StartTime\": 1747886519.4514103, \"EndTime\": 1747886522.1826086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2730.8809757232666, \"count\": 1, \"min\": 2730.8809757232666, \"max\": 2730.8809757232666}}}\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1695.7123352680321 records/second\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] #progress_metric: host=algo-1, completed 60.75 % of epochs\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.22208354028523\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] Epoch[243] Batch[0] avg_epoch_loss=2.384603\n",
      "[05/22/2025 04:02:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=2.3846033177025334\n",
      "[05/22/2025 04:02:03 INFO 140041726678848] Epoch[243] Batch[5] avg_epoch_loss=2.368256\n",
      "[05/22/2025 04:02:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.368255751170135\n",
      "[05/22/2025 04:02:03 INFO 140041726678848] Epoch[243] Batch [5]#011Speed: 2043.68 samples/sec#011loss=2.368256\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] Epoch[243] Batch[10] avg_epoch_loss=2.485471\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=2.626129354294265\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] Epoch[243] Batch [10]#011Speed: 1936.23 samples/sec#011loss=2.626129\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] processed a total of 4590 examples\n",
      "#metrics {\"StartTime\": 1747886522.1827052, \"EndTime\": 1747886524.8826406, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2699.624538421631, \"count\": 1, \"min\": 2699.624538421631, \"max\": 2699.624538421631}}}\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1700.172470069251 records/second\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] #progress_metric: host=algo-1, completed 61.0 % of epochs\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.4854710253174668\n",
      "[05/22/2025 04:02:04 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:05 INFO 140041726678848] Epoch[244] Batch[0] avg_epoch_loss=2.284338\n",
      "[05/22/2025 04:02:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.284337644853146\n",
      "[05/22/2025 04:02:06 INFO 140041726678848] Epoch[244] Batch[5] avg_epoch_loss=2.312302\n",
      "[05/22/2025 04:02:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.3123017376940074\n",
      "[05/22/2025 04:02:06 INFO 140041726678848] Epoch[244] Batch [5]#011Speed: 2184.04 samples/sec#011loss=2.312302\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] Epoch[244] Batch[10] avg_epoch_loss=2.490999\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=2.7054348204342986\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] Epoch[244] Batch [10]#011Speed: 1976.53 samples/sec#011loss=2.705435\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] processed a total of 4561 examples\n",
      "#metrics {\"StartTime\": 1747886524.8827105, \"EndTime\": 1747886527.4848993, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2601.85170173645, \"count\": 1, \"min\": 2601.85170173645, \"max\": 2601.85170173645}}}\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1752.8981398327444 records/second\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] #progress_metric: host=algo-1, completed 61.25 % of epochs\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.490998593485049\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] Epoch[245] Batch[0] avg_epoch_loss=2.130105\n",
      "[05/22/2025 04:02:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.1301046596603563\n",
      "[05/22/2025 04:02:08 INFO 140041726678848] Epoch[245] Batch[5] avg_epoch_loss=2.230063\n",
      "[05/22/2025 04:02:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.2300629364444133\n",
      "[05/22/2025 04:02:08 INFO 140041726678848] Epoch[245] Batch [5]#011Speed: 2280.84 samples/sec#011loss=2.230063\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] Epoch[245] Batch[10] avg_epoch_loss=2.438073\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=2.6876853076280622\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] Epoch[245] Batch [10]#011Speed: 1994.18 samples/sec#011loss=2.687685\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] processed a total of 4705 examples\n",
      "#metrics {\"StartTime\": 1747886527.484991, \"EndTime\": 1747886530.0343628, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2549.0217208862305, \"count\": 1, \"min\": 2549.0217208862305, \"max\": 2549.0217208862305}}}\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1845.7307196565146 records/second\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 61.5 % of epochs\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.438073105164254\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] Epoch[246] Batch[0] avg_epoch_loss=2.156886\n",
      "[05/22/2025 04:02:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.156886043421144\n",
      "[05/22/2025 04:02:11 INFO 140041726678848] Epoch[246] Batch[5] avg_epoch_loss=2.259021\n",
      "[05/22/2025 04:02:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.259021172810238\n",
      "[05/22/2025 04:02:11 INFO 140041726678848] Epoch[246] Batch [5]#011Speed: 2227.69 samples/sec#011loss=2.259021\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] Epoch[246] Batch[10] avg_epoch_loss=2.315387\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=2.383026517260579\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] Epoch[246] Batch [10]#011Speed: 2042.33 samples/sec#011loss=2.383027\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] processed a total of 4502 examples\n",
      "#metrics {\"StartTime\": 1747886530.0344338, \"EndTime\": 1747886532.5739157, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2539.1180515289307, \"count\": 1, \"min\": 2539.1180515289307, \"max\": 2539.1180515289307}}}\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1772.985838277345 records/second\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] #progress_metric: host=algo-1, completed 61.75 % of epochs\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=246, train loss <loss>=2.315387238469484\n",
      "[05/22/2025 04:02:12 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:13 INFO 140041726678848] Epoch[247] Batch[0] avg_epoch_loss=2.073249\n",
      "[05/22/2025 04:02:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.0732489842880013\n",
      "[05/22/2025 04:02:13 INFO 140041726678848] Epoch[247] Batch[5] avg_epoch_loss=2.071788\n",
      "[05/22/2025 04:02:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.0717884451704016\n",
      "[05/22/2025 04:02:13 INFO 140041726678848] Epoch[247] Batch [5]#011Speed: 2294.05 samples/sec#011loss=2.071788\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] Epoch[247] Batch[10] avg_epoch_loss=1.984900\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=1.8806330147724108\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] Epoch[247] Batch [10]#011Speed: 2040.01 samples/sec#011loss=1.880633\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] processed a total of 4603 examples\n",
      "#metrics {\"StartTime\": 1747886532.5739832, \"EndTime\": 1747886535.0884933, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2514.122247695923, \"count\": 1, \"min\": 2514.122247695923, \"max\": 2514.122247695923}}}\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1830.783709210606 records/second\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 62.0 % of epochs\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=247, train loss <loss>=1.984899613171315\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] best epoch loss so far\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/state_cf91f473-ba7a-45c0-bf4d-cbdbbacb2bde-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886535.0885644, \"EndTime\": 1747886535.0991123, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.190248489379883, \"count\": 1, \"min\": 10.190248489379883, \"max\": 10.190248489379883}}}\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] Epoch[248] Batch[0] avg_epoch_loss=2.052729\n",
      "[05/22/2025 04:02:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.0527292094411194\n",
      "[05/22/2025 04:02:16 INFO 140041726678848] Epoch[248] Batch[5] avg_epoch_loss=2.037276\n",
      "[05/22/2025 04:02:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.037275964273907\n",
      "[05/22/2025 04:02:16 INFO 140041726678848] Epoch[248] Batch [5]#011Speed: 2275.27 samples/sec#011loss=2.037276\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] Epoch[248] Batch[10] avg_epoch_loss=2.136567\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=2.2557152287200726\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] Epoch[248] Batch [10]#011Speed: 1916.26 samples/sec#011loss=2.255715\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] processed a total of 4663 examples\n",
      "#metrics {\"StartTime\": 1747886535.0991688, \"EndTime\": 1747886537.6887662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2589.545726776123, \"count\": 1, \"min\": 2589.545726776123, \"max\": 2589.545726776123}}}\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1800.6404286322056 records/second\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] #progress_metric: host=algo-1, completed 62.25 % of epochs\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.136566539022164\n",
      "[05/22/2025 04:02:17 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:18 INFO 140041726678848] Epoch[249] Batch[0] avg_epoch_loss=2.050815\n",
      "[05/22/2025 04:02:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.0508145542612053\n",
      "[05/22/2025 04:02:19 INFO 140041726678848] Epoch[249] Batch[5] avg_epoch_loss=2.165300\n",
      "[05/22/2025 04:02:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.165300398998643\n",
      "[05/22/2025 04:02:19 INFO 140041726678848] Epoch[249] Batch [5]#011Speed: 2292.75 samples/sec#011loss=2.165300\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] Epoch[249] Batch[10] avg_epoch_loss=2.056986\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=1.9270094024046491\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] Epoch[249] Batch [10]#011Speed: 2023.78 samples/sec#011loss=1.927009\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] processed a total of 4514 examples\n",
      "#metrics {\"StartTime\": 1747886537.6888258, \"EndTime\": 1747886540.2118576, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2522.2537517547607, \"count\": 1, \"min\": 2522.2537517547607, \"max\": 2522.2537517547607}}}\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1789.2286777252511 records/second\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] #progress_metric: host=algo-1, completed 62.5 % of epochs\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.0569863096377365\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] Epoch[250] Batch[0] avg_epoch_loss=2.030156\n",
      "[05/22/2025 04:02:20 INFO 140041726678848] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.0301555811960608\n",
      "[05/22/2025 04:02:21 INFO 140041726678848] Epoch[250] Batch[5] avg_epoch_loss=2.148559\n",
      "[05/22/2025 04:02:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.1485591171933\n",
      "[05/22/2025 04:02:21 INFO 140041726678848] Epoch[250] Batch [5]#011Speed: 2160.43 samples/sec#011loss=2.148559\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] Epoch[250] Batch[10] avg_epoch_loss=2.233753\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=2.335986110627784\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] Epoch[250] Batch [10]#011Speed: 2004.75 samples/sec#011loss=2.335986\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] processed a total of 4605 examples\n",
      "#metrics {\"StartTime\": 1747886540.211924, \"EndTime\": 1747886542.8080695, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2595.863103866577, \"count\": 1, \"min\": 2595.863103866577, \"max\": 2595.863103866577}}}\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.9076901260908 records/second\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] #progress_metric: host=algo-1, completed 62.75 % of epochs\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.2337532051180653\n",
      "[05/22/2025 04:02:22 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:23 INFO 140041726678848] Epoch[251] Batch[0] avg_epoch_loss=2.028305\n",
      "[05/22/2025 04:02:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.0283048158233576\n",
      "[05/22/2025 04:02:24 INFO 140041726678848] Epoch[251] Batch[5] avg_epoch_loss=2.162556\n",
      "[05/22/2025 04:02:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.162555538820353\n",
      "[05/22/2025 04:02:24 INFO 140041726678848] Epoch[251] Batch [5]#011Speed: 2300.91 samples/sec#011loss=2.162556\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] Epoch[251] Batch[10] avg_epoch_loss=2.136774\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=2.10583713590966\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] Epoch[251] Batch [10]#011Speed: 2021.92 samples/sec#011loss=2.105837\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] processed a total of 4593 examples\n",
      "#metrics {\"StartTime\": 1747886542.8081381, \"EndTime\": 1747886545.329214, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2520.68829536438, \"count\": 1, \"min\": 2520.68829536438, \"max\": 2520.68829536438}}}\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1822.0574283091948 records/second\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] #progress_metric: host=algo-1, completed 63.0 % of epochs\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.13677444658822\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] Epoch[252] Batch[0] avg_epoch_loss=2.014216\n",
      "[05/22/2025 04:02:25 INFO 140041726678848] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=2.014215753975849\n",
      "[05/22/2025 04:02:26 INFO 140041726678848] Epoch[252] Batch[5] avg_epoch_loss=2.146617\n",
      "[05/22/2025 04:02:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.1466170483017817\n",
      "[05/22/2025 04:02:26 INFO 140041726678848] Epoch[252] Batch [5]#011Speed: 2288.99 samples/sec#011loss=2.146617\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] Epoch[252] Batch[10] avg_epoch_loss=2.257665\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=2.3909216662026727\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] Epoch[252] Batch [10]#011Speed: 1967.15 samples/sec#011loss=2.390922\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] processed a total of 4555 examples\n",
      "#metrics {\"StartTime\": 1747886545.3292725, \"EndTime\": 1747886547.8782947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2548.7608909606934, \"count\": 1, \"min\": 2548.7608909606934, \"max\": 2548.7608909606934}}}\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1787.0677020311432 records/second\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] #progress_metric: host=algo-1, completed 63.25 % of epochs\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.257664601893096\n",
      "[05/22/2025 04:02:27 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:28 INFO 140041726678848] Epoch[253] Batch[0] avg_epoch_loss=1.999599\n",
      "[05/22/2025 04:02:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=1.9995993973152144\n",
      "[05/22/2025 04:02:29 INFO 140041726678848] Epoch[253] Batch[5] avg_epoch_loss=2.168054\n",
      "[05/22/2025 04:02:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.168054004377494\n",
      "[05/22/2025 04:02:29 INFO 140041726678848] Epoch[253] Batch [5]#011Speed: 2286.62 samples/sec#011loss=2.168054\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] Epoch[253] Batch[10] avg_epoch_loss=2.071973\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=1.9566766207892539\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] Epoch[253] Batch [10]#011Speed: 1998.34 samples/sec#011loss=1.956677\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] processed a total of 4658 examples\n",
      "#metrics {\"StartTime\": 1747886547.8783727, \"EndTime\": 1747886550.4074996, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2528.8262367248535, \"count\": 1, \"min\": 2528.8262367248535, \"max\": 2528.8262367248535}}}\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1841.898933207002 records/second\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] #progress_metric: host=algo-1, completed 63.5 % of epochs\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.0719733754737484\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] Epoch[254] Batch[0] avg_epoch_loss=2.050081\n",
      "[05/22/2025 04:02:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.050080637092845\n",
      "[05/22/2025 04:02:31 INFO 140041726678848] Epoch[254] Batch[5] avg_epoch_loss=2.049747\n",
      "[05/22/2025 04:02:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.0497473226092704\n",
      "[05/22/2025 04:02:31 INFO 140041726678848] Epoch[254] Batch [5]#011Speed: 2270.55 samples/sec#011loss=2.049747\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] Epoch[254] Batch[10] avg_epoch_loss=2.138657\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=254, batch=10 train loss <loss>=2.2453479792333657\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] Epoch[254] Batch [10]#011Speed: 2011.10 samples/sec#011loss=2.245348\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] processed a total of 4516 examples\n",
      "#metrics {\"StartTime\": 1747886550.4075584, \"EndTime\": 1747886552.949023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2541.212320327759, \"count\": 1, \"min\": 2541.212320327759, \"max\": 2541.212320327759}}}\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1777.0433714883145 records/second\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] #progress_metric: host=algo-1, completed 63.75 % of epochs\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.1386567119838595\n",
      "[05/22/2025 04:02:32 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:33 INFO 140041726678848] Epoch[255] Batch[0] avg_epoch_loss=1.997429\n",
      "[05/22/2025 04:02:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=1.9974293188422187\n",
      "[05/22/2025 04:02:34 INFO 140041726678848] Epoch[255] Batch[5] avg_epoch_loss=2.035438\n",
      "[05/22/2025 04:02:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.0354382034222462\n",
      "[05/22/2025 04:02:34 INFO 140041726678848] Epoch[255] Batch [5]#011Speed: 2238.54 samples/sec#011loss=2.035438\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] Epoch[255] Batch[10] avg_epoch_loss=2.140923\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=2.267505073122564\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] Epoch[255] Batch [10]#011Speed: 1996.43 samples/sec#011loss=2.267505\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] processed a total of 4533 examples\n",
      "#metrics {\"StartTime\": 1747886552.9490812, \"EndTime\": 1747886555.499909, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2550.5709648132324, \"count\": 1, \"min\": 2550.5709648132324, \"max\": 2550.5709648132324}}}\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1777.1863235924238 records/second\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] #progress_metric: host=algo-1, completed 64.0 % of epochs\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.140923144195118\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] Epoch[256] Batch[0] avg_epoch_loss=2.005990\n",
      "[05/22/2025 04:02:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.0059897373938615\n",
      "[05/22/2025 04:02:36 INFO 140041726678848] Epoch[256] Batch[5] avg_epoch_loss=2.012605\n",
      "[05/22/2025 04:02:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.012604552724225\n",
      "[05/22/2025 04:02:36 INFO 140041726678848] Epoch[256] Batch [5]#011Speed: 2273.73 samples/sec#011loss=2.012605\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] Epoch[256] Batch[10] avg_epoch_loss=2.113037\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=2.2335553073670655\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] Epoch[256] Batch [10]#011Speed: 2047.67 samples/sec#011loss=2.233555\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] processed a total of 4533 examples\n",
      "#metrics {\"StartTime\": 1747886555.4999712, \"EndTime\": 1747886558.025633, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2525.3610610961914, \"count\": 1, \"min\": 2525.3610610961914, \"max\": 2525.3610610961914}}}\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.9291679694757 records/second\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 64.25 % of epochs\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.113036713925516\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] Epoch[257] Batch[0] avg_epoch_loss=2.076847\n",
      "[05/22/2025 04:02:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.0768474757273108\n",
      "[05/22/2025 04:02:39 INFO 140041726678848] Epoch[257] Batch[5] avg_epoch_loss=2.200935\n",
      "[05/22/2025 04:02:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.200934871002401\n",
      "[05/22/2025 04:02:39 INFO 140041726678848] Epoch[257] Batch [5]#011Speed: 2250.05 samples/sec#011loss=2.200935\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] Epoch[257] Batch[10] avg_epoch_loss=2.183774\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=2.1631812012806235\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] Epoch[257] Batch [10]#011Speed: 2054.52 samples/sec#011loss=2.163181\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] processed a total of 4552 examples\n",
      "#metrics {\"StartTime\": 1747886558.025692, \"EndTime\": 1747886560.56426, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2538.316488265991, \"count\": 1, \"min\": 2538.316488265991, \"max\": 2538.316488265991}}}\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1793.25479800271 records/second\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] #progress_metric: host=algo-1, completed 64.5 % of epochs\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.183774112037957\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] Epoch[258] Batch[0] avg_epoch_loss=2.030968\n",
      "[05/22/2025 04:02:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.0309675254906736\n",
      "[05/22/2025 04:02:41 INFO 140041726678848] Epoch[258] Batch[5] avg_epoch_loss=2.168106\n",
      "[05/22/2025 04:02:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.1681061130855026\n",
      "[05/22/2025 04:02:41 INFO 140041726678848] Epoch[258] Batch [5]#011Speed: 2258.11 samples/sec#011loss=2.168106\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] Epoch[258] Batch[10] avg_epoch_loss=2.268151\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=2.388205506594516\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] Epoch[258] Batch [10]#011Speed: 2028.37 samples/sec#011loss=2.388206\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] processed a total of 4602 examples\n",
      "#metrics {\"StartTime\": 1747886560.564317, \"EndTime\": 1747886563.0995631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.994125366211, \"count\": 1, \"min\": 2534.994125366211, \"max\": 2534.994125366211}}}\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1815.32462678145 records/second\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] #progress_metric: host=algo-1, completed 64.75 % of epochs\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.268151291953236\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] Epoch[259] Batch[0] avg_epoch_loss=2.018435\n",
      "[05/22/2025 04:02:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.0184349280954206\n",
      "[05/22/2025 04:02:44 INFO 140041726678848] Epoch[259] Batch[5] avg_epoch_loss=2.177851\n",
      "[05/22/2025 04:02:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.177851189129779\n",
      "[05/22/2025 04:02:44 INFO 140041726678848] Epoch[259] Batch [5]#011Speed: 2252.09 samples/sec#011loss=2.177851\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] Epoch[259] Batch[10] avg_epoch_loss=2.099317\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=2.0050754334719514\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] Epoch[259] Batch [10]#011Speed: 1947.05 samples/sec#011loss=2.005075\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] processed a total of 4652 examples\n",
      "#metrics {\"StartTime\": 1747886563.0996246, \"EndTime\": 1747886565.6818047, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2581.9246768951416, \"count\": 1, \"min\": 2581.9246768951416, \"max\": 2581.9246768951416}}}\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1801.696107783187 records/second\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] #progress_metric: host=algo-1, completed 65.0 % of epochs\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.0993167547398577\n",
      "[05/22/2025 04:02:45 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:46 INFO 140041726678848] Epoch[260] Batch[0] avg_epoch_loss=2.045194\n",
      "[05/22/2025 04:02:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=2.0451937465200447\n",
      "[05/22/2025 04:02:47 INFO 140041726678848] Epoch[260] Batch[5] avg_epoch_loss=2.026772\n",
      "[05/22/2025 04:02:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.026771754977786\n",
      "[05/22/2025 04:02:47 INFO 140041726678848] Epoch[260] Batch [5]#011Speed: 2217.12 samples/sec#011loss=2.026772\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] Epoch[260] Batch[10] avg_epoch_loss=2.123444\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=260, batch=10 train loss <loss>=2.2394501887875835\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] Epoch[260] Batch [10]#011Speed: 2031.47 samples/sec#011loss=2.239450\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] processed a total of 4590 examples\n",
      "#metrics {\"StartTime\": 1747886565.6818645, \"EndTime\": 1747886568.232552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2550.4355430603027, \"count\": 1, \"min\": 2550.4355430603027, \"max\": 2550.4355430603027}}}\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1799.630869117375 records/second\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] #progress_metric: host=algo-1, completed 65.25 % of epochs\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.123443770345876\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] Epoch[261] Batch[0] avg_epoch_loss=2.018534\n",
      "[05/22/2025 04:02:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.0185336174571966\n",
      "[05/22/2025 04:02:49 INFO 140041726678848] Epoch[261] Batch[5] avg_epoch_loss=2.169521\n",
      "[05/22/2025 04:02:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.169521204347334\n",
      "[05/22/2025 04:02:49 INFO 140041726678848] Epoch[261] Batch [5]#011Speed: 2245.37 samples/sec#011loss=2.169521\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] Epoch[261] Batch[10] avg_epoch_loss=2.204698\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=2.24691012580039\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] Epoch[261] Batch [10]#011Speed: 1998.28 samples/sec#011loss=2.246910\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] processed a total of 4733 examples\n",
      "#metrics {\"StartTime\": 1747886568.2326117, \"EndTime\": 1747886570.7803464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2547.480821609497, \"count\": 1, \"min\": 2547.480821609497, \"max\": 2547.480821609497}}}\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1857.8492069604908 records/second\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] #progress_metric: host=algo-1, completed 65.5 % of epochs\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=261, train loss <loss>=2.204697986825996\n",
      "[05/22/2025 04:02:50 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:51 INFO 140041726678848] Epoch[262] Batch[0] avg_epoch_loss=2.092935\n",
      "[05/22/2025 04:02:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.0929354729259466\n",
      "[05/22/2025 04:02:52 INFO 140041726678848] Epoch[262] Batch[5] avg_epoch_loss=2.030815\n",
      "[05/22/2025 04:02:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.0308149829119686\n",
      "[05/22/2025 04:02:52 INFO 140041726678848] Epoch[262] Batch [5]#011Speed: 2268.95 samples/sec#011loss=2.030815\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] Epoch[262] Batch[10] avg_epoch_loss=2.061721\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=2.098808740560621\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] Epoch[262] Batch [10]#011Speed: 2011.05 samples/sec#011loss=2.098809\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] processed a total of 4656 examples\n",
      "#metrics {\"StartTime\": 1747886570.7804067, \"EndTime\": 1747886573.3142617, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2533.6008071899414, \"count\": 1, \"min\": 2533.6008071899414, \"max\": 2533.6008071899414}}}\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1837.6358617104795 records/second\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] #progress_metric: host=algo-1, completed 65.75 % of epochs\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.0617212363886286\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] Epoch[263] Batch[0] avg_epoch_loss=2.121130\n",
      "[05/22/2025 04:02:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.121129908912166\n",
      "[05/22/2025 04:02:54 INFO 140041726678848] Epoch[263] Batch[5] avg_epoch_loss=2.224084\n",
      "[05/22/2025 04:02:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.224084368438834\n",
      "[05/22/2025 04:02:54 INFO 140041726678848] Epoch[263] Batch [5]#011Speed: 2280.25 samples/sec#011loss=2.224084\n",
      "[05/22/2025 04:02:55 INFO 140041726678848] processed a total of 4432 examples\n",
      "#metrics {\"StartTime\": 1747886573.314321, \"EndTime\": 1747886575.6814544, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2366.8017387390137, \"count\": 1, \"min\": 2366.8017387390137, \"max\": 2366.8017387390137}}}\n",
      "[05/22/2025 04:02:55 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1872.4918476925097 records/second\n",
      "[05/22/2025 04:02:55 INFO 140041726678848] #progress_metric: host=algo-1, completed 66.0 % of epochs\n",
      "[05/22/2025 04:02:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=263, train loss <loss>=2.271190903287688\n",
      "[05/22/2025 04:02:55 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:56 INFO 140041726678848] Epoch[264] Batch[0] avg_epoch_loss=2.160736\n",
      "[05/22/2025 04:02:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.160735608209215\n",
      "[05/22/2025 04:02:57 INFO 140041726678848] Epoch[264] Batch[5] avg_epoch_loss=2.087013\n",
      "[05/22/2025 04:02:57 INFO 140041726678848] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.0870129104534962\n",
      "[05/22/2025 04:02:57 INFO 140041726678848] Epoch[264] Batch [5]#011Speed: 2270.25 samples/sec#011loss=2.087013\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] Epoch[264] Batch[10] avg_epoch_loss=2.056066\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=2.018929054583101\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] Epoch[264] Batch [10]#011Speed: 1997.50 samples/sec#011loss=2.018929\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] processed a total of 4709 examples\n",
      "#metrics {\"StartTime\": 1747886575.6815202, \"EndTime\": 1747886578.224683, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2542.8521633148193, \"count\": 1, \"min\": 2542.8521633148193, \"max\": 2542.8521633148193}}}\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1851.7915816564512 records/second\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] #progress_metric: host=algo-1, completed 66.25 % of epochs\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.0560657032396805\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] Epoch[265] Batch[0] avg_epoch_loss=2.106053\n",
      "[05/22/2025 04:02:58 INFO 140041726678848] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.106053409703856\n",
      "[05/22/2025 04:02:59 INFO 140041726678848] Epoch[265] Batch[5] avg_epoch_loss=2.201214\n",
      "[05/22/2025 04:02:59 INFO 140041726678848] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.2012142416452067\n",
      "[05/22/2025 04:02:59 INFO 140041726678848] Epoch[265] Batch [5]#011Speed: 2247.20 samples/sec#011loss=2.201214\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] Epoch[265] Batch[10] avg_epoch_loss=2.187596\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=2.1712540454482183\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] Epoch[265] Batch [10]#011Speed: 1986.64 samples/sec#011loss=2.171254\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] processed a total of 4618 examples\n",
      "#metrics {\"StartTime\": 1747886578.2247448, \"EndTime\": 1747886580.775241, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2550.2381324768066, \"count\": 1, \"min\": 2550.2381324768066, \"max\": 2550.2381324768066}}}\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1810.7491615515273 records/second\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] #progress_metric: host=algo-1, completed 66.5 % of epochs\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.1875959706465755\n",
      "[05/22/2025 04:03:00 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:01 INFO 140041726678848] Epoch[266] Batch[0] avg_epoch_loss=2.221576\n",
      "[05/22/2025 04:03:01 INFO 140041726678848] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.221575968515103\n",
      "[05/22/2025 04:03:02 INFO 140041726678848] Epoch[266] Batch[5] avg_epoch_loss=2.199505\n",
      "[05/22/2025 04:03:02 INFO 140041726678848] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.199505483829807\n",
      "[05/22/2025 04:03:02 INFO 140041726678848] Epoch[266] Batch [5]#011Speed: 2230.91 samples/sec#011loss=2.199505\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] Epoch[266] Batch[10] avg_epoch_loss=2.314432\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=2.452344184994432\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] Epoch[266] Batch [10]#011Speed: 2010.37 samples/sec#011loss=2.452344\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] processed a total of 4702 examples\n",
      "#metrics {\"StartTime\": 1747886580.7753012, \"EndTime\": 1747886583.3575797, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2581.9859504699707, \"count\": 1, \"min\": 2581.9859504699707, \"max\": 2581.9859504699707}}}\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1821.0156230696002 records/second\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] #progress_metric: host=algo-1, completed 66.75 % of epochs\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.314432166177364\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] Epoch[267] Batch[0] avg_epoch_loss=2.033029\n",
      "[05/22/2025 04:03:03 INFO 140041726678848] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.0330293990986914\n",
      "[05/22/2025 04:03:04 INFO 140041726678848] Epoch[267] Batch[5] avg_epoch_loss=2.117537\n",
      "[05/22/2025 04:03:04 INFO 140041726678848] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.1175374439582173\n",
      "[05/22/2025 04:03:04 INFO 140041726678848] Epoch[267] Batch [5]#011Speed: 2269.26 samples/sec#011loss=2.117537\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] Epoch[267] Batch[10] avg_epoch_loss=2.260255\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=2.4315163253410357\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] Epoch[267] Batch [10]#011Speed: 1973.63 samples/sec#011loss=2.431516\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] processed a total of 4548 examples\n",
      "#metrics {\"StartTime\": 1747886583.3576407, \"EndTime\": 1747886585.921603, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2563.7168884277344, \"count\": 1, \"min\": 2563.7168884277344, \"max\": 2563.7168884277344}}}\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1773.9251327628833 records/second\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] #progress_metric: host=algo-1, completed 67.0 % of epochs\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.2602551173140437\n",
      "[05/22/2025 04:03:05 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:06 INFO 140041726678848] Epoch[268] Batch[0] avg_epoch_loss=2.107744\n",
      "[05/22/2025 04:03:06 INFO 140041726678848] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.107744450558533\n",
      "[05/22/2025 04:03:07 INFO 140041726678848] Epoch[268] Batch[5] avg_epoch_loss=2.102267\n",
      "[05/22/2025 04:03:07 INFO 140041726678848] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.1022671909799553\n",
      "[05/22/2025 04:03:07 INFO 140041726678848] Epoch[268] Batch [5]#011Speed: 2270.55 samples/sec#011loss=2.102267\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] Epoch[268] Batch[10] avg_epoch_loss=2.131531\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=268, batch=10 train loss <loss>=2.1666469106695434\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] Epoch[268] Batch [10]#011Speed: 2054.24 samples/sec#011loss=2.166647\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] processed a total of 4506 examples\n",
      "#metrics {\"StartTime\": 1747886585.9216638, \"EndTime\": 1747886588.4566042, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.6839427948, \"count\": 1, \"min\": 2534.6839427948, \"max\": 2534.6839427948}}}\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1777.6737318242485 records/second\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] #progress_metric: host=algo-1, completed 67.25 % of epochs\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.131530699929768\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] Epoch[269] Batch[0] avg_epoch_loss=2.073568\n",
      "[05/22/2025 04:03:08 INFO 140041726678848] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=2.0735678895810135\n",
      "[05/22/2025 04:03:09 INFO 140041726678848] Epoch[269] Batch[5] avg_epoch_loss=2.072379\n",
      "[05/22/2025 04:03:09 INFO 140041726678848] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=2.0723790180798187\n",
      "[05/22/2025 04:03:09 INFO 140041726678848] Epoch[269] Batch [5]#011Speed: 2287.14 samples/sec#011loss=2.072379\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] Epoch[269] Batch[10] avg_epoch_loss=2.102755\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=269, batch=10 train loss <loss>=2.1392058306653676\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] Epoch[269] Batch [10]#011Speed: 2028.48 samples/sec#011loss=2.139206\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] processed a total of 4670 examples\n",
      "#metrics {\"StartTime\": 1747886588.4566653, \"EndTime\": 1747886590.9733527, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2516.4425373077393, \"count\": 1, \"min\": 2516.4425373077393, \"max\": 2516.4425373077393}}}\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1855.7312930906091 records/second\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] #progress_metric: host=algo-1, completed 67.5 % of epochs\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] #quality_metric: host=algo-1, epoch=269, train loss <loss>=2.1027548419823407\n",
      "[05/22/2025 04:03:10 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:11 INFO 140041726678848] Epoch[270] Batch[0] avg_epoch_loss=2.006003\n",
      "[05/22/2025 04:03:11 INFO 140041726678848] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=2.0060033309698637\n",
      "[05/22/2025 04:03:12 INFO 140041726678848] Epoch[270] Batch[5] avg_epoch_loss=2.159276\n",
      "[05/22/2025 04:03:12 INFO 140041726678848] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=2.159276428449216\n",
      "[05/22/2025 04:03:12 INFO 140041726678848] Epoch[270] Batch [5]#011Speed: 2246.62 samples/sec#011loss=2.159276\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] Epoch[270] Batch[10] avg_epoch_loss=2.184166\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=2.2140342797362194\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] Epoch[270] Batch [10]#011Speed: 2083.79 samples/sec#011loss=2.214034\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] processed a total of 4503 examples\n",
      "#metrics {\"StartTime\": 1747886590.9734087, \"EndTime\": 1747886593.4831, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2509.439468383789, \"count\": 1, \"min\": 2509.439468383789, \"max\": 2509.439468383789}}}\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1794.3610451536592 records/second\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] #progress_metric: host=algo-1, completed 67.75 % of epochs\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=270, train loss <loss>=2.1841663608523993\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] Epoch[271] Batch[0] avg_epoch_loss=2.086800\n",
      "[05/22/2025 04:03:13 INFO 140041726678848] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=2.0868004202046215\n",
      "[05/22/2025 04:03:14 INFO 140041726678848] Epoch[271] Batch[5] avg_epoch_loss=2.077081\n",
      "[05/22/2025 04:03:14 INFO 140041726678848] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=2.077080968051109\n",
      "[05/22/2025 04:03:14 INFO 140041726678848] Epoch[271] Batch [5]#011Speed: 2314.03 samples/sec#011loss=2.077081\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] Epoch[271] Batch[10] avg_epoch_loss=2.133768\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=271, batch=10 train loss <loss>=2.2017914701941814\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] Epoch[271] Batch [10]#011Speed: 2022.94 samples/sec#011loss=2.201791\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] processed a total of 4602 examples\n",
      "#metrics {\"StartTime\": 1747886593.4831595, \"EndTime\": 1747886595.987221, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2503.774404525757, \"count\": 1, \"min\": 2503.774404525757, \"max\": 2503.774404525757}}}\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1837.9607886453173 records/second\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] #progress_metric: host=algo-1, completed 68.0 % of epochs\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] #quality_metric: host=algo-1, epoch=271, train loss <loss>=2.1337675599343235\n",
      "[05/22/2025 04:03:15 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:16 INFO 140041726678848] Epoch[272] Batch[0] avg_epoch_loss=2.049540\n",
      "[05/22/2025 04:03:16 INFO 140041726678848] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=2.0495400205752365\n",
      "[05/22/2025 04:03:17 INFO 140041726678848] Epoch[272] Batch[5] avg_epoch_loss=2.164182\n",
      "[05/22/2025 04:03:17 INFO 140041726678848] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=2.1641815797257795\n",
      "[05/22/2025 04:03:17 INFO 140041726678848] Epoch[272] Batch [5]#011Speed: 2281.46 samples/sec#011loss=2.164182\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] Epoch[272] Batch[10] avg_epoch_loss=2.095486\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=2.0130507845124583\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] Epoch[272] Batch [10]#011Speed: 1990.32 samples/sec#011loss=2.013051\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] processed a total of 4672 examples\n",
      "#metrics {\"StartTime\": 1747886595.9872808, \"EndTime\": 1747886598.5292864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2541.6617393493652, \"count\": 1, \"min\": 2541.6617393493652, \"max\": 2541.6617393493652}}}\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1838.0930121131976 records/second\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] #progress_metric: host=algo-1, completed 68.25 % of epochs\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=272, train loss <loss>=2.0954857637197244\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] Epoch[273] Batch[0] avg_epoch_loss=2.063702\n",
      "[05/22/2025 04:03:18 INFO 140041726678848] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=2.063702487733157\n",
      "[05/22/2025 04:03:19 INFO 140041726678848] Epoch[273] Batch[5] avg_epoch_loss=2.169467\n",
      "[05/22/2025 04:03:19 INFO 140041726678848] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=2.1694670566029255\n",
      "[05/22/2025 04:03:19 INFO 140041726678848] Epoch[273] Batch [5]#011Speed: 2255.55 samples/sec#011loss=2.169467\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] Epoch[273] Batch[10] avg_epoch_loss=2.400984\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=273, batch=10 train loss <loss>=2.6788053856660636\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] Epoch[273] Batch [10]#011Speed: 2027.35 samples/sec#011loss=2.678805\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] processed a total of 4576 examples\n",
      "#metrics {\"StartTime\": 1747886598.529344, \"EndTime\": 1747886601.0553615, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2525.747299194336, \"count\": 1, \"min\": 2525.747299194336, \"max\": 2525.747299194336}}}\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1811.6649241089249 records/second\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] #progress_metric: host=algo-1, completed 68.5 % of epochs\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=273, train loss <loss>=2.400984478904352\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] Epoch[274] Batch[0] avg_epoch_loss=2.294411\n",
      "[05/22/2025 04:03:21 INFO 140041726678848] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=2.2944107565423164\n",
      "[05/22/2025 04:03:22 INFO 140041726678848] Epoch[274] Batch[5] avg_epoch_loss=2.255412\n",
      "[05/22/2025 04:03:22 INFO 140041726678848] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=2.2554115119826466\n",
      "[05/22/2025 04:03:22 INFO 140041726678848] Epoch[274] Batch [5]#011Speed: 2281.38 samples/sec#011loss=2.255412\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] Epoch[274] Batch[10] avg_epoch_loss=2.333920\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=274, batch=10 train loss <loss>=2.428130790863377\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] Epoch[274] Batch [10]#011Speed: 2016.34 samples/sec#011loss=2.428131\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] processed a total of 4663 examples\n",
      "#metrics {\"StartTime\": 1747886601.0554216, \"EndTime\": 1747886603.5882645, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2532.5801372528076, \"count\": 1, \"min\": 2532.5801372528076, \"max\": 2532.5801372528076}}}\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1841.1415272783138 records/second\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] #progress_metric: host=algo-1, completed 68.75 % of epochs\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] #quality_metric: host=algo-1, epoch=274, train loss <loss>=2.3339202751102515\n",
      "[05/22/2025 04:03:23 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:24 INFO 140041726678848] Epoch[275] Batch[0] avg_epoch_loss=2.145881\n",
      "[05/22/2025 04:03:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=2.1458813639685412\n",
      "[05/22/2025 04:03:24 INFO 140041726678848] Epoch[275] Batch[5] avg_epoch_loss=2.233757\n",
      "[05/22/2025 04:03:24 INFO 140041726678848] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=2.233756945411099\n",
      "[05/22/2025 04:03:24 INFO 140041726678848] Epoch[275] Batch [5]#011Speed: 2278.51 samples/sec#011loss=2.233757\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] Epoch[275] Batch[10] avg_epoch_loss=2.133497\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=275, batch=10 train loss <loss>=2.013184572487472\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] Epoch[275] Batch [10]#011Speed: 2027.08 samples/sec#011loss=2.013185\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] processed a total of 4592 examples\n",
      "#metrics {\"StartTime\": 1747886603.588324, \"EndTime\": 1747886606.1070924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2518.5177326202393, \"count\": 1, \"min\": 2518.5177326202393, \"max\": 2518.5177326202393}}}\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1823.2294444606948 records/second\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] #progress_metric: host=algo-1, completed 69.0 % of epochs\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=275, train loss <loss>=2.1334967759003596\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] Epoch[276] Batch[0] avg_epoch_loss=2.113456\n",
      "[05/22/2025 04:03:26 INFO 140041726678848] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=2.1134559274516285\n",
      "[05/22/2025 04:03:27 INFO 140041726678848] Epoch[276] Batch[5] avg_epoch_loss=2.090510\n",
      "[05/22/2025 04:03:27 INFO 140041726678848] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=2.090509948503909\n",
      "[05/22/2025 04:03:27 INFO 140041726678848] Epoch[276] Batch [5]#011Speed: 2216.48 samples/sec#011loss=2.090510\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] Epoch[276] Batch[10] avg_epoch_loss=2.111744\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=2.1372244854015867\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] Epoch[276] Batch [10]#011Speed: 2025.55 samples/sec#011loss=2.137224\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] processed a total of 4574 examples\n",
      "#metrics {\"StartTime\": 1747886606.1071537, \"EndTime\": 1747886608.6594818, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2552.065849304199, \"count\": 1, \"min\": 2552.065849304199, \"max\": 2552.065849304199}}}\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1792.2085397880223 records/second\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] #progress_metric: host=algo-1, completed 69.25 % of epochs\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] #quality_metric: host=algo-1, epoch=276, train loss <loss>=2.1117438289119446\n",
      "[05/22/2025 04:03:28 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:29 INFO 140041726678848] Epoch[277] Batch[0] avg_epoch_loss=2.012956\n",
      "[05/22/2025 04:03:29 INFO 140041726678848] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=2.0129556294804427\n",
      "[05/22/2025 04:03:30 INFO 140041726678848] Epoch[277] Batch[5] avg_epoch_loss=2.146563\n",
      "[05/22/2025 04:03:30 INFO 140041726678848] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=2.146562764621613\n",
      "[05/22/2025 04:03:30 INFO 140041726678848] Epoch[277] Batch [5]#011Speed: 2260.33 samples/sec#011loss=2.146563\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] Epoch[277] Batch[10] avg_epoch_loss=2.117162\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=277, batch=10 train loss <loss>=2.0818806331778954\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] Epoch[277] Batch [10]#011Speed: 1993.79 samples/sec#011loss=2.081881\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] processed a total of 4515 examples\n",
      "#metrics {\"StartTime\": 1747886608.6595442, \"EndTime\": 1747886611.2126398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2552.663803100586, \"count\": 1, \"min\": 2552.663803100586, \"max\": 2552.663803100586}}}\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1768.674480585125 records/second\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] #progress_metric: host=algo-1, completed 69.5 % of epochs\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=277, train loss <loss>=2.1171617957835593\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] Epoch[278] Batch[0] avg_epoch_loss=1.952386\n",
      "[05/22/2025 04:03:31 INFO 140041726678848] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=1.952385917272759\n",
      "[05/22/2025 04:03:32 INFO 140041726678848] Epoch[278] Batch[5] avg_epoch_loss=1.982834\n",
      "[05/22/2025 04:03:32 INFO 140041726678848] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=1.9828337150409474\n",
      "[05/22/2025 04:03:32 INFO 140041726678848] Epoch[278] Batch [5]#011Speed: 2196.02 samples/sec#011loss=1.982834\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] Epoch[278] Batch[10] avg_epoch_loss=2.103239\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=2.2477257131733714\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] Epoch[278] Batch [10]#011Speed: 2009.47 samples/sec#011loss=2.247726\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] processed a total of 4597 examples\n",
      "#metrics {\"StartTime\": 1747886611.2127023, \"EndTime\": 1747886613.801005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2587.97025680542, \"count\": 1, \"min\": 2587.97025680542, \"max\": 2587.97025680542}}}\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1776.2336757096564 records/second\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] #progress_metric: host=algo-1, completed 69.75 % of epochs\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] #quality_metric: host=algo-1, epoch=278, train loss <loss>=2.103239168737504\n",
      "[05/22/2025 04:03:33 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:34 INFO 140041726678848] Epoch[279] Batch[0] avg_epoch_loss=1.993597\n",
      "[05/22/2025 04:03:34 INFO 140041726678848] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=1.993597153831431\n",
      "[05/22/2025 04:03:35 INFO 140041726678848] Epoch[279] Batch[5] avg_epoch_loss=2.002925\n",
      "[05/22/2025 04:03:35 INFO 140041726678848] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=2.0029253602116395\n",
      "[05/22/2025 04:03:35 INFO 140041726678848] Epoch[279] Batch [5]#011Speed: 2215.27 samples/sec#011loss=2.002925\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] Epoch[279] Batch[10] avg_epoch_loss=2.084894\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=2.183256466192233\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] Epoch[279] Batch [10]#011Speed: 1957.67 samples/sec#011loss=2.183256\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] processed a total of 4642 examples\n",
      "#metrics {\"StartTime\": 1747886613.8010645, \"EndTime\": 1747886616.3869433, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2585.6237411499023, \"count\": 1, \"min\": 2585.6237411499023, \"max\": 2585.6237411499023}}}\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1795.2434494453498 records/second\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] #progress_metric: host=algo-1, completed 70.0 % of epochs\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=279, train loss <loss>=2.084894044748273\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] Epoch[280] Batch[0] avg_epoch_loss=1.971065\n",
      "[05/22/2025 04:03:36 INFO 140041726678848] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=1.9710649859931793\n",
      "[05/22/2025 04:03:37 INFO 140041726678848] Epoch[280] Batch[5] avg_epoch_loss=1.963411\n",
      "[05/22/2025 04:03:37 INFO 140041726678848] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=1.9634107605297653\n",
      "[05/22/2025 04:03:37 INFO 140041726678848] Epoch[280] Batch [5]#011Speed: 2214.03 samples/sec#011loss=1.963411\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] Epoch[280] Batch[10] avg_epoch_loss=2.115505\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=2.2980185731747635\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] Epoch[280] Batch [10]#011Speed: 1964.38 samples/sec#011loss=2.298019\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] processed a total of 4638 examples\n",
      "#metrics {\"StartTime\": 1747886616.3870115, \"EndTime\": 1747886618.9776125, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2590.3382301330566, \"count\": 1, \"min\": 2590.3382301330566, \"max\": 2590.3382301330566}}}\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1790.4386291551516 records/second\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] #progress_metric: host=algo-1, completed 70.25 % of epochs\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] #quality_metric: host=algo-1, epoch=280, train loss <loss>=2.1155052208229463\n",
      "[05/22/2025 04:03:38 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:39 INFO 140041726678848] Epoch[281] Batch[0] avg_epoch_loss=2.018122\n",
      "[05/22/2025 04:03:39 INFO 140041726678848] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=2.018122003975849\n",
      "[05/22/2025 04:03:40 INFO 140041726678848] Epoch[281] Batch[5] avg_epoch_loss=2.015269\n",
      "[05/22/2025 04:03:40 INFO 140041726678848] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=2.0152694373637017\n",
      "[05/22/2025 04:03:40 INFO 140041726678848] Epoch[281] Batch [5]#011Speed: 2186.76 samples/sec#011loss=2.015269\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] Epoch[281] Batch[10] avg_epoch_loss=2.045460\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=281, batch=10 train loss <loss>=2.081688855007656\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] Epoch[281] Batch [10]#011Speed: 1967.02 samples/sec#011loss=2.081689\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] processed a total of 4619 examples\n",
      "#metrics {\"StartTime\": 1747886618.977673, \"EndTime\": 1747886621.602157, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2624.229669570923, \"count\": 1, \"min\": 2624.229669570923, \"max\": 2624.229669570923}}}\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1760.0781686419841 records/second\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] #progress_metric: host=algo-1, completed 70.5 % of epochs\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] #quality_metric: host=algo-1, epoch=281, train loss <loss>=2.045460081747317\n",
      "[05/22/2025 04:03:41 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:42 INFO 140041726678848] Epoch[282] Batch[0] avg_epoch_loss=1.941126\n",
      "[05/22/2025 04:03:42 INFO 140041726678848] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=1.9411263582701141\n",
      "[05/22/2025 04:03:43 INFO 140041726678848] Epoch[282] Batch[5] avg_epoch_loss=2.143804\n",
      "[05/22/2025 04:03:43 INFO 140041726678848] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=2.143804129619641\n",
      "[05/22/2025 04:03:43 INFO 140041726678848] Epoch[282] Batch [5]#011Speed: 2196.09 samples/sec#011loss=2.143804\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] Epoch[282] Batch[10] avg_epoch_loss=2.081190\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=282, batch=10 train loss <loss>=2.006053899072592\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] Epoch[282] Batch [10]#011Speed: 1968.41 samples/sec#011loss=2.006054\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] processed a total of 4615 examples\n",
      "#metrics {\"StartTime\": 1747886621.6022155, \"EndTime\": 1747886624.1972282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2594.7606563568115, \"count\": 1, \"min\": 2594.7606563568115, \"max\": 2594.7606563568115}}}\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1778.5231267482745 records/second\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] #progress_metric: host=algo-1, completed 70.75 % of epochs\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=282, train loss <loss>=2.0811903884618914\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] Epoch[283] Batch[0] avg_epoch_loss=2.225425\n",
      "[05/22/2025 04:03:44 INFO 140041726678848] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=2.2254249895601337\n",
      "[05/22/2025 04:03:45 INFO 140041726678848] Epoch[283] Batch[5] avg_epoch_loss=2.112742\n",
      "[05/22/2025 04:03:45 INFO 140041726678848] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=2.112741766280392\n",
      "[05/22/2025 04:03:45 INFO 140041726678848] Epoch[283] Batch [5]#011Speed: 2206.83 samples/sec#011loss=2.112742\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] Epoch[283] Batch[10] avg_epoch_loss=2.106553\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=283, batch=10 train loss <loss>=2.0991253893200166\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] Epoch[283] Batch [10]#011Speed: 2052.24 samples/sec#011loss=2.099125\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] processed a total of 4513 examples\n",
      "#metrics {\"StartTime\": 1747886624.1972883, \"EndTime\": 1747886626.7610767, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2563.532829284668, \"count\": 1, \"min\": 2563.532829284668, \"max\": 2563.532829284668}}}\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1760.400754235834 records/second\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] #progress_metric: host=algo-1, completed 71.0 % of epochs\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] #quality_metric: host=algo-1, epoch=283, train loss <loss>=2.1065525040256756\n",
      "[05/22/2025 04:03:46 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:47 INFO 140041726678848] Epoch[284] Batch[0] avg_epoch_loss=2.148447\n",
      "[05/22/2025 04:03:47 INFO 140041726678848] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=2.1484474233104818\n",
      "[05/22/2025 04:03:48 INFO 140041726678848] Epoch[284] Batch[5] avg_epoch_loss=2.136024\n",
      "[05/22/2025 04:03:48 INFO 140041726678848] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=2.1360237331149663\n",
      "[05/22/2025 04:03:48 INFO 140041726678848] Epoch[284] Batch [5]#011Speed: 2291.32 samples/sec#011loss=2.136024\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] Epoch[284] Batch[10] avg_epoch_loss=2.197257\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=284, batch=10 train loss <loss>=2.2707369458170934\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] Epoch[284] Batch [10]#011Speed: 2007.70 samples/sec#011loss=2.270737\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] processed a total of 4700 examples\n",
      "#metrics {\"StartTime\": 1747886626.7611358, \"EndTime\": 1747886629.3121154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2550.731658935547, \"count\": 1, \"min\": 2550.731658935547, \"max\": 2550.731658935547}}}\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1842.5477691765795 records/second\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] #progress_metric: host=algo-1, completed 71.25 % of epochs\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=284, train loss <loss>=2.197257011615933\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] Epoch[285] Batch[0] avg_epoch_loss=2.049505\n",
      "[05/22/2025 04:03:49 INFO 140041726678848] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=2.0495045413418707\n",
      "[05/22/2025 04:03:50 INFO 140041726678848] Epoch[285] Batch[5] avg_epoch_loss=2.250559\n",
      "[05/22/2025 04:03:50 INFO 140041726678848] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=2.2505589905011716\n",
      "[05/22/2025 04:03:50 INFO 140041726678848] Epoch[285] Batch [5]#011Speed: 2345.88 samples/sec#011loss=2.250559\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] Epoch[285] Batch[10] avg_epoch_loss=2.326205\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=2.4169807145218543\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] Epoch[285] Batch [10]#011Speed: 2011.07 samples/sec#011loss=2.416981\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] processed a total of 4652 examples\n",
      "#metrics {\"StartTime\": 1747886629.312173, \"EndTime\": 1747886631.8116963, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2499.236583709717, \"count\": 1, \"min\": 2499.236583709717, \"max\": 2499.236583709717}}}\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1861.301103688785 records/second\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] #progress_metric: host=algo-1, completed 71.5 % of epochs\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] #quality_metric: host=algo-1, epoch=285, train loss <loss>=2.326205228692391\n",
      "[05/22/2025 04:03:51 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:52 INFO 140041726678848] Epoch[286] Batch[0] avg_epoch_loss=2.066531\n",
      "[05/22/2025 04:03:52 INFO 140041726678848] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=2.0665313108992205\n",
      "[05/22/2025 04:03:53 INFO 140041726678848] Epoch[286] Batch[5] avg_epoch_loss=2.185694\n",
      "[05/22/2025 04:03:53 INFO 140041726678848] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=2.185693889524464\n",
      "[05/22/2025 04:03:53 INFO 140041726678848] Epoch[286] Batch [5]#011Speed: 2270.99 samples/sec#011loss=2.185694\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] Epoch[286] Batch[10] avg_epoch_loss=2.203128\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=286, batch=10 train loss <loss>=2.2240496187273804\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] Epoch[286] Batch [10]#011Speed: 1949.98 samples/sec#011loss=2.224050\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] processed a total of 4619 examples\n",
      "#metrics {\"StartTime\": 1747886631.811758, \"EndTime\": 1747886634.3829358, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2570.9197521209717, \"count\": 1, \"min\": 2570.9197521209717, \"max\": 2570.9197521209717}}}\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1796.5666420521718 records/second\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] #progress_metric: host=algo-1, completed 71.75 % of epochs\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=286, train loss <loss>=2.203128311889426\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] Epoch[287] Batch[0] avg_epoch_loss=2.046450\n",
      "[05/22/2025 04:03:54 INFO 140041726678848] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=2.0464500648141706\n",
      "[05/22/2025 04:03:55 INFO 140041726678848] Epoch[287] Batch[5] avg_epoch_loss=2.015746\n",
      "[05/22/2025 04:03:55 INFO 140041726678848] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=2.0157460507943\n",
      "[05/22/2025 04:03:55 INFO 140041726678848] Epoch[287] Batch [5]#011Speed: 2188.97 samples/sec#011loss=2.015746\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] Epoch[287] Batch[10] avg_epoch_loss=2.059423\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=2.111834512893235\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] Epoch[287] Batch [10]#011Speed: 1938.28 samples/sec#011loss=2.111835\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] processed a total of 4691 examples\n",
      "#metrics {\"StartTime\": 1747886634.3830018, \"EndTime\": 1747886636.995526, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2612.229347229004, \"count\": 1, \"min\": 2612.229347229004, \"max\": 2612.229347229004}}}\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] #throughput_metric: host=algo-1, train throughput=1795.7225029798683 records/second\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] #progress_metric: host=algo-1, completed 72.0 % of epochs\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] #quality_metric: host=algo-1, epoch=287, train loss <loss>=2.059422624475634\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] loss did not improve\n",
      "[05/22/2025 04:03:56 INFO 140041726678848] Loading parameters from best epoch (247)\n",
      "#metrics {\"StartTime\": 1747886636.9955842, \"EndTime\": 1747886637.0016906, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 5.7582855224609375, \"count\": 1, \"min\": 5.7582855224609375, \"max\": 5.7582855224609375}}}\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] stopping training now\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] #progress_metric: host=algo-1, completed 100 % of epochs\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Final loss: 1.984899613171315 (occurred at epoch 247)\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] #quality_metric: host=algo-1, train final_loss <loss>=1.984899613171315\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Worker algo-1 finished training.\n",
      "[05/22/2025 04:03:57 WARNING 140041726678848] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] All workers finished. Serializing model for prediction.\n",
      "#metrics {\"StartTime\": 1747886637.001743, \"EndTime\": 1747886637.0547369, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 52.58369445800781, \"count\": 1, \"min\": 52.58369445800781, \"max\": 52.58369445800781}}}\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1747886637.054791, \"EndTime\": 1747886637.07669, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 74.56636428833008, \"count\": 1, \"min\": 74.56636428833008, \"max\": 74.56636428833008}}}\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Serializing to /opt/ml/model/model_algo-1\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\n",
      "#metrics {\"StartTime\": 1747886637.0767348, \"EndTime\": 1747886637.0806744, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 3.9129257202148438, \"count\": 1, \"min\": 3.9129257202148438, \"max\": 3.9129257202148438}}}\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] Successfully serialized the model for prediction.\n",
      "[05/22/2025 04:03:57 INFO 140041726678848] No test data passed, skipping evaluation.\n",
      "#metrics {\"StartTime\": 1747886637.0807133, \"EndTime\": 1747886637.0837772, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 3.8564205169677734, \"count\": 1, \"min\": 3.8564205169677734, \"max\": 3.8564205169677734}, \"totaltime\": {\"sum\": 738025.7954597473, \"count\": 1, \"min\": 738025.7954597473, \"max\": 738025.7954597473}}}\n",
      "\n",
      "2025-05-22 04:04:15 Uploading - Uploading generated training model\n",
      "2025-05-22 04:04:15 Completed - Training job completed\n",
      "Training seconds: 907\n",
      "Billable seconds: 907\n",
      "CPU times: total: 25.7 s\n",
      "Wall time: 16min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "2ff2079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-05-22 04:04:15 Starting - Preparing the instances for training\n",
      "2025-05-22 04:04:15 Downloading - Downloading the training image\n",
      "2025-05-22 04:04:15 Training - Training image download completed. Training in progress.\n",
      "2025-05-22 04:04:15 Uploading - Uploading generated training model\n",
      "2025-05-22 04:04:15 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('lilipink-forecasting-2025-05-22-03-48-30-015',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "966544f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 23:06:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-04-06-24-816 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 23:06:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-04-06-24-816 \u001b]8;id=366647;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=96928;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 23:06:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-04-06-24-816                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 23:06:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=219598;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=121678;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-04-06-24-816                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-04-06-24-816                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=132867;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=405087;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-04-06-24-816                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "dbaa02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "materiales = [df['material'].unique()[0] for df in timeseries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "f3e5bdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>28.570580</td>\n",
       "      <td>33.706036</td>\n",
       "      <td>37.759369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>40.106171</td>\n",
       "      <td>44.941391</td>\n",
       "      <td>48.891117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>15.922655</td>\n",
       "      <td>17.287342</td>\n",
       "      <td>18.594730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>9.118885</td>\n",
       "      <td>10.537629</td>\n",
       "      <td>12.171485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>5.690591</td>\n",
       "      <td>10.755075</td>\n",
       "      <td>14.273312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>2.132280</td>\n",
       "      <td>6.541682</td>\n",
       "      <td>10.474480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01  28.570580  33.706036  37.759369\n",
       "2024-12-01  40.106171  44.941391  48.891117\n",
       "2025-01-01  15.922655  17.287342  18.594730\n",
       "2025-02-01   9.118885  10.537629  12.171485\n",
       "2025-03-01   5.690591  10.755075  14.273312\n",
       "2025-04-01   2.132280   6.541682  10.474480"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_pred=6\n",
    "i=0\n",
    "predictor.predict(\n",
    "    ts = timeseries_list[i][:-horizon_pred], \n",
    "    cat=vectores_cat[i],\n",
    "    dynamic_feat=dynamic_list[i],\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "060d36e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-01    33\n",
       "2024-12-01    44\n",
       "2025-01-01    17\n",
       "2025-02-01    10\n",
       "2025-03-01    14\n",
       "2025-04-01     4\n",
       "Freq: MS, Name: cantidad, dtype: int32"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_list[i].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "96ce0939",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_por_material = generar_predicciones_por_material(\n",
    "    materiales=materiales,\n",
    "    timeseries_list=timeseries_list,\n",
    "    vectores_cat=vectores_cat,\n",
    "    dynamic_list=dynamic_list,\n",
    "    predictor=predictor,\n",
    "    horizon_pred=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "e47761a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([20000337001, 20000400003, 20000815002, 20000815003, 20000837001, 20000837002, 20001016001, 20001374001, 20003147001, 20003257001, 20003257002, 20003257004, 20008046001, 25109225001, 25109232001])"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_por_material.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "21f49e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>3.511388</td>\n",
       "      <td>5.638802</td>\n",
       "      <td>7.351160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>10.944141</td>\n",
       "      <td>13.902410</td>\n",
       "      <td>17.068285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>4.117705</td>\n",
       "      <td>4.820570</td>\n",
       "      <td>5.672948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>2.737851</td>\n",
       "      <td>3.517854</td>\n",
       "      <td>4.493963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>2.222531</td>\n",
       "      <td>4.483961</td>\n",
       "      <td>6.030576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>-1.047628</td>\n",
       "      <td>1.319560</td>\n",
       "      <td>3.686026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.5        0.9\n",
       "2024-11-01   3.511388   5.638802   7.351160\n",
       "2024-12-01  10.944141  13.902410  17.068285\n",
       "2025-01-01   4.117705   4.820570   5.672948\n",
       "2025-02-01   2.737851   3.517854   4.493963\n",
       "2025-03-01   2.222531   4.483961   6.030576\n",
       "2025-04-01  -1.047628   1.319560   3.686026"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_por_material[20000400003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "c15acda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado: mensual_modificado_completo.xlsx\n",
      "Orden de columnas: ['Material', 'Fecha', '0.1', '0.5', '0.9']\n",
      "Formato de fecha: YYYY-MM-DD\n"
     ]
    }
   ],
   "source": [
    "exportar_predicciones_consolidado(predicciones_por_material, \"mensual_modificado_completo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "982f5a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 23:28:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting model with name: lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-04-06-24-816 <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#5356\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5356</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 23:28:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting model with name: lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-04-06-24-816 \u001b]8;id=565771;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=19646;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#5356\u001b\\\u001b[2m5356\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/21/25 23:28:27] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration with name:                             <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4995\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4995</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-04-06-24-816                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/21/25 23:28:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration with name:                             \u001b]8;id=136362;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=750951;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4995\u001b\\\u001b[2m4995\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-04-06-24-816                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint with name:                                           <a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4985\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4985</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         lilipink-forecasting-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-22-04-06-24-816                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint with name:                                           \u001b]8;id=660670;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=695552;file://c:\\Users\\Usuario\\Desktop\\Proyecto_lilipink\\venv\\Lib\\site-packages\\sagemaker\\session.py#4985\u001b\\\u001b[2m4985\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         lilipink-forecasting-\u001b[1;36m2025\u001b[0m-05-22-04-06-24-816                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
